PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT	PM
J	Gepperth, A				Gepperth, Alexander			Processing and Transmission of Confidence in Recurrent Neural Hierarchies	NEURAL PROCESSING LETTERS			English	Article						Recurrent neural networks; Neural coding; Bayesian inference; Response latency	DYNAMIC FIELD-THEORY; RESPONSE COMPETITION; POPULATION CODES; LATENCY; REPRESENTATIONS; COMPUTATION; DECISIONS; ATTENTION; CORTEX; MODEL	This article addresses the construction of hierarchies from dynamic attractor networks. We claim that such networks, e.g., dynamic neural fields (DNFs), contain a data model which is encoded in their lateral connections, and which describes typical properties of afferent inputs. This allows to infer the most likely interpretation of inputs, robustly expressed through the position of the attractor state. The principal problem resides in the fact that positions of attractor states alone do not reflect the quality of match between input and data model, termed decision confidence. In hierarchies, this inevitably leads to final decisions which are not Bayes-optimal when inputs exhibit different degrees of ambiguity or conflict, since the resulting differences in confidence will be ignored by downstream layers. We demonstrate a solution to this problem by showing that a correctly parametrized DNF layer can encode decision confidence into the latency of the attractor state in a well-defined way. Conversely, we show that input stimuli gain competitive advantages w.r.t. each other as a function of their relative latency, thus allowing downstream layers to decode attractor latency in an equally well-defined way. Putting these encoding and decoding mechanisms together, we construct a three-stage hierarchy of DNF layers and show that the top-level layer can take Bayes-optimal decisions when the decisions in the lowest hierarchy levels have variable degrees of confidence. In the discussion, we generalize these findings, suggesting a novel possibility to represent and manipulate probabilistic information in recurrent networks without any need for log-encoding, just using the biologically well-founded effect of response latency as an additional coding dimension.	[Gepperth, Alexander] ENSTA ParisTech, F-91762 Palaiseau, France; [Gepperth, Alexander] INRIA FLOWERS, INRIA Bordeaux Sud Ouest, FLOWERS Res Team, F-33405 Talence, France	Gepperth, A (reprint author), ENSTA ParisTech, Blvd Marechaux, F-91762 Palaiseau, France.	alexander.gepperth@ensta-paristech.fr					Amari S-I, 1990, P IEEE, V78, P1441; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bicho E, 2010, FRONTIERS NEUROROBOT, V4, P5, DOI [10.3389/fnbot.2010.00005, DOI 10.3389/FNBOT.2010.00005]; Bishop CM, 2006, PATTERN RECOGNITION; Borowsky R, 1996, J EXP PSYCHOL LEARN, V22, P63, DOI 10.1037/0278-7393.22.1.63; Cisek P, 2007, PHILOS T R SOC B, V362, P1585, DOI 10.1098/rstb.2007.2054; Cisek P, 2006, J NEUROSCI, V26, P9761, DOI 10.1523/JNEUROSCI.5605-05.2006; Cuijpers RH, 2008, LECT NOTES COMPUT SC, V5164, P228, DOI 10.1007/978-3-540-87559-8_24; Deco G, 2004, VISION RES, V44, P621, DOI 10.1016/j.visres.2003.09.037; Deneve S, 2003, NEURON, V37, P347, DOI 10.1016/S0896-6273(02)01184-4; Erlhagen W, 2002, PSYCHOL REV, V109, P545, DOI 10.1037//0033-295X.109.3.545; Faubel C, 2008, NEURAL NETWORKS, V21, P562, DOI 10.1016/j.neunet.2008.03.007; Garcia Ortiz AM, 2009, 1 INT C COGN NEUR; Gautrais J, 1998, BIOSYSTEMS, V48, P57, DOI 10.1016/S0303-2647(98)00050-1; Gepperth A, 2012, NEURAL NETWORKS, V41, P39; Gold JI, 2001, TRENDS COGN SCI, V5, P10, DOI 10.1016/S1364-6613(00)01567-9; Hazeltine E, 2000, J COGNITIVE NEUROSCI, V12, P118, DOI 10.1162/089892900563984; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Johnson JS, 2008, NEW IDEAS PSYCHOL, V26, P227, DOI 10.1016/j.newideapsych.2007.07.007; Kiani R, 2005, J NEUROPHYSIOL, V94, P1587, DOI 10.1152/jn.00540.2004; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Kupper R, 2005, NEUROCOMPUTING, V65, P189, DOI 10.1016/j.neucom.2004.10.006; Lecun Y., 2004, P CVPR 04; Ma WJ, 2006, NAT NEUROSCI, V9, P1432, DOI 10.1038/nn1790; Michelet T, 2010, J NEUROPHYSIOL, V104, P119, DOI 10.1152/jn.00819.2009; Mikhailova I, 2005, BIOL CYBERN, V92, P82, DOI 10.1007/s00422-004-0537-8; Oram MW, 2002, PHILOS T ROY SOC B, V357, P987, DOI 10.1098/rstb.2002.1113; Pouget A, 2002, NAT REV NEUROSCI, V3, P741, DOI 10.1038/nrn914; Rao RPN, 2004, NEURAL COMPUT, V16, P1, DOI 10.1162/08997660460733976; Reich DS, 2001, J NEUROPHYSIOL, V85, P1039; Rougier NP, 2006, NEURAL NETWORKS, V19, P573, DOI 10.1016/j.neunet.2005.04.004; Sandamirskaya Y, 2010, P 19 IEEE INT WORKSH; Schrader S, 2009, NEURAL NETWORKS, V22, P1055, DOI 10.1016/j.neunet.2009.07.021; Taylor JG, 1999, BIOL CYBERN, V80, P393, DOI 10.1007/s004220050534; Turrigiano GG, 2004, NAT REV NEUROSCI, V5, P97, DOI 10.1038/nrn1327; Van Rullen R, 1998, BIOSYSTEMS, V48, P229, DOI 10.1016/S0303-2647(98)00070-7; Wilimzig C, 2006, NEURAL NETWORKS, V19, P1059, DOI 10.1016/j.neunet.2006.03.003; Zemel RS, 1998, NEURAL COMPUT, V10, P403, DOI 10.1162/089976698300017818; Zibner S. K. U., 2010, P INT C DEV LEARN IC	39	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621	1573-773X		NEURAL PROCESS LETT	Neural Process. Lett.	AUG	2014	40	1					75	91		10.1007/s11063-013-9311-z		17	Computer Science, Artificial Intelligence	Computer Science	AK8TD	WOS:000338700000005		
J	Grachten, M; Krebs, F				Grachten, Maarten; Krebs, Florian			An Assessment of Learned Score Features for Modeling Expressive Dynamics in Music	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						Computational Musicology; Unsupervised Learning; Expressive Music Performance	NONNEGATIVE MATRIX FACTORIZATION; ALGORITHM; PERFORMANCE; RULES	The study of musical expression is an ongoing and increasingly data-intensive endeavor, in which machine learning techniques can play an important role. The purpose of this paper is to evaluate the utility of unsupervised feature learning in the context of modeling expressive dynamics, in particular note intensities of performed music. We use a note centric representation of musical contexts, which avoids shortcomings of existing musical representations. With that representation, we perform experiments in which learned features are used to predict note intensities. The experiments are done using a data set comprising professional performances of Chopin's complete piano repertoire. For feature learning we use Restricted Boltzmann machines, and contrast this with features learned using matrix decomposition methods. We evaluate the results both quantitatively and qualitatively, identifying salient learned features, and discussing their musical relevance.	[Grachten, Maarten] Austrian Res Inst Artificial Intelligence OFAI, Vienna, Austria; [Krebs, Florian] Johannes Kepler Univ Linz, Dept Computat Percept, A-4040 Linz, Austria	Grachten, M (reprint author), Austrian Res Inst Artificial Intelligence OFAI, Vienna, Austria.				Austrian Science Fund (FWF) [Z159, TRP-109]; European Union Seventh Framework Programme FP7 through the PHENICX project [601166]	This work was supported in part by the Austrian Science Fund (FWF) in the context of the projects Z159 "Wittgenstein Award" and TRP-109, and in part by the European Union Seventh Framework Programme FP7 through the PHENICX project (grant agreement no. 601166). The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Mitsunori Ogihara.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Arzt A, 2008, FR ART INT, V178, P241, DOI 10.3233/978-1-58603-891-5-241; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9; Binet A., 1896, AN PSY, P201; Boulanger-Lewandowski N., 2012, P 29 INT C MACH LEAR; Erhan D, 2009, VISUALIZING HIGHER L; Flossmann S., 2010, J NEW MUSIC RES, V39, P369; Friberg A, 2006, ADV COGNITIVE PSYCHO, V2, P145, DOI DOI 10.2478/V10053-008-0052-X; Goebl W, 2003, J ACOUST SOC AM, V114, P2273, DOI 10.1121/1.1605387; Grachten M., 2004, LECT NOTES COMPUTER; Grachten M, 2012, J NEW MUSIC RES, V41, P311, DOI 10.1080/09298215.2012.731071; Halko N., 2009, APPL COMPUTAT MATH C; Hazan A, 2006, LECT NOTES COMPUT SC, V3907, P676; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Humphrey E. J., 2012, P 13 INT SOC MUS INF; Kivy Peter, 1980, CORDED SHELL REFLECT; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee DD, 1999, NATURE, V401, P788; Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756; Lockett A. J., 2009, AI0904 U TX AUST; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mohamed A., 2011, P ICASSP 2011; MOOG RA, 1990, COMPUT MUSIC J, V14, P52, DOI 10.2307/3679712; Schluter J., 2011, THESIS TU MUNCHEN MU; Schluter J., 2011, P 10 INT C MACH LEAR; Seashore C., 1938, PSYCHOL MUSIC; Spiliopoulou A, 2011, LECT NOTES ARTIF INT, V6913, P289, DOI 10.1007/978-3-642-23808-6_19; SUNDBERG J, 1991, MUSIC PERCEPT, V9, P71; SUNDBERG J, 1980, J ACOUST SOC AM, V68, P772, DOI 10.1121/1.384816; Sutskever I., 2007, P AISTATS; TODD NPM, 1992, J ACOUST SOC AM, V91, P3540; Widmer G, 2003, ARTIF INTELL, V146, P129, DOI 10.1016/S0004-3702(03)00016-X; Widmer G, 2009, AI MAG, V30, P35	35	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210	1941-0077		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	AUG	2014	16	5					1211	1218		10.1109/TMM.2014.2311013		8	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	AN0SZ	WOS:000340295600004		
J	Ji, NN; Zhang, JS; Zhang, CX; Wang, L				Ji, Nannan; Zhang, Jiangshe; Zhang, Chunxia; Wang, Lei			Discriminative restricted Boltzmann machine for invariant pattern recognition with linear transformations	PATTERN RECOGNITION LETTERS			English	Article						Discriminative restricted Boltzmann machine; Invariant pattern recognition; Linear transformation; Probabilistic max-pooling; Transformation invariance	ORDER NEURAL-NETWORKS; OBJECT RECOGNITION; CHARACTER-RECOGNITION; ROTATION; REPRESENTATIONS; CLASSIFICATION; MOMENTS; SCALE; NETS	How to make a machine automatically achieve invariant pattern recognition like human brain is still very challenging in machine learning community. In this paper, we present a single hidden-layer network TIClassRBM for invariant pattern recognition by incorporating linear transformations into discriminative restricted Boltzmann machine. In our model, invariant feature extraction and pattern classification can be implemented simultaneously. The mapping from input features to class label is represented by two groups of weights: transformed weights that connect hidden units to data, and pooling weights that connect pooling units yielded by probabilistic max-pooling to class label. All weights play an important role in the invariant pattern recognition. Moreover, TIClassRBM can handle general transformations contained in images, such as translation, rotation and scaling. The experimental studies on the variations of MNIST and NORB datasets demonstrate that the proposed model yields the best performance among some comparative models. (C) 2014 Elsevier B.V. All rights reserved.	[Ji, Nannan; Zhang, Jiangshe; Zhang, Chunxia] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China; [Wang, Lei] Xian Res Inst Nav Technol, Xian 710068, Shaanxi, Peoples R China	Zhang, JS (reprint author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.	jszhang@mail.xjtu.edu.cn			National Basic Research Program of China (973 Program) [2013CB329404]; National Natural Science Foundation of China [91230101, 61075006, 11131006, 11201367]; Research Fund for the Doctoral Program of Higher Education of China [20100201120048]	The authors would like to express their gratitude to the editor and two anonymous referees for their valuable comments and suggestions which lead to a substantial improvement of this paper. This work was supported by the National Basic Research Program of China (973 Program) under Grant No. 2013CB329404, the National Natural Science Foundation of China under Grant Nos. 91230101, 61075006, 11131006, 11201367, the Research Fund for the Doctoral Program of Higher Education of China under Grant No. 20100201120048.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Anh V.V., 1997, P IEEE INT C IM PROC, V2, P430; Barndorff-Nielsen O. E., 1978, INFORM EXPONENTIAL F; Barra A, 2012, NEURAL NETWORKS, V34, P1, DOI 10.1016/j.neunet.2012.06.003; BEBIS GN, 1992, PATTERN RECOGN, V25, P25, DOI 10.1016/0031-3203(92)90004-3; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bracewell R. N., 1978, FOURIER TRANSFORM IT; CAELLI TM, 1988, PATTERN RECOGN, V21, P205, DOI 10.1016/0031-3203(88)90055-6; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; FUKUMI M, 1992, IEEE T NEURAL NETWOR, V3, P272, DOI 10.1109/72.125868; FUKUSHIMA K, 1992, NEUROCOMPUTING, V4, P221, DOI 10.1016/0925-2312(92)90028-N; GILES CL, 1987, APPL OPTICS, V26, P4972, DOI 10.1364/AO.26.004972; Goh H., 2010, NIPS WORKSH DEEP LEA; Hertz J, 1991, INTRO THEORY NEURAL; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HUSSAIN B, 1994, IEEE T PATTERN ANAL, V16, P98, DOI 10.1109/34.273711; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605; KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; Kullback S., 1968, INFORM THEORY STAT; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Larochelle H., 2012, J MACH LEARN RES, V12, P643; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; LeCun Y., 2004, P COMP VIS PATT REC, V2, pII, DOI 10.1109/CVPR.2004.1315150; Lee H., 2007, P ADV NEUR INF PROC, V20, P1416; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; LI YJ, 1992, PATTERN RECOGN, V25, P723, DOI 10.1016/0031-3203(92)90135-6; LIN CC, 1987, IEEE T PATTERN ANAL, V9, P686; MINNIX JI, 1992, IEEE T KNOWL DATA EN, V4, P162, DOI 10.1109/69.134253; Minsky M, 1969, PERCEPTRONS; MOODY JE, 1992, P ADV NEUR INF PROC, V4, P847; PERANTONIS SJ, 1992, IEEE T NEURAL NETWOR, V3, P241, DOI 10.1109/72.125865; Rifai S., 2011, P 28 INT C MACH LEAR, P833; Rumelhart D.E., 1989, PARALLEL DISTRIBUTED, P318; Sohn K., 2012, P 29 INT C MACH LEAR, P1311; SPIRKOVSKA L, 1992, PATTERN RECOGN, V25, P975, DOI 10.1016/0031-3203(92)90062-N; SPIRKOVSKA L, 1993, IEEE T NEURAL NETWOR, V4, P276, DOI 10.1109/72.207615; Tkacik G, 2006, QBIO0611072 ARXIV; Vincent P, 2010, J MACH LEARN RES, V11, P3371; WANG SS, 1994, PATTERN RECOGN, V27, P1735, DOI 10.1016/0031-3203(94)90090-6; WECHSLER H, 1988, IEEE T PATTERN ANAL, V10, P811, DOI 10.1109/34.9104; WIDROW B, 1988, COMPUTER, V21, P25, DOI 10.1109/2.29	45	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655	1872-7344		PATTERN RECOGN LETT	Pattern Recognit. Lett.	AUG 1	2014	45						172	180		10.1016/j.patrec.2014.03.022		9	Computer Science, Artificial Intelligence	Computer Science	AI9AW	WOS:000337219200023		
J	Li, B; Sim, KC				Li, Bo; Sim, Khe Chai			A Spectral Masking Approach to Noise-Robust Speech Recognition Using Deep Neural Networks	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep neural network; noise robustness; spectral masking	BACKGROUND-NOISE	Improving the noise robustness of automatic speech recognition systems has been a challenging task for many years. Recently, it was found that Deep Neural Networks (DNNs) yield large performance gains over conventional GMM-HMM systems, when used in both hybrid and tandem systems. However, they are still far from the level of human expectations especially under adverse environments. Motivated by the separation-prior-to-recognition process of the human auditory system, we propose a robust spectral masking system where power spectral domain masks are predicted using a DNN trained on the same filter-bank features used for acoustic modeling. To further improve performance, Linear Input Network (LIN) adaptation is applied to both the mask estimator and the acousticmodel DNNs. Since the estimation of LINs for the mask estimator requires stereo data, which is not available during testing, we proposed using the LINs estimated for the acoustic model DNNs to adapt the mask estimators. Furthermore, we used the same set of weights obtained from pre-training for the input layers of both the mask estimator and the acoustic model DNNs to ensure a better consistency for sharing LINs. Experimental results on benchmark Aurora2 and Aurora4 tasks demonstrated the effectiveness of our system, which yielded Word Error Rates (WERs) of 4.6% and 11.8% respectively. Furthermore, the simple averaging of posteriors from systems with and without spectral masking can further reduce the WERs to 4.3% on Aurora2 and 11.4% on Aurora4.	[Li, Bo; Sim, Khe Chai] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore	Li, B (reprint author), Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.	li-bo@outlook.com; simkc@comp.nus.edu.sg					Abrash V., 1995, P EUROSPEECH 1995, P2183; Boldt J., 2011, THESIS AALBORG U AAL; Bourlard H., 1994, CONNECTIONIST SPEECH, V247; BOURLARD H, 1993, IEEE T NEURAL NETWOR, V4, P893, DOI 10.1109/72.286885; Brown G. J., 1992, THESIS U SHEFFIELD S; Chow S. L., 1996, STAT SIGNIFICANCE RA, V1; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Gemello R., 1998, P IJCNN, V3, P2190; Gemmeke J. F., 2009, P INTERSPEECH; Hartmann W, 2013, IEEE T AUDIO SPEECH, V21, P1993, DOI 10.1109/TASL.2013.2263802; Hartmann W., 2011, RECONSTRUCTION; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hirsch H. G., 2000, P AUT SPEECH REC ASR; Johnson D., QUICKNET; Keronen S., 2012, COMPUT SPEECH LANG, P798; Li B., 2013, P ICASSP, P7408; Li B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P526; Li B., 2013, P INTERSPEECH, P3002; Li B., 2013, P ASRU, P279; Lyon R. F., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing; Maas AL, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P22; Narayanan A., 2013, P OSU CISRC 6 13 TR1; Narayanan A, 2013, J ACOUST SOC AM, V133, P3083, DOI 10.1121/1.4798661; Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038; Neto JP, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1293; Neto JP, 1996, INT CONF ACOUST SPEE, P3382, DOI 10.1109/ICASSP.1996.550603; Parihar N., 2002, AURORA WORKING GROUP; Povey D., 2011, P ASRU; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Rennie SJ, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4297; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100; Seltzer ML, 2004, SPEECH COMMUN, V43, P379, DOI 10.1016/j.specom.2004.03.006; Vinyals O, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4085; Wang D., 2005, SPEECH SEPARATION HU; Wang D., 2006, COMPUTATIONAL AUDITO; Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233; Wang DLL, 1999, IEEE T NEURAL NETWOR, V10, P684, DOI 10.1109/72.761727; Wang YQ, 2013, INT CONF ACOUST SPEE, P7932, DOI 10.1109/ICASSP.2013.6639209	40	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	AUG	2014	22	8					1296	1305		10.1109/TASLP.2014.2329237		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AM7HL	WOS:000340036300007		
J	Yousefi, A; Dibazar, AA; Berger, TW				Yousefi, Ali; Dibazar, Alireza A.; Berger, Theodore W.			Synaptic dynamics: Linear model and adaptation algorithm	NEURAL NETWORKS			English	Article						Spiking neural networks; Plasticity; Learning; Bio-inspired models	SPIKING NEURAL-NETWORKS; TIMING-DEPENDENT PLASTICITY; SYNAPSES; NEURONS; TRAINS; RELIABILITY; STDP; BCM	In this research, temporal processing in brain neural circuitries is addressed by a dynamic model of synaptic connections in which the synapse model accounts for both pre- and post-synaptic processes determining its temporal dynamics and strength. Neurons, which are excited by the post-synaptic potentials of hundred of the synapses, build the computational engine capable of processing dynamic neural stimuli. Temporal dynamics in neural models with dynamic synapses will be analyzed, and learning algorithms for synaptic adaptation of neural networks with hundreds of synaptic connections are proposed. The paper starts by introducing a linear approximate model for the temporal dynamics of synaptic transmission. The proposed linear model substantially simplifies the analysis and training of spiking neural networks. Furthermore, it is capable of replicating the synaptic response of the non-linear facilitation depression model with an accuracy better than 92.5%. In the second part of the paper, a supervised spike-in-spike-out learning rule for synaptic adaptation in dynamic synapse neural networks (DSNN) is proposed. The proposed learning rule is a biologically plausible process, and it is capable of simultaneously adjusting both pre- and post-synaptic components of individual synapses. The last section of the paper starts with presenting the rigorous analysis of the learning algorithm in a system identification task with hundreds of synaptic connections which confirms the learning algorithm's accuracy, repeatability and scalability. The DSNN is utilized to predict the spiking activity of cortical neurons and pattern recognition tasks. The DSNN model is demonstrated Lobe a generative model capable of producing different cortical neuron spiking patterns and CA1 Pyramidal neurons recordings. A single-layer DSNN classifier on a benchmark pattern recognition task outperforms a 2-Layer Neural Network and GMM classifiers while having fewer numbers of free parameters and decides with a shorter observation of data. DSNN performance in the benchmark pattern recognition problem shows 96.7% accuracy in classifying three classes of spiking activity. (C) 2014 Elsevier Ltd. All rights reserved.	[Yousefi, Ali] Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA; [Dibazar, Alireza A.; Berger, Theodore W.] Univ So Calif, Dept Biomed Engn, Los Angeles, CA 90089 USA	Dibazar, AA (reprint author), 1042 Downey Way,DRB 140, Los Angeles, CA 90089 USA.	ayousefi@usc.edu; dibazar@usc.edu; berger@usc.edu					Abbott L. F., 1997, SCIENCE, V275, P221, DOI [10.1126/science.275.5297.221, DOI 10.1126/SCIENCE.275.5297.221]; Bartlett P.L., 2011, 11060665 ARXIV; Belatreche A, 2007, SOFT COMPUT, V11, P239, DOI [10.1007/S00500-006-0065-7, 10.1007/s00500-006-0065-7]; Berry MJ, 1997, P NATL ACAD SCI USA, V94, P5411, DOI 10.1073/pnas.94.10.5411; Bohte S. M., 2004, P ADV NEUR INF PROC, P270; Bohte S.M., 2003, THESIS CTR MATH COMP; Bohte SM, 2002, NEUROCOMPUTING, V48, P17, DOI 10.1016/S0925-2312(01)00658-0; Booij O., 2004, THESIS U AMSTERDAM; Burkitt AN, 2004, NEURAL COMPUT, V16, P885, DOI 10.1162/089976604773135041; Bush D, 2010, NEURAL COMPUT, V22, P2059, DOI 10.1162/NECO_a_00003-Bush; Davis B. A., 2003, P INT JOINT C NEUR N, V4; Deco G, 1999, NEURAL COMPUT, V11, P919, DOI 10.1162/089976699300016502; Dittman JS, 2000, J NEUROSCI, V20, P1374; Fang HJ, 2010, NEURAL COMPUT, V22, P1060, DOI 10.1162/neco.2009.10-08-885; Fiete IR, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.048104; Fiete I.R., 2003, THESIS HARVARD U CAM; Gerstner W., 2006, SPIKING NEURON MODEL; Ghaderi V. S., 2012, ANN INT C IEEE ENG M; Ghosh-Dastidar S, 2009, NEURAL NETWORKS, V22, P1419, DOI 10.1016/j.neunet.2009.04.003; Gupta A., 2009, INT JOINT C NEUR NET; Gutig R, 2006, NAT NEUROSCI, V9, P420, DOI 10.1038/nn1643; Hatsopoulos N, 2003, NEUROCOMPUTING, V52-4, P25, DOI 10.1016/S0925-2312(02)00773-7; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Izhikevich EM, 2003, NEURAL COMPUT, V15, P1511, DOI 10.1162/089976603321891783; Jin YC, 2007, LECT NOTES COMPUT SC, V4668, P370; Kreuz T, 2007, J NEUROSCI METH, V165, P151, DOI 10.1016/j.jneumeth.2007.05.031; Lee K, 2008, NEUROCOMPUTING, V71, P3037, DOI 10.1016/j.neucom.2007.09.009; Legenstein R, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000180; Liaw JS, 1996, HIPPOCAMPUS, V6, P591; Liaw JS, 1999, NEUROCOMPUTING, V26-7, P199, DOI 10.1016/S0925-2312(99)00063-6; Maass W, 1999, NEURAL COMPUT, V11, P903, DOI 10.1162/089976699300016494; MAINEN ZF, 1995, SCIENCE, V268, P1503, DOI 10.1126/science.7770778; Masquelier T, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001377; Mongillo G, 2008, SCIENCE, V319, P1543, DOI 10.1126/science.1150769; Morrison A, 2008, BIOL CYBERN, V98, P459, DOI 10.1007/s00422-008-0233-1; Pfister JP, 2006, NEURAL COMPUT, V18, P1318, DOI 10.1162/neco.2006.18.6.1318; Ponulak F, 2010, NEURAL COMPUT, V22, P467, DOI 10.1162/neco.2009.11-08-901; Rostro H., 2009, 09054810 ARXIV; Senn W, 2001, NEURAL COMPUT, V13, P35, DOI 10.1162/089976601300014628; Song S, 2000, NAT NEUROSCI, V3, P919; Storck J, 2001, NEURAL NETWORKS, V14, P275, DOI 10.1016/S0893-6080(00)00101-5; Strain T. J., 2006, INT JOINT C NEUR NET; Tiesinga PHE, 2002, NEURAL COMPUT, V14, P1629, DOI 10.1162/08997660260028647; Tsodyks M, 1998, NEURAL COMPUT, V10, P821, DOI 10.1162/089976698300017502; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1023/A:1022672621406; Xie XH, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.041909; Yousefi A., 2011, 2011 INT JOINT C NEU; Zucker RS, 2002, ANNU REV PHYSIOL, V64, P355, DOI 10.1146/annurev.physiol.64.092501.114547	48	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	AUG	2014	56						49	68		10.1016/j.neunet.2014.04.001		20	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AK7MJ	WOS:000338612100005	24867390	
J	Achler, T				Achler, Tsvi			Symbolic neural networks for cognitive capacities	BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES			English	Article						Symbolic neural networks; Auto-dissociative networks; Iterative neural networks; Regulatory feedback; Pattern recognition with symbolic networks; Gradient descent during recognition	MODEL	Pattern recognition (recognizing a pattern from inputs) and recall (describing or predicting the inputs associated with a recognizable pattern) are essential for neural-symbolic processing and cognitive capacities. Without them the brain cannot interact with the world e.g.: form internal representations and recall memory upon which it can perform logic and reason. Neural networks are efficient, biologically plausible algorithms that can perform large scale recognition. However, most neural network models of recognition perform recognition but not recall: they are sub-symbolic. It remains difficult to connect models of recognition with models of logic and emulate fundamental brain functions, because of the symbolic recall limitation. I introduce a completely symbolic neural network that is similar in function to standard feedforward neural networks but uses feedforward-feedback connections similar to auto-associative networks. However, unlike auto-associative networks, the symmetrical feedback connections are inhibitory not excitatory. Initially it may seem counterintuitive that recognition can even occur because the top-down connections are self-inhibitory. The self-inhibitory configuration is used to implement a gradient descent mechanism that functions during recognition not learning. The purpose of the gradient-descent is not to learn weights (weights are still learned during learning) but to find neuron activation. The advantage of this approach is the weights can now be symbolic (representing prototypes of expected patterns) allowing recall within neural networks. Moreover, considering the costs of both learning and recognition, this approach may be more efficient than feedforward recognition. I show that this model mathematically emulates standard feedforward model equations in single layer networks without hidden units. Comparisons that include more layers are planned in the future. (C) 2014 Elsevier B.V. All rights reserved.	ITOP Corp, Palo Alto, CA 94306 USA	Achler, T (reprint author), ITOP Corp, 3168 South Court, Palo Alto, CA 94306 USA.	achler@gmail.com					Achler T., 2011, AAAI P; Achler T., 2011, RELEVANCE TIME DOMAI; Achler T., 2009, P 2009 IEEE INT JOIN; Carpenter G. A., 1987, COMPUTER VISION GRAP, V13, P37, DOI DOI 10.1016/S0734-189X(87)80014-2; de Penning L., 2014, P AUT AG MULT SYST A; Fodor J. A., 1988, COGNITION, V78, P3; Franklin S., 2006, LIDA ARCHITECTURE AD; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; KOSKO B, 1988, IEEE T SYST MAN CYB, V18, P49, DOI 10.1109/21.87054; Laird J. E, 2008, ART GEN INT C MEMPH; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; MCFADDEN FE, 1993, NEURAL NETWORKS, V6, P667, DOI 10.1016/S0893-6080(05)80110-8; Meyer DE, 1997, PSYCHOL REV, V104, P3, DOI 10.1037//0033-295X.104.1.3; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pearl J, 1988, PROBABILISTIC REASON; Poole D, 2008, INDEPENDENT CHOICE L, P222; Rao R. P, 1999, NATURE NEUROSCIENCE; Rao R. P. N, 2011, COGNITIVE SCI; REGGIA JA, 1992, NEURAL COMPUT, V4, P287, DOI 10.1162/neco.1992.4.3.287; Rifkin R, 2004, J MACH LEARN RES, V5, P101; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P234, DOI 10.1162/neco.1992.4.2.234; Shastri L, 2000, LECT NOTES ARTIF INT, V1778, P28; Sun R., 2002, DUALITY MIND BOTTOM; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P2315; Vapnik V. N., 1995, NATURE STAT LEARNING; Wilkinson J. H., 1999, ALGEBRAIC EIGENVALUE; Williams R. J., 1994, BACK PROPAGATION THE	30	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	2212-683X	2212-6848		BIOL INSPIR COGN ARC	Biol. Inspired Cogn. Archit.	JUL	2014	9				SI		71	81		10.1016/j.bica.2014.07.001		11	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	CF7NV	WOS:000352744400007		
J	Badino, L; D'Ausilio, A; Fadiga, L; Metta, G				Badino, Leonardo; D'Ausilio, Alessandro; Fadiga, Luciano; Metta, Giorgio			Computational Validation of the Motor Contribution to Speech Perception	TOPICS IN COGNITIVE SCIENCE			English	Article						Motor theory of speech perception; Transcranial magnetic stimulation; Automatic speech recognition; Machine learning	PREMOTOR CORTEX; COMPREHENSION; RECOGNITION; DISCRIMINATION; LANGUAGE; APHASIA; IDENTIFICATION; ACOUSTICS; MOVEMENTS; FEATURES	Action perception and recognition are core abilities fundamental for human social interaction. A parieto-frontal network (the mirror neuron system) matches visually presented biological motion information onto observers' motor representations. This process of matching the actions of others onto our own sensorimotor repertoire is thought to be important for action recognition, providing a non-mediated "motor perception" based on a bidirectional flow of information along the mirror parieto-frontal circuits. State-of-the-art machine learning strategies for hand action identification have shown better performances when sensorimotor data, as opposed to visual information only, are available during learning. As speech is a particular type of action (with acoustic targets), it is expected to activate a mirror neuron mechanism. Indeed, in speech perception, motor centers have been shown to be causally involved in the discrimination of speech sounds. In this paper, we review recent neurophysiological and machine learning-based studies showing (a) the specific contribution of the motor system to speech perception and (b) that automatic phone recognition is significantly improved when motor data are used during training of classifiers (as opposed to learning from purely auditory data).	[Badino, Leonardo; D'Ausilio, Alessandro; Fadiga, Luciano; Metta, Giorgio] IIT Fdn Ist Italiano Tecnol, RBCS Robot Brain & Cognit Sci Dept, I-16163 Genoa, Italy; [Fadiga, Luciano] Univ Ferrara, DSBTA Sect Human Physiol, I-44100 Ferrara, Italy; [Metta, Giorgio] Univ Genoa, DIST Dipartimento Informat, I-16126 Genoa, Italy	Badino, L (reprint author), IIT Fdn Ist Italiano Tecnol, RBCS Robot Brain & Cognit Sci Dept, Via Morego 30, I-16163 Genoa, Italy.	leonardo.Badino@iit.it	D'Ausilio, Alessandro/A-3997-2010	D'Ausilio, Alessandro/0000-0003-1472-6200			Badino L., 2012, MIAM FL IEEE WORKSH; Benzeghiba M, 2007, SPEECH COMMUN, V49, P763, DOI 10.1016/j.specom.2007.02.006; Bever T. G., 2010, BIOLINGUISTICS, V4, P174; Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198; BISHOP DVM, 1990, J SPEECH HEAR RES, V33, P210; Boatman DF, 2005, J NEUROSCI, V25, P5475, DOI 10.1523/JNEUROSCI.0936-05.2005; BROWMAN CP, 1992, PHONETICA, V49, P155; Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006; RIZZOLATTI G, 1988, EXP BRAIN RES, V71, P491, DOI 10.1007/BF00248742; Castellini C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024055; Christen HJ, 2000, DEV MED CHILD NEUROL, V42, P122, DOI 10.1017/S0012162200000232; D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017; D'Ausilio A, 2012, J NEUROLINGUIST, V25, P328, DOI 10.1016/j.jneuroling.2010.02.003; D'Ausilio A, 2011, NEUROPSYCHOLOGIA, V49, P3670, DOI 10.1016/j.neuropsychologia.2011.09.022; D'Ausilio A, 2011, BRAIN LANG, V118, P9, DOI 10.1016/j.bandl.2011.02.007; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028; Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x; FOWLER CA, 1986, J PHONETICS, V14, P3; Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857; Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593; Grimaldi M., 2008, P LANGTECH 2008 ROM; Hickok G, 2008, BRAIN LANG, V107, P179, DOI 10.1016/j.bandl.2008.09.006; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang X., 2001, SPOKEN LANGUAGE PROC; King S, 2007, J ACOUST SOC AM, V121, P723, DOI 10.1121/1.2404622; KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301; LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279; Lindblom B., 1979, J PHONETICS, V7, P146; Livescu K., 2003, P EUR GEN SWITZ, V4, P2529; Londei A, 2010, HUM BRAIN MAPP, V31, P567, DOI 10.1002/hbm.20888; Markov K, 2006, SPEECH COMMUN, V48, P161, DOI 10.1016/j.specom.2005.07.003; MASSARO DW, 1972, PSYCHOL REV, V79, P124, DOI 10.1037/h0032264; Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064; Mitra V, 2012, J ACOUST SOC AM, V131, P2270, DOI 10.1121/1.3682038; Mitra V, 2010, IEEE J-STSP, V4, P1027, DOI 10.1109/JSTSP.2010.2076013; Mohamed A., 2012, IEEE T AUDIO SPEECH, V20; Moineau S, 2005, J SPEECH LANG HEAR R, V48, P884, DOI 10.1044/1092-4388(2005/061); Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009; Murakami T, 2011, NEUROPSYCHOLOGIA, V49, P2045, DOI 10.1016/j.neuropsychologia.2011.03.034; NAESER MA, 1989, BRAIN, V112, P1, DOI 10.1093/brain/112.1.1; Ostendorf M., 1999, P IEEE AUT SPEECH RE, V1, P79; Pfeifer R., 2008, HDB COGNITIVE SCI EM, P121, DOI 10.1016/B978-0-08-046616-3.00007-4; Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103; Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811; Qin C., 2007, INT ANTW BELG P; Richmond K, 2003, COMPUT SPEECH LANG, V17, P153, DOI 10.1016/S0885-2308(03)00005-6; Roweiss S., 1999, THESIS CALTECH PASAD; Roy AC, 2008, J PHYSIOLOGY-PARIS, V102, P101, DOI 10.1016/j.jphysparis.2008.03.006; Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002; Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006; Stevens K. N., 1967, MODELS PERCEPTION SP; Toda T., 2007, SPEECH COMMUN, V50, P215; Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0; WELLER M, 1993, J NEUROL, V240, P199, DOI 10.1007/BF00818705; Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263; Wrench A., 2000, P 5 SEM SPEECH PROD; Wrench A. A., 2000, P ICSLP BEIJ CHIN, P145; Zlokarnik I., 1995, J ACOUST SOC AM, V97, P3246, DOI 10.1121/1.411699	60	0	0	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1756-8757	1756-8765		TOP COGN SCI	Top. Cogn. Sci.	JUL	2014	6	3					461	475		10.1111/tops.12095		15	Psychology, Experimental	Psychology	AM9DK	WOS:000340180000009	24935820	
J	Bahari, MH; Dehak, N; Van Hamme, H; Burget, L; Ali, AM; Glass, J				Bahari, Mohamad Hasan; Dehak, Najim; Van Hamme, Hugo; Burget, Lukas; Ali, Ahmed M.; Glass, Jim			Non-Negative Factor Analysis of Gaussian Mixture Model Weight Adaptation for Language and Dialect Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Non-negative factor analysis; model adaptation; Gaussian mixture model weight; dialect recognition; language recognition	SUPPORT VECTOR MACHINES; SPEAKER VERIFICATION; MATRIX FACTORIZATION; IDENTIFICATION; ALGORITHM; SPEECH	Recent studies show that Gaussian mixture model (GMM) weights carry less, yet complimentary, information to GMM means for language and dialect recognition. However, state-of-the-art language recognition systems usually do not use this information. In this research, a non-negative factor analysis (NFA) approach is developed for GMM weight decomposition and adaptation. This modeling, which is conceptually simple and computationally inexpensive, suggests a new low-dimensional utterance representation method using a factor analysis similar to that of the i-vector framework. The obtained subspace vectors are then applied in conjunction with i-vectors to the language/dialect recognition problem. The suggested approach is evaluated on the NIST 2011 and RATS language recognition evaluation (LRE) corpora and on the QCRI Arabic dialect recognition evaluation (DRE) corpus. The assessment results show that the proposed adaptation method yields more accurate recognition results compared to three conventional weight adaptation approaches, namely maximum likelihood re-estimation, non-negative matrix factorization, and a subspace multinomial model. Experimental results also show that the intermediate-level fusion of i-vectors and NFA subspace vectors improves the performance of the state-of-the-art i-vector framework especially for the case of short utterances.	[Bahari, Mohamad Hasan; Van Hamme, Hugo] Katholieke Univ Leuven, Ctr Proc Speech & Images, B-3001 Louvain, Belgium; [Dehak, Najim; Glass, Jim] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; [Burget, Lukas] Brno Univ Technol, Speech FIT, Brno 61266, Czech Republic; [Ali, Ahmed M.] Qatar Comp Res Inst, Doha, Qatar	Bahari, MH (reprint author), Katholieke Univ Leuven, Ctr Proc Speech & Images, B-3001 Louvain, Belgium.	mohamadhasan.ba-hari@esat.kuleuven.be; najim@csail.mit.edu; hugo.vanhamme@esat.kuleuven.be; burget@fit.vutbr.cz; amali@qf.org.qa; glass@csail.mit.edu	Van hamme, Hugo/D-6581-2012		European Commission; Bayesian Biometrics for Forensics; FWO; Defense Advanced Research Projects Agency (DARPA)	The works of M. H. Bahari and H. Van hamme were supported by the European Commission through the Marie-Curie ITN-project, Bayesian Biometrics for Forensics and the FWO as a travel grant for a long stay abroad. The work of N. Dehak was supported in part by the Defense Advanced Research Projects Agency (DARPA). The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Shinji Watanabe.	Bahari MH, 2013, INT CONF ACOUST SPEE, P7344, DOI 10.1109/ICASSP.2013.6639089; Bahari MH, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P506; Biadsy F., 2011, AUTOMATIC DIALECT AC; Bolker E. D., 2005, COMMON SENSE MATH; Brummer N., 2007, TUTORIAL USER MANUAL; Brummer N., 2006, P IEEE OD SPEAK LANG, P1; Brummer N., 2004, P ODYSSEY04 SPEAK LA; Campbell WM, 2007, INT CONF ACOUST SPEE, P989; Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086; Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307; Dehak N., 2011, P INTERSPEECH, P857; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda R. O., 1995, PATTERN CLASSIFICATI, V2nd; Glembek O, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P743; Hanani A., 2012, HUMAN COMPUTER RECOG; Hanani A, 2013, COMPUT SPEECH LANG, V27, P59, DOI 10.1016/j.csl.2012.01.003; Hatch A.O., 2006, P INTERSPEECH, V4; Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOUSE AS, 1977, J ACOUST SOC AM, V62, P708, DOI 10.1121/1.381582; Kenny P, 2008, IEEE T AUDIO SPEECH, V16, P980, DOI 10.1109/TASL.2008.925147; Kockmann M., 2010, P 11 ANN C INT SPEEC; Lee DD, 1999, NATURE, V401, P788; Leonard R. G., 1974, RADCTR742007TI347650; Li M, 2013, COMPUT SPEECH LANG, V27, P151, DOI 10.1016/j.csl.2012.01.008; Muthusamy YK, 1994, IEEE SIGNAL PROC MAG, V11, P33, DOI 10.1109/79.317925; Ng T., 2012, P INTERSPEECH; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Rodriguez-Fuentes L. J., 2012, ALBAYZIN 2012 LANGUA; Singer E., 2011, P SPEAK OD, P209; Snyman JA, 2005, APPL OPTIM, V97, P1, DOI 10.1007/b105200; Soufifar M, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4853; Soufifar M., 2011, P INT 2011, P2913; Soufifar M. M., 2013, P INTERSPEECH, P74; Vair C, 2006, P OD, P1; Walker K., 2012, P OD; Zhang XR, 2013, SPEECH COMMUN, V55, P893, DOI 10.1016/j.specom.2013.05.001; Zissman MA, 1996, IEEE T SPEECH AUDI P, V4, P31, DOI 10.1109/TSA.1996.481450; Zissman MA, 2001, SPEECH COMMUN, V35, P115, DOI 10.1016/S0167-6393(00)00099-6	39	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	JUL	2014	22	7					1117	1129		10.1109/TASLP.2014.2319159		13	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AK0RI	WOS:000338122000001		
J	Jiang, B; Song, Y; Wei, S; Liu, JH; McLoughlin, IV; Dai, LR				Jiang, Bing; Song, Yan; Wei, Si; Liu, Jun-Hua; McLoughlin, Ian Vince; Dai, Li-Rong			Deep Bottleneck Features for Spoken Language Identification	PLOS ONE			English	Article							SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; RECOGNITION; SPEAKER; SPEECH	A key problem in spoken language identification (LID) is to design effective representations which are specific to language information. For example, in recent years, representations based on both phonotactic and acoustic features have proven their effectiveness for LID. Although advances in machine learning have led to significant improvements, LID performance is still lacking, especially for short duration speech utterances. With the hypothesis that language information is weak and represented only latently in speech, and is largely dependent on the statistical properties of the speech content, existing representations may be insufficient. Furthermore they may be susceptible to the variations caused by different speakers, specific content of the speech segments, and background noise. To address this, we propose using Deep Bottleneck Features (DBF) for spoken LID, motivated by the success of Deep Neural Networks (DNN) in speech recognition. We show that DBFs can form a low-dimensional compact representation of the original inputs with a powerful descriptive and discriminative capability. To evaluate the effectiveness of this, we design two acoustic models, termed DBF-TV and parallel DBF-TV (PDBF-TV), using a DBF based i-vector representation for each speech utterance. Results on NIST language recognition evaluation 2009 (LRE09) show significant improvements over state-of-the-art systems. By fusing the output of phonotactic and acoustic approaches, we achieve an EER of 1.08%, 1.89% and 7.01% for 30 s, 10 s and 3 s test utterances respectively. Furthermore, various DBF configurations have been extensively evaluated, and an optimal system proposed.	[Jiang, Bing; Song, Yan; McLoughlin, Ian Vince; Dai, Li-Rong] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Anhui, Peoples R China; [Wei, Si; Liu, Jun-Hua] Anhui USTC iFlytek Co Ltd, iFlytek Res, Hefei, Anhui, Peoples R China	Song, Y (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Anhui, Peoples R China.	songy@ustc.edu.cn			National Nature Science Foundation of China [61273264]; National 973 program of China [2012CB326405]; Chinese Universities Scientific Fund [Wk2100060008]	This work was partially funded by the National Nature Science Foundation of China (Grant No. 61273264), the National 973 program of China (Grant No. 2012CB326405) and Chinese Universities Scientific Fund (Grant No. Wk2100060008). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Bao YB, 2012, INT CONF SIGN PROCES, P562; Bielefeld B, 1994, P 14 ANN SPEECH RES; Burget L, 2006, INT CONF ACOUST SPEE, P209; Campbell W, 2004, P IEEE INT C AC SPEE, P73; Campbell WM, 2007, INT CONF ACOUST SPEE, P989; Campbell WM, 2006, P IEEE INT C AC SPEE, V1; Campbell WM, 2006, COMPUT SPEECH LANG, V20, P210, DOI 10.1016/j.csl.2005.06.003; Castaldo F, 2007, IEEE T AUDIO SPEECH, V15, P1969, DOI 10.1109/TASL.2007.901823; Castaldo F, 2007, P ANN C INT SPEECH C, V7, P346; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307; Dehak N., 2009, THESIS ECOLE TECHNOL; Dehak N., 2011, P INTERSPEECH, P857; Diez M, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P274, DOI 10.1109/SLT.2012.6424235; Diez M, 2013, P ANN C INT SPEECH C; EADY SJ, 1982, LANG SPEECH, V25, P29; Fontaine V, 1997, P EUR C SPEECH COMM; Freund Y., 1994, UNSUPERVISED LEARNIN; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hubeika V, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P301; Jancik Z, 2010, P OD 2010 SPEAK LANG, P215; Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1435, DOI 10.1109/TASL.2006.881693; Kenny P, 2005, IEEE T SPEECH AUDI P, V13, P345, DOI 10.1109/TSA.2004.840940; KIRCHHOFF K, 2002, ACOUST SPEECH SIG PR, P761; Kohler MA, 2002, P 45 IEEE INT MIDW S, P69, DOI [10.1109/MWSCAS.2002.1186972, DOI 10.1109/MWSCAS.2002.1186972]; Martin A., 2010, P OD 2010 SPEAK LANG, P165; Martin A, 1997, P EUR C SPEECH COMM; Martin AF, 2008, P OD 2008 SPEAK LANG; Matejka P., 2005, P INT 2005 LISB PORT, P2237; Matrouf D, 1998, P INT C SPOK LANG PR, V98, P181; Qu D, 2003, P ISCA IEEE WORKSH S; Schwarz P, 2000, THESIS BRNO U TECHNO; Seide F., 2011, P ASRU, P24; Singer E, 2012, P OD SPEAK LANG REC, p[25, 209]; Siniscalchi SM, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P168; Song Y, 2013, ELECTRON LETT, V49, P1569, DOI 10.1049/el.2013.1721; Sugiyama M, 1991, P ICASSP, P813, DOI 10.1109/ICASSP.1991.150461; Torres-Carrasquillo Pedro A, 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, DOI 10.1109/ICASSP.2010.5495080; Torres-Carrasquillo PA, 2002, P ANN C INT SPEECH C; Vair C, 2006, P OD, P1; Xu Y, 2010, P INT S CHIN SPOK LA, P157; Yu D, 2010, P NEUR INF PROC SYST; Zissman MA, 1996, IEEE T SPEECH AUDI P, V4, P31, DOI 10.1109/TSA.1996.481450; Zue W, 1993, P EUR C SPEECH COMM, P1303	48	0	0	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	JUL 1	2014	9	7							e100795	10.1371/journal.pone.0100795		11	Multidisciplinary Sciences	Science & Technology - Other Topics	AM1UX	WOS:000339635000040	24983963	
J	Montufar, GF				Montufar, Guido F.			Universal Approximation Depth and Errors of Narrow Belief Networks with Discrete Units	NEURAL COMPUTATION			English	Article							EXPONENTIAL-FAMILIES; DEEP	We generalize recent theoretical work on the minimal number of layers of narrow deep belief networks that can approximate any probability distribution on the states of their visible units arbitrarily well. We relax the setting of binary units (Sutskever & Hinton, 2008; Le Roux & Bengio, 2008,2010; Montufar & Ay, 2011) to units with arbitrary finite state spaces and the vanishing approximation error to an arbitrary approximation error tolerance. For example, we show that a q-ary deep belief network with L >= 2 + q(inverted right perpendicular-delta inverted left perpendicular)-1/q-1 layers of width n <= m + log(q) (m) + 1 for some m is an element of N can approximate any probability distribution on {0, 1, ... , q - 1}(n) without exceeding a Kullback-Leibler divergence of delta. Our analysis covers discrete restricted Boltzmann machines and naive Bayes models as special cases.	Penn State Univ, Dept Math, University Pk, PA 16802 USA	Montufar, GF (reprint author), Penn State Univ, Dept Math, University Pk, PA 16802 USA.	montufar@mis.mpg.de			DARPA [FA8650-11-1-7145]	I was supported in part by DARPA grant FA8650-11-1-7145. I completed the revision of the original manuscript at the Max Planck Institute for Mathematics in the Sciences, Leipzig, Germany.	Ay N, 2006, KYBERNETIKA, V42, P517; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Freund Y, 1991, ADV NEURAL INFORM PR, V4, P912; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Long P. M., 2010, P 27 ICML, P703; Montufar G., 2012, P 9 WORKSH UNC PROC, P137; Montufar G., 2013, ONL P 1 INT C LEARN; Montufar G., 2011, ADV NEURAL INFORM PR, V24, P415; Montufar G, 2011, NEURAL COMPUT, V23, P1306, DOI 10.1162/NECO_a_00113; Montufar GF, 2013, KYBERNETIKA, V49, P23; Rauh J, 2013, KYBERNETIKA, V49, P199; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481	19	0	0	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667	1530-888X		NEURAL COMPUT	Neural Comput.	JUL	2014	26	7					1386	1407		10.1162/NECO_a_00601		22	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AI4ZW	WOS:000336876200007	24708370	
J	Shi, Y; Larson, M; Hanjalic, A				Shi, Yue; Larson, Martha; Hanjalic, Alan			Collaborative Filtering beyond the User-Item Matrix: A Survey of the State of the Art and Future Challenges	ACM COMPUTING SURVEYS			English	Article						Algorithms; Design; Performance; applications; challenges; collaborative filtering; recommender systems; social networks; survey	RECOMMENDER SYSTEMS; SOCIAL BOOKMARKING; NETWORKS; MODEL; INFORMATION; DISTRIBUTIONS; ALGORITHMS; DYNAMICS; REVIEWS; SCIENCE	Over the past two decades, a large amount of research effort has been devoted to developing algorithms that generate recommendations. The resulting research progress has established the importance of the user-item (U-I) matrix, which encodes the individual preferences of users for items in a collection, for recommender systems. The U-I matrix provides the basis for collaborative filtering (CF) techniques, the dominant framework for recommender systems. Currently, new recommendation scenarios are emerging that offer promising new information that goes beyond the U-I matrix. This information can be divided into two categories related to its source: rich side information concerning users and items, and interaction information associated with the interplay of users and items. In this survey, we summarize and analyze recommendation scenarios involving information sources and the CF algorithms that have been recently developed to address them. We provide a comprehensive introduction to a large body of research, more than 200 key references, with the aim of supporting the further development of recommender systems exploiting information beyond the U-I matrix. On the basis of this material, we identify and discuss what we see as the central challenges lying ahead for recommender system technology, both in terms of extensions of existing techniques as well as of the integration of techniques and technologies drawn from other research areas.	[Shi, Yue] Delft Univ Technol, NL-2600 AA Delft, Netherlands; [Larson, Martha; Hanjalic, Alan] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Dept Intelligent Syst, Multimedia Informat Retrieval Lab, NL-2628 CD Delft, Netherlands	Shi, Y (reprint author), Yahoo Labs, 701 First Ave, Sunnyvale, CA 94089 USA.	yueshi@yahoo-inc.com; m.a.larson@tudelft.nl; a.hanjalic@tudelft.nl			European Union [610594]	The work leading to these results has received funding from the European Union's Seventh Framework Programme (FP7/2007-2013) under grant agreement no. 610594.	Aciar S, 2007, IEEE INTELL SYST, V22, P39, DOI 10.1109/MIS.2007.55; Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Adomavicius G, 2011, AI MAG, V32, P67; Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714; Agarwal D, 2010, P 3 ACM INT C WEB SE, P91, DOI DOI 10.1145/1718487.1718499; Agarwal D, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P19; Agarwal Deepak, 2011, P 17 ACM SIGKDD INT, P609; Amer-Yahia S., 2009, P VLDB ENDOW, V2, P754; Anderson C., 2006, LONG TAIL WHY FUTURE; Arase Y, 2010, P INT C MULT MM 10, P133, DOI 10.1145/1873951.1873971; Arias Jos J. Pazos, 2012, GROUP RECOMMENDER SY, V32, P139; Backstrom L., 2011, P 4 ACM INT C WEB SE, P635, DOI 10.1145/1935826.1935914; Baltrunas L., 2010, P 4 ACM C REC SYST R, P119, DOI DOI 10.1145/1864708.1864733; Baltrunas Linas, 2009, P 3 ACM C REC SYST R, P245, DOI 10.1145/1639714.1639759; Bao X, 2009, P 3 ACM C REC SYST R, P109, DOI 10.1145/1639714.1639734; Basilico Justin, 2004, P 21 INT C MACH LEAR, P9; Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Berkovsky S, 2007, LECT NOTES ARTIF INT, V4511, P355; Billsus Daniel, 1998, P 15 INT C MACH LEAR, P46; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bohmer M., 2011, P 13 INT C HUM COMP, P47; Breese J. S., 1998, P 14 C UNC ART INT, P43; Bu Jiajun, 2010, P ACM INT C MULT, P391, DOI 10.1145/1873951.1874005; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Cacheda F, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921593; Cai Yuanzhe, 2011, P 4 ACM INT C WEB SE, P695, DOI 10.1145/1935826.1935920; Campos Luis M., 2009, USER MODEL USER-ADAP, V19, P207, DOI 10.1007/s11257-008-9061-1; Chen L, 2012, USER MODEL USER-ADAP, V22, P125, DOI 10.1007/s11257-011-9108-6; Chen W., 2008, P 14 ACM SIGKDD INT, P115, DOI 10.1145/1401890.1401909; Cheng Z., 2010, P 19 ACM INT C INF K, P759, DOI DOI 10.1145/1871437.1871535; Chi Yun, 2008, P 17 ACM C INF KNOWL, P941, DOI 10.1145/1458082.1458206; Clauset A, 2009, SIAM REV, V51, P661, DOI 10.1137/070710111; Clements M, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852107; Clements M, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P851; Cremonesi P., 2010, P 4 ACM C REC SYST, P39, DOI 10.1145/1864708.1864721; Davidson J., 2010, P 4 ACM C REC SYST R, P293, DOI DOI 10.1145/1864708.1864770; Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776; Ding Y., 2005, P 14 ACM INT C INF K, P485, DOI 10.1145/1099554.1099689; Ekstrand Michael D., 2011, FDN TRENDS HUMAN COM, V4, P81; Firan Claudiu S., 2007, P 2007 LAT AM WEB C, P32; Friedrich G, 2011, AI MAG, V32, P90; Gantner Z., 2010, P WORKSH CONT AW MOV, P14, DOI 10.1145/1869652.1869654; Gantner Z, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.129; Gartrell Mike, 2010, P 16 ACM INT C SUPP, P97, DOI DOI 10.1145/1880071.1880087; Gilbert E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P211; Golbeck JA, 2005, THESIS COLL PARK MD; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Cori M., 2007, P 20 INT JOINT C ART, P2766; Grossman Lev, 2006, TIME; Grossman Lev, 2010, TIME, V175, P20; Guha R, 2004, P 13 INT C WORLD WID, P403, DOI DOI 10.1145/988672.988727; Gunawardana A., 2009, P 3 ACM C REC SYST R, P117, DOI DOI 10.1145/1639714.1639735; Guy I, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P194; Guy I., 2009, P 14 INT C INT US IN, P77; Guy I., 2010, P 4 ACM C REC SYST R, P7, DOI 10.1145/1864708.1864713; Harper FM, 2005, LECT NOTES ARTIF INT, V3538, P307; He Luheng, 2011, P 25 AAAI C ART INT; Herlocker J., 1999, P 22 ANN INT ACM SIG, V54, P230, DOI DOI 10.1145/312624.312682; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Herlocker J.L., 2000, P 2000 ACM C COMP SU, P241, DOI DOI 10.1145/358916.358995; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289; Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774; Hofmann T, 1999, ADV NEUR IN, V11, P466; Hongli Luo, 2012, Proceedings of the 2012 IEEE 3rd International Conference on Software Engineering and Service Science (ICSESS), DOI 10.1109/ICSESS.2012.6269580; Horozov Tzvetan, 2006, P INT S APPL INT, P124; Hotho A, 2006, LECT NOTES COMPUT SC, V4011, P411; Hurley N, 2011, ACM T INTERNET TECHN, V10, DOI 10.1145/1944339.1944341; Jakob N., 2009, P 1 INT CIKM WORKSH, P57, DOI 10.1145/1651461.1651473; Jamali M, 2010, P 4 ACM C REC SYST R, P135, DOI 10.1145/1864708.1864736; Jamali M., 2009, P 3 ACM C REC SYST, P181, DOI 10.1145/1639714.1639745; Jamali M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P397; Jameson A, 2007, ADAPTIVE WEB LNCS, V4321, P596, DOI 10.1007/978-3-540-72079-9_20; Jameson Anthony, 2011, WORKSH DEC MAK REC A; Jaschke R, 2008, AI COMMUN, V21, P231, DOI 10.3233/AIC-2008-0438; Kairam S.R., 2012, P 5 ACM INT C WEB SE, P673, DOI DOI 10.1145/2124295.2124374; Karatzoglou A, 2010, P 4 ACM C REC SYST R, P79, DOI 10.1145/1864708.1864727; Kleinberg J, 2008, J COMPUT SYST SCI, V74, P49, DOI 10.1016/j.jcss.2007.04.013; Knijnenburg BP, 2012, USER MODEL USER-ADAP, V22, P441, DOI 10.1007/s11257-011-9118-4; Koenigstein N., 2011, P 5 ACM C REC SYST R, P165, DOI DOI 10.1145/2043932.2043964; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Konstan JA, 2012, USER MODEL USER-ADAP, V22, P101, DOI 10.1007/s11257-011-9112-x; Konstas I, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P195, DOI 10.1145/1571941.1571977; Koren Y, 2010, COMMUN ACM, V53, P89, DOI 10.1145/1721654.1721677; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; KOREN Y, 2009, P 15 ACM SIGKDD INT, P447, DOI DOI 10.1145/1557019.1557072; Kurashima T., 2010, P 19 ACM INT C INF K, P579, DOI 10.1145/1871437.1871513; Kwak H., 2010, P 19 INT C WORLD WID, P591, DOI DOI 10.1145/1772690.1772751; Lam S. K., 2004, P 13 INT C WORLD WID, P393, DOI 10.1145/988672.988726; Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742; Lee S., 2011, P 5 ACM C REC SYST R, P93, DOI DOI 10.1145/2043932.2043952; Leskovec J, 2010, J MACH LEARN RES, V11, P985; Leskovec J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1361; Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI DOI 10.1145/1081870.1081893; Leskovec Jure, 2010, P 19 INT C WORLD WID, P641, DOI 10.1145/1772690.1772756; Levi A., 2012, P 6 ACM C REC SYST R, P115, DOI DOI 10.1145/2365952.2365977; Li B, 2011, PROC INT C TOOLS ART, P1085, DOI 10.1109/ICTAI.2011.184; Li B., 2011, P 22 INT JOINT C ART, P2293; Li B., 2009, P INT JOINT C ART IN, P2052; Li Y., 2010, P 19 ACM INT C INF K, P959, DOI 10.1145/1871437.1871559; Liang H., 2010, P 21 ACM C HYP HYP, P51, DOI 10.1145/1810617.1810628; Liben-Nowell D, 2003, P 12 INT C INF KNOWL, P556; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; Liu Nathan N., 2010, P 4 ACM C REC SYST R, P95, DOI 10.1145/1864708.1864729; Lu X., 2010, P INT C MULT MM 10, P143, DOI 10.1145/1873951.1873972; Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y; Ma H, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1961209.1961212; Ma H., 2008, P 17 ACM C INF KNOWL, P931, DOI DOI 10.1145/1458082.145; Ma H., 2011, P 4 ACM INT C WEB SE, P287, DOI DOI 10.1145/1935826.1935877]; Ma H, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P203, DOI 10.1145/1571941.1571978; Ma H, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961201; Mahmood T, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P73; Massa P, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P17; Massa P, 2004, LECT NOTES COMPUT SC, V2995, P221; Masthoff J, 2011, RECOMMENDER SYSTEMS HANDBOOK, P677, DOI 10.1007/978-0-387-85820-3_21; Melville Prem, 2002, P 18 NAT C ART INT, P187; Mobasher B, 2007, ACM T INTERNET TECHN, V7, DOI 10.1145/1278366.1278372; Moghaddam S., 2012, P 5 ACM INT C WEB SE, P163; Moshfeghi Y, 2009, LECT NOTES COMPUT SC, V5478, P54, DOI 10.1007/978-3-642-00958-7_8; Moshfeghi Y., 2011, P 34 INT ACM SIGIR C, P625; Nakatsuji Makoto, 2010, P 19 ACM INT C INF K, P949, DOI 10.1145/1871437.1871558; Newman MEJ, 2005, CONTEMP PHYS, V46, P323, DOI 10.1080/00107510500052444; Oestreicher-Singer G, 2012, MIS QUART, V36, P65; Oh Jinoh, 2011, P IEEE 11 INT C DAT, P507; Ono C, 2009, LECT NOTES COMPUT SC, V5535, P102, DOI 10.1007/978-3-642-02247-0_12; Onuma K, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P657; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pan Weike, 2011, P 22 INT JOINT C ART, P6; Pan Weike, 2010, P 24 AAAI C ART INT; Panniello U., 2009, P 3 ACM C REC SYST, P265, DOI 10.1145/1639714.1639764; PARK YJ, 2008, P 2008 ACM C REC SYS, P11, DOI 10.1145/1454008.1454012; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Pennock David M., 2000, P 17 NAT C ART INT A; Popescul A., 2001, P 17 C UNC ART INT U, P437; Porteous Ian, 2010, P 24 C ART INT AAAI1; Rattenbury T, 2009, ACM T WEB, V3, DOI 10.1145/1462148.1462149; Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.127; Rendle S., 2009, P 25 C UNC ART INT U, P452; Rendle S, 2011, P 34 INT ACM SIGIR C, P635; Rendle S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P727; Rendle S., 2010, P 3 ACM INT C WEB SE, P81, DOI 10.1145/1718487.1718498; Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771; Resnick P., 1994, P ACM C COMP SUPP CO, P175, DOI DOI 10.1145/192844.192905; Robu V, 2009, ACM T WEB, V3, DOI 10.1145/1594173.1594176; Roe RM, 2001, PSYCHOL REV, V108, P370, DOI 10.1037//0033-295X.108.2.370; Said Alan, 2010, P ACM IUI10 WORKSH S; Said Alan, 2011, P 2 CHALL CONT AW MO, P2; Salakhutdinov R., 2008, P 25 INT C MACH LEAR, P880, DOI DOI 10.1145/1390156.1390267; Salakhutdinov R., 2007, P 24 INT C MACH LEAR, V227, P791, DOI DOI 10.1145/1273496.1273596; Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, V20; Sarwar B. M., 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; Seko Shunichi, 2011, P 5 ACM C REC SYST R, P101; Sen S, 2006, P 2006 20 ANN C COMP, P181, DOI 10.1145/1180875.1180904; Sen S., 2009, P 18 INT C WORLD WID, P671, DOI 10.1145/1526709.1526800; Shan H, 2010, P IEEE INT C DAT MIN, P1025, DOI DOI 10.1109/ICDM.2010.116; Shepitsen A, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P259; Shi Y., 2009, P 3 ACM C REC SYST R, P125, DOI 10.1145/1639714.1639736; Shi Y., 2010, P WORKSH CONT AW MOV, P34, DOI 10.1145/1869652.1869658; Shi Y, 2011, LECT NOTES COMPUT SC, V6787, P305; Shi Y., 2012, P 35 INT ACM SIGIR C, P155; Shi Y, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2483669.2483680; Shi Yue, 2011, P 5 INT C WEBL SOC M, P622; Shi Yue, 2012, P 35 INT ACM SIGIR C, P175; Shi Yue, 2011, P 2 CHALL CONT AW MO, P53; Shi Yue, 2010, P WORKSH REC SYST SO; Si L., 2003, P 20 INT C MACH LEAR, P704; SIERSDORFER S, 2009, P 20 ACM C HYP HYP H, P261, DOI 10.1145/1557914.1557959; Singh A P, 2008, P 14 ACM SIGKDD INT, P650, DOI 10.1145/1401890.1401969; Singhal A., 2001, IEEE DATA ENG B, V24, P35; Singla Parag, 2008, P 17 INT C WORLD WID, P655, DOI 10.1145/1367497.1367586; Smyth B, 2011, AI MAG, V32, P35; Steck H., 2011, P 5 ACM C REC SYST R, P125; Stern D H, 2009, P 18 INT C WORLD WID, P111, DOI 10.1145/1526709.1526725; Sun J.-T., 2005, P 14 INT C WORLD WID, P382, DOI 10.1145/1060745.1060803; Symeonidis P, 2008, IEEE T SYST MAN CY A, V38, P1262, DOI 10.1109/TSMCA.2008.2003969; Symeonidis P, 2010, IEEE T KNOWL DATA EN, V22, P179, DOI 10.1109/TKDE.2009.85; Symeonidis P, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P43; Takeuchi Y, 2006, LECT NOTES COMPUT SC, V4159, P625; Tang Jian, 2011, P 25 AAAI C ART INT; Tong HH, 2006, IEEE DATA MINING, P613; Tran Truyen, 2009, P 25 C UNC ART INT U, P548; Tso-Sutter Karen H. L., 2006, P 10 PAC AS C ADV KN, P831; Tso-Sutter Karen H. L., 2008, P 2008 ACM S APPL CO, P1995; Tunkelang Daniel, 2011, P 5 ACM C REC SYST R, P11; Vasuki Vishvas, 2011, ACM T INTEL SYST TEC, V3; Victor P, 2011, IEEE INTELL SYST, V26, P48, DOI 10.1109/MIS.2011.22; Wang J, 2011, P 34 INT ACM SIGIR C, P1003, DOI DOI 10.1145/2009916.2010050]; Wang J, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1361684.1361689; Wang X., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148214; Watts DJ, 2007, NATURE, V445, P489, DOI 10.1038/445489a; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Wei YZ, 2005, ACM T INFORM SYST, V23, P227, DOI 10.1145/1080343.1080344; Wetzker R., 2009, P WSDM 09 WORKSH EXP, P25, DOI 10.1145/1506250.1506255; Xiang L., 2010, P 16 ACM SIGKDD INT, P723, DOI 10.1145/1835804.1835896; Xiaohui Yan, 2011, P 20 ACM INT C INF K, P2073; Xiong L., 2010, P SIAM INT C DAT MIN, P211; Xu YF, 2006, LECT NOTES COMPUT SC, V3841, P733; Yang S.H., 2011, P 20 INT C WORLD WID, P537, DOI DOI 10.1145/1963405.1963481; Yang Syu, 2011, Proceedings of the 2011 IEEE World Congress on Services (SERVICES 2011), DOI 10.1109/SERVICES.2011.68; YE LR, 1995, MIS QUART, V19, P157, DOI 10.2307/249686; Yildirim H, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P131; Yin Zhijun, 2011, P 20 INT C WORLD WID, P247, DOI [DOI 10.1145/1963405.1963443, 10.1145/1963405.1963443]; Yoo KH, 2011, RECOMMENDER SYSTEMS HANDBOOK, P455, DOI 10.1007/978-0-387-85820-3_14; Zhang JY, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P57; Zhang Y., 2010, P 26 C UNC ART INT U; Zhen Y., 2009, P 3 ACM C REC SYST, P69, DOI 10.1145/1639714.1639727; Zheng V. W., 2010, P 19 INT C WORLD WID, P1029, DOI DOI 10.1145/1772690.1772795; Zhou Tom, 2010, P 24 AAAI C ART INT; Zhu S., 2007, P 30 ANN INT ACM SIG, P487, DOI 10.1145/1277741.1277825	210	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0360-0300	1557-7341		ACM COMPUT SURV	ACM Comput. Surv.	JUL	2014	47	1							3	10.1145/2556270		45	Computer Science, Theory & Methods	Computer Science	AN7ZV	WOS:000340820600003		
J	Wang, JD; Zhou, JZ; Xu, H; Mei, T; Hua, XS; Li, SP				Wang, Jingdong; Zhou, Jiazhen; Xu, Hao; Mei, Tao; Hua, Xian-Sheng; Li, Shipeng			Image tag refinement by regularized latent Dirichlet allocation	COMPUTER VISION AND IMAGE UNDERSTANDING			English	Article						Image tag refinement; Visual affinity; Regularized latent Dirichlet allocation	ANNOTATION; PICTURES	Tagging is nowadays the most prevalent and practical way to make images searchable. However, in reality many manually-assigned tags are irrelevant to image content and hence are not reliable for applications. A lot of recent efforts have been conducted to refine image tags. In this paper, we propose to do tag refinement from the angle of topic modeling and present a novel graphical model, regularized latent Dirichlet allocation (rLDA). In the proposed approach, tag similarity and tag relevance are jointly estimated in an iterative manner, so that they can benefit from each other, and the multi-wise relationships among tags are explored. Moreover, both the statistics of tags and visual affinities of images in the corpus are explored to help topic modeling. We also analyze the superiority of our approach from the deep structure perspective. The experiments on tag ranking and image retrieval demonstrate the advantages of the proposed method. (C) 2014 Elsevier Inc. All rights reserved.	[Wang, Jingdong; Mei, Tao; Li, Shipeng] Microsoft Res, Beijing, Peoples R China; [Zhou, Jiazhen] Columbia Univ, New York, NY USA; [Xu, Hao] Univ Sci & Technol China, Hefei 230026, Peoples R China; [Hua, Xian-Sheng] Microsoft Res, Redmond, WA USA	Wang, JD (reprint author), Microsoft Res, Beijing, Peoples R China.	jingdw@microsoft.com; jiazhenzhou@yahoo.com; xuhao657@gmail.com; tmei@microsoft.com; xshua@microsoft.com; spli@microsoft.com					Ames M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P971; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Blei D., 2003, SIGIR 03, P127; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bundschus M., 2009, ICDM; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chang J., 2009, J MACH LEARN RES P T, V5, P81; Chen H.-M., 2008, ACM MULTIMEDIA, P737; Chua T.-S., 2009, CIVR; Datta R., 2008, ACM COMPUT SURV, V40; Feng Y., 2008, ACL, P272; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jeon J, 2004, LECT NOTES COMPUT SC, V3115, P24; Jiang W, 2006, IEEE IMAGE PROC, P2917, DOI 10.1109/ICIP.2006.313129; Jin R., 2004, ACM MULT C, P892; Kennedy LS, 2006, MULTIMEDIA INFORM RE, P249; Krestel R., 2009, ECML PKDD DISC CHALL; Krestel R., 2009, RECSYS 09, P61; Li J, 2003, IEEE T PATTERN ANAL, V25, P1075; Li Xirong, 2008, MULTIMEDIA INFORM RE, P180; Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598; Liu D, 2011, IEEE T MULTIMEDIA, V13, P702, DOI 10.1109/TMM.2011.2134078; Liu D., 2009, WWW, P351; Liu D., 2010, ACM INT C MULT, P491; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Minka T., 2009, TECHNICAL REPORT; Nguyen C.-T., 2010, CIKM, P1481; Putthividhya D, 2010, INT CONF ACOUST SPEE, P1894, DOI 10.1109/ICASSP.2010.5495341; Qi Guo J., 2007, ACM MULTIMEDIA, P17, DOI DOI 10.1145/1291233.1291245; Sigurbornsson B., 2008, WWW 08, P327; Song Jingkuan, 2013, SIGMOD C, P785; Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647; Wang JD, 2012, INFORM RETRIEVAL, V15, P278, DOI 10.1007/s10791-012-9193-0; Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120; Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041; Weinberger K. Q., 2008, ACM MULTIMEDIA, P111; Wu L., 2009, WWW, P361; Xu H., 2009, ACM INT C MULT, P573; Yang Y., 2009, ACM MULTIMEDIA, P175; Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204; Zhu G, 2010, ACM MULTIMEDIA, P461	42	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1077-3142	1090-235X		COMPUT VIS IMAGE UND	Comput. Vis. Image Underst.	JUL	2014	124				SI		61	70		10.1016/j.cviu.2014.02.011		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	AJ4RN	WOS:000337663600007		
J	Hu, XL; Zhang, JW; Qi, P; Zhang, B				Hu, Xiaolin; Zhang, Jianwei; Qi, Peng; Zhang, Bo			Modeling response properties of V2 neurons using a hierarchical K-means model	NEUROCOMPUTING			English	Article						Neural network; Deep learning; K-means; V1; V2	QUADRATIC-PROGRAMMING PROBLEMS; NATURAL SCENES; NEURAL-NETWORK; AREA V2; EMERGENCE	Many computational models have been proposed for interpreting the properties of neurons in the primary visual cortex (V1). But relatively fewer models have been proposed for interpreting the properties of neurons beyond VI. Recently, it was found that the sparse deep belief network (DBN) could reproduce some properties of the secondary visual cortex (V2) neurons when trained on natural images. In this paper, by investigating the key factors that contribute to the success of the sparse DBN, we propose a hierarchical model based on a simple algorithm, K-means, which can be realized by competitive Hebbian learning. The resulting model exhibits some response properties of V2 neurons, and it is more biologically feasible and computationally efficient than the sparse DBN. (C) 2014 Elsevier B.V. All rights reserved.	[Hu, Xiaolin; Qi, Peng; Zhang, Bo] Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China; [Hu, Xiaolin; Qi, Peng; Zhang, Bo] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; [Zhang, Jianwei] Univ Hamburg, Dept Informat, D-22527 Hamburg, Germany	Hu, XL (reprint author), Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.	xlhu@tsinghua.edu.cn	Hu, Xiaolin/K-2443-2013		National Basic Research Program (973 Program) of China [2013CB329403, 2012CB316301]; National Natural Science Foundation of China [61273023, 91120011]; Tsinghua University Initiative Scientific Research Program [20121088071]; Tsinghua National Laboratory for Information Science and Technology (TNList) Cross-discipline Foundation; DFG-MOE International Research Training Group IGK 1247 CINACS	This work was supported by the National Basic Research Program (973 Program) of China (Grant Nos. 2013CB329403 and 2012CB316301), National Natural Science Foundation of China (Grant Nos. 61273023 and 91120011), Tsinghua University Initiative Scientific Research Program No. 20121088071, Tsinghua National Laboratory for Information Science and Technology (TNList) Cross-discipline Foundation and the DFG-MOE International Research Training Group IGK 1247 CINACS.	Anzai A, 2007, NAT NEUROSCI, V10, P1313, DOI 10.1038/nn1975; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bishop CM, 2006, PATTERN RECOGNITION; Cadieu C, 2007, J NEUROPHYSIOL, V98, P1733, DOI 10.1152/jn.01265.2006; Coates A., 2011, P 14 INT C ART INT S; COULTRIP R, 1992, NEURAL NETWORKS, V5, P47, DOI 10.1016/S0893-6080(05)80006-1; Dayan P., 2001, THEORETICAL NEUROSCI; Ekanadham C, 2007, THESIS STANFORD U; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu XL, 2008, IEEE T NEURAL NETWOR, V19, P2022, DOI 10.1109/TNN.2008.2003287; Hu XL, 2009, IEEE T NEURAL NETWOR, V20, P654, DOI 10.1109/TNN.2008.2011266; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Karklin Y, 2009, NATURE, V457, P83, DOI 10.1038/nature07481; Karklin Yan, 2005, Neural Comput, V17, P397, DOI 10.1162/0899766053011474; Le Q., 2012, P 29 INT C MACH LEAR, P81; Lee H., 2007, ADV NEURAL INFORM PR; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; P Qi, NEURAL COMP IN PRESS; Ranzato M., 2007, ADV NEURAL INFORM PR, V20; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Saxe A., 2011, ADV NEURAL INFORM PR, V24, P1971; Sohn K., 2011, P INT C COMP VIS	27	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	JUN 25	2014	134				SI		198	205		10.1016/j.neucom.2013.07.052		8	Computer Science, Artificial Intelligence	Computer Science	AG5VE	WOS:000335486000026		
J	Ji, NN; Zhang, JS; Zhang, CX; Yin, QY				Ji, Nannan; Zhang, Jiangshe; Zhang, Chunxia; Yin, Qingyan			Enhancing performance of restricted Boltzmann machines via log-sum regularization	KNOWLEDGE-BASED SYSTEMS			English	Article						Restricted Boltzmann machine; Sparsity; Log-sum regularization; Deep belief network; Feature learning	PYRAMIDAL NEURONS; NEURAL-NETWORKS; VISUAL-CORTEX; SPARSE; REPRESENTATION; MINIMIZATION; RECOGNITION; ALGORITHM; GRADIENT; STIMULI	Restricted Boltzmann machines (RBMs) are often used as building blocks to construct a deep belief network. By optimizing several RBMs, the deep networks can be trained quickly to achieve good performance on the tasks of interest. To further improve the performance of data representation, many researches focus on incorporating sparsity into RBMs. In this paper, we propose a novel sparse RBM model, referred to as LogSumRBM. Instead of constraining the expected activation of every hidden unit to the same low level of sparsity as done in [27], we explicitly encourage the hidden units to be sparse through adding a log-sum norm constraint on the totality of the hidden units' activation probabilities. In this approach, we do not need to keep the "firing rate" of each hidden unit at a certain level that is set beforehand, and therefore the level of sparsity corresponding to each hidden unit can be automatically learnt based on the task at hand. Some experiments conducted on several image data sets of different scales show that LogSumRBM learns sparser and more discriminative representations compared with the related state-of-the-art models, and stacking two LogSumRBMs learns more significant features which mimic computations in the cortical hierarchy. Meanwhile, LogSumRBM can also be used to pre-train deep networks, and achieve better classification performance. (C) 2014 Elsevier B.V. All rights reserved.	[Ji, Nannan; Zhang, Jiangshe; Zhang, Chunxia; Yin, Qingyan] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China	Zhang, JS (reprint author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.	jszhang@mail.xjtu.edu.cn			National Basic Research Program of China (973 Program) [2013CB329404]; National Natural Science Foundation of China [91230101, 11131006, 11201367]	The authors would like to express their gratitude to the editor and two anonymous referees for their valuable comments and suggestions which lead to a substantial improvement of this paper. This work was supported by the National Basic Research Program of China (973 Program) under Grant No. 2013CB329404, the National Natural Science Foundation of China under Grant Nos. 91230101, 11131006, 11201367.	Barlow H B, 1972, Perception, V1, P371, DOI 10.1068/p010371; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1; Bengio Y., 2009, TRENDS MACH LEARN, V2, P1; Bengio Y., 2007, P ADV NEUR INF PROC, P153; Brugge K, 2013, MACH LEARN, V93, P53, DOI 10.1007/s10994-013-5390-3; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Chen EK, 2008, INT CONF ACOUST SPEE, P829, DOI 10.1109/ICASSP.2008.4517738; Cho K, 2013, NEURAL COMPUT, V25, P805, DOI 10.1162/NECO_a_00397; Cho K. H., 2010, P 2010 INT JOINT C N, P1; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Deselaers T., 2009, P EACL 2009 WORKSH S, P233, DOI 10.3115/1626431.1626476; Desjardins G., 2010, P 13 INT C ART INT S, V9, P145; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025; Fischer A., 2012, PROGR PATTERN RECOGN, V7441, P14; Fradkin D., 2003, P 9 ACM SIGKDD INT C, P517; Freund Y., 1992, P ADV NEUR INF PROC, P912; Friedman J., 2010, ARXIV10010736; Halkias X., 2013, ARXIV13013533V2; Hinton G., 2010, 2010003 U TOR MACH L; Hinton GE, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1765; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Horster E., 2008, P 16 ACM INT C MULT, P643, DOI 10.1145/1459359.1459449; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Hyder M, 2009, INT CONF ACOUST SPEE, P3365, DOI 10.1109/ICASSP.2009.4960346; Hyvarinen A, 2005, BMC NEUROSCI, V6, DOI 10.1186/1471-2202-6-12; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Kegl B., 2009, P 26 ANN INT C MACH, V26, P497, DOI DOI 10.1145/1553374.1553439; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 2004, PROC CVPR IEEE, P97; Lee H., 2007, P ADV NEUR INF PROC, P1416; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Luo H., 2011, P 25 AAAI C ART INT, P429; MANCERA L, 2006, P IEEE INT C IM PROC, P2089; Markram H, 1997, J PHYSIOL-LONDON, V500, P409; Marlin B.M., 2010, P 13 INT C ART INT S, P509; MASON A, 1991, J NEUROSCI, V11, P72; Mohimani GH, 2007, LECT NOTES COMPUT SC, V4666, P389; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; Osindero S., 2006, NEURAL COMPUT, V18, P344; Ranzato M. A., 2006, NIPS, P1137; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Salakhutdinov R., 2009, P ADV NEUR INF PROC, P1598; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Swersky K., 2010, P INF THEOR APPL WOR, P1; Taylor G., 2007, P ADV NEUR INF PROC, V19, P1345; Taylor G., 2009, P 26 ANN INT C MACH, P1025; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Wang N., 2012, EUR S ART NEUR NETW, P287; Welling M., 2005, P ADV NEUR INF PROC, V17, P1481; Wipf D., 1993, IEEE J-STSP, V4, P1487	62	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051	1872-7409		KNOWL-BASED SYST	Knowledge-Based Syst.	JUN	2014	63						82	96		10.1016/j.knosys.2014.03.016		15	Computer Science, Artificial Intelligence	Computer Science	AI2OC	WOS:000336696800008		
J	Nakashika, T; Takiguchi, T; Ariki, Y				Nakashika, Toru; Takiguchi, Tetsuya; Ariki, Yasuo			Voice Conversion Based on Speaker-Dependent Restricted Boltzmann Machines	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						voice conversion; restricted Boltzmann machine; deep learning; speaker individuality	SPEECH RECOGNITION	This paper presents a voice conversion technique using speaker-dependent Restricted Boltzmann Machines (RBM) to build high-order eigen spaces of source/target speakers, where it is easier to convert the source speech to the target speech than in the traditional cepstrum space. We build a deep conversion architecture that concatenates the two speaker-dependent RBMs with neural networks, expecting that they automatically discover abstractions to express the original input features. Under this concept, if we train the RBMs using only the speech of an individual speaker that includes various phonemes while keeping the speaker individuality unchanged, it can be considered that there are fewer phonemes and relatively more speaker individuality in the output features of the hidden layer than original acoustic features. Training the RBMs for a source speaker and a target speaker, we can then connect and convert the speaker individuality abstractions using Neural Networks (NN). The converted abstraction of the source speaker is then back-propagated into the acoustic space (e.g., MFCC) using the RBM of the target speaker. We conducted speaker-voice conversion experiments and confirmed the efficacy of our method with respect to subjective and objective criteria, comparing it with the conventional Gaussian Mixture Model-based method and an ordinary NN.	[Nakashika, Toru; Takiguchi, Tetsuya; Ariki, Yasuo] Kobe Univ, Fac Syst Informat, Kobe, Hyogo 6578501, Japan	Nakashika, T (reprint author), Kobe Univ, Fac Syst Informat, Kobe, Hyogo 6578501, Japan.	nakashika@me.cs.scitec.kobe-u.ac.jp; takigu@kobe-u.ac.jp; ariki@kobe-u.ac.jp					DENG L, 2001, ACOUST SPEECH SIG PR, P301; Desai S, 2009, INT CONF ACOUST SPEE, P3893, DOI 10.1109/ICASSP.2009.4960478; Deselaers T., 2009, P EACL 2009 WORKSH S, P233, DOI 10.3115/1626431.1626476; Gray R. M., 1984, IEEE ASSP Magazine, V1, DOI 10.1109/MASSP.1984.1162229; Helander E, 2010, IEEE T AUDIO SPEECH, V18, P912, DOI 10.1109/TASL.2010.2041699; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jian ZH, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 1, PROCEEDINGS, P210; KAIN A, 1998, ACOUST SPEECH SIG PR, P285; Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514; Kunikoshi A., 2009, P INTERSPEECH, P308; KUREMATSU A, 1990, SPEECH COMMUN, V9, P357, DOI 10.1016/0167-6393(90)90011-W; LEE CH, 2006, P INT 2006 ICSLP SEP, P2254; Ling ZH, 2012, IEEE T AUDIO SPEECH, V20, P1492, DOI 10.1109/TASL.2011.2182511; Ling Z.-H, 2006, BLIZZ CHALL WORKSH; Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291; Ling-Hui C, 2013, P INTERSPEECH, P3052; McDermott E, 2007, IEEE T AUDIO SPEECH, V15, P203, DOI 10.1109/TASL.2006.876778; Milner B., 2002, P INTERSPEECH; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed A.R., P IEEE INT C AC SPEE, P4354; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007; Nakashika T., 2013, P INTERSPEECH, P369; Saito D., 2011, P INTERSPEECH, P653; Saito D, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1728; Salakhutdinov R., 2009, THESIS U TORONTO; Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472; TAKASHIMA R, 2012, IEEE SPOK LANG TECHN, P313; Toda T, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2446; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; Tomoki T., 2007, IEICE T INF SYST, V90, P816; VALBRET H, 1992, SPEECH COMMUN, V11, P175, DOI 10.1016/0167-6393(92)90012-V; Veaux C., 2011, P INTERSPEECH, P2765; Wang N., 2012, P EUR S ART NEUR NET, P287; Wu Y.-J., 2004, P IEEE INT C AC SPEE, P629; Wu Z., 2013, P 8 ISCA SPEECH SYNT; Wu Z, 2013, P IEEE CHIN SUMM INT	38	0	0	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011, JAPAN	1745-1361			IEICE T INF SYST	IEICE Trans. Inf. Syst.	JUN	2014	E97D	6					1403	1410		10.1587/transinf.E97.D.1403		8	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	AQ4QX	WOS:000342784300002		
J	Wang, PF; Tamilselvan, P; Hu, C				Wang, Pingfeng; Tamilselvan, Prasanna; Hu, Chao			Health diagnostics using multi-attribute classification fusion	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						Fault diagnosis; Machine learning; Classification fusion	ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; SELF-ORGANIZING MAP; FAULT-DIAGNOSIS; ENSEMBLE; PROPAGATION; ALGORITHMS; SURROGATES; PREDICTION; WEAR	This paper presents a classification fusion approach for health diagnostics that can leverage the strengths of multiple member classifiers to form a robust classification model. The developed approach consists of three primary steps: (i) fusion formulation using a k-fold cross validation model; (ii) diagnostics with multiple multi-attribute classifiers as member algorithms; and (iii) classification fusion through a weighted majority voting with dominance approach. State-of-the-art classification techniques from three broad categories (i.e., supervised learning, unsupervised learning, and statistical inference) were employed as member algorithms. The diagnostics results from the fusion approach will be better than, or at least as good as, the best result provided by all individual member algorithms. The developed classification fusion approach is demonstrated with the 2008 PHM challenge problem and rolling bearing health diagnostics problem. Case study results indicated that, in both problems, the developed fusion diagnostics approach outperforms any stand-alone member algorithrn with better diagnostic accuracy and robustness. (C) 2014 Elsevier Ltd. All rights reserved.	[Wang, Pingfeng; Tamilselvan, Prasanna] Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67208 USA; [Hu, Chao] Univ Maryland, Medtron Inc, Dept Mech Engn, College Pk, MD 20742 USA	Wang, PF (reprint author), Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67208 USA.	pingfeng.wang@wichita.edu	Wang, Pingfeng/D-3764-2011	Wang, Pingfeng/0000-0002-2160-4917	National Science Foundation [CMMI-1200597]; Spirit AeroSystems Inc [PO-4400221590]	This research is partially supported by National Science Foundation (CMMI-1200597), and Spirit AeroSystems Inc (PO-4400221590).	Abbasion S, 2007, MECH SYST SIGNAL PR, V21, P2933, DOI 10.1016/j.ymssp.2007.02.003; Acar E, 2009, STRUCT MULTIDISCIP O, V37, P279, DOI 10.1007/s00158-008-0230-y; ALGUINDIGUE IE, 1993, IEEE T IND ELECTRON, V40, P209, DOI 10.1109/41.222642; Alsabti K., 1997, ELECT ENG COMPUT SCI; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Baraldi P, 2011, RELIAB ENG SYST SAFE, V96, P480, DOI 10.1016/j.ress.2010.11.005; Bishop CM, 2005, NEURAL NETWORKS PATT; Booth C, 1998, NEUROCOMPUTING, V23, P97, DOI 10.1016/S0925-2312(98)00064-2; Breikin T, 2005, 16 IFAC WORLD C; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen SY, 2009, EXPERT SYST APPL, V36, P10976, DOI 10.1016/j.eswa.2009.02.039; Coit DW, 2000, IIE TRANS, V32, P1161, DOI 10.1080/07408170008967470; Dekker R, 1996, RELIAB ENG SYST SAFE, V51, P229, DOI 10.1016/0951-8320(95)00076-3; Ebeling C. E., 1997, INTRO RELIABILITY MA; Elsayed EA, 2000, INT J PROD RES, V38, P1953, DOI 10.1080/002075400188438; Evensen G., 2003, OCEAN DYNAM, V53, P343, DOI DOI 10.1007/S10236-003-0036-9; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148; Gao J., 2010, TUT SIAM DAT MIN C S; Ge M, 2004, MECH SYST SIGNAL PR, V18, P143, DOI 10.1016/S0888-3270(03)00071-2; Geramifard O, 2010, 8 IEEE INT C CONTR A, P1618; Goel T, 2007, STRUCT MULTIDISCIP O, V33, P199, DOI 10.1007/s00158-006-0051-9; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu C, 2012, RELIAB ENG SYST SAFE, V103, P120, DOI 10.1016/j.ress.2012.03.008; Hu JJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-342; Huang RQ, 2007, MECH SYST SIGNAL PR, V21, P193, DOI 10.1016/j.ymssp.2005.11.008; Li Y, 1999, TRIBOL T, V42, P385, DOI 10.1080/10402009908982232; Licht T., 2003, AM SOC MECH ENG DYN, V71, P1059; Macian V, 2003, TRIBOL INT, V36, P771, DOI 10.1016/S0301-679X(03)00060-4; MARTIN KF, 1994, INT J MACH TOOL MANU, V34, P527, DOI 10.1016/0890-6955(94)90083-3; Perrone M.P., 1993, NEURAL NETW SPEECH I; Polikar R., 2006, CIRCUITS SYSTEMS MAG, V6, P21, DOI DOI 10.1109/MCAS.2006.1688199; Qiu H, 2003, ADV ENG INFORM, V17, P127, DOI 10.1016/j.aei.2004.08.001; Saimurugan M, 2010, EXPERT SYST APPL; Samanta B, 2004, MECH SYST SIGNAL PR, V18, P625, DOI 10.1016/S0888-3270(03)00020-7; Saxena A, 2007, APPL SOFT COMPUT, V7, P441, DOI 10.1016/j.asoc.2005.10.001; Saxena A., 2008, INT C PROGN HLTH MAN; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Srinivasan S, 2007, IRAN J ELECT COMPUTE, V6, P62; Sun J, 2004, INT J MACH TOOL MANU, V44, P1179, DOI 10.1016/j.ijmachtools.2004.04.003; Tamilselvan P, 2011, ASME 2011 INT DES EN; Tamilselvan P., 2013, 54 AIAA ASME ASCE AH; Tamilselvan P, 2013, MICROELECTRON RELIAB, V53, P1117, DOI 10.1016/j.microrel.2013.04.011; Wang P., 2010, ANN C PROGN HLTH MAN; Wong MLD, 2006, MECH SYST SIGNAL PR, V20, P593, DOI 10.1016/j.ymssp.2005.01.008; Yang BS, 2005, MECH SYST SIGNAL PR, V19, P371, DOI 10.1016/j.myssp.2004.06.002; Zerpa LE, 2005, J PETROL SCI ENG, V47, P197, DOI 10.1016/j.petrol.2005.03.002; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; Zhang L, 2010, EXPERT SYST APPL, V37, P6077, DOI 10.1016/j.eswa.2010.02.118; Zhao XL, 2007, SMART MATER STRUCT, V16, P1208, DOI 10.1088/0964-1726/16/4/032	52	0	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976	1873-6769		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	JUN	2014	32						192	202		10.1016/j.engappai.2014.03.006		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	AI6BD	WOS:000336953900016		
J	Gebicke-Haerter, PJ				Gebicke-Haerter, Peter J.			Engrann formation in psychiatric disorders	FRONTIERS IN NEUROSCIENCE			English	Review						neuronal networks; computational simulation; synaptic engram; cross-frequency coupling; gap junctions; post-translational modifications; epigenetics; schizophrenia	LONG-TERM POTENTIATION; CENTRAL-NERVOUS-SYSTEM; GAP-JUNCTIONAL COMMUNICATION; CA1 PYRAMIDAL NEURONS; REGULATES MEMORY FORMATION; ASTROCYTES IN-SITU; KINASE M-ZETA; SYNAPTIC PLASTICITY; DENDRITIC SPINES; PROTEIN-SYNTHESIS	Environmental factors substantially influence beginning and progression of mental illness, reinforcing or reducing the consequences of genetic vulnerability. Often initiated by early traumatic events, "engrams" or memories are formed that may give rise to a slow and subtle progression of psychiatric disorders. The large delay between beginning and time of onset (diagnosis) may be explained by efficient compensatory mechanisms observed in brain metabolism that use optional pathways in highly redundant molecular interactions. To this end, research has to deal with mechanisms of learning and long-term memory formation, which involves (a) epigenetic changes, (b) altered neuronal activities, and (c) changes in neuron-glia communication. On the epigenetic level, apparently DNA-methylations are more stable than histone modifications, although both closely interact. Neuronal activities basically deliver digital information, which clearly can serve as basis for memory formation (LTP). However, research in this respect has long time neglected the importance of glia. They are more actively involved in the control of neuronal activities than thought before. They can both reinforce and inhibit neuronal activities by transducing neuronal information from frequency-encoded to amplitude and frequency-modulated calcium wave patterns spreading in the glial syncytium by use of gap junctions. In this way, they serve integrative functions. In conclusion, we are dealing with two concepts of encoding information that mutually control each other and synergize: a digital (neuronal) and a wave-like (glial) computing, forming neuron-glia functional units with inbuilt feedback loops to maintain balance of excitation and inhibition. To better understand mental illness, we have to gain more insight into the dynamics of adverse environmental impact on those cellular and molecular systems. This report summarizes existing knowledge and draws some outline about further research in molecular psychiatry.	[Gebicke-Haerter, Peter J.] Heidelberg Univ, Inst Psychopharmacol, Cent Inst Mental Hlth, Med Fac Mannheim, D-68159 Mannheim, Germany; [Gebicke-Haerter, Peter J.] Univ Chile, Fac Med, Program Farmacol, Santiago, Chile; [Gebicke-Haerter, Peter J.] Univ Chile, Fac Med, Program Inmunol, Santiago, Chile	Gebicke-Haerter, PJ (reprint author), Heidelberg Univ, Inst Psychopharmacol, Cent Inst Mental Hlth, Med Fac Mannheim, J5, D-68159 Mannheim, Germany.	peter.gebicke@zi-mannheim.de					Aguado F, 2002, J NEUROSCI, V22, P9430; Ahmed R, 2006, MOL CELL NEUROSCI, V31, P37, DOI 10.1016/j.mcn.2005.08.020; Alberini CM, 2011, FRONT BEHAV NEUROSCI, V5, DOI 10.3389/fnbeh.2011.00012; Alberini CM, 2009, PHYSIOL REV, V89, P121, DOI 10.1152/physrev.00017.2008; Alvarez-Maubecin V, 2000, J NEUROSCI, V20, P4091; Angulo MC, 2004, J NEUROSCI, V24, P6920, DOI 10.1523/JNEUROSCI.0473-04.2004; Araque A, 2001, ANNU REV PHYSIOL, V63, P795, DOI 10.1146/annurev.physiol.63.1.795; Armano S, 2000, J NEUROSCI, V20, P5208; Axelsen LN, 2013, FRONT PHARMACOL, V4, DOI 10.3389/fphar.2013.00130; Bailey CH, 1996, P NATL ACAD SCI USA, V93, P13445, DOI 10.1073/pnas.93.24.13445; Bailey CH, 2004, NEURON, V44, P49, DOI 10.1016/j.neuron.2004.09.017; BANK M, 1992, J NEUROSCI, V12, P2960; Bekar LK, 2008, CEREB CORTEX, V18, P2789, DOI 10.1093/cercor/bhn040; Bekar LK, 2002, GLIA, V39, P207, DOI 10.1002/glia.10096; Bekkers JM, 2000, J PHYSIOL-LONDON, V525, P611, DOI 10.1111/j.1469-7793.2000.t01-2-00611.x; Ben Achour S, 2010, Neurochem Int, V57, P440, DOI 10.1016/j.neuint.2010.02.013; Bennett MVL, 2004, NEURON, V41, P495, DOI 10.1016/S0896-6273(04)00043-1; Bennett MVL, 2012, BRAIN RES, V1487, P3, DOI 10.1016/j.brainres.2012.08.042; Benuskova L, 2007, NEUROCOMPUTING, V70, P2035, DOI 10.1016/j.neucom.2006.10.133; Bhaumik SR, 2007, NAT STRUCT MOL BIOL, V14, P1008, DOI 10.1038/nsmb1337; BIENENSTOCK EL, 1982, J NEUROSCI, V2, P32; Bloodgood BL, 2007, CURR OPIN NEUROBIOL, V17, P345, DOI 10.1016/j.conb.2007.04.003; Bushong EA, 2002, J NEUROSCI, V22, P183; BUZSAKI G, 1995, CURR OPIN NEUROBIOL, V5, P504, DOI 10.1016/0959-4388(95)80012-3; CAMPBELL G, 1992, J NEUROSCI, V12, P1847; Canolty RT, 2006, SCIENCE, V313, P1626, DOI 10.1126/science.1128115; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Carracedo LM, 2013, J NEUROSCI, V33, P10750, DOI 10.1523/JNEUROSCI.0735-13.2013; CHAPMAN LJ, 1994, J ABNORM PSYCHOL, V103, P171, DOI 10.1037/0021-843X.103.2.171; Chen JD, 2013, GLIA, V61, P178, DOI 10.1002/glia.22425; Clarke LE, 2013, NAT REV NEUROSCI, V14, P311, DOI 10.1038/nrn3484; Condorelli DF, 1998, EUR J NEUROSCI, V10, P1202, DOI 10.1046/j.1460-9568.1998.00163.x; Connors BW, 2004, ANNU REV NEUROSCI, V27, P393, DOI 10.1146/annurev.neuro.26.041002.131128; Costa-Mattioli Mauro, 2006, Critical Reviews in Neurobiology, V18, P187; Cotrina ML, 1998, J NEUROSCI, V18, P2520; Creixell P, 2012, MOL SYST BIOL, V8, DOI 10.1038/msb.2012.33; Dere E, 2012, NEUROSCI BIOBEHAV R, V36, P206, DOI 10.1016/j.neubiorev.2011.05.015; Dermietzel R, 1998, CELL BIOL INT, V22, P719, DOI 10.1006/cbir.1999.0393; Derouiche A, 2002, J PHYSIOLOGY-PARIS, V96, P177, DOI 10.1016/S0928-4257(02)00004-9; Dobrowolski R, 2009, ANTIOXID REDOX SIGN, V11, P283, DOI 10.1089/ars.2008.2128; Dombeck DA, 2007, NEURON, V56, P43, DOI 10.1016/j.neuron.2007.08.003; Dong Y, 2006, NAT NEUROSCI, V9, P475, DOI 10.1038/nn1661; Dudai Y, 2004, ANNU REV PSYCHOL, V55, P51, DOI 10.1146/annurev.psych.55.090902.142050; Eberwine J, 2002, NEUROCHEM RES, V27, P1065, DOI 10.1023/A:1020956805307; Egawa K, 2013, J PHYSIOL-LONDON, V591, P3901, DOI 10.1113/jphysiol.2013.257162; Eichenbaum H, 2004, NEURON, V44, P109, DOI 10.1016/j.neuron.2004.08.028; Escartin Carole, 2013, Front Neuroenergetics, V5, P4, DOI 10.3389/fnene.2013.00004; Eugenin EA, 2001, P NATL ACAD SCI USA, V98, P4190, DOI 10.1073/pnas.051634298; Eugenin EA, 2012, J NEUROIMMUNE PHARM, V7, P499, DOI 10.1007/s11481-012-9352-5; Feldman DE, 2002, NAT NEUROSCI, V5, P712, DOI 10.1038/nn0802-712; Fellin T, 2004, NEURON, V43, P729, DOI 10.1016/j.neuron.2004.08.011; Fiacco TA, 2004, J NEUROSCI, V24, P722, DOI 10.1523/JNEUROSCI.2859-03.2004; Fields D. R., 2002, SCIENCE, V298, P556, DOI [10.1126/science.298.5593.556, DOI 10.1126/SCIENCE.298.5593.556]; Fields RD, 2014, NEUROSCIENTIST, V20, P426, DOI 10.1177/1073858413504465; Finnie PSB, 2012, NEUROSCI BIOBEHAV R, V36, P1667, DOI 10.1016/j.neubiorev.2012.03.008; Ford JM, 2008, SCHIZOPHRENIA BULL, V34, P904, DOI 10.1093/schbul/sbn090; Foss J, 1996, PHYS REV LETT, V76, P708, DOI 10.1103/PhysRevLett.76.708; Fregnac Y, 1998, NATURE, V391, P845, DOI 10.1038/35996; Frey U, 1997, NATURE, V385, P533, DOI 10.1038/385533a0; Frisch C, 2005, BEHAV BRAIN RES, V157, P177, DOI 10.1016/j.bbr.2004.06.023; Fukuda T, 2006, J NEUROSCI, V26, P3434, DOI 10.1523/JNEURSCI.4076-05.2006; Fukuda T, 2007, NEUROSCIENTIST, V13, P199, DOI 10.1177/1073858406296760; FUSTER JM, 1971, SCIENCE, V173, P652, DOI 10.1126/science.173.3997.652; Giaume C, 1996, TRENDS NEUROSCI, V19, P319, DOI 10.1016/0166-2236(96)10046-1; Giaume C, 2010, NAT REV NEUROSCI, V11, P87, DOI 10.1038/nrn2757; Gordon GRJ, 2009, NEURON, V64, P391, DOI 10.1016/j.neuron.2009.10.021; Govindarajan A, 2006, NAT REV NEUROSCI, V7, P575, DOI 10.1038/nrn1937; Graber TE, 2013, LEARN MEMORY, V20, P518, DOI 10.1101/lm.027664.112; Graber TE, 2013, P NATL ACAD SCI USA, V110, P16205, DOI 10.1073/pnas.1307747110; Gray NW, 2006, PLOS BIOL, V4, P2065, DOI 10.1371/journal.pbio.0040370; Gupta S, 2010, J NEUROSCI, V30, P3589, DOI 10.1523/JNEUROSCI.3732-09.2010; Gupta-Agarwal S, 2012, J NEUROSCI, V32, P5440, DOI 10.1523/JNEUROSCI.0147-12.2012; Guzowski JF, 1999, NAT NEUROSCI, V2, P1120, DOI 10.1038/16046; Haber M, 2006, J NEUROSCI, V26, P8881, DOI 10.1523/JNEUROSCI.1302/06.2006; Hama H, 2004, NEURON, V41, P405, DOI 10.1016/S0896-6273(04)00007-8; Han XN, 2013, CELL STEM CELL, V12, P342, DOI 10.1016/j.stem.2012.12.015; Hart GW, 2007, NATURE, V446, P1017, DOI 10.1038/nature05815; Havik B, 2007, NEUROSCIENCE, V148, P925, DOI 10.1016/j.neuroscience.2007.07.024; Henneberger C, 2010, NATURE, V463, P232, DOI 10.1038/nature08673; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoffman DA, 1997, NATURE, V387, P869; Hoogland TM, 2009, P NATL ACAD SCI USA, V106, P3496, DOI 10.1073/pnas.0809269106; Hormuzdi SG, 2004, BBA-BIOMEMBRANES, V1662, P113, DOI 10.1016/j.bbamem.2003.10.023; Houades V, 2008, J NEUROSCI, V28, P5207, DOI 10.1523/JNEUROSCI.5100-07.2008; Hunter T, 2007, MOL CELL, V28, P730, DOI 10.1016/j.molcel.2007.11.019; Jarome TJ, 2013, REV NEUROSCIENCE, V24, P375, DOI 10.1515/revneuro-2013-0008; Jarome TJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024349; Johnston D, 2008, TRENDS NEUROSCI, V31, P309, DOI 10.1016/j.tins.2008.03.004; Jourdain P, 2007, NAT NEUROSCI, V10, P331, DOI 10.1038/nn1849; Kang J, 2008, J NEUROSCI, V28, P4702, DOI 10.1523/JNEUROSCI.5048-07.2008; Kavalali ET, 1997, NEURON, V18, P651, DOI 10.1016/S0896-6273(00)80305-0; Kelleher RJ, 2004, NEURON, V44, P59, DOI 10.1016/j.neuron.2004.09.013; Kelly MT, 2007, J NEUROSCI, V27, P3439, DOI 10.1523/JNEUROSCI.5612-06.2007; Kim SJ, 2007, NEURON, V56, P582, DOI 10.1016/j.neuron.2007.10.030; Klann E, 2008, NEUROBIOL LEARN MEM, V89, P247, DOI 10.1016/j.nlm.2007.08.009; Koch H, 2011, INTEGR COMP BIOL, V51, P856, DOI 10.1093/icb/icr099; Kole MHP, 2006, J NEUROSCI, V26, P1677, DOI 10.1523/JNEUROSCI.3664-05.2006; Koulakoff A, 2008, GLIA, V56, P1299, DOI 10.1002/glia.20698; Kreuzberg MM, 2008, MOL CELL NEUROSCI, V37, P119, DOI 10.1016/j.mcn.2007.09.003; Kronenberg F, 2010, ATHEROSCLEROSIS, V213, P30, DOI 10.1016/j.atherosclerosis.2010.07.049; Kunze A, 2009, P NATL ACAD SCI USA, V106, P11336, DOI 10.1073/pnas.0813160106; Kwapis JL, 2014, BRAIN RES BULL, V105, P36, DOI 10.1016/j.brainresbull.2013.09.005; LAMPE PD, 1994, J CELL BIOL, V127, P1895, DOI 10.1083/jcb.127.6.1895; Lang C, 2004, P NATL ACAD SCI USA, V101, P16665, DOI 10.1073/pnas.0407581101; Latham JA, 2007, NAT STRUCT MOL BIOL, V14, P1017, DOI 10.1038/nsmb1307; Law JA, 2010, NAT REV GENET, V11, P204, DOI 10.1038/nrg2719; Lee AK, 2006, NEURON, V51, P399, DOI 10.1016/j.neuron.2006.07.004; Lee JLC, 2010, FRONT BEHAV NEUROSCI, V4, DOI 10.3389/fnbeh.2010.00168; Letzkus JJ, 2006, J NEUROSCI, V26, P10420, DOI 10.1523/JNEUROSCI.2650-06.2006; Liao L, 2007, J PROTEOME RES, V6, P1059, DOI 10.1021/pr060358f; Lichtman JW, 2008, NAT REV NEUROSCI, V9, P417, DOI 10.1038/nrn2391; Lim S, 2013, NAT NEUROSCI, V16, P1306, DOI 10.1038/nn.3492; Lim WA, 2002, CURR OPIN STRUC BIOL, V12, P61, DOI 10.1016/S0959-440X(02)00290-7; Lim WA, 2010, CELL, V142, P661, DOI 10.1016/j.cell.2010.08.023; Lisman John, 2006, Sci STKE, V2006, pre11, DOI 10.1126/stke.3562006re11; Liu X, 2012, NATURE, V484, P381, DOI 10.1038/nature11028; London M, 2005, ANNU REV NEUROSCI, V28, P503, DOI 10.1146/annurev.neuro.28.061604.135703; LOO LWM, 1995, J BIOL CHEM, V270, P12751; Lopez F, 2006, MED HYPOTHESES, V66, P121, DOI 10.1016/j.mehy.2005.07.015; Lorincz A, 2002, NAT NEUROSCI, V5, P1185, DOI 10.1038/nn962; Losonczy A, 2006, NEURON, V50, P291, DOI 10.1016/j.neuron.2006.03.016; Losonczy A, 2008, NATURE, V452, P436, DOI 10.1038/nature06725; MADISON DV, 1986, NATURE, V321, P695, DOI 10.1038/321695a0; Marin I, 2013, LEARN MEMORY, V20, P601, DOI 10.1101/lm.028357.112; MARKRAM H, 1995, J PHYSIOL-LONDON, V485, P1; Martin KC, 2006, J NEUROSCI, V26, P7131, DOI 10.1523/JNEUROSCI.1801-06.2006; Matsumoto M, 2007, NEUROSCI RES, V57, P411, DOI 10.1016/j.neures.2006.11.015; Matus A, 2000, HIPPOCAMPUS, V10, P555, DOI 10.1002/1098-1063(2000)10:5<555::AID-HIPO5>3.0.CO;2-Z; McGuffin P, 2013, AM J PSYCHIAT, V170, P821, DOI 10.1176/appi.ajp.2013.13030336; MCNAUGHTON BL, 1981, J NEUROPHYSIOL, V46, P952; Meier SD, 2008, GLIA, V56, P1127, DOI 10.1002/glia.20684; Melchor JP, 2005, THROMB HAEMOSTASIS, V93, P655, DOI 10.1160/TH04-12-0838; Meme W, 2009, NEUROSCI RES, V63, P236, DOI 10.1016/j.neures.2008.12.008; Miller CA, 2007, NEURON, V53, P857, DOI 10.1016/j.neuron.2007.02.022; Minguez P, 2013, NUCLEIC ACIDS RES, V41, pD306, DOI 10.1093/nar/gks1230; Minguez P, 2012, MOL SYST BIOL, V8, DOI 10.1038/msb.2012.31; Mitterauer BJ, 2011, CNS NEUROSCI THER, V17, P333, DOI 10.1111/j.1755-5949.2009.00113.x; Mozzachiodi R, 2010, TRENDS NEUROSCI, V33, P17, DOI 10.1016/j.tins.2009.10.001; Murai KK, 2003, NAT NEUROSCI, V6, P153, DOI 10.1038/nn994; Nagy JI, 2000, BRAIN RES REV, V32, P29, DOI 10.1016/S0165-0173(99)00066-1; Nagy JI, 2011, EUR J NEUROSCI, V34, P263, DOI 10.1111/j.1460-9568.2011.07741.x; Narayanan R, 2007, NEURON, V56, P1061, DOI 10.1016/j.neuron.2007.10.033; Nedergaard M, 2003, TRENDS NEUROSCI, V26, P523, DOI 10.1016/j.tins.2003.08.008; Nett WJ, 2002, J NEUROPHYSIOL, V87, P528; Noble D., 2013, MUSIC LIFE OUP BIOL; Oberheim NA, 2006, TRENDS NEUROSCI, V29, P547, DOI 10.1016/j.tins.2006.08.004; Orellana JA, 2011, J NEUROSCI, V31, P4962, DOI 10.1523/JNEUROSCI.6417-10.2011; Orosz G, 2009, IEEE T NEURAL NETWOR, V20, P1135, DOI 10.1109/TNN.2009.2016658; Pajevic S, 2014, NEUROSCIENCE, V276, P135, DOI 10.1016/j.neuroscience.2013.11.007; Panatier A, 2011, CELL, V146, P785, DOI 10.1016/j.cell.2011.07.022; Pannasch U, 2011, P NATL ACAD SCI USA, V108, P8467, DOI 10.1073/pnas.1016650108; Pannasch Ulrike, 2012, Commun Integr Biol, V5, P248, DOI 10.4161/cib.19410; Pape HC, 1996, ANNU REV PHYSIOL, V58, P299, DOI 10.1146/annurev.physiol.58.1.299; PARPURA V, 1994, NATURE, V369, P744, DOI 10.1038/369744a0; Pastalkova E, 2006, SCIENCE, V313, P1141, DOI 10.1126/science.1128657; Pellerin L, 2012, J CEREBR BLOOD F MET, V32, P1152, DOI 10.1038/jcbfm.2011.149; Pellerin L, 2007, GLIA, V55, P1251, DOI 10.1002/glia.20528; Perea G, 2007, SCIENCE, V317, P1083, DOI 10.1126/science.1144640; Perea G, 2006, J PHYSIOLOGY-PARIS, V99, P92, DOI 10.1016/j.physparis.2005.12.003; Perea G, 2005, J NEUROSCI, V25, P2192, DOI 10.1523/JNEUROSCI.3956-04.2005; PERKEL DH, 1988, TRENDS NEUROSCI, V11, P9, DOI 10.1016/0166-2236(88)90041-0; Petronis A, 2010, NATURE, V465, P721, DOI 10.1038/nature09230; Phelan P, 2008, CURR BIOL, V18, P1955, DOI 10.1016/j.cub.2008.10.067; Pouget A, 2013, NAT NEUROSCI, V16, P1170, DOI 10.1038/nn.3495; Purcell SM, 2009, NATURE, V460, P748; Ramirez JM, 2004, CURR OPIN NEUROBIOL, V14, P665, DOI 10.1016/j.conb.2004.10.011; Redondo RL, 2010, J NEUROSCI, V30, P4981, DOI 10.1523/JNEUROSCI.3140-09.2010; Redondo RL, 2011, NAT REV NEUROSCI, V12, P17, DOI 10.1038/nrn2963; Ren SQ, 2013, EMBO J, V32, P1365, DOI 10.1038/emboj.2013.60; Retamal MA, 2006, P NATL ACAD SCI USA, V103, P4475, DOI 10.1073/pnas.0511118103; Retamal MA, 2009, AM J PHYSIOL-CELL PH, V296, pC1356, DOI 10.1152/ajpcell.00054.2009; Rottingen JA, 2000, ACTA PHYSIOL SCAND, V169, P203; Rouach N, 2008, SCIENCE, V322, P1551, DOI 10.1126/science.1164022; Routtenberg A, 2008, NEUROBIOL LEARN MEM, V89, P225, DOI 10.1016/j.nlm.2007.10.012; Routtenberg A, 2008, EUR J PHARMACOL, V585, P60, DOI 10.1016/j.ejphar.2008.02.047; ROUTTENB.A, 1972, ANN NY ACAD SCI, V193, P159, DOI 10.1111/j.1749-6632.1972.tb27832.x; Routtenberg A, 2005, TRENDS NEUROSCI, V28, P12, DOI 10.1016/j.tins.2004.11.008; Routtenberg A, 2013, HIPPOCAMPUS, V23, P202, DOI 10.1002/hipo.22088; Ruthenburg AJ, 2007, NAT REV MOL CELL BIO, V8, P983, DOI 10.1038/nrm2298; Saar D, 2003, EUR J NEUROSCI, V17, P2727, DOI 10.1046/j.1460-9568.2003.02699.x; Saez JC, 2003, ACTA PHYSIOL SCAND, V179, P9, DOI 10.1046/j.1365-201X.2003.01196.x; Sakaguchi M, 2012, MOL BRAIN, V5, DOI 10.1186/1756-6606-5-32; Salameh A, 2005, BBA-BIOMEMBRANES, V1719, P36, DOI 10.1016/j.bbamem.2005.09.007; Sanabria H, 2009, J BIOL CHEM, V284, P9770, DOI 10.1074/jbc.M809518200; Schafer DP, 2013, GLIA, V61, P24, DOI 10.1002/glia.22389; Schmitt A, 2011, WORLD J BIOL PSYCHIA, V12, P201, DOI 10.3109/15622975.2010.530690; Seet BT, 2006, NAT REV MOL CELL BIO, V7, P473, DOI 10.1038/nrm1960; Seibt Julie, 2012, Commun Integr Biol, V5, P491, DOI 10.4161/cib.21010; Semon R., 1921, THE MNEME; Shelton MK, 2000, J NEUROCHEM, V74, P555, DOI 10.1046/j.1471-4159.2000.740555.x; Shema R, 2011, SCIENCE, V331, P1207, DOI 10.1126/science.1200215; Shi JX, 2009, NATURE, V460, P753, DOI 10.1038/nature08192; Siegel M, 2012, NAT REV NEUROSCI, V13, P121, DOI 10.1038/nrn3137; Slezak M, 2006, J PHYSIOLOGY-PARIS, V99, P84, DOI 10.1016/j.jphysparis.2005.12.082; Sonenberg N, 2003, CURR OPIN STRUC BIOL, V13, P56, DOI 10.1016/S0959-440X(03)00009-5; SPENCER WA, 1961, J NEUROPHYSIOL, V24, P272; Squire LR, 2004, ANNU REV NEUROSCI, V27, P279, DOI 10.1146/annurev.neuro.27.070203.144130; Squire LR, 2009, J NEUROSCI, V29, P12711, DOI 10.1523/JNEUROSCI.3575-09.2009; Stefansson H, 2009, NATURE, V460, P744, DOI 10.1038/nature08186; Stehberg J, 2012, FASEB J, V26, P3649, DOI 10.1096/fj.11-198416; STEWARD O, 1982, J NEUROSCI, V2, P284; STUART GJ, 1994, NATURE, V367, P69, DOI 10.1038/367069a0; Sui L, 2012, NEUROBIOL LEARN MEM, V97, P425, DOI 10.1016/j.nlm.2012.03.007; Sutherland RJ, 2011, CURR OPIN NEUROBIOL, V21, P446, DOI 10.1016/j.conb.2011.04.007; Suzuki A, 2011, CELL, V144, P810, DOI 10.1016/j.cell.2011.02.018; Tanaka M, 2013, MOL BRAIN, V6, DOI 10.1186/1756-6606-6-6; Taverna SD, 2007, P NATL ACAD SCI USA, V104, P2086, DOI 10.1073/pnas.0610993104; Theiss C, 2002, EXP CELL RES, V281, P197, DOI 10.1006/excr.2002.5652; Todd KJ, 2006, J PHYSIOLOGY-PARIS, V99, P75, DOI 10.1016/j.jphysparis.2005.12.002; Tress O, 2012, J NEUROSCI, V32, P7499, DOI 10.1523/JNEUROSCI.0392-12.2012; Tretter F., 2010, SYSTEMS BIOL PSYCHIA, DOI [10.1002/9783527630271, DOI 10.1002/9783527630271]; Tretter F, 2012, METHODS MOL BIOL, V829, P567, DOI 10.1007/978-1-61779-458-2_36; Triesch J, 2007, NEURAL COMPUT, V19, P885, DOI 10.1162/neco.2007.19.4.885; Tsuriel S, 2006, PLOS BIOL, V4, P1572, DOI 10.1371/journal.pbio.0040271; Uhlhaas Peter J, 2013, Dialogues Clin Neurosci, V15, P301; Ullian EM, 2001, SCIENCE, V291, P657, DOI 10.1126/science.291.5504.657; Vandecasteele M, 2006, NEUROSCI RES, V56, P419, DOI 10.1016/j.neures.2006.08.013; Vazdarjanova A, 2004, J NEUROSCI, V24, P6489, DOI 10.1523/JNEUROSCI.0350-04.2004; Venance L, 2004, J PHYSIOL-LONDON, V559, P215, DOI 10.1113/jphysiol.2004.065672; Ventriglia F, 2008, COGN NEURODYNAMICS, V2, P335, DOI 10.1007/s11571-008-9057-x; Vinogradova OS, 2001, HIPPOCAMPUS, V11, P578, DOI 10.1002/hipo.1073; von Stein A, 2000, INT J PSYCHOPHYSIOL, V38, P301, DOI 10.1016/S0167-8760(00)00172-0; Wade JJ, 2010, IEEE T NEURAL NETWOR, V21, P1817, DOI 10.1109/TNN.2010.2074212; Wahlsten D, 2012, DEV PSYCHOBIOL, V54, P475, DOI 10.1002/dev.21043; Wallace JG, 1995, LECT NOTES COMPUT SC, V930, P53; Wang HM, 2006, PROG NEUROBIOL, V79, P123, DOI 10.1016/j.pneurobio.2006.06.004; Warn-Cramer BJ, 1998, J BIOL CHEM, V273, P9188, DOI 10.1074/jbc.273.15.9188; Wasseff SK, 2011, NEUROBIOL DIS, V42, P506, DOI 10.1016/j.nbd.2011.03.003; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Weeber EJ, 2002, J BIOL CHEM, V277, P39944, DOI 10.1074/jbc.M205147200; Willecke K, 2002, BIOL CHEM, V383, P725, DOI 10.1515/BC.2002.076; Wiltgen BJ, 2004, NEURON, V44, P101, DOI 10.1016/j.neuron.2004.09.015; Wittenberg GM, 2002, TRENDS NEUROSCI, V25, P501, DOI 10.1016/S0166-2236(02)02231-2; Xu J, 2005, J NEUROSCI, V25, P1750, DOI 10.1523/JNEUROSCI.4217-04.2005; Yamamoto T, 1992, Brain Res Dev Brain Res, V66, P165; YANG XD, 1990, NATURE, V348, P542, DOI 10.1038/348542a0; Yao YD, 2008, J NEUROSCI, V28, P7820, DOI 10.1523/JNEUROSCI.0223-08.2008; Yuste R, 2004, J PHYSIOLOGY-PARIS, V98, P479, DOI 10.1016/j.jphysparis.2005.09.014; Zou SF, 2012, NEURAL NETWORKS, V29-30, P37, DOI 10.1016/j.neunet.2012.01.007; Zovkic IB, 2013, LEARN MEMORY, V20, P61, DOI 10.1101/lm.026575.112	240	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-453X			FRONT NEUROSCI-SWITZ	Front. Neurosci.	MAY 28	2014	8								118	10.3389/fnins.2014.00118		19	Neurosciences	Neurosciences & Neurology	AW8AU	WOS:000346483900001	24904262	
J	Zhou, SS; Chen, QC; Wang, XL				Zhou, Shusen; Chen, Qingcai; Wang, Xiaolong			Fuzzy deep belief networks for semi-supervised sentiment classification	NEUROCOMPUTING			English	Article						Supervised learning; Deep learning; Fuzzy sets; Sentiment classification	NEURAL-NETWORKS	By embedding prior knowledge into the learning structure, this paper presents a two-step semi-supervised learning method called fuzzy deep belief networks (FDBN) for sentiment classification. First, we train the general deep belief networks (DBN) by the semi-supervised learning taken on training dataset. Then, we design a fuzzy membership function for each class of reviews based on the learned deep architecture. Since the training of DBN maps each review into the DBN output space, the distribution of all training samples in the space is treated as prior knowledge and is encoded by a series of fuzzy membership functions. Second, based on the fuzzy membership functions and the DBN obtained in the first step, a novel FDBN architecture is constructed and the supervised learning stage is applied to improve the classification performance of the FDBN. FDBN not only inherits the powerful abstraction ability of DBN, but also demonstrates the attractive fuzzy classification ability for handling sentiment data. To inherit the advantages of both active learning and FDBN, we also propose an active FDBN (AFD) semi-supervised learning method. The empirical validation on five sentiment classification datasets demonstrates the effectiveness of FDBN and AFD methods. Crown Copyright (C) 2013 Published by Elsevier B.V. All rights reserved.	[Zhou, Shusen] Ludong Univ, Sch Informat & Elect Engn, Yantai, Peoples R China; [Chen, Qingcai; Wang, Xiaolong] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China	Zhou, SS (reprint author), Ludong Univ, Sch Informat & Elect Engn, Yantai, Peoples R China.	zhoushusen@hotmail.com; qingcai.chen@hitsz.edu.cn; wangxl@insun.hit.edu.cn			National Natural Science Foundation of China [61300155, 61173075]; Ludong University [LY2013004]	This work is supported in part by National Natural Science Foundation of China (No. 61300155 and No. 61173075) and Scientific Research Fund of Ludong University (LY2013004).	Aue A., 2005, INT C REC ADV NAT LA; Bengio Y., 2007, LARGE SCALE KERNEL M; Blitzer J., 2007, ANN M ASS COMP LING, V45, P440; Chapelle O., 2006, SEMISUPERVISED LEARN; Collobert R, 2006, J MACH LEARN RES, V7, P1687; Dasgupta S, 2009, JOINT C 47 ANN M ASS, P701; Dave K., 2003, INT C WORLD WID WEB, P519; Fu G., 2010, INT C COMP LING ASS, P312; Goldberg A.B., 2006, P 1 WORKSH GRAPH BAS, P45, DOI 10.3115/1654758.1654769; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kamvar S., 2003, IJCAI, P561; LEUBA G, 1994, ANAT EMBRYOL, V190, P351; Li S., 2008, ANN M ASS COMP LING, P257, DOI 10.1142/9789812790019_0017; Li S., 2010, INT C COMP LING, P635; Li S, 2010, ANN M ASS COMP LING, P414; Liu Y, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P873; McDonald R. T., 2007, ANN M ASS COMP LING, P432; Mullen T., 2004, C EMP METH NAT LANG, P412; Ng V., 2006, 21 INT C COMP LING 4, P611; Pan S.J., 2010, INT WORLD WID WEB C, P751; Pang B., 2002, C EMP METH NAT LANG, V10, P79, DOI DOI 10.3115/1118693.1118704; Pang B., 2004, ACL 04 P 42 ANN M AS, V42, P271; Purushothaman G, 1997, IEEE T NEURAL NETWOR, V8, P679, DOI 10.1109/72.572106; Rutkowska D., 2002, NEUROFUZZY ARCHITECT; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; Sindhwani V, 2008, IEEE DATA MINING, P1025, DOI 10.1109/ICDM.2008.113; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tan S., 2007, C INF KNOWL MAN, P979; Tong S, 2002, J MACH LEARN RES, V2, P45; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Turney P. D., 2002, ACL 02, P417; Wan X., 2009, JOINT C 47 ANN M ASS, V1, P235; Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400; Wang M., 2012, ACM COMPUT SURV, V44, P1; Wang M., 2011, ACM T INTEL SYST TEC, V2, P1; Wang XM, 2010, NEUROCOMPUTING, V73, P2186, DOI 10.1016/j.neucom.2010.01.021; Wei W, 2010, ANN M ASS COMP LING, P404; Xia Y., 2008, ANN M ASS COMP LING, P133; Yu J, 2012, NEUROCOMPUTING, V79, P105, DOI 10.1016/j.neucom.2011.10.003; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083; Yu J, 2011, IEEE T IMAGE PROCESS, V20, P3257, DOI 10.1109/TIP.2011.2158225; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zagibalov T., 2008, INT C COMP LING ASS, V1, P1073; Zeki S, 2008, SPLENDORS MISERIES B; Zeki Semir, 1993, VISION BRAIN; Zhou S, 2010, INT C COMP LING, P1515; Zhu X., 2007, THESIS	50	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	MAY 5	2014	131						312	322		10.1016/j.neucom.2013.10.011		11	Computer Science, Artificial Intelligence	Computer Science	AC8SS	WOS:000332805700032		
J	Bo, LF; Ren, XF; Fox, D				Bo, Liefeng; Ren, Xiaofeng; Fox, Dieter			Learning hierarchical sparse features for RGB-(D) object recognition	INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH			English	Article						Object recognition; feature learning; sparse coding; hierarchical segmentation; RGB-D cameras	ORTHOGONAL MATCHING PURSUIT; KERNEL DESCRIPTORS; K-SVD; ALGORITHM; IMAGES; REPRESENTATIONS; DICTIONARIES; RECOVERY; SCENES	Recently introduced RGB-D cameras are capable of providing high quality synchronized videos of both color and depth. With its advanced sensing capabilities, this technology represents an opportunity to significantly increase the capabilities of object recognition. It also raises the problem of developing expressive features for the color and depth channels of these sensors. In this paper we introduce hierarchical matching pursuit (HMP) for RGB-D data. As a multi-layer sparse coding network, HMP builds feature hierarchies layer by layer with an increasing receptive field size to capture abstract representations from raw RGB-D data. HMP uses sparse coding to learn codebooks at each layer in an unsupervised way and builds hierarchical feature representations from the learned codebooks in conjunction with orthogonal matching pursuit, spatial pooling and contrast normalization. Extensive experiments on various datasets indicate that the features learned with our approach enable superior object recognition results using linear support vector machines.	[Bo, Liefeng; Ren, Xiaofeng] ISTC Pervas Comp Intel Labs, Seattle, WA USA; [Bo, Liefeng; Fox, Dieter] Univ Washington, Seattle, WA 98195 USA	Bo, LF (reprint author), Box 352350,101 Paul G Allen Ctr CSE446, Seattle, WA 98105 USA.	lfb@cs.washington.edu			Intel Science and Technology Center for Pervasive Computing; ONR MURI [N00014-07-1-0749]	This work was funded in part by the Intel Science and Technology Center for Pervasive Computing and by ONR MURI (grant number N00014-07-1-0749).	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Aldoma A, 2012, IEEE ROBOT AUTOM MAG, V19, P80, DOI 10.1109/MRA.2012.2206675; Anand A., 2012, INT J ROBOT RES, V32, P19; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Blum M, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), P1298, DOI 10.1109/ICRA.2012.6225188; Bo L., 2011, P NEUR INF PROC SYST, P2115; BO L, 2012, P INT S EXP ROB ISER; BO L, 2010, P ANN C NEUR INF PRO, P1729; Bo LF, 2011, PROC CVPR IEEE, P1729; Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91; Bo LF, 2011, IEEE INT C INT ROBOT, P821; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Browatzki B., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), DOI 10.1109/ICCVW.2011.6130385; Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Carreira J, 2012, INT J COMPUT VISION, V98, P243, DOI 10.1007/s11263-011-0507-2; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Coates A., 2011, P ANN C NEUR INF PRO, P2528; Coates A., 2011, P 14 INT C ART INT S, V15, P215; Coates A., 2011, P INT C MACH LEARN, V28, P921; Dalal N, 2005, PROC CVPR IEEE, P886; Davenport MA, 2010, IEEE T INFORM THEORY, V56, P4395, DOI 10.1109/TIT.2010.2054653; Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; GENS R, 2012, P ANN C NEUR INF PRO, P3248; Henry P., 2010, P ISER, V20, P22; Hinterstoisser S, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P858, DOI 10.1109/ICCV.2011.6126326; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; JAIN P, 2011, P ANN C NEUR INF PRO, P1672; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jiang Y, 2012, INT J ROBOT RES, V31, P1021, DOI 10.1177/0278364912438781; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kavukcuoglu K., 2010, P ADV NEUR INF PROC, V23, P1090; KIROS R, 2012, ICML REPR LEARN WORK; Krizhevsky A., 2012, P ADV NEUR INF PROC, V25, P1106; LAI K, 2012, CONSUMER DEPTH CAMER, P167; LAI K, 2011, P AAAI C ART INT AAA; LAI K, 2011, P IEEE INT C ROB AUT, P1817; LAI KV, 2012, P IEEE INT C ROB AUT, P1330; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Le Q., 2012, P INT C MACH LEARN I, P8595; Le Q. V., 2011, P ADV NEUR INF PROC, V24, P1017; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H, 2006, P NEUR INF PROC SYST, V19, P801; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Li L, 2010, P NIPS, V22, P1378; LIVSHITZ E, 2010, ARXIV10043946; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587652; Mairal J., 2008, P ADV NEUTR INF PROC, V21, P1033; Maji S., 2008, P IEEE C COMP VIS PA, P1; Mo Q, 2012, IEEE T INFORM THEORY, V58, P3654, DOI 10.1109/TIT.2012.2185923; Morisset B, 2009, P IEEE INT C ROB AUT, P3786; Newcombe R., 2011, IEEE INT S MIX AUGM, V1, P127; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pandey M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1307, DOI 10.1109/ICCV.2011.6126383; Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001; Pati Y. C., 1993, AS C SIGN SYST COMP, V1, P40; Quattoni A, 2009, PROC CVPR IEEE, P413; Ren X., 2012, P ANN C NEUR INF PRO, V25, P593; Ren XF, 2012, PROC CVPR IEEE, P2759; Rubinstein R, 2008, TECHNICAL REPORT; Ruhnke M, 2010, IEEE INT C INT ROBOT, P2137; RUHNKE M, 2013, P AAAI C ART INT AAA; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Socher R., 2011, P 28 INT C MACH LEAR, P129; SUN Y, 2013, P IEEE INT C ROB AUT, P2096; Tang J, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), P3467; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; VANDESANDE KEA, 2011, P IEEE INT C COMP VI, P1879; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/ICPR.2008.4761824; Yang JC, 2009, PROC CVPR IEEE, P1794; Yu K, 2011, PROC CVPR IEEE, P1713; Zeiler MD, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2018, DOI 10.1109/ICCV.2011.6126474; Zhang T, 2011, IEEE T INFORM THEORY, V57, P6215, DOI 10.1109/TIT.2011.2162263	83	0	0	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0278-3649	1741-3176		INT J ROBOT RES	Int. J. Robot. Res.	APR	2014	33	4			SI		581	599		10.1177/0278364913514283		19	Robotics	Robotics	AG6SH	WOS:000335548200008		
J	Kelly, N; Gero, JS				Kelly, Nick; Gero, John S.			Interpretation in design: modelling how the situation changes during design activity	RESEARCH IN ENGINEERING DESIGN			English	Article						Situated design; Computational modelling; Interpretation	PERCEPTUAL SYMBOL SYSTEMS; PATTERN-RECOGNITION; FRAMEWORK; CONCEPTUALIZATION; IMPLICIT; MEMORY	This paper presents a model of the way that designers move between situations when interpreting during design activity. Three hypotheses are presented that arise from this model: that designers change their situation during interpretation, that small changes in a source can lead to large changes in the representation and that changes to the situation have their origins in the experience of the designer. The paper demonstrates how this internal movement between situations can be computationally implemented using three examples. The systems implemented demonstrate the way that interpretation can lead to changes in the situation and present an example of how the changes to a designer's situation can be guided by past experiences.	[Kelly, Nick] Univ So Queensland, Australian Digital Futures Inst, Toowoomba, Qld 4350, Australia; [Gero, John S.] George Mason Univ, Krasnow Inst Adv Study & Computat Social Sci, Fairfax, VA 22030 USA; [Gero, John S.] Univ N Carolina, Charlotte, NC 28223 USA	Kelly, N (reprint author), Univ So Queensland, Australian Digital Futures Inst, Toowoomba, Qld 4350, Australia.	nick.kelly.mail@gmail.com; john@johngero.com	Kelly, Nick/	Kelly, Nick/0000-0001-8621-105X	Australian Postgraduate Award scholarship; Australian Research Council [DP 0559885]; US National Science Foundation [SBE-0915482]; Pontificia Universidad Catolica de Chile through the MECESUP project [PUC0611]	This work has been supported by an Australian Postgraduate Award scholarship, by the Australian Research Council under grant no. DP 0559885 and by the US National Science Foundation under Grant No. SBE-0915482. Writing support has been provided by the Pontificia Universidad Catolica de Chile through the MECESUP PUC0611 project. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Australian Research Council or of the US National Science Foundation.	Barsalou LW, 2009, PHILOS T R SOC B, V364, P1281, DOI 10.1098/rstb.2008.0319; Barsalou LW, 2005, CARN S COGN, P389; Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577; Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639; Beyer O, 2012, WORKSH 26 AAAI C ART; Bilda Z, 2006, DESIGN STUD, V27, P587, DOI 10.1016/j.destud.2006.02.002; CARPENTER GA, 1990, NEURAL NETWORKS, V3, P129, DOI 10.1016/0893-6080(90)90085-Y; CARPENTER GA, 1988, COMPUTER, V21, P77, DOI 10.1109/2.33; Chisholm R. M, 1982, FDN KNOWING; Clancey W. J., 1999, CONCEPTUAL COORDINAT; Clancey W. J., 1997, SITUATED COGNITION H; Cross N., 1982, DESIGN STUDIES, V3, P221, DOI [10.1016/0142-694X(82)90040-0, DOI 10.1016/0142-694X(82)90040-0]; Dittenbach M, 2000, NEUR NETW 2000 IJCNN; Fish J, 1990, PERCEPT MOTOR SKILL, V63, P1047; Fodor J., 1975, LANGUAGE THOUGHT; Gabora L, 2008, ECOL PSYCHOL, V20, P84, DOI 10.1080/10407410701766676; Gardenfors P., 2000, CONCEPTUAL SPACES GE; Gero J. S., 1998, Artificial Intelligence in Structural Engineering. Information Technology for Design, Collaboration, Maintenance, and Monitoring; Gero JS, 2000, KNOWL-BASED SYST, V13, P361, DOI 10.1016/S0950-7051(00)00076-9; Gero JS, 2009, KNOWL-BASED SYST, V22, P600, DOI 10.1016/j.knosys.2009.05.005; Gero JS, 2004, DESIGN STUD, V25, P373, DOI 10.1016/j.destud.2003.10.010; Goel AK, 1997, IEEE EXPERT, V12, P62; Gombrich E., 1966, NORM FORM STUDIES AR; GRAF P, 1985, J EXP PSYCHOL LEARN, V11, P501, DOI 10.1037/0278-7393.11.3.501; Gross MD, 2000, COMPUT GRAPH-UK, V24, P835, DOI 10.1016/S0097-8493(00)00087-X; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jupp J, 2005, DIAGRAMMATIC REASONI; Jupp J, 2010, STRUCTUE OF STYLE: ALGORITHMIC APPROACHES TO UNDERSTANDING MANNER AND MEANING, P159, DOI 10.1007/978-3-642-12337-5_8; Kennedy PJ, 2004, J NEUROSCI, V24, P6979, DOI 10.1523/JNEUROSCI.1388-04.2004; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Lee H., 2009, P 26 ANN INT C MACH; Menezes A, 2006, DESIGN STUD, V27, P571, DOI 10.1016/j.destud.2006.02.001; Minsky M., 1975, PSYCHOL COMPUTER VIS, P211; MONTARE A, 1994, PERCEPT MOTOR SKILL, V79, P975; Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701; Murphy G. L., 2002, BIG BOOK CONCEPTS; Newell A., 1994, UNIFIED THEORIES COG, V187; NOSOFSKY RM, 1988, J EXP PSYCHOL LEARN, V14, P54, DOI 10.1037/0278-7393.14.1.54; Peng W, 2006, INNOVATIONS IN DESIGN & DECISION SUPPORT SYSTEMS IN ARCHITECTURE AND URBAN PLANNING, P293, DOI 10.1007/978-1-4020-5060-2_19; Piaget J., 1954, CONSTRUCTION REALITY; Pylyshyn Z. W., 1984, COMPUTATION COGNITIO; Pylyshyn ZW, 1977, IMAGES PERCEPT KNOWL, P1; Riecke L, 2007, J NEUROSCI, V27, P12684, DOI 10.1523/JNEUROSCI.2713-07.2007; Rosch E. H., 1978, COGNITION CATEGORIZA; SCHACTER DL, 1987, J EXP PSYCHOL LEARN, V13, P501, DOI 10.1037//0278-7393.13.3.501; Schon D. A., 1992, DESIGN STUDIES, V13, P135; Shaffer D. W., 2009, INT J LEARNING MEDIA, V1, P33, DOI [10.1162/ijlm.2009.0013, DOI 10.1162/IJLM.2009.0013]; Suwa M., 2000, DESIGN STUDIES, V21, P539, DOI DOI 10.1016/S0142-694X(99)00034-4; Suwa M., 1997, DESIGN STUDIES, V18, P385, DOI 10.1016/S0142-694X(97)00008-2; Thoreau HD, 1851, YEAR THOREAUS J 1851; Tscherepanow M, 2010, LECT NOTES COMPUT SC, V6354, P157, DOI 10.1007/978-3-642-15825-4_21; Wright PC, 1985, PEOPLE COMPUTERS, P345; Yaner PW, 2008, AI EDAM, V22, P117, DOI 10.1017/S0890060408000085	54	0	0	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0934-9839	1435-6066		RES ENG DES	Res. Eng. Design	APR	2014	25	2					109	124		10.1007/s00163-013-0168-y		16	Engineering, Multidisciplinary; Engineering, Industrial; Engineering, Manufacturing	Engineering	AD4SC	WOS:000333239800003		
J	Makukhin, K; Bolland, S				Makukhin, Kirill; Bolland, Scott			Dissociable Forms of Repetition Priming: A Computational Model	NEURAL COMPUTATION			English	Letter							MONKEY INFEROTEMPORAL CORTEX; STIMULUS-SPECIFIC ADAPTATION; INFERIOR TEMPORAL CORTEX; RECOGNITION MEMORY; NEURONAL MECHANISMS; PERIRHINAL CORTEX; PREFRONTAL CORTEX; NEURAL MECHANISMS; REPRESENTATION; HIPPOCAMPUS	Nondeclarative memory and novelty processing in the brain is an actively studied field of neuroscience, and reducing neural activity with repetition of a stimulus (repetition suppression) is a commonly observed phenomenon. Recent findings of an opposite trend-specifically, rising activity for unfamiliar stimuli-question the generality of repetition suppression and stir debate over the underlying neural mechanisms. This letter introduces a theory and computational model that extend existing theories and suggests that both trends are, in principle, the rising and falling parts of an inverted U-shaped dependence of activity with respect to stimulus novelty that may naturally emerge in a neural network with Hebbian learning and lateral inhibition. We further demonstrate that the proposed model is sufficient for the simulation of dissociable forms of repetition priming using real-world stimuli. The results of our simulation also suggest that the novelty of stimuli used in neuroscientific research must be assessed in a particularly cautious way. The potential importance of the inverted-U in stimulus processing and its relationship to the acquisition of knowledge and competencies in humans is also discussed.	[Makukhin, Kirill] Univ Queensland, Brisbane, Qld 4072, Australia; [Bolland, Scott] Queensland Univ Technol, Brisbane, Qld 4059, Australia	Makukhin, K (reprint author), Univ Queensland, Brisbane, Qld 4072, Australia.	k.makukhin@webage.net.au					Anderson J. R., 1976, LANGUAGE MEMORY THOU; Atallah HE, 2004, NEUROBIOL LEARN MEM, V82, P253, DOI 10.1016/j.nlm.2004.06.004; Balu R, 2004, J NEUROPHYSIOL, V92, P743, DOI 10.1152/jn.00016.2004; Beaulieu C., 1992, Cerebral Cortex, V2, P295, DOI 10.1093/cercor/2.4.295; BIEDERMAN I, 2006, AM SCI, V94, P248; BRENNAN WM, 1966, SCIENCE, V151, P354, DOI 10.1126/science.151.3708.354; Brown MW, 2001, NAT REV NEUROSCI, V2, P51, DOI 10.1038/35049064; DEMB JB, 1995, J NEUROSCI, V15, P5870; Desimone R, 1996, P NATL ACAD SCI USA, V93, P13494, DOI 10.1073/pnas.93.24.13494; Duzel E, 2004, EUR J NEUROSCI, V19, P1408, DOI 10.1111/j.1460-9568.2004.03253.x; Eichenbaum H, 2007, ANNU REV NEUROSCI, V30, P123, DOI 10.1146/annurev.neuro.30.051606.094328; Fiebach CJ, 2005, J NEUROSCI, V25, P3414, DOI 10.1523/JNEUROSCI.4107-04.2005; Gagnepain P, 2011, J COGNITIVE NEUROSCI, V23, P391, DOI 10.1162/jocn.2010.21454; Gerstner W., 2002, SPIKING NEURON MODEL; Gibson JR, 1999, NATURE, V402, P75; Gotts SJ, 2003, THESIS CARNEGIE MELL; Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006; Grill-Spector K, 2001, ACTA PSYCHOL, V107, P293, DOI 10.1016/S0001-6918(01)00019-1; Gruber T, 2002, COGNITIVE BRAIN RES, V13, P377, DOI 10.1016/S0926-6410(01)00130-6; Henson R, 2000, SCIENCE, V287, P1269, DOI 10.1126/science.287.5456.1269; HEYDUK RG, 1975, PERCEPT PSYCHOPHYS, V17, P84, DOI 10.3758/BF03204003; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton G. E., 2006, MATLAB CODE SCI PAPE; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hunkin NM, 2002, NEUROPSYCHOLOGIA, V40, P1456, DOI 10.1016/S0028-3932(01)00200-7; Imamoglu C, 2000, J ENVIRON PSYCHOL, V20, P5, DOI 10.1006/jevp.1999.0155; Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719; James TW, 2006, HUM BRAIN MAPP, V27, P37, DOI 10.1002/hbm.20165; Kaplan Frederic, 2007, Front Neurosci, V1, P225, DOI 10.3389/neuro.01.1.1.017.2007; KARMEL BZ, 1969, J COMP PHYSIOL PSYCH, V69, P649, DOI 10.1037/h0028195; Kobatake E, 1998, J NEUROPHYSIOL, V80, P324; Kumaran D, 2007, HIPPOCAMPUS, V17, P735, DOI 10.1002/hipo.20326; Larsson J, 2012, CEREB CORTEX, V22, P567, DOI 10.1093/cercor/bhr119; LeCun Y., 1998, MNIST DATABASE HANDW; Levy CM, 2006, ACTA PSYCHOL, V123, P394, DOI 10.1016/j.actpsy.2006.06.006; LI L, 1993, J NEUROPHYSIOL, V69, P1918; Luo HY, 2011, AM J CLIN ONCOL-CANC, V34, P555, DOI 10.1097/COC.0b013e3181f47ac1; McMahon DBT, 2007, J NEUROPHYSIOL, V97, P3532, DOI 10.1152/jn.01042.2006; MILLER EK, 1994, SCIENCE, V263, P520, DOI 10.1126/science.8290960; MILLER EK, 1991, SCIENCE, V254, P1377, DOI 10.1126/science.1962197; Moldakarimov S, 2010, NEURAL COMPUT, V22, P1312, DOI 10.1162/neco.2009.04-09-999; Naccache L, 2001, CEREB CORTEX, V11, P966, DOI 10.1093/cercor/11.10.966; Nair V., 2010, P 27 INT C MACH LEAR; NEELY JH, 1977, J EXP PSYCHOL GEN, V106, P226, DOI 10.1037//0096-3445.106.3.226; O'Reilly R. C., 1996, THESIS CARNEGIE MELL; O'Reilly R. C., 2011, COGNITIVE SCI, V35, P1; O'Reilly RC, 2000, COMPUTATIONAL EXPLOR; Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271; Palmer S. E., 1999, VISION SCI PHOTONS P; Rainer G, 2000, NEURON, V27, P179, DOI 10.1016/S0896-6273(00)00019-2; Ranzato M., 2010, P 13 INT C ART INT S; Ringo JL, 1996, BEHAV BRAIN RES, V76, P191, DOI 10.1016/0166-4328(95)00197-2; ROLLS ET, 1989, EXP BRAIN RES, V76, P153; Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020; Schacter DL, 2007, CURR OPIN NEUROBIOL, V17, P171, DOI 10.1016/j.conb.2007.02.001; Schmidhuber J, 2010, IEEE T AUTON MENT DE, V2, P230, DOI 10.1109/TAMD.2010.2056368; Schott BH, 2004, LEARN MEMORY, V11, P383, DOI 10.1101/lm.75004; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P282; Sobotka S, 1996, J NEUROSCI, V16, P4222; SOBOTKA S, 1994, BRAIN RES, V646, P95, DOI 10.1016/0006-8993(94)90061-2; Soldan A, 2008, J COGNITIVE NEUROSCI, V20, P1762, DOI 10.1162/jocn.2008.20130; Soldan A, 2010, BRAIN RES, V1343, P122, DOI 10.1016/j.brainres.2010.04.071; Somogyi P, 1998, BRAIN RES REV, V26, P113, DOI 10.1016/S0165-0173(97)00061-1; Squire LR, 2004, NEUROBIOL LEARN MEM, V82, P171, DOI 10.1016/j.nlm.2004.06.005; Summerfield C, 2008, NAT NEUROSCI, V11, P1004, DOI 10.1038/nn.2163; Tang Y., 2011, DATA NORMALIZATION L; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Voss JL, 2010, J NEUROSCI, V30, P9181, DOI 10.1523/JNEUROSCI.0403-10.2010; Wan HM, 1999, J NEUROSCI, V19, P1142; Wig GS, 2005, NAT NEUROSCI, V8, P1228, DOI 10.1038/nn1515; Wiggs CL, 1998, CURR OPIN NEUROBIOL, V8, P227, DOI 10.1016/S0959-4388(98)80144-X; WILLIAMS SM, 1987, CURR PSYCHOL RES REV, V6, P148, DOI 10.1007/BF02686619; Yang JJ, 2008, LEARN MEMORY, V15, P703, DOI 10.1101/lm.900108	74	0	0	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667	1530-888X		NEURAL COMPUT	Neural Comput.	APR	2014	26	4					712	738		10.1162/NECO_a_00569		27	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AC3ZA	WOS:000332459100004	24479780	
J	Principe, JC; Chalasani, R				Principe, Jose C.; Chalasani, Rakesh			Cognitive Architectures for Sensory Processing	PROCEEDINGS OF THE IEEE			English	Article						Empirical Bayes; object recognition; top-down; visual cortex	VISUAL-CORTEX; RECEPTIVE-FIELDS; NATURAL IMAGES; MODEL; RECOGNITION; ATTENTION; FILTERS	This paper describes our efforts to design a cognitive architecture for object recognition in video. Unlike most efforts in computer vision, our work proposes a Bayesian approach to object recognition in video, using a hierarchical, distributed architecture of dynamic processing elements that learns in a self-organizing way to cluster objects in the video input. A biologically inspired innovation is to implement a top-down pathway across layers in the form of causes, creating effectively a bidirectional processing architecture with feedback. To simplify discrimination, overcomplete representations are utilized. Both inference and parameter learning are performed using empirical priors, while imposing appropriate sparseness constraints. Preliminary results show that the cognitive architecture has features that resemble the functional organization of the early visual cortex. One example showing the use of top-down connections is given to disambiguate a synthetic video from correlated noise.	[Principe, Jose C.; Chalasani, Rakesh] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA	Principe, JC (reprint author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.	principe@cnel.ufl.edu; rakeshch@ufl.edu			Office of Naval Research (ONR) [N000141010375]	This work was supported by the Office of Naval Research (ONR) under Grant N000141010375.	Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Cadieu C., 2008, ADV NEURAL INFORM PR, P209; Chalasani R., 2013, P WORKSH INT C LEARN; Chalasani R., 2012, P IEEE INT WORKSH MA, DOI [10.1109/MLSP.2012.6349758, DOI 10.1109/MLSP.2012.6349758]; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; Erhan D, 2010, J MACH LEARN RES, V11, P625; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000211; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; Fuster J. M., 2003, CORTEX MIND UNIFYING; Gazzaniga M. S., 2009, COGNITIVE NEUROSCIEN; Gregor K., 2010, P INT C MACH LEARN, P399; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2001, VISION RES, V41, P2413, DOI 10.1016/S0042-6989(01)00114-6; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Karklin Yan, 2005, Neural Comput, V17, P397, DOI 10.1162/0899766053011474; Kiebel SJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000209; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Maunsell JHR, 2006, TRENDS NEUROSCI, V29, P317, DOI 10.1016/j.tins.2006.04.001; Memisevic R., 2007, P IEEE C COMP VIS PA, DOI [10.1109/CVPR.2007.383036, DOI 10.1109/CVPR.2007.383036]; Mobahi H., 2009, P 26 ANN INT C MACH, P737; Nelson A. T., 2000, THESIS OREGON GRADUA; Nene S. A., 1996, COLUMBIA OBJECT IMAG; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Principe J, 2002, NEURAL NETWORKS, V15, P1069, DOI 10.1016/S0893-6080(02)00080-1; Ranzato M., 2007, P IEEE C COMP VIS PA, V5, P1, DOI DOI 10.1109/CVPR.2007.383157; Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721; Rao RPN, 1998, ADV NEUR IN, V10, P80; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Rust NC, 2005, NEURON, V46, P945, DOI 10.1016/j.neuron.2005.05.021; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P2315; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957; Zou W., 2012, ADV NEURAL INFORM PR, V25, P3212	37	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9219	1558-2256		P IEEE	Proc. IEEE	APR	2014	102	4			SI		514	525		10.1109/JPROC.2014.2307023		12	Engineering, Electrical & Electronic	Engineering	AE6LE	WOS:000334103300012		
J	Raudies, F; Zilli, EA; Hasselmo, ME				Raudies, Florian; Zilli, Eric A.; Hasselmo, Michael E.			Deep Belief Networks Learn Context Dependent Behavior	PLOS ONE			English	Article							DECISION-PROCESS STRUCTURE; POSSIBLE STRATEGIC USE; PREFRONTAL CORTEX; EPISODIC MEMORY; WORKING-MEMORY; SWITCHES; SYSTEMS; NEURONS; MODEL; TASKS	With the goal of understanding behavioral mechanisms of generalization, we analyzed the ability of neural networks to generalize across context. We modeled a behavioral task where the correct responses to a set of specific sensory stimuli varied systematically across different contexts. The correct response depended on the stimulus (A,B,C,D) and context quadrant (1,2,3,4). The possible 16 stimulus-context combinations were associated with one of two responses (X,Y), one of which was correct for half of the combinations. The correct responses varied symmetrically across contexts. This allowed responses to previously unseen stimuli (probe stimuli) to be generalized from stimuli that had been presented previously. By testing the simulation on two or more stimuli that the network had never seen in a particular context, we could test whether the correct response on the novel stimuli could be generated based on knowledge of the correct responses in other contexts. We tested this generalization capability with a Deep Belief Network (DBN), Multi-Layer Perceptron (MLP) network, and the combination of a DBN with a linear perceptron (LP). Overall, the combination of the DBN and LP had the highest success rate for generalization.	[Raudies, Florian; Hasselmo, Michael E.] Boston Univ, Ctr Computat Neurosci & Neural Technol, Boston, MA 02215 USA; [Raudies, Florian; Hasselmo, Michael E.] Boston Univ, Ctr Excellence Learning Educ Sci & Technol, Boston, MA 02215 USA; [Zilli, Eric A.] Facebook, Menlo Pk, CA USA; [Hasselmo, Michael E.] Boston Univ, Dept Psychol, Boston, MA 02215 USA; [Hasselmo, Michael E.] Boston Univ, Grad Program Neurosci, Boston, MA 02215 USA	Raudies, F (reprint author), Boston Univ, Ctr Computat Neurosci & Neural Technol, Boston, MA 02215 USA.	fraudies@bu.edu			NIMH [P50 MH094263, MH60013]; Office of Naval Research [ONR MURI N00014-10-1-0936]; CELEST, a NSF Science of Learning Center [NSF SMA-0835976]	MH is supported in part by NIMH P50 MH094263 and MH60013. MH and FR are supported in part by the Office of Naval Research (ONR MURI N00014-10-1-0936) and by CELEST, a NSF Science of Learning Center (NSF SMA-0835976). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Badre D, 2010, NEURON, V66; Chapelle O., 2006, SEMISUPERVISED LEARN; Chapmans D., 1991, P 12 INT JOINT C ART, P726; Fischer A., 2012, LNCS, V7441, P14; Givan R, 2003, ARTIF INTELL, V147, P163, DOI 10.1016/S0004-3702(02)00376-4; Hasselmo ME, 2005, J COGNITIVE NEUROSCI, V17, P1115, DOI 10.1162/0898929054475190; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2009, SCHOLARPEDIA, V4; Hyman JM, 2005, HIPPOCAMPUS, V15, P739, DOI 10.1002/hipo.20106; Koene RA, 2005, CEREB CORTEX, V15, P1964, DOI 10.1093/cercor/bhi072; Kumaran D, 2009, NEURON, V63, P889, DOI 10.1016/j.neuron.2009.07.030; McCallum Andrew Kachites, 1995, THESIS U ROCHESTER R; MCCLELLAND JL, 1995, PSYCHOL REV, V102, P419, DOI 10.1037/0033-295X.102.3.419; Miller EK, 1999, NEURON, V22, P15, DOI 10.1016/S0896-6273(00)80673-X; Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167; Narayanamurthy SM, 2008, P 25 INT C ICML 2008; Navawongse R, 2013, J NEUROSCI, V33, P1002, DOI 10.1523/JNEUROSCI.3891-12.2013; Petrides M, 1996, PHILOS T ROY SOC B, V351, P1455, DOI 10.1098/rstb.1996.0130; Pyeatt LD, 1998, CS98112 COL STAT U; Ranganath CRB, 2008, LEARNING MEMORY COMP, P261; Ravindran B, 2003, ALGEBRAIC APPROACH A; Rich EL, 2007, J NEUROSCI, V27, P4747, DOI 10.1523/JNEUROSCI.0369-07.2007; Rich EL, 2009, J NEUROSCI, V29, P7208, DOI 10.1523/JNEUROSCI.6068-08.2009; Rumelhart RE, 1986, NATURE, V323, P533; Taylor ME, 2009, J MACH LEARN RES, V10, P1633; Tse D, 2007, SCIENCE, V316, P76, DOI 10.1126/science.1135935; Wallis JD, 2003, J NEUROPHYSIOL, V90, P1790, DOI 10.1152/jn.00086.2003; Wallis JD, 2001, NATURE, V411, P953, DOI 10.1038/35082081; Young JJ, 2009, BEHAV NEUROSCI, V123, P1028, DOI 10.1037/a0016822; Zilli EA, 2008, FRONT COMPUT NEUROSC, V2, DOI 10.3389/neuro.10.006.2008; Zilli EA, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002756; Zilli EA, 2008, HIPPOCAMPUS, V18, P193, DOI 10.1002/hipo.20382	32	0	0	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	MAR 26	2014	9	3							e93250	10.1371/journal.pone.0093250		9	Multidisciplinary Sciences	Science & Technology - Other Topics	AE0SR	WOS:000333677000129	24671178	
J	Eguchi, A; Neymotin, SA; Stringer, SM				Eguchi, Akihiro; Neymotin, Samuel A.; Stringer, Simon M.			Color opponent receptive fields self-organize in a biophysical model of visual cortex via spike-timing dependent plasticity	FRONTIERS IN NEURAL CIRCUITS			English	Article						brain modeling; visual cortex; neocortex; color; color selectivity; self-organizing color maps; self-organizing feature maps; STDP	INVARIANT OBJECT RECOGNITION; LATERAL GENICULATE-NUCLEUS; SYNAPTIC PLASTICITY; ORIENTATION MAPS; STRIATE CORTEX; COMPUTER-MODEL; SMALL-WORLD; MACAQUE; NEURONS; SYSTEM	Although many computational models have been proposed to explain orientation maps in primary visual cortex (V1), it is not yet known how similar clusters of color-selective neurons in macaque V1N2 are connected and develop. In this work, we address the problem of understanding the cortical processing of color information with a possible mechanism of the development of the patchy distribution of color selectivity via computational modeling. Each color input is decomposed into a red, green, and blue representation and transmitted to the visual cortex via a simulated optic nerve in a luminance channel and red green and blue yellow opponent color channels. Our model of the early visual system consists of multiple topographically-arranged layers of excitatory and inhibitory neurons, with sparse intra-layer connectivity and feed-forward connectivity between layers. Layers are arranged based on anatomy of early visual pathways, and include a retina, lateral geniculate nucleus, and layered neocortex. Each neuron in the V1 output layer makes synaptic connections to neighboring neurons and receives the three types of signals in the different channels from the corresponding photoreceptor position. Synaptic weights are randomized and learned using spike-timing-dependent plasticity (STDP). After training with natural images, the neurons display heightened sensitivity to specific colors. Information-theoretic analysis reveals mutual information between particular stimuli and responses, and that the information reaches a maximum with fewer neurons in the higher layers, indicating that estimations of the input colors can be done using the output of fewer cells in the later stages of cortical processing. In addition, cells with similar color receptive fields form clusters. Analysis of spiking activity reveals increased firing synchrony between neurons when particular color inputs are presented or removed (ON-cell/OFF-cell).	[Eguchi, Akihiro; Stringer, Simon M.] Univ Oxford, Dept Expt Psychol, Oxford Ctr Theoret Neurosci & Artificial Intellig, Oxford OX1 3UD, England; [Neymotin, Samuel A.] Suny Downstate Med Ctr, Dept Physiol & Pharmacol, New York, NY USA; [Neymotin, Samuel A.] Yale Univ, Sch Med, Dept Neurobiol, New Haven, CT USA	Eguchi, A (reprint author), Univ Oxford, Dept Expt Psychol, Oxford Ctr Theoret Neurosci & Artificial Intellig, S Parks Rd, Oxford OX1 3UD, England.	akihiro.eguchi@psy.ox.ac.uk	Neymotin, Samuel/	Neymotin, Samuel/0000-0003-3646-5195			Abbott LF, 2000, NAT NEUROSCI, V3, P1178, DOI 10.1038/81453; Adesnik H, 2010, NATURE, V464, P1155, DOI 10.1038/nature08935; Alivisatos AP, 2013, ACS NANO, V7, P1850, DOI 10.1021/nn4012847; Barbour B, 2007, TRENDS NEUROSCI, V30, P622, DOI 10.1016/j.tins.2007.09.005; Barrow HG, 1996, NEURAL COMPUT, V8, P1427, DOI 10.1162/neco.1996.8.7.1427; Basalyga G, 2011, ADV EXP MED BIOL, V718, P33, DOI 10.1007/978-1-4614-0164-3_4; Bednar JA, 2005, NEUROCOMPUTING, V65, P69, DOI 10.1016/j.neucom.2004.10.055; Bi GQ, 1998, J NEUROSCI, V18, P10464; Carnevale N. T., 2009, NEURON BOOK; CASAGRANDE VA, 1994, TRENDS NEUROSCI, V17, P305, DOI 10.1016/0166-2236(94)90065-5; Chatterjee S, 2003, NATURE, V426, P668, DOI 10.1038/nature02163; Choe Y, 1998, NEUROCOMPUTING, V21, P139, DOI 10.1016/S0925-2312(98)00040-X; Douglas RJ, 2007, NEURON, V56, P226, DOI 10.1016/j.neuron.2007.10.017; Dura-Bernal S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048216; Eguchi A, 2013, WORLD WIDE WEB, V16, P357, DOI 10.1007/s11280-012-0182-4; Evans BD, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069952; Freeman J, 2011, NAT NEUROSCI, V14, P1195, DOI 10.1038/nn.2889; Freiwald WA, 2010, SCIENCE, V330, P845, DOI 10.1126/science.1194908; Friedman HS, 2003, J PHYSIOL-LONDON, V548, P593, DOI 10.1113/jphysiol.2002.033555; Gerstner W, 1996, NATURE, V383, P76, DOI 10.1038/383076a0; Goda N, 2009, LECT NOTES COMPUT SC, V5646, P23, DOI 10.1007/978-3-642-03265-3_3; Graves A., 2008, ADV NEURAL INFORM PR, V21, P545; Hines Michael L, 2009, Front Neuroinform, V3, P1, DOI 10.3389/neuro.11.001.2009; Hines ML, 2004, J COMPUT NEUROSCI, V17, P7, DOI 10.1023/B:JCNS.0000023869.22017.2e; Hines ML, 2001, NEUROSCIENTIST, V7, P123; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hopf JM, 2006, P NATL ACAD SCI USA, V103, P1053, DOI 10.1073/pnas.0507746103; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Hung CP, 2005, SCIENCE, V310, P863, DOI 10.1126/science.1117593; Kang KJ, 2003, P NATL ACAD SCI USA, V100, P2848, DOI 10.1073/pnas.0138051100; Kato H., 2007, P 2007 INT S NONL TH, P429; Kato H, 2009, LECT NOTES COMPUT SC, V5768, P306; Komatsu H, 2009, LECT NOTES COMPUT SC, V5646, P1, DOI 10.1007/978-3-642-03265-3_1; Komatsu H, 1998, CURR OPIN NEUROBIOL, V8, P503, DOI 10.1016/S0959-4388(98)80038-X; Landisman CE, 2002, J NEUROPHYSIOL, V87, P3138, DOI 10.1152/jn.00957.1999; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; LIVINGSTONE MS, 1984, J NEUROSCI, V4, P309; Lu HD, 2008, CEREB CORTEX, V18, P516, DOI 10.1093/cercor/bhm081; Lytton WW, 2008, NAT REV NEUROSCI, V9, P626, DOI 10.1038/nrn2416; Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213; Martin KAC, 2002, CURR OPIN NEUROBIOL, V12, P418, DOI 10.1016/S0959-4388(02)00343-4; MICHAEL CR, 1978, J NEUROPHYSIOL, V41, P572; Neymotin SA, 2011, FRONT COMPUT NEUROSC, V5, DOI 10.3389/fncom.2011.00019; Neymotin S. A., 2011, 2011 IEEE SIGN PROC, P1, DOI [10.1109/SPMB.2011.6120115, DOI 10.1109/SPMB.2011.6120115]; Neymotin SA, 2013, NEURAL COMPUT, V25, P3263, DOI 10.1162/NECO_a_00521; Paik SB, 2011, NAT NEUROSCI, V14, P919, DOI 10.1038/nn.2824; PETTET MW, 1992, P NATL ACAD SCI USA, V89, P8366, DOI 10.1073/pnas.89.17.8366; Qiu SF, 2011, J NEUROSCI, V31, P5855, DOI 10.1523/JNEUROSCI.6569-10.2011; QUATTONI A, 2009, IEEE C COMP VIS PATT, P413, DOI DOI 10.1109/CVPR.2009.5206537; Rao A., 2012, 2012 INT JOINT C NEU, P1; Rolls ET, 1998, NEURAL NETWORKS BRAI; Rolls ET, 2000, NEURAL COMPUT, V12, P2547, DOI 10.1162/089976600300014845; Rolls ET, 2006, J PHYSIOLOGY-PARIS, V100, P43, DOI 10.1016/j.jphysparis.2006.09.004; Rowan M., 2013, ADAPTIVE NATURAL COM, V7824, P20; Rowe MH, 2002, NEWS PHYSIOL SCI, V17, P93, DOI 10.1152/nips.01376.2001; Royer S, 2003, NATURE, V422, P518, DOI 10.1038/nature01530; Rullen R. V., 2001, NEURAL COMPUT, V13, P1255, DOI DOI 10.1162/08997660152002852; Salzmann MFV, 2012, J NEUROSCI, V32, P7881, DOI 10.1523/JNEUROSCI.4832-11.2012; SHAPLEY R, 1981, NATURE, V292, P543, DOI 10.1038/292543a0; Shepherd G. M., 2004, SYNAPTIC ORG BRAIN, P165, DOI DOI 10.1093/ACPR0F:0S0/9780195159561.003.0005; Shin CW, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.045101; SOMERS DC, 1995, J NEUROSCI, V15, P5448; Song S, 2000, NAT NEUROSCI, V3, P919; Stringer SM, 2002, NEURAL COMPUT, V14, P2585, DOI 10.1162/089976602760407982; Sugase Y, 1999, NATURE, V400, P869, DOI 10.1038/23703; Weiler N, 2008, NAT NEUROSCI, V11, P360, DOI 10.1038/nn2049; Xiao YP, 2003, NATURE, V421, P535, DOI 10.1038/nature01372; Yu S, 2008, CEREB CORTEX, V18, P2891, DOI 10.1093/cercor/bhn047	68	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-5110			FRONT NEURAL CIRCUIT	Front. Neural Circuits	MAR 12	2014	8								16	10.3389/fncir.2014.00016		14	Neurosciences	Neurosciences & Neurology	AC7TW	WOS:000332735800001	24659956	
J	Manning, T; Sleator, RD; Walsh, P				Manning, Timmy; Sleator, Roy D.; Walsh, Paul			Biologically inspired intelligent decision making A commentary on the use of artificial neural networks in bioinformatics	BIOENGINEERED			English	Editorial Material						artificial neural networks; multilayer perceptron; bioinformatics; protein structure prediction; gene-gene interaction; gene identification; genome wide association study	PROTEIN SECONDARY STRUCTURE; STRUCTURE PREDICTION CASP; CODING REGIONS; DNA-SEQUENCES; LEARNING RATE; CANCER; CLASSIFICATION; ALGORITHM; BACKPROPAGATION; RECOGNITION	Artificial neural networks (ANNs) are a class of powerful machine learning models for classification and function approximation which have analogs in nature. An ANN learns to map stimuli to responses through repeated evaluation of exemplars of the mapping. This learning approach results in networks which are recognized for their noise tolerance and ability to generalize meaningful responses for novel stimuli. It is these properties of ANNs which make them appealing for applications to bioinformatics problems where interpretation of data may not always be obvious, and where the domain knowledge required for deductive techniques is incomplete or can cause a combinatorial explosion of rules. In this paper, we provide an introduction to artificial neural network theory and review some interesting recent applications to bioinformatics problems.	[Manning, Timmy] Cork Inst Technol, Dept Comp Sci, Cork, Ireland; [Sleator, Roy D.] Cork Inst Technol, Dept Biol Sci, Cork, Ireland; [Walsh, Paul] NSilico Ltd, Rubicon Innovat Ctr, Cork, Ireland	Sleator, RD (reprint author), Cork Inst Technol, Dept Biol Sci, Cork, Ireland.	roy.sleator@cit.ie					Acharya UR, 2013, P I MECH ENG H, V227, P788, DOI 10.1177/0954411913483637; Ahmad AM, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1031, DOI 10.1145/2330163.2330307; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Arad BS, 1997, NEURAL NETWORKS, V10, P539, DOI 10.1016/S0893-6080(96)00089-5; Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700; Attoh-Okine NO, 1999, ADV ENG SOFTW, V30, P291, DOI 10.1016/S0965-9978(98)00071-4; BABA N, 1989, NEURAL NETWORKS, V2, P367, DOI 10.1016/0893-6080(89)90021-X; Bahri B, 2013, APPL ENERG, V108, P24, DOI 10.1016/j.apenergy.2013.03.004; Bandyopadhyay S, 2008, IEEE T SYST MAN CY C, V38, P55, DOI 10.1109/TSMCC.2007.906066; Bertin E, 1996, ASTRON ASTROPHYS SUP, V117, P393, DOI 10.1051/aas:1996164; Bishop C.M., 1995, NEURAL NETWORKS PATT; Burset M, 1996, GENOMICS, V34, P353, DOI 10.1006/geno.1996.0298; Bush WS, 2009, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2009, P368; Chan KL, 2002, IEEE T BIO-MED ENG, V49, P963, DOI 10.1109/TBME.2002.802012; Chang RF, 2003, ACAD RADIOL, V10, P189, DOI 10.1016/S1076-6332(03)80044-2; Chen K, 2012, HDB NATURAL COMPUTIN, P565; Chen XM, 2005, INT J NEURAL SYST, V15, P435, DOI 10.1142/S0129065705000426; Cho S-B, 2003, P 1 AS PAC BIOINF C, V19, P189; Cho SB, 2002, P IEEE, V90, P1744, DOI 10.1109/JPROC.2002.804682; Chowdhury SA, 2011, J COMPUT BIOL, V18, P263, DOI 10.1089/cmb.2010.0269; Chuang HY, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100180; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Djavan B, 2002, J CLIN ONCOL, V20, P921, DOI 10.1200/JCO.20.4.921; Dobson CM, 2001, PHILOS T ROY SOC B, V356, P133, DOI 10.1098/rstb.2000.0758; Durda K, 2009, BEHAV RES METHODS, V41, P1210, DOI 10.3758/BRM.41.4.1210; Ein-Dor L, 2006, P NATL ACAD SCI USA, V103, P5923, DOI 10.1073/pnas.0601231103; Elfwing Stefan, 2013, Front Neurorobot, V7, P3, DOI 10.3389/fnbot.2013.00003; Fahlman SE, 1989, CMUCS90100; FICKETT JW, 1992, NUCLEIC ACIDS RES, V20, P6441, DOI 10.1093/nar/20.24.6441; FICKETT JW, 1982, NUCLEIC ACIDS RES, V10, P5303, DOI 10.1093/nar/10.17.5303; Firoozpour L, 2012, DARU, V20, DOI 10.1186/2008-2231-20-31; Floreano Dario, 2008, Evolutionary Intelligence, V1, DOI 10.1007/s12065-007-0002-4; Florido JP, 2013, NEUROCOMPUTING, V121, P64, DOI 10.1016/j.neucom.2012.11.040; Fogel GB, 2003, EVOLUTIONARY COMPUTA, P193; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0; Giacobini M, 2012, P 10 EUR C EV COMP M; Gori M, 1992, IEEE T PATTERN ANAL, V12, P1992; HAPPEL BLM, 1994, NEURAL NETWORKS, V7, P985, DOI 10.1016/S0893-6080(05)80155-8; Hawkins J, 2009, PHILOS T R SOC B, V364, P1203, DOI 10.1098/rstb.2008.0322; Hawkins J., 2010, HIERARCHICAL TEMPORA; Hayward JA, 2013, RETROVIROLOGY, V10, DOI 10.1186/1742-4690-10-35; Hecht-Nielsen R, 1989, INT JOINT C NEURAL N, V1, P593; Henry Marine, 2011, Bioeng Bugs, V2, P88, DOI 10.4161/bbug.2.2.14138; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G. E., ARXIV12070580; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holzinger E. R., 2010, GENET EVOL COMPUT C, V12, P203; Holzinger Emily R, 2013, Pac Symp Biocomput, P385; Homaei H, 2013, J ENG, V2013; Hughes VF, 2001, LIVER TRANSPLANT, V7, P496, DOI 10.1053/jlts.2001.24642; Irsoy O, 2012, IEEE ACM T COMPUT BI, V9, P1663, DOI 10.1109/TCBB.2012.117; JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2; Jin W, 2000, SIGN PROC P 2000 WCC, P1647; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Khan MM, 2010, EV COMP CEC 2010 IEE, P1; Kotsiantis SB, 2007, FRONT ARTIF INTEL AP, V160, P3; Lancashire LJ, 2009, BRIEF BIOINFORM, V10, P315, DOI 10.1093/bib/bbp012; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Leite D, 2013, NEURAL NETWORKS, V38, P1, DOI 10.1016/j.neunet.2012.10.006; Lowery JW, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057840; Manning T, 2013, BIOENGINEERED, V4, P266, DOI 10.4161/bioe.23041; Manning Timmy, 2012, Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics. Proceedings of the 10th European Conference, EvoBIO 2012, DOI 10.1007/978-3-642-29066-4_1; Manning Timmy, 2013, Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics. 11th European Conference, EvoBIO 2013. Proceedings, DOI 10.1007/978-3-642-37189-9_15; Mariani S, 2013, CLIN NEUROPHYSIOL, V124, P1815, DOI 10.1016/j.clinph.2013.04.005; Meighani HM, 2013, DESALIN WATER TREAT, V51, P7476, DOI 10.1080/19443994.2013.773861; McEvoy FJ, 2012, VET RADIOL ULTRASOUN, V54, P122; McGuffin LJ, 2000, BIOINFORMATICS, V16, P404, DOI 10.1093/bioinformatics/16.4.404; Meireles MRG, 2003, IEEE T IND ELECTRON, V50, P585, DOI 10.1109/TIE.2003.812470; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Montana DJ, 1989, MACH LEARN, V1, P762; Moult J, 1999, PROTEINS, P2; Moult J, 2001, PROTEINS, P2; Nannapaneni K, 2013, COMPUT BIOL MED, V43, P738, DOI 10.1016/j.compbiomed.2013.03.004; Nissen S., 2003, IMPLEMENTATION FAST, P31; Picton P., 2000, NEURAL NETWORKS; Plake C, 2006, BIOINFORMATICS, V22, P2444, DOI 10.1093/bioinformatics/btl408; Pollack JB., 1990, COMPLEX SYSTEMS, V4, P269; Prechelt L., 1994, FAKULTAT INFORM U KA, V21, P94; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Rao PNDT, 2010, INT J ENG SCI TECHNO, V2, P1752; Razavi S, 2011, IEEE T NEURAL NETWOR, V22, P1588, DOI 10.1109/TNN.2011.2163169; Reese MG, 2001, COMPUT CHEM, V26, P51, DOI 10.1016/S0097-8485(01)00099-7; Roberts RJ, 2001, P NATL ACAD SCI USA, V98, P381, DOI 10.1073/pnas.98.2.381; Rodrigues JPGLM, 2012, NUCLEIC ACIDS RES, V40, pW323, DOI 10.1093/nar/gks376; Rodriguez-Gonzalez A, 2011, EXPERT SYST APPL, V38, P11489, DOI 10.1016/j.eswa.2011.03.023; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0; Salakhutdinov R., 2009, JMLR W CP AISTATS 20, V5, P448; Shamseldin AY, 1997, J HYDROL, V199, P272, DOI 10.1016/S0022-1694(96)03330-6; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1007/BF00114160; SIETSMA J, 1991, NEURAL NETWORKS, V4, P67, DOI 10.1016/0893-6080(91)90033-2; Sjostrom PJ, 1999, CYTOMETRY, V36, P18; Sleator RD, 2012, METHODS MOL BIOL, V815, P15, DOI [10.1007/978-1-61779-424-7_2, 10.1007/978-1-61779-424-72]; Sleator RD, 2012, BIOENGINEERED, V3, P311, DOI 10.4161/bioe.22367; Sleator RD, 2012, BIOENGINEERED, V3, P80, DOI 10.4161/bbug.18303; Sleator RD, 2010, GENE, V461, P1, DOI 10.1016/j.gene.2010.04.008; Sontag ED, 1989, AIP C P, V3, P91; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Surkan A. J., 1990, P INT JOINT C NEUR N, V2, P157; Sussillo D, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026027; SZU H, 1987, PHYS LETT A, V122, P157, DOI 10.1016/0375-9601(87)90796-1; Taylor JA, 2013, J NEUROPHYSIOL, V109, P202, DOI 10.1152/jn.00247.2012; TETKO IV, 1995, J CHEM INF COMP SCI, V35, P826, DOI 10.1021/ci00027a006; Touretzky DS, 1988, P 1988 CONN MOD SUMM; Tsien RY, 1998, ANNU REV BIOCHEM, V67, P509, DOI 10.1146/annurev.biochem.67.1.509; Tu JV, 1996, J CLIN EPIDEMIOL, V49, P1225, DOI 10.1016/S0895-4356(96)00002-9; Turner SD, 2010, BIODATA MIN, V3, DOI 10.1186/1756-0381-3-5; UBERBACHER EC, 1991, P NATL ACAD SCI USA, V88, P11261, DOI 10.1073/pnas.88.24.11261; Van den Broeke A, 2013, CZECH J ANIM SCI, V58, P79; WADA KN, 1990, NUCLEIC ACIDS RES, V18, P2367; Waibel A., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.39; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Werbos P. J., 1974, THESIS HARVARD U CAM; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323; Xu S., 2008, INT C INF TECHN APPL, P683; Yang ZR, 2010, METHODS MOL BIOL, V609, P197, DOI 10.1007/978-1-60327-241-4_12; Yao AI, 2013, ACS SYNTH BIOL, V2, P111, DOI 10.1021/sb300114d; Zhao Y, 2013, LAB CHIP, V13, P2272, DOI 10.1039/c3lc41361f	126	0	0	LANDES BIOSCIENCE	AUSTIN	1806 RIO GRANDE ST, AUSTIN, TX 78702 USA	2165-5979	2165-5987		BIOENGINEERED	Bioengineered	MAR-APR	2014	5	2					80	95		10.4161/bioe.26997		16	Biotechnology & Applied Microbiology	Biotechnology & Applied Microbiology	AI5KU	WOS:000336906200015	24335433	
J	Vavrecka, M; Farkas, I				Vavrecka, Michal; Farkas, Igor			A Multimodal Connectionist Architecture for Unsupervised Grounding of Spatial Language	COGNITIVE COMPUTATION			English	Article						Unsupervised learning; Self-organizing map; Symbol grounding; Spatial phrases; Multimodal representations	SELF-ORGANIZING NETWORK; NEURAL-NETWORKS; MODEL; INSIGHTS; FEATURES; BINDING; WORDS; MAPS	We propose a bio-inspired unsupervised connectionist architecture and apply it to grounding the spatial phrases. The two-layer architecture combines by concatenation the information from the visual and the phonological inputs. In the first layer, the visual pathway employs separate 'what' and 'where' subsystems that represent the identity and spatial relations of two objects in 2D space, respectively. The bitmap images are presented to an artificial retina and the phonologically encoded five-word sentences describing the image serve as the phonological input. The visual scene is hence represented by several self-organizing maps (SOMs) and the phonological description is processed by the Recursive SOM that learns to topographically represent the spatial phrases, represented as five-word sentences (e.g., 'blue ball above red cup'). Primary representations from the first-layer modules are unambiguously integrated in a multimodal second-layer module, implemented by the SOM or the 'neural gas' algorithms. The system learns to bind proper lexical and visual features without any prior knowledge. The simulations reveal that separate processing and representation of the spatial location and the object shape significantly improve the performance of the model. We provide quantitative experimental results comparing three models in terms of their accuracy.	[Vavrecka, Michal] Czech Tech Univ, Dept Cybernet, CR-16635 Prague, Czech Republic; [Farkas, Igor] Comenius Univ, Dept Appl Informat, Bratislava 84248, Slovakia	Vavrecka, M (reprint author), Czech Tech Univ, Dept Cybernet, Karlovo Namesti 13, CR-16635 Prague, Czech Republic.	vavrecka@fel.cvut.cz	Farkas, Igor/I-3705-2014; Vavrecka, Michal/C-7023-2015		CTU in Prague [MSM 6840770012]; SAIA scholarship; GACR [P407/11/P696]; VEGA [1/0439/11]	This work has been supported by the research program MSM 6840770012 of the CTU in Prague, SAIA scholarship and GACR Grant P407/11/P696 (M.V.) and by VEGA Grant 1/0439/11 (I.F.).	Cangelosi A, 2004, BRAIN LANG, V89, P401, DOI 10.1016/S0093-934X(03)00353-5; Cangelosi A, 2006, COGNITIVE SCI, V30, P673, DOI 10.1207/s15516709cog0000_72; Cangelosi A, 2000, CONNECT SCI, V12, P143, DOI 10.1080/09540090050129763; Cangelosi A, 2007, IEEE COMPUT INTELL M, V2, P65, DOI 10.1109/MCI.2007.385366; Dorffner G, 1996, P GRON ASS LANG ACQ; Feldman J, 2013, COGN NEURODYNAMICS, V7, P1, DOI 10.1007/s11571-012-9219-8; Fontanari JF, 2009, NEURAL NETWORKS, V22, P579, DOI 10.1016/j.neunet.2009.06.010; Ghose GM, 1999, NEURON, V24, P79, DOI 10.1016/S0896-6273(00)80823-5; Gliozzi V, 2009, COGNITIVE SCI, V33, P709, DOI 10.1111/j.1551-6709.2009.01026.x; GOLDSTEIN E.B., 2002, WAHRNEHMUNGSPSYCHOLO; Greco A., 2010, FRONT NEUROROBOT, V4, DOI [10.3389/fnbot.2010.00111, DOI 10.3389/FNB0T.2010.00111]; GROSSBERG S, 1987, COGNITIVE SCI, V11, P23; Hammer B, 2004, NEURAL NETWORKS, V17, P1061, DOI 10.1016/j.neunet.2004.06.009; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; JACOBS RA, 1991, COGNITIVE SCI, V15, P219, DOI 10.1207/s15516709cog1502_2; James D., 1995, ADV NEURAL INFORMATI, V7, P577; Joyce D., 2003, LOGIC COGNITIVE SYST, P147; Kim B, 2011, NEUROCOMPUTING, V74, P646, DOI 10.1016/j.neucom.2010.09.003; Kohonen T, 2001, SELF ORGANIZING MAPS; Li P, 2002, BEHAV RES METH INS C, V34, P408, DOI 10.3758/BF03195469; Li P, 2004, NEURAL NETWORKS, V17, P1345, DOI 10.1016/j.neunet.2004.07.004; Malach R, 2002, TRENDS COGN SCI, V6, P176, DOI 10.1016/S1364-6613(02)01870-3; Marocco D., 2010, FRONT NEUROROBOT, V4, P7, DOI DOI 10.3389/FNB0T.2010.00007; Marsland S, 2002, NEURAL NETWORKS, V15, P1041, DOI 10.1016/S0893-6080(02)00078-3; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Mel BW, 2000, NEURAL COMPUT, V12, P247, DOI 10.1162/089976600300015772; Miikkulainen R, 1997, BRAIN LANG, V59, P334, DOI 10.1006/brln.1997.1820; Newell A., 1972, HUMAN PROBLEM SOLVIN; O'Reilly RC, 2003, UNITY CONSCIOUSNESS, P168; Peirce Charles Sanders, 1931, COLLECTED PAPERS CS, P1931; Perlovsky LI, 2001, NEURAL NETWORKS INTE; Pezzulo G, 2011, NEW IDEAS PSYCHOL, V29, P275, DOI 10.1016/j.newideapsych.2009.07.004; Pylyshyn Z. W., 1984, COMPUTATION COGNITIO; Regier T., 1996, HUMAN SEMANTIC POTEN; Riesenhuber M, 2002, CURR OPIN NEUROBIOL, V12, P162, DOI 10.1016/S0959-4388(02)00304-5; Roy D, 2005, TRENDS COGN SCI, V9, P389, DOI 10.1016/j.tics.2005.06.013; Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4; Steels L, 1999, P 16 INT JOINT C ART, V2, P862; Stein BE, 1993, MERGING SENSES; Sugita Y, 2005, ADAPT BEHAV, V13, P33, DOI 10.1177/105971230501300102; Taddeo M, 2005, J EXP THEOR ARTIF IN, V17, P419, DOI 10.1080/09528130500284053; Tikhanoff V., 2008, P 8 WORKSH PERF METR, P57, DOI 10.1145/1774674.1774684; Tikhanoff V, 2009, THESIS U POLYMOUTH U; Tino P, 2006, NEURAL COMPUT, V18, P2529, DOI 10.1162/neco.2006.18.10.2529; Ungerleider L. G., 1982, ANAL VISUAL BEHAV; Vavrecka M., 2007, KOGNICE UMELY ZIVOT, P365; Vavrecka M, 2011, LECT NOTES COMPUT SC, V7062, P443, DOI 10.1007/978-3-642-24955-6_53; Vavrecka M., 2008, THESIS MASARYK U BRN; Vavrecka M., 2006, KOGNICE UMELY ZIVOT, V365-377; Vesanto J, 2000, P MATL DSP C, P35; Voegtlin T, 2002, NEURAL NETWORKS, V15, P979, DOI 10.1016/S0893-6080(02)00072-2; Vogt P, 2007, INTERACT STUD, V8, P31, DOI 10.1075/is.8.1.04vog; Ziemke T, 1999, UNDERSTANDING REPRESENTATION IN THE COGNITIVE SCIENCES, P177	53	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1866-9956	1866-9964		COGN COMPUT	Cogn. Comput.	MAR	2014	6	1					101	112		10.1007/s12559-013-9212-5		12	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AC3XM	WOS:000332454800008		
J	Li, JC; Ng, WWY; Yeung, DS; Chan, PPK				Li, Jin-Cheng; Ng, Wing W. Y.; Yeung, Daniel S.; Chan, Patrick P. K.			Bi-firing deep neural networks	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS			English	Article						Deep neural networks; Activation function; Bi-firing function; Gradient diffusion	LOCALIZED GENERALIZATION ERROR; RECOGNITION	Deep neural networks provide more expressive power in comparison to shallow ones. However, current activation functions can not propagate error using gradient descent efficiently with the increment of the number of hidden layers. Current activation functions, e.g. sigmoid, have large saturation regions which are insensitive to changes of hidden neuron's input and yield gradient diffusion. To relief these problems, we propose a bi-firing activation function in this work. The bi-firing function is a differentiable function with a very small saturation region. Experimental results show that deep neural networks with the proposed activation functions yield faster training, better error propagation and better testing accuracies on seven image datasets.	[Li, Jin-Cheng; Ng, Wing W. Y.; Yeung, Daniel S.; Chan, Patrick P. K.] S China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China	Ng, WWY (reprint author), S China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.	jc.castle.li@gmail.com; wingng@ieee.org			National Natural Science Foundation of China [61272201, 61003171, 61003172]; Program for New Century Excellent Talents in University of China [NCET-11-0162]	This work is supported by National Natural Science Foundation of China (61272201, 61003171 and 61003172) and a Program for New Century Excellent Talents in University (NCET-11-0162) of China.	Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2007, NIPS, V19, P153; Bottou L, 2012, NEURAL NETWORKS TRIC, P430; Chacko BP, 2012, INT J MACH LEARN CYB, V3, P149, DOI 10.1007/s13042-011-0049-5; Duda R.O., 2012, PATTERN CLASSIFICATI; Erhan D, 2009, J MACH LEARN RES, V11, P625; Glorot X., 2010, J MACH LEARN RES P T, V9, P249; Glorot X., 2011, P 14 INT C ART INT S, V15, P315; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Krizhevsky A., 2009, THESIS U TORONTO; Larochelle H., 2007, P 24 INT C MACH LEAR, V227, P473; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Ling Tong Dong, 2010, INT J MACH LEARN CYB, V1, P75; Nair V., 2010, P 27 INT C MACH LEAR, P807; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Ng WWY, 2003, ELECTRON LETT, V39, P787, DOI 10.1049/el:20030499; Ng WWY, 2007, SOFT COMPUT, V11, P375, DOI 10.1007/s00500-006-0092-4; Ranzato M., 2008, P 25 INT C MACH LEAR, P792, DOI 10.1145/1390156.1390256; Ranzato M, 2007, ICDAR 2007: NINTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS, P1213; Rifai S., 2011, P 28 INT C MACH LEAR, P833; Serre T, 2007, PROG BRAIN RES, V165, P33, DOI 10.1016/S0079-6123(06)65004-8; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Yeung DS, 2009, INFORM SCIENCES, V179, P3199, DOI 10.1016/j.ins.2009.06.001	28	0	0	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1868-8071	1868-808X		INT J MACH LEARN CYB	Int. J. Mach. Learn. Cybern.	FEB	2014	5	1					73	83		10.1007/s13042-013-0198-9		11	Computer Science, Artificial Intelligence	Computer Science	AZ2BN	WOS:000348039600008		
J	Chen, FQ; Wu, Y; Bu, YD; Zhao, GD				Chen Fuqiang; Wu Yan; Bu Yude; Zhao Guodong			Spectral Classification Using Restricted Boltzmann Machine	PUBLICATIONS OF THE ASTRONOMICAL SOCIETY OF AUSTRALIA			English	Article						astronomical instrumentation; methods and techniques; methods: analytical; methods: data analysis; methods: statistical	DIGITAL SKY SURVEY; PRINCIPAL COMPONENT ANALYSIS; ARTIFICIAL NEURAL-NETWORKS; CATACLYSMIC VARIABLES; STELLAR SPECTRA; LEARNING ALGORITHM	In this study, a novel machine learning algorithm, restricted Boltzmann machine, is introduced. The algorithm is applied for the spectral classification in astronomy. Restricted Boltzmann machine is a bipartite generative graphical model with two separate layers (one visible layer and one hidden layer), which can extract higher level features to represent the original data. Despite generative, restricted Boltzmann machine can be used for classification when modified with a free energy and a soft-max function. Before spectral classification, the original data are binarised according to some rule. Then, we resort to the binary restricted Boltzmann machine to classify cataclysmic variables and non-cataclysmic variables (one half of all the given data for training and the other half for testing). The experiment result shows state-of-the-art accuracy of 100%, which indicates the efficiency of the binary restricted Boltzmann machine algorithm.	[Chen Fuqiang; Wu Yan; Zhao Guodong] Tongji Univ, Coll Elect & Informat Engn, Shanghai 201804, Peoples R China; [Bu Yude] Shandong Univ, Sch Math & Stat, Weihai 264209, Peoples R China	Wu, Y (reprint author), Tongji Univ, Coll Elect & Informat Engn, Shanghai 201804, Peoples R China.	yanwu@tongji.edu.cn					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Ball NM, 2006, ASTROPHYS J, V650, P497, DOI 10.1086/507440; Bazarghan M, 2012, ASTROPHYS SPACE SCI, V337, P93, DOI 10.1007/s10509-011-0822-7; Bu YD, 2013, PUBL ASTRON SOC AUST, V30, DOI 10.1017/pas.2012.24; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; Daniel SF, 2011, ASTRON J, V142, DOI 10.1088/0004-6256/142/6/203; Gelfand AE, 2000, J AM STAT ASSOC, V95, P1300, DOI 10.2307/2669775; Greenwell R. N., 2003, CALCULUS APPL LIFE S; Gunawardana A., 2008, P 2008 LAUS SWITZ AC, V2, P19; Hinton Geoffrey E., 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, DOI 10.1007/978-3-642-35289-8_32; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Mandic D. P., 2001, P INT C MACH LEARN; McGurk RC, 2010, ASTRON J, V139, P1261, DOI 10.1088/0004-6256/139/3/1261; Muno MP, 2009, ASTROPHYS J SUPPL S, V181, P110, DOI 10.1088/0067-0049/181/1/110; Navarro SG, 2012, ASTRON ASTROPHYS, V538, DOI 10.1051/0004-6361/201016422; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Sarty GE, 2006, PUBL ASTRON SOC AUST, V23, P106, DOI 10.1071/AS06011; Schluter J., 2011, ICMLA, V2, P118; Singh HP, 1998, MON NOT R ASTRON SOC, V295, P312, DOI 10.1046/j.1365-8711.1998.01255.x; Szkody P, 2004, ASTRON J, V128, P1882, DOI 10.1086/423997; Szkody P., 2003, AJ, V583, P430; Szkody P, 2007, ASTRON J, V134, P185, DOI 10.1086/518506; Szkody P, 2002, ASTRON J, V123, P430, DOI 10.1086/324734; Szkody P, 2006, ASTRON J, V131, P973, DOI 10.1086/499308; Szkody P, 2005, ASTRON J, V129, P2386, DOI 10.1086/429595; Tang Y., 2012, CVPR, V25, P2264; Taylor G. W., 2009, ICML, V26, P1025; Warner B., 2003, CATACLYSMIC VARIABLE; WILLIAMS G, 1983, ASTROPHYS J SUPPL S, V53, P523, DOI 10.1086/190900; Wu KW, 2000, SPACE SCI REV, V93, P611, DOI 10.1023/A:1026522914125; Xiong Z., 2012, TRUST SEC PRIV COMP, V81, P640; Yang N, 2009, LECT NOTES COMPUT SC, V5446, P297; Zhang Y, 2004, ASTRON ASTROPHYS, V422, P1113, DOI 10.1051/0004-6361:20040141	35	0	0	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	1323-3580	1448-6083		PUBL ASTRON SOC AUST	Publ. Astron. Soc. Aust.	JAN 2	2014	31								e001	10.1017/pasa.2013.38		7	Astronomy & Astrophysics	Astronomy & Astrophysics	AM2MP	WOS:000339685400001		
J	Prescott, TJ				Prescott, Tony J.			Untitled	CONNECTION SCIENCE			English	Editorial Material							MODEL; BRAIN									Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Braitenberg V., 1984, VEHICLES EXPT SYNTHE; Chiel HJ, 2009, J NEUROSCI, V29, P12807, DOI 10.1523/JNEUROSCI.3338-09.2009; Clark Andy, 2013, Behav Brain Sci, V36, P181, DOI 10.1017/S0140525X12000477; Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266; Gardner H, 1985, MINDS NEW SCI HIST C; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Pfeiffer R., 2007, BODY SHAPES WAY WE T; Prescott T. J., 2012, LECT NOTES COMPUTER, V7375; Prescott TJ, 2006, NEURAL NETWORKS, V19, P31, DOI 10.1016/j.ncunct.2005.06.049; Wyss R., 2006, PLOS BIOL, V4, P120	13	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0954-0091	1360-0494		CONNECT SCI	Connect. Sci.	JAN 2	2014	26	1					1	4		10.1080/09540091.2013.877219		4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	AE4JQ	WOS:000333949100001		
S	Adil, SH; Ali, SSA; Raza, K; Hussaan, AM		Fujita, H; Selamat, A; Haron, H		Adil, S. Hasan; Ali, S. Saad Azhar; Raza, Kamran; Hussaan, A. Mahmood			An Improved Intrusion Detection Approach using Synthetic Minority Over-Sampling Technique and Deep Belief Network	NEW TRENDS IN SOFTWARE METHODOLOGIES, TOOLS AND TECHNIQUES	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	13th International Conference on Intelligent Software Methodologies, Tools, and Techniques (SoMeT)	SEP 22-24, 2014	Langkawi, MALAYSIA			Intrusion Detection; DBN; Multi-Layer Perceptron		This paper presents a network intrusion detection technique based on Synthetic Minority Over-Sampling Technique (SMOTE) and Deep Belief Network (DBN) applied to a class imbalance KDD-99 dataset. SMOTE is used to eliminate the class imbalance problem while intrusion classification is performed using DBN. The proposed technique first resolves the class imbalance problem in the KDD-99 dataset followed by DBN to estimate the initial model. The accuracy is further enhanced by using multilayer perceptron networks. The obtained results are compared with the existing best technique based on reduced size recurrent neural network. The study shows that our approach is competitive and efficient in classifying both intrusion and normal patterns in KDD-99 dataset.	[Adil, S. Hasan; Raza, Kamran; Hussaan, A. Mahmood] Iqra Univ, Fac Engn Sci & Technol, Karachi, Pakistan; [Ali, S. Saad Azhar] Univ Teknol PETRONAS, Elect & Elect Engn Dept, Bandar Seri Iskandar, Malaysia	Adil, SH (reprint author), Iqra Univ, Fac Engn Sci & Technol, Karachi, Pakistan.	hasan.adil@iqra.edu.pk					Ali, 2005, INT J NEURAL SYST, V15, P259; Bouzida Y., 2006, 21 IFIP TC 11 INT IN; Cieslak D. A., 2006, IEEE INT C GRAN COMP; Cohen G, 2006, ARTIF INTELL MED, V37, P7, DOI 10.1016/j.artmed.2005.03.002; Dokas P., 2002, P NSF WORKSH NEXT GE; Endler D., 1998, P ANN COMP SEC APPL, P267; Freund Y., 1994, UCSCCRL9425; Gollmann D., 2006, COMPUTER SECURITY; Graves A., 2009, IEEE T PATTERN ANAL, V31; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang Y-M., 2006, REAL WORLD APPL, V7, P720; Kemmerer R.A., 2002, COMPUTER, V35, P27; Kruegel C, 2004, INTRUSION DETECTION; Lee W., 2001, IEEE S SEC PRIV MAY; LEWIS L, 1993, P IFIP 3 INT S INT N, V12, P671; Mansour S., 2012, NEURAL COMPUT APPL, V21, P1185; Nitesh V. C., 2002, J ARTIFICIAL INTELLI, V16, P321; Owens S. F., 2006, International Journal of Security and Networks, V1, DOI 10.1504/IJSN.2006.011780; Rojas R, 1996, NEURAL NETWORKS SYST; Sabhnani M., 2003, P INT C MACH LEARN M, V1, P209; Sabhnani M., 2004, INTELL DATA ANAL, V8, P403; Stamatatos E, 2008, INFORM PROCESS MANAG, V44, P790, DOI 10.1016/j.ipm.2007.05.012	22	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		978-1-61499-434-3; 978-1-61499-433-6	FRONT ARTIF INTEL AP			2014	265						94	102		10.3233/978-1-61499-434-3-94		9	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BC1JL	WOS:000350151300009		
S	Albornoz, EM; Sanchez-Gutierrez, M; Martinez-Licona, F; Rufiner, HL; Goddard, J		BayroCorrochano, E; Hancock, E		Albornoz, E. M.; Sanchez-Gutierrez, M.; Martinez-Licona, F.; Rufiner, H. L.; Goddard, J.			Spoken Emotion Recognition Using Deep Learning	PROGRESS IN PATTERN RECOGNITION IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS, CIARP 2014	Lecture Notes in Computer Science		English	Proceedings Paper	19th Iberoamerican Congress on Pattern Recognition (CIARP)	NOV 01-05, 2014	Puerto Vallarta, MEXICO	CINVESTAV, Campus Guadalajara, Mexican Assoc Comp Vis, Neural Comp & Robot, Int Assoc Pattern Recognit, Cuban Assoc Pattern Recognit, Chilean Assoc Pattern Recognit, Brazilian Comp Soc, Special Interest Grp, Spanish Assoc Pattern Recognt & Image Anal, Portuguese Assoc Pattern Recognit, INTEL Educ			SPEECH RECOGNITION; FEATURES; SIGNALS	Spoken emotion recognition is a multidisciplinary research area that has received increasing attention over the last few years. In this paper, restricted Boltzmann machines and deep belief networks are used to classify emotions in speech. The motivation lies in the recent success reported using these alternative techniques in speech processing and speech recognition. This classifier is compared with a multilayer perceptron classifier, using spectral and prosodic characteristics. A well-known German emotional database is used in the experiments and two methodologies of cross-validation are proposed. Our experimental results show that the deep method achieves an improvement of 8.67% over the baseline in a speaker independent scheme.	[Albornoz, E. M.; Rufiner, H. L.] Univ Nacl Litoral, CONICET, Ctr Invest SINC I, Santa Fe, Argentina	Albornoz, EM (reprint author), Univ Nacl Litoral, CONICET, Ctr Invest SINC I, Santa Fe, Argentina.						Albornoz EM, 2011, COMPUT SPEECH LANG, V25, P556, DOI 10.1016/j.csl.2010.10.001; Batliner A, 2011, COMPUT SPEECH LANG, V25, P4, DOI 10.1016/j.csl.2009.12.003; Bengio Y., 2009, MACH LEARN, V2, P1; Borchert M, 2005, Proceedings of the 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering (IEEE NLP-KE'05), P147; Brueckner R., 2012, 13 ANN C INT SPEECH, P1; Burkhardt F., 2005, P INT, P1517; Devillers L., 2007, LECT NOTES COMPUTER, V4441, P34; El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020; Eyben F., 2010, P ACM MULT MM FLOR I, P1459, DOI 10.1145/1873951.1874246; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Haykin S., 1998, NEURAL NETWORKS COMP; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, LECT NOTES COMPUTER, V7700, P599; Kim Y, 2013, INT CONF ACOUST SPEE, P3687; Koolagudi Shashidhar G., 2012, International Journal of Speech Technology, V15, DOI 10.1007/s10772-012-9139-3; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Popovic B., 2013, 12 INT SCI PROF S IN; Rabiner L., 1993, FUNDAMENTALS SPEECH; Rufiner HL, 2004, PHYSICA A, V332, P496, DOI [10.1016/j.physa.2003.09.050, 10.1016/i.physa.2003.09.050]; Sanchez-Gutierrez M., 2014, 6 MEX C PAT IN PRESS; Schmidt EM, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P65, DOI 10.1109/ASPAA.2011.6082328; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688; Wulsin D, 2010, DBN TOOLBOX V1 0; Yang B, 2010, SIGNAL PROCESS, V90, P1415, DOI 10.1016/j.sigpro.2009.09.009; Yildirim S, 2011, COMPUT SPEECH LANG, V25, P29, DOI 10.1016/j.csl.2009.12.004	27	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-12568-8; 978-3-319-12567-1	LECT NOTES COMPUT SC			2014	8827						104	111				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BB8DA	WOS:000346407400013		
S	Amaral, T; Silva, LM; Alexandre, LA; Kandaswamy, C; de Sa, JM; Santos, JM		Campilho, A; Kamel, M		Amaral, Telmo; Silva, Luis M.; Alexandre, Luis A.; Kandaswamy, Chetak; de Sa, Joaquim Marques; Santos, Jorge M.			Transfer Learning Using Rotated Image Data to Improve Deep Neural Network Performance	IMAGE ANALYSIS AND RECOGNITION, ICIAR 2014, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	11th International Conference on Image Analysis and Recognition (ICIAR)	OCT 22-24, 2014	PORTUGAL	Assoc Image & Machine Intelligence		Transfer learning; Deep learning; Stacked auto-encoders	NETS	In this work we explore the idea that, in the presence of a small training set of images, it could be beneficial to use that set itself to obtain a transformed training set (by performing a random rotation on each sample), train a source network using the transformed data, then retrain the source network using the original data. Applying this transfer learning technique to three different types of character data, we achieve average relative improvements between 6% and 16% in the classification test error. Furthermore, we show that it is possible to achieve relative improvements between 8% and 42% in cases where the amount of original training samples is very limited (30 samples per class), by introducing not just one rotation but several random rotations per sample.	[Amaral, Telmo; Silva, Luis M.; Kandaswamy, Chetak; de Sa, Joaquim Marques; Santos, Jorge M.] Univ Porto, Inst Engn Biomed INEB, P-4100 Oporto, Portugal	Amaral, T (reprint author), Univ Porto, Inst Engn Biomed INEB, Rua Campo Alegre 823, P-4100 Oporto, Portugal.	Telmo.Amaral@newcastle.ac.uk; lmas@ua.pt					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Ciresan D., 2012, INT JOINT C NEUR NET, P1; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Deng L., 2013, DEEP LEARNING SIGNAL; Glorot X., 2011, INT C MACH LEARN, P513; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Larochelle H., 2007, P 24 INT C MACH LEAR, V227, P473; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Simard P., 2003, INT C DOC AN REC, V2, P958, DOI DOI 10.1109/ICDAR.2003.1227801	10	0	0	SPRINGER INT PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743		978-3-319-11758-4; 978-3-319-11757-7	LECT NOTES COMPUT SC			2014	8814						290	300		10.1007/978-3-319-11758-4_32		11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BB7IO	WOS:000345583300032		
S	Brosch, T; Yoo, Y; Li, DKB; Traboulsee, A; Tam, R		Golland, P; Hata, N; Barillot, C; Hornegger, J; Howe, R		Brosch, Tom; Yoo, Youngjin; Li, David K. B.; Traboulsee, Anthony; Tam, Roger			Modeling the Variability in Brain Morphology and Lesion Distribution in Multiple Sclerosis by Deep Learning	MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2014, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	17th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)	SEP 14-18, 2014	Boston, MA	Harvard Med Sch	Massachusetts Inst Technol	Population modeling; multiple sclerosis; T2 lesion; machine learning; brain imaging; MRI; deep learning; deep belief networks	REGISTRATION; ACCURATE; ROBUST	Changes in brain morphology and white matter lesions are two hallmarks of multiple sclerosis (MS) pathology, but their variability beyond volumetrics is poorly characterized. To further our understanding of complex MS pathology, we aim to build a statistical model of brain images that can automatically discover spatial patterns of variability in brain morphology and lesion distribution. We propose building such a model using a deep belief network (DBN), a layered network whose parameters can be learned from training images. In contrast to other manifold learning algorithms, the DBN approach does not require a prebuilt proximity graph, which is particularly advantageous for modeling lesions, because their sparse and random nature makes defining a suitable distance measure between lesion images challenging. Our model consists of a morphology DBN, a lesion DBN, and a joint DBN that models concurring morphological and lesion patterns. Our results show that this model can automatically discover the classic patterns of MS pathology, as well as more subtle ones, and that the parameters computed have strong relationships to MS clinical scores.	[Brosch, Tom; Yoo, Youngjin] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada	Brosch, T (reprint author), Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada.						Aljabar P, 2011, IEEE T MED IMAGING, V30, P2072, DOI 10.1109/TMI.2011.2162529; Andersson J.L.R., 2007, TR07JA2 FMRIB CTR; Cayton L., 2005, ALGORITHMS MANIFOLD, P1; Ceccarelli A, 2012, AM J NEURORADIOL, V33, P1579, DOI 10.3174/ajnr.A3083; Fischer JS, 1999, MULT SCLER, V5, P244, DOI 10.1191/135245899678846168; Fonov V, 2011, NEUROIMAGE, V54, P313, DOI 10.1016/j.neuroimage.2010.07.033; Geoffrey Hinton, 2010, 2010003 UTML TR U TO; Gerber S, 2010, MED IMAGE ANAL, V14, P643, DOI 10.1016/j.media.2010.05.008; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Ngiam J., 2011, 28 INT C MACH LEARN, P689; Smith SM, 2002, NEUROIMAGE, V17, P479, DOI 10.1006/nimg.2002.1040; Wolz R, 2012, MED IMAGE ANAL, V16, P819, DOI 10.1016/j.media.2011.12.003; Wolz R, 2010, LECT NOTES COMPUT SC, V6357, P116, DOI 10.1007/978-3-642-15948-0_15	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-10470-6; 978-3-319-10469-0	LECT NOTES COMPUT SC			2014	8674						462	469				8	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	BB8WS	WOS:000347686400058		
J	Chen, DP; Mak, B; Leung, CC; Sivadas, S			IEEE	Chen, Dongpeng; Mak, Brian; Leung, Cheung-Chi; Sivadas, Sunil			JOINT ACOUSTIC MODELING OF TRIPHONES AND TRIGRAPHEMES BY MULTI-TASK LEARNING DEEP NEURAL NETWORKS FOR LOW-RESOURCE SPEECH RECOGNITION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		triphone modeling; trigrapheme modeling; multitask learning; deep neural networks	LANGUAGES	It is well-known in machine learning that multitask learning (MTL) can help improve the generalization performance of singly learning tasks if the tasks being trained in parallel are related, especially when the amount of training data is relatively small. In this paper, we investigate the estimation of triphone acoustic models in parallel with the estimation of trigrapheme acoustic models under the MTL framework using deep neural network (DNN). As triphone modeling and trigrapheme modeling are highly related learning tasks, a better shared internal representation (the hidden layers) can be learned to improve their generalization performance. Experimental evaluation on three low-resource South African languages shows that triphone DNNs trained by the MTL approach perform significantly better than triphone DNNs that are trained by the single-task learning (STL) approach by similar to 3-13%. The MTL-DNN triphone models also outperform the ROVER result that combines a triphone STL-DNN and a trigrapheme STL-DNN.	[Chen, Dongpeng; Mak, Brian] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Chen, DP (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.	dpchen@cse.ust.hk; mak@cse.ust.hk; ccleung@i2r.a-star.edu.sg; sivadass@i2r.a-star.edu.sg					Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Ben-David S, 2003, LECT NOTES ARTIF INT, V2777, P567, DOI 10.1007/978-3-540-45167-9_41; Caruana R., 1997, THESIS CARNEGIE MELL, P2; Charoenpornsawat P., 2006, P HUM LANG TECHN C N, P17, DOI 10.3115/1614049.1614054; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Davel M., 2009, DICTIONARYMAKER 2 16; Fiscus J. G., 1997, ASRU, P347; Ghoshal A, 2013, INT CONF ACOUST SPEE, P7319, DOI 10.1109/ICASSP.2013.6639084; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUANG J, 2013, P ICASSP, P7304; Huang Y., 2013, P IEEE INT C IM PROC, P2897; KANTHAK S, 2002, ACOUST SPEECH SIG PR, P845; Ko T, 2014, SPEECH COMMUN, V56, P132, DOI 10.1016/j.specom.2013.01.010; Kohler J., 1996, P INT C SPOK LANG PR, P1029; Le VB, 2009, IEEE T AUDIO SPEECH, V17, P1471, DOI 10.1109/TASL.2009.2021723; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Ogbureke KU, 2010, INT CONF ACOUST SPEE, P5266, DOI 10.1109/ICASSP.2010.5494978; Parveen S., 2003, P EUROSPEECH, P1813; Seltzer ML, 2013, INT CONF ACOUST SPEE, P6965, DOI 10.1109/ICASSP.2013.6639012; Stolcke A., 2002, ICSLP, P901; Stuker S., 2009, THESIS U KARLSRUHE G; Thrun S., 1997, LEARNING LEARN; Tur G, 2006, INT CONF ACOUST SPEE, P585	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655305125		
S	Chen, FQ; Wu, Y; Zhao, GD; Zhang, JM; Zhu, M; Bai, J		Huang, DS; Bevilacqua, V; Premaratne, P		Chen, Fu-qiang; Wu, Yan; Zhao, Guo-dong; Zhang, Jun-ming; Zhu, Ming; Bai, Jing			Contractive De-noising Auto-Encoder	INTELLIGENT COMPUTING THEORY	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Intelligent Computing (ICIC)	AUG 03-06, 2014	Taiyuan, PEOPLES R CHINA	IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Sci Fdn China, Tongji Univ, N Univ China, Taiyuan Normal Univ, Taiyuan Univ Sci & Technol		De-noising Auto-encoder; Contractive Auto-encoder; SVM	SUPPORT VECTOR MACHINES; REPRESENTATIONS	De-noising auto-encoder (DAE) is an improved auto-encoder which is robust to the input by corrupting the original data first and then reconstructing the input by minimizing the error function. And contractive auto-encoder (CAE) is another kind of improved auto-encoder learning robust feature by introducing Frobenius norm of the Jacobean matrix of the learned feature with respect to the input. In this paper, we combine DAE and CAE, and propose contractive de-noising auto-encoder (CDAE), which is robust to both the original input and the learned feature. We stack CDAE to extract more abstract features and apply SVM for classification. The experiment on benchmark dataset MNIST shows that CDAE performed better than CAE and DAE	[Chen, Fu-qiang; Wu, Yan; Zhao, Guo-dong; Zhang, Jun-ming; Zhu, Ming; Bai, Jing] Tongji Univ, Coll Elect & Informat Engn, Shanghai 200092, Peoples R China	Wu, Y (reprint author), Tongji Univ, Coll Elect & Informat Engn, Shanghai 200092, Peoples R China.	yanwu@tongji.edu.cn					BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Glorot X., 2010, AI STAT, V9, P249; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ngiam J., 2011, ICML, P265; Rifai S., 2011, ICML, P833; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, INT C MACH LEARN, P1096	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-09333-8; 978-3-319-09332-1	LECT NOTES COMPUT SC			2014	8588						776	781				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BB7GO	WOS:000345518700084		
J	Chen, IF; Siniscalchi, SM; Lee, CH			IEEE	Chen, I-Fan; Siniscalchi, Sabato Marco; Lee, Chin-Hui			ATTRIBUTE BASED LATTICE RESCORING IN SPONTANEOUS SPEECH RECOGNITION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Lattice Rescoring; Artificial Neural Networks; Phonetic Features; Automatic Speech Recognition	VERIFICATION; MODELS	In this paper we extend attribute-based lattice rescoring to spontaneous speech recognition. This technique is based on two key features: (i) an attribute-based frontend, which consists of a bank of speech attribute detectors followed up by an evidence merger that generates confidence scores (e. g., sub-word posterior probabilities), and (ii) a rescoring module that integrates information generated by the frontend into an existing ASR engine through lattice rescoring. The speech attributes used in this work are phonetic features, such as frication and palatalization. Experimental results on the Switchboard part of the NIST 2000 Hub5 data set demonstrate that the proposed approach outperforms LVCSR systems based on Gaussian mixture model/hidden Markov model (GMM/HMM) that does not use attribute related information. Furthermore, a small yet promising improvement is also observed when rescoring word-lattices generated by a state-of-the-art ASR system using deep neural networks. Different frontend configuration are investigated and tested.	[Chen, I-Fan; Siniscalchi, Sabato Marco; Lee, Chin-Hui] Georgia Inst Technol, Sch ECE, Atlanta, GA 30332 USA	Chen, IF (reprint author), Georgia Inst Technol, Sch ECE, Atlanta, GA 30332 USA.						Chien JT, 2010, SPEECH COMMUN, V52, P223, DOI 10.1016/j.specom.2009.10.003; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Deng L., 1999, NATO ASI; Duda R.O., 1973, PATTERN CLASSIFICATI; Gauvain JL, 2000, P IEEE, V88, P1181, DOI 10.1109/5.880079; Ghitza O, 1994, IEEE T SPEECH AUDI P, V2, P115, DOI 10.1109/89.260357; Godfrey J., 1992, P ICASSP, P517, DOI 10.1109/icassp.1992.225858; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kawahara T, 1998, IEEE T SPEECH AUDI P, V6, P558, DOI 10.1109/89.725322; Lee CH, 2013, P IEEE, V101, P1089, DOI 10.1109/JPROC.2013.2238591; Lee CH, 2000, P IEEE, V88, P1241; Li Y., 2002, P ICSLP, P1471; Ney H, 2000, P IEEE, V88, P1224, DOI 10.1109/5.880081; Povey D., 2011, ASRU BIG ISL HAW US; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Seide F., 2011, P INTERSPEECH, P437; SENEFF S, 1988, J PHONETICS, V16, P55; Siniscalchi S. M., 2013, SIGNAL PROCESSING LE, V20, P201; SINISCALCHI SM, 2007, P ASRU KYOT JAP, P566; Siniscalchi SM, 2009, SPEECH COMMUN, V51, P1139, DOI 10.1016/j.specom.2009.05.004; Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008; Tang M., 2003, P EUR GEN SWITZ, P2585; Vesely K., 2013, P INTERSPEECH, P2345; Yan Z.-J., 2013, P INT, P104; Young S., 2005, HTK BOOK HTK VERSION	28	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655303073		
S	Chen, XH; Zhang, Y; Xing, CX; Liu, X; Chen, HC		Zheng, X; Zeng, D; Chen, H; Zhang, Y; Xing, C; Neill, DB		Chen, Xinhuan; Zhang, Yong; Xing, Chunxiao; Liu, Xiao; Chen, Hsinchun			Diabetes-Related Topic Detection in Chinese Health Websites Using Deep Learning	SMART HEALTH, ICSH 2014	Lecture Notes in Computer Science		English	Proceedings Paper	International Conference for Smart Health (ICSH)	JUL 10-11, 2014	Beijing, PEOPLES R CHINA	Tsinghua Univ, Chinese Acad Sci, Natl Nat Sci Fdn China, Univ Arizona, Inst Operat Res & Management Sci, ACM Beijing Chapter, China Assoc Informat Syst		classification; topic detection; diabetes; Chinese; deep learning	ONLINE SOCIAL NETWORKS; CANCER	With 98.4 million people diagnosed with diabetes in China, most of the Chinese health websites provide diabetes related news and articles in diabetes subsection for patients. However, most of the articles are uncategorized and without a clear topic or theme, resulting in time consuming information seeking experience. To address this issue, we propose an advanced deep learning approach to detect topics for diabetes related articles from health websites. Our research framework for topic detection on diabetes related articles in Chinese is the first one to incorporate deep learning in topic detection in Chinese. It can identify topics of diabetes articles with high performance and potentially assist health information seeking. To evaluate our framework, experiment is conducted on a test bed of 12,000 articles. The results showed the framework achieved an accuracy of 70% in detecting topics and significantly outperformed the SVM based approach.	[Chen, Xinhuan; Zhang, Yong; Xing, Chunxiao] Tsinghua Univ, Res Inst Informat Technol, Tsinghua Natl Lab Informat Sci & Technol, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	Chen, XH (reprint author), Tsinghua Univ, Res Inst Informat Technol, Tsinghua Natl Lab Informat Sci & Technol, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	xh-chen13@mails.tsinghua.edu.cn; zhangyong05@tsinghua.edu.cn; xingcx@tsinghua.edu.cn; xiaoliu@email.arizona.edu; hchen@eller.arizona.edu					Basch EM, 2004, CANCER, V100, P2476, DOI 10.1002/cncr.20261; Brody Samuel, 2010, AMIA Annu Symp Proc, V2010, P202; Gouws S., 2012, P 2012 C N AM CHAPT, P48; Greene JA, 2011, J GEN INTERN MED, V26, P287, DOI 10.1007/s11606-010-1526-3; Hinton G, 2010, MOMENTUM, V9, P926; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kandula Sasikiran, 2011, AMIA Annu Symp Proc, V2011, P674; Klemm P, 1998, Oncol Nurs Forum, V25, P673; Li N, 2010, DECIS SUPPORT SYST, V48, P354, DOI 10.1016/j.dss.2009.09.003; Lin YJ, 2007, J AM MED INFORM ASSN, V14, P651, DOI 10.1197/jamia.M2215; Lu YJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056221; Monnier J, 2002, CANCER PRACT, V10, P305, DOI 10.1046/j.1523-5394.2002.106005.x; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Shrank WH, 2011, ARCH INTERN MED, V171, P1589, DOI 10.1001/archinternmed.2011.407; Socher R., 2012, TUTORIAL ABSTRACTS A, P5; Tamilselvan P, 2013, RELIAB ENG SYST SAFE, V115, P124, DOI 10.1016/j.ress.2013.02.022; Wang B., 2011, TALIP, V10, P21; Weitzman ER, 2011, J AM MED INFORM ASSN, V18, P292, DOI [10.1136/jamia.2010.009712, 10.1136/amiajnl-2010.009712]	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-08416-9; 978-3-319-08415-2	LECT NOTES COMPUT SC			2014	8549						13	24				12	Computer Science, Information Systems; Computer Science, Theory & Methods; Medical Informatics	Computer Science; Medical Informatics	BB9JD	WOS:000348361400002		
J	Cheng, GC; Hou, YX; Zhao, XZ; Yu, Q			Destech Publicat Inc	Cheng, Guo-Chen; Hou, Yue-Xian; Zhao, Xiao-Zhao; Yu, Qian			Local and Non-Local Regularization for Semi-supervised Deep Learning	INTERNATIONAL CONFERENCE ON CONTROL ENGINEERING AND AUTOMATION (ICCEA 2014)			English	Proceedings Paper	International Conference on Control Engineering and Automation (ICCEA)	NOV 29-30, 2014	Chongqing, PEOPLES R CHINA			Deep Learning; Semi-Supervised; Topological Structure		This paper studies a semi-supervised discriminant regularization for training deep neural networks by embedding a topological regularizer to the loss function. The method integrates the local and non-local topological regularizer for both labeled and unlabeled data to extract abstract features that are more suitable for classification purpose. For the labeled data, we make use of the label to define the pairwise proximity matrix, then the topological regularizer can be obtained by minimizing intraclass (local) compactness and maximizing interclass (non-local) separability. For the unlabeled data, we use the average distance from one sample to others as the threshold to select its neighbors apart from the non-local samples, then the topological regularizer for unlabeled samples is to simultaneously maximize the non-local scatter and minimize the local scatter. The proposed method is investigated on several publicly available image datasets. The experimental results demonstrate that the method is competitive in feature extraction and image recognition performance.	[Cheng, Guo-Chen; Hou, Yue-Xian; Zhao, Xiao-Zhao] Tianjin Univ, Sch Comp Sci & Tec, Tianjin, Nankai, Peoples R China; [Yu, Qian] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China	Hou, YX (reprint author), Tianjin Univ, Sch Comp Sci & Tec, Tianjin, Nankai, Peoples R China.	chengguochen659@126.com; yxhou@tju.edu.cn; 0.25eye@gmail.com; yqcloud@gmail.com					[Anonymous], 2013, IMAGE GRAPHICS, P499; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Chapelle O, 2006, SEMISUPERVISED LEARN, V2; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Liao Y., 2013, ARXIV13120786; Salakhutdinov R, 2007, INT C ART INT STAT, V2, P412; Wei J., 2013, SOFT COMPUT, P1; Weston Jason, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, DOI 10.1007/978-3-642-35289-8_34; Wong W. K., 2011, NEURAL NETWORKS IEEE, V22, P1668; Yang J., 2007, PATTERN ANAL MACHINE, V29, P650	11	0	0	DESTECH PUBLICATIONS, INC	LANCASTER	439 DUKE STREET, LANCASTER, PA 17602-4967 USA			978-1-60595-210-9				2014							272	278				7	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BC3MO	WOS:000351733900041		
J	Chetty, G; White, M; Singh, M; Mishra, A			IEEE	Chetty, Girija; White, Matthew; Singh, Monica; Mishra, Anurag			Multimodal Activity Recognition Based on Automatic Feature Discovery	2014 INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM)			English	Proceedings Paper	8th International Conference on Computing for Sustainable Global Development (INDIACom)	MAR 05-07, 2014	New Delhi, INDIA	IEEE Delhi Sect, GGSIP Univ, Govt India, Minist Sci & Technol, Dept Sci & Technol, Council Sci & Ind Res, All India Council Tech Educ, Inst Elect & Telecommunicat Engineers, Delhi Ctr, Jagdishprasad Jhabarmal Tibrewala Univ, Rajashthan & Shridhar Univ, IEEE Delhi Sect, Comp Soc & Computat Intelligence Soc, ISTE, Delhi Section & CSI Reg I Bharati Vidyapeeth CSI Students Branch		Multimodal; PCA; LDA; RBM; activity recognition; feature learning	BIOMETRICS; IMAGES; FUSION	In this article, we propose a novel multimodal data analytics scheme for human activity recognition. Traditional data analysis schemes for activity recognition using heterogeneous sensor network setups for e-Health application scenarios are usually a heuristic process, involving underlying domain knowledge. Relying on such explicit knowledge is problematic when aiming to created automatic, unsupervised monitoring and tracking of different activities, and detection of abnormal events. Experiments on a publicly available OPPORTUNITY activity recognition database from UCI machine learning repository demonstrates the potential of our approach to address next generation unsupervised automatic classification and detection approaches for remote activity recognition for novel, eHealth application scenarios, such as monitoring and tracking of elderly, disabled and those with special needs.	[Chetty, Girija] Univ Canberra, Canberra, ACT 2601, Australia; [White, Matthew; Singh, Monica] Infin Imaging, Melbourne, Vic, Australia; [Mishra, Anurag] Univ Delhi, Delhi 110007, India	Chetty, G (reprint author), Univ Canberra, Canberra, ACT 2601, Australia.	girija.chetty@canberra.edu.au; amishra@ddu.du.ac.in					Berretti S., 2010, IEEE T PATTERN ANAL, V32; Bringer J., 2011, BIOMETRIC THEORY APP, P123; Len Bui, 2010, Proceedings of the 2010 Fourth International Conference on Network and System Security (NSS 2010), DOI 10.1109/NSS.2010.19; Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160; Chetty G, 2007, LECT NOTES COMPUT SC, V4815, P469; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Hossain E, 2011, LECT NOTES COMPUT SC, V7064, P1, DOI 10.1007/978-3-642-24965-5_1; Huang L., 2011, PERSON RECOGNITION F; Jain A., 1999, 2 INT C AUD VID BAS, P182; Jain A.K., 2009, NEXT GENERATION BIOM; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Meraoumia A., 2011, IEEE COMMUNICATIONS; Mishra Anurag, 2012, NEUR NETW IJCNN, P1; Platt J. C., 1998, MSRTR9814; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; Sagha Hesam, 2011, IEEE INT C SYST MAN; Singh Lavneet, 2012, P INT C NEUR EV INT; Wang Y., 2003, INT C AVBPA, P805; Yampolskiy R. V., 2010, TAXONOMY BEHAV BIOME, P1; Yuan L., USING EAR BIOMETRICS	21	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-93-80544-12-0				2014							632	637				6	Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BC9LI	WOS:000356599900125		
S	Chu, JL; Krzyzak, A		Rutkowski, L; Korytkowski, M; Scherer, R; Tadeusiewicz, R; Zadeh, LA; Zurada, JM		Chu, Joseph Lin; Krzyzak, Adam			Application of Support Vector Machines, Convolutional Neural Networks and Deep Belief Networks to Recognition of Partially Occluded Objects	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING ICAISC 2014, PT I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	13th International Conference on Artificial Intelligence and Soft Computing (ICAISC)	JUN 01-05, 2014	Zakopane, POLAND	Polish Neural Network Soc, Univ Social Sci Lodz, Czestochowa Univ Technol, Inst Computat Intelligence, IEEE Computat Intelligence Soc, Poland Chapter			LEARNING ALGORITHM; NEOCOGNITRON	Artificial neural networks have been widely used for machine learning tasks such as object recognition. Recent developments have made use of biologically inspired architectures, such as the Convolutional Neural Network, and the Deep Belief Network. We test the hypothesis that generative models such as the Deep Belief Network should perform better on occluded object recognition tasks than purely discriminative models such as Convolutional Neural Networks. We find that the data does not support this hypothesis when the generative models are run in a partially discriminative manner. We also find that the use of Gaussian visible units in a Deep Belief Network trained on occluded image data allows it to also learn to classify non-occluded images.(1)	[Chu, Joseph Lin; Krzyzak, Adam] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada	Chu, JL (reprint author), Concordia Univ, Dept Comp Sci & Software Engn, 1455 Maisonneuve Blvd West, Montreal, PQ H3G 1M8, Canada.	jo_chu@encs.concordia.ca; krzyzak@cs.concordia.ca					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Collobert R., 2004, P 21 INT C MACH LEAR, P23; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Fukushima K, 2003, NEUROCOMPUTING, V51, P161, DOI 10.1016/S0925-2312(02)00614-8; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2010, MOMENTUM, V9, P599; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Huang F.J., 2006, P COMP VIS PATT REC, V1, P284; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 2004, PROC CVPR IEEE, P97; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Ranzato M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI 10.1109/CVPR.2011.5995710; Ranzato M.A., 2007, 2007 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2007.383157; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; TSANG PWM, 1993, IEEE T SYST MAN CYB, V23, P228, DOI 10.1109/21.214781; Winn J., 2006, 2006 IEEE COMP SOC C, V1, P37, DOI 10.1109/CVPR.2006.305; Wiskott L., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000479	24	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-07172-5; 978-3-319-07173-2	LECT NOTES ARTIF INT			2014	8467						34	46				13	Computer Science, Artificial Intelligence	Computer Science	BB1OW	WOS:000341246000004		
S	Cowley, B; Kneller, A; Thornton, J		Pham, DN; Park, SB		Cowley, Benjamin; Kneller, Adam; Thornton, John			Cortically-Inspired Overcomplete Feature Learning for Colour Images	PRICAI 2014: TRENDS IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	13th Pacific Rim International Conference on Artificial Intelligence (PRICAI)	DEC 01-05, 2014	Gold Coast, AUSTRALIA	Griffith Univ, NICTA Ltd, AF Off Sci Res, Asian Off Aerosp Res & Dev, Commonwealth Sci & Ind Corp, Gold Coast Convent Bur, MIMOS Berhad, Queensland Univ Technol, Univ Queensland		Hierarchical Temporal Memory; Biologically-Inspired AI; Image Classification; Machine Learning	NEOCORTEX; RECOGNITION	The Hierarchical Temporal Memory (HTM) framework is a deep learning system inspired by the functioning of the human neocortex. In this paper we investigate the feasibility of this framework by evaluating the performance of one component, the spatial pooler. Using a recently developed implementation, the augmented spatial pooler (ASP), as a single layer feature detector, we test its performance using a standard image classification pipeline. The main contributions of the paper are the implementation and evaluation of modifications to ASP that enable it to form overcomplete representations of the input and to form connections with multiple data channels. Our results show that these modifications significantly improve the utility of ASP, making its performance competitive with more traditional feature detectors such as sparse restricted Boltzmann machines and sparse auto-encoders.	[Cowley, Benjamin; Kneller, Adam; Thornton, John] Griffith Univ, Sch ICT, Inst Integrated & Intelligent Syst, Nathan, Qld 4111, Australia	Cowley, B (reprint author), Griffith Univ, Sch ICT, Inst Integrated & Intelligent Syst, Nathan, Qld 4111, Australia.	benjamin.cowley@griffithuni.edu.au; adam.kneller@griffithuni.edu.au; j.thornton@griffith.edu.au					BARLOW HB, 1981, PROC R SOC SER B-BIO, V212, P1, DOI 10.1098/rspb.1981.0022; Clark A, 2013, BEHAV BRAIN SCI, V36, P233, DOI [10.1017/S0140525X12000477, 10.1017/S0140525X12002440]; Coates A., 2011, J MACHINE LEARNING R, V15, P215; Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90; Fino E, 2011, NEURON, V69, P1188, DOI 10.1016/j.neuron.2011.02.025; Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787; Hawkins J., 2011, HIERARCHICAL TEMPORA; Hawkins J., 2004, INTELLIGENCE; Hawkins J., 2006, HIERARCHICAL TEMPORA; Hebb DO, 1949, ORG BEHAV NEUROPSYCH; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holmgren C, 2003, J PHYSIOL-LONDON, V551, P139, DOI 10.1113/jphysiol.2003.044784; Isaacson JS, 2011, NEURON, V72, P231, DOI 10.1016/j.neuron.2011.09.027; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Main L., 2013, LNCS, V8272, P396; Malkin RG, 2005, INT CONF ACOUST SPEE, P509; Markram H, 2004, NAT REV NEUROSCI, V5, P793, DOI 10.1038/nrn1519; Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701; Olshausen B., 2003, VISUAL NEUROSCIENCES, V2, P1603; Teh YW, 2001, ADV NEUR IN, V13, P908; Thomson Alex M, 2007, Front Neurosci, V1, P19, DOI 10.3389/neuro.01.1.1.002.2007; Thornton J, 2013, INT J MACH LEARN CYB, V4, P207, DOI 10.1007/s13042-012-0087-7; Thornton J., 2012, LNCS, V7691, P707; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096	24	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-13560-1; 978-3-319-13559-5	LECT NOTES ARTIF INT			2014	8862						720	732				13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BC7DM	WOS:000354778700057		
S	Cui, Z; Chang, H; Shan, SG; Zhong, BN; Chen, XL		Fleet, D; Pajdla, T; Schiele, B; Tuytelaars, T		Cui, Zhen; Chang, Hong; Shan, Shiguang; Zhong, Bineng; Chen, Xilin			Deep Network Cascade for Image Super-resolution	COMPUTER VISION - ECCV 2014, PT V	Lecture Notes in Computer Science		English	Proceedings Paper	13th European Conference on Computer Vision (ECCV)	SEP 06-12, 2014	Zurich, SWITZERLAND			Super-resolution; Auto-encoder; Deep learning	LIMITS; RECONSTRUCTION; ALGORITHMS; RESOLUTION; SPARSE	In this paper, we propose a new model called deep network cascade (DNC) to gradually upscale low-resolution images layer by layer, each layer with a small scale factor. DNC is a cascade of multiple stacked collaborative local auto-encoders. In each layer of the cascade, non-local self-similarity search is first performed to enhance high-frequency texture details of the partitioned patches in the input image. The enhanced image patches are then input into a collaborative local auto-encoder (CLA) to suppress the noises as well as collaborate the compatibility of the overlapping patches. By closing the loop on non-local self-similarity search and CLA in a cascade layer, we can refine the super-resolution result, which is further fed into next layer until the required image scale. Experiments on image super-resolution demonstrate that the proposed DNC can gradually upscale a low-resolution image with the increase of network layers and achieve more promising results in visual quality as well as quantitative performance.	[Cui, Zhen; Chang, Hong; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China	Cui, Z (reprint author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.	zhen.cui@vipl.ict.ac.cn; hong.chang@vipl.ict.ac.cn; sgshan@ict.ac.cn; bnzhong@hqu.edu.cn; xlchen@ict.ac.cn					Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Buades A., 2005, IEEE C COMP VIS PATT; Chang H, 2004, PROC CVPR IEEE, P275; Dong WS, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1259; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669; Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25; Le Q.V., 2011, INT C MACH LEARN ICM; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Lin ZC, 2008, INT J COMPUT VISION, V80, P406, DOI 10.1007/s11263-008-0148-2; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83; Lu XQ, 2012, PROC CVPR IEEE, P1648; Ngiam Jiquan, 2011, ADV NEURAL INFORM PR, V24, P1125; Nguyen K, 2012, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2012.6247984; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21; Ranzato M., 2007, ADV NEURAL INFORM PR, V20, P1185; TIPPING M E, 2003, ADV NEURAL INFORMATI, P1279; Vincent P., 2008, INT C MACH LEARN, P1096; Wang W., 2014, ARXIV14022031; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xie J., 2012, ADV NEURAL INFORM PR, V25, P350; Yang J., 2013, IEEE C COMP VIS PATT; Yang Jack Y., 2008, International Journal of Functional Informatics and Personalised Medicine, V1, P1, DOI 10.1504/IJFIPM.2008.018289; Zhang KB, 2012, PROC CVPR IEEE, P1114; Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407; Zontak M., 2011, IEEE C COMP VIS PATT	36	0	1	SPRINGER INT PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743		978-3-319-10602-1; 978-3-319-10601-4	LECT NOTES COMPUT SC			2014	8693						49	64				16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BB7GY	WOS:000345528200004		
J	Deng, W; Qian, YM; Fan, YC; Fu, TF; Yu, K			IEEE	Deng, Wei; Qian, Yanmin; Fan, Yuchen; Fu, Tianfan; Yu, Kai			STOCHASTIC DATA SWEEPING FOR FAST DNN TRAINING	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Deep neural network; Speech recognition; Stochastic Data Sweeping; Asynchronous SGD; GPU		Context-dependent deep neural network (CD-DNN) has been successfully used in large vocabulary continuous speech recognition (LVCSR). However the immense computational cost of the mini-batch based back-propagation (BP) training has become a major block to utilize massive speech data for DNN training. Previous works on BP training acceleration mainly focus on parallelization with multiple GPUs. In this paper, a novel stochastic data sweeping (SDS) framework is proposed from a different perspective to speed up DNN training with a single GPU. Part of the training data is randomly selected from the whole set and the quantity is gradually reduced at each training epoch. SDS utilizes less data in the entire process and consequently save tremendous training time. Since SDS works at data level, it is complementary to parallel training strategies and can be integrated to form a much faster training framework. Experiments showed that, combining SDS with asynchronous stochastic gradient descent (ASGD) can achieve almost 3.0 times speed-up on 2 GPUs at no loss of recognition accuracy.	[Deng, Wei; Qian, Yanmin; Fan, Yuchen; Fu, Tianfan; Yu, Kai] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, MOE Microsoft Key Lab Intelligent Comp & Intellig, Inst Intelligent Human Machine Interact, Shanghai 200030, Peoples R China	Deng, W (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, MOE Microsoft Key Lab Intelligent Comp & Intellig, Inst Intelligent Human Machine Interact, Shanghai 200030, Peoples R China.	cosmic_phantom@sjtu.edu.cn; yanminqian@sjtu.edu.cn; fyc0624@sjtu.edu.cn; erduo@sjtu.edu.cn; kai.yu@sjtu.edu.cn					Chen X., 2012, P INTERSPEECH; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dong Yu, 2012, P ICASSP; Godfrey John J., 1997, SWITCHBOARD 1 RELEAS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Rumelhart David E, 2002, COGNITIVE MODELING, V1, P213; Seide F., 2011, P INTERSPEECH, P437; ZHANG SS, 2013, P ICASSP, P6660; ZHOU P, 2013, P ICASSP, P6650	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655300049		
J	Du, J; Dai, LR; Huo, Q			IEEE	Du, Jun; Dai, Li-Rong; Huo, Qiang			SYNTHESIZED STEREO MAPPING VIA DEEP NEURAL NETWORKS FOR NOISY SPEECH RECOGNITION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		HMM-based speech synthesis; joint Gaussian mixture model; deep neural network; noisy speech recognition	ALGORITHMS	In our previous work, we extend the traditional stereo-based stochastic mapping by relaxing the constraint of stereo-data, which is not practical in real applications, via HMM-based speech synthesis to construct the "clean" channel data for noisy speech recognition. In this paper, we propose to use deep neural networks (DNNs) for stereo mapping compared with the joint Gaussian mixture model (GMM). The experimental results on Aurora3 databases show that our proposed DNN based synthesized stereo mapping can achieve consistently significant improvements of recognition performance over joint GMM based synthesized stereo mapping in the well-matched (WM) condition among four different European languages.	[Du, Jun; Dai, Li-Rong] Univ Sci & Technol China, Hefei 230026, Peoples R China	Du, J (reprint author), Univ Sci & Technol China, Hefei 230026, Peoples R China.	jundu@ustc.edu.cn; lrdai@ustc.edu.cn; qianghuo@microsoft.com					Acero A., 1993, ACOUSTIC ENV ROBUSTN; Afify M, 2007, INT CONF ACOUST SPEE, P377; Afify M, 2009, IEEE T AUDIO SPEECH, V17, P1325, DOI 10.1109/TASL.2009.2018017; [Anonymous], 2001, AU37801 AALB U; [Anonymous], 1999, AU21799 NOK; [Anonymous], 2001, AU27300 TEX I; [Anonymous], 2000, AU27100 UPC; Buera L., 2004, P ICASSP, P1013; Cerisara C, 2006, INT CONF ACOUST SPEE, P521; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L, 2005, IEEE SIGNAL PROC LET, V12, P477, DOI 10.1109/LSP.2005.847861; Droppo J., 2005, P INTERSPEECH, P989; Droppo J, 2001, P EUR, P217; DU J, 2012, P ISCSLP, P122; Du J., 2012, P INTERSPEECH; Du J, 2010, INT CONF ACOUST SPEE, P4570, DOI 10.1109/ICASSP.2010.5495569; GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G, 2010, 2010003 UTML TR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HUO Q, 2006, P INTERSPEECH ICSLP, P1129; Maas A., 2012, P INTERSPEECH; Moreno PJ, 1996, THESIS CARNEGIE MELL; POVEY D, 2005, P ICASSP 05, V1, P961, DOI 10.1109/ICASSP.2005.1415275; Seide F., 2011, P INTERSPEECH, P437; Seltzer M. L., 2013, P ICASSP, P7398; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Wu J, 2006, IEEE T AUDIO SPEECH, V14, P2147, DOI 10.1109/TASL.2006.872616; Xu Y., SIGNAL PROC IN PRESS; YAN ZJ, 2007, P ICASSP, P373; Young S., 2006, HTK BOOK HTK V3 4; Zen H., 2007, ISCA WORKSH SPEECH S, P294	33	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655301159		
J	Dwivedi, K; Biswaranjan, K; Sethi, A		Batra, U; Sujata; Arpita		Dwivedi, Kartik; Biswaranjan, Kumar; Sethi, Amit			Drowsy Driver Detection using Representation Learning	SOUVENIR OF THE 2014 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE (IACC)	IEEE International Advance Computing Conference		English	Proceedings Paper	4th IEEE International Advance Computing Conference (IACC)	FEB 21-22, 2014	Gurgaon, INDIA	IEEE, ITM Univ, Dept Comp Sci Engn & Informat Technol, IEEE Comp Soc, IEEE Student Branch	ITM Univ	Driver Drowsiness; Artificial Intelligence; Feature learning; Deep learning; Convolutional Neural Networks	ALGORITHM	The advancement of computing technology over the years has provided assistance to drivers mainly in the form of intelligent vehicle systems. Driver fatigue is a significant factor in a large number of vehicle accidents. Thus, driver drowsiness detection has been considered a major potential area so as to prevent a huge number of sleep induced road accidents. This paper proposes a vision based intelligent algorithm to detect driver drowsiness. Previous approaches are generally based on blink rate, eye closure, yawning, eye brow shape and other hand engineered facial features. The proposed algorithm makes use of features learnt using convolutional neural network so as to explicitly capture various latent facial features and the complex non-linear feature interactions. A softmax layer is used to classify the driver as drowsy or non- drowsy. This system is hence used for warning the driver of drowsiness or in attention to prevent traffic accidents. We present both qualitative and quantitative results to substantiate the claims made in the paper.	[Dwivedi, Kartik; Biswaranjan, Kumar; Sethi, Amit] Indian Inst Technol, Dept Elect & Elect Engn, Gauhati, India	Dwivedi, K (reprint author), Indian Inst Technol, Dept Elect & Elect Engn, Gauhati, India.	k.dwivedi@iitg.ernet.in; k.biswaranjan@iitg.ernet.in; amitsethi@iitg.ernet.in	Sethi, Amit/	Sethi, Amit/0000-0002-8634-1804			ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; [Anonymous], 1999, C OC MEAS DRIV ALT W; Chen H, 2003, IEE P-VIS IMAGE SIGN, V150, P153, DOI 10.1049/ip-vis:20030362; Cobb W.A., 1983, RECOMMENDATIONS PRAC; Eriksson M, 1997, IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P314, DOI 10.1109/ITSC.1997.660494; Hinton G. E., 1994, ADV NEURAL INFORMATI, V6, P3; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hong K., 2005, INT J IND ERGONOM, V35, P307; Horng W., 2004, P IEEE INT C NETW SE; Ji Q., 2004, IEEE T VEHICULAR TEC, V53; LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361; Mandic D. P., 2001, P INT C MACH LEARN; Perez Claudio A., 2001, IEEE INT C SYST MAN, V2, P1178; Rau P. S., 2005, P 19 INT TECHN C ENH; Saito H, 1994, P 1994 VEH NAV INF S, P21, DOI 10.1109/VNIS.1994.396872; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Singh M., 2012, INT J EMERGING TECHN, V2; Singh S., 1999, IEEE INT C INT TRANS, P316; Smith P, 2000, P 15 INT C PATT REC, V4; Takei Y., 2005, MAN CYBERNETICS, V2, P1765; United States Department of Transportation, SAV LIV ADV VEH SAF; Vural E., 2010, IEEE INT C PATT REC; Vural E., 2007, P HUM COMP INT, P6	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2164-8263		978-1-4799-2571-1	IEEE INT ADV COMPUT			2014							995	999				5	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0ZG	WOS:000349866100175		
J	Enachescu, C		Moldovan, L		Enachescu, Calin			Supervised learning using an active strategy	7TH INTERNATIONAL CONFERENCE INTERDISCIPLINARITY IN ENGINEERING (INTER-ENG 2013)	Procedia Technology		English	Proceedings Paper	7th International Conference on Interdisciplinarity in Engineering (INTER-ENG)	OCT 10-11, 2013	Tirgu Mures, ROMANIA	Petru Maior Univ Tirgu Mures		neural networks; learning; supervised learning; active learning; RBF neural networks	NEURAL NETWORKS	We consider an active supervised learning scenario in which the supervisor (trainer) can make decisions regarding the possibility to choose new examples for learning. In the classical forms of supervised learning, the training set is chosen according to some known or random given distribution. The supervisor is a passive agent in the sense that he is not able to interact with the training set in order to improve the performances of the learning process of the neural network. We will introduce in a formal manner the terms of "difficult learning" and "easy learning" related to the training data set. We will investigate some possibilities that allow the trainer to become active and we will analyse the performances of such supervised learning. An active supervised learning algorithm is presented and also we have performed some simulation in order to prove our theoretical results. (C) 2013 The Authors. Published by Elsevier Ltd.	Petru Maior Univ Tirgu Mures, Targu Mures 540088, Romania	Enachescu, C (reprint author), Petru Maior Univ Tirgu Mures, 1 N Iorga, Targu Mures 540088, Romania.	ecalin@upm.ro					Campbell C., 2000, P 17 INT C MACH LEAR; Chang E, 2003, ACM T INFORM SYSTEMS; Chang EY, 2003, IEEE INT C IM PROC I, P609; Cotter N E, 1990, IEEE Trans Neural Netw, V1, P290, DOI 10.1109/72.80265; Enachescu C, 2008, JNAIAM J NUMERICAL A, V3, P221; Enachescu C, 2008, ADV BIOINSPIRED COMP, P101; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; GIROSI F, 1990, BIOL CYBERN, V63, P169, DOI 10.1007/BF00195855; Gosselin P, 2004, IEEE ICIP; Haykin S., 1994, COMPREHENSIVE FDN; Hecht-Nielsen R, 1989, INT JOINT C NEURAL N, V1, P593; Hecht-Nielsen R., 1987, IEEE INT C NEUR NETW, V3, P11; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Irie B., 1988, IEEE INT C NEURAL NE, V1, P641; Jaakkola T, 2001, ADV NEURAL INFORM PR, V14; KREINOVICH VY, 1991, NEURAL NETWORKS, V4, P381, DOI 10.1016/0893-6080(91)90074-F; Lai WC, 2004, WORKSH COMP VIS MEET, P11; Lindenbaum M, 2004, MACH LEARN, V54, P125, DOI 10.1023/B:MACH.0000011805.60520.fe; Mohri M, 2012, FDN MACHINE LEARNING; Nguyen H. T., 2004, P 21 INT C MACH LEAR; Niyogi P, 1995, 1514 AI MIT; Pogio T, 1990, P IEEE, V78, P1481; Roy N., 2001, P 18 INT C MACH LEAR, P441; Tihonov N, 1977, SOLUTION ILL POSED P; Vapnik V., 2000, NATURE STAT LEARNING; White DA, 1989, NEURAL COMPUT, V1, P425; Yee P. V., 2001, REGULARIZED RADIAL B	28	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	2212-0173			PROC TECH			2014	12						220	228		10.1016/j.protcy.2013.12.478		9	Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary	Computer Science; Engineering	BA4DF	WOS:000335391100030		
S	Fan, XM; Zhang, SJ; Hapeshi, K; Yang, YS		Ren, L; Wang, H; Dai, Z		Fan, Xuemei; Zhang, Shujun; Hapeshi, Kevin; Yang, Yinsheng			Biological System Behaviours and Natural-inspired Methods and Their Applications to Supply Chain Management	ADVANCES IN BIONIC ENGINEERING	Applied Mechanics and Materials		English	Proceedings Paper	4th International Conference of Bionic Engineering (ICBE 2013)	AUG 13-16, 2013	Nanjing, PEOPLES R CHINA	Int Soc Bionic Engn, Nanjing Univ Aeronaut & Astronaut, Jilin Univ, Natl Nat Sci Fdn China, Minist Sci & Technol China, Res Inst Petr Explorat & Dev		learn from nature; biological system behaviours; supply chain management; ACO; Bees Algorithm; Genetic Algorithm; Firefly Algorithm	VEHICLE-ROUTING PROBLEM; FISH SCHOOLS; PERFORMANCE; ALGORITHMS; MODELS; OPTIMIZATION; BIOMIMETICS; INTEGRATION; SELECTION; ANT	People have learnt from biological system behaviours and structures to design and develop a number of different kinds of optimisation algorithms that have been widely used in both theoretical study and practical applications in engineering and business management. An efficient supply chain is very important for companies to survive in global competitive market. An effective SCM (supply chain management) is the key for implement an efficient supply chain. Though there have been considerable amount of study of SCM, there have been very limited publications of applying the findings from the biological system study into SCM. In this paper, through systematic literature review, various SCM issues and requirements are discussed and some typical biological system behaviours and natural-inspired algorithms are evaluated for the purpose of SCM. Then the principle and possibility are presented on how to learn the biological systems' behaviours and natural-inspired algorithms for SCM and a framework is proposed as a guide line for users to apply the knowledge learnt from the biological systems for SCM. In the framework, a number of the procedures have been presented for using XML to represent both SCM requirement and bioinspiration data. To demonstrate the proposed framework, a case study has been presented for users to find the bio-inspirations for some particular SCM problems in automotive industry.	[Fan, Xuemei] Jilin Univ, Coll Quartermaster Technol, Changchun 130023, Jilin, Peoples R China	Fan, XM (reprint author), Jilin Univ, Coll Quartermaster Technol, Changchun 130023, Jilin, Peoples R China.	meizi1971@163.com; szhang@glos.ac.uk; khapehi@glos.ac.uk; yys@jlu.edu.cn					Aardal K I, 2001, OPER RES, V1, P261; Amintoosi M, 2007, P 2007 INT C LIF SYS; [Anonymous], 2013, CSCMPS DEF SUPPL CHA; Ball P, 2001, NATURE, V409, P413, DOI 10.1038/35053198; Ballerini M, 2006, ROYAL SOC PHILOS T B, V361, P5; Ballerini M, 2008, P NATL ACAD SCI USA, V105, P1232, DOI 10.1073/pnas.0711437105; Ballou R. H., 2007, EUROPEAN BUSINESS RE, V19, P332, DOI 10.1108/09555340710760152; Bar-Cohen Y., 2006, BIOINSPIR BIOMIM, V1, P1; Barricelli N A, 1957, METHODS, V9, P143; Baucer A, 2000, CENTRAL EUROPEAN J O, V8, P125; Beamon B M, 1998, INT J PROD ECON, V55, P281; Beamon BM, 1999, INT J OPER PROD MAN, V19, P275, DOI 10.1108/01443579910249714; Billington C., 2004, J SUPPLY CHAIN MANAG, V40, P17, DOI DOI 10.1111/JSCM.2004.40.ISSUE-4; Bititci US, 1997, INT J OPER PROD MAN, V17, P522, DOI 10.1108/01443579710167230; Blanchard David, 2010, SUPPLY CHAIN MANAGEM, V2nd; Blazis DEJ, 2002, BIOL BULL, V202, P245; Bode NWF, 2010, P ROY SOC B-BIOL SCI, V277, P3065, DOI 10.1098/rspb.2010.0855; Cai Y., 2010, INTELLIGENT SYSTEMS, V1, P37; Cha Sung-Hyuk, 2009, J PATTERN RECOGNITIO, V4, P1; Chan FTS, 2003, SUPPLY CHAIN MANAG, V8, P209, DOI 10.1108/13598540310484618; Chen CT, 2006, INT J PROD ECON, V102, P289, DOI 10.1016/j.ijpe.2005.03.009; Christopher M., 1992, LOGISTICS SUPPLY CHA; Conradt L, 2012, INTERFACE FOCUS, V2, P226, DOI 10.1098/rsfs.2011.0090; Croom S.R., 2000, EUROPEAN J PURCHASIN, V6, P67, DOI DOI 10.1016/S0969-7012(99)00030-1; Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585892; Dorigo M., 1992, THESIS POLITECNICO M; Frisch K.V., 1976, BEES THEIR VISION CH; Fukushima K., 1980, BIOL CYBERN, V36, P93; Goldberg David E, 1989, GENETIC ALGORITHMS S; GOSS S, 1989, NATURWISSENSCHAFTEN, V76, P579, DOI 10.1007/BF00462870; Gueron S, 1996, J THEOR BIOL, V182, P85, DOI 10.1006/jtbi.1996.0144; Gunasekaran A, 2001, INT J OPER PROD MAN, V21, P71, DOI 10.1108/01443570110358468; Handfield RB, 2002, IND MARKET MANAG, V31, P367, DOI 10.1016/S0019-8501(01)00169-9; Hervani A.A., 2005, BENCHMARKING INT J, V12, P330, DOI DOI 10.1108/14635770510609015; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; IREDI S, 2001, 1 INT C EMO 2001 ZUR, V1993, P359; Jackson DE, 2006, CURR BIOL, V16, pR570, DOI 10.1016/j.cub.2006.07.015; Jacoby D., 2009, GUIDE SUPPLY CHAIN M; Kouvelis P, 2006, PROD OPER MANAG, V15, P449; Lee CW, 2007, SUPPLY CHAIN MANAG, V12, P444, DOI 10.1108/13598540710826371; Lee HL, 2000, MANAGE SCI, V46, P626, DOI 10.1287/mnsc.46.5.626.12047; Li SH, 2006, DECIS SUPPORT SYST, V42, P1641, DOI 10.1016/j.dss.2006.02.011; Lin R, 1998, P 3 ANN HAW INT C SY, P247; Liu Yun-zhong, 2004, Information and Control, V33; Lopez U, 2012, INTERFACE FOCUS, V2, P693, DOI 10.1098/rsfs.2012.0033; Martens D, 2007, IEEE T EVOLUT COMPUT, V11, P651, DOI 10.1109/TEVC.2006.890229; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Mechelena P, 2010, P ROYAL SOC PHILOS B, V277, P1093; Olague G, 2006, P 18 INT C PATT REC, V1, P1116; Oliver RK, 1982, SUPPLY CHAIN MANAGEM; Parrish JK, 2002, BIOL BULL, V202, P296, DOI 10.2307/1543482; Pham D.T., 2006, P 2 INT VIRT C INT P, P454; PITCHER TJ, 1979, MAR BIOL, V54, P383, DOI 10.1007/BF00395444; POTTS WK, 1984, NATURE, V309, P344, DOI 10.1038/309344a0; Rai A, 2006, MIS QUART, V30, P225; Ren LQ, 2009, SCI CHINA SER E, V52, P273, DOI 10.1007/s11431-009-0042-3; Richardson P, 2010, THESIS BATH U; Richardson P, 2007, COMP BIOCHEM PHYS A, V146, pS137, DOI 10.1016/j.cbpa.2007.01.267; Secomandi N, 2000, COMPUT OPER RES, V27, P1201, DOI 10.1016/S0305-0548(99)00146-X; Seeley T. D., 1996, WISDOM HIVE SOCIAL P; Seppala O, 2008, ANIM BEHAV, V75, P145, DOI 10.1016/j.anbehav.2007.04.022; SHAW E, 1978, AM SCI, V66, P166; Stefansson G., 2006, International Journal of Physical Distribution & Logistics Management, V36, DOI 10.1108/09600030610656413; Stevens G. C., 1989, International Journal of Physical Distribution & Materials Management, V19, DOI 10.1108/EUM0000000000329; Stutzle T, 2000, FUTURE GENER COMP SY, V16, P889; Ting CK, 2005, LECT NOTES ARTIF INT, V3630, P403; Toth P, 2002, DISCRETE APPL MATH, V123, P487, DOI 10.1016/S0166-218X(01)00351-1; Vincent J F V, 2003, PHIL T R SOC, V358, P1597; Vincent JFV, 2002, PHILOS T ROY SOC A, V360, P159, DOI 10.1098/rsta.2001.0923; Vincent JFV, 2006, CREATIVITY INNOV MAN, V14, P66, DOI DOI 10.1111/J.1476-8691.200500326.X; Vincent JFV, 2006, J R SOC INTERFACE, V3, P471, DOI 10.1098/rsif.2006.0127; Wan Xu, 2005, Computer Integrated Manufacturing Systems, V11; Ward AJW, 2008, P NATL ACAD SCI USA, V105, P6948, DOI 10.1073/pnas.0710344105; Williams BD, 2008, INT J LOGIST MANAG, V19, P212, DOI 10.1108/09574090810895960; Wong W. P., 2008, BENCHMARKING INT J, V15, P25, DOI 10.1108/14635770810854335; Yang Xin-She, 2008, NATURE INSPIRED META; Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169; Yu ZX, 2001, IND MANAGE DATA SYST, V101, P114, DOI 10.1108/02635570110386625; Zang HN, 2010, J BIONIC ENG, V7, pS232, DOI 10.1016/S1672-6529(09)60240-7; Zhao X, 2005, BUSINESS RES, V2, P60	81	0	0	TRANS TECH PUBLICATIONS LTD	STAFA-ZURICH	LAUBLSRUTISTR 24, CH-8717 STAFA-ZURICH, SWITZERLAND	1660-9336		978-3-03785-932-2	APPL MECH MATER			2014	461						942	958		10.4028/www.scientific.net/AMM.461.942		17	Engineering, Biomedical; Materials Science, Multidisciplinary; Materials Science, Biomaterials	Engineering; Materials Science	BA4RS	WOS:000336185100125		
J	Feng, X; Zhang, YD; Glass, J			IEEE	Feng, Xue; Zhang, Yaodong; Glass, James			SPEECH FEATURE DENOISING AND DEREVERBERATION VIA DEEP AUTOENCODERS FOR NOISY REVERBERANT SPEECH RECOGNITION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		robust speech recognition; feature denoising; denoising autoencoder; deep neural network		Denoising autoencoders (DAs) have shown success in generating robust features for images, but there has been limited work in applying DAs for speech. In this paper we present a deep denoising autoencoder (DDA) framework that can produce robust speech features for noisy reverberant speech recognition. The DDA is first pre-trained as restricted Boltzmann machines (RBMs) in an unsupervised fashion. Then it is unrolled to autoencoders, and fine-tuned by corresponding clean speech features to learn a nonlinear mapping from noisy to clean features. Acoustic models are re-trained using the reconstructed features from the DDA, and speech recognition is performed. The proposed approach is evaluated on the CHiME-WSJ0 corpus, and shows a 16-25% absolute improvement on the recognition accuracy under various SNRs.	[Feng, Xue; Zhang, Yaodong; Glass, James] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	Feng, X (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	xfeng@csail.mit.edu; ydzhang@csail.mit.edu; jrg@csail.mit.edu					Astudillo F. R., 2010, THESIS TU BERLIN; Bengio Y., 2009, FDN TRENDS MACHINE L, V2; Du J, 2011, IEEE T AUDIO SPEECH, V19, P2285, DOI 10.1109/TASL.2011.2129508; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ishii T., 2013, P INTERSPEECH; Koldovsky Z., 2011, P CHIME; Maganti H. K., 2010, P INTERSPEECH; Nikias CL, 1993, IEEE SIGNAL PROC MAG, V10, P10, DOI 10.1109/79.221324; Sainath T.N., 2012, P ICASSP; Vertanen K., 2006, BASELINE WSJ ACOUSTI; Vincent E., 2013, P ASRU; Vincent E., 2013, P ICASSP; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, P ICML; Vinyals O., 2011, P ICASSP; Weninger F., 2012, P ICASSP; WIGGINS RA, 1978, GEOEXPLORATION, V16, P21, DOI 10.1016/0016-7142(78)90005-4; Wilson K., 2008, P ICASSP; Young Steve, 2002, HTK BOOK VERSION 3 2	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655301158		
J	Fursin, G; Miceli, R; Lokhmotov, A; Gerndt, M; Baboulin, M; Malony, AD; Chamski, Z; Novillo, D; Del Vento, D				Fursin, Grigori; Miceli, Renato; Lokhmotov, Anton; Gerndt, Michael; Baboulin, Marc; Malony, Allen D.; Chamski, Zbigniew; Novillo, Diego; Del Vento, Davide			Collective mind: Towards practical and collaborative auto-tuning	SCIENTIFIC PROGRAMMING			English	Article						High performance computing; systematic auto-tuning; systematic benchmarking; big data driven optimization; modeling of computer behavior; performance prediction; collaborative knowledge management; public repository of knowledge; NoSQL repository; code and data sharing; specification sharing; collaborative experimentation; machine learning; data mining; multi-objective optimization; model driven optimization; agile development; plugin-based tuning; performance regression buildbot; open access publication model; reproducible research	COMPLEXITY REDUCTION; COMPILER HEURISTICS; SYSTEMS; OPTIMIZATION; ALGORITHMS; PROJECT	Empirical auto-tuning and machine learning techniques have been showing high potential to improve execution time, power consumption, code size, reliability and other important metrics of various applications for more than two decades. However, they are still far from widespread production use due to lack of native support for auto-tuning in an ever changing and complex software and hardware stack, large and multi-dimensional optimization spaces, excessively long exploration times, and lack of unified mechanisms for preserving and sharing of optimization knowledge and research material. We present a possible collaborative approach to solve above problems using Collective Mind knowledge management system. In contrast with previous cTuning framework, this modular infrastructure allows to preserve and share through the Internet the whole auto-tuning setups with all related artifacts and their software and hardware dependencies besides just performance data. It also allows to gradually structure, systematize and describe all available research material including tools, benchmarks, data sets, search strategies and machine learning models. Researchers can take advantage of shared components and data with extensible meta-description to quickly and collaboratively validate and improve existing auto-tuning and benchmarking techniques or prototype new ones. The community can now gradually learn and improve complex behavior of all existing computer systems while exposing behavior anomalies or model mispredictions to an interdisciplinary community in a reproducible way for further analysis. We present several practical, collaborative and model-driven auto-tuning scenarios. We also decided to release all material at c-mind.org/repo to set up an example for a collaborative and reproducible research as well as our new publication model in computer engineering where experimental results are continuously shared and validated by the community.	[Fursin, Grigori; Baboulin, Marc] Inria, Orsay, France; [Fursin, Grigori; Baboulin, Marc] Univ Paris 11, Orsay, France; [Miceli, Renato] Univ Rennes 1, Rennes, France; [Miceli, Renato] ICHEC, Dublin, Ireland; [Lokhmotov, Anton] ARM, Cambridge, England; [Gerndt, Michael] Tech Univ Munich, D-80290 Munich, Germany; [Malony, Allen D.] Univ Oregon, Eugene, OR 97403 USA; [Chamski, Zbigniew] Infrasoft IT Solut, Plock, Poland; [Novillo, Diego] Google Inc, Toronto, ON, Canada; [Del Vento, Davide] Natl Ctr Atmospher Res, Boulder, CO 80307 USA	Fursin, G (reprint author), Inria, Orsay, France.	grigori.fursin@inria.fr	freitas Junior, Jose Carlos/M-6834-2014				Aarts B., 1997, LECT NOTES COMPUTER, V1300, P1351; Agakov F., 2006, P INT S COD GEN OPT; [Anonymous], 2012, HIPEAC VISION HIGH P; Ansel J, 2009, ACM SIGPLAN NOTICES, V44, P38; Asanovic K., 2006, UCBEECS2006183; Augonnet C, 2011, CONCURR COMP-PRACT E, V23, P187, DOI 10.1002/cpe.1631; Baboulin M, 2012, INT PARALL DISTRIB P, P14, DOI 10.1109/IPDPS.2012.12; Baboulin M, 2012, PROCEDIA COMPUT SCI, V9, P17, DOI 10.1016/j.procs.2012.04.003; Bailey D.H., 2008, J PHYS C SERIES SCID, V125; Balaprakash P, 2011, PROCEDIA COMPUT SCI, V4, P2136, DOI 10.1016/j.procs.2011.04.234; Benedict S., 2010, TOOLS HIGH PERFORMAN, P1, DOI 10.1007/978-3-642-11261-4_1; Bishop CM, 2006, PATTERN RECOGNITION; Bondhugula U., 2008, ACM SIGPLAN C PROGR; Calotoiu A., 2013, SC, P45; Cavazos J., 2007, P INT S COD GEN OPT; Cerf VG, 2012, COMMUN ACM, V55, P5, DOI 10.1145/2347736.2347737; Chen Y., 2010, P ACM SIGPLAN C PROG; Cooper K.D., 1999, P C LANG COMP TOOLS, P1; Dongarra J, 2011, INT J HIGH PERFORM C, V25, P3, DOI 10.1177/1094342010391989; Dubach C., 2009, P IEEE ACM INT S MIC; EPPS TW, 1983, BIOMETRIKA, V70, P723, DOI 10.1093/biomet/70.3.723; Ferrucci D, 2010, AI MAG, V31, P59; Franke B., 2005, P C LANG COMP TOOLS; Fursin G., 2007, 1 WORKSH STAT MACH L; Fursin G, 2004, CONCURR COMP-PRACT E, V16, P271, DOI 10.1002/cpe.774; Fursin G., 2009, P GCC DEV SUMM JUN; Fursin G., 2010, ACM T ARCHIT CODE OP, V7; Fursin G, 2011, INT J PARALLEL PROG, V39, P296, DOI 10.1007/s10766-010-0161-2; Fursin G., 2007, P INT C HIGH PERF EM; Fursin G., 2004, THESIS U EDINBURGH U; Fursin G, 2005, LECT NOTES COMPUT SC, V3793, P29; Fursin G., 2014, P 1 WORKSH REPR RES; Fursin G., 2013, CORR; Fursin G.G., 2002, P LANG COMP PAR COMP, P305; Garrett J J, AJAX NEW APPROACH WE; Geimer M, 2010, CONCURR COMP-PRACT E, V22, P702, DOI 10.1002/cpe.1556; Hartono A., 2009, IEEE INT S PAR DISTR, P1; Heroux M.A., 2013, NEW METRIC RANKING H; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoste K., 2008, P INT S COD GEN OPT; Huang Y., 2010, 2 INT WORKSH GCC RES; Jimenez V., 2009, P INT C HIGH PERF EM; Jin YC, 2000, IEEE T FUZZY SYST, V8, P212, DOI 10.1109/91.842154; Kisuki T., 2000, Proceedings 2000 International Conference on Parallel Architectures and Compilation Techniques (Cat. No.PR00622), DOI 10.1109/PACT.2000.888348; Kulkarni P, 2003, ACM SIGPLAN NOTICES, V38, P12, DOI 10.1145/780731.780735; KUNG HT, 1975, J ACM, V22, P469, DOI 10.1145/321906.321910; Lattner C., 2004, P 2004 INT S COD GEN; Le Q. V., 2012, INT C MACH LEARN; Lu J., 2004, J INSTRUCTION LEVEL, V6; Luk C.-K., 2009, P 42 ANN IEEE ACM IN, P45, DOI 10.1145/1669112.1669121; Luo L., 2009, 3 WORKSH STAT MACH L; Luszczek P.R., 2006, P 2006 ACM IEEE C SU; Marin G., 2004, SIGMETRICS PERFORM E, V32, P2; Mars J, 2009, CGO 2009: INTERNATIONAL SYMPOSIUM ON CODE GENERATION AND OPTIMIZATION, PROCEEDINGS, P169, DOI 10.1109/CGO.2009.24; Matteo F., 1998, P IEEE INT C AC SPEE, V3, P1381; Miceli R., 2013, P 11 INT C APPL PAR, P328; Monsifrot A, 2002, LECT NOTES ARTIF INT, V2443, P41; Roubos H, 2001, IEEE T FUZZY SYST, V9, P516, DOI 10.1109/91.940965; Shen J., 2013, C COMP FRONT, P14; Shende SS, 2006, INT J HIGH PERFORM C, V20, P287, DOI 10.1177/1094342006064482; Shoham Y, 2009, MULTIAGENT SYSTEMS: ALGORITHMIC, GAME-THEORETIC, AND LOGICAL FOUNDATIONS, P1; Singer B., 2000, P C MACH LEARN; Stephenson M, 2003, ACM SIGPLAN NOTICES, V38, P77, DOI 10.1145/780822.781141; Stephenson M., 2005, P INT S COD GEN OPT; Tapus C., 2002, P 2002 ACM IEEE C SU, P1, DOI DOI 10.1109/SC.2002.10062; Tomov S, 2010, PARALLEL COMPUT, V36, P232, DOI 10.1016/j.parco.2009.12.005; Treibig J., 2010, CORR; Voss M.J., 2000, P INT C PAR PROC; Whaley R., 1998, P C HIGH PERF NETW C; Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785; Yi Q., 2007, P WORKSH PERF OPT HI; Zhao M., 2005, 3 ANN IEEE ACM INT C, P317; Zhelong Pan, 2006, P INT S COD GEN OPT, P319; Zuckerman S., 2011, P 1 INT WORKSH AD SE, P64	74	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1058-9244	1875-919X		SCI PROGRAMMING-NETH	Sci. Program.		2014	22	4					309	329		10.3233/SPR-140396		21	Computer Science, Software Engineering	Computer Science	AN5QT	WOS:000340647100006		
J	Ghahabi, O; Hernando, J			IEEE	Ghahabi, Omid; Hernando, Javier			DEEP BELIEF NETWORKS FOR I-VECTOR BASED SPEAKER RECOGNITION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Speaker Recognition; i-vector; Deep Belief Network; Neural Network	VERIFICATION	The use of Deep Belief Networks (DBNs) is proposed in this paper to model discriminatively target and impostor i-vectors in a speaker verification task. The authors propose to adapt the network parameters of each speaker from a background model, which will be referred to as Universal DBN (UDBN). It is also suggested to backpropagate class errors up to only one layer for few iterations before to train the network. Additionally, an impostor selection method is introduced which helps the DBN to outperform the cosine distance classifier. The evaluation is performed on the core test condition of the NIST SRE 2006 corpora, and it is shown that 10% and 8% relative improvements of EER and minDCF can be achieved, respectively.	[Ghahabi, Omid; Hernando, Javier] Univ Politecn Cataluna, Dept Signal Theory & Commun, TALP Res Ctr, Barcelona, Spain	Ghahabi, O (reprint author), Univ Politecn Cataluna, Dept Signal Theory & Commun, TALP Res Ctr, Barcelona, Spain.	omid.ghahabi@upc.edu; javier.hernando@upc.edu					[Anonymous], 2006, NIST YEAR 2006 SPEAK; Brummer N, 2010, P OD SPEAK LANG REC; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307; Hinton G., 2012, IEEE SIGNAL PROCESSI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., LECT NOTES COMPUTER, V7700, P599; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968; Kenny P, 2008, IEEE T AUDIO SPEECH, V16, P980, DOI 10.1109/TASL.2008.925147; Kenny P., 2010, SPEAK LANG REC WORKS; Larcher A., 2013, P INTERSPEECH, P2768; Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291; McLaren M, 2009, INT CONF ACOUST SPEE, P4041, DOI 10.1109/ICASSP.2009.4960515; Mohamed A., 2010, P INTERSPEECH; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nadeu C, 2001, SPEECH COMMUN, V34, P93, DOI 10.1016/S0167-6393(00)00048-0; Nair V., 2009, ADV NEURAL INFORM PR; Prince S. J. D., 2007, IEEE 11 INT C COMP V; Senoussaoui M., 2012, OD 2012 SPEAK LANG R; Stafylakis T., 2012, OD 2012 SPEAK LANG R; Vasilakakis V., 2013, BIOMETRIC TECHNOLOGI; Zhang XL, 2013, IEEE T AUDIO SPEECH, V21, P697, DOI 10.1109/TASL.2012.2229986	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655301146		
J	Ghifary, M; Kleijn, WB; Zhang, MJ			IEEE	Ghifary, Muhammad; Kleijn, W. Bastiaan; Zhang, Mengjie			DEEP HYBRID NETWORKS WITH GOOD OUT-OF-SAMPLE OBJECT RECOGNITION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		deep hybrid network; out-of-sample; noise robustness; sparse features; object recognition	SPARSE; REPRESENTATIONS	We introduce Deep Hybrid Networks that are robust to the recognition of out-of-sample objects, i.e., ones that are drawn from a different probability distribution from the training data distribution. The networks are based on a particular combination of an auto-encoder and stacked Restricted Boltzmann Machines (RBMs). The auto-encoder is used to extract sparse features, which are expected to be noise invariant in the observations. The stacked RBMs then observe the sparse features as inputs to learn the top hierarchical features. The use of RBMs is motivated by the fact that the stacked RBMs typically provide good performance when dealing with in-sample observations, as proven in the previous works. To improve the robustness against local noise, we propose a variant of our hybrid network by the usage of a mixture of sparse features and sparse connections in the auto-encoder layer. The experiments show that our proposed deep networks provide good performance in both the in-sample and out-of-sample situations, particularly when the number of training examples is small.	[Ghifary, Muhammad; Kleijn, W. Bastiaan; Zhang, Mengjie] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington, New Zealand	Ghifary, M (reprint author), Victoria Univ Wellington, Sch Engn & Comp Sci, POB 600, Wellington, New Zealand.	muhammad.ghifary@ecs.vuw.ac.nz; bastiaan.kleijn@ecs.vuw.ac.nz; mengjie.zhang@ecs.vuw.ac.nz					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bradley D. M., 2009, ADV NEURAL INFORM PR, V21, P113; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Coates A., 2011, P 28 INT C MACH LEAR, P912; Dalal N, 2005, PROC CVPR IEEE, P886; Deng L, 2013, INT CONF ACOUST SPEE, P8604; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Fiesler E., 1990, P 1 WORKSH NEUR NETW, V2, P51; Goodfellow I. J., 2013, P 30 INT C MACH LEAR, P1319; Goodfellow J., 2009, ADV NEURAL INFORM PR, V22, P646; HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Le QV, 2011, P 28 INT C MACH LEAR, P265; Lee H., 2007, ADV NEURAL INFORM PR, V20, P873; Mairal J., 2012, IEEE T PATTERN ANAL, V34; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Mushtaq A, 2013, INT CONF ACOUST SPEE, P7107, DOI 10.1109/ICASSP.2013.6639041; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; Salakhutdinov R., 2009, 12 INT C ART INT STA, P448; Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100; Tang Y., 2010, ICML, P1055; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Zhou W. Y., 2012, ADV NEURAL INFORM PR, V25, P3212	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655305094		
S	Golovko, V; Kroshchanka, A; Rubanau, U; Jankowski, S		Golovko, V; Imada, A		Golovko, Vladimir; Kroshchanka, Aliaksandr; Rubanau, Uladzimir; Jankowski, Stanislaw			A Learning Technique for Deep Belief Neural Networks	NEURAL NETWORKS AND ARTIFICIAL INTELLIGENCE, ICNNAI 2014	Communications in Computer and Information Science		English	Proceedings Paper	8th International Conference on Neural Networks and Artificial Intelligence (ICNNAI)	JUN 03-06, 2014	Brest, BYELARUS	ERICPOL Brest, Brest Tech Univ, Dept Intelligent Informat Technol				Deep belief neural network represents many-layered perceptron and permits to overcome some limitations of conventional multilayer perceptron due to deep architecture. The supervised training algorithm is not effective for deep belief neural network and therefore in many studies was proposed new learning procedure for deep neural networks. It consists of two stages. The first one is unsupervised learning using layer by layer approach, which is intended for initialization of parameters (pre-training of deep belief neural network). The second is supervised training in order to provide fine tuning of whole neural network. In this work we propose the training approach for restricted Boltzmann machine, which is based on minimization of reconstruction square error. The main contribution of this paper is new interpretation of training rules for restricted Boltzmann machine. It is shown that traditional approach for restricted Boltzmann machine training is particular case of proposed technique. We demonstrate the efficiency of proposed approach using deep nonlinear auto-encoder.	[Golovko, Vladimir; Kroshchanka, Aliaksandr; Rubanau, Uladzimir] Brest State Tech Univ, Brest 224017, Byelarus	Golovko, V (reprint author), Brest State Tech Univ, Moskowskaja 267, Brest 224017, Byelarus.	gva@bstu.by					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Erhan D, 2010, J MACH LEARN RES, V11, P625; Golovko V., 2012, Optical Memory and Neural Networks (Information Optics), V21, DOI 10.3103/S1060992X12030095; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2010, 2010000 U TOR MACH L; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Scholz M., 2008, PRINCIPAL MANIFOLDS, V58, P44, DOI 10.1007/978-3-540-73750-6_2	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929		978-3-319-08201-1; 978-3-319-08200-4	COMM COM INF SC			2014	440						136	146				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BB8TQ	WOS:000347515900013		
J	Grais, EM; Sen, MU; Erdogan, H			IEEE	Grais, Emad M.; Sen, Mehmet Umut; Erdogan, Hakan			DEEP NEURAL NETWORKS FOR SINGLE CHANNEL SOURCE SEPARATION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Single channel source separation; deep neural network; nonnegative matrix factorization	NONNEGATIVE MATRIX FACTORIZATION	In this paper, a novel approach for single channel source separation (SCSS) using a deep neural network (DNN) architecture is introduced. Unlike previous studies in which DNN and other classifiers were used for classifying time-frequency bins to obtain hard masks for each source, we use the DNN to classify estimated source spectra to check for their validity during separation. In the training stage, the training data for the source signals are used to train a DNN. In the separation stage, the trained DNN is utilized to aid in estimation of each source in the mixed signal. Single channel source separation problem is formulated as an energy minimization problem where each source spectra estimate is encouraged to fit the trained DNN model and the mixed signal spectrum is encouraged to be written as a weighted sum of the estimated source spectra. The proposed approach works regardless of the energy scale differences between the source signals in the training and separation stages. Nonnegative matrix factorization (NMF) is used to initialize the DNN estimate for each source. The experimental results show that using DNN initialized by NMF for source separation improves the quality of the separated signal compared with using NMF for source separation.	[Grais, Emad M.; Sen, Mehmet Umut; Erdogan, Hakan] Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Istanbul, Turkey	Grais, EM (reprint author), Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Istanbul, Turkey.	grais@sabanciuniv.edu; umutsen@sabanciuniv.edu; haerdogan@sabanciuniv.edu					Deoras A. N., 2004, IEEE INT C AC SPEECH; Fevotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771; Grais E. M., 2013, ANN C INT SPEECH COM; Grais E. M., 2012, ANN C INT SPEECH COM; Grais E. M., 2011, ANN C INT SPEECH COM; Grais E. M., 2011, INT C DIG SIGN PROC; Grais E. M., 2012, EUR SIGN PROC C EUSI; Grais EM, 2013, COMPUT SPEECH LANG, V27, P746, DOI 10.1016/j.csl.2012.09.002; Hershey JR, 2010, COMPUT SPEECH LANG, V24, P45, DOI 10.1016/j.csl.2008.11.001; Hinton G., 2012, SIGNAL PROCESSING MA; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kristjansson T., 2004, IEEE INT C AC SPEECH; Lee DD, 2001, ADV NEUR IN, V13, P556; Ozerov A., 2009, IEEE WORKSH APPL SIG; Radfar M. H., 2007, P IEEE WORKSH APPL S; Radfar M. H., 2010, IEEE INT C AC SPEECH; Radfar M. H., 2008, J SIGNAL PROCESSING, V61, P21; Radfar M. H., 2009, P IEEE INT WORKSH MA; Reddy A. M., 2004, INT C SPOK LANG PROC; Reddy A. M., 2007, IEEE T AUDIO SPEECH, V15; Roweis S. T., 2000, NEURAL INFORM PROCES, V13, P793; Schmidt M. N., 2006, INT C SPOK LANG PROC; Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005; Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253; Virtanen T., 2006, INT C SPOK LANG PROC; Wang Y., 2012, ADV NEURAL INFORM PR	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655303155		
J	Han, B; He, B; Ma, MM; Sun, TT; Yan, TH; Lendasse, A				Han, Bo; He, Bo; Ma, Mengmeng; Sun, Tingting; Yan, Tianhong; Lendasse, Amaury			RMSE-ELM: Recursive Model Based Selective Ensemble of Extreme Learning Machines for Robustness Improvement	MATHEMATICAL PROBLEMS IN ENGINEERING			English	Article							NEURAL-NETWORK; FEEDFORWARD NETWORKS; ALGORITHM; APPROXIMATION; REGRESSION; ACCURATE	For blended data, the robustness of extreme learning machine (ELM) is so weak because the coefficients (weights and biases) of hidden nodes are set randomly and the noisy data exert a negative effect. To solve this problem, a new framework called "RMSE-ELM" is proposed in this paper. It is a two-layer recursive model. In the first layer, the framework trains lots of ELMs in different ensemble groups concurrently and then employs selective ensemble approach to pick out an optimal set of ELMs in each group, which can be merged into a large group of ELMs called candidate pool. In the second layer, selective ensemble approach is recursively used on candidate pool to acquire the final ensemble. In the experiments, we apply UCI blended datasets to confirm the robustness of our new approach in two key aspects (mean square error and standard deviation). The space complexity of our method is increased to some degree, but the result has shown that RMSE-ELM significantly improves robustness with a rapid learning speed compared to representative methods (ELM, OP-ELM, GASEN-ELM, GASEN-BP, and E-GASEN). It becomes a potential framework to solve robustness issue of ELM for high-dimensional blended data in the future.	[Han, Bo; He, Bo; Ma, Mengmeng; Sun, Tingting] Ocean Univ China, Sch Informat & Engn, Qingdao 266000, Shandong, Peoples R China; [Yan, Tianhong] China Jiliang Univ, Sch Mech & Elect Engn, Hangzhou 310018, Zhejiang, Peoples R China; [Lendasse, Amaury] Univ Iowa, Dept Mech & Ind Engn, Iowa City, IA 52242 USA; [Lendasse, Amaury] Univ Iowa, Iowa Informat Initiat, Iowa City, IA 52242 USA; [Lendasse, Amaury] Arcada Univ Appl Sci, Helsinki 00550, Finland	He, B (reprint author), Ocean Univ China, Sch Informat & Engn, Qingdao 266000, Shandong, Peoples R China.	bhe@ouc.edu.cn; thyan@163.com			Natural Science Foundation of China [41176076, 31202036, 51379198, 51075377]	This work is partially supported by Natural Science Foundation of China (41176076, 31202036, 51379198, and 51075377).	Asuncion A., 2007, UCI MACHINE LEARNING; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Chen YN, 2006, INT C PATT RECOG, P552; Frenay B, 2011, NEUROCOMPUTING, V74, P2526, DOI 10.1016/j.neucom.2010.11.037; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977; Huang GB, 2004, IEEE IJCNN, P985; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Huang GB, 2005, IEEE T NEURAL NETWOR, V16, P57, DOI 10.1109/TNN.2004.836241; Huang G.-B., 2004, P 8 INT C CONTR AUT, V2, P1029, DOI DOI 10.1109/ICARCV.2004.1468985]; Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y; Huang GB, 2004, IEEE T SYST MAN CY B, V34, P2284, DOI 10.1109/TSMCB.2004.834428; Krogh A., 1997, STAT MECH ENSEMBLE L; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; Li N., 2009, SELECTIVE ENSEMBLE R; Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583; Miche Y, 2010, IEEE T NEURAL NETWOR, V21, P158, DOI 10.1109/TNN.2009.2036259; Miche Y., 2008, P EUR S ART NEUR NET, P247; Miche Y, 2008, LECT NOTES COMPUT SC, V5163, P145, DOI 10.1007/978-3-540-87536-9_16; Opitz DW, 1996, ADV NEUR IN, V8, P535; Rao C.-R., 1972, GEN INVERSE MATRIX I; Rong HJ, 2008, NEUROCOMPUTING, V72, P359, DOI 10.1016/j.neucom.2008.01.005; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2010, P INT C ART INT STAT; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Schuldt C, 2004, P INT C PATT REC, V3, P32; Serre D., 2002, GRADUATE TEXTS MATH, V216; Sun ZL, 2008, DECIS SUPPORT SYST, V46, P411, DOI 10.1016/j.dss.2008.07.009; Tang Y., 2009, SEG TECHN PROGR EXP, V28, P2859; Van H.-M., 2009, LECT NOTES COMPUTING, V5769, P305; van Heeswijk M, 2011, NEUROCOMPUTING, V74, P2430, DOI 10.1016/j.neucom.2010.11.034; Zhao L.-J., 2012, INT J AUTOMATION COM, V9, P627; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zhou Z.-H., 2001, P 17 INT JOINT C ART, P797	36	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1024-123X	1563-5147		MATH PROBL ENG	Math. Probl. Eng.		2014									395686	10.1155/2014/395686		12	Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications	Engineering; Mathematics	AY1FA	WOS:000347337800001		
J	Han, K; Wang, YX; Wang, DL			IEEE	Han, Kun; Wang, Yuxuan; Wang, DeLiang			LEARNING SPECTRAL MAPPING FOR SPEECH DEREVERBERATION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Speech Dereverberation; Deep Neural Networks; Spectral Mapping	REVERBERANT SPEECH; COCHLEAR IMPLANTS; BINARY MASKING; INTELLIGIBILITY; ALGORITHM; CRITERION	Reverberation distorts human speech and usually has negative effects on speech intelligibility, especially for hearing-impaired listeners. It also causes performance degradation in automatic speech recognition and speaker identification systems. Therefore, the dereverberation problem must be dealt with in daily listening environments. We propose to use deep neural networks (DNNs) to learn a spectral mapping from the reverberant speech to the anechoic speech. The trained DNN produces the estimated spectral representation of the corresponding anechoic speech. We demonstrate that distortion caused by reverberation is substantially attenuated by the DNN whose outputs can be resynthesized to the dereverebrated speech signal. The proposed approach is simple, and our systematic evaluation shows promising dereverberation results, which are significantly better than those of related systems.	[Han, Kun] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	Han, K (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	hank@cse.ohio-state.edu; wangyuxu@cse.ohio-state.edu; dwang@cse.ohio-state.edu					Avendano C, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P889; Habets E., 2010, ROOM IMPULSE RESPONS; Hazrati O, 2013, J ACOUST SOC AM, V133, P1607, DOI 10.1121/1.4789891; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kingsbury BED, 1997, INT CONF ACOUST SPEE, P1259, DOI 10.1109/ICASSP.1997.596174; Kokkinakis K, 2011, J ACOUST SOC AM, V129, P3221, DOI 10.1121/1.3559683; Lee H., 2007, P NIPS, P873; Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493; MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509; Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4; NEELY ST, 1979, J ACOUST SOC AM, V66, P165, DOI 10.1121/1.383069; Roman N, 2011, J ACOUST SOC AM, V130, P2153, DOI 10.1121/1.3631668; Rothauser E. H., 1969, IEEE T AUDIO ELECTRO, V17, P227; Sadjadi SO, 2011, INT CONF ACOUST SPEE, P5448; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang D., 2006, COMPUTATIONAL AUDITO; Wang YX, 2013, INT CONF ACOUST SPEE, P7472; Wu MY, 2006, IEEE T AUDIO SPEECH, V14, P774, DOI 10.1109/TSA.2005.858066; Wu M., 2003, P IEEE ICASSP, P844; ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655304131		
J	Han, K; Wang, DL			IEEE	Han, Kun; Wang, DeLiang			NEURAL NETWORKS FOR SUPERVISED PITCH TRACKING IN NOISE	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Pitch estimation; Deep neural networks; Recurrent neural networks; Viterbi decoding; Supervised learning	SPEECH; ALGORITHM; DATABASE	Determination of pitch in noise is challenging because of corrupted harmonic structure. In this paper, we extract pitch using supervised learning, where probabilistic pitch states are directly learned from noisy speech. We investigate two alternative neural networks modeling the pitch states given observations. The first one is the feedforward deep neural network (DNN), which is trained on static frame-level features. The second one is the recurrent deep neural network (RNN) capable of learning the temporal dynamics trained on sequential frame-level features. Both DNNs and RNNs produce accurate probabilistic outputs of pitch states, which are then connected into pitch contours by Viterbi decoding. Our systematic evaluation shows that the proposed pitch tracking approaches are robust to different noise conditions and significantly outperform current state-of-the-art pitch tracking techniques.	[Han, Kun] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	Han, K (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	hank@cse.ohio-state.edu; dwang@cse.ohio-state.edu					Boersma P., 2007, PRAAT DOING PHONETIC; Chu W, 2012, IEEE T AUDIO SPEECH, V20, P933, DOI 10.1109/TASL.2011.2168518; de Cheveigne A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Gonzalez S., 2011, P EUSIPCO 2011; Han K, 2012, J ACOUST SOC AM, V132, P3475, DOI 10.1121/1.4754541; HERMES DJ, 1988, J ACOUST SOC AM, V83, P257, DOI 10.1121/1.396427; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu G., 2006, 100 NONSPEECH SOUNDS; Hu G., 2006, THESIS OHIO STATE U; Huang F., 2013, IEEE T AUDIO SPEECH, V21, P99; Jin Z., 2011, IEEE T AUDIO SPEECH, V19, P1091; Lee B. S., 2012, P INT; Maas A.L., 2012, P INT 2012; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; SCHROEDE.MR, 1968, J ACOUST SOC AM, V43, P829, DOI 10.1121/1.1910902; Talkin D., 1995, SPEECH CODING SYNTHE, V495, P495; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Vinyals O., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288816; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961; Wu MY, 2003, IEEE T SPEECH AUDI P, V11, P229, DOI 10.1109/TSA.2003.811539; Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803; ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655301103		
J	Hatakeyama, Y; Kataoka, H; Okuhara, Y; Yoshida, S			IEEE	Hatakeyama, Yutaka; Kataoka, Hiromi; Okuhara, Yoshiyasu; Yoshida, Shinichi			Decoding analysis for fMRI based on Deep Brief Network	2014 WORLD AUTOMATION CONGRESS (WAC): EMERGING TECHNOLOGIES FOR A NEW PARADIGM IN SYSTEM OF SYSTEMS ENGINEERING	World Automation Congress		English	Proceedings Paper	World Automation Congress (WAC) on Emerging Technologies for a New Paradigm in System of Systems Engineering	AUG 03-07, 2014	Waikoloa Hilton, HI	IEEE SMC Soc		Deep Brief Network; fMRI; decoding	BRAIN STATES	A decoding process for fMRI data is constructed based on Deep Brief Network (DBN) which extracts the feature for classification on each ROI of input fMRI data in order to evaluate robustness for task complexity. The decoding experiment results for hand motion and visual stimulus task show that the results based on DBN in both task can classify the state of subject without the effect of distributions in input voxel values. The decoding process based on the DBN is appropriate for complicate task, which these processes may deal with all voxel values in the selected ROI for each task.	[Hatakeyama, Yutaka; Kataoka, Hiromi; Okuhara, Yoshiyasu] Kochi Univ, Ctr Med Informat Sci, Kochi, Japan	Hatakeyama, Y (reprint author), Kochi Univ, Ctr Med Informat Sci, Kochi, Japan.	hatake@kochi-u.ac.jp					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Chang C.-C., 2011, ACM T INTEL SYST TEC; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444; Lancaster J, 1997, NEUROIMAGE, V5, pS633, DOI DOI 10.1002/(SICI)1097-0193(1997)5:4<238:AID-HBM6>3.0.C0;2-4; Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8; Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1; Mokhtari F, 2013, J NEUROSCI METH, V212, P259, DOI 10.1016/j.jneumeth.2012.10.012; Pantazatos SP, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002441; Richiardi J, 2011, NEUROIMAGE, V56, P616, DOI 10.1016/j.neuroimage.2010.05.081; Schmah T., 2009, ADV NEURAL INFORM PR, V21, P1409; Yamashita O, 2008, NEUROIMAGE, V42, P1414, DOI 10.1016/j.neuroimage.2008.05.050	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2154-4824		978-1-889335-49-0	WORLD AUTOMAT CONG			2014												5	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BC0JK	WOS:000349117400054		
S	Hessel, M; Ortalli, F; Borgatelli, F		Hodicky, J		Hessel, Matteo; Ortalli, Fabio; Borgatelli, Francesco			Machine Learning for Parameter Screening in Computer Simulations	MODELLING AND SIMULATION FOR AUTONOMOUS SYSTEMS, MESAS 2014	Lecture Notes in Computer Science		English	Proceedings Paper	1st International Workshop on Modelling and Simulation for Autonomous Systems (MESAS)	MAY 05-06, 2014	Rome, ITALY	Off Naval Res Sci & Technol, Selex ES, Finmeccanica, Qbit Technologies, GM SPA ZIO, Alenia Aermacchi, SSI, Antycip Simulat, Clar Events, MIMOS, AFCEA Europe, AFCEA, IEEE, RA Italy, Simulat Team, SCS		Model tuning; parameter screening; machine learning; feature ranking; logistic regression; multilayer perceptron	MODELS	The aim of this paper is to highlight the potential of Machine Learning for parameter screening in computer simulations, presenting alternative approaches to automatic parameter ranking and screening. This is indeed a fundamental step in the development of a simulator, because it allows reducing the dimensionality of the parameter set, making model tuning more efficient. With parameter ranking we denote the process of measuring the relevance of the parameters for accurately simulating a phenomenon, while with parameter screening we denote the choice of a specific subset of parameters to be used for model tuning. We will present ranking techniques based on Logistic Regression and Multilayer Perceptron, and a simple procedure for going from ranking to screening. Our techniques have been validated against a helicopter simulator case-study but the techniques do not rely on any domain-specific feature or assumption.	[Hessel, Matteo] Politecn Milan, I-20133 Milan, Italy; [Ortalli, Fabio; Borgatelli, Francesco] TXT esolut, Milan, Italy	Hessel, M (reprint author), Politecn Milan, I-20133 Milan, Italy.	matteo.hessel@mail.polimi.it; fabio.ortalli@txtgroup.com; francesco.borgatelli@txtgroup.com					Bergmeir C., 2012, J STAT SOFTWARE, V46; Bettonvil B, 1997, EUR J OPER RES, V96, P180, DOI 10.1016/S0377-2217(96)00156-7; Bishop C, 2006, PATTERN RECOGN, P217; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Fisher RA, 1935, DESIGN EXPT; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P1, DOI DOI 10.1145/1656274.1656278; Harrel F, 2001, REGRESSION MODELING; Haykin S., 1998, NEURAL NETWORKS COMP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Last M, 2008, COMPUT STAT DATA AN, V52, P5215, DOI 10.1016/j.csda.2008.04.024; Le Cessie S, 1992, RIDGE ESTIMATORS LOG; Lewis JH, 2009, PHYS MED BIOL, V54, P745, DOI 10.1088/0031-9155/54/3/018; Morgan Pamela J, 2006, Med Teach, V28, pe10; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Zhang A, 2007, 2007011660 SAE, DOI [10.4271/2007-01-1660, DOI 10.4271/2007-01-1660]	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-13823-7; 978-3-319-13822-0	LECT NOTES COMPUT SC			2014	8906						308	320				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BC7JP	WOS:000354951100027		
S	Hong, HK; Huang, WH; Song, GJ; Xie, KQ		Zeng, Z; Li, Y; King, I		Hong, Haikun; Huang, Wenhao; Song, Guojie; Xie, Kunqing			Metric-Based Multi-Task Grouping Neural Network for Traffic Flow Forecasting	ADVANCES IN NEURAL NETWORKS - ISNN 2014	Lecture Notes in Computer Science		English	Proceedings Paper	11th International Symposium on Neural Networks (ISNN)	NOV 28-DEC 01, 2014	PEOPLES R CHINA	Chinese Univ Hong Kong, Univ Macau, European Neural Network Soc, Int Neural Network Soc, IEEE Computat Intelligence Soc, Asia Pacific Neural Network Assembly		Metric learning; Traffic flow forecasting; Multi-task learning; Deep neural network; Metric-based MTGNN	PREDICTION; VOLUME; SVR	Traffic flow forecasting is a fundamental problem in transportation modeling and management. Among various methods multitask neural network has been demonstrated to be a promising and effective model for traffic flow forecasting, while there are still two issues unconsidered: 1) learning unrelated tasks together tends to reduce the model's performance; 2) how to define or learn the distance metric for distinguishing related tasks and unrelated tasks. In this paper, a metric learning based K-means method is proposed to group related tasks together which effectively reduces the semantic gap between domain knowledge and handcrafted feature engineering. Then for each group of tasks, a deep neural network is built for traffic flow forecasting. Experimental results show the metric-based grouping method clusters tasks more reasonably with a better metric than classic Euclidean-based Kmeans. The final results of traffic flow forecasting on real dataset show the metric-based multi-task neural network outperforms the Euclidean-based multi-task neural network.	[Hong, Haikun; Huang, Wenhao; Song, Guojie; Xie, Kunqing] Peking Univ, Sch Elect Engn & Comp Sci, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China	Hong, HK (reprint author), Peking Univ, Sch Elect Engn & Comp Sci, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China.	honghaikun@hotmail.com					Ahmed M.S., 1979, 722 TRSNP RES; Bellet A., 2013, ABS13066709 CORR; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Castro-Neto M, 2009, EXPERT SYST APPL, V36, P6164, DOI 10.1016/j.eswa.2008.07.069; Chrobok R, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P434; Gao Y., 2010, 2010 6 INT C NAT COM, V1, P398; Gao Y, 2011, LECT NOTES COMPUT SC, V6676, P151; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hong WC, 2011, APPL MATH MODEL, V35, P1282, DOI 10.1016/j.apm.2010.09.005; Huang W., 2013, LNCS, V8347, P165; Jiang XM, 2005, J TRANSP ENG-ASCE, V131, P771, DOI 10.1061/(ASCE)0733-947X(2005)131:10(771); Jin F, 2008, IEEE IJCNN, P1897; Kulis B., 2012, FDN TRENDS MACH LEAR, V5, P287; Min WL, 2011, TRANSPORT RES C-EMER, V19, P606, DOI 10.1016/j.trc.2010.10.002; OKUTANI I, 1984, TRANSPORT RES B-METH, V18, P1, DOI 10.1016/0191-2615(84)90002-X; Park B, 1998, TRANSPORT RES REC, P39; Smith BL, 2002, TRANSPORT RES C-EMER, V10, P303, DOI 10.1016/S0968-090X(02)00009-8; Sun SL, 2006, IEEE T INTELL TRANSP, V7, P124, DOI 10.1109/TITS.2006.869623; Sun SL, 2009, WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09), P961; Wei Y, 2012, TRANSPORT RES C-EMER, V21, P148, DOI 10.1016/j.trc.2011.06.009; Williams BM, 2003, J TRANSP ENG-ASCE, V129, P664, DOI 10.1061/(ASCE)0733-947X(2003)129:6(664); Xing E., 2002, ADV NEURAL INFORM PR, V15, P505; Yin HB, 2002, TRANSPORT RES C-EMER, V10, P85, DOI 10.1016/S0968-090X(01)00004-3	23	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-12436-0; 978-3-319-12435-3	LECT NOTES COMPUT SC			2014	8866						499	507		10.1007/978-3-319-12436-0_55		9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BC7GU	WOS:000354869400055		
J	Hu, WP; Qian, Y; Soong, FK			IEEE	Hu, Wenping; Qian, Yao; Soong, Frank K.			A DNN-BASED ACOUSTIC MODELING OF TONAL LANGUAGE AND ITS APPLICATION TO MANDARIN PRONUNCIATION TRAINING	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Computer-Aided Pronunciation Training; F0; Acoustic Model; Mandarin; Deep Neural Network		In this paper we investigate a Deep Neural Network (DNN) based approach to acoustic modeling of tonal language and assess its speech recognition performance with different features and modeling techniques. Mandarin Chinese, the most widely spoken tonal language, is chosen for testing the tone related ASR performance. Furthermore, the DNN-trained, tone-sensitive model is evaluated in automatic detection of mispronunciation among L2 Mandarin learners. The best DNN-HMM acoustic model of tonal syllable (initial and tonal final), trained with embedded F0 features, has shown improved ASR performance, when compared with the baseline DNN system of 39 MFCC features. The proposed system achieves better ASR performance than the baseline system, i.e., by 32% and 35% in relative tone error rate reduction and 20% and 23% in relative tonal syllable error rate reduction, for female and male speakers, respectively. In a speech database of L2 Mandarin learners (native speakers of European languages), 2% equal error rate reduction, from 27.5% to 25.5%, has been obtained with our DNN-HMM system in detecting mispronunciations, compared with the baseline system.	[Hu, Wenping] Microsoft Res Asia, Speech Grp, Beijing, Peoples R China	Hu, WP (reprint author), Microsoft Res Asia, Speech Grp, Beijing, Peoples R China.	v-wenh@microsoft.com; yaoqian@microsoft.com; frankkps@microsoft.com					[Anonymous], TITLE ERROR; Chang E., 2000, INTERSPEECH, P983; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hirst Daniel, 1993, TRAVAUX I PHONETIQUE, V15, P75; Julian Chen C., 1997, EUROSPEECH, P1543; Lei X., 2005, INTERSPEECH, P2981; Qian X., 2012, INTERSPEECH; Qian Y, 2009, SPEECH COMMUN, V51, P1169, DOI 10.1016/j.specom.2009.08.001; Seide F., 2011, ASRU, P24; Talkin D., 1995, SPEECH CODING SYNTHE, V495, P495; Tokuda K, 2002, IEICE T INF SYST, VE85D, P455; Wenping Hu, 2013, INTERSPEECH, P1886	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655303048		
S	Hu, XN; Liu, QH; Cai, HB; Li, F		Wen, Z; Li, T		Hu, Xiaonan; Liu, Qihe; Cai, Hongbin; Li, Fan			Gas Recognition Under Sensor Drift by Using Deep Learning	PRACTICAL APPLICATIONS OF INTELLIGENT SYSTEMS, ISKE 2013	Advances in Intelligent Systems and Computing		English	Proceedings Paper	8th International Conference on Intelligent Systems and Knowledge Engineering (ISKE)	NOV 20-23, 2013	Shenzhen, PEOPLES R CHINA	Shenzhen Univ, Sci China Press, Chinese Acad Sci, IEEE Computat Intelligence Soc, Chinese Assoc Artificial Intelligence, State Key Lab Complex Elect Syst Simulat, Sci & Technol Integrated Informat Syst Lab, SW Jiaotong Univ, Univ Technol		Sensor drift; Deep learning; Machine olfaction	OLFACTION	Machine olfaction is an intelligent system that combines cross-sensitivity chemical sensor array and an effective pattern recognition algorithm for the detection, identification, or quantification of various odors. Data collected by the sensor array are multivariate time-series signals with complex structure, and these signals become more difficult to analyze due to sensor drift. In this work, we focus on improving the classification performance under sensor drift by using the deep learning method, which is popular among these years. Compared with other methods, our method can effectively tackle sensor drift by automatically extracting features, thus not only removing the complexity of designing the hand-made features, but also making it pervasive for a variety of application in machine olfaction. Our experimental results show that the deep learning method can learn the features that are more robust to drift than the original input and achieves high classification accuracy.	[Hu, Xiaonan; Liu, Qihe; Cai, Hongbin; Li, Fan] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Digital Media Technol Key Lab Sichuan Prov, Chengdu 611731, Peoples R China	Liu, QH (reprint author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Digital Media Technol Key Lab Sichuan Prov, Chengdu 611731, Peoples R China.	hxn1025@foxmail.com; qiheliu@uestc.edu.cn; caihb@uestc.edu.cn; lifan@uestc.edu.cn					Artursson T, 2000, J CHEMOMETR, V14, P711, DOI 10.1002/1099-128X(200009/12)14:5/6<711::AID-CEM607>3.0.CO;2-4; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; De Vito S, 2012, IEEE SENS J, V12, P3215, DOI 10.1109/JSEN.2012.2192425; Erhan D., 2009, INT C ART INT STAT, V5, P153; Gardner J, 1999, ELECT NOSES PRINCIPL; Gutierrez-Osuna R, 2000, P 7 INT S OLF EL NOS; Gutierrez-Osuna R, 2002, IEEE SENS J, V2, P189, DOI 10.1109/JSEN.2002.800688; Haugen JE, 2000, ANAL CHIM ACTA, V407, P23, DOI 10.1016/S0003-2670(99)00784-9; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Langkvist M, 2011, WORKSH DEEP LEARN UN; Ngiam J., 2011, P 28 INT C MACH LEAR, P265; Pearce T.C., 2003, HDB MACHINE OLFACTIO; Vergara A, 2012, SENSOR ACTUAT B-CHEM, V166, P320, DOI 10.1016/j.snb.2012.01.074	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	2194-5357		978-3-642-54927-4; 978-3-642-54926-7	ADV INTELL SYST			2014	279						23	33		10.1007/978-3-642-54927-4_3		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Robotics	Computer Science; Robotics	BB9ND	WOS:000348509400003		
J	Huang, CC; Gong, W; Fu, WL; Feng, DY				Huang, Chenchen; Gong, Wei; Fu, Wenlong; Feng, Dongyu			A Research of Speech Emotion Recognition Based on Deep Belief Network and SVM	MATHEMATICAL PROBLEMS IN ENGINEERING			English	Article								Feature extraction is a very important part in speech emotion recognition, and in allusion to feature extraction in speech emotion recognition problems, this paper proposed a new method of feature extraction, using DBNs in DNN to extract emotional features in speech signal automatically. By training a 5 layers depth DBNs, to extract speech emotion feature and incorporate multiple consecutive frames to form a high dimensional feature. The features after training in DBNs were the input of nonlinear SVM classifier, and finally speech emotion recognition multiple classifier system was achieved. The speech emotion recognition rate of the system reached 86.5%, which was 7% higher than the original method.	[Huang, Chenchen; Gong, Wei; Fu, Wenlong; Feng, Dongyu] Commun Univ China, Dept Comp, Beijing 100024, Peoples R China	Huang, CC (reprint author), Commun Univ China, Dept Comp, Beijing 100024, Peoples R China.	hcc.1990@163.com			National Key Science and Technology Pillar Program of China [2012BAH38F05, 2013BAH66F02, 3132013XNG1442]	The authors would like to thank the National Key Science and Technology Pillar Program of China (the key technology research and system of stage design and dress rehearsal, 2012BAH38F05; study on the key technology research of the aggregation, marketing, production and broadcasting of online music resources, 2013BAH66F02; Research of Speech Emotion Recognition Based on Deep Belief Network and SVM, 3132013XNG1442).	Banziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bo X., 2003, P INT C AFF COMP INT, P221; Chunxia Z., INTRO RESTRICTED BOL; Guo P., 2007, RES METHOD SPEECH MO; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kai X., 2013, J COMPUTER RES DEV, V50, P1799; Kim Y., 2013, P IEEE INT C AC SPEE; Krizhevsky A., 2012, P 26 ANN C NEUR INF, P1097; Lee H., 2007, P 21 ANN C NEUR INF; Li Z., 2000, J CHINA I COMMUNICAT, V21, P18; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S01167-6393(03)00099-2; Pengjuan G., 2007, APPL RES COMPUTERS, V24, P101; Rui R., 2008, J SYSTEM SIMULATION, V20, P423; Shimmura T., 1995, ANAL PROSODIC COMPON, P3; Sun Zhi-jun, 2012, Application Research of Computers, V29, DOI 10.3969/j.issn.1001-3695.2012.08.002; Yongzhao Z., 2005, J JIANGSU U, V26, P72; Zhao Li, 2004, Acta Electronica Sinica, V32; Zhao L., 2000, J DATA ACQUISTION PR, V15, P120; Zhijun S., 2012, APPL RES COMPUTERS, V29, P2806; Zhu J., 2011, COMPUTER SYSTEMS APP, V20, P87	21	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1024-123X	1563-5147		MATH PROBL ENG	Math. Probl. Eng.		2014									749604	10.1155/2014/749604		7	Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications	Engineering; Mathematics	AN7GQ	WOS:000340767500001		
J	Jirayucharoensak, S; Pan-Ngum, S; Israsena, P				Jirayucharoensak, Suwicha; Pan-Ngum, Setha; Israsena, Pasin			EEG-Based Emotion Recognition Using Deep Learning Network with Principal Component Based Covariate Shift Adaptation	SCIENTIFIC WORLD JOURNAL			English	Article							SUPPORT VECTOR MACHINES	Automatic emotion recognition is one of the most challenging tasks. To detect emotion from nonstationary EEG signals, a sophisticated learning algorithm that can represent high-level abstraction is required. This study proposes the utilization of a deep learning network (DLN) to discover unknown feature correlation between input signals that is crucial for the learning task. The DLN is implemented with a stacked autoencoder (SAE) using hierarchical feature learning approach. Input features of the network are power spectral densities of 32-channel EEG signals from 32 subjects. To alleviate overfitting problem, principal component analysis (PCA) is applied to extract the most important components of initial input features. Furthermore, covariate shift adaptation of the principal components is implemented to minimize the nonstationary effect of EEG signals. Experimental results show that the DLNis capable of classifying three different levels of valence and arousal with accuracy of 49.52% and 46.03%, respectively. Principal component based covariate shift adaptation enhances the respective classification accuracy by 5.55% and 6.53%. Moreover, DLN provides better performance compared to SVM and naive Bayes classifiers.	[Jirayucharoensak, Suwicha; Pan-Ngum, Setha] Chulalongkorn Univ, Fac Engn, Dept Comp Engn, Bangkok 10330, Thailand; [Jirayucharoensak, Suwicha; Israsena, Pasin] Thailand Sci Pk, Natl Elect & Comp Technol Ctr, Khlong Luang 12120, Pathum Thani, Thailand	Pan-Ngum, S (reprint author), Chulalongkorn Univ, Fac Engn, Dept Comp Engn, Bangkok 10330, Thailand.	setha.p@chula.ac.th					Akram F., 2013, P INT WINT WORKSH BR, P24; AlZoubi O, 2009, LECT NOTES ARTIF INT, V5866, P52, DOI 10.1007/978-3-642-10439-8_6; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Chanel G, 2006, LECT NOTES COMPUT SC, V4105, P530; Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000; Chanel G, 2009, INT J HUM-COMPUT ST, V67, P607, DOI 10.1016/j.ijhcs.2009.03.005; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chung S. Y., 1768, P 12 INT C CONTR AUT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang D., 2012, P INT JOINT C NEUR N, P1; Jatupaiboon N, 2013, SCI WORLD J, V2013; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Koelstra S., 2010, P INT C BRAIN INF TO; Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15; Langkvist M., 2012, ADV ARTIF NEU SYS, V2012; Li K., 2013, P IEEE INT C BIOINF; Lotte F, 2010, INT CONF ACOUST SPEE, P614, DOI 10.1109/ICASSP.2010.5495183; Morris JD, 1995, J ADVERTISING RES, V35, P63; Naveen R. S., 2013, P 4 INT C COMP COMM, P1; Nie D, 2011, I IEEE EMBS C NEUR E, P667; Samek W, 2013, IEEE T BIO-MED ENG, V60, P2289, DOI 10.1109/TBME.2013.2253608; Sharbrough F, 1991, J CLIN NEUROPHYSIOL, V8, P200; Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25; Spuler M., 2012, EURASIP J ADV SIG PR, V2012; Wang XW, 2011, LECT NOTES COMPUT SC, V7062, P734; Wijeratne U., 2012, P IEEE EMBS C BIOM E, P636; Wikipedia, 2014, ELECTROENCEPHALOGRAP; Wulsin DF, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/3/036015	28	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1537-744X			SCI WORLD J	Sci. World J.		2014									627892	10.1155/2014/627892		10	Multidisciplinary Sciences	Science & Technology - Other Topics	AR4RE	WOS:000343573200001		
J	Kim, J; Hwang, K; Sung, W			IEEE	Kim, Jonghong; Hwang, Kyuyeon; Sung, Wonyong			X1000 REAL-TIME PHONEME RECOGNITION VLSI USING FEED-FORWARD DEEP NEURAL NETWORKS	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Deep neural network; fixed-point optimization; phoneme recognition; VLSI	HARDWARE; SYSTEMS	Deep neural networks show very good performance in phoneme and speech recognition applications when compared to previously used GMM (Gaussian Mixture Model)-based ones. However, efficient implementation of deep neural networks is difficult because the network size needs to be very large when high recognition accuracy is demanded. In this work, we develop a digital VLSI for phoneme recognition using deep neural networks and assess the design in terms of throughput, chip size, and power consumption. The developed VLSI employs a fixed-point optimization method that only uses +Delta, 0, and -Delta for representing each of the weight. The design employs 1,024 simple processing units in each layer, which however can be scaled easily according to the needed throughput, and the throughput of the architecture varies from 62.5 to 1,000 times of the real-time processing speed.	[Kim, Jonghong; Hwang, Kyuyeon; Sung, Wonyong] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 151744, South Korea	Kim, J (reprint author), Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 151744, South Korea.	jhkim@dsp.snu.ac.kr; khwang@dsp.snu.ac.kr; wysung@snu.ac.kr					Ayala J.L., 2002, P 45 MIDW S CIRC SYS, V1, P419; Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346; Fiesler E., 1990, HAG 90 12 16 APR, P164; Goknar IC, 2012, IEEE T NEUR NET LEAR, V23, P717, DOI 10.1109/TNNLS.2012.2188541; Golub G. H., 2012, MATRIX COMPUTATIONS, V3; Hammerstrom D., 1990, P IEEE INT JOINT C N, V2, P537; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jung S, 2007, IEEE T IND ELECTRON, V54, P265, DOI 10.1109/TIE.2006.888791; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Sung WY, 1995, IEEE T SIGNAL PROCES, V43, P3087; TANG CZ, 1993, IEEE T SIGNAL PROCES, V41, P2724, DOI 10.1109/78.229903; Tomlinson Jr M.S., 1990, P INT JOINT C NEUR N, V2, P545; Vanhoucke V., 2011, P DEEP LEARN UNS FEA	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655307109		
S	Kuang, DP; Guo, XJ; An, X; Zhao, YL; He, LH		Huang, DS; Han, K; Gromiha, M		Kuang, Deping; Guo, Xiaojiao; An, Xiu; Zhao, Yilu; He, Lianghua			Discrimination of ADHD Based on fMRI Data with Deep Belief Network	INTELLIGENT COMPUTING IN BIOINFORMATICS	Lecture Notes in Bioinformatics		English	Proceedings Paper	10th International Conference on Intelligent Computing (ICIC)	AUG 03-06, 2014	Taiyuan, PEOPLES R CHINA	IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Sci Fdn China, Tongji Univ, N Univ China, Taiyuan Normal Univ, Taiyuan Univ Sci & Technol		ADHD; fMRI; Deep Learning; Deep Belief Network	ATTENTION-DEFICIT/HYPERACTIVITY DISORDER; PREFRONTAL CORTEX	Effective discrimination of attention deficit hyperactivity disorder (ADHD) using imaging and functional biomarkers would have fundamental influence on public health. In this paper, we created a classification model using ADHD-200 dataset focusing on resting state functional magnetic resonance imaging. We predicted ADHD status and subtype by deep belief network (DBN). In the data preprocessing stage, in order to reduce the high dimension of fMRI brain data, brodmann mask, Fast Fourier Transform algorithm (FFT) and max-pooling of frequencies are applied respectively. Experimental results indicate that our method has a good discrimination effect, and outperform the results of the ADHD-200 competition. Meanwhile, our results conform to the biological research that there exists discrepancy in prefrontal cortex and cingulate cortex. As far as we know, it is the first time that the deep learning method has been used for the discrimination of ADHD with fMRI data.	[Kuang, Deping] Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 201804, Peoples R China	Kuang, DP (reprint author), Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 201804, Peoples R China.	kuangdp1990@gmail.com					American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th; Bengio Y., 2007, ADV NEURAL INFORM PR, P19; Bush G., FUNCTIONAL NEUROIMAG; Eloyan A., 2012, AUTOMATED DIAGNOSES; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huettel S. A., 2004, FUNCTIONAL MAGNETIC; Kooij SJJ, 2010, BMC PSYCHIATRY, V10, DOI 10.1186/1471-244X-10-67; Lee H., 2009, NIPS, V9, P1096; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Milham MP, 2012, NEURON, V73, P214, DOI 10.1016/j.neuron.2011.11.004; Ranzato M., 2007, IEEE C COMP VIS PATT, P1; Rubia K, 2010, HUM BRAIN MAPP, V31, P287, DOI 10.1002/hbm.20864; Sarikaya R., APPL DEEP BELIEF NET; Wanchai, 2012, CORT FUNCT; Wolf RC, 2009, HUM BRAIN MAPP, V30, P2252, DOI 10.1002/hbm.20665; Zhu CZ, 2008, NEUROIMAGE, V40, P110, DOI 10.1016/j.neuroimage.2007.11.029	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-09330-7; 978-3-319-09329-1	LECT N BIOINFORMAT	Lect. Notes Bioinforma.		2014	8590						225	232				8	Biochemical Research Methods; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BB7GN	WOS:000345518100027		
S	Kurkova, V		Rutkowski, L; Korytkowski, M; Scherer, R; Tadeusiewicz, R; Zadeh, LA; Zurada, JM		Kurkova, Vera			Representations of Highly-Varying Functions by One-Hidden-Layer Networks	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING ICAISC 2014, PT I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	13th International Conference on Artificial Intelligence and Soft Computing (ICAISC)	JUN 01-05, 2014	Zakopane, POLAND	Polish Neural Network Soc, Univ Social Sci Lodz, Czestochowa Univ Technol, Inst Computat Intelligence, IEEE Computat Intelligence Soc, Poland Chapter		model complexity of neural networks; one-hidden-layer networks; highly-varying functions; tractability of representations of multi-variable functions by neural networks	NEURAL-NETWORKS; APPROXIMATION; COMPLEXITY; BOUNDS	Limitations of capabilities of one-hidden-layer networks are investigated. It is shown that for networks with Heaviside perceptrons as well as for networks with kernel units used in SVM, there exist large sets of d-variable functions which cannot be tractably represented by these networks, i.e., their representations require numbers of units or sizes of weighs depending on d exponentially. Our results are derived using the concept of variational norm from nonlinear approximation theory and the concentration of measure property of high dimensional Euclidean spaces.	Acad Sci Czech Republic, Inst Comp Sci, Prague 18207, Czech Republic	Kurkova, V (reprint author), Acad Sci Czech Republic, Inst Comp Sci, Pod Vodarenskou Vezi 2, Prague 18207, Czech Republic.	vera@cs.cas.cz	Kurkova, Vera/J-8115-2012				Ball K., 1997, MATH SCI RES I PUBL, V31, P1; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Barron A.R., 1992, P 7 YAL WORKSH AD LE, P69; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Chow T.W.S., 2007, NEURAL NETWORKS COMP; Fine T. L., 1999, FEEDFORWARD NEURAL N; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ito Y., 1992, MATH SCI, V17, P69; Kainen PC, 2012, IEEE T INFORM THEORY, V58, P1203, DOI 10.1109/TIT.2011.2169531; Knuth D. E., 1976, SIGACT News, V8; Kurkova V, 2002, IEEE T INFORM THEORY, V48, P264, DOI 10.1109/18.971754; Kurkova V., 2013, INFORM TECHNOLOGIE A; Kurkova V, 2012, NEURAL NETWORKS, V33, P160, DOI 10.1016/j.neunet.2012.05.002; Kurkova V, 1998, NEURAL NETWORKS, V11, P651, DOI 10.1016/S0893-6080(98)00039-2; Kurkova V, 2008, NEURAL COMPUT, V20, P250; Kurkova V, 1997, COMPUTER-INTENSIVE METHODS IN CONTROL AND SIGNAL PROCESSING, P261; Kurkova V., 2012, LNCS, V7553, P17; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; Maiorov V, 1999, NEUROCOMPUTING, V25, P81, DOI 10.1016/S0925-2312(98)00111-8; Maiorov VE, 1999, J APPROX THEORY, V99, P68, DOI 10.1006/jath.1998.3304; Matousek J., 2002, LECT DISCRETE GEOMET; Mhaskar H.N., 1995, P IEEE WORKSH NONL I, P70; MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414; PARK J, 1993, NEURAL COMPUT, V5, P305, DOI 10.1162/neco.1993.5.2.305; Pinkus A., 1999, Acta Numerica, V8, DOI 10.1017/S0962492900002919; Roychowdhury V., 1997, THEORERTICAL ADV NEU, P3; Schlafli L, 1950, GESAMELTE MATH ABHAN, V1; Schlafli Ludwig, 1901, THEORIE VIELFACHEN K; Steinwart I, 2008, INFORM SCI STAT, P1	31	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-07172-5; 978-3-319-07173-2	LECT NOTES ARTIF INT			2014	8467						67	76				10	Computer Science, Artificial Intelligence	Computer Science	BB1OW	WOS:000341246000007		
J	Lee, HS; Tso, Y; Chang, YF; Wang, HM; Jeng, SK			IEEE	Lee, Hung-Shin; Tso, Yu; Chang, Yun-Fan; Wang, Hsin-Min; Jeng, Shyh-Kang			SPEAKER VERIFICATION USING KERNEL-BASED BINARY CLASSIFIERS WITH BINARY OPERATION DERIVED FEATURES	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		speaker verification; SVM; DNN; i-vector	MODELS; RECOGNITION	In this paper, we study the use of two kinds of kernel-based discriminative models, namely support vector machine (SVM) and deep neural network (DNN), for speaker verification. We treat the verification task as a binary classification problem, in which a pair of two utterances, each represented by an i-vector, is assumed to belong to either the "within-speaker" group or the "between-speaker" group. To solve the problem, we employ various binary operations to retain the basic relationship between any pair of i-vectors to form a single vector for training the discriminative models. This study also investigates the correlation of achievable performances with the number of training pairs and the various combinations of basic binary operations, using the SVM and DNN binary classifiers. The experiments are conducted on the male portion of the core task in the NIST 2005 Speaker Recognition Evaluation (SRE), and the results are competitive or even better, in terms of normalized decision cost function (minDCF) and equal error rate (EER), while compared to other non-probabilistic based models, such as the conventional speaker SVMs and the LDA-based cosine distance scoring.	[Lee, Hung-Shin; Jeng, Shyh-Kang] Natl Taiwan Univ, Dept Elect Engn, Taipei, Taiwan	Lee, HS (reprint author), Natl Taiwan Univ, Dept Elect Engn, Taipei, Taiwan.						Auckenthaler R, 2000, DIGIT SIGNAL PROCESS, V10, P42, DOI 10.1006/dspr.1999.0360; BenZeghiba MF, 2006, SPEECH COMMUN, V48, P1200, DOI 10.1016/j.specom.2005.08.008; Bimbot F, 2004, EURASIP J APPL SIG P, V2004, P430, DOI 10.1155/S1110865704310024; Bishop CM, 2006, PATTERN RECOGNITION; Brummer N., 2010, P OD SPEAK LANG REC, P194; Campbell W., 2005, P IEEE INT C AC SPEE, P637; Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086; Cumani S, 2011, INT CONF ACOUST SPEE, P4852; Cumani S, 2012, IEEE T AUDIO SPEECH, V20, P1585, DOI 10.1109/TASL.2012.2186290; Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307; Garcia-Romero D., 2011, P INTERSPEECH, P249; Hatch AO, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1471; Haykin S., 1994, NEURAL NETWORKS COMP; Hinton G., 2012, IMPROVING NEURAL NET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kenny P., 2010, P OD SPEAK LANG REC; Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009; Li P, 2012, IEEE T PATTERN ANAL, V34, P144, DOI 10.1109/TPAMI.2011.104; MANDASARI M.I., 2011, P INTERSPEECH, P21; Melin H., 2001, TMH QPSR; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Naik J. M., 1989, P IEEE INT C AC SPEE, P524; Pelecanos J., 2001, P OD SPEAK LANG REC, P213; Prince S., 2007, P 11 INT C COMP VIS, P1; Rao W, 2013, IEEE T AUDIO SPEECH, V21, P1012, DOI 10.1109/TASL.2013.2243436; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Scholkopf B., 2002, LEARNING KERNELS; Stafylakis T., 2012, P INT 2012; Vapnik V. N., 1995, NATURE STAT LEARNING; Weisstein E. W., BINARY OPERATION; You CH, 2010, IEEE T AUDIO SPEECH, V18, P1300, DOI 10.1109/TASL.2009.2032950	32	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655301138		
J	Lee, M; Hwang, K; Sung, W			IEEE	Lee, Minjae; Hwang, Kyuyeon; Sung, Wonyong			FAULT TOLERANCE ANALYSIS OF DIGITAL FEED-FORWARD DEEP NEURAL NETWORKS	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		dropout training; fault model; fault tolerant characteristic; neural network hardware	RECOGNITION	As the homeostatis characteristics of nerve systems show, artificial neural networks are considered to be robust to variation of circuit components and interconnection faults. However, the tolerance of neural networks depends on many factors, such as the fault model, the network size, and the training method. In this study, we analyze the fault tolerance of fixed-point feed-forward deep neural networks for the implementation in CMOS digital VLSI. The circuit errors caused by the interconnection as well as the processing units are considered. In addition to the conventional and dropout training methods, we develop a new technique that randomly disconnects weights during the training to increase the error resiliency. Feed-forward deep neural networks for phoneme recognition are employed for the experiments.	[Lee, Minjae; Hwang, Kyuyeon; Sung, Wonyong] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 151744, South Korea	Lee, M (reprint author), Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 151744, South Korea.	mjlee@dsp.snu.ac.kr; khwang@dsp.snu.ac.kr; wysung@snu.ac.kr					Chang YN, 2013, INT CONF ACOUST SPEE, P2697; Choudry A., 1990, HAG 90 APR INT SOC O, P164; Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hsieh W. S., 1994, Proceedings of the 20th EUROMICRO Conference. EUROMICRO 94. System Architecture and Integration, DOI 10.1109/EURMIC.1994.390347; Joye N., 2007, P RES MICR EL C JUL, P249; Krizhevsky A., 2012, IMPROVING NEURAL NET; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Sequin C. H., 1990, IJCNN INT JOINT C NE, V1, P703; Shanbhag N. R., 2010, ACM IEEE DAC, P859; Sung WY, 1995, IEEE T SIGNAL PROCES, V43, P3087; TANG CZ, 1993, IEEE T SIGNAL PROCES, V41, P2724, DOI 10.1109/78.229903; Vural M., 2007, 50 IEEE MIDW S CIRC, P779	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655305012		
J	Li, K; Meng, H		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		Li, Kun; Meng, Helen			Mispronunciation Detection and Diagnosis in L2 English Speech Using Multi-Distribution Deep Neural Networks	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		speech recognition; mispronunciation detection and diagnosis; L2 English speech; deep neural networks		This paper investigates the use of multi-distribution Deep Neural Networks (DNNs) for mispronunciation detection and diagnosis (MD&D). Our existing approach uses extended recognition networks (ERNs) to constrain the recognition paths to the canonical pronunciation of the target words and the likely phonetic mispronunciations. Although this approach is viable, it has some problems: (1) deriving appropriate phonological rules to generate the ERNs remains a challenging task; (2) the acoustic model (AM) and the phonological rules are trained independently and hence contextual information is lost; and (3) phones missing from the ERNs cannot be recognized even if we have a well-trained AM. Hence we propose an Acoustic Phonological Model (APM) using a multi-distribution DNN, whose input features include acoustic features and corresponding canonical pronunciations. The APM can implicitly learn the phonological rules from the canonical productions and annotated mispronunciations in the training data. Furthermore, the APM can also capture the relationships between the phonological rules and related acoustic features. As we do not restrict any pathways as in the ERNs, all phones can be recognized if we have a perfect APM. Experiments show that our method achieves an accuracy of 83.3% and a correctness of 88.5%. It significantly outperforms the approach of forced-alignment with ERNs whose correctness is 75.9%.	[Li, Kun; Meng, Helen] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Human Comp Communicat Lab, Hong Kong, Peoples R China	Li, K (reprint author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Human Comp Communicat Lab, Hong Kong, Peoples R China.	kli@se.cuhk.edu.hk; hmmeng@se.cuhk.edu.hk					Abdel-Hamid O., ICASSP 2012; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L., ICASSP 2013; Graves A., ICASSP 2013; Harrison A. M., SLATE 2009; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kang S., 2013, ICASSP 2013; Lee K-F, 1989, IEEE T AUDIO SPEECH; Li K., 2013, INT 2013; Lo W., 2010, INT 2010; Mohamed A., ICASSP 2011; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Qian X., 2010, INT 2010; Qian X., 2012, INT 2012; Qian X., 2011, INT 2011; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Yong S., 2006, HTK BOOK HTK VERSION, P187	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							255	259				5	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600053		
S	Li, WB		Jiang, X; Hornegger, J; Koch, R		Li, Wenbin			Learning Multi-scale Representations for Material Classification	PATTERN RECOGNITION, GCPR 2014	Lecture Notes in Computer Science		English	Proceedings Paper	36th German Conference on Pattern Recognition (GCPR)	SEP 02-05, 2014	Munster, GERMANY	Cells Mot Cluster Excellence, MVTec Software GmbH, Olympus Soft Imaging Solut GmbH, Univ Munster			TEXTURE; IMAGES	The recent progress in sparse coding and deep learning has made unsupervised feature learning methods a strong competitor to hand-crafted descriptors. In computer vision, success stories of learned features have been predominantly reported for object recognition tasks. In this paper, we investigate if and how feature learning can be used for material recognition. We propose two strategies to incorporate scale information into the learning procedure resulting in a novel multi-scale coding procedure. Our results show that our learned features for material recognition outperform hand-crafted descriptors on the FMD and the KTH-TIPS2 material classification benchmarks.	Max Planck Inst Informat, D-66123 Saarbrucken, Germany	Li, WB (reprint author), Max Planck Inst Informat, D-66123 Saarbrucken, Germany.	Wenbinli@mpi-inf.mpg.de					Bengio Y., 2007, NIPS; Bergstra J., 2010, P PYTH SCI COMP C SC; Caputo B., 2005, ICCV; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Courville A., 2011, JMLR; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Farabet C., 2012, ICML; Goodfellow Ian, 2012, ICML; Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu D., 2011, BMVC; Hussain S.u., 2012, LNCS, V7573, P716; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li WB, 2012, LECT NOTES COMPUT SC, V7575, P345; Liu C., 2010, CVPR; Maenpaa T, 2003, LECT NOTES COMPUT SC, V2749, P885; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Qi XB, 2012, LECT NOTES COMPUT SC, V7577, P158; Raina R., 2007, ICML; Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255; Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4	23	0	0	SPRINGER INT PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743		978-3-319-11752-2; 978-3-319-11751-5	LECT NOTES COMPUT SC			2014	8753						757	764		10.1007/978-3-319-11752-2_65		8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BB8OA	WOS:000347032100065		
J	Li, XG		Xu, XD; Li, B; Lu, QM; Yan, XY; Li, JL		Li, Xiaoguang			Research on the Development and Applications of Artificial Neural Networks	MECHATRONICS ENGINEERING, COMPUTING AND INFORMATION TECHNOLOGY	Applied Mechanics and Materials		English	Proceedings Paper	International Conference on Mechatronics Engineering and Computing Technology (ICMECT)	APR 09-10, 2014	Shanghai, PEOPLES R CHINA			Intelligent control; Artificial neural networks; Application	BRAIN; NETS	Intelligent control is a class of control techniques that use various AI computing approaches like neural networks, Bayesian probability, fuzzy logic, machine learning, evolutionary computation and genetic algorithms. In computer science and related fields, artificial neural networks are computational models inspired by animals' central nervous systems (in particular the brain) that are capable of machine learning and pattern recognition. They are usually presented as systems of interconnected "neurons" that can compute values from inputs by feeding information through the network. Like other machine learning methods, neural networks have been used to solve a wide variety of tasks that are hard to solve using ordinary rule-based programming, including computer vision and speech recognition.	Harbin Univ, Harbin 150086, Peoples R China	Li, XG (reprint author), Harbin Univ, Harbin 150086, Peoples R China.	13936660911@126.com					Balabin RM, 2009, J CHEM PHYS, V131, DOI 10.1063/1.3206326; Farley B., 1954, IEEE T INFORM THEORY, V4, P76, DOI 10.1109/TIT.1954.1057468; Fukushima K., 1980, BIOL CYBERN, V36, P93; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; ROCHESTER N, 1956, IRE T INFORM THEOR, V2, P80, DOI 10.1109/TIT.1956.1056810; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Secomandi N, 2000, COMPUT OPER RES, V27, P1201, DOI 10.1016/S0305-0548(99)00146-X; SIEGELMANN HT, 1991, APPL MATH LETT, V4, P77, DOI 10.1016/0893-9659(91)90080-F; Warren M., 1943, MATH BIO, V5, P115; Yang JJ, 2008, NAT NANOTECHNOL, V3, P429, DOI 10.1038/nnano.2008.160	10	0	0	TRANS TECH PUBLICATIONS LTD	STAFA-ZURICH	LAUBLSRUTISTR 24, CH-8717 STAFA-ZURICH, SWITZERLAND	1660-9336		978-3-03835-115-3	APPL MECH MATER			2014	556-562						6011	6014		10.4028/www.scientific.net/AMM.556-562.6011		4	Engineering, Electrical & Electronic; Engineering, Mechanical; Materials Science, Multidisciplinary; Mechanics	Engineering; Materials Science; Mechanics	BC0RU	WOS:000349448508107		
J	Liu, GP; Yan, JJ; Wang, YQ; Zheng, W; Zhong, T; Lu, X; Qian, P				Liu, Guo-Ping; Yan, Jian-Jun; Wang, Yi-Qin; Zheng, Wu; Zhong, Tao; Lu, Xiong; Qian, Peng			Deep Learning Based Syndrome Diagnosis of Chronic Gastritis	COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE			English	Article								In Traditional Chinese Medicine (TCM), most of the algorithms used to solve problems of syndrome diagnosis are superficial structure algorithms and not considering the cognitive perspective from the brain. However, in clinical practice, there is complex and nonlinear relationship between symptoms (signs) and syndrome. So we employed deep leaning and multilabel learning to construct the syndrome diagnostic model for chronic gastritis (CG) in TCM. The results showed that deep learning could improve the accuracy of syndrome recognition. Moreover, the studies will provide a reference for constructing syndrome diagnostic models and guide clinical practice.	[Liu, Guo-Ping; Wang, Yi-Qin; Zheng, Wu; Qian, Peng] Shanghai Univ Tradit Chinese Med, Basic Med Coll, Shanghai 201203, Peoples R China; [Yan, Jian-Jun; Zhong, Tao] E China Univ Sci & Technol, Ctr Mechatron Engn, Shanghai 200237, Peoples R China; [Lu, Xiong] Shanghai Univ Tradit Chinese Med, Technol & Expt Ctr, Shanghai 201203, Peoples R China	Liu, GP (reprint author), Shanghai Univ Tradit Chinese Med, Basic Med Coll, Shanghai 201203, Peoples R China.	guoping2013penn@gmail.com; jjyan@ecust.edu.cn			National Natural Science Foundation of China [81270050, 30901897, 81173199]	This work was supported by the National Natural Science Foundation of China (Grant nos. 81270050, 30901897, and 81173199).	Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Chinese Medical Association Digestive Diseases Branch, 2007, CHINESE J DIGESTIVE, V24, P58; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Dong Y., 2011, P 12 ANN C INT SPEEC, P2285; Erhan D, 2010, J MACH LEARN RES, V11, P625; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Gao HuaiLin, 2008, China Journal of Chinese Medicine and Pharmacy, V23, P307; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kavukcuoglu K., 2010, ADV NEURAL INFORM PR, V23; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu G. P., 2009, J CHINESE INTEGRATIV, V7, P1222; Liu GP, 2012, EVID-BASED COMPL ALT, DOI 10.1155/2012/135387; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Nasierding G., 2009, P IEEE INT C SYST MA, P4627; Poon H., 2011, P IEEE INT C COMP VI, P689; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; State Bureau of Technical Supervision National Standards of Peoples Republic of China, 1997, NAT STAND PEOPL REP; [苏越 SU Yue], 2009, [中国中西医结合杂志, Chinese Journal of Integrated Traditional and Western Medicine], V29, P398; Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, ICML, P1096; Zheng X. Y., 2004, CHINESE HERBAL MED C	24	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1748-670X	1748-6718		COMPUT MATH METHOD M	Comput. Math. Method Med.		2014									938350	10.1155/2014/938350		8	Mathematical & Computational Biology	Mathematical & Computational Biology	AC9YI	WOS:000332890400001		
J	Liu, WW; Cai, M; Yuan, H; Shi, XB; Zhang, WQ; Liu, J		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		Liu, Wei-Wei; Cai, Meng; Yuan, Hua; Shi, Xiao-Bei; Zhang, Wei-Qiang; Liu, Jia			Phonotactic Language Recognition Based on DNN-HMM Acoustic Model	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		language recognition; DNN-HMM; acoustic model	IDENTIFICATION; SPEECH	A recently introduced deep neural network (DNN) has achieved some unprecedented gains in many challenging automatic speech recognition (ASR) tasks. In this paper deep neural network hidden Markov model (DNN-HMM) acoustic models is introduced to phonotactic language recognition and outperforms artificial neural network hidden Markov model (ANN-HMM) and Gaussian mixture model hidden Markov model (GMM-HMM) acoustic model. Experimental results have confirmed that phonotactic language recognition system using DNN-HMM acoustic model yields relative equal error rate reduction of 28.42%, 14.06%, 18.70% and 12.55%, 7.20%, 2.47% for 30s, 10s, 3s comparing with the ANN-HMM and GMM-HMM approaches respectively on National Institute of Standards and Technology language recognition evaluation (NIST LRE) 2009 tasks.	[Liu, Wei-Wei; Cai, Meng; Yuan, Hua; Zhang, Wei-Qiang; Liu, Jia] Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Liu, WW (reprint author), Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	liu-ww10@hotmail.com	Zhang, Wei-Qiang/A-7088-2008	Zhang, Wei-Qiang/0000-0003-3841-1959			[Anonymous], 2009, 2009 NIST LANGUAGE R; [Anonymous], 2002, HTK BOOK, V3; Cai M., 2013, ASRU; Campbell W. M., 2004, PHONETIC SPEAKER REC; Campbell WM, 2006, COMPUT SPEECH LANG, V20, P210, DOI 10.1016/j.csl.2005.06.003; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Gauvain J. L., 2004, P INT C SPOK LANG PR, P1283; Godfrey J. J., 1992, AC SPEECH SIGN PROC, V1, P517; Han K. J., 2013, P INTERSPEECH; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Li HZ, 2013, P IEEE, V101, P1136, DOI 10.1109/JPROC.2012.2237151; Matejka P., 2005, INTERSPEECH, P2237; Mnih V., 2009, UTML TR, V4; Mohamed AR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4273; Montavon G., 2009, NIPS WORKSH DEEP LEA; Morgan N., 1990, AC SPEECH SIGN PROC, P413; Seide F., 2011, ASRU, P24; Sim KC, 2008, IEEE T AUDIO SPEECH, V16, P1029, DOI 10.1109/TASL.2008.924150; Song Y, 2013, ELECTRON LETT, V49, P1569, DOI 10.1049/el.2013.1721; Stolcke A., 2002, SRILM EXTENSIBLE LAN; Torres-Carrasquillo P. A., 2002, P INT C SPOK LANG PR, P33; Waibel A, 2000, P IEEE, V88, P1297, DOI 10.1109/5.880085; Zhang WQ, 2010, CHINESE J ELECTRON, V19, P124; Zissman M. A., 1996, IEEE T SPEECH AUDIO, V4, P33	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							153	157				5	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600032		
J	Lopes, N; Ribeiro, B				Lopes, Noel; Ribeiro, Bernardete			Towards adaptive learning with improved convergence of deep belief networks on graphics processing units	PATTERN RECOGNITION			English	Article						Deep learning; Deep belief networks; Restricted Boltzmann machines; Contrastive divergence; Adaptive step size; GPU computing		In this paper we focus on two complementary approaches to significantly decrease pre-training time of a deep belief network (DBN). First, we propose an adaptive step size technique to enhance the convergence of the contrastive divergence (CD) algorithm, thereby reducing the number of epochs to train the restricted Boltzmann machine (RBM) that supports the DBN infrastructure. Second, we present a highly scalable graphics processing unit (GPU) parallel implementation of the CD-k algorithm, which boosts notably the training speed. Additionally, extensive experiments are conducted on the MNIST and the HHreco databases. The results suggest that the maximum useful depth of a DBN is related to the number and quality of the training samples. Moreover, it was found that the lower-level layer plays a fundamental role for building successful DBN models. Furthermore, the results contradict the preconceived idea that all the layers should be pre-trained. Finally, it is shown that by incorporating multiple back-propagation (MBP) layers, the DBNs generalization capability is remarkably improved. (C) 2013 Elsevier Ltd. All rights reserved.	[Ribeiro, Bernardete] Univ Coimbra, Dept Informat Engn, P-3000 Coimbra, Portugal		noel@ipg.pt; bribeiro@dei.uc.pt	Ribeiro, Bernardete/	Ribeiro, Bernardete/0000-0002-9770-7672	FCT (Fundacao para a Ciencia e Tecnologia) [PEst-OE/EGE/UI4056/2011]	We would like to express our gratitude to the anonymous reviewers for their comments and suggestions. FCT (Fundacao para a Ciencia e Tecnologia) is acknowledged for funding project PEst-OE/EGE/UI4056/2011.	Almeida L.B., 1997, HDB NEURAL COMPUTATI; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Catanzaro B., 2008, P 25 INT C MACH LEAR, P104, DOI DOI 10.1145/1390156.1390170; Garland M, 2010, COMMUN ACM, V53, P58, DOI 10.1145/1839676.1839694; HALFHILL T. R., 2009, TECHNICAL REPORT; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2010, TECHNICAL REPORT; Kim S.K., 2010, 18 IEEE ANN INT S FI; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Lopes N., 2003, Neural, Parallel & Scientific Computations, V11; Lopes N., 2012, 2012 INT JOINT C NEU; Lopes N., 2010, P 10 INT C HYBR INT, P229; Lopes N, 2011, INT J NEURAL SYST, V21, P31, DOI 10.1142/S0129065711002638; Lopes N., 2012, LECT NOTES COMPUTER, V7441, P511; Lopes Noel, 2011, International Journal of Computer Information Systems and Industrial Management Applications, V3; Ly D. L., 2009, TECHNICAL REPORT; Ly Daniel Le, 2010, IEEE Trans Neural Netw, V21, P1780, DOI 10.1109/TNN.2010.2073481; Markoff J., 2012, INT HERALD TRIBUNE, V24-25, P1; Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757; Raina R., 2009, P 26 ANN INT C MACH, P873; Ranzato M., 2007, ADV NEURAL INFORM PR, V20, P1185; Roux N. L., 2008, NEURAL COMPUT, V20, P1631; Roux N.L., 2010, NEURAL COMPUT, V22, P2192; Ryoo S, 2008, PPOPP'08: PROCEEDINGS OF THE 2008 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P73, DOI 10.1145/1345206.1345220; Silva F.M., 1990, LECT NOTES COMPUTER, V412; Srinivas J., 2012, INT J COMPUTER APPL, V48, P45; Steinkraus D., 2005, P 8 INT C DOC AN REC, V2, P1115; Swersky K., 2010, INF THEOR APPL WORKS, P1; Tony Hey, 2009, 4 PARADIGM DATA INTE; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Zainuddin Z., 2005, INT J COMPUTATIONAL, P172	34	0	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	JAN	2014	47	1			SI		114	127		10.1016/j.patcog.2013.06.029		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	251BT	WOS:000326903500010		
J	Lu, MC; Kang, Y; Han, XM; Yan, GW			IEEE	Lu, Muchao; Kang, Yan; Han, Xiaoming; Yan, Gaowei			Soft Sensor Modeling of Mill Level Based on Deep Belief Network	26TH CHINESE CONTROL AND DECISION CONFERENCE (2014 CCDC)	Chinese Control and Decision Conference		English	Proceedings Paper	26th Chinese Control and Decision Conference (CCDC)	MAY 31-JUN 02, 2014	Changsha, PEOPLES R CHINA	NE Univ, IEEE Ind Elect Chapter, IEEE Harbin Sect Control Syst Soc Chapter, Hunan UnivTechnol, Cent S Univ, IEEE, IEEE Control Syst Soc, Syst Engn Soc China, Chinese Assoc Artificial Intelligence, Chinese Assoc Automat, Tech Comm Control Theory, China & Cent S Univ		mill level; feature extraction; deep belief network; back propagation neural network	PARTIAL LEAST-SQUARES; VIBRATION SIGNAL; BALL MILL; PARAMETERS	Accurate measurement of the mill level is a key factor to improve the ball mill's productive efficiency, safety and economy. Aiming at solving the critical problem of the mill level soft sensor, feature extraction of the processing parameters, a novel method based on Deep Belief Network (DBN) is proposed. DBN is one of the deep learning methods, which focuses on learning deep hierarchical models of data. In this paper, basic features, namely power spectrum density are obtained from the vibration signal of ball mill by Welch's method firstly. T hen DBN is built on the basic features to learn high level deep features. Finally a supervised learning algorithm named back propagation neural network is used to model the relationships between extracted features and mill level. Experimental results indicate that the DBN based method outperforms traditional feature extraction methods.	[Lu, Muchao; Kang, Yan; Han, Xiaoming; Yan, Gaowei] Taiyuan Univ Technol, Coll Informat Engn, Taiyuan 030024, Peoples R China	Lu, MC (reprint author), Taiyuan Univ Technol, Coll Informat Engn, Taiyuan 030024, Peoples R China.	Lumc_cn@163.com; yan2274@163.com; hanxiaoming@tyut.edu.cn; yangaowei@tyut.edu.cn					Behera B, 2007, MINER ENG, V20, P84, DOI 10.1016/j.mineng.2006.05.007; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y, 2011, LECT NOTES ARTIF INT, V6925, P18, DOI 10.1007/978-3-642-24412-4_3; Bengio Y., 2009, FDN TRENDS MACHINE L, V2, P121; Bhaumik A., 2005, WSEAS Transactions on Information Science and Applications, V2; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Hinton G.E., 2012, PRACTICAL GUIDE TRAI, P599; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Noulas A.K., 2008, BELG DUTCH C ART INT, P185; Su ZG, 2008, MINER ENG, V21, P699, DOI 10.1016/j.mineng.2008.01.009; Tang J, 2012, CONTROL ENG PRACT, V20, P991, DOI 10.1016/j.conengprac.2012.03.020; Tang J, 2012, SOFT COMPUT, V16, P1585, DOI 10.1007/s00500-012-0819-3; Tang J., 2010, LECT NOTES ELECT ENG, P803; Tang JA, 2010, MINER ENG, V23, P720, DOI 10.1016/j.mineng.2010.05.001; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; ZENG YG, 1994, MINER ENG, V7, P495, DOI 10.1016/0892-6875(94)90162-7	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1948-9439		978-1-4799-3706-6	CHIN CONT DECIS CONF			2014							189	193				5	Automation & Control Systems	Automation & Control Systems	BB4ZE	WOS:000343577700036		
J	Lv, Q; Dou, Y; Niu, X; Xu, JQ; Li, BL			IEEE	Lv, Qi; Dou, Yong; Niu, Xin; Xu, Jiaqing; Li, Baoliang			CLASSIFICATION OF LAND COVER BASED ON DEEP BELIEF NETWORKS USING POLARIMETRIC RADARSAT-2 DATA	2014 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (IGARSS)	IEEE International Symposium on Geoscience and Remote Sensing IGARSS		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 13-18, 2014	Quebec, CANADA	IEEE, Inst Elect & Elect Engineers, Geoscience & Remote Sensing Soc, Canadian Remote Sensing Soc		Land cover classification; deep learning; Restricted Boltzmann Machines(RBMs); Deep Belief Network(DBN); PolSAR	SAR DATA; ALGORITHM	Urban land use and land cover (LULC) classification is one of the core applications in Geographic Information System(GIS). In this paper, a novel classification approach based on Deep Belief Network(DBN) for detailed urban mapping is proposed. Deep Belief Network (DBN) is a widely investigated and deployed deep learning model. By applying the DBN model, effective spatio-temporal mapping features can be automatically extracted to improve the classification performance. Six-date RADARSAT-2 Polarimetric SAR (PolSAR) data over the Great Toronto Area were used for evaluation. Experimental results showed that the proposed method can outperform SVM and contextual approaches using adaptive MRF.	[Lv, Qi; Dou, Yong; Niu, Xin; Xu, Jiaqing; Li, Baoliang] Natl Univ Def Technol, Sch Comp, Natl Lab Parallel & Distributed Proc, Changsha, Hunan, Peoples R China	Lv, Q (reprint author), Natl Univ Def Technol, Sch Comp, Natl Lab Parallel & Distributed Proc, Changsha, Hunan, Peoples R China.	lvqi@nudt.edu.cn					Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Hinton G, 2010, 2010003 UTML TR; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jones N, 2014, NATURE, V505, P146, DOI 10.1038/505146a; Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16; Moreira A., 2013, IEEE Geoscience and Remote Sensing Magazine, V1, DOI 10.1109/MGRS.2013.2248301; Niu X, 2012, IEEE J-STARS, V5, P1129, DOI 10.1109/JSTARS.2012.2201448; Niu X, 2013, INT J REMOTE SENS, V34, P1, DOI 10.1080/01431161.2012.700133; Niu X, 2014, IEEE GEOSCI REMOTE S, V11, P681, DOI 10.1109/LGRS.2013.2274815; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-6996		978-1-4799-5775-0	INT GEOSCI REMOTE SE			2014												4	Engineering, Electrical & Electronic; Geosciences, Multidisciplinary; Remote Sensing	Engineering; Geology; Remote Sensing	BC0WG	WOS:000349688106135		
J	Marasek, K; Korzinek, D; Brocki, L				Marasek, Krzysztof; Korzinek, Danijel; Brocki, Lukasz			System for Automatic Transcription of Sessions of the Polish Senate	ARCHIVES OF ACOUSTICS			English	Article						large vocabulary speech recognition; language modelling; transcription; transliteration; sub titles		This paper describes research behind a Large-Vocabulary Continuous Speech Recognition (LVCSR) system for the transcription of Senate speeches for the Polish language. The system utilizes several components: a phonetic transcription system, language and acoustic model training systems, a Voice Activity Detector (VAD), a LVCSR decoder, and a subtitle generator and presentation system. Some of the modules relied on already available tools and some had to be made from the beginning but the authors ensured that they used the most advanced techniques they had available at the time. Finally, several experiments were performed to compare the performance of both more modern and more conventional technologies.	[Marasek, Krzysztof; Korzinek, Danijel; Brocki, Lukasz] Polish Japanese Inst Informat Technol, PL-02008 Warsaw, Poland	Marasek, K (reprint author), Polish Japanese Inst Informat Technol, Koszykowa 86, PL-02008 Warsaw, Poland.	kmarasek@pjwstk.edu.pl; danijel@pjwstk.edu.pl; lucas@pjwstk.edu.pl			Polish Ministry of Science and Higher Education [N516 519439]	The work was sponsored by a research grant from the Polish Ministry of Science and Higher Education, no. N516 519439.	Brocki L, 2012, STUD COMPUT INTELL, V390, P243; Brocki L., 2010, 12 INT PHD WORKSH OW; Brocki L, 2006, LECT NOTES ARTIF INT, V4188, P343; Brocki L., 2008, TELEPHONY BASED VOIC; Brocki L., 2010, THESIS POLISH JAPANE; Brocki L., 2014, LECT NOTES COMPUTER, V8502, P355; Brocki L., 2012, FDN INTELLIGENT SYST, P143; Demenko G., 2008, LREC; Eide E, 1996, INT CONF ACOUST SPEE, P346, DOI 10.1109/ICASSP.1996.541103; Federico M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1618; Glass J. R., 2009, LANGUAGE MODELING LI; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; GRAVES A, 2004, BIOL INSPIRED APPROA, V3141, P127, DOI 10.1007/978-3-540-27835-1_10; Hickson I., 2012, WEBVTT LIVING STANDA; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huijbregts M. A. H., 2008, SEGMENTATION DIARIZA; Jelinek F., 1997, STAT METHODS SPEECH; Katsamanis A., 2011, P WORKSH NEW TOOLS M; KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394; Korzinek D, 2007, RECENT ADVANCES IN MECHATRONICS, P87, DOI 10.1007/978-3-540-73956-2_18; Kos M., 1996, SLOPARL SLOVENIAN PA; Lee A., 2001, JULIUS OPEN SOURCE R; Loof J., 2006, INTERSPEECH; Marasek K., 2012, P IWSLT 2012; Marasek K, 2009, LECT NOTES COMPUT SC, V5070, P273; Michalewicz Z., 1996, GENETIC ALGORITHMS D; Milkowski M., 2012, POLISH LANGUAGE DIGI; Mori R. D., 1998, SPOKEN DIALOGUE COMP; Povey D., 2011, IEEE 2011 WORKSH AUT; Povey D, 2010, INT CONF ACOUST SPEE, P4330, DOI 10.1109/ICASSP.2010.5495662; PRAZAK A, 2006, TEXT SPEECH DIALOGUE, V4188, P501, DOI 10.1007/11846406_63; Przepiorkowski A., 2012, NARODOWY KORPUS JEZY; Psutka JV, 2007, LECT NOTES ARTIF INT, V4629, P431; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Robinson T., 1996, AUTOMATIC SPEECH SPE, P233; Romero-Fresco P., 2011, SUBTITLING SPEECH RE; Stolcke A., 2002, INTERSPEECH; Vesely K., 2013, SEQUENCE DISCRIMINAT; Wells J.C, 2013, POLISH SAMPA; Young S., 2002, HTK BOOK, P3	40	0	0	POLSKA AKAD NAUK, POLISH ACAD SCIENCES, INST FUNDAMENTAL TECH RES PAS	WARSZAWA	PL DEFILAD 1, WARSZAWA, 00-901, POLAND	0137-5075	2300-262X		ARCH ACOUST	Arch. Acoust.		2014	39	4					501	509		10.2478/aoa-2014-0054		9	Acoustics	Acoustics	CC4AN	WOS:000350293000008		
J	McCoppin, R; Rizki, M		Kolodny, MA		McCoppin, Ryan; Rizki, Mateen			Deep learning for image classification	GROUND/AIR MULTISENSOR INTEROPERABILITY, INTEGRATION, AND NETWORKING FOR PERSISTENT ISR V	Proceedings of SPIE		English	Proceedings Paper	5th Conference on Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR as part of the SPIE Defense and Security Sensing Symposium	MAY 05-06, 2014	Baltimore, MD	SPIE		gender recognition; convolutional restricted Boltzmann machine; electro-optical; deep learning; unsupervised feature learning; MNIST; SWAG		This paper provides an overview of deep learning and introduces the several subfields of deep learning including a specific tutorial of convolutional neural networks. Traditional methods for learning image features are compared to deep learning techniques. In addition, we present our preliminary classification results, our basic implementation of a convolutional restricted Boltzmann machine on the Mixed National Institute of Standards and Technology database (MNIST), and we explain how to use deep learning networks to assist in our development of a robust gender classification system.	[McCoppin, Ryan; Rizki, Mateen] Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA	McCoppin, R (reprint author), Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.						Bastien F., 2010, ARXIV10093589; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Ciresan D, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1918, DOI 10.1109/IJCNN.2011.6033458; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Hinton G, 2010, MOMENTUM, V9, P926; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Krizhevsky A., 2012, NIPS, V1, P4; Le Q., 2012, P ICML 2012; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; McCoppin R, 2012, PROC NAECON IEEE NAT, P134; McCoppin R, 2013, PROC SPIE, V8751, DOI 10.1117/12.2018903; Ngiam J., 2011, P 28 INT C MACH LEAR, P265; Rude H., 2014, P SPIE, V9079; Salakhutdinov R., 2009, INT C ART INT STAT, P448	16	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-1-62841-016-7	PROC SPIE			2014	9079								90790T	10.1117/12.2054045		10	Engineering, Electrical & Electronic; Optics; Telecommunications	Engineering; Optics; Telecommunications	BB2ZN	WOS:000342580900023		
J	Nakashika, T; Takiguchi, T; Ariki, Y			IEEE	Nakashika, Toru; Takiguchi, Tetsuya; Ariki, Yasuo			VOICE CONVERSION IN TIME-INVARIANT SPEAKER-INDEPENDENT SPACE	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Voice conversion; conditional restricted Boltzmann machine; deep learning; speaker specific features	SPEECH RECOGNITION	In this paper, we present a voice conversion (VC) method that utilizes conditional restricted Boltzmann machines (CRBMs) for each speaker to obtain time-invariant speaker-independent spaces where voice features are converted more easily than those in an original acoustic feature space. First, we train two CRBMs for a source and target speaker independently using speaker-dependent training data (without the need to parallelize the training data). Then, a small number of parallel data are fed into each CRBM and the high-order features produced by the CRBMs are used to train a concatenating neural network (NN) between the two CRBMs. Finally, the entire network (the two CRBMs and the NN) is fine-tuned using the acoustic parallel data. Through voice-conversion experiments, we confirmed the high performance of our method in terms of objective and subjective evaluations, comparing it with conventional GMM, NN, and speaker-dependent DBN approaches.	[Nakashika, Toru; Takiguchi, Tetsuya; Ariki, Yasuo] Kobe Univ, Grad Sch Syst Informat, Nada Ku, Kobe, Hyogo 6578501, Japan	Nakashika, T (reprint author), Kobe Univ, Grad Sch Syst Informat, Nada Ku, 1-1 Rokkodai, Kobe, Hyogo 6578501, Japan.	nakashika@me.cs.scitec.kobe-u.ac.jp; takigu@kobe-u.ac.jp; ariki@kobe-u.ac.jp					DENG L, 2001, ACOUST SPEECH SIG PR, P301; Desai S, 2009, INT CONF ACOUST SPEE, P3893, DOI 10.1109/ICASSP.2009.4960478; Freund Y., 1994, UNSUPERVISED LEARNIN; Gray R. M., 1984, IEEE ASSP Magazine, V1, DOI 10.1109/MASSP.1984.1162229; Helander E, 2010, IEEE T AUDIO SPEECH, V18, P912, DOI 10.1109/TASL.2010.2041699; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; KAIN A, 1998, ACOUST SPEECH SIG PR, P285; Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514; Kunikoshi A., 2009, P INTERSPEECH, P308; KUREMATSU A, 1990, SPEECH COMMUN, V9, P357, DOI 10.1016/0167-6393(90)90011-W; Milner B., 2002, P ICSLP DENV CO US, P2421; Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007; Nakashika T., 2013, P INTERSPEECH, P369; Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472; Taylor Graham W., 2006, ADV NEURAL INFORM PR, P1345; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; VALBRET H, 1992, SPEECH COMMUN, V11, P175, DOI 10.1016/0167-6393(92)90012-V; Veaux C., 2011, P INTERSPEECH, P2765; Zhizheng Wu, 2013, IEEE CHIN SUMM INT C	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655307186		
J	Ni, CJ; Chen, NF; Ma, B		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		Ni, Chongjia; Chen, Nancy F.; Ma, Bin			Multiple Time-Span Feature Fusion for Deep Neural Network Modeling	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		Feature representation; deep bottleneck; deep hierarchical bottleneck; deep neural network (DNN); Hidden Markov model (HMM)	SPEECH	In this paper, we exploit long term information from multiple time-spans for automatic speech recognition. The multiple time-span information is encoded into three different feature streams: speaker-adaptation-transformed features, deep bottleneck features and deep hierarchical bottleneck features. By combining three different time-spans in discriminative acoustic modeling, the character/syllable error rate improves for Mandarin and Vietnamese conversational telephone speech recognition. We obtain 0.8% and 1.9% absolute over DNN-HMM baselines in character error rate and syllable error rate for Mandarin and Vietnamese, respectively. Further analysis also suggests that our proposed feature fusion approach is able to encode finer-grain temporal information than directly using input features of long time-spans in DNN-HMM baselines.	[Ni, Chongjia; Chen, Nancy F.; Ma, Bin] ASTAR, Inst Infocomm Res I2R, Singapore, Singapore	Ni, CJ (reprint author), ASTAR, Inst Infocomm Res I2R, Singapore, Singapore.	nicj@i2r.a-star.edu.sg; nfychen@i2r.a-star.edu.sg; mabin@i2r.a-star.edu.sg					Dahl George E., 2012, IEEE T AUDIO SPEECH, V20, P33; Gillick L., 1989, P ICASSP, V1, P532; Grezl F, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P470, DOI 10.1109/ASRU.2013.6707775; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Haeb-Umbach R., 1992, P IEEE INT C AC SPEE, V1, P13; Harper M., IARPA SOLICITATION I; Hermansky H., 1999, P ASRU KEYST CO US D; HERMANSKY H, 1999, ACOUST SPEECH SIG PR, P289; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2012, P INTERSPEECH; Kingsbury B., 2012, P INTERSPEECH; Liu Y., P ISCSLP, P724; Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301; Plahl C, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1197; Povey D., 2011, IEEE 2011 WORKSH AUT; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; Sainath TN, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4153; Seide F., 2011, P INTERSPEECH; Tuske Z, 2013, INT CONF ACOUST SPEE, P6970, DOI 10.1109/ICASSP.2013.6639013; Tuske Zoltan, 2012, P INTERSPEECH; Valente F., 2010, P INT, P2630; Vesely K., 2013, P INTERSPEECH; Weng C., P ICASSP2013; YAN ZJ, 2013, P ICASSP, P6940; Yu D., 2011, P INTERSPEECH, P237	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							138	142				5	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600029		
J	Niu, JW; Qian, YM; Yu, K		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		Niu, Jianwei; Qian, Yanmin; Yu, Kai			Acoustic Emotion Recognition using Deep Neural Network	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		emotion recognition; deep neural networks; restricted Boltzmann machine; gaussian mixture models	LEARNING ALGORITHM; CEPSTRUM	Traditionally acoustic emotion recognition system has been using Gaussian Mixture Models (GMMs) for classification. However, the Gaussian Mixture Models do not make good use of multiple frames of input data and can not exploit the high-dimensional dependencies of features efficiently, thus it's hard to improve the recognition accuracy for achieving a better result. Deep neural networks (DNNs) are artificial neural networks having more than one hidden layer, which are first pre-trained layer by layer and then fine-tuned using back propagation algorithm. The well-trained deep neural networks are capable of modeling complex and non-linear features of input training data and can better predict the probability distribution over classification labels. In this paper, we used DNNs to replace GMMs in the recognition system architecture and conducted a series of experiments using neural networks that involved deep learning. Six discrete emotional states are classified based on these two kinds of classifiers. Our work focused on the performance of DNNs and experiments showed that the best recognition rate achieved by DNN-based system increased by 8.2 percentage points compared with baselines GMMs.	[Niu, Jianwei; Qian, Yanmin; Yu, Kai] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Key Lab Shanghai Educ Commiss Intelligent Interac, Shanghai 200030, Peoples R China	Niu, JW (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Key Lab Shanghai Educ Commiss Intelligent Interac, Shanghai 200030, Peoples R China.	tianzimai@sjtu.edu.cn; yanminqian@sjtu.edu.cn; kai.yu@sjtu.edu.cn					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bourlard H., 1994, CONNECTIONIST SPEECH, V247; Bozkurt Elif, 2009, INTERSPEECH, P324; Brueckner Raymond, 2012, INTERSPEECH; Cheng Xianglin, 2012, 2 INT C COMP APPL SY; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton G, 2010, MOMENTUM, V9, P926; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kim Y, 2013, INT CONF ACOUST SPEE, P3687; LE D, 2013, AUT SPEECH REC UND A, P216; Mohamed A-R, 2012, AUDIO SPEECH LANGUAG, V20, P14; Neiberg Daniel, 2006, INTERSPEECH; NOLL AM, 1967, J ACOUST SOC AM, V41, P293, DOI 10.1121/1.1910339; Oppenheim AV, 2004, IEEE SIGNAL PROC MAG, V21, P95, DOI 10.1109/MSP.2004.1328092; SCHMIDT EM, 2011, APPL SIGN PROC AUD A, P65; Smolensky P., 1986, INFORM PROCESSING DY; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							128	132				5	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600027		
J	Nogueira, RF; Lotufo, RD; Machado, RC			IEEE	Nogueira, Rodrigo Frassetto; Lotufo, Roberto de Alencar; Machado, Rubens Campos			Evaluating software-based fingerprint liveness detection using Convolutional Networks and Local Binary Patterns	2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS			English	Proceedings Paper	5th IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS)	OCT 17, 2014	Rome, ITALY	IEEE, IEEE Italy Sect Biometr Council Chapter, IEEE Italy Sect, IEEE Italy Sect Sys Council Chapter		fingerprint; liveness; convolutional networks; local binary patterns; data augmentation; support vector machines	ADAPTIVE HISTOGRAM EQUALIZATION; CLASSIFICATION; ALGORITHMS	With the growing use of biometric authentication systems in the past years, spoof fingerprint detection has become increasingly important. In this work, we implement and evaluate two different feature extraction techniques for software-based fingerprint liveness detection: Convolutional Networks with random weights and Local Binary Patterns. Both techniques were used in conjunction with a Support Vector Machine (SVM) classifier. Dataset Augmentation was used to increase classifier's performance and a variety of preprocessing operations were tested, such as frequency filtering, contrast equalization, and region of interest filtering. The experiments were made on the datasets used in The Liveness Detection Competition of years 2009, 2011 and 2013, which comprise almost 50,000 real and fake fingerprints' images. Our best method achieves an overall rate of 95.2% of correctly classified samples - an improvement of 35% in test error when compared with the best previously published results.	[Nogueira, Rodrigo Frassetto; Lotufo, Roberto de Alencar] Univ Estadual Campinas, DCA, Campinas, SP, Brazil; [Machado, Rubens Campos] Ctr Tecnol Informacao Renato Archer CTI, Campinas, SP, Brazil	Nogueira, RF (reprint author), Univ Estadual Campinas, DCA, Campinas, SP, Brazil.	rodrigonogueira4@gmail.com; lotufo@unicamp.br; rubens.campos.machado@gmail.com	Lotufo, Roberto/C-1496-2009	Lotufo, Roberto/0000-0002-5652-0852			Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469; Antonelli A, 2006, IEEE T INF FOREN SEC, V1, P360, DOI 10.1109/TIFS.2006.879289; Baldisserra D., 2005, ADV BIOMETRICS, V3832, P265, DOI 10.1007/11608288_36; Boureau Y.-L., 2010, P 27 INT C MACH LEAR; Cao LJ, 2003, NEUROCOMPUTING, V55, P321, DOI 10.1016/S0925-2312(03)00433-8; Chen Y., 2005, P IEEE BIOM S, P19; Chiachia G., 1998, [No title captured], Patent No. 5737439; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Ciresan D. C., 2011, ARXIV11020183; Coates A., 2011, INT C ART INT STAT; Coli P., 2008, INT J IMAGE GRAPHICS, V8, P495, DOI 10.1142/S0219467808003209; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024; Ghiani L., 2012, P IEEE INT C PATT RE; Ghiani L., 2013, P IEEE INT C BIOM TH; Ghiani L., 2013, BIOM ICB 2013 INT C, P1; Goodfellow I.J., 2013, ARXIV13024389; Gragnaniello D., 2014, PATTERN RECOGNITION; Gragnaniello D., 2013, IEEE WORKSH BIOM MEA; Hadid A., 2004, COMPUTER VISION PATT; Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarmen A., 2009, NATURAL IMAGE STAT, P93; Jain AK, 2007, IEEE T PATTERN ANAL, V29, P15, DOI 10.1109/TPAMI.2007.250596; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jia X., 2013, INFORM SCI; Krizhevsky A., 2012, NIPS, V24; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253; LeCun Y., 1989, CONNECTIONS PERSPECT; Lei H., 2005, FEATURE SELECTION DA, P72; Lyu S., 2008, COMP VIS PATT REC 20; Lyu S., 2010, NIPS; Marcialis GL, 2009, LECT NOTES COMPUT SC, V5716, P12, DOI 10.1007/978-3-642-04146-4_4; Martinsson PG, 2011, APPL COMPUT HARMON A, V30, P47, DOI 10.1016/j.acha.2010.02.003; Nair V., 2010, P 27 INT C MACH LEAR; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pinto N., 2008, PLOS COMPUTATIONAL B; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; Saxe A., 2011, P 28 INT C MACH LEAR, P1089; Simard P. Y., 2013, ICDAR, V3, P958; Tan B., 2006, DEF SEC S INT SOC OP; Wan L., 2013, P INT C MACH LEARN I, V28, P1058; Wiehe A., 2004, ATTACKING FINGERPRIN; Yambay D., 2012, BIOM ICB 2012 5 IAPR, P208; Zeiler MD, 2013, ARXIV13013557; ZIMMERMAN JB, 1988, IEEE T MED IMAGING, V7, P304, DOI 10.1109/42.14513	46	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-5176-5				2014							22	29				8	Computer Science, Theory & Methods; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BC4MT	WOS:000352734000004		
J	Pikrakis, A			IEEE	Pikrakis, Aggelos			Unsupervised Audio Segmentation based on Restricted Boltzmann Machines	5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014			English	Proceedings Paper	5th International Conference on Information, Intelligence, Systems and Applications (IISA)	JUL 07-09, 2014	Chania, GREECE	Inst Elect & Elect Engineers, Biol & Artificial Intelligence Fdn, Univ Piraeus				In this paper the Conditional Restricted Boltzmann Machine (CRBM) is employed in the context of unsupervised audio segmentation. The CRBM acts as a temporal modeling method and learns, from a maximum likelihood perspective, the temporal relationships of the feature vectors that have been extracted from a large corpus of training data. After the CRBM has been trained, we quantify the correlation of the activation of the neurons of the hidden layer for successive feature vectors by means of an appropriately defined similarity function. A simple thresholding scheme is then applied on the output of the similarity function to segment automatically the audio recording. Our experiments have been carried out on a large corpus of documentaries. We provide an interpretation of the segmentation results and comment on the segmentation efficiency of the method.	Univ Piraeus, Sch Informat & Commun Technol, Dept Informat, Piraeus, Greece	Pikrakis, A (reprint author), Univ Piraeus, Sch Informat & Commun Technol, Dept Informat, Piraeus, Greece.	pikrakis@unipi.gr					Cont A, 2011, IEEE T AUDIO SPEECH, V19, P837, DOI 10.1109/TASL.2010.2066266; Deng L, 2013, INT CONF ACOUST SPEE, P8599; Dessein A, 2013, IEEE SIGNAL PROC LET, V20, P331, DOI 10.1109/LSP.2013.2247039; Giannakopoulos T., 2014, INTRO AUDIO ANAL MAT; Giannakopoulos T., 2008, PATTERN RECOGN, P1; Giannakopoulos T, 2012, IEEE T AUDIO SPEECH, V20, P1913, DOI 10.1109/TASL.2012.2191285; Harchaoui Z, 2009, INT CONF ACOUST SPEE, P1665, DOI 10.1109/ICASSP.2009.4959921; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Rabiner L. R., 2011, THEORY APPL DIGITAL; Sainath TN, 2007, INT CONF ACOUST SPEE, P209; Slaney M., 1998, INTERVAL RES CORPORA, V10, P1998; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA							2014							311	314				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BB7PA	WOS:000345861900089		
J	Polanco, C; Buhse, T; Castanon-Gonzalez, JA; Samaniego, JL				Polanco, Carlos; Buhse, Thomas; Alberto Castanon-Gonzalez, Jorge; Lino Samaniego, Jose			Possible computational filter to detect proteins associated to influenza A subtype H1N1	ACTA BIOCHIMICA POLONICA			English	Article						Polarity Index Method; influenza A virus subtype H1N1; drug design; QSAR method	HIDDEN MARKOV-MODELS; HEMAGGLUTININ GENE; NUCLEOTIDE-SEQUENCE; ANTIBACTERIAL PEPTIDES; PATTERN-RECOGNITION; VIRUS; DATABASE	The design of drugs with bioinformatics methods to identify proteins and peptides with a specific toxic action is increasingly recurrent. Here, we identify toxic proteins towards the influenza A virus subtype H1N1 located at the UniProt database. Our quantitative structure-activity relationship (QSAR) approach is based on the analysis of the linear peptide sequence with the so-called Polarity Index Method that shows an efficiency of 90% for proteins from the Uniprot Database. This method was exhaustively verified with the APD2, CPP-site, Uniprot, and AmyPDB databases as well as with the set of antibacterial peptides studied by del Rio et al. and Oldfield etal.	[Polanco, Carlos; Alberto Castanon-Gonzalez, Jorge; Lino Samaniego, Jose] Univ Anahuac, Fac Ciencias Salud, Col Lomas Anahuac, Huixquilucan Es, Mexico; [Buhse, Thomas] Univ Autonoma Estado Morelos, Ctr Invest Quim, Cuernavaca, Morelos, Mexico	Polanco, C (reprint author), Univ Anahuac, Fac Ciencias Salud, Col Lomas Anahuac, Huixquilucan Es, Mexico.	polanco@unam.mx			Computer Science Department at the Institute for Nuclear Sciences of the National Autonomous University of Mexico; Mexican-French bilateral research grant CONACYT [188689]; ANR [12-IS07-0006]	The authors thank the Computer Science Department at the Institute for Nuclear Sciences of the National Autonomous University of Mexico for support. We also gratefully acknowledge financial support received form the Mexican-French bilateral research grant CONACYT (188689) - ANR (12-IS07-0006), and Concepcion Cells Juarez whose suggestions and proof-reading have greatly improved the original manuscript.	ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; ASAKURA T, 1994, P NATL ACAD SCI USA, V91, P12589, DOI 10.1073/pnas.91.26.12589; AUSTIN FJ, 1990, J GEN VIROL, V71, P2471, DOI 10.1099/0022-1317-71-10-2471; Barik S, 2012, BMC MED, V10, DOI 10.1186/1741-7015-10-104; BEKLEMISHEV AB, 1986, BIOORG KHIM+, V12, P375; Bolintineanu DS, 2011, PEPTIDES, V32, P188, DOI 10.1016/j.peptides.2010.10.006; BOTH GW, 1983, P NATL ACAD SCI-BIOL, V80, P6996, DOI 10.1073/pnas.80.22.6996; Chowell G, 2011, PLOS MED, V8, DOI 10.1371/journal.pmed.1000436; CONCANNON P, 1984, J VIROL, V49, P276; del Rio G, 2001, FEBS LETT, V494, P213, DOI 10.1016/S0014-5793(01)02348-1; Gautam A, 2012, DATABASE OXFORD; Gonzalez-Diaz H, 2005, BIOORG MED CHEM LETT, V15, P5088, DOI 10.1016/j.bmcl.2005.07.056; Hagen JB, 2000, NAT REV GENET, V1, P231, DOI 10.1038/35042090; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HITI AL, 1981, VIROLOGY, V111, P113, DOI 10.1016/0042-6822(81)90658-9; Ito T, 1998, J VIROL, V72, P7367; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; LAMB RA, 1981, P NATL ACAD SCI-BIOL, V78, P4170, DOI 10.1073/pnas.78.7.4170; Lee KS, 2008, IEEE T BIO-MED ENG, V55, P930, DOI 10.1109/TBME.2008.915658; LUOH SM, 1992, J VIROL, V66, P1066; Magrane M, 2011, UNIPROT KNOWLEDGEBAS; Matsunaga N, 2003, J ORG CHEM, V68, P3158, DOI 10.1021/jo020650g; Mohamed R, 2009, VIROL J, V6, DOI [10.1186/1743-422X-6-74, DOI 10.1186/1743-422X-6-74]; Nishiura H, 2011, EUR J EPIDEMIOL, V26, P583, DOI 10.1007/s10654-011-9597-y; Oldfield CJ, 2005, BIOCHEMISTRY-US, V44, P1989, DOI 10.1021/bi047993o; Pawlicki, 2008, BMC BIOINFORMATICS, V10, P273; Polanco C, 2013, ACTA BIOCHIM POL, V60, P175; Polanco C, 2012, INT J PEPT, V2012, P58502, DOI 10.1155/2012/585027.; Polanco C, 2013, MODEL COMPUT MATH ME, V2013; Polanco C, 2009, ACTA BIOCHIM POL, V56, P167; Polanco C, 2013, ACTA BIOCHIM POL, V60, P183; Rabiner L. R., 1989, P IEEE, V77; ROTA PA, 1987, VIROLOGY, V161, P269, DOI 10.1016/0042-6822(87)90118-8; Taubenberger JK, 1997, SCIENCE, V275, P1793, DOI 10.1126/science.275.5307.1793; Thakur N, 2012, NUCLEIC ACIDS RES, V40, pW199, DOI 10.1093/nar/gks450; Wang GS, 2009, NUCLEIC ACIDS RES, V37, pD933, DOI 10.1093/nar/gkn823; Wang XL, 2013, STAT MED, V32, P2292, DOI 10.1002/sim.5658; Wenjun M, 2009, J MOL GENET MED, V3, P158; WINTER G, 1980, NUCLEIC ACIDS RES, V8, P1965, DOI 10.1093/nar/8.9.1965; WINTER G, 1981, NATURE, V292, P72, DOI 10.1038/292072a0; YAMNIKOVA SS, 1993, VIROLOGY, V197, P558, DOI 10.1006/viro.1993.1629	41	0	0	ACTA BIOCHIMICA POLONICA	WARSAW	PASTEURA 3, 02-093 WARSAW, POLAND	0001-527X	1734-154X		ACTA BIOCHIM POL	Acta Biochim. Pol.		2014	61	4					693	698				6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	AY2RC	WOS:000347435900010	25379569	
J	Qi, Y; Wang, YM; Zheng, XX; Wu, ZH			IEEE	Qi, Yu; Wang, Yueming; Zheng, Xiaoxiang; Wu, Zhaohui			ROBUST FEATURE LEARNING BY STACKED AUTOENCODER WITH MAXIMUM CORRENTROPY CRITERION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Unsupervised feature learning; stacked autoencoder; correntropy; deep learning	RECOGNITION	Unsupervised feature learning with deep networks has been widely studied in the recent years. Despite the progress, most existing models would be fragile to non-Gaussian noises and outliers due to the criterion of mean square error (MSE). In this paper, we propose a robust stacked autoencoder (R-SAE) based on maximum correntropy criterion (MCC) to deal with the data containing non-Gaussian noises and outliers. By replacing MSE with MCC, the anti-noise ability of stacked autoencoder is improved. The proposed method is evaluated using the MNIST benchmark dataset. Experimental results show that, compared with the ordinary stacked autoencoder, the R-SAE improves classification accuracy by 14% and reduces the reconstruction error by 39%, which demonstrates that R-SAE is capable of learning robust features on noisy data.	[Qi, Yu; Wang, Yueming; Zheng, Xiaoxiang] Zhejiang Univ, Qiushi Acad Adv Studies, Hangzhou 310003, Zhejiang, Peoples R China	Wang, YM (reprint author), Zhejiang Univ, Qiushi Acad Adv Studies, Hangzhou 310003, Zhejiang, Peoples R China.	ymingwang@zju.edu.cn					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Boureau Y., 2007, ADV NEURAL INFORM PR, P1185; Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46; He R, 2011, IEEE T IMAGE PROCESS, V20, P1485, DOI 10.1109/TIP.2010.2103949; He R, 2011, NEURAL COMPUT, V23, P2074; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton R., 2006, SCIENCE, V313, P504; Jeong KH, 2009, PATTERN RECOGN, V42, P871, DOI 10.1016/j.patcog.2008.09.023; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu WF, 2006, IEEE IJCNN, P4919; Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Xie J., 2012, ADV NEURAL INFORM PR, V25, P350	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655306151		
J	Qi, Y; Wang, YM; Zhang, JM; Zhu, JM; Zheng, XX				Qi, Yu; Wang, Yueming; Zhang, Jianmin; Zhu, Junming; Zheng, Xiaoxiang			Robust Deep Network with Maximum Correntropy Criterion for Seizure Detection	BIOMED RESEARCH INTERNATIONAL			English	Article							EPILEPTIC SEIZURES; NEURAL-NETWORKS; SCALP EEG; RECOGNITION; ALGORITHM; ONSET	Effective seizure detection from long-term EEG is highly important for seizure diagnosis. Existing methods usually design the feature and classifier individually, while little work has been done for the simultaneous optimization of the two parts. This work proposes a deep network to jointly learn a feature and a classifier so that they could help each other to make the whole system optimal. To deal with the challenge of the impulsive noises and outliers caused by EMG artifacts in EEG signals, we formulate a robust stacked autoencoder (R-SAE) as a part of the network to learn an effective feature. In R-SAE, the maximum correntropy criterion (MCC) is proposed to reduce the effect of noise/outliers. Unlike the mean square error (MSE), the output of the new kernel MCC increases more slowly than that of MSE when the input goes away from the center. Thus, the effect of those noises/outliers positioned far away from the center can be suppressed. The proposed method is evaluated on six patients of 33.6 hours of scalp EEG data. Our method achieves a sensitivity of 100% and a specificity of 99%, which is promising for clinical applications.	[Qi, Yu; Wang, Yueming; Zheng, Xiaoxiang] Zhejiang Univ, Qiushi Acad Adv Studies, Hangzhou 310027, Zhejiang, Peoples R China; [Qi, Yu; Wang, Yueming] Zhejiang Univ, Dept Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China; [Zhang, Jianmin; Zhu, Junming] Zhejiang Univ, Coll Med, Affiliated Hosp 2, Hangzhou 310000, Zhejiang, Peoples R China; [Zheng, Xiaoxiang] Zhejiang Univ, Dept Biomed Engn, Hangzhou 310027, Zhejiang, Peoples R China	Wang, YM (reprint author), Zhejiang Univ, Qiushi Acad Adv Studies, Hangzhou 310027, Zhejiang, Peoples R China.	ymingwang@zju.edu.cn			National Natural Science Foundation of China [61031002, 61103107]; National 973 Program [2013CB329500]; National High Technology Research and Development Program of China [2012AA020408]; Zhejiang Provincial Science and Technology Project [2013C03045-3]	This research was supported by Grants from the National Natural Science Foundation of China (no. 61031002), National 973 Program (no. 2013CB329500), National High Technology Research and Development Program of China (no. 2012AA020408), National Natural Science Foundation of China (no. 61103107), and Zhejiang Provincial Science and Technology Project (no. 2013C03045-3).	Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Boureau Y., 2007, P ADV NEUR INF PROC, P1185; Fisher RS, 2005, EPILEPSIA, V46, P470, DOI 10.1111/j.0013-9580.2005.66104.x; Ghosh-Dastidar S, 2008, IEEE T BIO-MED ENG, V55, P512, DOI 10.1109/TBME.2007.905490; He R, 2011, IEEE T IMAGE PROCESS, V20, P1485, DOI 10.1109/TIP.2010.2103949; He R, 2011, NEURAL COMPUT, V23, P2074; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jeong KH, 2009, PATTERN RECOGN, V42, P871, DOI 10.1016/j.patcog.2008.09.023; Jouny CC, 2012, CLIN NEUROPHYSIOL, V123, P658, DOI 10.1016/j.clinph.2011.08.003; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; Lee H., 2009, P 23 ANN C NEUR INF, V9, P1096; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Liu DR, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/638534; Liu DR, 2008, IEEE INT C NETW SENS, P351; Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065; Majumdar KK, 2011, IEEE T NEUR SYS REH, V19, P356, DOI 10.1109/TNSRE.2011.2157525; Mormann F, 2007, BRAIN, V130, P314, DOI 10.1093/brain/awl241; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Rummel C, 2010, J NEUROSCI METH, V191, P94, DOI 10.1016/j.jneumeth.2010.05.022; Saab ME, 2005, CLIN NEUROPHYSIOL, V116, P427, DOI 10.1016/j.clinph.2004.08.004; Salakhutdinov R, 2013, IEEE T PATTERN ANAL, V35, P1958, DOI 10.1109/TPAMI.2012.269; Santaniello S, 2011, EPILEPSY BEHAV, V22, pS49, DOI 10.1016/j.yebeh.2011.08.041; Schindler K, 2007, BRAIN, V130, P65, DOI 10.1093/brain/awl304; SCHINDLER KA, 2008, CHAOS, V18; Scholkopft B., 1999, FISHER DISCRIMINANT; Silverman B., 1986, DENSITY ESTIMATION S, V26; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Weifeng L., 2006, P INT JOINT C NEUR N, P4919; Xie J., 2012, P 26 ANN C NEUR INF, V25, P350; Yadav R, 2012, IEEE T BIO-MED ENG, V59, P1871, DOI 10.1109/TBME.2012.2190601; Zandi AS, 2010, IEEE T BIO-MED ENG, V57, P1639, DOI 10.1109/TBME.2010.2046417	34	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	2314-6133	2314-6141		BIOMED RES INT	Biomed Res. Int.		2014									703816	10.1155/2014/703816		10	Biotechnology & Applied Microbiology; Medicine, Research & Experimental	Biotechnology & Applied Microbiology; Research & Experimental Medicine	AL5RK	WOS:000339190700001		
J	Qian, L; Shi, XJ			IEEE	Qian, Long; Shi, Xingjian			Denoising Predictive Sparse Decomposition	2014 INTERNATIONAL CONFERENCE ON BIG DATA AND SMART COMPUTING (BIGCOMP)	International Conference on Big Data and Smart Computing		English	Proceedings Paper	International Conference on Big Data and Smart Computing (BIGCOMP)	JAN 15-17, 2014	Bangkok, THAILAND			Sparse coding; denoising; predictive sparse decomposition; object recognition	OVERCOMPLETE REPRESENTATIONS; LEARNING SPARSE; NATURAL IMAGES	Recent years have witnessed the great success of sparse coding in many areas, including data mining, machine learning, and computer vision. Sparse coding provides a class of unsupervised algorithms for learning a set of over-complete basis functions, allowing to reconstruct the original signal by linearly combining a small subset of the bases. A shortcoming of most existing sparse coding algorithms is that they need to do some sort of iterative minimization to inference the sparse representations for test points, which means that it's not convenient for these algorithms to perform out-of-sample extension. By additionally training a non-linear regressor that maps input to sparse representation during the training procedure, predictive sparse decomposition (PSD) can naturally be used for out-of-sample extension. Hence, PSD has recently become one of the most famous learning algorithms for sparse coding. However, when the training set is not large enough to capture the variations of the sample, PSD may not achieve satisfactory performance in real applications. In this paper, we propose a novel model, called denoising PSD (DPSD), for robust sparse coding. Experiments on real visual object recognition tasks show that DPSD can dramatically outperform PSD in real applications.	[Qian, Long; Shi, Xingjian] Shanghai Jiao Tong Univ, Shanghai Key Lab Scalable Comp & Syst, Shanghai 200030, Peoples R China	Qian, L (reprint author), Shanghai Jiao Tong Univ, Shanghai Key Lab Scalable Comp & Syst, Shanghai 200030, Peoples R China.	isaiah@sjtu.edu.cn; sxjscience@sjtu.edu.cn					Aharon M., 2005, INT SOC OPT PHOT; [Anonymous], 2013, INT SOC OPT PHOT; Olshausen BA, 2003, IEEE IMAGE PROC, P41; Bengio Y., 2006, NIPS, P153; Bo L., 2013, IEEE C COMP VIS PATT; Bristow H., 2013, IEEE C COMP VIS PATT; Efron B, 2004, ANN STAT, V32, P407; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kavukcuoglu K., 2008, TECHNICAL REPORT; Kavukcuoglu K., 2010, 24 ANN C NEUR INF PR, V23, P1090; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H, 2006, P NEUR INF PROC SYST, V19, P801; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Mairal J., 2008, IEEE COMP SOC C COMP; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Martin D., 2001, P 8 INT C COMP VIS, V2, P416, DOI 10.1109/ICCV.2001.937655; Murray JF, 2007, J VLSI SIG PROC SYST, V46, P1, DOI 10.1007/s11265-006-0003-z; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Ren X., 2013, IEEE C COMP VIS PATT; Rifai S., 2011, P 28 INT C MACH LEAR, P833; Rozell CJ, 2008, NEURAL COMPUT, V20, P2526, DOI 10.1162/neco.2008.03-07-486; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Yuan C., 2013, IEEE C COMP VIS PATT	30	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2375-933X		978-1-4799-3919-0	INT CONF BIG DATA			2014							223	228				6	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BC1AI	WOS:000349894500045		
J	Qian, Y; Fan, YC; Hu, WP; Soong, FK			IEEE	Qian, Yao; Fan, Yuchen; Hu, Wenping; Soong, Frank K.			ON THE TRAINING ASPECTS OF DEEP NEURAL NETWORK (DNN) FOR PARAMETRIC TTS SYNTHESIS	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Speech Synthesis; HMM; DNN; TTS		Deep Neural Network (DNN), which can model a long-span, intricate transform compactly with a deep-layered structure, has recently been investigated for parametric ITS synthesis with a fairly large corpus (33,000 utterances) [6]. In this paper, we examine DNN ITS synthesis with a moderate size corpus of 5 hours, which is more commonly used for parametric ITS training. DNN is used to map input text features into output acoustic features (LSP, F0 and V/U). Experimental results show that DNN can outperform the conventional HM,M, which is trained in ML first and then refined by MGE. Both objective and subjective measures indicate that DNN can synthesize speech better than HMM-based baseline. The improvement is mainly on the prosody, i.e., the RMSE of natural and generated FO trajectories by DNN is improved by 2 Hz. This benefit is likely from the key characteristics of DNN, which can exploit feature correlations, e.g., between FO and spectrum, without using a more restricted, e.g. diagonal Gaussian probability family. Our experimental results also show: the layer-wise BP pre-training can drive weights to a better starting point than random initialization and result in a more effective DNN; state boundary info is important for training DNN to yield better synthesized speech; and a hyperbolic tangent activation function in DNN hidden layers yields faster convergence than a sigmoidal one.	[Qian, Yao; Fan, Yuchen; Hu, Wenping; Soong, Frank K.] Microsoft Res, Redmond, WA 98052 USA	Qian, Y (reprint author), Microsoft Res, Redmond, WA 98052 USA.	yaoqian@microsoft.com; v-yufan@microsoft.com; v-wenh@microsoft.com; frankkps@microsoft.com					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bourlard H., 1993, CONNECTIONIST SPEECH; Chen C. J., 1997, EUROSPEECH; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Erhan D., 2010, JMLR; HINTON G, 2012, SIGNAL PROCESSING MA, V29, P82; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kang S., 2013, P ICASSP, P7962; Krogh A., 1992, NEURAL INFORM PROCES, P950; Ling Z.- H., 2006, P BLIZZ CHALL 2006 W; Ling Z.-H., 2013, P ICASSP, P7825; Lu H., 2013, 8 ISCA WORKSH SPEECH, P281; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sainath T.N., 2011, IEEE ASRU; Seide F., 2011, IEEE ASRU; Seide F., 2011, P INTERSPEECH, P437; Shinoda K., 2000, Journal of the Acoustical Society of Japan (E), V21, DOI 10.1250/ast.21.79; Tokuda K., 2000, P ICASSP, P1315; Wu Y.-J., 2006, P ICASSP; Yu D., 2010, NIPS WORKSH; Zen H., 2013, P ICASSP, P8012; Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004	22	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655303174		
S	Ranftl, R; Pock, T		Jiang, X; Hornegger, J; Koch, R		Ranftl, Rene; Pock, Thomas			Deep Variational Model for Image Segmentation	PATTERN RECOGNITION, GCPR 2014	Lecture Notes in Computer Science		English	Proceedings Paper	36th German Conference on Pattern Recognition (GCPR)	SEP 02-05, 2014	Munster, GERMANY	Cells Mot Cluster Excellence, MVTec Software GmbH, Olympus Soft Imaging Solut GmbH, Univ Munster			NETWORKS	In this paper we introduce a novel model that combines Deep Convolutional Neural Networks with a global inference model. Our model is derived from a convex variational relaxation of the minimum s-t cut problem on graphs, which is frequently used for the task of image segmentation. We treat the outputs of Convolutional Neural Networks as the unary and pairwise potentials of a graph and derive a smooth approximation to the minimum s-t cut problem. During training, this approximation facilitates the adaptation of the Convolutional Neural Network to the smoothing that is induced by the global model. The training algorithm can be understood as a modified backpropagation algorithm, that explicitly takes the global inference layer into account. We illustrate our approach on the task of supervised figure-ground segmentation. In contrast to competing approaches we train directly on the raw pixels of the input images and do not rely on hand-crafted features. Despite its generality, simplicity and complete lack of hand-crafted features, our approach is able to yield competitive performance on the Graz02 and Weizmann Horses datasets.	[Ranftl, Rene; Pock, Thomas] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria	Ranftl, R (reprint author), Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.	ranftl@icg.tugraz.at					Aldavert D., 2010, CVPR; Alvarez J.M., 2012, ECCV WORKSH; Bertelli L., 2011, CVPR; Borenstein E., 2004, CVPR; Bottou L, 1997, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.1997.609370; Boykov Y., 2001, ICCV; Brakel P, 2013, J MACH LEARN RES, V14, P2771; Chambolle A, 2009, INT J COMPUT VISION, V84, P288, DOI 10.1007/s11263-009-0238-9; Chan T.F., 2004, J APPL MATH, V66, P1632; Cour T., 2005, AISTATS; Domke J, 2012, J MACHINE LEARNING R, V22, P318; Farabet C., 2012, ICML; Fulkerson B., 2009, ICCV; Hinton G., 2000, NEURAL COMPUT, V14, P1771; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jain V., 2008, NIPS; Jancsary J., 2012, CVPR; Krizhevsky A., 2012, NIPS; Kuettel D., 2012, CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lempitsky V., 2011, NIPS; Levin A, 2009, INT J COMPUT VISION, V81, P105, DOI 10.1007/s11263-008-0166-0; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Marszalek Marcin, 2007, CVPR; Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5; Nowozin S., 2011, ICCV, p[2, 3]; Opelt A., 2004, PAMI, V28, P416; Pock T., 2009, CVPR; Samuel K.G.G., 2009, CVPR; Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881	32	0	0	SPRINGER INT PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743		978-3-319-11752-2; 978-3-319-11751-5	LECT NOTES COMPUT SC			2014	8753						107	119		10.1007/978-3-319-11752-2_9		13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BB8OA	WOS:000347032100009		
J	Ravanelli, M; Do, VH; Janin, A		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		Ravanelli, Mirco; Van Hai Do; Janin, Adam			TANDEM-Bottleneck Feature Combination using Hierarchical Deep Neural Networks	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		Deep Neural Networks; TANDEM feature; bottleneck; feature	AUTOMATIC SPEECH RECOGNITION; NECK FEATURES; LVCSR	To improve speech recognition performance, a combination between TANDEM and bottleneck Deep Neural Networks (DNN) is investigated. In particular, exploiting a feature combination performed by means of a multi-stream hierarchical processing, we show a performance improvement by combining the same input features processed by different neural networks. The experiments are based on the spontaneous telephone recordings of the Cantonese IARPA Babel corpus using both standard MFCCs and Gabor as input features.	[Ravanelli, Mirco] Fdn Bruno Kessler, Trento, Italy	Ravanelli, M (reprint author), Fdn Bruno Kessler, Trento, Italy.	mravanelli@fbk.eu; dova001@i2r.a-star.edu.sg; janin@icsi.berkeley.edu					Bengio Y., 2006, NIPS; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOURLARD H, 1993, IEEE T NEURAL NETWOR, V4, P893, DOI 10.1109/72.286885; Chen B.Y., 2005, THESIS U CALIFORNIA; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Grezl F, 2008, INT CONF ACOUST SPEE, P4729, DOI 10.1109/ICASSP.2008.4518713; Grezl F, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1201; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Grezl F., 2009, INTERSPEECH, V9, P2947; Hermansky H, 2000, INT CONF ACOUST SPEE, P1635, DOI 10.1109/ICASSP.2000.862024; Hermansky H., 1998, ISCA ICSLP, P1003; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kleinschmidt M., 2002, ICSLP, P25; Kleinschmidt M, 2002, ACTA ACUST UNITED AC, V88, P416; Lee B., 2012, INTERSPEECH; Meyer B.T., 2011, INTERSPEECH, P1269; Mohamed A., 2009, NIPS; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Plahl C., 2010, INTERSPEECH; Plahl C., 2013, ICASSP; Ravanelli M., 2014, EUSIPCO; Schadler MR, 2012, J ACOUST SOC AM, V131, P4134, DOI 10.1121/1.3699200; Seide F., 2011, ASRU; Valente F., 2011, INTERSPEECH, P1245; Vesely K, 2010, LECT NOTES ARTIF INT, V6231, P439, DOI 10.1007/978-3-642-15760-8_56; Vinyals O, 2011, INT CONF ACOUST SPEE, P4596; Young S., 2000, HTK BOOK VERSION 3 0; Yu D, 2011, INTERSPEECH, P237; Zhou P, 2012, INT CONF SIGN PROCES, P557	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							113	117				5	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600024		
J	Ryant, N; Yuan, JH; Liberman, M			IEEE	Ryant, Neville; Yuan, Jiahong; Liberman, Mark			MANDARIN TONE CLASSIFICATION WITHOUT PITCH TRACKING	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		speech recognition; Mandarin; tone modeling; deep neural networks		A deep neural network (DNN) based classifier achieved 27.38% frame error rate (FER) and 15.62% segment error rate (SER) in recognizing five tonal categories in Mandarin Chinese broadcast news, based on 40 mel-frequency cepstral coefficients (MFCCs). The same architecture scored substantially lower when trained and tested with F-0 and amplitude parameters alone: 40.05% FER and 22.66% SER. These results are substantially better than the best previously-reported results on broadcast-news tone classification [1] and are also better than a human listener achieved in categorizing test stimuli created by amplitude-and frequency-modulating complex tones to match the extracted F-0 and amplitude parameters.	[Ryant, Neville; Yuan, Jiahong; Liberman, Mark] Univ Penn, Linguist Data Consortium, Philadelphia, PA 19104 USA	Ryant, N (reprint author), Univ Penn, Linguist Data Consortium, Philadelphia, PA 19104 USA.						Chang E., 2000, INTERSPEECH, P983; Chao H, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4741; Chao Y., 1980, MAITRE PHONETIQUE, V45; Chen C. J., 1997, EUROSPEECH; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Ellis D. P. W., 2005, PLP RASTA MFCC INVER; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; HUANG HCH, 2000, ACOUST SPEECH SIG PR, P1523; Huang S., 1997, CALL HOME MANDARIN C; Huang S., 1998, 1997 MANDARIN BROADC; Kalinli O, 2011, INT CONF ACOUST SPEE, P5208; Lei X., 2005, INTERSPEECH, P2981; Lei X., 2006, INTERSPEECH; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; Nair V., 2010, P 27 INT C MACH LEAR, P807; Pui-Fung W., 2004, P ICASSP, P905; Shih C., 1997, INTONATION THEORY MO; Shih C., 1987, PHONETICS CHINESE TO; Sinha R., 2006, P ICASSP; Talkin D., 1995, SPEECH CODING SYNTHE, V495, P518; Umeda N., 1980, JASA, V68, pS70, DOI 10.1121/1.2004881; van Santen J., 1997, MULTILINGUAL TEXT TO, P141; Xu Y, 1999, J PHONETICS, V27, P55, DOI 10.1006/jpho.1999.0086; Yip M. J., 1980, THESIS MIT; Yuan J., 2013, INTERSPEECH, P2306; Yuan J., 2004, THESIS CORNELL U; Yuan JH, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P134	28	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655304179		
S	Sanchez-Gutierrez, ME; Albornoz, EM; Martinez-Licona, F; Rufiner, HL; Goddard, J		MartinezTrinidad, JF; CarrascoOchoa, JA; OlveraLopez, JA; SalasRodriguez, J; Suen, CY		Sanchez-Gutierrez, Maximo E.; Marcelo Albornoz, E.; Martinez-Licona, Fabiola; Leonardo Rufiner, H.; Goddard, John			Deep Learning for Emotional Speech Recognition	PATTERN RECOGNITION, MCPR 2014	Lecture Notes in Computer Science		English	Proceedings Paper	6th Mexican Conference on Pattern Recognition (MCPR)	JUN 25-28, 2014	Cancun, MEXICO	Natl Inst Astrophys, Opt & Elect Mexico, Comp Sci Dept, Autonomous Univ Puebla, Mexican Assoc Comp Vis, Neurocomputing & Robot, Int Assoc Pattern Recognit, Natl Council Sci & Technol Mexico, Secretariat Publ Educ Mexico		Emotional speech recognition; restricted Boltzmann machines; deep belief networks		Emotional speech recognition is a multidisciplinary research area that has received increasing attention over the last few years. The present paper considers the application of restricted Boltzmann machines (RBM) and deep belief networks (DBN) to the difficult task of automatic Spanish emotional speech recognition. The principal motivation lies in the success reported in a growing body of work employing these techniques as alternatives to traditional methods in speech processing and speech recognition. Here a well-known Spanish emotional speech database is used in order to extensively experiment with, and compare, different combinations of parameters and classifiers. It is found that with a suitable choice of parameters, RBM and DBN can achieve comparable results to other classifiers.	[Sanchez-Gutierrez, Maximo E.; Martinez-Licona, Fabiola; Goddard, John] Univ Autonoma Metropolitana, Dept Ingn Elect, Ciudad De Mexico, DF, Mexico	Sanchez-Gutierrez, ME (reprint author), Univ Autonoma Metropolitana, Dept Ingn Elect, Ciudad De Mexico, DF, Mexico.	edmax86@gmail.com					Albornoz EM, 2011, COMPUT SPEECH LANG, V25, P556, DOI 10.1016/j.csl.2010.10.001; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bruckner R., 2012, P INTERSPEECH 13 ANN; Catalogue E., EMOTIONAL SPEECH SYN; Chang C.-C., 2011, ACM T INTELLIGENT SY; Deller JR, 1993, DISCRETE TIME PROCES; Douglas-Cowie C., HUMAINE D5F DELIVERA; El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020; Eyben F., 2010, P ACM MULT MM; Guide M.U., 2011, MATHWORKS; Hinton G., 2012, IEEE SIGNAL PROCESSI; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, LECT NOTES COMPUTER, V7700, P599; Mohamed A., 2012, ICASSP 2011 ISCA POR; Rabiner L., 1993, FUNDAMENTALS SPEECH; Scherer K.R., 2010, BLUEPRING AFFECTIVE; Schuller B., 2009, 10 ANN C INT SPEECH, P312; Schuller B., 2012, P INTERSPEECH; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688; Wulsin D., 2010, DBN TOOLBOX V1	21	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-07491-7; 978-3-319-07490-0	LECT NOTES COMPUT SC			2014	8495						311	320				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Robotics	Computer Science; Robotics	BB9JZ	WOS:000348378300032		
J	Sebag, M				Sebag, Michele			A tour of machine learning: An AI perspective	AI COMMUNICATIONS			English	Article						Machine Learning; statistical learning; unsupervised learning; change of representation; reinforcement learning; machine reasoning	ALLOCATION; ALGORITHMS; SEARCH; ROBOT; NETS	Machine Learning has been at the core of Artificial Intelligence since its inception. Many promises have been held, if one is to consider that Google is a living demonstration of AI. This paper presents a historical perspective on Machine Learning, describing how the emphasis was gradually shifted from logical to statistical induction, from induction to optimization, from the search of hypotheses to the search of representations. The paper concludes with a discussion about the new frontier of Machine Learning.	Univ Paris 11, TAO, CNRS INRIA LRI, F-91405 Orsay, France	Sebag, M (reprint author), Univ Paris 11, TAO, CNRS INRIA LRI, Bat 425, F-91405 Orsay, France.	sebag@lri.fr					Abbeel P., 2004, ACM INT C P SERIES, V69; Achlioptas D., 2001, ACM S PRINC DAT SYST, P274; AMARI SI, 1977, BIOL CYBERN, V26, P175, DOI 10.1007/BF00365229; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352; Baker S, 2011, FINAL JEOPARDY MAN V; Bardenet R., 2013, P INT C MACH LEARN; Ben-David S., 2005, THEORETICAL FDN CLUS; Bengio Y., 2006, ADV NEURAL INFORM PR, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM; Beygelzimer A., 2004, EL C COMP COMPL ECCC; Bishop CM., 2011, LECT NOTES COMPUTER, V6911; Bishop CM, 2006, PATTERN RECOGNITION; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boden M. A., 1990, PHILOS ARTIFICIAL IN; Bollier D., 2010, TECHNICAL REPORT; Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; Bottou L., 2007, ADV NEURAL INFORM PR; Bottou L., 2011, CORR; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Byron R., 1996, MEDIA EQUATION; Calinon S, 2007, IEEE T SYST MAN CY B, V37, P286, DOI 10.1109/TSMCB.2006.886952; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Carlson A., 2010, NAT C ART INT AAAI; CHAPELLE O, 2011, JMLR WORKSH C P, V14, P1; CLANCEY WJ, 1993, COGNITIVE SCI, V17, P87, DOI 10.1207/s15516709cog1701_7; Collobert R., 2008, ACM INT C P SERIES, V307, P160; Cristianini N., 2009, LECT NOTES COMPUTER, V5781; De Raedt L, 2008, LECT NOTES COMPUTER, V4911; De Silva V., 2003, ADV NEURAL INFORM PR, P721; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dimitrakakis C, 2008, MACH LEARN, V72, P157, DOI 10.1007/s10994-008-5069-3; Efron B, 1982, CBMS NSF REGIONAL C, V38; Freund Y., 1996, INT C MACH LEARN, P148; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Furnkranz J., 2012, FDN RULE LEARNING; Furtlehner C., 2010, PHYS REV E, V81; Gelly S., 2007, P 24 INT C MACH LEAR, P273, DOI 10.1145/1273496.1273531; Goutte C, 2009, NEURAL INF PROCESS S, pXI; Grunwald PD, 2007, MINIMUM DESCRIPTION; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastad J., 1987, THESIS MIT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoos HH, 2012, COMMUN ACM, V55, P70, DOI 10.1145/2076450.2076469; Hsu F-H., 2002, DEEP BLUE BUILDING C; King RD, 2009, SCIENCE, V325, P945, DOI 10.1126/science.325_945a; Kleiner A., 2012, P INT C MACH LEARN; Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282; Kodratoff Y., 1990, MACHINE LEARNING ART, V3; Konidaris G., 2010, ADV NEURAL INFORM PR, P1162; LAI TL, 1985, ADV APPL MATH, V6, P4, DOI 10.1016/0196-8858(85)90002-8; Le Cun Y., 1987, THESIS U PIERRE MARI; LENAT DB, 1982, ARTIF INTELL, V19, P189, DOI 10.1016/0004-3702(82)90036-4; Lipson H, 2006, INTELLIGENT AUTONOMOUS SYSTEMS 9, P11; Littman M., 2001, ADV NEURAL INFORM PR, V14, P1555; Mairal J, 2010, J MACH LEARN RES, V11, P19; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Meila M., 2005, P 22 INT C MACH LEAR, P577, DOI 10.1145/1102351.1102424; Michalski R.S., 1986, MACHINE LEARNING ART, V2; Michalski R.S., 1983, MACH LEARN, V1, P83; Michalski R.S., 1983, MACHINE LEARNING ART, V1; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MUGGLETON S, 1994, J LOGIC PROGRAM, V20, P629; Newell A., 1959, P INT C INF PROC, P256; Ng A. Y., 2000, P 17 INT C MACH LEAR, P663; O'Regan J.K., 2006, LECT NOTES COMPUTER, V4850, P332; Pearl J, 1991, PROBABILISTIC REASON; Pearl J., 2000, CAUSALITY MODELS REA; Peters J, 2008, NEURAL NETWORKS, V21, P682, DOI 10.1016/j.neunet.2008.02.003; Pfeiffer R., 2007, BODY SHAPES WAY WE T; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rumelhart D. E, 1986, PARALLEL DISTRIBUTED; Russell S., 1995, ARTIFICIAL INTELLIGE; Russo F., 2006, PHILOS WRITINGS, V32, P32; Saitta L., 2011, PHASE TRANSITIONS MA; Samuel A.L., 1960, ADV COMPUT, V1, P165; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Scholkopf B., 1998, ADV KERNEL METHODS S; Surowiecki J., 2004, WISDOM CROWDS; Sutton RS, 1998, REINFORCEMENT LEARNI; Szepesvari C., 2010, ALGORITHMS REINFORCE; Tesauro G, 2002, ARTIF INTELL, V134, P181, DOI 10.1016/S0004-3702(01)00110-2; Thrun S., 2005, PROBABILISTIC ROBOTI; Tishby N., 1999, P ANN ALL C COMM CON, V49, P368; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Turing A., 1950, MIND, V49, p[433, 2099], DOI DOI 10.1093/MIND/LIX.236.433; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V. N., 1995, NATURE STAT LEARNING; Vert R, 2006, J MACH LEARN RES, V7, P817; Viappiani P., 2010, ADV NEURAL INFORM PR, P2352; Vilalta R, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P717, DOI 10.1007/978-0-387-09823-4_36; Weinberger K. Q., 2005, ADV NEURAL INFORM PR, P1473; WEIZENBA.J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168; Widrow B., 1962, SELF ORG SYSTEMS; Winston P, 1975, PSYCHOL COMPUTER VIS, P157; Xu L, 2008, J ARTIF INTELL RES, V32, P565	103	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126	1875-8452		AI COMMUN	AI Commun.		2014	27	1					11	23		10.3233/AIC-130580		13	Computer Science, Artificial Intelligence	Computer Science	259UP	WOS:000327552100003		
J	Seide, F; Fu, H; Droppo, J; Li, G; Yu, D			IEEE	Seide, Frank; Fu, Hao; Droppo, Jasha; Li, Gang; Yu, Dong			ON PARALLELIZABILITY OF STOCHASTIC GRADIENT DESCENT FOR SPEECH DNNS	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE				This paper compares the theoretical efficiency of model-parallel and data-parallel distributed stochastic gradient descent training of DNNs. For a typical Switchboard DNN with 46M parameters, the results are not pretty: With modern GPUs and interconnects, model parallelism is optimal with only 3 GPUs in a single server, while data parallelism with a minibatch size of 1024 does not even scale to 2 GPUs. We further show that data-parallel training efficiency can be improved by increasing the minibatch size (through a combination of AdaGrad and automatic adjustments of learning rate and minibatch size) and data compression. We arrive at an estimated possible end-to-end speed-up of 5 times or more. We do not address issues of robustness to process failure or other issues that might occur during training, nor of speed of convergence differences between ASGD and SGD parameter update patterns.	[Seide, Frank; Fu, Hao; Li, Gang] Microsoft Res Asia, Beijing 100080, Peoples R China	Seide, F (reprint author), Microsoft Res Asia, 5 Danling St, Beijing 100080, Peoples R China.	fseide@microsoft.com; fuhao9202@hotmail.com; jdroppo@microsoft.com; ganl@microsoft.com; dongyu@microsoft.com					Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, DOI 10.1561/2200000016; Chen X., 2012, INTERSPEECH; Coates A., 2013, ICML; Dahl G., 2011, IEEE T SPEECH AUDIO; Dean J., 2012, NIPS; Duchi J., 2010, ADAPTIVE SUBGRADIENT; FRANCO H, 1994, COMPUT SPEECH LANG, V8, P211, DOI 10.1006/csla.1994.1010; Godfrey John J., 1997, SWITCHBOARD 1 RELEAS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kingsbury B., 2009, ICASSP; Kingsbury B., 2012, INTERSPEECH; Le Q.V., 2012, ICML; Martens J., 2010, ICML; Minjie W., 2013, MINERVA SCALAB UNPUB; Rosenblatt F., 1961, PRINCIPLES NEURODYNA; Rumelhart D., 1986, NATURE, V323; Sainath T.-N., 2013, IEEE T AUDIO SPEECH, V21; Seide F., 2011, P ASRU WAIK VILL; Seide Frank, 2011, INTERSPEECH; Senior A., 2013, ICASSP; Yu D., 2010, NIPS WORKSH DEEP LEA; Zhang Shanshan, 2013, ICASSP; Zhou P., 2013, ICASSP	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655300048		
J	Sigtia, S; Dixon, S			IEEE	Sigtia, Siddharth; Dixon, Simon			IMPROVED MUSIC FEATURE LEARNING WITH DEEP NEURAL NETWORKS	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Deep Learning; Neural Networks; MIR	CLASSIFICATION	Recent advances in neural network training provide a way to efficiently learn representations from raw data. Good representations are an important requirement for Music Information Retrieval (MIR) tasks to be performed successfully. However, a major problem with neural networks is that training time becomes prohibitive for very large datasets and the learning algorithm can get stuck in local minima for very deep and wide network architectures. In this paper we examine 3 ways to improve feature learning for audio data using neural networks: 1. using Rectified Linear Units (ReLUs) instead of standard sigmoid units; 2. using a powerful regularisation technique called Dropout; 3. using Hessian-Free (HF) optimisation to improve training of sigmoid nets. We show that these methods provide significant improvements in training time and the features learnt are better than state of the art hand-crafted features, with a genre classification accuracy of 83 +/- 1.1% on the Tzanetakis (GTZAN) dataset. We found that the rectifier networks learnt better features than the sigmoid networks. We also demonstrate the capacity of the features to capture relevant information from audio data by applying them to genre classification on the ISMIR 2004 dataset.	[Sigtia, Siddharth; Dixon, Simon] Queen Mary Univ London, Ctr Digital Mus, London E1 4NS, England	Sigtia, S (reprint author), Queen Mary Univ London, Ctr Digital Mus, Mile End Rd, London E1 4NS, England.						BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bergstra J, 2010, P PHYTH SCI COMP C S; Bergstra J, 2006, MACH LEARN, V65, P473, DOI 10.1007/s10994-006-9019-7; Bergstra James, 2010, ISMIR, P507; Bishop C.M., 1995, NEURAL NETWORKS PATT; Carlos Jr NSilla, 2010, P 25 ACM S APPL COMP, P1702, DOI 10.1145/1774088.1774453; Dahl G.E., 2013, P ICASSP; Eric JHumphrey, 2013, J INTELL INF SYST, V1- 21, P2013; Glorot X., 2011, P 14 INT C ART INT S, V15, P315; Glorot X., 2010, INT C ART INT STAT, V9, P249; Hamel P., 2011, ISMIR, P729; Hamel Philippe, 2010, ISMIR, P339; Henaff Mikael, 2011, ISMIR, V2011; Hinton G. E., 2012, TECHNICAL REPORT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; Martens J, 2010, P 27 INT C MACH LEAR, P735; Martens J., 2011, P 28 INT C MACH LEAR, P1033; Nair V., 2010, P 27 INT C MACH LEAR, P807; Sturm B., 2012, P 2 INT ACM WORKSH M, P7; Tang Yichuan, 2013, WORKSH REPR LEARN IC; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655306200		
J	Stuker, S; Muller, M; Nguyen, QB; Waibel, A			IEEE	Stueker, Sebastian; Mueller, Markus; Quoc Bao Nguyen; Waibel, Alex			TRAINING TIME REDUCTION AND PERFORMANCE IMPROVEMENTS FROM MULTILINGUAL TECHNIQUES ON THE BABEL ASR TASK	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		automatic speech recognition; multilingual speech recognition; rapid system development		In the IARPA sponsored program BABEL we are faced with the challenge of training automatic speech recognition systems in sparse data conditions in very little time. In this paper we show that by using multilingual bootstrapping techniques in combination with multilingual deep belief bottle neck features that are only fine tuned on the target language the training time of an LVCSR system can be essentially halved while the word error rate stays the same. We show this for recognition systems on Tagalog, making use of multilingual systems trained on the other four languages of the Babel base period: Cantonese, Pashto, Turkish, and Vietnamese.	[Stueker, Sebastian; Mueller, Markus; Quoc Bao Nguyen; Waibel, Alex] Karlsruhe Inst Technol, Inst Anthropomat, D-76021 Karlsruhe, Germany	Stuker, S (reprint author), Karlsruhe Inst Technol, Inst Anthropomat, D-76021 Karlsruhe, Germany.						Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Gales M. J. F., 1998, SEMITIED COVARIANCE; Gehring Jonas, 2013, P ASRU OL CZECH REP; Gehring Jonas, 2013, P ICASSP VANC CAN MA; Ghoshal Arnab, 2013, P ICASSP VANC CAN; Heigold G., 2013, P ICASSP VANC CAN MA; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Mangu L., 2011, P ASRU WAIK HI US DE; Nguyen Quoc Bao, 2013, P RIVF HAN VIETN; Sainath T. N., 2012, P ICASSP KYOT JAP MA; Scanzio Stefano, 2008, P INTERSPEECH BRISB; Schultz T, 2001, SPEECH COMMUN, V35, P31, DOI 10.1016/S0167-6393(00)00094-7; Stuker Sebastian, 2008, P 1 INT WORKSH SPOK; Veseley K., 2012, P SLT MIAM FL US DEC; Vu Ngoc Thang, 2012, P INTERSPEECH PORTL; Yu Dong, 2011, P INTERSPEECH FLOR I	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655306082		
J	Swietojanski, P; Li, JY; Huang, JT			IEEE	Swietojanski, Pawel; Li, Jinyu; Huang, Jui-Ting			INVESTIGATION OF MAXOUT NETWORKS FOR SPEECH RECOGNITION	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		deep neural networks; maxout networks; multi-task learning; low-resource speech recognition		We explore the use of maxout neuron in various aspects of acoustic modelling for large vocabulary speech recognition systems; including low-resource scenario and multilingual knowledge transfers. Through the experiments on voice search and short message dictation datasets, we found that maxout networks are around three times faster to train and offer lower or comparable word error rates on several tasks, when compared to the networks with logistic nonlinearity. We also present a detailed study of the maxout unit internal behaviour suggesting the use of different nonlinearities in different layers.	[Swietojanski, Pawel] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9YL, Midlothian, Scotland	Swietojanski, P (reprint author), Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9YL, Midlothian, Scotland.	p.swietojanski@ed.ac.uk; jinyli@microsoft.com; jthuang@microsoft.com					Bengio Y., 2013, ABS13050445 CORR; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Cai M, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P291; Dahl G.E., 2013, P ICASSP; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Ghoshal A., 2013, P ICASSP; Glorot X., 2011, J MACHINE LEARNING R, V15; Goodfellow I.J., 2013, ARXIV13024389; Heigold G., 2013, P ICASSP; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G. E., 2012, ABS12070580 CORR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang J-T, 2013, P ICASSP; Jaitly N., 2012, P INTERSPEECH; Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445; Kingsbury B., 2012, P INTERSPEECH; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li JY, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P131; Maas A. L., 2013, P ICML; Miao Y., 2013, INTERSPEECH; Miao Y., 2013, P ASRU; Mikolov T, 2012, THESIS BRNO U TECHNO; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2010, P ICML, P131; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Seide F., 2011, P ASRU, P24; Seltzer M., 2013, P ICASSP; Snoek J., 2012, NEURAL INFORM PROCES; Swietojanski P., 2013, P IEEE ASRU DEC; Swietojanski P., 2012, P IEEE SLT MIAM; Toth L., 2013, P ICASSP; Zeiler M.D., 2013, P ICASSP	33	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655307138		
J	Tian, C; Liu, J; Peng, ZM		Xu, XD; Li, B; Lu, QM; Yan, XY; Li, JL		Tian, Chao; Liu, Jia; Peng, Zhaomeng			Acceleration Strategies for Speech Recognition based on Deep Neural Networks	MECHATRONICS ENGINEERING, COMPUTING AND INFORMATION TECHNOLOGY	Applied Mechanics and Materials		English	Proceedings Paper	International Conference on Mechatronics Engineering and Computing Technology (ICMECT)	APR 09-10, 2014	Shanghai, PEOPLES R CHINA			deep neural network; speech recognition; acceleration method		The Context-Dependent Deep-Neural-Network HMM, or CD-DNN-HMM, is a powerful acoustic modeling technique for HMM-based speech recognition systems. The CD-DNN-HMM can greatly outperform against the conventional Gaussian-mixture HMMs. Therefore, we build a CD-DNN-HMM LVCSR system by modifying a mature GMM-HMM system. The baseline CD-DNN-HMM system achieve word-error rate of 18.6% that is far better than 24.9% achieved by the GMM-HMM system. However, the speed of the baseline CD-DNN-HMM system becomes a major roadblock for its real-time rate reaches 0.72 on the standard NIST 2000 Hub5 evaluation set. In this paper, we realize several optimization algorithms in our baseline system to accelerate the recognition speed. Testing the optimized system on the same evaluation set, we achieve real-time rate of 0.39, a relative reduction of 45.8%.	[Tian, Chao; Liu, Jia; Peng, Zhaomeng] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China	Tian, C (reprint author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.	tchao07@gmail.com; liuj@tsinghua.edu.cn; pzm10@mails.tsinghua.edu.cn					Cai M., 2013, SIGN INF PROC CHINAS, P137; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Gales M., 2008, FDN TRENDS SIGNAL PR, V1, P195; Godfrey J., 1992, P ICASSP, P517, DOI 10.1109/icassp.1992.225858; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Intel R., LIB INTEL CORPORATIO, V2200; Le Q., 2012, P ICML INT MACH LEAR; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Seide F., 2011, ASRU, P24; Seide F., 2012, IEEE T AUDIO SPEECH, V20, P30; Seide F., 2011, P INTERSPEECH, P437; Young S., 1996, SIGNAL PROCESSING MA, V13, P45; Young S., 2009, HTK BOOK VERSION 3 4	15	0	0	TRANS TECH PUBLICATIONS LTD	STAFA-ZURICH	LAUBLSRUTISTR 24, CH-8717 STAFA-ZURICH, SWITZERLAND	1660-9336		978-3-03835-115-3	APPL MECH MATER			2014	556-562						5181	5185		10.4028/www.scientific.net/AMM.556-562.5181		5	Engineering, Electrical & Electronic; Engineering, Mechanical; Materials Science, Multidisciplinary; Mechanics	Engineering; Materials Science; Mechanics	BC0RU	WOS:000349448507078		
J	Tu, YH; Du, J; Xu, Y; Dai, LR; Lee, CH		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		Tu, Yanhui; Du, Jun; Xu, Yong; Dai, Lirong; Lee, Chin-Hui			Speech Separation Based on Improved Deep Neural Networks with Dual Outputs of Speech Features for Both Target and Interfering Speakers	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		single-channel speech separation; deep neural networks; semi-supervised mode	COCHANNEL SPEECH; ALGORITHM	In this paper, a novel deep neural network (DNN) architecture is proposed to generate the speech features of both the target speaker and interferer for speech separation. DNN is adopted here to directly model the highly nonlinear relationship between speech features of the mixed signals and the two competing speakers. With the modified output speech features for learning the parameters of the DNN, the generalization capacity to unseen interferers is improved for separating the target speech. Meanwhile, without any prior information from the interferer, the interfering speech can also be separated. Experimental results show that the proposed new DNN enhances the separation performance in terms of different objective measures under the semi-supervised mode where the training data of the target speaker is provided while the unseen interferer in the separation stage is predicted by using multiple interfering speakers mixed with the target speaker in the training stage.	[Tu, Yanhui; Du, Jun; Xu, Yong; Dai, Lirong] Univ Sci & Technol China, Beijing, Peoples R China	Tu, YH (reprint author), Univ Sci & Technol China, Beijing, Peoples R China.	tuyanhui@mail.ustc.edu.cn; xuyong62@mail.ustc.edu.cn; jundu@ustc.edu.cn; lrdai@ustc.edu.cn; chl@ece.gatech.edu					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Cooke M., 2006, SPEEH SEPARATION CHA; Du J., ICSP 2014 UNPUB; Geoffrey Hinton, 2010, 2010003 UTML TR U TO; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu GN, 2010, IEEE T AUDIO SPEECH, V18, P2067, DOI 10.1109/TASL.2010.2041110; Hu K., 2013, EURASIP J AUDIO SPEE, V14; Hu K, 2013, IEEE T AUDIO SPEECH, V21, P120, DOI 10.1109/TASL.2012.2215591; Li P, 2010, COMPUT SPEECH LANG, V24, P30, DOI 10.1016/j.csl.2008.05.005; Ming J, 2013, IEEE T AUDIO SPEECH, V21, P1355, DOI 10.1109/TASL.2013.2250959; Radfar MH, 2007, IEEE T AUDIO SPEECH, V15, P2299, DOI 10.1109/TASL.2007.904233; Reddy AM, 2007, IEEE T AUDIO SPEECH, V15, P1766, DOI 10.1109/TASL.2007.901310; Rennie SJ, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.938081; Roweis S., 2000, ADV NEURAL INF PROCE, V13, P793; Schmidt MN, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2614; Shao Y, 2006, IEEE T AUDIO SPEECH, V14, P289, DOI 10.1109/TSA.2005.854106; Stark M, 2011, IEEE T AUDIO SPEECH, V19, P242, DOI 10.1109/TASL.2010.2047419; Taal CH, 2010, INT CONF ACOUST SPEE, P4214, DOI 10.1109/ICASSP.2010.5495701; Wang D., 2006, COMPUTATIONAL AUDITO; Wang DLL, 1999, IEEE T NEURAL NETWOR, V10, P684, DOI 10.1109/72.761727; Weiss RJ, 2010, COMPUT SPEECH LANG, V24, P16, DOI 10.1016/j.csl.2008.03.003; Wu MY, 2003, IEEE T SPEECH AUDI P, V11, P229, DOI 10.1109/TSA.2003.811539; Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							250	254				5	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600052		
S	Turchenko, V; Sachenko, A		Golovko, V; Imada, A		Turchenko, Volodymyr; Sachenko, Anatoly			Efficiency of Parallel Large-Scale Two-Layered MLP Training on Many-Core System	NEURAL NETWORKS AND ARTIFICIAL INTELLIGENCE, ICNNAI 2014	Communications in Computer and Information Science		English	Proceedings Paper	8th International Conference on Neural Networks and Artificial Intelligence (ICNNAI)	JUN 03-06, 2014	Brest, BYELARUS	ERICPOL Brest, Brest Tech Univ, Dept Intelligent Informat Technol		Parallel batch pattern training; multilayer perceptron; parallelization efficiency; data classification	ALGORITHM; NETWORKS	The development of parallel batch pattern back propagation training algorithm of multilayer perceptron with two hidden layers and its parallelization efficiency research on many-core high performance computing system are presented in this paper. The model of multilayer perceptron and the batch pattern training algorithm are theoretically described. The algorithmic description of the parallel batch pattern training method is presented. Our results show high parallelization efficiency of the developed training algorithm on large scale data classification task on many-core parallel computing system with 48 CPUs using MPI technology.	[Turchenko, Volodymyr; Sachenko, Anatoly] Ternopil Natl Econ Univ, Res Inst Intelligent Comp Syst, Ternopol, Ukraine	Turchenko, V (reprint author), Ternopil Natl Econ Univ, Res Inst Intelligent Comp Syst, 3 Peremogy Sq, Ternopol, Ukraine.	vtu@tneu.edu.ua; as@tneu.edu.ua					Cernansky M, 2009, LECT NOTES COMPUT SC, V5768, P381; De Llano R.M., 2010, FUT GEN COMP SYS, V26, P183; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Golovko V., 2001, NEURAL NETWORKS TRAI; Haykin S, 2008, NEURAL NETWORKS LEAR, V3rd; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Lotric U, 2009, LECT NOTES COMPUT SC, V5495, P99, DOI 10.1007/978-3-642-04921-7_11; Turchenko V., 2010, 14 IEEE INT C INT EN, P25; Turchenko V, 2010, PROCEDIA COMPUT SCI, V1, P525, DOI 10.1016/j.procs.2010.04.056; Turchenko V., 2013, 7 IEEE INT C INT DAT, P692; Turchenko V., 2009, J NATL ACAD SCI UKRA, V2, P144; Turchenko V., 2012, 7 INT C NEUR NETW AR, P47; Turchenko V, 2010, ADV INTEL SOFT COMPU, V79, P525	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929		978-3-319-08201-1; 978-3-319-08200-4	COMM COM INF SC			2014	440						201	210				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BB8TQ	WOS:000347515900019		
J	Walid, R; Lasfar, A			IEEE	Walid, Ragheb; Lasfar, Ali			Handwritten Digit Recognition using Sparse Deep Architectures	2014 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS: THEORIES AND APPLICATIONS (SITA'14)			English	Proceedings Paper	9th International Conference on Intelligent Systems - Theories and Applications (SITA)	MAY 07-08, 2014	Rabat, MOROCCO	IEEE, IEEE Morocco	Inst Natl Postes & Telecommunicat		NEURAL-NETWORKS	A lot of research has been lately focusing on deep neural networks as an alternative to shallow ones. The added advantage among many, is the automated feature extraction of pattern from data. These models have been applied successfully to many tasks, including handwritten digit recognition, where they lead the state of the art performance. In this paper we apply a sparse deep belief network and a denoising autoencoder to a new dataset proposed in the ICDAR 2013 handwritten digit competition, which is a challenging alternative in multiple aspects to many popular digit datasets. Additionally we raise some difficulties met during modelling. We finally put the spot on some elements that could improve the performance for subsequent attempts in improving models' accuracy.	[Walid, Ragheb; Lasfar, Ali] LASTIMI EST Sale, Rabat, Morocco	Walid, R (reprint author), LASTIMI EST Sale, Rabat, Morocco.	w.ragheb90@gmail.com; ali.lasfar@gmail.com					Bergstra James, 2010, P PYTH SCI COMP C SC; Chopra S., 2006, NIPS; Coates Adam, 2011, P 14 INT C ART INT S; Delalleau Olivier, 2011, NIPS; Elad M., 2006, IEEE COMPUTER VISION; Garz Angelika, 2013, P 12 INT C DOC AN RE, P1454; Goodfellow Ian, 2009, NIPS; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Japkowicz N, 2000, NEURAL COMPUT, V12, P531, DOI 10.1162/089976600300015691; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lecun Y., 1998, EFFICIENT BACK PROP; LeCun Y., 2006, PREDICTING STRUCTURE, P191; LeCun Yann, 2010, ISCAS; Lee H., 2007, ADV NEURAL INFORM PR, V20; Ng Andrew, 2004, FEATURE SELECTION 11; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Ranzato M., 2007, NIPS; Rubinstein Ron, 2010, DICT SPARSE REPRESEN; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Yang J., 2009, CVPR; Yang Jianchao, 2010, IEEE T IMAGE PROCESS; Yann LeCun, 1998, P IEEE	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-3566-6				2014												6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BB7ZH	WOS:000346142800009		
S	Wang, AR; Lu, JW; Wang, G; Cai, JF; Cham, TJ		Fleet, D; Pajdla, T; Schiele, B; Tuytelaars, T		Wang, Anran; Lu, Jiwen; Wang, Gang; Cai, Jianfei; Cham, Tat-Jen			Multi-modal Unsupervised Feature Learning for RGB-D Scene Labeling	COMPUTER VISION - ECCV 2014, PT V	Lecture Notes in Computer Science		English	Proceedings Paper	13th European Conference on Computer Vision (ECCV)	SEP 06-12, 2014	Zurich, SWITZERLAND			RGB-D scene labeling; unsupervised feature learning; joint feature learning and encoding; multi-modality		Most of the existing approaches for RGB-D indoor scene labeling employ hand-crafted features for each modality independently and combine them in a heuristic manner. There has been some attempt on directly learning features from raw RGB-D data, but the performance is not satisfactory. In this paper, we adapt the unsupervised feature learning technique for RGB-D labeling as a multi-modality learning problem. Our learning framework performs feature learning and feature encoding simultaneously which significantly boosts the performance. By stacking basic learning structure, higher-level features are derived and combined with lower-level features for better representing RGB-D data. Experimental results on the benchmark NYU depth dataset show that our method achieves competitive performance, compared with state-of-the-art.	[Wang, Anran; Wang, Gang; Cai, Jianfei; Cham, Tat-Jen] Nanyang Technol Univ, Singapore 639798, Singapore	Wang, AR (reprint author), Nanyang Technol Univ, Singapore 639798, Singapore.		Cai, Jianfei/A-3691-2011	Cai, Jianfei/0000-0002-9444-3763			Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Cadena C., 2013, WORKSH SEM PERC MAPP; Coates A, 2011, INT C ART INT STAT, P215; Couprie C., 2013, ARXIV13013572; Dalal N, 2005, PROC CVPR IEEE, P886; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Galleguillos C., 2008, CVPR, P1; Gould S., 2009, ICCV; Grangier D., 2009, ICML DEEP LEARN WORK; He X., 2004, CVPR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Koppula H. S., 2011, NIPS, P244; Kumar A., 2011, NIPS, P1413; Le Q. V., 2011, NIPS, P1017; Lee H., 2006, NIPS, P801; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Lempitsky V.S., 2011, NIPS, P1485; Liu C., 2011, PAMI; Lowe D., 1999, INT C COMP VIS CORF, P1150; Micusik B., 2009, IEEE INT C COMP VIS, P625; Ngiam J., 2011, ICML, P689; Pei D., 2013, IJCNN; Potamianos G., 2004, ISSUES VISUAL AUDIO, V22, P23; Ren XF, 2012, PROC CVPR IEEE, P2759; Schimidt M., 2005, MINFUNC; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Silberman N., 2011, ICCV WORKSH, P601; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Socher R., 2011, ICML, P129; Socher R., 2012, NIPS, P665; Wang H., 2009, BRIT MACH VIS C, P1; Yang JC, 2009, PROC CVPR IEEE, P1794	32	0	0	SPRINGER INT PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743		978-3-319-10602-1; 978-3-319-10601-4	LECT NOTES COMPUT SC			2014	8693						453	467				15	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BB7GY	WOS:000345528200030		
J	Wang, H; Cai, YF				Wang, Hai; Cai, Yingfeng			A Multistep Framework for Vision Based Vehicle Detection	JOURNAL OF APPLIED MATHEMATICS			English	Article							IMAGE SEGMENTATION	Vision based vehicle detection is a critical technology that plays an important role in not only vehicle active safety but also road video surveillance application. In this work, a multistep framework for vision based vehicle detection is proposed. In the first step, for vehicle candidate generation, a novel geometrical and coarse depth information based method is proposed. In the second step, for candidate verification, a deep architecture of deep belief network (DBN) for vehicle classification is trained. In the last step, a temporal analysis method based on the complexity and spatial information is used to further reduce miss and false detection. Experiments demonstrate that this framework is with high true positive (TP) rate as well as low false positive (FP) rate. On road experimental results demonstrate that the algorithm performs better than state-of-the-art vehicle detection algorithm in testing data sets.	[Wang, Hai] Jiangsu Univ, Sch Automot & Traff Engn, Zhenjiang 212013, Peoples R China; [Cai, Yingfeng] Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Peoples R China	Cai, YF (reprint author), Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Peoples R China.	caicaixiao0304@126.com			National Natural Science Foundation of China [51305167, 61203244, 61403172]; Information Technology Research Program of Transport, Ministry of China [2013364836900]; Natural Science Foundation of Jiangsu Province [BK20140555]; Jiangsu Province Colleges and Universities; Natural Science Foundation [13KJD520003]; Jiangsu University Scientific Research Foundation for Senior Professionals [12JDG010, 1291120026]	This research was supported in part by the National Natural Science Foundation of China under Grants 51305167, 61203244 and 61403172 Information Technology Research Program of Transport, Ministry of China, under Grant 2013364836900, Natural Science Foundation of Jiangsu Province under Grant BK20140555, Jiangsu Province Colleges and Universities, Natural Science Foundation, under Grant 13KJD520003 and Jiangsu University Scientific Research Foundation for Senior Professionals under Grant 12JDG010, 1291120026.	Acunzo D., 2007, P IEEE ITSC, P654; Alonso D., 2007, P IEEE INT C IM PROC, V4, P321; Bergmiller P., 2008, P 2008 IEEE INT VEH, P226; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Cui JZ, 2010, IEEE INT VEH SYM, P871, DOI 10.1109/IVS.2010.5548101; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fulkerson B, 2009, IEEE I CONF COMP VIS, P670, DOI 10.1109/ICCV.2009.5459175; He XM, 2006, LECT NOTES COMPUT SC, V3951, P338; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Kim G., 2012, P INT C CONTR AUT SY, P625; Lin C. T., 2013, J SIGNAL INFORM PROC, V4; Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823; Liu WL, 2007, INT C COMP AID DES C, P252; Ludwig O, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P310; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Sindoori R., 2013, INT J ENG TECHNOLOGY, V5, p765 ; Sivaraman S, 2014, MACH VISION APPL, V25, P599, DOI 10.1007/s00138-011-0388-y; Son TT, 2009, IEEE INT VEH SYM, P507, DOI 10.1109/IVS.2009.5164330; Southall B, 2009, PROC CVPR IEEE, P541; Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363; Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062; Teoh SS, 2012, MACH VISION APPL, V23, P831, DOI 10.1007/s00138-011-0355-7; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Wood F., 2012, TRAINING PRODUCTS EX	26	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-757X	1687-0042		J APPL MATH	J. Appl. Math.		2014									876451	10.1155/2014/876451		9	Mathematics, Applied	Mathematics	AR4LT	WOS:000343559000001		
J	Wang, H; Cai, YF; Chen, L				Wang, Hai; Cai, Yingfeng; Chen, Long			A Vehicle Detection Algorithm Based on Deep Belief Network	SCIENTIFIC WORLD JOURNAL			English	Article							CLASSIFIERS	Vision based vehicle detection is a critical technology that plays an important role in not only vehicle active safety but also road video surveillance application. Traditional shallow model based vehicle detection algorithm still cannot meet the requirement of accurate vehicle detection in these applications. In this work, a novel deep learning based vehicle detection algorithm with 2D deep belief network (2D-DBN) is proposed. In the algorithm, the proposed 2D-DBN architecture uses second-order planes instead of first-order vector as input and uses bilinear projection for retaining discriminative information so as to determine the size of the deep architecture which enhances the success rate of vehicle detection. On-road experimental results demonstrate that the algorithm performs better than state-of-the-art vehicle detection algorithm in testing data sets.	[Wang, Hai] Jiangsu Univ, Sch Automot & Traff Engn, Zhenjiang 212013, Peoples R China; [Cai, Yingfeng; Chen, Long] Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Peoples R China	Cai, YF (reprint author), Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Peoples R China.	caicaixiao0304@126.com			National Natural Science Foundation of China [51305167]; Information Technology Research Program of Transport Ministry of China [2013364836900]; Jiangsu University Scientific Research Foundation [12JDG010]	This research was funded partly and was supported in part by the National Natural Science Foundation of China under Grant no. 51305167, Information Technology Research Program of Transport Ministry of China under Grant no. 2013364836900, and Jiangsu University Scientific Research Foundation for Senior Professionals under Grant no. 12JDG010.	Acunzo D., 2007, P IEEE ITSC, P654; Cui JZ, 2010, IEEE INT VEH SYM, P871, DOI 10.1109/IVS.2010.5548101; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lin C. T., 2013, J SIGNAL INFORM PROC, V4; Liu WL, 2007, INT C COMP AID DES C, P252; Ludwig O, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P310; Nair V., 2009, P 23 ANN C NEUR INF, V22, P1339; Sindoori R., 2013, INT J ENG TECHNOLOGY, V5; Sivaraman S., 2011, MACH VISION APPL, P1; Son TT, 2009, IEEE INT VEH SYM, P507, DOI 10.1109/IVS.2009.5164330; Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Teoh SS, 2012, MACH VISION APPL, V23, P831, DOI 10.1007/s00138-011-0355-7; Wood F., 2012, 201253 BROWN U, p[53, 143]; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Zhang CX, 2014, PATTERN RECOGN LETT, V36, P161, DOI 10.1016/j.patrec.2013.10.009; Zhong S. - H., 2011, P 19 ACM INT C MULT	17	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1537-744X			SCI WORLD J	Sci. World J.		2014									647380	10.1155/2014/647380		7	Multidisciplinary Sciences	Science & Technology - Other Topics	AH7PC	WOS:000336324600001		
S	Wang, JJ; Zhang, XH		Luo, X; Yu, JX; Li, Z		Wang, Junjie; Zhang, Xiaolong			Efficient Deep Learning Algorithm with Accelerating Inference Strategy	ADVANCED DATA MINING AND APPLICATIONS, ADMA 2014	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	10th International Conference on Advanced Data Mining and Applications (ADMA)	DEC 19-21, 2014	Guilin, PEOPLES R CHINA			Layer-wise; Accelerating inference strategy; Deep learning		In this paper, we present an efficient learning algorithm for Deep Boltzmann Machine (DBM) to get the data-dependent expectation quickly. The algorithm adopts a layer-wise accelerating inference strategy to compute the mean values of all hidden layers, instead of the mean values by repeatedly running the equations of mean-field fixed-point until convergence. By taking advantage of layer-wise inference strategy, we can rapidly get the approximate mean values in a few iterations. This strategy also could learn efficiently a high performance model for high-dimensional high-structured sensory inputs. The proposed algorithm with layer-wise accelerating inference performs well compared to original DBM with given learning tasks.	[Wang, Junjie; Zhang, Xiaolong] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Peoples R China; [Wang, Junjie; Zhang, Xiaolong] Intelligent Informat Proc & Real Time Ind Syst Hu, Wuhan 430065, Peoples R China	Wang, JJ (reprint author), Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Peoples R China.	wangjunjie_wust@163.com; xiaolong.zhang@wust.edu.cn					Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G.E., 2012, LECT NOTES COMPUTER, V7700, P599; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Nair V, 2009, ADV NEURAL INFORM PR, P1145; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Salakhutdinov R., 2010, P 27 INT C MACH LEAR, P943; Salakhutdinov R., 2010, INT C ART INT STAT, V9, P693; Salakhutdinov R., 2012, NIPS, V3, P2456	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-14717-8; 978-3-319-14716-1	LECT NOTES ARTIF INT			2014	8933						394	405				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BC7HF	WOS:000354877700031		
J	Wang, YN; Du, J; Dai, LR; Lee, CH		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		Wang, Yannan; Du, Jun; Dai, Lirong; Lee, Chin-Hui			A Fusion Approach to Spoken Language Identification Based on Combining Multiple Phone Recognizers and Speech Attribute Detectors	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		spoken language recognition; phonetic features; automatic speech attribute transcription; deep neural network; bottleneck features; phone recognition followed by language modeling; manner and place of articulation	DEEP NEURAL-NETWORKS; BOTTLENECK FEATURES; TELEPHONE SPEECH; RECOGNITION	We propose a fusion approach to spoken language recognition by combining multiple tokenizers with phone and speech attribute models trained on a collection of multilingual corpora with different front-end features. The speech attribute models are trained with bottleneck features extracted from deep neural networks while the phone models are trained with temporal patterns neural network features. By exploiting different combinations of front-end features, fundamental speech units and tokenization models, we demonstrate that speech attribute units are complementary to phone units and produce enhanced performances when they are combined with conventional phone based tokenizers. Tested on the National Institute of Standards and Technology 2009 language recognition evaluation task, leveraged upon diversity in system combination, we find that speech attribute recognition followed by language modeling achieves an additional average relative equal error rate reduction of more than 20% when fused with the state-of-the-art systems with phone recognition followed by language modeling.	[Wang, Yannan; Du, Jun; Dai, Lirong] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Changsha, Hunan, Peoples R China	Wang, YN (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Changsha, Hunan, Peoples R China.	wyn314@mail.ustc.edu.cn; jundu@ustc.edu.cn; lrdai@ustc.edu.cn; chl@ece.gatech.edu					Bao YB, 2013, INT CONF ACOUST SPEE, P6980; Bishop C.M., 1995, NEURAL NETWORKS PATT; C-H Lee, 1988, P ICASSP, V1, P501; Evermann G., P SPEECH TRANSCR WOR; Fant G., 1973, SPEECH SOUNDS FEATUR; Fiscus J. G., 1997, P IEEE WORKSH AUT SP, P347; Godfrey J. J., 1992, P ICASSP, V1, P517; HERMANSKY H, 1999, ACOUST SPEECH SIG PR, P289; HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoffmeister B, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P537; Jelinek F., 1990, READINGS SPEECH RECO, P450; Lee CH, 2013, P IEEE, V101, P1089, DOI 10.1109/JPROC.2013.2238591; Lee C.-H., 1996, COMPUTATIONAL LINGUI, V1; Lee C.-H., 2004, P ICSLP, P109; Li HZ, 2007, IEEE T AUDIO SPEECH, V15, P271, DOI 10.1109/TASL.2006.876860; Li HZ, 2013, P IEEE, V101, P1136, DOI 10.1109/JPROC.2012.2237151; Martin A., 2010, P OD 2010 SPEAK LANG, P165; Martin A., 2007, SIGN PROC APPL PUBL, P1; Martin A, 1997, P EUROSPEECH, V4, P1895; Pigeon S, 2000, DIGIT SIGNAL PROCESS, V10, P237, DOI 10.1006/dspr.1999.0358; Rabiner L., 1989, P INT C AC SPEECH SI, P405; Rabiner L., 1993, FUNDAMENTALS SPEECH; Salton G., 1971, SMART RETRIEVAL SYST; Schwarz P., 2009, PHONEME RECOGNITION; SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144; Siniscalchi S. M., 2010, P INTERSPEECH, P2718; Siniscalchi SM, 2013, COMPUT SPEECH LANG, V27, P209, DOI 10.1016/j.csl.2012.05.001; Siniscalchi SM, 2008, INT CONF ACOUST SPEE, P4261, DOI 10.1109/ICASSP.2008.4518596; Song Y, 2013, ELECTRON LETT, V49, P1569, DOI 10.1049/el.2013.1721; Stevens Kenneth N, 1998, ACOUSTIC PHONETICS; Torres-Carrasquillo P. A., 2002, P INTERSPEECH; Yu D., 2011, P INTERSPEECH, P237; Zissman M. A., 1997, P EUR 97 SEPT, V1, P51; Zissman MA, 1996, IEEE T SPEECH AUDI P, V4, P31, DOI 10.1109/TSA.1996.481450; ZISSMAN MA, 1994, INT CONF ACOUST SPEE, P305	37	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							158	162				5	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600033		
S	Wei, H; Ge, WT		Zeng, Z; Li, Y; King, I		Wei, Hui; Ge, Wentao			An Orientation Column-Inspired Contour Representation and Its Application in Shape-Based Recognition	ADVANCES IN NEURAL NETWORKS - ISNN 2014	Lecture Notes in Computer Science		English	Proceedings Paper	11th International Symposium on Neural Networks (ISNN)	NOV 28-DEC 01, 2014	PEOPLES R CHINA	Chinese Univ Hong Kong, Univ Macau, European Neural Network Soc, Int Neural Network Soc, IEEE Computat Intelligence Soc, Asia Pacific Neural Network Assembly		Orientation column; Line segments; Route; Line context; Object recognition	OBJECT RECOGNITION; VISUAL-CORTEX	Recognizing an object from its background in a real-world image is always a very challenging task. During the recognition process, shape (or contour) information of an object is useful. In this paper, we build a bio-inspired contour detection model which can organize the edge information into a structured data form. Biological primary visual cortex, which can be simulated by computer, is specialized in detecting orientation of edge to producing a set of line segments. Then we propose the concept of route that indicates a continuous part of the contour. The set of line segments is divided into several routes which are the basic processing units of following recognition steps.	[Wei, Hui; Ge, Wentao] Fudan Univ, Sch Comp Sci, Lab Cognit Model & Algorithm, Shanghai 200433, Peoples R China	Wei, H (reprint author), Fudan Univ, Sch Comp Sci, Lab Cognit Model & Algorithm, Shanghai 200433, Peoples R China.	weihui@fudan.edu.cn; wge13@fudan.edu.cn					Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Canny J, 1986, MACH INTELL, V8, P679, DOI DOI 10.1109/TPAMI.1986.4767851; Carpenter G. A., 1987, COMPUTER VISION GRAP, V13, P37, DOI DOI 10.1016/S0734-189X(87)80014-2; Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1974, J COMP NEUROL, V158, P267, DOI 10.1002/cne.901580304; Jhuang H., 2007, COMPUTER VISION, V11, P1; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Swindale NV, 1996, NETWORK-COMP NEURAL, V7, P161, DOI 10.1088/0954-898X/7/2/002; ULLMAN S, 1976, BIOL CYBERN, V25, P1; Wei H., 2013, 2013 IEEE 25 INT C T, P235; Wei H, 2014, COGN COMPUT, V6, P164, DOI 10.1007/s12559-013-9222-3	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-12436-0; 978-3-319-12435-3	LECT NOTES COMPUT SC			2014	8866						405	413		10.1007/978-3-319-12436-0_45		9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BC7GU	WOS:000354869400045		
J	Wu, KZ; Chen, X; Ding, MY				Wu, Kaizhi; Chen, Xi; Ding, Mingyue			Deep learning based classification of focal liver lesions with contrast-enhanced ultrasound	OPTIK			English	Article						Deep learning; Contrast-enhanced ultrasound; Focal liver lesions	HEPATIC PERFUSION; NEURAL-NETWORKS; FACE DETECTION; BREAST-CANCER; DIAGNOSIS; QUANTIFICATION; GUIDELINES; PARAMETERS; ALGORITHM; CARCINOMA	Classification of liver masses is important to early diagnosis of patients. In this paper, a diagnostic system of liver disease classification based on contrast enhanced ultrasound (CEUS) imaging is proposed. In the proposed system, the dynamic CEUS videos of hepatic perfusion are firstly retrieved. Secondly, time intensity curves (TICs) are extracted from the dynamic CEUS videos using sparse non-negative matrix factorizations. Finally, deep learning is employed to classify benign and malignant focal liver lesions based on these TICs. Quantitative comparisons demonstrate that the proposed method outperforms the compared classification methods in accuracy, sensitivity and specificity. (C) 2014 Elsevier GmbH. All rights reserved.	[Wu, Kaizhi; Ding, Mingyue] Huazhong Univ Sci & Technol, Sch Life Sci & Technol, Dept Biomed Engn, Key Lab Image Proc & Intelligent Control,Educ Min, Wuhan 430074, Peoples R China; [Chen, Xi] Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Sci & Technol Multispectral Informat Proc Lab, Wuhan 430074, Peoples R China; [Wu, Kaizhi] Nanchang Hangkong Univ, Sch Informat Engn, Nanchang 330063, Peoples R China	Ding, MY (reprint author), Huazhong Univ Sci & Technol, Sch Life Sci & Technol, Dept Biomed Engn, Key Lab Image Proc & Intelligent Control,Educ Min, Wuhan 430074, Peoples R China.	mingyueding.hust@gmail.com			National 973 Project [2011CB933103]; National 12th-Five Year Research Program of China [2012BAI13B02]	The work is supported by the National 973 Project (Grant no. 2011CB933103) and the Project of the National 12th-Five Year Research Program of China (Grant no. 2012BAI13B02). The authors would like to thank Dr. Tianwei Yan and Ziming Zhang from Huazhong University of Science and Technology affiliated Wuhan Union Hospital, for their assistance with data acquisition and insightful comments.	Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; BARBER DC, 1980, PHYS MED BIOL, V25, P283, DOI 10.1088/0031-9155/25/2/008; Bartolotta TV, 2009, ABDOM IMAGING, V34, P193, DOI 10.1007/s00261-008-9378-6; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Budd GT, 2006, CLIN CANCER RES, V12, P6403, DOI 10.1158/1078-0432.CCR-05-1769; Casey N.T., 2012, J VAC SCI TECHNOL B, V30; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chen X., 2013, OPTIK; Claudon M, 2013, ULTRASCHALL MED, V34, P11, DOI 10.1055/s-0032-1325499; Dong XQ, 2009, CHINESE MED J-PEKING, V122, P1179, DOI 10.3760/cma.j.issn.0366-6999.2009.10.012; Erdogan SZ, 2012, IET COMMUN, V6, P3281, DOI 10.1049/iet-com.2011.0228; Eskew LA, 1997, J UROLOGY, V157, P199, DOI 10.1016/S0022-5347(01)65322-9; Ferlay J, 2010, INT J CANCER, V127, P2893, DOI 10.1002/ijc.25516; Goertz R.S., 2010, EUR J RADIOL, V75, P22; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G.E., 2012, LECT NOTES COMPUTER, V7700, P599; Huang F.-J., 2006, P COMP VIS PATT REC; Ignee A, 2010, EUR J RADIOL, V73, P153, DOI 10.1016/j.ejrad.2008.10.016; Junji S., 2008, MED PHYS, V35, P1734; Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134; Kwolek B, 2005, LECT NOTES COMPUT SC, V3696, P551; Langkvist M, 2013, SENSORS-BASEL, V13, P1578, DOI 10.3390/s130201578; Lavrac N, 1999, ARTIF INTELL MED, V16, P3, DOI 10.1016/S0933-3657(98)00062-1; Lee H., 2009, ADV NEURAL INFORM PR; Lueck GJ, 2008, IEEE T MED IMAGING, V27, P1449, DOI 10.1109/TMI.2008.922695; Marret H, 2004, J ULTRAS MED, V23, P1629; Mitterberger M, 2007, EUR J RADIOL, V64, P231, DOI 10.1016/j.ejrad.2007.07.027; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Paola R.D., 1982, IEEE T NUCL SCI, V43, P1310; Quaia E, 2004, RADIOLOGY, V232, P420, DOI 10.1148/radiol.2322031401; Ramnarine KV, 2002, J ULTRAS MED, V21, P1121; Renault G, 2005, PHYS MED BIOL, V50, P4465, DOI 10.1088/0031-9155/50/19/003; Rognin NG, 2010, IEEE T ULTRASON FERR, V57, P2503, DOI 10.1109/TUFFC.2010.1716; Salakhutdinov RR, 2008, P 25 INT C MACH LEAR, P872, DOI 10.1145/1390156.1390266; Salvatore V, 2012, EUR J RADIOL, V81, P709, DOI 10.1016/j.ejrad.2011.01.097; Shafey E.L., 2013, IEEE T PATTERN ANAL, V35, P1788; Sijens P.E., 2010, WORLD J GASTROENTERO, V16, P1598; Smith RA, 2010, CA-CANCER J CLIN, V60, P99, DOI 10.3322/caac.20063; Streba CT, 2012, WORLD J GASTROENTERO, V18, P4427, DOI 10.3748/wjg.v18.i32.4427; Sukittanon S., 2004, INTERSPEECH, P1077; Veronesi U, 2010, ANN SURG, V251, P595, DOI 10.1097/SLA.0b013e3181c0e92a; Yasufuku K, 2007, RESPIROLOGY, V12, P173, DOI 10.1111/j.1440-1843.2007.01035.x; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Zhang J, 2011, MED PHYS, V38, P4737, DOI 10.1118/1.3606456; Zhang J., 2013, IEEE T BIOMED ENG, V60, P1449	47	0	0	ELSEVIER GMBH, URBAN & FISCHER VERLAG	JENA	OFFICE JENA, P O BOX 100537, 07705 JENA, GERMANY	0030-4026			OPTIK	Optik		2014	125	15					4057	4063		10.1016/j.ijleo.2014.01.114		7	Optics	Optics	AM1YU	WOS:000339646000055		
J	Xie, HM; Wang, S; Lin, K; Lin, SP; Hou, BA			IEEE	Xie, Huiming; Wang, Shuang; Lin, Kun; Lin, Shaopeng; Hou, Biao			MULTILAYER FEATURE LEARNING FOR POLARIMETRIC SYNTHETIC RADAR DATA CLASSIFICATION	2014 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (IGARSS)	IEEE International Symposium on Geoscience and Remote Sensing IGARSS		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 13-18, 2014	Quebec, CANADA	IEEE, Inst Elect & Elect Engineers, Geoscience & Remote Sensing Soc, Canadian Remote Sensing Soc		polarimetric synthetic radar data; deep learning; feature learning; stacked sparse autoencoder	SAR	Features are important for polarimetric synthetic aperture radar (PolSAR) image classification. Various methods focus on extracting feature artificially. Compared with them, we have developed a method to learn feature automatically. The method is based on deep learning which can learn multilayer features. In this paper, stacked sparse autoencoder (SAE) as one of the deep learning models is applied as a useful strategy to achieve the goal. For improving the classification result, we use a small amount of labels to fine-tuning the parameters of the proposed method Finally, a real PolSAR dataset is used to verify the effectiveness. Experiment result confirms that the proposed method provides noteworthy improvements in classification accuracy and visual effect.	[Xie, Huiming; Wang, Shuang; Lin, Kun; Lin, Shaopeng; Hou, Biao] Xidian Univ, Minist Educ China, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China	Xie, HM (reprint author), Xidian Univ, Minist Educ China, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.	shwang@mail.xidian.edu.cn					Bengio Y, 2013, ARXIV13050445; Cloude SR, 1997, IEEE T GEOSCI REMOTE, V35, P68, DOI 10.1109/36.551935; He C., 2013, IEEE T GEOSCI REMOTE, V51; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; LEE JS, 1994, INT J REMOTE SENS, V15, P2299; Lee JS, 1999, IEEE T GEOSCI REMOTE, V37, P2363; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Ranzato M., 2008, P 25 INT C MACH LEAR, P792, DOI 10.1145/1390156.1390256; Ranzato M., 2007, IEEE C COMP VIS PATT, P1; Shin H. C., 2013, IEEE T GEOSCI REMOTE, V35; Touzi R, 2009, IEEE T GEOSCI REMOTE, V47, P3241, DOI 10.1109/TGRS.2009.2018626; Tu ST, 2012, IEEE T GEOSCI REMOTE, V50, P170, DOI 10.1109/TGRS.2011.2168532; Uhlmann S, 2014, IEEE T GEOSCI REMOTE, V52, P2197, DOI 10.1109/TGRS.2013.2258675; Vapnik V. N., 1995, NATURE STAT LEARNING; Yamaguchi Y, 2005, IEEE T GEOSCI REMOTE, V43, P1699, DOI 10.1109/TGRS.2005.852084	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-6996		978-1-4799-5775-0	INT GEOSCI REMOTE SE			2014												4	Engineering, Electrical & Electronic; Geosciences, Multidisciplinary; Remote Sensing	Engineering; Geology; Remote Sensing	BC0WG	WOS:000349688104027		
J	Xu, PY; Sarikaya, R			IEEE	Xu, Puyang; Sarikaya, Ruhi			CONTEXTUAL DOMAIN CLASSIFICATION IN SPOKEN LANGUAGE UNDERSTANDING SYSTEMS USING RECURRENT NEURAL NETWORK	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		Recurrent neural network; contextual domain classification		In a multi-domain, multi-turn spoken language understanding session, information from the history often greatly reduces the ambiguity of the current turn. In this paper, we apply the recurrent neural network (RNN) to exploit contextual information for query domain classification. The Jordan-type RNN directly sends the vector of output distribution to the next query turn as additional input features to the convolutional neural network (CNN). We evaluate our approach against SVM with and without contextual features. On our contextually labeled dataset, we observe a 1.4% absolute (8.3% relative) improvement in classification error rate over the non-contextual SVM, and 0.9% absolute (5.5% relative) improvement over the contextual SVM.	[Xu, Puyang; Sarikaya, Ruhi] Microsoft Corp, Redmond, WA 98052 USA	Xu, PY (reprint author), Microsoft Corp, Redmond, WA 98052 USA.	puyangxu@microsoft.com; ruhi.sarikaya@microsoft.com					Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Bhargava A., 2013, INTERSPEECH; Collobert R., 2008, ICML; Collobert R., 2011, J MACHINE LEARNING R; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L., 2012, IEEE SLT; Deoras A., 2013, INTERSPEECH; Elman J., 1990, COGNITIVE SCI, V14; Hinton G., 2012, ARXIV; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jordan M., 8604 U CAL I COGN SC; Mesnil G., 2013, INTERSPEECH; Mikolov T., 2010, INTERSPEECH; Sarikaya R., 2011, ICASSP; Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003; Sutskever I., 2011, ICML; Tur G., 2013, ICASSP; Xu P., 2013, IEEE ASRU; Xu P., 2011, ICASSP; Yao K., 2013, INTERSPEECH	21	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655300028		
J	Xu, Y; Mo, T; Feng, QW; Zhong, PL; Lai, MD; Chang, EIC			IEEE	Xu, Yan; Mo, Tao; Feng, Qiwei; Zhong, Peilin; Lai, Maode; Chang, Eric I-Chao			DEEP LEARNING OF FEATURE REPRESENTATION WITH MULTIPLE INSTANCE LEARNING FOR MEDICAL IMAGE ANALYSIS	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		deep learning; feature learning; supervised; unsupervised; multiple instance learning	CLASSIFICATION; SCALE	This paper studies the effectiveness of accomplishing high-level tasks with a minimum of manual annotation and good feature representations for medical images. In medical image analysis, objects like cells are characterized by significant clinical features. Previously developed features like SIFT and HARR are unable to comprehensively represent such objects. Therefore, feature representation is especially important. In this paper, we study automatic extraction of feature representation through deep learning (DNN). Furthermore, detailed annotation of objects is often an ambiguous and challenging task. We use multiple instance learning (MIL) framework in classification training with deep learning features. Several interesting conclusions can be drawn from our work: (1) automatic feature learning outperforms manual feature; (2) the unsupervised approach can achieve performance that's close to fully supervised approach (93.56%) vs. (94.52%); and (3) the MIL performance of coarse label (96.30%) outweighs the supervised performance of fine label (95.40%) in supervised deep learning features.	[Xu, Yan] Beihang Univ, Minist Educ, Key Lab Biomech & Mechanobiol, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China	Chang, EIC (reprint author), Microsoft Res, Beijing, Peoples R China.	xuyan04@gmail.com; v-tamo@microsoft.com; v-qifen@microsoft.com; v-pezhon@microsoft.com; lmd@zju.edu.cn; eric.chang@microsoft.com					Bengio Y., 2012, CORR; Boucheron LE, 2010, INT CONF ACOUST SPEE, P666, DOI 10.1109/ICASSP.2010.5495124; CHANG H, 2013, CVPR, P2203; Ciresan D., 2013, MICCAI, V2, P411; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Ciresan D.C., 2012, NEURAL INFORM PROCES, P2852; Coates A, 2011, INT C ART INT STAT, P215; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang PW, 2009, IEEE T MED IMAGING, V28, P1037, DOI 10.1109/TMI.2009.2012704; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605; Kong J, 2009, PATTERN RECOGN, V42, P1080, DOI 10.1016/j.patcog.2008.10.035; Krizhevsky A., 2012, NIPS, P1106; Lazebnik S., 2006, CVPR, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Le Q., 2012, ISBI, P302; Lee H., 2007, NIPS, P873; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, COMP VIS PATT REC 20, P1; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ranzato M., 2007, NIPS, P1185; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688; van der Maaten L.J., 2009, J MACH LEARN RES, V10, P66; Xu Y, 2012, PROC CVPR IEEE, P964; Xu Y., 2012, MICCAI, P623; Yan Z.J., 2013, ISCA	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655301131		
J	You, Z; Xu, B		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		You, Zhao; Xu, Bo			Investigation of Stochastic Hessian-Free Optimization In Deep Neural Networks For Speech Recognition	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		Deep neural networks; Stochastic Hessian-Free optimization; Dropout; Speech recognition		Effective training of Deep neural networks (DNNs) has very important significance for the DNNs based speech recognition systems. Stochastic gradient descent (SGD) is the most popular method for training DNNs. SGD often provides the solutions that are well adapt to generalization on held-out data. Recently, Hessian Free (HF) optimization have proved another optional algorithm for training DNNs. HF can be used for solving the pathological tasks. Stochastic Hessian Free (SHF) is a variation of HF, which can combine the generalization advantages of stochastic gradient descent (SGD) with second-order information from Hessian Free. This paper focus on investigating the SHF algorithm for DNN training. We conduct this algorithm on 100 hours Mandarin Chinese recorded speech recognition task. The first experiment shows that choosing proper size of gradient and curvature minibatch results in less training time and good performance. Next, it is observed that the performance of SHF does not depend on the initial parameters. Further more, experimental results shows that SHF performs with comparable results with SGD but better than traditional HF. Finally, we find that additional performance improvement is obtained with a dropout algorithm.	[You, Zhao; Xu, Bo] Chinese Acad Sci, Interact Digital Media Technol Res Ctr, Inst Automat, Beijing, Peoples R China	You, Z (reprint author), Chinese Acad Sci, Interact Digital Media Technol Res Ctr, Inst Automat, Beijing, Peoples R China.	zhao.you@ia.ac.cn; xubo@ia.ac.cn					Hinton G., 2012, IMPROVING NEURAL NET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kingsbury B., 2012, INTERSPEECH; Kiros R., 2013, CORR; Martens J., 2010, P 27 INT C MACH LEAR, V951, P2010; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Povey D., 2011, ASRU; Sainath T. N., 2011, ASRU, P30; SCHRAUDOLPH NN, 2001, FAST CURVATURE MATRI, V2130, P19; Seide F., 2011, INTERSPEECH, P437; Simon W., 2013, INTERSPEECH	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							450	453				4	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600116		
S	Zeng, XY; Ouyang, WL; Wang, M; Wang, XG		Fleet, D; Pajdla, T; Schiele, B; Tuytelaars, T		Zeng, Xingyu; Ouyang, Wanli; Wang, Meng; Wang, Xiaogang			Deep Learning of Scene-Specific Classifier for Pedestrian Detection	COMPUTER VISION - ECCV 2014, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	13th European Conference on Computer Vision (ECCV)	SEP 06-12, 2014	Zurich, SWITZERLAND					The performance of a detector depends much on its training dataset and drops significantly when the detector is applied to a new scene due to the large variations between the source training dataset and the target scene. In order to bridge this appearance gap, we propose a deep model to automatically learn scene-specific features and visual patterns in static video surveillance without any manual labels from the target scene. It jointly learns a scene-specific classifier and the distribution of the target samples. Both tasks share multi-scale feature representations with both discriminative and representative power. We also propose a cluster layer in the deep model that utilizes the scene-specific visual patterns for pedestrian detection. Our specifically designed objective function not only incorporates the confidence scores of target training samples but also automatically weights the importance of source training samples by fitting the marginal distributions of target samples. It significantly improves the detection rates at 1 FPPI by 10% compared with the state-of-the-art domain adaptation methods on MIT Traffic Dataset and CUHK Square Dataset.	[Zeng, Xingyu; Ouyang, Wanli; Wang, Meng; Wang, Xiaogang] Chinese Univ Hong Kong, Shatin, Hong Kong, Peoples R China	Zeng, XY (reprint author), Chinese Univ Hong Kong, Shatin, Hong Kong, Peoples R China.						Benfold B., 2011, CVPR; Blum A., 1998, ACM COLT; Chen M., 2012, MARGINALIZED DENOISI; Dai W., 2007, ICML; Dalal N., 2005, CVPR; Daume III H., 2010, P WORKSH DOM AD NAT; Dollar P., 2009, BMVC; DOLLAR P, 2012, PATTERN ANAL MACHINE, V34, P743; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Glorot X., 2011, ICML; Gong B., 2012, CVPR; Goodfellow I.J., 2012, NIPS WORKSH CHALL LE; Gopalan R., 2011, ICCV; Guyon I., 2011, IJCNN; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jiang W., 2008, ICIP; Krizhevsky A., 2012, NIPS, V1, P4; Le Q.V., 2011, NIPS WORKSH; Levin A., 2003, ICCV; Luo P., 2014, CVPR; Mesnil G., 2012, JMLR P TRACK, V27, P97; Nair V., 2004, CVPR; Ouyang W., 2012, CVPR; Ouyang W., 2013, CVPR; Ouyang W., 2013, ICCV; Pang JB, 2011, IEEE T IMAGE PROCESS, V20, P1388, DOI 10.1109/TIP.2010.2103951; Rosenberg C., 2005, WACV; Roth P. M., 2009, CVPR; Sermanet P, 2013, CVPR; Wang M., 2012, CVPR; Wang M., 2011, CVPR; Wang X., 2012, CVPR; Wang XG, 2014, IEEE T PATTERN ANAL, V36, P361, DOI 10.1109/TPAMI.2013.124; Wu B., 2007, CVPR; Yang J., 2007, ACM MULTIMEDIA; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Zeng X., 2013, ICCV	38	0	1	SPRINGER INT PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743		978-3-319-10578-9; 978-3-319-10577-2	LECT NOTES COMPUT SC			2014	8691						472	487				16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BB7GX	WOS:000345527000031		
S	Zhang, R; Zhang, SF; Huang, KZ		Loo, CK; Yap, KS; Wong, KW; Teoh, A; Huang, K		Zhang, Rui; Zhang, Shufei; Huang, Kaizhu			A Novel Hybrid Approach for Combining Deep and Traditional Neural Networks	NEURAL INFORMATION PROCESSING, ICONIP 2014, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	21st International Conference on Neural Information Processing (ICONIP)	NOV 03-06, 2014	Kuching, MALAYSIA					Over last fifty years, Neural Networks (NN) have been important and active models in machine learning and pattern recognition. Among different types of NNs, Back Propagation (BP) NN is one popular model, widely exploited in various applications. Recently, NNs attract even more attention in the community because a deep learning structure (if appropriately adopted) could significantly improve the learning performance. In this paper, based on a probabilistic assumption over the output neurons, we propose a hybrid strategy that manages to combine one typical deep NN, i.e., Convolutional NN (CNN) with the popular BP. We present the justification and describe the detailed learning formulations. A series of experiments validate that the hybrid approach could largely improve the accuracy for both CNN and BP on two large-scale benchmark data sets, i.e., MNIST and USPS. In particular, the proposed hybrid method significantly reduced the error rates of CNN and BP respectively by 11.72% and 28.89% on MNIST.	[Zhang, Rui; Zhang, Shufei; Huang, Kaizhu] Xian Jiaotong Liverpool Univ, SIP, Suzhou 215123, Peoples R China	Zhang, R (reprint author), Xian Jiaotong Liverpool Univ, SIP, Suzhou 215123, Peoples R China.	Rui.Zhang02@xjtlu.edu.cn; Shufei.zhang10@student.xjtlu.edu.cn; Kaizhu.Huang@xjtlu.edu.cn					Bishop C.M., 1995, NEURAL NETWORKS PATT; Ciresan D.C., 2011, P INT JOINT C ART IN; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kohonen T., 2007, KOHONEN NETWORK; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Storkey A. J., 1999, Neural Networks, V12, DOI 10.1016/S0893-6080(99)00038-6	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-12643-2; 978-3-319-12642-5	LECT NOTES COMPUT SC			2014	8836						349	356				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BB8BI	WOS:000346245200043		
J	Zhang, SL; Bao, YB; Zhou, P; Jiang, H; Dai, LR			IEEE	Zhang, Shiliang; Bao, Yebo; Zhou, Pan; Jiang, Hui; Dai, Lirong			IMPROVING DEEP NEURAL NETWORKS FOR LVCSR USING DROPOUT AND SHRINKING STRUCTURE	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE		dropout; dropout as pre-conditioner (DAP); shrinking hidden layer; deep neural networks; LVCSR; DNN-HMM		Recently, the hybrid deep neural networks and hidden Markov models (DNN/HMMs) have achieved dramatic gains over the conventional GMM/HMMs method on various large vocabulary continuous speech recognition (LVCSR) tasks. In this paper, we propose two new methods to further improve the hybrid DNN/HMMs model: i) use dropout as pre-conditioner (DAP) to initialize DNN prior to back-propagation (BP) for better recognition accuracy; ii) employ a shrinking DNN structure (sDNN) with hidden layers decreasing in size from bottom to top for the purpose of reducing model size and expediting computation time. The proposed DAP method is evaluated in a 70-hour Mandarin transcription (PSC) task and the 309-hour Switchboard (SWB) task. Compared with the traditional greedy layer-wise pre-trained DNN, it can achieve about 10% and 6.8% relative recognition error reduction for PSC and SWB tasks respectively. In addition, we also evaluate sDNN as well as its combination with DAP on the SWB task. Experimental results show that these methods can reduce model size to 45% of original size and accelerate training and test time by 55%, without losing recognition accuracy.	[Zhang, Shiliang; Bao, Yebo; Zhou, Pan; Dai, Lirong] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Anhui, Peoples R China	Zhang, SL (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Anhui, Peoples R China.	zsl2008@mail.ustc.edu.cn; bybillow@mail.ustc.edu.cn; pan2005@mail.ustc.edu.cn; hj@cse.yorku.ca; lrdai@ustc.edu.cn					Bao Y.B., 2012, 11 INT C SIGN PROC I, V1, P562; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Dahl G.E., 2013, ICASSP; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Jian Xue, 2013, INTERSPEECH; Li J., 2013, ICASSP; Miao Yajie, 2013, P INTERSPEECH, P2237; Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301; Sainath T. N., 2011, ASRU, P30; Sainath T.N., 2013, ICASSP; Seide F., 2011, ASRU, P24; Seide F., 2011, INTERSPEECH, P437; Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4409; Zhou P, 2013, INT CONF ACOUST SPEE, P6650; Zhou Pan, 2014, AC SPEECH SIGN PROC	21	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014												5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BB5BJ	WOS:000343655306178		
S	Zhang, XLL; Sun, JP; Huang, XH; Luo, ZG		Babu, AS		Zhang, Xianglilan; Sun, Jiping; Huang, Xuhui; Luo, Zhigang			A Novel Weighted Dynamic Time Warping for Light Weight Speaker-Dependent Speech Recognition in Noisy and Bad Recording Conditions	MECHANICAL DESIGN AND POWER ENGINEERING, PTS 1 AND 2	Applied Mechanics and Materials		English	Proceedings Paper	2nd International Conference on Mechanical Design and Power Engineering (ICMDPE 2013)	NOV 29-30, 2013	Beijing, PEOPLES R CHINA			Computing Methodologies; Weighted DTW; Natural Language Processing; Speech Recognition and Feature Index		Lightweight speaker-dependent (SD) automatic speech recognition (ASR) is a promising solution for the problems of possibility of disclosing personal privacy and difficulty of obtaining training material for many seldom used English words and (often non-English) names. Dynamic time warping (DTW) algorithm is the state-of-the-art algorithm for small foot-print SD ASR applications, which have limited storage space and small vocabulary. In our previous work, we have successfully developed two fast and accurate DTW variations for clean speech data. However, speech recognition in adverse conditions is still a big challenge. In order to improve recognition accuracy in noisy and bad recording conditions, such as too high or low recording volume, we introduce a novel weighted DTW method. This method defines a feature index for each time frame of training data, and then applies it to the core DTW process to tune the final alignment score. With extensive experiments on one representative SD dataset of three speakers' recordings, our method achieves better accuracy than DTW, where 0.5% relative reduction of error rate (RRER) on clean speech data and 7.5% RRER on noisy and bad recording speech data. To the best of our knowledge, our new weighted DTW is the first weighted DTW method specially designed for speech data in noisy and bad recording conditions.	[Zhang, Xianglilan] Natl Univ Def Technol, Sch Comp Sci, Natl Lab Parallel & Distributed Proc, Changsha 410073, Hunan, Peoples R China	Zhang, XLL (reprint author), Natl Univ Def Technol, Sch Comp Sci, Natl Lab Parallel & Distributed Proc, Changsha 410073, Hunan, Peoples R China.	x322zhan@uwaterloo.ca; jiping_s@evestech.com; xhhuang@nudt.edu.cn; zgluo@nudt.edu.cn					Chapaneri S., 2012, INT J COMPUTER APPL, V40, P6; Cox RV, 2000, P IEEE, V88, P1314, DOI 10.1109/5.880086; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Furui S., 2010, SPEECH TECHNOLOGY, DOI [10.1007/978-0-387-73819-2-1, DOI 10.1007/978-0-387-73819-2-1]; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jeong YS, 2011, PATTERN RECOGN, V44, P2231, DOI 10.1016/j.patcog.2010.09.022; Kim S., 2001, DAT ENG 2001 P 17 C; Levy C., 2003, WORKSH DSP MOB VEH S; Muller M., 2006, P ISMIR VICT BC CAN; Rabiner L., 1993, FUNDAMENTALS SPEECH; Sakurai Y., 2005, PODS; Sun J., 2012, AIS 2012 AV PORT; Talking N Y, 2012, IEEE INTELL SYST APP, V27, P2; Young S., 2006, HTK BOOK HTK VERSION, P349; Zhang X., 2013, J COMPUTER SCI UNPUB; Zhang X., 2013, ICASSP; Zhu Y., 2003, SIGMOD	17	0	0	TRANS TECH PUBLICATIONS LTD	STAFA-ZURICH	LAUBLSRUTISTR 24, CH-8717 STAFA-ZURICH, SWITZERLAND	1660-9336		978-3-03835-001-9	APPL MECH MATER			2014	490-491						1347	1355		10.4028/www.scientific.net/AMM.490-491.1347		9	Engineering, Mechanical; Materials Science, Multidisciplinary; Mechanics	Engineering; Materials Science; Mechanics	BA6EP	WOS:000337114300256		
J	Zhang, Y; Du, N; Li, K; Feng, JC; Jia, KB; Zhang, AD				Zhang, Yuan; Du, Nan; Li, Kang; Feng, Jinchao; Jia, Kebin; Zhang, Aidong			msiDBN: A Method of Identifying Critical Proteins in Dynamic PPI Networks	BIOMED RESEARCH INTERNATIONAL			English	Article							GENE-EXPRESSION PROFILES; TIME-COURSE; MODULARITY; COMPLEXES; CYCLE	Dynamics of protein-protein interactions (PPIs) reveals the recondite principles of biological processes inside a cell. Shown in a wealth of study, just a small group of proteins, rather than the majority, play more essential roles at crucial points of biological processes. This present work focuses on identifying these critical proteins exhibiting dramatic structural changes in dynamic PPI networks. First, a comprehensive way of modeling the dynamic PPIs is presented which simultaneously analyzes the activity of proteins and assembles the dynamic coregulation correlation between proteins at each time point. Second, a novel method is proposed, named msiDBN, which models a common representation of multiple PPI networks using a deep belief network framework and analyzes the reconstruction errors and the variabilities across the time courses in the biological process. Experiments were implemented on data of yeast cell cycles. We evaluated our network construction method by comparing the functional representations of the derived networks with two other traditional construction methods. The ranking results of critical proteins in msiDBN were compared with the results from the baseline methods. The results of comparison showed that msiDBN had better reconstruction rate and identified more proteins of critical value to yeast cell cycle process.	[Zhang, Yuan; Feng, Jinchao; Jia, Kebin] Beijing Univ Technol, Coll Elect Informat & Control Engn, Beijing 100124, Peoples R China; [Du, Nan; Li, Kang; Zhang, Aidong] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Zhang, Y (reprint author), Beijing Univ Technol, Coll Elect Informat & Control Engn, Beijing 100124, Peoples R China.	zhangyuan1012@gmail.com			National Natural Science Foundation of China [81000624, 81370038]; National Natural Science Foundation of Beijing [7142012]; Scientific Research Project of Beijing Educational Committee [km201410005003]; Rixin Fund of Beijing University of Technology [2013-RX-L04]	This work is supported by the National Natural Science Foundation of China under Grant no.s 81000624 and 81370038, the National Natural Science Foundation of Beijing under Grant no. 7142012, the Scientific Research Project of Beijing Educational Committee under Grant no. km201410005003, and the Rixin Fund of Beijing University of Technology under Grant no. 2013-RX-L04.	Arnau V, 2005, BIOINFORMATICS, V21, P364, DOI 10.1093/bioinformatics/bti021; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bhardwaj N, 2005, BIOINFORMATICS, V21, P2730, DOI 10.1093/bioinformatics/bti398; Chang X., 2013, SCI REPORTS, V3; Cho YR, 2009, IEEE DATA MINING, P91, DOI 10.1109/ICDM.2009.39; de Lichtenberg U, 2005, SCIENCE, V307, P724, DOI 10.1126/science.1105103; Du N., 2012, P ACM C BIO COMP BIO, P250; Ge L., 2013, P 19 ACM SIGKDD INT, P766; Ge L, 2012, IEEE DATA MINING, P876, DOI 10.1109/ICDM.2012.151; Han JDJ, 2004, NATURE, V430, P88, DOI 10.1038/nature02555; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Komurov K., 2007, MOL SYST BIOL, V3, P1; Lee HK, 2004, GENOME RES, V14, P1085, DOI 10.1101/gr.1910904; Markowetz F, 2007, MOL BIOSYST, V3, P478, DOI 10.1039/b617014p; Pan W, 2002, BIOINFORMATICS, V18, P546, DOI 10.1093/bioinformatics/18.4.546; Pu SY, 2009, NUCLEIC ACIDS RES, V37, P825, DOI 10.1093/nar/gkn1005; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Sutskever I., 2010, P 13 INT C ART INT S; Tang XW, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-339; Tarassov K, 2008, SCIENCE, V320, P1465, DOI 10.1126/science.1153878; Taylor IW, 2009, NAT BIOTECHNOL, V27, P199, DOI 10.1038/nbt.1522; Tu BP, 2005, SCIENCE, V310, P1152, DOI 10.1126/science.1120499; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Wang JX, 2013, PROTEOMICS, V13, P301, DOI 10.1002/pmic.201200277; Xiao QH, 2013, PROTEOME SCI, V11, DOI 10.1186/1477-5956-11-S1-S20; Yuille A., 2004, P NIPS	28	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	2314-6133	2314-6141		BIOMED RES INT	Biomed Res. Int.		2014									138410	10.1155/2014/138410		10	Biotechnology & Applied Microbiology; Medicine, Research & Experimental	Biotechnology & Applied Microbiology; Research & Experimental Medicine	AE7QF	WOS:000334192900001		
J	Zhao, T; Zhao, YX; Chen, X		Dong, M; Tao, J; Li, H; Zheng, TF; Lu, Y		Zhao, Tuo; Zhao, Yunxin; Chen, Xin			Building an Ensemble of CD-DNN-HMM Acoustic Model Using Random Forests of Phonetic Decision Trees	2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)			English	Proceedings Paper	9th International Symposium on Chinese Spoken Language Processing (ISCSLP)	SEP 12-14, 2014	SINGAPORE	Chinese & Oriental Language Informat Proc Soc, Int Speech Commun Assoc, Inst Infocomm Res, ISCA Special Interest Grp Chinese Spoken Language Proc, Natl Conf Man Machine Speed Commun China, IEEE Singapore SMC Chapter, IEEE		ensemble acoustic model; single acoustic model; random forest; phonetic decision tree; deep neural network; discriminative pre-training	RECOGNITION	We propose an RF-PDT+CD-DNN approach to generate an ensemble of context-dependent pre-trained deep neural networks (CD-DNNs) using random forests of phonetic decision trees (RF-PDTs) and constructing a CD-DNN-HMM-based ensemble acoustic model (FAN). We present evaluation results on the TIMIT dataset and a telemedicine automatic captioning dataset and demonstrate that the proposed RF-PDT+CD-DNN based EAM significantly outperforms the CD-DNN based single acoustic model (SAM) in phone and word recognition accuracies.	[Zhao, Tuo; Zhao, Yunxin] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA	Zhao, T (reprint author), Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.	tz579@mail.missouri.edu; zhaoy@missouri.edu; xin.chen@pearson.com					[Anonymous], HIDD MARK MOD TOOLK; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen X, 2013, IEEE T AUDIO SPEECH, V21, P498, DOI 10.1109/TASL.2012.2227729; Cook G., 1996, P ICSLP 96 PHIL PA, V3, P1305, DOI 10.1109/ICSLP.1996.607852; Cook G., 1997, P EUR, V3, P1959; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DENG L, 2012, P ICASSP, P2133; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kazcmi A., 2011, P INT S AISP, P11; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Qian Y., 2012, P INTERSPEECH, P354; Schwcnk H., 1999, P INT C AC SPEECH SI, P1009; Seide F., 2011, P ASRU, P24; SIOHAN O, 2005, P ICASSP, P197; VESELY K, 2010, P INT C TEXT SPEECH, V6231, P439; Xue J, 2008, IEEE T AUDIO SPEECH, V16, P519, DOI 10.1109/TASL.2007.913036; Young SJ, 1994, P ARPA HUM LANG TECH, P307, DOI DOI 10.3115/1075812.1075885; Zhang XJ, 2007, IEEE T INF TECHNOL B, V11, P332, DOI 10.1109/TITB.2006.885549; ZHAO Y, 2006, P ICASSP, P957	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-4219-0				2014							98	102				5	Computer Science, Artificial Intelligence	Computer Science	BC0WX	WOS:000349765600021		
J	Zhu, M; Wu, Y		Babu, SP; Wenzheng, L; Tsui, E	IEEE	Zhu, Ming; Wu, Yan			A Novel Deep Model for Image Recognition	2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS)			English	Proceedings Paper	5th IEEE International Conference on Software Engineering and Service Science (ICSESS)	JUN 27-29, 2014	Beijing, PEOPLES R CHINA	IEEE		deep belief network; sparse autoencoder; image recognition		In this paper we propose a hybrid deep network for image recognition. First we use the sparse autoencoder(SAE) which is a method to extract high-level feature representations of data in an unsupervised way, without any manual feature engineering, and then we perform the classification using the deep belief networks(DBNs), which consist of restricted Boltzmann machine(RBM). Finally, we implement some comparative experiments on image datasets, and the results show that our methods achieved better performance when compared with neural network and other deep learning techniques such as DBNs.	[Zhu, Ming; Wu, Yan] Tongji Univ, Coll Elect & Informat Engn, Shanghai 200092, Peoples R China	Zhu, M (reprint author), Tongji Univ, Coll Elect & Informat Engn, Shanghai 200092, Peoples R China.	yanwu@tongji.edu.cn					Bengio Y., 2009, MACH LEARN, V2, P1; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Coates A, 2011, INT C ART INT STAT, P215; Dalal N, 2005, PROC CVPR IEEE, P886; DENG J, 2013, AFF COMP INT INT ACI, P511; Hastie T., 2009, ELEMENTS STAT LEARNI; Hinton G, 2010, MOMENTUM, V9, P926; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; JIANG XJ, 2013, ADV COMP INT ICACI 2, P256; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H, 2007, NIPS, V7, P873; Liu J. S., 2008, MONTE CARLO STRATEGI; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Nair V, 2009, NIPS, P1339; Nair V, 2008, NIPS, V21, P1145; Salakhutdinov R, 2007, INT C ART INT STAT, P412	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-3279-5				2014							373	376				4	Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BC8OA	WOS:000355926400084		
J	Shankar, KH; Howard, MW				Shankar, Karthik H.; Howard, Marc W.			Optimally Fuzzy Temporal Memory	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						temporal information compression; forecasting long range correlated time series	ECHO STATE NETWORKS; TIME; STATISTICS; INTERVAL; NOISE	Any learner with the ability to predict the future of a structured time-varying signal must maintain a memory of the recent past. If the signal has a characteristic timescale relevant to future prediction, the memory can be a simple shift register-a moving window extending into the past, requiring storage resources that linearly grows with the timescale to be represented. However, an independent general purpose learner cannot a priori know the characteristic prediction-relevant timescale of the signal. Moreover, many naturally occurring signals show scale-free long range correlations implying that the natural prediction-relevant timescale is essentially unbounded. Hence the learner should maintain information from the longest possible timescale allowed by resource availability. Here we construct a fuzzy memory system that optimally sacrifices the temporal accuracy of information in a scale-free fashion in order to represent prediction-relevant information from exponentially long timescales. Using several illustrative examples, we demonstrate the advantage of the fuzzy memory system over a shift register in time series forecasting of natural signals. When the available storage resources are limited, we suggest that a general purpose learner would be better off committing to such a fuzzy memory system.	[Shankar, Karthik H.; Howard, Marc W.] Boston Univ, Ctr Memory & Brain, Boston, MA 02215 USA	Shankar, KH (reprint author), Boston Univ, Ctr Memory & Brain, Boston, MA 02215 USA.	SHANKARK@BU.EDU; MARC777@BU.EDU	Howard, Marc/E-2518-2012		National Science Foundation; NSF [BCS-1058937]; Air Force Office of Scientific Research [AFOSR FA9550-12-1-0369]	The authors acknowledge support from National Science Foundation grant, NSF BCS-1058937, and Air Force Office of Scientific Research grant AFOSR FA9550-12-1-0369.	Baillie RT, 1996, J ECONOMETRICS, V73, P5, DOI 10.1016/0304-4076(95)01732-1; Balsam PD, 2009, TRENDS NEUROSCI, V32, P73, DOI 10.1016/j.tins.2008.10.004; Beran J, 1994, STAT LONG MEMORY PRO; Chechik G, 2005, J MACH LEARN RES, V6, P165; Creutzig F, 2008, NEURAL COMPUT, V20, P1026, DOI 10.1162/neco.2008.01-07-455; Creutzig F, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.041925; Donkin C, 2012, PSYCHOL SCI, V23, P625, DOI 10.1177/0956797611430961; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Gallistel CR, 2000, PSYCHOL REV, V107, P289, DOI 10.1037//0033-295X.107.2.289; Ganguli S, 2008, P NATL ACAD SCI USA, V105, P18970, DOI 10.1073/pnas.0804451105; Gilden DL, 2001, PSYCHOL REV, V108, P33, DOI 10.1037/0033-295X.108.1.33; Granger C. W. J., 1980, Journal of Time Series Analysis, V1, DOI 10.1111/j.1467-9892.1980.tb00297.x; Hermans M, 2010, NEURAL NETWORKS, V23, P341, DOI 10.1016/j.neunet.2009.08.008; Hermans M, 2012, NEURAL COMPUT, V24, P104, DOI 10.1162/NECO_a_00200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOSKING JRM, 1981, BIOMETRIKA, V68, P165, DOI 10.1093/biomet/68.1.165; Jaeger H., 2002, 152 GMD GERM NAT RES; Jaegera H, 2007, NEURAL NETWORKS, V20, P335, DOI 10.1016/j.neunet.2007.04.016; Jaeger H., 2001, 148 GMD GERM NAT RES; Linkenkaer-Hansen K, 2001, J NEUROSCI, V21, P1370; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Mandelbrot B. B., 1982, FRACTAL GEOMETRY NAT; Muller K. R., 1997, P INT C AN NEUR NETW; Post EL, 1930, T AM MATH SOC, V32, P723, DOI 10.2307/1989348; Rakitin BC, 1998, J EXP PSYCHOL ANIM B, V24, P15, DOI 10.1037//0097-7403.24.1.15; ROBERTS S, 1981, J EXP PSYCHOL ANIM B, V7, P242, DOI 10.1037/0097-7403.7.3.242; Shankar KH, 2012, NEURAL COMPUT, V24, P134, DOI 10.1162/NECO_a_00212; SMITH MC, 1968, J COMP PHYSIOL PSYCH, V66, P679, DOI 10.1037/h0026550; Tishby N., 1999, P 37 ALL C COMM COMP; Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302; Van Orden GC, 2003, J EXP PSYCHOL GEN, V132, P331, DOI 10.1037/0096-3445.132.3.331; Vapnik V. N., 1998, STAT LEARNING THEORY; VOSS RF, 1975, NATURE, V258, P317, DOI 10.1038/258317a0; Wagenmakers EJ, 2004, PSYCHON B REV, V11, P579, DOI 10.3758/BF03196615; Wallace E, 2013, NEURAL COMPUT, V25, P1408, DOI 10.1162/NECO_a_00449; Wearden JH, 2008, Q J EXP PSYCHOL, V61, P569, DOI 10.1080/17470210701282576; White OL, 2004, PHYS REV LETT, V92, DOI 10.1103/PhysRevLett.92.148102; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Wyffels F, 2010, NEUROCOMPUTING, V73, P1958, DOI 10.1016/j.neucom.2010.01.016	39	0	0	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	DEC	2013	14						3785	3812				28	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	AG5KE	WOS:000335457100010		
J	Carneiro, G; Nascimento, JC				Carneiro, Gustavo; Nascimento, Jacinto C.			Combining Multiple Dynamic Models and Deep Learning Architectures for Tracking the Left Ventricle Endocardium in Ultrasound Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Left ventricle segmentation; deep belief networks; particle filters; dynamical model; discriminative classifiers	BOUNDARY DETECTION ALGORITHMS; ROBUST SHAPE TRACKING; LEVEL SET APPROACH; CARDIAC MR-IMAGES; MEDICAL IMAGES; ECHOCARDIOGRAPHIC SEQUENCES; AUTOMATIC SEGMENTATION; MAXIMUM-LIKELIHOOD; TIME SEGMENTATION; DEFORMABLE MODELS	We present a new statistical pattern recognition approach for the problem of left ventricle endocardium tracking in ultrasound data. The problem is formulated as a sequential importance resampling algorithm such that the expected segmentation of the current time step is estimated based on the appearance, shape, and motion models that take into account all previous and current images and previous segmentation contours produced by the method. The new appearance and shape models decouple the affine and nonrigid segmentations of the left ventricle to reduce the running time complexity. The proposed motion model combines the systole and diastole motion patterns and an observation distribution built by a deep neural network. The functionality of our approach is evaluated using a dataset of diseased cases containing 16 sequences and another dataset of normal cases comprised of four sequences, where both sets present long axis views of the left ventricle. Using a training set comprised of diseased and healthy cases, we show that our approach produces more accurate results than current state-of-the-art endocardium tracking methods in two test sequences from healthy subjects. Using three test sequences containing different types of cardiopathies, we show that our method correlates well with interuser statistics produced by four cardiologists.	[Carneiro, Gustavo] Univ Adelaide, Sch Comp Sci, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia; [Nascimento, Jacinto C.] Inst Super Tecn, Inst Sistemas & Robot, P-1049001 Lisbon, Portugal	Carneiro, G (reprint author), Univ Adelaide, Sch Comp Sci, Australian Ctr Visual Technol, North Terrace,Inkarni Wardli Bldg, Adelaide, SA 5005, Australia.	gustavo.carneiro@adelaide.edu.au; jan@isr.ist.utl.pt			FCT (ISR/IST) through the PIDDAC Program funds; HEARTRACK [PTDC/EEA-CRO/103462/2008]; EU Project IMASEG3D [PIIF-GA-2009-236173];  [PTDC/EEA-CRO/098550/2008]	This work was supported by project the FCT (ISR/IST plurianual funding) through the PIDDAC Program funds and by project PTDC/EEA-CRO/098550/2008. This work was also supported by project "HEARTRACK"-PTDC/EEA-CRO/103462/2008. This work was partially funded by EU Project IMASEG3D (PIIF-GA-2009-236173).	Alberola-Lopez C, 2004, IEEE T MED IMAGING, V23, P658, DOI 10.1109/TMI.2004.826358; Bardinet E, 1996, Med Image Anal, V1, P129, DOI 10.1016/S1361-8415(96)80009-0; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bernard O, 2009, IEEE T IMAGE PROCESS, V18, P1179, DOI 10.1109/TIP.2009.2017343; Bernard O., 2007, P IEEE INT C IM PROC; BLAND JM, 1986, LANCET, V1, P307; Bosch JG, 2002, IEEE T MED IMAGING, V21, P1374, DOI 10.1109/TMI.2002.806427; Boyd S., 2004, CONVEX OPTIMIZATION, V1st; Carneiro G, 2012, IEEE T IMAGE PROCESS, V21, P968, DOI 10.1109/TIP.2011.2169273; Carneiro G, 2010, I S BIOMED IMAGING, P1085, DOI 10.1109/ISBI.2010.5490181; Carneiro G, 2008, IEEE T MED IMAGING, V27, P1342, DOI 10.1109/TMI.2008.928917; Carneiro G., 2010, P IEEE C COMP VIS PA; Carreira-Perpinan M., 2005, P WORKSH ART INT STA; Chalana V, 1996, IEEE T MED IMAGING, V15, P290, DOI 10.1109/42.500138; Chalana V, 1997, IEEE T MED IMAGING, V16, P642, DOI 10.1109/42.640755; Chen T, 2008, IEEE T MED IMAGING, V27, P1084, DOI 10.1109/TMI.2008.918327; Comaniciu D, 2004, IEEE T MED IMAGING, V23, P849, DOI 10.1109/TMI.2004.827967; Cootes TF, 1999, LECT NOTES COMPUT SC, V1613, P322; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; Corsi C, 2002, IEEE T MED IMAGING, V21, P1202, DOI 10.1109/TMI.2002.804418; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Debreuve E, 2001, IEEE T MED IMAGING, V20, P643, DOI 10.1109/42.932748; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dias JMB, 1996, IEEE T MED IMAGING, V15, P25, DOI 10.1109/42.481438; Duan Q, 2010, COMPUT METH PROG BIO, V98, P223, DOI 10.1016/j.cmpb.2009.09.001; Duda R, 2001, PATTERN CLASSIFICATI; Fisher RA, 1948, AM STAT, V2, P30; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRIEDLAND N, 1989, IEEE T MED IMAGING, V8, P344, DOI 10.1109/42.41487; Fukunaga K., 1990, INTRO STAT PATTERN R; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; Georgescu B., 2005, P IEEE C COMP VIS PA; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Hammoude A., 1988, THESIS U WASHINGTON; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jacob G, 2002, IEEE T MED IMAGING, V21, P226, DOI 10.1109/42.996341; Jolly MP, 2009, LECT NOTES COMPUT SC, V5762, P910; KASS M, 1987, INT J COMPUT VISION, V1, P321; Lin N, 2003, MED IMAGE ANAL, V7, P529, DOI 10.1016/S1361-8415(03)00035-5; Lorenzo-Valdes M, 2004, MED IMAGE ANAL, V8, P255, DOI 10.1016/j.media.2004.06.005; Lynch M, 2008, IEEE T MED IMAGING, V27, P195, DOI 10.1109/TMI.2007.904681; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9; Mignotte M, 2001, PATTERN ANAL APPL, V4, P256, DOI 10.1007/PL00010988; Mikic I, 1998, IEEE T MED IMAGING, V17, P274, DOI 10.1109/42.700739; Mitchell SC, 2001, IEEE T MED IMAGING, V20, P415, DOI 10.1109/42.925294; Montagnat J, 2005, MED IMAGE ANAL, V9, P87, DOI 10.1016/j.media.2004.06.025; Montagnat J, 2003, PATTERN RECOGN LETT, V24, P815, DOI 10.1016/S0167-8655(02)00184-8; Nascimento JC, 2008, IEEE T IMAGE PROCESS, V17, P392, DOI 10.1109/TIP.2007.915552; Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092; Okuma K., 2004, P EUR C COMP VIS; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Paragios N, 2003, IEEE T MED IMAGING, V22, P773, DOI 10.1109/TMI.2003.814785; Paragios N., 2005, MED IMAGE ANAL, V9, P87; Qian Z, 2006, LECT NOTES COMPUT SC, V4190, P636; Reiber JHC, 1996, INT J CARDIAC IMAG, V12, P69, DOI 10.1007/BF01880736; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2007, AI STAT; SANDLER H, 1968, AM HEART J, V75, P325, DOI 10.1016/0002-8703(68)90089-6; Sarti A, 2005, IEEE T ULTRASON FERR, V52, P947, DOI 10.1109/TUFFC.2005.1504017; Senegas J, 2004, LECT NOTES COMPUT SC, V3117, P157; Setarehdan SK, 1999, IEEE T BIO-MED ENG, V46, P1364, DOI 10.1109/10.797997; Sun W, 2005, LECT NOTES COMPUT SC, V3565, P553; Sun W, 2008, IEEE T IMAGE PROCESS, V17, P2186, DOI 10.1109/TIP.2008.2004638; Terzopoulos D., 1993, TRACKING KALMAN SNAK; Viola P, 2001, PROC CVPR IEEE, P511; Weng J, 1997, IEEE T MED IMAGING, V16, P378, DOI 10.1109/42.611346; Yang L, 2008, P IEEE C COMP VIS PA; Zagrodsky V, 2005, IEEE T MED IMAGING, V24, P1089, DOI 10.1109/TMI.2005.852057; Zheng YF, 2008, IEEE T MED IMAGING, V27, P1668, DOI 10.1109/TMI.2008.2004421; Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115; Zhu X., 2005, 1530 U WISC MAD COMP; Zhu Y, 2010, IEEE T MED IMAGING, V29, P669, DOI 10.1109/TMI.2009.2031063	74	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2592	2607		10.1109/TPAMI.2013.96		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	223SU	WOS:000324830900003	24051722	
J	Fernando, C				Fernando, Chrisantha			From Blickets to Synapses: Inferring Temporal Causal Networks by Observation	COGNITIVE SCIENCE			English	Article						Causal inference; Rational process model; Neuronal replicator hypothesis; Polychronous groups; Backwards blocking; Screening-off	THETA PHASE PRECESSION; HIPPOCAMPAL COMPLEX; SYNAPTIC STRENGTH; BAYES NETS; MEMORY; REPRESENTATION; COMPUTATION; INDUCTION; BRAIN; ACETYLCHOLINE	How do human infants learn the causal dependencies between events? Evidence suggests that this remarkable feat can be achieved by observation of only a handful of examples. Many computational models have been produced to explain how infants perform causal inference without explicit teaching about statistics or the scientific method. Here, we propose a spiking neuronal network implementation that can be entrained to form a dynamical model of the temporal and causal relationships between events that it observes. The network uses spike-time dependent plasticity, long-term depression, and heterosynaptic competition rules to implement Rescorla-Wagner-like learning. Transmission delays between neurons allow the network to learn a forward model of the temporal relationships between events. Within this framework, biologically realistic synaptic plasticity rules account for well-known behavioral data regarding cognitive causal assumptions such as backwards blocking and screening-off. These models can then be run as emulators for state inference. Furthermore, this mechanism is capable of copying synaptic connectivity patterns between neuronal networks by observing the spontaneous spike activity from the neuronal circuit that is to be copied, and it thereby provides a powerful method for transmission of circuit functionality between brain regions.	Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	Fernando, C (reprint author), Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.	ctf20@eecs.qmul.ac.uk					Abbott J. T., 2011, P 33 ANN C COGN SCI; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Bi GQ, 1998, J NEUROSCI, V18, P10464; Blaisdell AP, 2006, SCIENCE, V311, P1020, DOI 10.1126/science.1121872; Buechner M. J., 1997, P 19 C COGN SCI SOC, P55; Bush D., 2010, PLOS COMPUTATIONAL B, V6; Bussel F. V., 2011, FRONT COMPUT NEUROSC, V5, P3, DOI [10.3389/fncom.2011.00003, DOI 10.3389/FNCOM.2011.00003]; Butz MV, 2010, ADAPT BEHAV, V18, P315, DOI 10.1177/1059712310376842; Cheng PW, 1997, PSYCHOL REV, V104, P367, DOI 10.1037//0033-295X.104.2.367; Chronicle EP, 2004, J EXP PSYCHOL LEARN, V30, P14, DOI 10.1037/0278-7393.30.1.14; Citri A, 2008, NEUROPSYCHOPHARMACOL, V33, P18, DOI 10.1038/sj.npp.1301559; Clark A, 2012, BEHAV BRAIN SCI, V36, P181, DOI DOI 10.1017/S0140525X12000477; Cooke SF, 2006, BRAIN, V129, P1659, DOI 10.1093/brain/awl082; Craik K., 1943, NATURE EXPLANATION; Danks D, 2003, J MATH PSYCHOL, V47, P109, DOI 10.1016/S0022-2496(02)00016-0; Daw N. D., 2008, PROBABILISTIC MIND P, P427, DOI [DOI 10.1093/ACPR0F:0S0/9780199216093.003.0019, 10.1093/acprof:oso/9780199216093.003.0019]; Daw ND, 2006, NEURAL COMPUT, V18, P1637, DOI 10.1162/neco.2006.18.7.1637; Dayan P., 1995, NEURAL COMPUT, V7, P1022; Deneve S, 2007, J NEUROSCI, V27, P5744, DOI 10.1523/JNEUROSCI.3985-06.2007; Dudek S. M., 1992, HOMOSYNAPTIC LONG TE; Fernando C., 2011, PLOS ONE, V6; Fernando C, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003775; Fernando Chrisantha, 2010, P209; Fernando C., 2009, THEORY THINKING, P291; Fernando C, 2010, NEURAL COMPUT, V22, P2809, DOI 10.1162/NECO_a_00031; Fernando C, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00024; Fonseca R, 2004, NEURON, V44, P1011, DOI 10.1016/j.neuron.2004.10.033; Fries P, 2007, TRENDS NEUROSCI, V30, P309, DOI 10.1016/j.tins.2007.05.005; Gerstner W, 2002, BIOL CYBERN, V87, P404, DOI 10.1007/s00422-002-0353-y; Glymour C, 2003, TRENDS COGN SCI, V7, P43, DOI 10.1016/S1364-6613(02)00009-8; Glymour C, 1999, COMPUTATION CAUSATIO; Glymour C., 2001, MINDS ARROWS BAYES N; Gopnik A., 2007, CAUSAL LEARNING PSYC; Gopnik A, 2007, DEVELOPMENTAL SCI, V10, P281, DOI 10.1111/j.1467-7687.2007.00584.x; Gopnik A, 2004, TRENDS COGN SCI, V8, P371, DOI 10.1016/j.tics.2004.06.005; Gopnik A, 2004, PSYCHOL REV, V111, P3, DOI 10.1037/0033-295X.111.1.3; Griffiths TL, 2005, COGNITIVE PSYCHOL, V51, P334, DOI 10.1016/j.cogpsych.2005.05.004; Grush R, 2004, BEHAV BRAIN SCI, V27, P377; Hardingham NR, 2007, J NEUROPHYSIOL, V97, P2965, DOI 10.1152/jn.01352.2006; Hasselmo ME, 2006, CURR OPIN NEUROBIOL, V16, P710, DOI 10.1016/j.conb.2006.09.002; Hebb DO, 1949, ORG BEHAV NEUROPSYCH; Heckerman D, 1999, LEARNING GRAPHICAL M; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huxter JR, 2008, NAT NEUROSCI, V11, P587, DOI 10.1038/nn.2106; Izhikevich EM, 2009, INT J BIFURCAT CHAOS, V19, P1733, DOI 10.1142/S0218127409023809; Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882; Kamin LJ, 1969, PUNISHMENT AVERSIVE, P279; Kandel E.R., 2000, PRINCIPLES NEURAL SC, Vfourth; Kemp C, 2010, COGNITIVE SCI, V34, P1185, DOI 10.1111/j.1551-6709.2010.01128.x; Kemp C, 2008, P NATL ACAD SCI USA, V105, P10687, DOI 10.1073/pnas.0802631105; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Kohler Wolfgang, 1925, MENTALITY APES; Lagnado D. A., 2007, CAUSAL LEARNING PSYC, P154, DOI DOI 10.1093/ACPROF:OSO/9780195176803.003.0011; Lagnado David, 2010, OPEN PSYCHOL J, V3, P184; Laskey KB, 2003, MACH LEARN, V50, P175, DOI 10.1023/A:1020206129842; Lisman J, 2005, HIPPOCAMPUS, V15, P913, DOI 10.1002/hipo.20121; Lober K, 2000, PSYCHOL REV, V107, P195; Love BC, 1999, ADV NEUR IN, V11, P38; Makarov VA, 2005, J NEUROSCI METH, V144, P265, DOI 10.1016/j.jneumeth.2004.11.013; MARR DC, 1977, NEUROSCI RES PROG B, V15, P470; Mazzoni A, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000439; MILES R, 1990, J PHYSIOL-LONDON, V428, P61; Nadasdy Z, 1999, J NEUROSCI, V19, P9497; Nadel L, 1997, CURR OPIN NEUROBIOL, V7, P217, DOI 10.1016/S0959-4388(97)80010-4; Nadel L, 2007, NEURAL PLASTICITY; Nadel L, 2000, HIPPOCAMPUS, V10, P352, DOI 10.1002/1098-1063(2000)10:4<352::AID-HIPO2>3.0.CO;2-D; Nelson SB, 2008, NEURON, V60, P477, DOI 10.1016/j.neuron.2008.10.020; Nessler B., 2013, PLOS COMPUTATIONAL B, V9; Nessler B., 2009, ADV NEURAL INFORM PR, V22, P1357; OKEEFE J, 1993, HIPPOCAMPUS, V3, P317, DOI 10.1002/hipo.450030307; Pearl J., 2000, CAUSALITY MODELS REA; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rescorla RA, 1972, CLASSICAL CONDITION, P64, DOI DOI 10.1016/J.COGPSYCH.2004.11.001; Richardson T., 1996, CMUPHIL68; Royer S, 2003, NATURE, V422, P518, DOI 10.1038/nature01530; Ryan L, 2001, HIPPOCAMPUS, V11, P707, DOI 10.1002/hipo.1086; Sanborn AN, 2010, PSYCHOL REV, V117, P1144, DOI 10.1037/a0020511; Sato N, 2003, NEURAL COMPUT, V15, P2379, DOI 10.1162/089976603322362400; SHASTRI L, 1993, BEHAV BRAIN SCI, V16, P417; Shouval H. Z., 2012, FRONTIERS COMPUTATIO, V4, P19; Simonton D. K., 1995, NATURE INSIGHT, P464; Singer W, 1999, NEURON, V24, P49, DOI 10.1016/S0896-6273(00)80821-1; Sobel DM, 2004, COGNITIVE SCI, V28, P303, DOI 10.1016/j.cogsci.2003.11.001; Spellman BA, 1996, PSYCHOL SCI, V7, P337, DOI 10.1111/j.1467-9280.1996.tb00385.x; Sporns O, 2004, PLOS BIOL, V2, P1910, DOI 10.1371/journal.pbio.0020369; Sprites P., 2000, CAUSATION PREDICTION; Steels L., 2006, P 3 INT WORKSH SCAL; Steels L., 2008, EV LANG P 7 INT C EV, P503, DOI 10.1142/9789812776129_0102; Steyvers M, 2003, COGNITIVE SCI, V27, P453, DOI 10.1016/S0364-0213(03)00010-7; Strens M. J. A., 2003, P 20 INT C MACH LEAR; Taylor AH, 2009, P R SOC B, V276, P247, DOI 10.1098/rspb.2008.1107; Tenenbaum B., 2003, ADV NEURAL INFORM PR, V15, P35; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Tenenbaum JB, 2001, ADV NEUR IN, V13, P59; VANHAMME LJ, 1994, LEARN MOTIV, V25, P127, DOI 10.1006/lmot.1994.1008; von der Malsburg C, 1999, NEURON, V24, P95, DOI 10.1016/S0896-6273(00)80825-9; White PA, 1998, EUR J COGN PSYCHOL, V10, P131, DOI 10.1080/713752269; Wilson R. C., 2009, NEURAL INFORM PROCES, P2062; Yamaguchi Y, 2003, BIOL CYBERN, V89, P1, DOI 10.1007/s00422-003-0415-9; Young J. D., 1996, TECHNICAL REPORT; Yu AJ, 2002, NEURAL NETWORKS, V15, P719, DOI 10.1016/S0893-6080(02)00058-8	101	0	0	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0364-0213	1551-6709		COGNITIVE SCI	Cogn. Sci.	NOV	2013	37	8					1426	1470		10.1111/cogs.12073		45	Psychology, Experimental	Psychology	248UN	WOS:000326729900002	23957457	
J	Lightheart, T; Grainger, S; Lu, TF				Lightheart, Toby; Grainger, Steven; Lu, Tien-Fu			Spike-Timing-Dependent Construction	NEURAL COMPUTATION			English	Letter							VISUAL-PATTERN RECOGNITION; SYNAPTIC PLASTICITY; NEURAL-NETWORKS; COMPUTATIONAL POWER; ADULT NEUROGENESIS; LEARNING ALGORITHM; NEURONS; MODEL; REINFORCEMENT; ROBOTS	Spike-timing-dependent construction (STDC) is the production of new spiking neurons and connections in a simulated neural network in response to neuron activity. Following the discovery of spike-timing-dependent plasticity (STDP), significant effort has gone into the modeling and simulation of adaptation in spiking neural networks (SNNs). Limitations in computational power imposed by network topology, however, constrain learning capabilities through connection weight modification alone. Constructive algorithms produce new neurons and connections, allowing automatic structural responses for applications of unknown complexity and nonstationary solutions. A conceptual analogy is developed and extended to theoretical conditions for modeling synaptic plasticity as network construction. Generalizing past constructive algorithms, we propose a framework for the design of novel constructive SNNs and demonstrate its application in the development of simulations for the validation of developed theory. Potential directions of future research and applications of STDC for biological modeling and machine learning are also discussed.	[Lightheart, Toby; Grainger, Steven; Lu, Tien-Fu] Univ Adelaide, Sch Mech Engn, Adelaide, SA 5005, Australia	Lightheart, T (reprint author), Univ Adelaide, Sch Mech Engn, Adelaide, SA 5005, Australia.	toby.lightheart@adelaide.edu.au; steven.grainger@adelaide.edu.au; tien-fu.lu@adelaide.edu.au					Abbott LF, 2000, NAT NEUROSCI, V3, P1178, DOI 10.1038/81453; Abrous DN, 2005, PHYSIOL REV, V85, P523, DOI 10.1152/physrev.00055.2003; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1007/BF00153759; Aimone JB, 2009, NEURON, V61, P187, DOI 10.1016/j.neuron.2008.11.026; Arena P, 2009, IEEE T NEURAL NETWOR, V20, P202, DOI 10.1109/TNN.2008.2005134; Becker S, 2005, HIPPOCAMPUS, V15, P722, DOI 10.1002/hipo.20095; Bi GQ, 1998, J NEUROSCI, V18, P10464; Bohte SM, 2002, IEEE T NEURAL NETWOR, V13, P426, DOI 10.1109/72.991428; BRUSKE J, 1995, NEURAL COMPUT, V7, P845, DOI 10.1162/neco.1995.7.4.845; Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639; Carrillo RR, 2008, BIOSYSTEMS, V94, P18, DOI 10.1016/j.biosystems.2008.05.008; Cirean D., 2012, IDSIA0412; Delorme A, 2001, NEURAL NETWORKS, V14, P795, DOI 10.1016/S0893-6080(01)00049-1; Di Paolo EA, 2003, PHILOS T ROY SOC A, V361, P2299, DOI 10.1098/rsta.2003.1256; Floreano D, 2006, INT J INTELL SYST, V21, P1005, DOI 10.1002/int.20173; Florian RV, 2007, NEURAL COMPUT, V19, P1468, DOI 10.1162/neco.2007.19.6.1468; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; Fukushima K, 2011, NEURAL NETWORKS, V24, P767, DOI 10.1016/j.neunet.2011.03.017; Gerstner W., 2002, SPIKING NEURON MODEL; Gilson M., 2012, PLOS COMPUT BIOL, V8; Guyonneau R, 2005, NEURAL COMPUT, V17, P859, DOI 10.1162/0899766053429390; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holtmaat A, 2009, NAT REV NEUROSCI, V10, P647, DOI 10.1038/nrn2699; Huang GB, 1998, IEEE T NEURAL NETWOR, V9, P224, DOI 10.1109/72.655045; Huemer A, 2009, STUD COMP INTELL, V258, P225; Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440; Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882; Kasinski A., 2006, International Journal of Applied Mathematics and Computer Science, V16; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Legenstein R, 2005, NEURAL COMPUT, V17, P2337, DOI 10.1162/0899766054796888; Lightheart T., 2010, P 2010 AUSTR C ROB A; Liu J, 2005, INT C DEVEL LEARN, P121; Maass W, 1996, NEURAL COMPUT, V8, P1, DOI 10.1162/neco.1996.8.1.1; Maass W, 1997, ADV NEUR IN, V9, P211; Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7; Masquelier T, 2009, NEURAL COMPUT, V21, P1259, DOI 10.1162/neco.2008.06-08-804; Masquelier T, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001377; Masquelier T, 2007, PLOS COMPUT BIOL, V3, P247, DOI 10.1371/journal.pcbi.0030031; Morrison A, 2008, BIOL CYBERN, V98, P459, DOI 10.1007/s00422-008-0233-1; Nessler B., 2009, ADV NEURAL INFORM PR, V22, P1357; Nicoletti MD, 2009, STUD COMPUT INTELL, V258, P1; Pfister JP, 2006, J NEUROSCI, V26, P9673, DOI 10.1523/JNEUROSCI.1425-06.2006; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Savin C., 2010, PLOS COMPUT BIOL, V6; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Seung HS, 2003, NEURON, V40, P1063, DOI 10.1016/S0896-6273(03)00761-X; Soltic S, 2008, IEEE IJCNN, P2091, DOI 10.1109/IJCNN.2008.4634085; Song S, 2000, NAT NEUROSCI, V3, P919; Sutton RS, 1998, REINFORCEMENT LEARNI; Takita K, 2002, IEEE IJCNN, P1643, DOI 10.1109/IJCNN.2002.1007764; Takita K., 2005, Systems and Computers in Japan, V36, DOI 10.1002/scj.10645; Thorpe S, 2001, NEURAL NETWORKS, V14, P715, DOI 10.1016/S0893-6080(01)00083-1; van Rossum MCW, 2000, J NEUROSCI, V20, P8812; Watt A. J., 2010, FRONT SYNAPTIC NEURO, V2; Watts MJ, 2009, IEEE T SYST MAN CY C, V39, P253, DOI 10.1109/TSMCC.2008.2012254; Wysoski SG, 2010, NEURAL NETWORKS, V23, P819, DOI 10.1016/j.neunet.2010.04.009; Wysoski SG, 2006, LECT NOTES COMPUT SC, V4131, P61	58	0	0	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	OCT	2013	25	10					2611	2645		10.1162/NECO_a_00501		35	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	210HW	WOS:000323822800003	23895051	
J	Maul, T				Maul, Tomas			Early experiments with neural diversity machines	NEUROCOMPUTING			English	Article						Hybrid neural networks; Neural diversity machines; Optimization; Pattern recognition	GLOBAL OPTIMIZATION; NEURONAL DIVERSITY; NETWORKS; INTERNEURONS; PROJECTION; EVOLUTION	The current paper introduces the concept of neural diversity machines (NDM) which, refers to hybrid artificial neural networks (HANN) with conditions on the minimum number of functions available to the network, amongst several other properties. The paper demonstrates how NDM networks can be optimized for solving different problems. The results demonstrate the feasibility of the approach and bolster some of the biological and computational arguments in favor of neural diversity. A substantial number of optimization experiments were conducted, generating a corresponding number of diverse neural architectures, which revealed several unexpected statistics, including the relative commonality of nodes combining inner-product and Gaussian functions. The paper confirms the advantages of HANN, demonstrates the potential of increasing the focus on neural diversity and hints at possible new neural computational strategies. (C) 2013 Elsevier B.V. All rights reserved.	Univ Nottingham, Sch Comp Sci, Selangor Darul Ehsan 43500, Semenyih, Malaysia	Maul, T (reprint author), Univ Nottingham, Sch Comp Sci, Malaysia Campus, Selangor Darul Ehsan 43500, Semenyih, Malaysia.	Tomas.Maul@nottingham.edu.my					Asuncion A., 2007, UCI MACHINE LEARNING; Azzini A., 2011, INTELLIGENZA ARTIFIC, V5, P19; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Buzsaki G, 2004, TRENDS NEUROSCI, V27, P186, DOI 10.1016/j.tins.2004.02.007; Cohen S, 2002, PATTERN ANAL APPL, V5, P113, DOI 10.1007/s100440200010; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Duch W., 2001, 9th European Symposium on Artificial Neural Networks. ESANN'2001. Proceedings; GILES CL, 1987, APPL OPTICS, V26, P4972, DOI 10.1364/AO.26.004972; Gutierrez P., 2011, ADV COMPUT INTELL, V6692, P177; Gutierrez PA, 2009, NEUROCOMPUTING, V72, P2731, DOI 10.1016/j.neucom.2008.09.020; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hornik K. M., 1989, NEURAL NETWORKS, V2, P359, DOI DOI 10.1016/0893-6080(89)90020-8; Jankowski N., 2001, 9th European Symposium on Artificial Neural Networks. ESANN'2001. Proceedings; Klausberger T, 2008, SCIENCE, V321, P53, DOI 10.1126/science.1149381; Leung F. H. F., 2003, IEEE T NEURAL NETWOR, V14, P54; MANIEZZO V, 1994, IEEE T NEURAL NETWOR, V5, P39, DOI 10.1109/72.265959; Marder E, 2006, NAT REV NEUROSCI, V7, P563, DOI 10.1038/nrn1949; Masland RH, 2001, CURR OPIN NEUROBIOL, V11, P431, DOI 10.1016/S0959-4388(00)00230-0; Maul T. H., 1989, GENETIC ALGORITHMS S; Maul T. H., 2010, NEUROCOMPUTING, V74, P884; Maul TH, 2011, IEEE T SYST MAN CY A, V41, P398, DOI 10.1109/TSMCA.2010.2085432; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; McGarry K., 1999, NEURAL COMPUTING SUR, V2, P62; Moore CI, 2010, CELL, V142, P184, DOI 10.1016/j.cell.2010.07.005; Nusser Z, 2009, TRENDS NEUROSCI, V32, P267, DOI 10.1016/j.tins.2009.01.003; Schapire RE, 1999, LECT NOTES ARTIF INT, V1720, P13; Soltesz I., 2002, DIVERSITY NEURONAL M; Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328; Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042	29	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	AUG 3	2013	113						36	48		10.1016/j.neucom.2012.12.035		13	Computer Science, Artificial Intelligence	Computer Science	158ER	WOS:000319952700005		
J	Zhou, SS; Chen, QC; Wang, XL				Zhou, Shusen; Chen, Qingcai; Wang, Xiaolong			Convolutional Deep Networks for Visual Data Classification	NEURAL PROCESSING LETTERS			English	Article						Semi-supervised learning; Deep learning; Convolutional neural networks; Visual data classification	RECOGNITION; ALGORITHM	This paper develops a semi-supervised learning algorithm called convolutional deep networks (CDN), to address the image classification problem with deep learning. First, we construct the previous several hidden layers using convolutional restricted Boltzmann machines, which can reduce the dimension and abstract the information of the images effectively. Second, we construct the following hidden layers using restricted Boltzmann machines, which can abstract the information of images quickly. Third, the constructed deep architecture is fine-tuned by gradient-descent based supervised learning with an exponential loss function. CDN can reduce the dimension and abstract the information of the images at the same time efficiently. More importantly, the abstraction and classification procedure of CDN use the same deep architecture to optimize the same parameter in different steps continuously, which can improve the learning ability effectively. We did several experiments on two standard image datasets, and show that CDN are competitive with both representative semi-supervised classifiers and existing deep learning techniques.	[Zhou, Shusen; Chen, Qingcai; Wang, Xiaolong] Harbin Inst Technol, Shenzhen Grad Sch, Key Lab Network Oriented Intelligent Computat, Harbin 150006, Peoples R China	Zhou, SS (reprint author), Harbin Inst Technol, Shenzhen Grad Sch, Key Lab Network Oriented Intelligent Computat, Harbin 150006, Peoples R China.	zhoushusen@gmail.com; qingcai.chen@hitsz.edu.cn; wangxl@insun.hit.edu.cn			National Natural Science Foundation of China [61272383, 61173075, 60973076]	This work was supported in part by the National Natural Science Foundation of China (No. 61272383, No. 61173075 and No. 60973076).	Chapelle O., 2006, SEMISUPERVISED LEARN; Collobert R, 2006, J MACH LEARN RES, V7, P1687; Desjardins G., 2008, EMPIRICAL EVALUATION; Feng GY, 2008, NEURAL PROCESS LETT, V27, P247, DOI 10.1007/s11063-008-9073-1; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Li F, 2004, CVPR WORKSHOP GENERA, P1; Liu Y, 2011, PATTERN RECOGN, V44, P2287, DOI 10.1016/j.patcog.2010.12.012; Machajdik J., 2010, INT C MULT, P83; Salakhutdinov R, 2007, J MACH LEARN RES, V2, P412; Weston J., 2008, ICML 08, P1168; Zhu X., 2007, SEMISUPERVISED LEARN	17	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621			NEURAL PROCESS LETT	Neural Process. Lett.	AUG	2013	38	1					17	27		10.1007/s11063-012-9260-y		11	Computer Science, Artificial Intelligence	Computer Science	184LC	WOS:000321890100002		
J	Bohmer, W; Grunewalder, S; Shen, Y; Musial, M; Obermayer, K				Boehmer, Wendelin; Gruenewaelder, Steffen; Shen, Yun; Musial, Marek; Obermayer, Klaus			Construction of Approximation Spaces for Reinforcement Learning	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						reinforcement learning; diffusion distance; proto value functions; slow feature analysis; least-squares policy iteration; visual robot navigation	SLOW FEATURE ANALYSIS; DIMENSIONALITY REDUCTION; LAPLACIAN EIGENMAPS; REPRESENTATION; ALGORITHMS; FRAMEWORK; DOMAINS	Linear reinforcement learning (RL) algorithms like least-squares temporal difference learning (LSTD) require basis functions that span approximation spaces of potential value functions. This article investigates methods to construct these bases from samples. We hypothesize that an ideal approximation spaces should encode diffusion distances and that slow feature analysis (SFA) constructs such spaces. To validate our hypothesis we provide theoretical statements about the LSTD value approximation error and induced metric of approximation spaces constructed by SFA and the state-of-the-art methods Krylov bases and proto-value functions (PVF). In particular, we prove that SFA minimizes the average (over all tasks in the same environment) bound on the above approximation error. Compared to other methods, SFA is very sensitive to sampling and can sometimes fail to encode the whole state space. We derive a novel importance sampling modification to compensate for this effect. Finally, the LSTD and least squares policy iteration (LSPI) performance of approximation spaces constructed by Krylov bases, PVF, SFA and PCA is compared in benchmark tasks and a visual robot navigation experiment (both in a realistic simulation and with a robot). The results support our hypothesis and suggest that (i) SFA provides subspace-invariant features for MDPs with self-adjoint transition operators, which allows strong guarantees on the approximation error, (ii) the modified SFA algorithm is best suited for LSPI in both discrete and continuous state spaces and (iii) approximation spaces encoding diffusion distances facilitate LSPI performance.	[Boehmer, Wendelin; Shen, Yun; Obermayer, Klaus] Tech Univ Berlin, Neural Informat Proc Grp, D-10587 Berlin, Germany; [Gruenewaelder, Steffen] UCL, Ctr Computat Stat & Machine Learning, London WC1E 6BT, England; [Musial, Marek] Tech Univ Berlin, Robot Grp, D-10587 Berlin, Germany	Bohmer, W (reprint author), Tech Univ Berlin, Neural Informat Proc Grp, Marchstr 23, D-10587 Berlin, Germany.	WENDELIN@NI.TU-BERLIN.DE; STEFFEN@CS.UCL.AC.UK; YUN@NI.TU-BERLIN.DE; MUSIAL@CS.TU-BERLIN.DE; OBY@NI.TU-BERLIN.DE			German science foundation (DFG) [SPP 1527]; German federal ministry of education and research [01GQ0850]; EPSRC [EP/H017402/1]; Technische Universitat Berlin	We would like to thank Roland Vollgraf, Hannes Nickisch and Mathias Franzius for pointing us to SFA as a pre-processing method for video data. This work was funded by the German science foundation (DFG) within the SPP 1527 autonomous learning, the German federal ministry of education and research (grant 01GQ0850), the EPSRC grant #EP/H017402/1 (CARDyAL) and by the integrated graduate program on human-centric communication at Technische Universitat Berlin.	Abbeel P., 2007, ADV NEURAL INFORM PR, P1; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9; Bertsekas D., 2007, DYNAMIC PROGRAMMING, V2; Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM; Bohmer W, 2012, MACH LEARN, V89, P67, DOI 10.1007/s10994-012-5300-0; Bowling M., 2005, INT C MACH LEARN; Boyan J.A., 1995, ADV NEURAL INFORM PR, V7, P369; Boyd S., 2004, CONVEX OPTIMIZATION, V1st; Bradtke SJ, 1996, MACH LEARN, V22, P33, DOI 10.1007/BF00114723; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Csato L, 2002, NEURAL COMPUT, V14, P641, DOI 10.1162/089976602317250933; Davies EB, 2007, CAM ST AD M, V106, P1, DOI 10.1017/CBO9780511618864; Davison A., 2003, IEEE INT C COMP VIS, V2, P1403; De Farias DP, 2003, OPER RES, V51, P850, DOI 10.1287/opre.51.6.850.24925; Engel Y., 2003, INT C MACH LEARN ICM, P154; Ferguson K., 2006, ICML WORKSH TRANSF L; Ferrante E., 2008, INT JOINT C AUT AG M; Foldiak P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.194; Franzius M, 2007, PLOS COMPUT BIOL, V3, P1605, DOI 10.1371/journal.pcbi.0030166; Grunewalder S, 2011, MACH LEARN, V83, P289, DOI 10.1007/s10994-010-5220-9; Guestrin C., 2001, IJCAI, P673; Guestrin C., 2004, UNCERTAINTY ARTIFICI, P235; Hauskrecht M., 2003, ADV NEURAL INFORM PR, P895; Haykin S., 1998, NEURAL NETWORKS COMP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holden H., 2010, STOCHASTIC PARTIAL D; Jenkins O., 2004, INT C MACH LEARN; Jensen ST, 2007, ECONOMET THEOR, V23, P761, DOI 10.1017/S0266466607070326; Jodogne S, 2007, J ARTIF INTELL RES, V28, P349; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X; Kober J, 2009, ADV NEURAL INFORM PR; Koller D., 2000, UAI 00, P326; Koller D, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1332; Kompella VR, 2012, NEURAL COMPUT, V24, P2994, DOI 10.1162/NECO_a_00344; Konidaris G, 2011, P 25 C ART INT; Lagoudakis M. G., 2003, J MACHINE LEARNING R, V4, P1107, DOI DOI 10.1162/JMLR.2003.4.6.1107; Lange S., 2010, INT JOINT C NEUR NET, P1, DOI 10.1109/PES.2010.5590032; Legenstein R, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000894; Littman M. L., 2001, ADV NEURAL INFORM PR, V14; Lowe D., 1999, INT C COMP VIS; Luciw M., 2012, INT C ART NEUR NETW, VIII, P279; Mahadevan S, 2007, J MACH LEARN RES, V8, P2169; Mahadevan S., 2010, ADV NEUTRAL INFORM P, P1540; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mehta N, 2008, MACH LEARN, V73, P289, DOI 10.1007/s10994-008-5061-y; Parr R., 2007, INT C MACH LEARN; Parr R., 2008, INT C MACH LEARN; Pearson K, 1901, PHILOS MAG, V2, P559; Petrik M, 2011, J MACH LEARN RES, V12, P3027; Petrik M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2574; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Reed M., 1980, METHODS MODERN MATH; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Smith R., 1990, AUTONOMOUS ROBOT VEH; Smola A. J., 2000, P 17 INT C MACH LEAR, P911; Snel M., 2011, EUR WORKSH REINF LEA, P237; Sprague N, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1223; Sprekeler H, 2011, NEURAL COMPUT, V23, P3287, DOI 10.1162/NECO_a_00214; Sun Y., 2011, INT C MACH LEARN, P481; Sutton RS, 1996, ADV NEUR IN, V8, P1038; Sutton RS, 1998, REINFORCEMENT LEARNI; Taylor ME, 2009, J MACH LEARN RES, V10, P1633; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Thrun S., 1993, P 4 CONN MOD SUMM SC; Tsitsiklis JN, 1997, IEEE T AUTOMAT CONTR, V42, P674, DOI 10.1109/9.580874; Wahba G., 1990, SPLINE MODELS OBSERV; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1023/A:1022676722315; Wingate D, 2012, ADAPT LEARN OPTIM, V12, P415; Wingate D., 2007, INT C AUT AG MULT SY, P1128; Wiskott L, 2003, NEURAL COMPUT, V15, P2147, DOI 10.1162/089976603322297331; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Xu X, 2006, LECT NOTES COMPUT SC, V4221, P47	75	0	0	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2013	14						2067	2118				52	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	204LO	WOS:000323367000012		
J	Fan, XM; Zhang, SJ; Wang, LZ; Yang, YS; Hapeshi, K				Fan, Xuemei; Zhang, Shujun; Wang, Longzhao; Yang, Yinsheng; Hapeshi, Kevin			An Evaluation Model of Supply Chain Performances Using 5DBSC and LMBP Neural Network Algorithm	JOURNAL OF BIONIC ENGINEERING			English	Article						supply chain; performance evaluation; 5DBSC; bionics; LMBP neural network	BALANCED SCORECARD; OPTIMIZATION	A high efficient Supply Chain (SC) would bring great benefits to an enterprise such as integrated resources, reduced logistics costs, improved logistics efficiency and high quality of overall level of services. So it is important to research various methods, performance indicator systems and technology for evaluating, monitoring, predicting and optimizing the performance of a SC. In this paper, the existing performance indicator systems and methods are discussed and evaluated. Various nature-inspired algorithms are reviewed and their applications for SC Performance Evaluation (PE) are discussed. Then, a model is proposed and developed using 5 Dimensional Balanced Scorecard (5DBSC) and LMBP (Levenberg-Marquardt Back Propagation) neural network for SC PE. A program is written using Matlab tool box to implement the model based on the practical values of the 14 indicators of 5DBSC of a given previous period. This model can be used to evaluate, predict and optimize the performance of a SC. The analysis results of a case study of a company show that the proposed model is valid, reliable and effective. The convergence speed is faster than that in the previous work.	[Fan, Xuemei; Yang, Yinsheng] Jilin Univ, Sch Biol & Agr Engn, Changchun 130022, Peoples R China; [Fan, Xuemei; Wang, Longzhao] Jilin Univ, Coll Quartermaster Technol, Logist Dept, Changchun 130062, Peoples R China; [Zhang, Shujun] Jilin Univ, Key Lab Bion Engn, Minist Educ, Changchun 130022, Peoples R China; [Zhang, Shujun; Hapeshi, Kevin] Univ Gloucestershire, Sch Comp & Technol, Cheltenham GL50 2RH, Glos, England	Zhang, SJ (reprint author), Jilin Univ, Key Lab Bion Engn, Minist Educ, Changchun 130022, Peoples R China.	szhang@glos.ac.uk					Akkermans H, 2002, P 20 INT SYST DYN C; Beamon BM, 1999, INT J OPER PROD MAN, V19, P275, DOI 10.1108/01443579910249714; Bolch G., 2006, QUEUING NETWORKS MAR; Boxwell R. J., 1994, BENCHMARKING COMPETI; Cha Sung-Hyuk, 2009, J PATTERN RECOGNITIO, V4, P1; Chen K, 2009, THESIS TIANJIN U; Chen KY, 2011, ADV ENG INFORM, V25, P11, DOI 10.1016/j.aei.2010.05.003; Coulibaly P, 2000, J HYDROL, V230, P244, DOI 10.1016/S0022-1694(00)00214-6; Dorigo M., 1992, THESIS POLITECNICO M; Estampe D, 2013, INT J PROD ECON, V142, P247, DOI 10.1016/j.ijpe.2010.11.024; Farris P.W., 2010, MARKETING METRICS DE, Vsecond; Fogel L J., 1994, COMPUTATIONAL INTELL, P135; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gabbert P, 1991, 4TH P INT C GEN ALG, P430; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Huang J Y, 2006, SHANGHAI MANAGEMENT, V6, P75; Kaplan RS, 1996, HARVARD BUS REV, V74, P75; KAPLAN RS, 1992, HARVARD BUS REV, V70, P71; Li J, 2011, THESIS JILIN U CHINA; Li X., 2000, J SICHUAN U, V32, P105; Li Yan, 2010, Computer Engineering and Applications, V46, DOI 10.3778/j.issn.1002-8331.2010.01.073; Liu C., 2006, THESIS CHANGSHA CENT; Liu Yun-zhong, 2004, Information and Control, V33; Lummus R. R., 1998, Production and Inventory Management Journal, V39; Martens D, 2007, IEEE T EVOLUT COMPUT, V11, P651, DOI 10.1109/TEVC.2006.890229; Masters T., 1995, ADV ALGORITHMS NEURA; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Pawlak Z, 2002, EUR J OPER RES, V136, P181, DOI 10.1016/S0377-2217(01)00029-7; Ren LQ, 2009, SCI CHINA SER E, V52, P273, DOI 10.1007/s11431-009-0042-3; Richardson P., 2010, THESIS BATH U UK; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saaty TL, 1989, CONFLICT RESOLUTION; SABELIS MW, 1991, BIOL J LINN SOC, V42, P267, DOI 10.1111/j.1095-8312.1991.tb00563.x; Seeley T. D., 1996, WISDOM HIVE SOCIAL P; [史成东 SHI Chengdong], 2007, [计算机工程与应用, Computer Engineering and Application], V43, P203; Shi Y H, 1999, P C EV COMP WASH DC; Stewart G., 1997, LOGISTICS INFORMATIO, V10, P62, DOI 10.1108/09576059710815716; Vincent JFV, 2006, J R SOC INTERFACE, V3, P471, DOI 10.1098/rsif.2006.0127; Wong W. P., 2008, BENCHMARKING INT J, V15, P25, DOI 10.1108/14635770810854335; Wu Xue-jing, 2010, Computer Integrated Manufacturing Systems, V16; Xi YF, 2007, INFORM J, V9, P77; Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169; Yi KG, 2005, TECHNOLOGICAL EC, V24, P48; Yu J M. G. A, 2011, THESIS S CHINA U TEC; Zandieh M, 2006, APPL MATH COMPUT, V180, P111, DOI 10.1016/j.amc.2005.11.136; Zhang FM, 2008, INT C MANAGE SCI ENG, P370, DOI 10.1109/ICMSE.2008.4668942; Zhao X, 2005, BUSINESS RES, V2, P60; Zheng P, 2008, THESIS HUNAN U CHINA	49	0	0	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1672-6529			J BIONIC ENG	J. Bionic Eng.	JUL	2013	10	3					383	395		10.1016/S1672-6529(13)60234-6		13	Engineering, Multidisciplinary; Materials Science, Biomaterials; Robotics	Engineering; Materials Science; Robotics	187VL	WOS:000322149500014		
J	Makki, B; Hosseini, MN				Makki, Behrooz; Hosseini, Mona Noori			Some refinements of the standard autoassociative neural network	NEURAL COMPUTING & APPLICATIONS			English	Article						Autoassociative neural network; Nonlinear principal component analysis; Constructive and destructive neural networks; Reinforcement learning; Genetic algorithm; Recurrent neural networks	PRINCIPAL COMPONENT ANALYSIS; DIMENSION REDUCTION; ALGORITHMS; MODELS; TRANSFORMATIONS; EXPECTATION	Improving the training algorithm, determining near-optimal number of nonlinear principal components (NLPCs), extracting meaningful NLPCs, and increasing the nonlinear, dynamic, and selective processing capability of the standard autoassociative neural network are the objectives of this article that are achieved independently by some new refinements of the network structure and the training algorithm. In addition, three different topologies of the network are presented, which make it possible to perform local nonlinear principal component analysis. Performances of all methods are evaluated by a stock price database that demonstrates their efficiency in different situations. Finally, as it will be illustrated in the last section, the proposed structures can be easily combined together, which introduce them as efficient tools in a wide range of signal processing applications.	[Makki, Behrooz; Hosseini, Mona Noori] Amirkabir Univ Technol, Tehran, Iran	Makki, B (reprint author), Amirkabir Univ Technol, 15,Taslimi St,Dibaji Jonubi St,POB 1959673965, Tehran, Iran.	behrooz.makki@gmail.com					Alvarez-Ramirez J, 2001, PHYSICA A, V301, P493, DOI 10.1016/S0378-4371(01)00410-1; Bailing Zhang, 2001, Pattern Recognition, V34; Byungjoo Y, 1994, IEEE INT C NEURAL NE, V3, P1766; Chen M-H, 2010, INT COMP S, P711; DenWux T, 2004, IEEE T FUZZY SYST, V12, P336; Duda R, 1988, PATTERN CLASSIFICATI; Embrechts MJ, 2010, INT JOINT C NEUR NET, P1; Frolov AA, 2007, IEEE T NEURAL NETWOR, V18, P698, DOI 10.1109/TNN.2007.891664; GELLABOINA MK, 2009, 7 INT C ADV PATT REC, P297, DOI DOI 10.1109/ICAPR.2009.45; Guttman L., 1941, PREDICTION PERSONAL, V48, P319; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOLMSTROM L, 1992, IEEE T NEURAL NETWOR, V3, P24, DOI 10.1109/72.105415; Honda K, 2004, IEEE T FUZZY SYST, V12, P183, DOI 10.1109/TFUZZ.2004.825073; Hsieh WW, 2001, TELLUS A, V53, P599, DOI 10.1034/j.1600-0870.2001.00251.x; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; KRUSKAL JB, 1965, J ROY STAT SOC B, V27, P251; Lappalainen H, 2000, PERSP NEURAL COMP, P93; Licciardi G, 2009, INT GEOSCI REMOTE SE, P176; Lopez-Rubio E, 2004, NEURAL NETWORKS, V17, P261, DOI 10.1016/j.neunet.2003.04.001; Makki B, 2007, IEEE IJCNN, P558, DOI 10.1109/IJCNN.2007.4371017; Makki B, 2010, NEURAL COMPUT APPL, V19, P459, DOI 10.1007/s00521-009-0328-1; Makki B, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN IMAGE AND SIGNAL PROCESSING, P336, DOI 10.1109/CIISP.2007.369191; Marseguerra M, 2005, ANN NUCL ENERGY, V32, P1191, DOI 10.1016/j.anucene.2005.03.006; Myers R, 2001, EVOL COMPUT, V9, P461, DOI 10.1162/10636560152642878; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; OJA E, 1985, J MATH ANAL APPL, V106, P69, DOI 10.1016/0022-247X(85)90131-3; Oja E, 2004, SIGNAL PROCESS, V84, P215, DOI 10.1016/j.sigpro.2003.11.005; Parekh R, 2000, IEEE T NEURAL NETWOR, V11, P436, DOI 10.1109/72.839013; Plaut D., 1986, CMUCS86126; Rajasekaran S, 2002, MATH COMPUT MODEL, V35, P229, DOI 10.1016/S0895-7177(01)00161-3; Rega G, 2005, NONLINEAR DYNAM, V41, P1, DOI 10.1007/s11071-005-2790-3; Reiser P, 1996, COMPUT CONTROL ENG J, V7, P144; RIOS A, 1995, MATH COMPUT MODEL, V21, P159, DOI 10.1016/0895-7177(94)00202-Y; Rosipal R, 2001, NEURAL COMPUT, V13, P505, DOI 10.1162/089976601300014439; Saegusa R, 2004, NEUROCOMPUTING, V61, P57, DOI 10.1016/j.neucom.2004.03.004; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Sarma P, 2008, MATH GEOSCI, V40, P3, DOI 10.1007/s11004-007-9131-7; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SHEPARD RN, 1966, J MATH PSYCHOL, V3, P287, DOI 10.1016/0022-2496(66)90017-4; Shively P., 2003, Q REV EC FINANCE, V43, P505, DOI 10.1016/S1062-9769(02)00190-4; Stamkopoulos T, 1998, IEEE T SIGNAL PROCES, V46, P3058, DOI 10.1109/78.726818; Stone JV, 2002, TRENDS COGN SCI, V6, P59, DOI 10.1016/S1364-6613(00)01813-1; Ture M, 2007, EXPERT SYST APPL, V32, P422, DOI 10.1016/j.eswa.2005.12.003; Valpola H, 2002, NEURAL COMPUT, V14, P2647, DOI 10.1162/089976602760408017; Vasudevan BG, 2004, IEEE T GEOSCI REMOTE, V42, P985, DOI 10.1109/TGRS.2004.825580; Voegtlin T, 2005, NEURAL NETWORKS, V18, P1051, DOI 10.1016/j.neunet.2005.07.005; Weingessel A, 2000, IEEE T NEURAL NETWOR, V11, P1242, DOI 10.1109/72.883408; Wen XRM, 2007, STAT PROBABIL LETT, V77, P817, DOI 10.1016/j.spl.2006.12.016; WINSBERG S, 1983, PSYCHOMETRIKA, V48, P575, DOI 10.1007/BF02293881; Xin Yao, 1999, Proceedings of the IEEE, V87, DOI 10.1109/5.784219; YOUNG FW, 1978, PSYCHOMETRIKA, V43, P279, DOI 10.1007/BF02293871; Zheng WM, 2005, NEURAL PROCESS LETT, V22, P49, DOI 10.1007/s11063-004-0036-x; Zhi-Yong Liu, 2003, Neurocomputing, V55, DOI 10.1016/S0925-2312(03)00414-4; Zohdy MA, 1997, NEUROCOMPUTING, V17, P77, DOI 10.1016/S0925-2312(97)00043-X	57	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0941-0643			NEURAL COMPUT APPL	Neural Comput. Appl.	JUN	2013	22	7-8					1461	1475		10.1007/s00521-012-0825-5		15	Computer Science, Artificial Intelligence	Computer Science	155SU	WOS:000319769300021		
J	Weng, JY; Luciw, MD; Zhang, Q				Weng, Juyang; Luciw, Matthew D.; Zhang, Qi			Brain-Like Emergent Temporal Processing: Emergent Open States	IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT			English	Article						Attention; behavior; brain-mind architecture; cognition; complexity; computer vision; perception; regression; representation; sequential abstraction; text understanding; time warping; transfer	PRIMARY VISUAL-CORTEX; TIMING-DEPENDENT PLASTICITY; RECURRENT NEURAL-NETWORKS; OBJECT RECOGNITION; LEARNING ALGORITHM; CEREBRAL-CORTEX; TIME; ATTENTION; CONNECTIONS; LANGUAGE	Informed by brain anatomical studies, we present the developmental network (DN) theory on brain-like temporal information processing. The states of the brain are at its effector end, emergent and open. A finite automaton (FA) is considered an external symbolic model of brain's temporal behaviors, but the FA uses handcrafted states and is without "internal" representations. The term "internal" means inside the network "skull." Using action-based state equivalence and the emergent state representations, the time driven processing of DN performs state-based abstraction and state-based skill transfer. Each state of DN, as a set of actions, is openly observable by the external environment (including teachers). Thus, the external environment can teach the state at every frame time. Through incremental learning and autonomous practice, the DN lumps (abstracts) infinitely many temporal context sequences into a single equivalent state. Using this state equivalence, a skill learned under one sequence is automatically transferred to other infinitely many state-equivalent sequences in the future without the need for explicit learning. Two experiments are shown as examples: The experiments for video processing showed almost perfect recognition rates in disjoint tests. The experiment for text language, using corpora from the Wall Street Journal, treated semantics and syntax in a unified interactive way.	[Weng, Juyang] Fudan Univ, Shanghai 200433, Peoples R China; [Weng, Juyang; Luciw, Matthew D.] Michigan State Univ, E Lansing, MI 48824 USA; [Zhang, Qi] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China	Weng, JY (reprint author), Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.	weng@cse.msu.edu; luciwmat@cse.msu.edu; qi_zhang@fudan.edu.cn					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Anderson J., 1993, RULES OF THE MIND; Andreolini M., 2009, P IEEE ICIT CHURCH A, P1; Bates E. A., 1998, INNATENESS EMERGENTI; Bi GQ, 2001, ANNU REV NEUROSCI, V24, P139, DOI 10.1146/annurev.neuro.24.1.139; Bichot NP, 2005, SCIENCE, V308, P529, DOI 10.1126/science.1109676; Bonvillian J., 1976, SIGN LANGUAGE STUDIE, V12, P211; BRUECKNER AL, 1986, J PHILOS, V83, P148, DOI 10.2307/2026572; BUONOMANO DV, 1995, SCIENCE, V267, P1028, DOI 10.1126/science.7863330; Callaway EM, 1998, ANNU REV NEUROSCI, V21, P47, DOI 10.1146/annurev.neuro.21.1.47; Callaway EM, 2004, NEURAL NETWORKS, V17, P625, DOI 10.1016/j.neunet.2004.04.004; Chomsky N., 1978, RULES REPRESENTATION; Daly J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2917, DOI 10.1109/IJCNN.2011.6033604; Dan Y, 2006, PHYSIOL REV, V86, P1033, DOI 10.1152/physrev.00030.2005; Deco G, 2000, VISION RES, V40, P2845, DOI 10.1016/S0042-6989(00)00140-1; Domjan M, 1998, PRINCIPLES LEARNING; Drew PJ, 2006, P NATL ACAD SCI USA, V103, P8876, DOI 10.1073/pnas.0600676103; Elman J. L., 1997, RETHINKING INNATENES; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Emami A, 2005, MACH LEARN, V60, P195, DOI 10.1007/s10994-005-0916-y; Fahlman S. E., 1990, CMUCS90100; Fei-Fei Li, 2006, IEEE Trans Pattern Anal Mach Intell, V28, P594; Feitelson D., 1988, FACTS FADS BEGINNING; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Forcada M. L., 2001, FIELD GUIDE DYNAMICA, P103; FRASCONI P, 1995, IEEE T KNOWL DATA EN, V7, P340, DOI 10.1109/69.382304; Frasconi P., 2006, MACH LEARN, V23, P532; GARDNER RA, 1969, SCIENCE, V165, P664, DOI 10.1126/science.165.3894.664; George D, 2009, PLOS COMPUTATIONAL B, V5, P1; Grossberg S, 2003, CEREB CORTEX, V13, P852, DOI 10.1093/cercor/13.8.852; Grossberg S, 2000, VISION RES, V40, P1413, DOI 10.1016/S0042-6989(99)00229-1; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hopcroft J. E., 2006, INTRO AUTOMATA THEOR, V3rd; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Ito I, 2008, NAT NEUROSCI, V11, P1177, DOI 10.1038/nn.2192; Iverson JM, 2010, J CHILD LANG, V37, P229, DOI 10.1017/S0305000909990432; Ivry RB, 2008, TRENDS COGN SCI, V12, P273, DOI 10.1016/j.tics.2008.04.002; Jaeger H., 2003, ADV NEURAL INFORM PR, P593; Jelinek F., 1990, READINGS SPEECH RECO, P450; Jenkins R, 2008, SCIENCE, V319, P435, DOI 10.1126/science.1149656; Ji Z., 2010, P IEEE INT JOINT C N, P1; Ji ZP, 2008, INT C DEVEL LEARN, P61, DOI 10.1109/DEVLRN.2008.4640806; Jordan M. I., 1986, P 8 ANN C COGN SCI S, P531; Kandel E.R., 2000, PRINCIPLES NEURAL SC, Vfourth; Karmarkar UR, 2007, NEURON, V53, P427, DOI 10.1016/j.neuron.2007.01.006; Kohonen T, 2001, SELF ORGANIZING MAPS; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LENAT D, 1995, COMMUN ACM, V38, P45, DOI 10.1145/219717.219757; Lin TN, 1996, IEEE T NEURAL NETWOR, V7, P1329; Lovejoy WS, 1991, ANN OPER RES, V28, P47, DOI 10.1007/BF02055574; Luciw M., 2010, P IEEE INT JOINT C N, P4233; Luciw M., 2010, P IEEE 9 INT C DEV L, P311; Luciw M., 2008, P IEEE INT C DEV LEA, P1; Luenberger D. G., 1969, OPTIMIZATION VECTOR; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Mauk MD, 2004, ANNU REV NEUROSCI, V27, P307, DOI 10.1146/annurev.neuro.27.070203.144247; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V2; Miikkulainen R, 2005, COMPUTATIONAL MAPS V; MINSKY M, 1991, AI MAG, V12, P34; Munakata Y, 2003, DEVELOPMENTAL SCI, V6, P413, DOI 10.1111/1467-7687.00296; NIEBUR E, 1993, VISION RES, V33, P2789, DOI 10.1016/0042-6989(93)90236-P; Oblinger D, 2011, AI MAG, V32, P126; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Omlin CW, 1996, J ACM, V43, P937, DOI 10.1145/235809.235811; Paine RW, 2005, ADAPT BEHAV, V13, P211, DOI 10.1177/105971230501300303; Paslaski S, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P3016, DOI 10.1109/IJCNN.2011.6033618; Piaget J., 1954, CONSTRUCTION REALITY; Puterman M. L, 1994, MARKOV DECISION PROC; Quartz SR, 1997, BEHAV BRAIN SCI, V20, P537; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RABINER LR, 1995, AT&T TECH J, V74, P4; Ramanan D., 2006, P NEUR INF PROC SYST, P1; REBER AS, 1980, J EXP PSYCHOL-HUM L, V6, P492, DOI 10.1037/0278-7393.6.5.492; Roelfsema PR, 2005, NEURAL COMPUT, V17, P2176, DOI 10.1162/0899766054615699; Rumelhart D. E., 1986, PARALLEL DISTRIB PRO, V1; Russell S. J., 2010, ARTIFICIAL INTELLIGE; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sit YF, 2006, NEUROCOMPUTING, V69, P1309, DOI 10.1016/j.neucom.2005.12.098; Song XY, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2795; Stockman I. J., 2004, MOVEMENT ACTION LEAR; Sun R., 2005, PSYCHOL REV, V112, P59192; Sur M, 2005, SCIENCE, V310, P805, DOI 10.1126/science.1112070; Sur M, 2001, NAT REV NEUROSCI, V2, P251, DOI 10.1038/35067562; Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1; Vygotsky L.S., 1962, THOUGHT AND LANGUAGE; Weng J., 2009, P INT JOINT C NEUR N; Weng J., 2011, NATURAL INTELLIGENCE, V1, P13; Weng J., 2006, P 5 INT C DEV LEARN, P1; Weng J., 2010, P INT JOINT C NEUR N, P1; Weng J, 2009, P IEEE 8 INT C DEV L, P1; Weng J., 2011, MSUCSE119 DEP COMP S; Weng JY, 2009, IEEE T AUTON MENT DE, V1, P68, DOI 10.1109/TAMD.2009.2021698; Weng JY, 2012, IEEE T AUTON MENT DE, V4, P29, DOI 10.1109/TAMD.2011.2159113; Weng JY, 2008, NEURAL NETWORKS, V21, P150, DOI 10.1016/j.neunet.2007.12.048; Weng JY, 2007, NEUROCOMPUTING, V70, P2303, DOI 10.1016/j.neucom.2006.07.017; Weng JY, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2983; Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599; Werbos P. J., 1994, ROOTS BACKPROPAGATIO; Wiemer JC, 2003, NEURAL COMPUT, V15, P1143, DOI 10.1162/089976603765202695; Wiser AK, 1996, J NEUROSCI, V16, P2724; Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220; Yao B., 2010, P COMP VIS PATT REC, P1; Zeng SQ, 2007, J INTELL ROBOT SYST, V50, P219, DOI 10.1007/s10846-007-9162-9	108	0	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1943-0604			IEEE T AUTON MENT DE	IEEE Trans. Auton. Ment. Dev.	JUN	2013	5	2					89	116		10.1109/TAMD.2013.2258398		28	Computer Science, Artificial Intelligence; Robotics; Neurosciences	Computer Science; Robotics; Neurosciences & Neurology	166TJ	WOS:000320580500001		
J	Perez-Benitez, JA; Padovese, LR				Perez-Benitez, J. A.; Padovese, L. R.			A system for classification of time-series data from industrial non-destructive device	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						MBN decorrelation; Plastic deformation; Carbon content; Non-destructive methods	PROBABILISTIC NEURAL-NETWORKS; SIGNALS; ALGORITHM	This work proposes a system for classification of industrial steel pieces by means of magnetic nondestructive device. The proposed classification system presents two main stages, online system stage and off-line system stage. In online stage, the system classifies inputs and saves misclassification information in order to perform posterior analyses. In the off-line optimization stage, the topology of a Probabilistic Neural Network is optimized by a Feature Selection algorithm combined with the Probabilistic Neural Network to increase the classification rate. The proposed Feature Selection algorithm searches for the signal spectrogram by combining three basic elements: a Sequential Forward Selection algorithm, a Feature Cluster Grow algorithm with classification rate gradient analysis and a Sequential Backward Selection. Also, a trash-data recycling algorithm is proposed to obtain the optimal feedback samples selected from the misclassified ones. (c) 2012 Elsevier Ltd. All rights reserved.	[Perez-Benitez, J. A.] Inst Politecn Nacl, IPN ESIME SEPI, Lab Evaluac Nodestruct Electromagnet LENDE, Mexico City, DF, Mexico; [Padovese, L. R.] Univ Sao Paulo, Escola Politecn, Dept Engn Mecan, BR-05508900 Sao Paulo, Brazil	Perez-Benitez, JA (reprint author), Inst Politecn Nacl, IPN ESIME SEPI, Lab Evaluac Nodestruct Electromagnet LENDE, Zacantenco Edif Z-4, Mexico City, DF, Mexico.	benitez_edl@yahoo.es			FAPESP [2008/10859-0]; CNPq [490617/2008-5]	The authors would like to thank the financial support of Brazilian agencies FAPESP/ Proc. No. 2008/10859-0 and CNPq/ proc. No. 490617/2008-5.	Begg Rezaul K., 2005, IEEE T BIOMED ENG, V52; Berthold MR, 1998, NEUROCOMPUTING, V19, P167, DOI 10.1016/S0925-2312(97)00063-5; Carvalho AA, 2006, NDT&E INT, V39, P661, DOI 10.1016/j.ndteint.2006.04.003; Castellano G, 1997, IEEE T NEURAL NETWOR, V8, P519, DOI 10.1109/72.572092; Francesca Cau, 2006, ENG APPL ARTIF INTEL, V19, P753; Frean M., 1990, NEURAL COMPUT, V2, P198, DOI 10.1162/neco.1990.2.2.198; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarmulak J, 2001, ENG APPL ARTIF INTEL, V14, P401, DOI 10.1016/S0952-1976(01)00026-4; Masnata A, 1996, NDT&E INT, V29, P87, DOI 10.1016/0963-8695(95)00053-4; Perez-Benitez J A, 2011, Expert Systems with Applications, V38, DOI 10.1016/j.eswa.2011.02.088; Perez-Benitez JA, 2011, EXPERT SYST APPL, V38, P3192, DOI 10.1016/j.eswa.2010.09.007; Ramakrishnan S, 2009, TELECOMMUN SYST, V40, P67, DOI 10.1007/s11235-008-9138-5; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Specht D F, 1990, IEEE Trans Neural Netw, V1, P111, DOI 10.1109/72.80210; Taisuke Matsuda, 2010, J ELECT ENG, V61, P81; Tsai Hih-Yang, 2000, OMEGA, V28, P513; Uraikul V, 2007, ENG APPL ARTIF INTEL, V20, P115, DOI 10.1016/j.engappai.2006.07.002; Vicen R, 2004, ULTRASONICS, V42, P355, DOI 10.1016/j.ultras.2003.11.002; Wang Y, 2009, PATTERN RECOGN LETT, V30, P661, DOI 10.1016/j.patrec.2009.02.001; Zaknich A, 1998, IEEE T SIGNAL PROCES, V46, P1980, DOI 10.1109/78.700969	20	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976			ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	MAR	2013	26	3					974	983		10.1016/j.engappai.2012.09.006		10	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	105RX	WOS:000316091300005		
J	Wolf, C; Gaida, D; Stuhlsatz, A; Ludwig, T; McLoone, S; Bongards, M				Wolf, Christian; Gaida, Daniel; Stuhlsatz, Andre; Ludwig, Thomas; McLoone, Sean; Bongards, Michael			Predicting organic acid concentration from UV/vis spectrometry measurements - a comparison of machine learning techniques	TRANSACTIONS OF THE INSTITUTE OF MEASUREMENT AND CONTROL			English	Article						Anaerobic digestion; classification; feature extraction; GerDA; LDA; neural networks; online measurement; organic acids; random forest; RVM; SVM; UV/vis spectroscopy	RELEVANCE VECTOR MACHINE; VOLATILE FATTY-ACIDS; NEURAL-NETWORK; ALGORITHM; PRODUCTS; BIOGAS	The concentration of organic acids in anaerobic digesters is one of the most critical parameters for monitoring and advanced control of anaerobic digestion processes. Thus, a reliable online-measurement system is absolutely necessary. A novel approach to obtaining these measurements indirectly and online using UV/vis spectroscopic probes, in conjunction with powerful pattern recognition methods, is presented in this paper. An UV/vis spectroscopic probe from S::CAN is used in combination with a custom-built dilution system to monitor the absorption of fully fermented sludge at a spectrum from 200 to 750 nm. Advanced pattern recognition methods are then used to map the non-linear relationship between measured absorption spectra to laboratory measurements of organic acid concentrations. Linear discriminant analysis, generalized discriminant analysis (GerDA), support vector machines (SVM), relevance vector machines, random forest and neural networks are investigated for this purpose and their performance compared. To validate the approach, online measurements have been taken at a full-scale 1.3-MW industrial biogas plant. Results show that whereas some of the methods considered do not yield satisfactory results, accurate prediction of organic acid concentration ranges can be obtained with both GerDA and SVM-based classifiers, with classification rates in excess of 87% achieved on test data.	[Wolf, Christian; McLoone, Sean] Natl Univ Ireland Maynooth, Dept Elect Engn, Maynooth, Kildare, Ireland; [Wolf, Christian; Gaida, Daniel; Ludwig, Thomas; Bongards, Michael] Cologne Univ Appl Sci, Inst Automat & Ind IT, D-51643 Gummersbach, Germany; [Stuhlsatz, Andre] Univ Appl Sci Dusseldorf, Inst Informat Technol, Dept Mech & Proc Engn, Dusseldorf, Germany	Wolf, C (reprint author), Cologne Univ Appl Sci, Inst Automat & Ind IT, Steinmullerallee 1, D-51643 Gummersbach, Germany.	christian.wolf@fh-koeln.de					Balabin RM, 2011, MICROCHEM J, V98, P121, DOI 10.1016/j.microc.2010.12.007; Batista L, 2010, FOOD CHEM, V122, P1067, DOI 10.1016/j.foodchem.2010.03.076; Bongards M, 2007, ONLINE KONZENTRATION, P173; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cheung HNB, 2010, BIORESOURCE TECHNOL, V101, P5925, DOI 10.1016/j.biortech.2010.02.062; Clerc M., 2006, PARTICLE SWARM OPTIM; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Diamantis V, 2006, ANAL CHIM ACTA, V573, P189, DOI 10.1016/j.aca.2006.05.036; Duda R, 2001, PATTERN CLASSIFICATI; Guo L, 2011, ISPRS J PHOTOGRAMM, V66, P56, DOI 10.1016/j.isprsjprs.2010.08.007; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsu C.-W., 2003, PRACTICAL GUIDE SUPP; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Langergraber G, 2003, WATER SCI TECHNOL, V47, P63; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; McLoone S, 1998, IEEE T NEURAL NETWOR, V9, P669, DOI 10.1109/72.701180; Moore H, 2009, MATLAB ENG; OSMAN H, 1994, IEEE T PATTERN ANAL, V16, P837, DOI 10.1109/34.308481; Ozkaya B, 2007, ENVIRON MODELL SOFTW, V22, P815, DOI 10.1016/j.envsoft.2006.03.004; Palacio-Barco E, 2010, ANAL CHIM ACTA, V668, P74, DOI 10.1016/j.aca.2009.12.019; Punal A, 2003, WATER SCI TECHNOL, V48, P103; R Development Core Team, 2010, R LANG ENV STAT COMP; Rodrigues JEA, 2010, ANAL CHIM ACTA, V674, P166, DOI 10.1016/j.aca.2010.06.029; Schmidt H, 2008, THESIS COLOGNE U APP; Silva C, 2010, STUD COMPUT INTELL, V255, P1, DOI 10.1007/978-3-642-04533-2; Steyer JP, 2002, WATER SCI TECHNOL, V45, P133; Strik DPBTB, 2005, ENVIRON MODELL SOFTW, V20, P803, DOI 10.1016/j.envsoft.2004.09.006; Stuhlsatz A, 2010, P INT C PATT REC ICP; Stuhlsatz A, 2010, P 2010 INT JOINT C N; Tipping ME, 2000, ADV NEUR IN, V12, P652; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tipping ME, 2009, SPARSEBAYES 2 0 EFFI; Wang DL, 2010, IEEE T INSTRUM MEAS, V59, P3237, DOI 10.1109/TIM.2010.2047551; Yogameena B., 2010, Journal of Computer Sciences, V6, DOI 10.3844/jcssp.2010.1021.1026	38	0	0	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0142-3312			T I MEAS CONTROL	Trans. Inst. Meas. Control	FEB	2013	35	1			SI		5	15		10.1177/0142331211403797		11	Automation & Control Systems; Instruments & Instrumentation	Automation & Control Systems; Instruments & Instrumentation	134AV	WOS:000318182900002		
J	Ahmed, S; Merino, LM; Mao, ZJ; Meng, J; Robbins, K; Huang, YF			IEEE	Ahmed, Shaheen; Merino, Lenis Mauricio; Mao, Zijing; Meng, Jia; Robbins, Kay; Huang, Yufei			A Deep Learning method for Classification of images RSVP events with EEG data	2013 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP)	IEEE Global Conference on Signal and Information Processing		English	Proceedings Paper	IEEE Global Conference on Signal and Information Processing (GlobalSIP)	DEC 03-05, 2013	Austin, TX	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		RSVP; feature clustering; Deep learning; DBN; cLDA; SVM		In this paper, we investigated Deep Learning (DL) for characterizing and detecting target images in an image rapid serial visual presentation (RSVP) task based on EEG data. We exploited DL technique with input feature clusters to handle high dimensional features related to time - frequency events. The method was applied to EEG recordings of a RSVP experiment with multiple sessions and subjects. For classification of target and non-target images, a deep belief net (DBN) classifier was based on the uncorrelated features, which was constructed from original correlated features using clustering method. The performance of the proposed DBN was tested for different combinations of hidden units and hidden layers on multiple subjects. The results of DBN were compared with cluster Linear Discriminant Analysis (cLDA) and Support vector machine (SVM) and DBN demonstrated better performance in all tested cases. There was an improvement of 10 - 25% for certain cases. We also demonstrated how DBN is used to characterize brain activities.	[Ahmed, Shaheen; Merino, Lenis Mauricio; Mao, Zijing; Huang, Yufei] Univ Texas San Antonio, Dept Elect & Comp Engn, San Antonio, TX 78249 USA; [Robbins, Kay] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX USA; [Meng, Jia] MIT, Picower Inst Learning & Memory, Cambridge, MA 02139 USA	Ahmed, S (reprint author), Univ Texas San Antonio, Dept Elect & Comp Engn, San Antonio, TX 78249 USA.						Bengio Y., 2006, NIPS; Bigdely-Shamlo N, 2008, IEEE T NEUR SYS REH, V16, P432, DOI 10.1109/TNSRE.2008.2003381; ERIKSEN CW, 1969, J EXP PSYCHOL, V79, P1, DOI 10.1037/h0026873; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K., 2009, ICCV; Mia J., 2012, PLOS ONE, V7	6	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2376-4066		978-1-4799-0248-4	IEEE GLOB CONF SIG			2013							33	36				4	Engineering, Electrical & Electronic	Engineering	BC2FE	WOS:000350825600009		
B	Amaral, T; Silva, LM; Alexandre, LA; Kandaswamy, C; Santos, JM; Sa, JM		Castro, F; Gelbukh, A; Mendoza, MG		Amaral, Telmo; Silva, Luis M.; Alexandre, Lus A.; Kandaswamy, Chetak; Santos, Jorge M.; de Sa, Joaquim Marques			Using Different Cost Functions to Train Stacked Auto-encoders	2013 12TH MEXICAN INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (MICAI 2013)	Mexican International Conference on Artificial Intelligence-MICAI		English	Proceedings Paper	12th Mexican International Conference on Artificial Intelligence (MICAI)	NOV 24-30, 2013	Mexico City, MEXICO	Mexican Soc Artificial Intelligence, Univ Autonoma Metropolitana Azcapotzalco, Univ Autonoma Estado Hidalgo, Centro Investigacion Computac Inst Politccnico Nacl, Tecnologico Monterrey, Mexican Govt, Museo Nacl Antropologia, Inst Nacl Antropologia & Historia		cost functions; stacked auto-encoders; deep neural networks		Deep neural networks comprise several hidden layers of units, which can be pre-trained one at a time via an unsupervised greedy approach. A whole network can then be trained (fine-tuned) in a supervised fashion. One possible pre-training strategy is to regard each hidden layer in the network as the input layer of an auto-encoder. Since auto-encoders aim to reconstruct their own input, their training must be based on some cost function capable of measuring reconstruction performance. Similarly, the supervised fine-tuning of a deep network needs to be based on some cost function that reflects prediction performance. In this work we compare different combinations of cost functions in terms of their impact on layer-wise reconstruction performance and on supervised classification performance of deep networks. We employed two classic functions, namely the cross-entropy (CE) cost and the sum of squared errors (SSE), as well as the exponential (EXP) cost, inspired by the error entropy concept. Our results were based on a number of artificial and real-world data sets.	[Amaral, Telmo; Silva, Luis M.; Kandaswamy, Chetak; Santos, Jorge M.; de Sa, Joaquim Marques] Univ Porto, Inst Engn Biomed INEB, P-4100 Oporto, Portugal; [Silva, Luis M.] Univ Aveiro, Dept Matemat, Aveiro, Portugal; [Alexandre, Lus A.] Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal; [Santos, Jorge M.] Inst Politecn Porto, Inst Super Engn, Dept Matemat, Oporto, Portugal; [de Sa, Joaquim Marques] Univ Porto, Fac Engn, Dept Engn Electrotecn & Comp, P-4100 Oporto, Portugal	Amaral, T (reprint author), Univ Porto, Inst Engn Biomed INEB, Rua Campo Alegre 823, P-4100 Oporto, Portugal.	tga@fe.up.pt; lmas@ua.pt	Alexandre, Luis/E-8770-2013	Alexandre, Luis/0000-0002-5133-5025			Amaral T., 2013, 12013 INEBNNIG; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2007, NIPS, V19, P153; Bishop CM, 2006, PATTERN RECOGNITION; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; de Sa Marques J., 2013, STUDIES COMPUTATIONA, V420; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Larochelle H., 2007, ICML 2007, V227, P473; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2605-3; 978-1-4799-2604-6	MEX INT CONF ARTIF I			2013							114	120		10.1109/MICAI.2013.20		7	Computer Science, Artificial Intelligence	Computer Science	BC1JM	WOS:000350153700017		
S	Audhkhasi, K; Osoba, O; Kosko, B			IEEE	Audhkhasi, Kartik; Osoba, Osonde; Kosko, Bart			Noise Benefits in Backpropagation and Deep Bidirectional Pre-training	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc		Backpropagation; bidirectional associative memory; noise benefit; neural network; stochastic resonance; Expectation-Maximization algorithm	ASSOCIATIVE MEMORIES; STOCHASTIC RESONANCE; EM ALGORITHM; LEVY NOISE; NEURON; MODELS	We prove that noise can speed convergence in the backpropagation algorithm. The proof consists of two separate results. The first result proves that the backpropagation algorithm is a special case of the generalized ExpectationMaximization (EM) algorithm for iterative maximum likelihood estimation. The second result uses the recent EM noise benefit to derive a sufficient condition for backpropagation training. The noise adds directly to the training data. A noise benefit also applies to the deep bidirectional pre-training of the neural network as well as to the backpropagation training of the network. The geometry of the noise benefit depends on the probability structure of the neurons at each layer. Logistic sigmoidal neurons produce a forbidden noise region that lies below a hyperplane. Then all noise on or above the hyperplane can only speed convergence of the neural network. The forbidden noise region is a sphere if the neurons have a Gaussian signal or activation function. These noise benefits all follow from the general noise benefit of the EM algorithm. Monte Carlo sample means estimate the population expectations in the EM algorithm. We demonstrate the noise benefits using MNIST digit classification.	[Audhkhasi, Kartik; Osoba, Osonde; Kosko, Bart] Univ So Calif, Signal & Image Proc Inst, Dept Elect Engn, Los Angeles, CA 90089 USA	Audhkhasi, K (reprint author), Univ So Calif, Signal & Image Proc Inst, Dept Elect Engn, Los Angeles, CA 90089 USA.	kosko@sipi.usc.edu					An G., 1996, NEURAL COMPUT, V674, P643; Bishop C. M., 2006, PATTERN RECOGNITION, V4; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; BULSARA AR, 1989, BIOL CYBERN, V61, P211, DOI 10.1007/BF00198768; Cover T. M., 2012, ELEMENTS INFORM THEO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Franzke B, 2011, PHYS REV E, V84, DOI 10.1103/PhysRevE.84.041112; Gammaitoni L, 1998, REV MOD PHYS, V70, P223, DOI 10.1103/RevModPhys.70.223; HAYAKAWA Y, 1995, PHYS REV E, V51, pR2693; Haykin S., 1998, NEURAL NETWORKS COMP; Hinton G., TRAINING DEEP AUTOEN; Hinton G., 2012, IEEE SIGNAL PROCESSI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; KOSKO B, 1988, IEEE T SYST MAN CYB, V18, P49, DOI 10.1109/21.87054; Kosko B, 1991, NEURAL NETWORKS FUZZ; Kosko B., 2006, NOISE; KOSKO B, 1987, APPL OPTICS, V26, P4947, DOI 10.1364/AO.26.004947; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; MATSUOKA K, 1992, IEEE T SYST MAN CYB, V22, P436, DOI 10.1109/21.155944; McLachlan G.J., 2007, EM ALGORITHM EXTENSI, V382; Oakes D, 1999, J ROY STAT SOC B, V61, P479, DOI 10.1111/1467-9868.00188; Osoba O., 2013, REVIEW; Osoba O., 2013, NEURAL NETWORKS; Osoba O, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P3178, DOI 10.1109/IJCNN.2011.6033642; Patel A, 2011, IEEE T SIGNAL PROCES, V59, P488, DOI 10.1109/TSP.2010.2091409; Patel A, 2008, IEEE T NEURAL NETWOR, V19, P1993, DOI 10.1109/TNN.2008.2005610; Patel A, 2007, INT CONF ACOUST SPEE, P1413; Patel A, 2009, NEURAL NETWORKS, V22, P697, DOI 10.1016/j.neunet.2009.06.044; Patel A, 2010, IEEE SIGNAL PROC LET, V17, P1005, DOI 10.1109/LSP.2010.2059376; Peel David, 2000, FINITE MIXTURE MODEL; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Smolensky P., 1986, INFORM PROCESSING DY; TEICHER H, 1963, ANN MATH STAT, V34, P1265, DOI 10.1214/aoms/1177703862; Wilde M., 2009, J PHYS A, V42	35	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200315		
J	Azim, T; Niranjan, M		Sanei, S; Smaragdis, P; Nandi, A; Ho, ATS; Larsen, J		Azim, Tayyaba; Niranjan, Mahesan			INDUCING DISCRIMINATION IN BIOLOGICALLY INSPIRED MODELS OF VISUAL SCENE RECOGNITION	2013 IEEE INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING (MLSP)	IEEE International Workshop on Machine Learning for Signal Processing		English	Proceedings Paper	23rd IEEE International Workshop on Machine Learning for Signal Processing (MLSP)	SEP 22-25, 2013	Southampton, ENGLAND	IEEE, IEEE Signal Proc Soc, Machine Learning Signal Proc Tech Comm		Deep Learning; Restricted Boltzmann Machine; Multivariate Gaussian model; Fisher Kernel		To enhance the understanding of human perception and mimic it into an artificial system, several types of graphical models have been proposed that emulate the functionality of neurons in biological neural networks. In this work, we investigate the discriminatory power of two such probabilistic models of vision: a multivariate Gaussian model [1] and a restricted Boltzmann machine [2], both widely used to solve classification problems in computer vision. We quantify the generative ability of these models on standard benchmark data sets and show that neither approach on their own is powerful enough to carry out vision tasks because of the very low discrimination they achieve. There is clearly a need for inducing discrimination by a mechanism that exploits these generative models. We show that the Fisher kernels [3] derived from both the Gaussian and restricted Boltzmann machine can significantly improve the classification performance on benchmark tasks while maintaining the biological plausibility of its implementation [4].	[Azim, Tayyaba; Niranjan, Mahesan] Univ Southampton, Sch Elect & Comp Sci, Southampton, Hants, England	Azim, T (reprint author), Univ Southampton, Sch Elect & Comp Sci, Southampton, Hants, England.	ta2e09@ecs.soton.ac.uk; mn@ecs.soton.ac.uk					Bottou L., 2008, NIPS, P161; Ciresan D.C., 2012, CVPR; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Denve S., 2007, J NEUROSCI, V27, P5744; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hinton G, 2010, 2010003 UTML TR; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Karklin Y, 2009, NATURE, V457, P83, DOI 10.1038/nature07481; Larochelle H., 2008, ICML, P536; Lazebnik S., 2005, PAMI, V27, P1; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lowe D., 1999, ICCV, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Navneet D., 2005, COMPUTER VISION PATT, P886; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Perronnin F., 2010, ECCV; Salakhutdinov R., 2008, INT C MACH LEARN HEL, P872; Sanchez J., 2013, RR8209 INRIA; Shawe-Taylor John, 2004, KERNEL METHODS PATTE; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Viville T., 2004, NEUROCOMPUTING, V58-60, P923	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-0363		978-1-4799-1180-6	IEEE INT WORKS MACH			2013										10.1109/MLSP.2013.6661977		6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BB7OP	WOS:000345844100083		
B	Banerjee, B; Dutta, JK		Hu, X; Lin, TY; Raghavan, V; Wah, B; BaezaYates, R; Fox, G; Shahabi, C; Smith, M; Yang, Q; Ghani, R; Fan, W; Lempel, R; Nambiar, R		Banerjee, Bonny; Dutta, Jayanta K.			Hierarchical Feature Learning from Sensorial Data by Spherical Clustering	2013 IEEE INTERNATIONAL CONFERENCE ON BIG DATA			English	Proceedings Paper	IEEE International Conference on Big Data (Big Data)	OCT 06-09, 2013	Santa Clara, CA	IEEE, IEEE Comp Soc, CCF, Yahoo Labs, CISCO		learning hierarchical representations; repeating coincidences; spherical clustering; Hebbian rule	RETINAL PROJECTIONS; RECEPTIVE-FIELDS; VISUAL-CORTEX; DEEP BELIEF; AREA V2; ARCHITECTURE; RECOGNITION; RESPONSES; STIMULI; SHAPES	Surveillance sensors are a major source of unstructured Big Data. Discovering and recognizing spatiotemporal objects (e.g., events) in such data is of paramount importance to the security and safety of facilities and individuals. What kind of computational model is necessary for discovering spatiotemporal objects at the level of abstraction they occur? Hierarchical invariant feature learning is the crux to the problems of discovery and recognition in Big Data. We present a multilayered convergent neural architecture for storing repeating spatially and temporally coincident patterns in data at multiple levels of abstraction. A node is the canonical computational unit consisting of neurons. Neurons are connected in and across nodes via bottom-up, top-down and lateral connections. The bottom-up weights are learned to encode a hierarchy of overcomplete and sparse feature dictionaries from space- and time-varying sensorial data by recursive layer-by-layer spherical clustering. The model scales to full-sized high-dimensional input data and also to an arbitrary number of layers thereby having the capability to capture features at any level of abstraction. The model is fully-learnable with only two manually tunable parameters. The model is general-purpose (i.e., there is no modality-specific assumption for any spatiotemporal data), unsupervised and online. We use the learning algorithm, without any alteration, to learn meaningful feature hierarchies from images and videos which can then be used for recognition. Besides being online, operations in each layer of the model can be implemented in parallelized hardware, making it very efficient for real world Big Data applications.	[Banerjee, Bonny] Memphis State Univ, Inst Intelligent Syst, Memphis, TN 38152 USA	Banerjee, B (reprint author), Memphis State Univ, Inst Intelligent Syst, Memphis, TN 38152 USA.	bonnybanerjee@yahoo.com; jkdutta@memphis.edu					Bach-y-Rita P, 2003, TRENDS COGN SCI, V7, P541, DOI 10.1016/j.tics.2003.10.013; Blake C., 1998, UCI REPOSITORY MACHI; CONSTANTINEPATON M, 1978, SCIENCE, V202, P639, DOI 10.1126/science.309179; Datta A, 2001, PATTERN RECOGN, V34, P617, DOI 10.1016/S0031-3203(00)00013-3; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Dutta J. K., 2013, ARXIV13082350; Einhauser W, 2002, EUR J NEUROSCI, V15, P475, DOI 10.1046/j.0953-816x.2001.01885.x; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; Fukushima K, 2003, NEUROCOMPUTING, V51, P161, DOI 10.1016/S0925-2312(02)00614-8; George D., 2008, THESIS STANFORD U CA; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hegde J, 2000, J NEUROSCI, V20, part. no.; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Ji S., 2010, INT C MACH LEARN, P221; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Le Q. V., 2011, IEEE C COMP VIS PATT, P3361; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; METIN C, 1989, P NATL ACAD SCI USA, V86, P357, DOI 10.1073/pnas.86.1.357; Pati Y. C., 1993, 27 AS C SIGN SYST CO, P40, DOI 10.1109/acssc.1993.342465; Ranzato M., 2007, J MACHINE LEARNING R, V2, P371; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Sirosh J, 1997, NEURAL COMPUT, V9, P577, DOI 10.1162/neco.1997.9.3.577; Theis L, 2011, J MACH LEARN RES, V12, P3071; Vincent P., 2008, INT C MACH LEARN, P1096; von Melchner L, 2000, NATURE, V404, P871, DOI 10.1038/35009102; Zhu L, 2008, LECT NOTES COMPUT SC, V5303, P759	30	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-1292-6; 978-1-4799-1293-3				2013												7	Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BA0BK	WOS:000330831300184		
J	Barone, RE; Salerno, V; Siniscalchi, SM		Simos, T; Psihoyios, G; Tsitouras, C		Barone, Rosamaria E.; Salerno, Valerio; Siniscalchi, Sabato Marco			An Introductory Study on Deep Neural Networks for High Resolution Aerial Images	11TH INTERNATIONAL CONFERENCE OF NUMERICAL ANALYSIS AND APPLIED MATHEMATICS 2013, PTS 1 AND 2 (ICNAAM 2013)	AIP Conference Proceedings		English	Proceedings Paper	11th International Conference of Numerical Analysis and Applied Mathematics (ICNAAM)	SEP 21-27, 2013	GREECE	European Soc Computat Methods Sci, Engn & Technol, Santilli Fdn		artificial neural networks; geospatial database; high resolution images	RECOGNITION; EXTRACTION; ROADS; NETS	The aim of this paper is to discussthe use deep neural networks (DNNs) for road detection from high-resolution aerial images. DNNs are a powerful mathematical model for information processing that has been proven to be effective to accomplish several complex tasks includingcoding and classification of image data. The DNN with its many trainable weights allows taking a large context into account that is essential for the difficult problem of detect roads from aerial image. Furthermore it allows to progressively combining lower-level features or concepts into more abstract and higher-level representations. Thus, we believe useful to discuss possible applications DNNsfor roads detection in the present work.	[Barone, Rosamaria E.; Salerno, Valerio; Siniscalchi, Sabato Marco] Kore Univ Enna, Fac Engn & Architecture, I-94100 Enna, Italy	Barone, RE (reprint author), Kore Univ Enna, Fac Engn & Architecture, CittadellaUniv, I-94100 Enna, Italy.		Siniscalchi, Sabato Marco/	Siniscalchi, Sabato Marco/0000-0002-0770-0507			Bae JH, 1998, PATTERN RECOGN LETT, V19, P701, DOI 10.1016/S0167-8655(98)00048-8; BAJCSY R, 1976, IEEE T SYST MAN CYB, V6, P623, DOI 10.1109/TSMC.1976.4309568; Bengio Y., 2007, LARGE SCALE KERNEL M, V34; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Danchenko P, 2007, ACTA ASTRONAUT, V60, P622, DOI 10.1016/j.actaastro.2006.07.022; Haykin Simon O., 2008, NEURAL NETWORKS LEAR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ho ML, 2012, APPL SOFT COMPUT, V12, P3514, DOI 10.1016/j.asoc.2012.07.004; Hu J, 2007, IEEE T GEOSCI REMOTE, V45, P4144, DOI 10.1109/TGRS.2007.906107; Huang X, 2009, INT J REMOTE SENS, V30, P1977, DOI 10.1080/01431160802546837; Jain V., 2008, ADV NEURAL INFORM PR, V21, P769; Lahnajarvi JJT, 2004, NEUROCOMPUTING, V56, P345, DOI 10.1016/j.neucom.2003.03.001; Laptev I, 2000, MACH VISION APPL, V12, P23, DOI 10.1007/s001380050121; MNIH V, 2010, COMP VIS ECCV 2010, V6316, P210, DOI 10.1007/978-3-642-15567-3_16; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Mokhtarzade M, 2007, INT J APPL EARTH OBS, V9, P32, DOI 10.1016/j.jag.2006.05.001; Mokhtarzade M., 2008, INT ARCH PHOT REM SE, V549; Nair V., 2009, NEURAL INFORM PROCES, V22, P1339; RAVICHANDRAN A, 1995, NEURAL NETWORKS, V8, P481, DOI 10.1016/0893-6080(94)00077-Y; Siniscalchi S. M., 2007, P ASRU KYOT JAP DEC, P556; Siniscalchi Sabato Marco, 2012, INTERSPEECH; Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008; Tang Yichuan, 2010, INT C MACH LEARN, V28; Tesauro G, 2002, ARTIF INTELL, V134, P181, DOI 10.1016/S0004-3702(01)00110-2; Vinyals Oriol, 2012, AC SPEECH SIGN PROC; Wickens JR, 1998, J NEUROPHYSIOL, V79, P2358; Zell A., 2000, SIMULATION NEURONALE	28	0	0	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X		978-0-7354-1185-2	AIP CONF PROC			2013	1558						1232	1236		10.1063/1.4825733		5	Mathematics, Applied; Physics, Applied	Mathematics; Physics	BA0IB	WOS:000331472800294		
J	Bell, P; Swietojanski, P; Renals, S			IEEE	Bell, Peter; Swietojanski, Pawel; Renals, Steve			MULTI-LEVEL ADAPTIVE NETWORKS IN TANDEM AND HYBRID ASR SYSTEMS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		deep neural networks; tandem; hybrid; MLAN; TED; BBC	SPEECH RECOGNITION	In this paper we investigate the use of Multi-level adaptive networks (MLAN) to incorporate out-of-domain data when training large vocabulary speech recognition systems. In a set of experiments on multi-genre broadcast data and on TED lecture recordings we present results using of out-of-domain features in a hybrid DNN system and explore tandem systems using a variety of input acoustic features. Our experiments indicate using the MLAN approach in both hybrid and tandem systems results in consistent reductions in word error rate of 5-10% relative.	[Bell, Peter; Swietojanski, Pawel; Renals, Steve] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland	Bell, P (reprint author), Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland.						[Anonymous], 1998, COMPUTER SPEECH LANG, V12; Bell P.J., 2012, P IEEE WORKSH SPOK L; Bergstra J, 2010, P SCIPY; Bourlard H., 1992, P ICASSP 92, V2, P349; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Cettolo M., 2012, P 16 C EUR ASS MACH, P261; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Federico M, 2012, P INT WORKSH SPOK LA; Grezl F., 2007, P ICASSP; Grezl Frantisek, 2011, P ASRU; Hain T, 2012, IEEE T AUDIO SPEECH, V20, P486, DOI 10.1109/TASL.2011.2163395; Hasler E., 2012, P IWSLT; HERMANSKY H, 2000, P ICASSP, P1635; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOCHBERG MM, 1995, INT CONF ACOUST SPEE, P69, DOI 10.1109/ICASSP.1995.479275; Kershaw D, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1325; Le VB, 2010, INT CONF ACOUST SPEE, P4866, DOI 10.1109/ICASSP.2010.5495116; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Pinto J., 2009, P ASRU; Povey D., 2005, P ICASSP; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Robinson AJ, 2002, SPEECH COMMUN, V37, P27, DOI 10.1016/S0167-6393(01)00058-9; Sainath T., 2011, P ASRU; Sainath T.N., 2012, P ICASSP; Schwarz P, 2006, P ICASSP; Seide F., 2011, P ASRU; Seide F., 2011, P INTERSPEECH; Sivadas S., 2004, P ICASSP; Stolcke Andreas, 2006, P ICASSP; Thomas S., 2012, P INTERSPEECH; Thomas Samuel, 2012, P ICASSP; YOUNG SJ, 1994, COMPUT SPEECH LANG, V8, P369, DOI 10.1006/csla.1994.1019; Zhu Q., 2005, P INTERSPEECH	34	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							6975	6979				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507027		
J	Berka, T; Mayer, HA		Blum, C		Berka, Tobias; Mayer, Helmut A.			Evolving Artificial Neural Networks for Nonlinear Feature Construction	GECCO'13: PROCEEDINGS OF THE 2013 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE			English	Proceedings Paper	15th Genetic and Evolutionary Computation Conference (GECCO)	JUL 06-10, 2013	Amsterdam, NETHERLANDS	Assoc Comp Machinery, Special Interest Grp Genet & Evolutionary Computat (ACM SIGEVO)		Multi-layer perceptron; Evolutionary algorithm; Nonlinear dimensionality reduction; Feature construction; Classification	EXTREME LEARNING-MACHINE; COMPONENT ANALYSIS; CLASSIFICATION	We use neuroevolution to construct nonlinear transformation functions for feature construction that map points in the original feature space to augmented pattern vectors and improve the performance of generic classifiers. Our research demonstrates that we can apply evolutionary algorithms to both adapt the weights of a fully connected standard multilayer perceptron (MLP), and optimize the topology of a generalized multi-layer perceptron (GMLP). The evaluation of the MLPs on four commonly used data sets shows an improvement in classification accuracy ranging from 4 to 13 percentage points over the performance on the original pattern set. The GMLPs obtain a slightly better accuracy and conserve 14% to 54% of all neurons and between 40% and 89% of all connections compared to the standard MLP.	[Berka, Tobias] Univ Cambridge, Cambridge CB3 0FD, England	Berka, T (reprint author), Univ Cambridge, 15 JJ Thomson Ave,William Gates Bldg, Cambridge CB3 0FD, England.	tobias.berka@cl.cam.ac.uk; helmut@cosy.sbg.ac.at					Aggarwal C., 2010, P SDM, P607; Aizerman A, 1964, AUTOMAT REM CONTR, V25, P821; Back T., 1996, EVOLUTIONARY ALGORIT; Bengio Y., 2006, P NIPS, P153; Berka T., 2012, P ICPRAM INSTICC; Bishop C.M., 1995, NEURAL NETWORKS PATT; Chin T.-J., 2006, P BMVC, P939; Coelho A., 2001, P GEN EV COMP C SAN, P266; Cortez P, 2009, DECIS SUPPORT SYST, V47, P547, DOI 10.1016/j.dss.2009.05.016; Dragusu M., 2012, P WIVACE IT, P1; Frank A, 2010, UCI MACHINE LEARNING; Guo H, 2006, PATTERN RECOGN, V39, P980, DOI 10.1016/j.patcog.2005.10.001; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y; Huber R., 1996, P WORLD C NEUR NETW, P1063; Ittner A., 1996, P 2 INT C KNOWL DISC, P108; John G, 1994, P 11 INT C MACH LEAR, V129, P121; Kim KI, 2005, IEEE T PATTERN ANAL, V27, P1351; Mayer A., 2006, P CI NOV; Mayer HA, 2002, IEEE IJCNN, P1773, DOI 10.1109/IJCNN.2002.1007787; Neshatian K, 2012, IEEE T EVOLUT COMPUT, V16, P645, DOI 10.1109/TEVC.2011.2166158; Ranzato M., 2007, P AISTATS, V2, P860; RUMELHART DE, 1994, COMMUN ACM, V37, P87, DOI 10.1145/175247.175256; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scott M. J. J., 1998, P BMVC; Sherrah J., 1997, P 2 INT C GEN PROGR, P304; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; STREET WN, 1993, P SOC PHOTO-OPT INS, V1905, P861, DOI 10.1117/12.148698; Vapnik V. N., 1995, NATURE STAT LEARNING; Yao X, 1999, P IEEE, V87, P1423; Zhang Y, 2011, APPL SOFT COMPUT, V11, P1087, DOI 10.1016/j.asoc.2010.02.008; Zhu QY, 2005, PATTERN RECOGN, V38, P1759, DOI 10.1016/j.patcog.2005.03.028; Ziemke T., 1999, P KHEP WORKSH	34	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-4503-1963-8				2013							1037	1044				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BFZ66	WOS:000321981300130		
J	Carneiro, G; Liao, ZB; Chin, TJ		DeSouza, P; Engelke, U; Rahman, A		Carneiro, Gustavo; Liao, Zhibin; Chin, Tat-Jun			Closed-Loop Deep Vision	2013 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES & APPLICATIONS (DICTA)			English	Proceedings Paper	International Conference on Digital Image Computing - Techniques and Applications (DICTA)	NOV 26-28, 2013	Hobart, AUSTRALIA	IEEE, APRS, Australian Govt, Dept Def, Def Sci & Technol Org, Canon Informat Syst Res Australia Pty Ltd, Australian Comp Soc, CSIRO, UTAS			TWO-DIMENSIONAL IMAGES; RECOGNITION	There has been a resurgence of interest in one of the most fundamental aspects of computer vision, which is related to the existence of a feedback mechanism in the inference of a visual classification process. Indeed, this mechanism was present in the first computer vision methodologies, but technical and theoretical issues imposed major roadblocks that forced researchers to seek alternative approaches based on pure feed-forward inference. These open loop approaches process the input image sequentially with increasingly more complex analysis steps, and any mistake made by intermediate steps impair all subsequent analysis tasks. On the other hand, closed-loop approaches involving feed-forward and feedback mechanisms can fix mistakes made during such intermediate stages. In this paper, we present a new closed-loop inference for computer vision problems based on an iterative analysis using deep belief networks (DBN). Specifically, an image is processed using a feed-forward mechanism that will produce a classification result, which is then used to sample an image from the current belief state of the DBN. Then the difference between the input image and the sampled image is fed back to the DBN for re-classification, and this process iterates until convergence. We show that our closed-loop vision inference improves the classification results compared to pure feed-forward mechanisms on the MNIST handwritten digit dataset [1] and the Multiple Object Categories [2] containing shapes of horses, dragonflies, llamas and rhinos.	[Carneiro, Gustavo; Liao, Zhibin; Chin, Tat-Jun] Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia	Carneiro, G (reprint author), Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia.						Barriuso A., 2012, ARXIV12103448; Barrow H.G., 1978, COMPUTER VISION SYST, P3; Bar-Shalom Y., 1987, TRACKING DATA ASS; Biederman I., 1985, COMPUTER VISION GRAP, V32, P2973; Binford T., 1971, IEEE C SYST CONTR; Borenstein E., 2004, COMP VIS PATT REC WO, P46; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140; Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Cortes C., 1995, SUPPORT NETWORKS MAC, V20, P273, DOI [DOI 10.1007/BF00994018, DOI 10.1023/A:1022627411411]; Dickinson S. J., 2009, OBJECT CATEGORIZATIO, P1, DOI 10.1017/CBO9780511635465.002; ESLAMI SMA, 2012, CVPR, P406; Fei-Fei L, 2004, COMPUTER VISION PATT, V12, P178; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Grenander U., 2007, PATTERN THEORY REPRE; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hoiem D., 2008, COMP VIS PATT REC CV, P1; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee YJ, 2012, IEEE T PATTERN ANAL, V34, P346, DOI 10.1109/TPAMI.2011.122; Li L, 2009, J NANOMATER, DOI 10.1155/2009/168041; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; Marr D., 1978, COMPUTER VISION SYST, P61; PENTLAND AP, 1986, IEEE T PAMI, V28, P293; Ranzato M., 2011, COMP VIS PATT REC CV, P2857; Salakhutdinov R., 2009, JMLR W CP AISTATS 20, V5, P448; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2126-3				2013							260	267				8	Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BA0EK	WOS:000331079600036		
S	Chalasani, R; Principe, JC; Ramakrishnan, N			IEEE	Chalasani, Rakesh; Principe, Jose C.; Ramakrishnan, Naveen			A Fast Proximal Method for Convolutional Sparse Coding	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc		Convolution; Sparse Coding; Feature Extraction; Unsupervised Learning	ALGORITHM	Sparse coding, an unsupervised feature learning technique, is often used as a basic building block to construct deep networks. Convolutional sparse coding is proposed in the literature to overcome the scalability issues of sparse coding techniques to large images. In this paper we propose an efficient algorithm, based on the fast iterative shrinkage thresholding algorithm (FISTA), for learning sparse convolutional features. Through numerical experiments, we show that the proposed convolutional extension of FISTA can not only lead to faster convergence compared to existing methods but can also easily generalize to other cost functions.	[Chalasani, Rakesh; Principe, Jose C.] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA; [Ramakrishnan, Naveen] Robert Bosch LLC Res & Technol, Ctr North Amer, Pittsburgh, PA USA	Chalasani, R (reprint author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.	rakeshch@ufl.edu; principe@cnel.ufl.edu; Naveen.Ramakrishnan@us.bosch.com					Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Chen X, 2012, ANN APPL STAT, V6, P719, DOI 10.1214/11-AOAS514; Dalal N, 2005, PROC CVPR IEEE, P886; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Gregor K., 2010, P INT C MACH LEARN, P399; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kavukcuoglu K., 2010, ADV NEURAL INFORM PR, V23, P1090; Kavukcuoglu Koray, 2010, CORR, Vabs/1010.3467; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Li YY, 2009, INVERSE PROBL IMAG, V3, P487, DOI 10.3934/ipi.2009.3.487; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Mairal J., 2009, P 26 ANN INT C MACH, P689, DOI DOI 10.1145/1553374.1553463; Martin D., 2001, P 8 INT C COMP VIS, V2, P416, DOI 10.1109/ICCV.2001.937655; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.2307/2006193; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Samaria F. S., 1994, APPL COMP VIS 1994 P, P138; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												5	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200147		
J	Charalampous, K; Gasteratos, A			IEEE	Charalampous, Konstantinos; Gasteratos, Antonios			Bio-inspired Deep Learning Model for Object Recognition	2013 IEEE INTERNATIONAL CONFERENCE ON IMAGING SYSTEMS AND TECHNIQUES (IST 2013)			English	Proceedings Paper	IEEE International Conference on Imaging Systems and Techniques (IST)	OCT 22-23, 2013	Beijing, PEOPLES R CHINA	IEEE, IEEE Instrumentat & Measurement Soc		Deep Learning; Spatial Features; L-1-norm minimization; Unsupervised Learning; Saliency Maps	FACE RECOGNITION; CATEGORIZATION; ALGORITHM	This paper proposes a bio-inspired deep learning architecture for object recognition and classification. The image samples are subjected to a saliency-based pre-processing step suitable for scene analysis and feature derivation. This preprocessing step bears similarities with the primate visual system which also assembles a saliency map. Thereafter, the deep learning model which relies upon the Hierarchical Temporal Memories (HTM) notion is utilized to form the corresponding feature vector. The latter HTM architecture consists of a tree shaped hierarchy of computational nodes where all nodes perform an identical procedure. Concerning the node operation, it forms representative vectors in order to sufficiently describe the input space. Afterwards, the representative vectors are utilized in order to derive spatial groups. The samples are expressed according to their degree of similarity with these groups using the L-1-norm minimization. The proposed bio-inspired scheme is compared with other state-of-the-art algorithms yielding remarkable performance.	[Charalampous, Konstantinos; Gasteratos, Antonios] Democritus Univ Thrace, Dept Prod & Management Engn, Lab Robot & Automat, GR-67100 Xanthi, Greece	Charalampous, K (reprint author), Democritus Univ Thrace, Dept Prod & Management Engn, Lab Robot & Automat, Bldg 1,Vasilissis Sophias 12, GR-67100 Xanthi, Greece.	kchara@pme.duth.gr; agaster@pme.duth.gr					Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Charalampous K, 2012, ELECTRON LETT, V48, P1259, DOI 10.1049/el.2012.1033; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; George D., 2008, THESIS STANFORD; Hawkins J., 2004, INTELLIGENCE NEW UND; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang F.-J., 2006, P COMP VIS PATT REC; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Kjellstrom H, 2011, COMPUT VIS IMAGE UND, V115, P81, DOI 10.1016/j.cviu.2010.08.002; Koch C., 1987, MATTERS INTELLIGENCE, V188, P115; Kostavelis I., 2012, IEEE INT C IM SYST T, P528; Leibe B, 2003, PROC CVPR IEEE, P409; Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-5791-3				2013							51	55				5	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BC1PH	WOS:000350344000011		
S	Chen, G; Zhang, FH; Giuliani, M; Buckl, C; Knoll, A		Herrmann, G; Pearson, MJ; Lenz, A; Bremner, P; Spiers, A; Leonards, U		Chen, Guang; Zhang, Feihu; Giuliani, Manuel; Buckl, Christian; Knoll, Alois			Unsupervised Learning Spatio-temporal Features for Human Activity Recognition from RGB-D Video Data	SOCIAL ROBOTICS, ICSR 2013	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th International Conference on Social Robotics (ICSR)	OCT 27-29, 2013	Bristol, ENGLAND	Univ Bristol, Univ W England, Inst Engn & Technol Robot & Mechatron, Tech & Profess Network, Act Robots, Aldebaran Robot, Bristol Robot Lab		activity recognition; unsupervised learning; depth video		Being able to recognize human activities is essential for several applications, including social robotics. The recently developed commodity depth sensors open up newpossibilities of dealing with this problem. Existing techniques extract hand-tuned features, such as HOG3D or STIP, from video data. They are not adapting easily to new modalities. In addition, as the depth video data is low quality due to the noise, we face a problem: does the depth video data provide extra information for activity recognition? To address this issue, we propose to use an unsupervised learning approach generally adapted to RGB and depth video data. we further employ the multi kernel learning (MKL) classifier to take into account the combinations of different modalities. We show that the low-quality depth video is discriminative for activity recognition. We also demonstrate that our approach achieves superior performance to the state-of-the-art approaches on two challenging RGB-D activity recognition datasets.	[Chen, Guang; Zhang, Feihu; Knoll, Alois] Tech Univ Munich, Inst Informat 4, D-85748 Garching, Germany	Chen, G (reprint author), Tech Univ Munich, Inst Informat 4, Boltzmannstr 3, D-85748 Garching, Germany.	guang@in.tum.de; zhang@in.tum.de; giuliani@fortiss.org; buckl@fortiss.org; knoll@in.tum.de					Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Dalal N, 2005, PROC CVPR IEEE, P886; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvrinen A., 2009, NATURAL IMAGE STAT P; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I., 2008, C COMP VIS PATT REC; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI 10.1109/CVPR.2011.5995496; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Oreifej O., 2013, HON4D HISTOGRAM ORIE; Platt J., 1999, ADV LARGE MARGIN CLA, V1, P61; Socher R., 2012, NIPS, P665; Wang H., 2009, BMVC, P127; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Xia L., 2012, 2012 IEEE COMP SOC C, P20; Yang X., 2012, COMP VIS PATT REC WO, P14; Zhang H., 2011, INTELLIGENT ROBOTS S, V2011, P2044	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-02675-6; 978-3-319-02674-9	LECT NOTES ARTIF INT			2013	8239						341	350				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BB1DN	WOS:000341015200034		
J	Chen, XY; Xiang, SM; Liu, CL; Pan, CH			IEEE	Chen, Xueyun; Xiang, Shiming; Liu, Cheng-Lin; Pan, Chun-Hong			Aircraft Detection by Deep Belief Nets	2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013)			English	Proceedings Paper	2nd IAPR Asian Conference on Pattern Recognition (ACPR)	NOV 05-08, 2013	Naha, JAPAN	Int Assoc Pattern Recognit, IEEE, IEEE Comp Soc, KDDI Fdn, Support Ctr Adv Telecommunicat Technol Res, Pattern Recognit & Media Understanding, IEICE ISS, Comp Vis & Image Media, IPSJ, IEEE Comp Soc Fukuoka Chapter		Remote Sensing; Object detection; Deep Belief Nets	SATELLITE IMAGES; NEURAL-NETWORKS; RECOGNITION	Aircraft detection is a difficult task in high-resolution remote sensing images, due to the variable sizes, colors, orientations and complex backgrounds. In this paper, an effective aircraft detection method is proposed which exactly locates the object by outputting its geometric center, orientation, position. To reduce the influence of background, multi-images including gradient image and gray thresholding images of the object were input to a Deep Belief Net (DBN), which was pre-trained first to learn features and later fine-tuned by back-propagation to yield a robust detector. Experimental results show that DBNs can detecte the tiny blurred aircrafts correctly in many difficult airport images, DBNs outperform the traditional Feature+Classifier methods in robustness and accuracy, and the multi-images help improve the detection precision of DBN than using only single-image.	[Chen, Xueyun; Xiang, Shiming; Liu, Cheng-Lin; Pan, Chun-Hong] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Chen, XY (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	xueyun.chen@nlpr.ia.ac.cn; smxiang@nlpr.ia.ac.cn; liucl@nlpr.ia.ac.cn; chpang@nlpr.ia.ac.cn					Cai KH, 2012, INT CONF SIGN PROCES, P993; Dalal N., 2005, P CVPR, V1, P888; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Filippidis A, 2000, IEEE T PATTERN ANAL, V22, P378, DOI 10.1109/34.845380; Grabner H, 2008, ISPRS J PHOTOGRAMM, V63, P382, DOI 10.1016/j.isprsjprs.2007.10.005; Hinton G. E., 2010, PRACTICAL GUIDE TRAI, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hsieh JW, 2005, IEE P-VIS IMAGE SIGN, V152, P307, DOI 10.1049/ip-vis:20049020; Kembhavi D. H. A., 2011, IEEE T PAMI, V63, P1250; Li W, 2011, P ICIP, P2877; Liu G, 2013, IEEE GEOSCI REMOTE S, V10, P573, DOI 10.1109/LGRS.2012.2214022; Matas J., 2002, P BRIT MACH VIS C, V1, P384; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Sarikaya R, 2011, INT CONF ACOUST SPEE, P5680; Scott GJ, 2011, IEEE T GEOSCI REMOTE, V49, P1603, DOI 10.1109/TGRS.2010.2088404; Sun H, 2012, IEEE GEOSCI REMOTE S, V9, P109, DOI 10.1109/LGRS.2011.2161569; Tien SC, 2003, PATTERN RECOGN LETT, V24, P2047, DOI 10.1016/S0167-8655(03)00042-4; Xu CF, 2010, PATTERN RECOGN LETT, V31, P1759, DOI 10.1016/j.patrec.2009.11.018; Yildiz C., 2011, 2011 IEEE 19 C SIGN, P515; Zunic J, 2006, IEEE T IMAGE PROCESS, V15, P3478, DOI 10.1109/TIP.2006.877527	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-1-4799-2190-4				2013							54	58		10.1109/ACPR.2013.5		5	Computer Science, Artificial Intelligence	Computer Science	BA9KJ	WOS:000339501000012		
J	Cheng, DY; Sun, TF; Jiang, XH; Wang, SL			IEEE	Cheng, Dongyang; Sun, Tanfeng; Jiang, Xinghao; Wang, Shilin			UNSUPERVISED FEATURE LEARNING USING MARKOV DEEP BELIEF NETWORK	2013 20TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP 2013)	IEEE International Conference on Image Processing ICIP		English	Proceedings Paper	20th IEEE International Conference on Image Processing (ICIP)	SEP 15-18, 2013	Melbourne, AUSTRALIA	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		Deep learning; Block RBM; Markov DBN; image classification; SIFT		Recently, deep architectures, such as Deep Belief Network (DBN), have been used to learn features from unlabeled data. However, since DBN supports bi-directional inference and the units between two layers are fully connected, it is difficult to directly apply the traditional convolutional network to DBN, or scale DBN to fit the large images (e.g. 1024. 768). In this paper, a new deep learning model, named Markov DBN (MDBN), is proposed to address these problems. This model employs a new way for DBN to reduce computational burden and handle large images. Markov sub-layers are also adopted to take the neighboring relationship of the inputs into consideration. To train MDBN, we devise Block Restricted Boltzmann Machine (BRBM) which chooses non-overlapping blocks as input. Furthermore, SIFT descriptor is employed to enable this model to learn translation, scaling and rotation invariant features. Experimental results on datasets Caltech-101 and Caltech-256 have demonstrated the superiority of our model.	[Cheng, Dongyang; Sun, Tanfeng; Jiang, Xinghao; Wang, Shilin] Shanghai Jiao Tong Univ, Sch Informat Secur Engn, Shanghai 200030, Peoples R China; [Sun, Tanfeng] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA	Jiang, XH (reprint author), Shanghai Jiao Tong Univ, Sch Informat Secur Engn, Shanghai 200030, Peoples R China.	xhjiang@sjtu.edu.cn					Bengio Y., 2006, P NIPS, P153; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kavukcuoglu K., 2010, P ANN C NEUR INF PRO; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2007, P ANN C NEUR INF PRO; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Raina R, 2007, P 24 INT C MACH LEAR, P759, DOI DOI 10.1145/1273496.1273592; Ranzato M., 2007, P ANN C NEUR INF PRO; SOHN K, 2011, P IEEE INT C COMP VI, P2643; Zeiler MD, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2018, DOI 10.1109/ICCV.2011.6126474; Zhou SS, 2010, IEEE IMAGE PROC, P1561, DOI 10.1109/ICIP.2010.5649922	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		978-1-4799-2341-0	IEEE IMAGE PROC			2013							260	264				5	Imaging Science & Photographic Technology	Imaging Science & Photographic Technology	BC3FD	WOS:000351597600053		
J	Djurdjevic, PD; Huber, M			IEEE	Djurdjevic, Predrag D.; Huber, Manfred			Deep Belief Network for Modeling Hierarchical Reinforcement Learning Policies	2013 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC 2013)	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man, and Cybernetics (SMC)	OCT 13-16, 2013	Manchester, ENGLAND	IEEE, IEEE Comp Soc				Intelligent agents over their lifetime face multiple tasks that require simultaneous modeling and control of complex, initially unknown environments, observed via incomplete and uncertain observations. In such scenarios, policy learning is subject to the curse of dimensionality, leading to scaling problems for traditional Reinforcement Learning (RL). To address this, the agent has to efficiently acquire and reuse latent knowledge. One way is through Hierarchical Reinforcement Learning (HRL), which embellishes RL with a hierarchical, model-based approach to state, reward and policy representation. This paper presents a novel learning approach for HRL based on Conditional Restricted Boltzmann Machines (CRBMs). The proposed model provides a uniform means to simultaneously learn policies and associated abstract state features, and allows learning and executing hierarchical skills within a consistent, uniform network structure. In this model, learning is performed incrementally from basic grounded features to complex abstract policies based on automatically extracted latent states and rewards.	[Djurdjevic, Predrag D.; Huber, Manfred] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA	Djurdjevic, PD (reprint author), Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.	predrag.djurdjevic@mavs.uta.edu; huber@cse.uta.edu					Andre D, 2001, UCBCSD021177; Asadi M, 2007, P IJCAI 07; Bakker B., 2003, HIERARCHICAL REINFOR; Barto A., 2003, DISCRETE EVENT DYN S, V13, P341, DOI [DOI 10.1023/A:1025696116075, 10.1023/A:1025696116075)00052-1]; Bulitko V., 2005, IJCAI 2005; Butz M., 2004, EFFECTIVE ONLINE DET; Charlin L., 2006, P NIPS; Dean T., 1997, P UAI 97; Dietterich TG, 2000, J ARTIF INTELL RES, V13, P227; Drummond C, 1998, P 10 ECML, P370; Goel S, 2003, SUBGOAL DISCOVERY HI; Hayes G, 2004, P ABIALS 2004; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jong N., 2005, P IJCAI05; Konidaris G, 2006, 26 ICML; Konidaris G, 2006, BUILDING PORTABLE OP; Konidaris G, 2004, P 8 INT SAB C; Mahadevan S, 2002, P SARA, P33; Manfredi V., P ICML05 WKSHP RRRL, P39; McGovern A., 2001, P 18 ICML; McGovern A., 2001, ICML 2001, P361; Mcgovern A., 2001, ICML 01, P361; Papudesi V., 2006, LEARNING BEHAV GROUN; Pineau J., 2002, TECHNICAL REPORT; Ravindan B, 2002, P SARA 2002; Sallans B, 2004, J MACH LEARN RES, V5, P1063; Shestorov A., 2005, P AAAI O5; Simsek O, 2004, P 21 ICML; Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5; Sutton R.S., ARTIFICIAL INTELLIGE, V112, P181; Taylor M, 2005, P AAMAS 05; Theocharous G., MITCSAILTR2005058; Thrun S, 1995, ADV NEURAL INFORM PR, V7	36	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4799-0652-9	IEEE SYS MAN CYBERN			2013							2485	2491		10.1109/SMC.2013.424		7	Computer Science, Cybernetics; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BA0SU	WOS:000332201902102		
J	Fan, LC; Li, HY; Ke, DF; Xu, B		Lee, G		Fan, Lichun; Li, Hongyan; Ke, Dengfeng; Xu, Bo			A Novel Noise-Robust ASR Method by Applying Partially Connected DNN Model and Mixed-Bandwidth Concept	PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON COMPUTER, COMMUNICATION, CONTROL AND AUTOMATION	Advances in Intelligent Systems Research		English	Proceedings Paper	2nd International Symposium on Computer, Communication, Control and Automation (3CA)	DEC 01-02, 2013	Singapore, SINGAPORE			robust; ASR; DNN; mixed-bandwidth		In recent years, deep neural networks achieve significant improvements in automatic speech recognition. In this paper, we propose a deep structure used for robust ASR. The model has several partially connected layers which can suppress noise in different frequency bands. In order to recognize the speech data which has been distorted by noise seriously, we try to use parts of their frequency bands with a mixed-bandwidth model. The results have shown that the partially connected network could suppress noises in different frequency bands properly. The model's phone recognition on TIMIT corpus outperforms the state-of-the-art DNN model.	[Fan, Lichun; Li, Hongyan; Ke, Dengfeng; Xu, Bo] Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr, Beijing, Peoples R China	Fan, LC (reprint author), Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr, Beijing, Peoples R China.	lichun.fan@ia.ac.cn; hongyan.li@ia.ac.cn; dengfeng.ke@ia.ac.cn; xubo@ia.ac.cn					Abdel-Hamid O., 2012, ICASSP; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Daniel P., 2011, IEEE WORKSH AUT SPEE; Deng L., 2013, ICASSP; Deng L., 2012, ICASSP; Hermansky H., 1998, ICSLP 1998; Hinton G. E., 2012, IEEE SIGNAL PROCESSI, V29; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Kim C., 2012, ICASSP; Kingsbury B., 2012, INTERSPEECH; Lee K-F, 1989, IEEE T AUDIO SPEECH; Li J., 2012, IEEE WORKSH SPOK LAN; Maas A. L., 2012, INTERSPEECH; Mohamed A., 2012, ICASSP; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Sainath T.N., 2013, ICASSP; Schulz H., 2012, EUR S ART NEUR NETW; Segura J., 2002, ICASSP; Tamura S., 1988, ICASSP; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Yu D, 2013, IEEE T AUDIO SPEECH, V21, P388, DOI 10.1109/TASL.2012.2227738	22	0	0	ATLANTIS PRESS	PARIS	29 AVENUE LAVMIERE, PARIS, 75019, FRANCE	1951-6851		978-90786-77-91-8	ADV INTEL SYS RES			2013	68						182	185				4	Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary	Computer Science; Engineering	BA4EL	WOS:000335510100046		
J	Fink, O; Zio, E; Weidmann, U		Zio, E; Baraldi, P; Pierucci, S; Klemes, JJ		Fink, Olga; Zio, Enrico; Weidmann, Ulrich			Anticipating Railway Operation Disruption Events Based on the Analysis of Discrete-Event Diagnostic Data	2013 PROGNOSTICS AND HEALTH MANAGEMENT CONFERENCE (PHM)	Chemical Engineering Transactions		English	Proceedings Paper	4th IEEE Conference on Prognostics and System Health Management (PHM)	SEP 08-11, 2013	Milan, ITALY	IEEE			LEARNING ALGORITHM; MACHINES	Public transport reliability is a highly important factor affecting passenger service quality, transportation mode choice, and operating costs. Unreliable service increases operating costs and reduces patronage. In railway systems reliability is significantly influenced by the technical reliability of infrastructure and rolling stock systems. To meet the stringent requirements on reliability and availability, many advanced railway systems and components include monitoring and diagnostic tools. The data generated by these systems can be supplied to data-based methods predicting reliability. Approaches to predict component failures and remaining useful life are usually based on continuously measured diagnostic signal data. The use of event-based diagnostic data is limited. This paper describes our research applying Echo-State Networks (ESN) in combination with Restricted Boltzmann Machines (RBM) and fuzzy logic to predict potential railway network disruptions based on discrete-event diagnostic data. The case study focuses on predicting impending failures of a train door system on the level of an individual system potentially causing disruption events of railway operations. The proposed approach achieved an average prediction accuracy of 97 %. The research results demonstrate the suitability of the proposed combination of methods for use in predicting railway operation disruption events. The findings show that the prediction of medium-term class event patterns is especially helpful since railway operators can use this information to take remedial actions to prevent the disruption.	[Fink, Olga; Weidmann, Ulrich] ETH, Inst Transportat Planning & Syst, CH-8093 Zurich, Switzerland	Fink, O (reprint author), ETH, Inst Transportat Planning & Syst, Wolfgang Pauli Str 15, CH-8093 Zurich, Switzerland.	ofink@ethz.ch					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; ARONOFF S, 1982, PHOTOGRAMM ENG REM S, V48, P1299; Fink O., 2013, TRANSPORTATION RES R; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Jaeger H., 2005, 159 GMD GERM NAT RES; Lehrasab N, 2002, P I MECH ENG F-J RAI, V216, P175, DOI 10.1243/095440902760213602; Marquez FPG, 2007, RELIAB ENG SYST SAFE, V92, P830, DOI 10.1016/j.ress.2006.02.011; Pai PF, 2006, MATH COMPUT MODEL, V43, P262, DOI 10.1016/j.mcm.2005.02.008; Roberts C., 2012, ADV TECHNIQUES MONIT, P341; Smith AE, 2010, IEEE T AUTOM SCI ENG, V7, P183, DOI 10.1109/TASE.2009.2020508; Verstraeten D., 2009, RESERVOIR COMPUTING; Caesarendra W, 2011, IEEE T RELIAB, V60, P14, DOI 10.1109/TR.2011.2104716; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; Zio E., 2012, CHEM ENG T, V26	15	0	0	AIDIC SERVIZI SRL	MILANO	VIA GIUSEPPE COLOMBO 81/A, MILANO, MI 20133, ITALY	1974-9791		978-88-95608-24-2	CHEM ENGINEER TRANS			2013	33						715	720		10.3303/CET1333120		6	Engineering, Multidisciplinary; Engineering, Chemical	Engineering	BA8BZ	WOS:000337960300119		
S	Firat, O; Vural, FTY			IEEE	Firat, Orhan; Vural, Fatos T. Yarman			Representation Learning with Convolutional Sparse Autoencoders for Remote Sensing	2013 21ST SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE (SIU)	Signal Processing and Communications Applications Conference		Turkish	Proceedings Paper	21st Signal Processing and Communications Applications Conference (SIU)	APR 24-26, 2013	CYPRUS			representation learning; unsupervised feature learning; sparse auto-encoders; self-taught learning; remote sensing		The performance of object recognition and classification on remote sensing imagery is highly dependent on the quality of extracted features and the amount of labeled data in the dataset. In this study, we concentrated on representation learning using unlabeled remote sensing data and using these representations to recognize different objects which vary in complexity, characteristics and ground resolution. In the proposed framework, randomly sampled patches from remote sensing images are first used to train a single layer sparse-auto encoder in order to learn the most efficient representation for the dataset. These representations are appeared to be as gabor filters in various orientations and parameters, color co-occurrence and color filters and edge-detection filters. Subsequently, representations are used to extract features from target object based on convolution and pooling. Finally, extracted features are used to train a machine learning algorithm and classification performances are evaluated. The proposed method is tested on recognition of dispersal areas, taxi-routes, parking areas and airplanes which are all subparts of an airfield. Performance of the proposed method is competitive with currently used rule-based and supervised methods.	[Firat, Orhan; Vural, Fatos T. Yarman] Orta Dogu Tekn Univ, Bilgisayar Muhendisligi Bolumu, Ankara, Turkey	Firat, O (reprint author), Orta Dogu Tekn Univ, Bilgisayar Muhendisligi Bolumu, Ankara, Turkey.	orhan.firat@ceng.metu.edu.tr; vural@ceng.metu.edu.tr					Arel I., 2010, IEEE COMPUTATIONAL I, V5; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2012, CORR; BYRD RH, 1994, MATH PROGRAM, V63, P129, DOI 10.1007/BF01582063; Cheriyadat A., 2012, P 8 IND C COMP VIS G, P1; Coates A., 2011, AISTATS; Goodfellow I, 2009, NIPS; Hinton G. E., 2011, COMMUNICATIONS ACM, V54; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kullback S. Leibler, 1951, ANN MATH STAT, V22; Le Q.V., 2012, ICML; Lee H., 2009, ICML; Lee H., 2007, NIPS; Mnih V., 2012, ICML; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Raina R., 2007, P 24 ICML	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2165-0608		978-1-4673-5563-6; 978-1-4673-5562-9	SIG PROCESS COMMUN			2013												4	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BHC85	WOS:000325005300365		
S	Fish, J; Ossian, L; Weng, JY			IEEE	Fish, Jordan; Ossian, Lisa; Weng, Juyang			Novelty Estimation in Developmental Networks: Acetylcholine and Norepinephrine	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc			AUTONOMOUS MENTAL-DEVELOPMENT; INTELLIGENCE; CORTEX	The receiver operating characteristic (ROC) curve has been widely applied to classifiers to show how the threshold value for acceptance changes the true positive rate and the false positive rate of the detection jointly. However, it is largely unknown how a biological brain autonomously selects a confidence value for each detection case. In the reported work, we investigated this issue based on the class of Developmental Networks (DNs) which have a power of abstraction similar to symbolic finite automata (FA) but all the DN's representations are emergent (i.e., numeric from the physical world and nonsymbolic). Our theory is based on two types of neurotransmitters: Acetylcholine (Ach) and Norepinephrine (NE). Inspired by studies that proposed Ach and NE represent uncertainty and unpredicted uncertainty, respectively, we model how a DN uses Ach and NE to allow neurons to collectively decide acceptance or rejection by estimated novelty based on past experience, instead of using a single threshold value. This is a neural network, distributed, incremental, automatic version of ROC.	[Fish, Jordan; Ossian, Lisa; Weng, Juyang] Michigan State Univ, Dept Comp Sci & Engn, Cognit Sci Program, E Lansing, MI 48824 USA; [Fish, Jordan; Ossian, Lisa; Weng, Juyang] Michigan State Univ, Neurosci Program, E Lansing, MI 48824 USA	Fish, J (reprint author), Michigan State Univ, Dept Comp Sci & Engn, Cognit Sci Program, E Lansing, MI 48824 USA.	fishjord@cse.msu.edu; ossianli@cse.msu.edu; weng@cse.msu.edu					Anderson J., 1993, RULES OF THE MIND; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; George D, 2009, PLOS COMPUTATIONAL B, V5, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang X, 2007, INT J HUM ROBOT, V4, P407, DOI 10.1142/S0219843607001011; Huang X., 2002, P 2 INT WORKSH EP RO, V94, P47; Izhikevich E. M., 2007, DYNAMICAL SYSTEMS NE; Jordan M. I., 1986, P 8 ANN C COGN SCI S, P531; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI [10.1016/j.sigpro.2003.07.018, 10.1016/j.sigpro.2003.018]; MINSKY M, 1991, AI MAG, V12, P34; Rogers TT, 2008, BEHAV BRAIN SCI, V31, P689, DOI 10.1017/S0140525X0800589X; Ryan J, 1998, ADV NEUR IN, V10, P943; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Singh S, 2004, IEEE T KNOWL DATA EN, V16, P396, DOI 10.1109/TKDE.2004.1269665; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; Weng J., 2011, NATURAL INTELLIGENCE, V1, P13; Weng J., 2012, NATURAL ARTIFICIAL I; Weng J., 2010, P INT JOINT C NEUR N, P1; Weng J., 2011, MSUCSE119; Weng JY, 2012, IEEE T AUTON MENT DE, V4, P29, DOI 10.1109/TAMD.2011.2159113; Weng JY, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2983; Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599; Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220; Yu A. J., 2005, NEURON, V46	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200015		
S	Ghifary, M; Kleijn, WB; Zhang, MJ		Rhee, T; Rayudu, R; Hollitt, C; Lewis, J; Zhang, M		Ghifary, Muhammad; Kleijn, W. Bastiaan; Zhang, Mengjie			Sparse Representations in Deep Learning for Noise-Robust Digit Classification	PROCEEDINGS OF 2013 28TH INTERNATIONAL CONFERENCE ON IMAGE AND VISION COMPUTING NEW ZEALAND (IVCNZ 2013)	International Conference on Image and Vision Computing New Zealand		English	Proceedings Paper	28th International Conference on Image and Vision Computing New Zealand (IVCNZ)	NOV 27-29, 2013	Wellington, NEW ZEALAND	IEEE, Victoria Univ Wellington, Sch Engn & Comp Sci				Many sparse regularization methods for encouraging succinct hierarchical features of deep architectures have been proposed, but there is still a lack of studies that compare them. We present a comparison of several sparse regularization methods in deep learning with respect to the performance of a noisy digit classification task under varying size of training samples. We also propose a deep hybrid architecture built from a particular combination of sparse auto-encoders and Restricted Boltzmann Machines. The results show that the sparse architectures can produce better classification performance under noisy test samples than the dense architectures in most cases. In addition, the deep hybrid architectures can solve the digit classification task more effectively with a small size of training samples.	[Ghifary, Muhammad; Kleijn, W. Bastiaan; Zhang, Mengjie] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington, New Zealand	Ghifary, M (reprint author), Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington, New Zealand.	muhammad.ghifary@ecs.vuw.ac.nz; bastiaan.kleijn@ecs.vuw.ac.nz; mengjie.zhang@ecs.vuw.ac.nz					Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2007, JUSTIFYING GEN CONTR; Bengio Y., 2012, PRACTICAL RECOMMENDA; Bengio Y., 2012, COMPUTING RES REPOSI; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bradley D. M., 2009, ADV NEURAL INFORM PR, V21, P113; Dahl G. E., 2010, ADV NEURAL INFORM PR, V24, P469; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Larochelle H., 2007, P 24 INT C MACH LEAR, V227, P473; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Le QV, 2011, P 28 INT C MACH LEAR, P265; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2007, ADV NEURAL INFORM PR, V20, P873; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Mairal J., 2008, IEEE T IMAGE PROCESS; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; Rigamonti R., 2011, ARE SPARSE REPRESENT; Xu H, 2012, IEEE T PATTERN ANAL, V34, P187, DOI 10.1109/TPAMI.2011.177; Yang JC, 2009, PROC CVPR IEEE, P1794; Zhang L, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P471	30	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2151-2191		978-1-4799-0883-7; 978-1-4799-0882-0	INT CONF IMAG VIS			2013							340	345				6	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BC1NN	WOS:000350291600059		
J	Graff, P; Feroz, F; Hobson, MP; Lasenby, A		Ding, W; Washio, T; Xiong, H; Karypis, G; Thuraisingham, B; Cook, D; Wu, X		Graff, Philip; Feroz, Farhan; Hobson, Michael P.; Lasenby, Anthony			Neural Networks for Astronomical Data Analysis and Bayesian Inference	2013 IEEE 13TH INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS (ICDMW)	IEEE International Conference on Data Mining		English	Proceedings Paper	IEEE 13th International Conference on Data Mining (ICDM)	DEC 07-10, 2013	Dallas, TX	IEEE, IEEE Comp Soc, NSF, Toshiba, KNIME, TechMatrix, Univ Texas Dallas, Univ Texas Dallas, Erik Jonsson Sch Engn & Comp Sci, Dept Comp Sci			COSMOLOGICAL PARAMETER-ESTIMATION; EFFICIENT; MODELS	We present our generic neural network training algorithm, called SKYNET and the accelerated Bayesian inference algorithm, BAMBI. SKYNET combines multiple techniques already developed individually in the literature to create an efficient and robust machine-learning tool that is able to train large and deep feed-forward neural networks for use in a wide range of learning applications, such as regression, classification, density estimation, clustering and dimensionality reduction. SKYNET uses a powerful 'pre-training' method, to obtain a set of network parameters close to the true global maximum of the training objective function, followed by further optimisation using an automatically-regularised variant of Newton's method that uses second-order derivative information to improve convergence, but without the need to evaluate or store the full Hessian matrix, by using a fast approximate method to calculate Hessian-vector products. This combination of methods allows for the training of complicated networks that are difficult to optimise using standard backpropagation techniques. The blind accelerated multimodal Bayesian inference (BAMBI) algorithm implements the MULTINEST package for nested sampling as well as the training of an artificial neural network by SKYNET to learn the likelihood function. In the case of computationally expensive likelihoods, this allows the substitution of a much more rapid approximation in order to increase significantly the speed of the analysis. Astrophysical examples are provided for both SKYNET and BAMBI.	[Graff, Philip] NASA, Goddard Space Flight Ctr, Gravitat Astrophys Lab, Greenbelt, MD 20771 USA	Graff, P (reprint author), NASA, Goddard Space Flight Ctr, Gravitat Astrophys Lab, 8800 Greenbelt Rd, Greenbelt, MD 20771 USA.						Auld T, 2008, MON NOT R ASTRON SOC, V387, P1575, DOI 10.1111/j.1365-2966.2008.13279.x; Auld T, 2007, MON NOT R ASTRON SOC, V376, pL11, DOI 10.1111/j.1745-3933.2006.00276.x; Ball NM, 2010, INT J MOD PHYS D, V19, P1049, DOI 10.1142/S0218271810017160; Bertin E, 1996, ASTRON ASTROPHYS SUP, V117, P393, DOI 10.1051/aas:1996164; Bliznyuk N, 2008, J COMPUT GRAPH STAT, V17, P270, DOI 10.1198/106186008X320681; Bouland A, 2011, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2011/05/016; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fendt WA, 2007, ASTROPHYS J, V654, P2, DOI 10.1086/508342; Feroz F., 2013, ARXIV13062144ASTROPH; Feroz F., 2008, ARXIV08100781ASTROPH; Feroz F, 2009, MON NOT R ASTRON SOC, V398, P1601, DOI 10.1111/j.1365-2966.2009.14548.x; Feroz F, 2008, MON NOT R ASTRON SOC, V384, P449, DOI 10.1111/j.1365-2966.2007.12353.x; Gehrels N, 2004, ASTROPHYS J, V611, P1005, DOI 10.1086/422091; Graff P, 2012, MON NOT R ASTRON SOC, V421, P169, DOI 10.1111/j.1365-2966.2011.20288.x; Graff P., 2013, ARXIV13090790ASTROPH; Gull S.F., 1999, QUANTIFIED MAXIMUM E; Higdon D., 2012, STAT CHANLLENGES MOD, P41; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hornik K., 1990, NEURAL NETWORKS, V3, P359; Karpenka N.V., 2013, MNRAS IN PRESS; Kitching T., 2012, NEW ASTRONOMY UNPUB; Kitching T, 2011, ANN APPL STAT, V5, P2231, DOI 10.1214/11-AOAS484; LEWIS A, 2002, PHYS REV D, V66; Lewis A, 2000, ASTROPHYS J, V538, P473, DOI 10.1086/309179; Lien A., 2012, P INT ASTRONOMICAL U, V279, P347; MacKay D., 2003, INFORM THEORY INFERE; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Martens J, 2010, P 27 INT C MACH LEAR, P735; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; Rasmussen C. E., 2003, BAYESIAN STAT, V7, P651; Schraudolph NN, 2002, NEURAL COMPUT, V14, P1723, DOI 10.1162/08997660260028683; Skilling J, 2004, AIP CONF PROC, V735, P395; Tagliaferri R, 2003, NEURAL NETWORKS, V16, P297, DOI 10.1016/S0893-6080(03)00028-5; Wanderman D, 2010, MON NOT R ASTRON SOC, V406, P1944, DOI 10.1111/j.1365-2966.2010.16787.x; Way MJ, 2012, CH CRC DATA MIN KNOW, pXIII	36	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-4786		978-0-7695-5109-8	IEEE DATA MINING			2013							16	23		10.1109/ICDMW.2013.82		8	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BB5AQ	WOS:000343602800003		
J	Guo, QZ; Zeng, Z; Zhang, SW; Zhang, Y; Wang, FY			IEEE	Guo, Qin-Zhen; Zeng, Zhi; Zhang, Shuwu; Zhang, Yuan; Wang, Fangyuan			ADAPTIVE BIT ALLOCATION HASHING FOR APPROXIMATE NEAREST NEIGHBOR SEARCH	2013 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME 2013)	IEEE International Conference on Multimedia and Expo		English	Proceedings Paper	IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	JUL 15-19, 2013	San Jose, CA	IEEE		Approximate nearest neighbor search; hamming embedding; adaptive bit allocation; image retrieval		Using hashing algorithms to learn binary codes representation of data for fast approximate nearest neighbor (ANN) search has attracted more and more attentions. Most existing hashing methods employ various hash functions to encode data. The resulting binary codes can be obtained by concatenating bits produced by those hash functions. These methods usually have two main steps: projection and thresholding. One problem of these methods is that every dimension of the projected data is regarded as the same importance and represented by one bit, which may result in ineffective codes. We introduce an adaptive bit allocation hashing (ABAH) method to encode data for ANN search. The basic idea is, according to the dispersion of every dimension after projection we use different number of bits to encode them. ABAH can effectively preserve the neighborhood structure in the original data space. Extensive experiments show that ABAH significantly outperforms three state-of-the-art methods.	[Guo, Qin-Zhen; Zeng, Zhi; Zhang, Shuwu; Zhang, Yuan; Wang, Fangyuan] Chinese Acad Sci, Inst Automat, Beijing 100864, Peoples R China	Guo, QZ (reprint author), Chinese Acad Sci, Inst Automat, Beijing 100864, Peoples R China.	qinzhen.guo@ia.ac.cn; zhi.zeng@ia.ac.cn; shuwu.zhang@ia.ac.cn; yuan.zhang@ia.ac.cn; fangyuan.wang@ia.ac.cn					Bentley Jon Louis, 1990, SCG 90, P187, DOI DOI 10.1145/98524.98564; Datar M., 2004, S COMP GEOM, P153; Gong Y., 2011, CVPR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jegou H., 2008, ECCV; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Lin RS, 2010, PROC CVPR IEEE, P848, DOI 10.1109/CVPR.2010.5540129; Liu W., 2011, ICML; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nisters D, 2006, CVPR, P2161; Oliva A., 2001, IJCV; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Wang B., 2005, TECHNICAL REPORT; Weiss Y., 2008, NIPS, V21, P1753	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1945-7871		978-1-4799-0015-2	IEEE INT CON MULTI			2013												6	Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BB8FR	WOS:000346507500073		
J	Han, M; Wang, XY			IEEE	Han, Min; Wang, Xinying			Multi Reservoir Support Vector Echo State Machine for Multivariate Time Series Prediction	2013 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC 2013)	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man, and Cybernetics (SMC)	OCT 13-16, 2013	Manchester, ENGLAND	IEEE, IEEE Comp Soc			NETWORKS; REGRESSION	Chaotic time series prediction has received considerable attention in the last few years. Although many studies have been conducted in the field, there is little attention focused on multivariate time series prediction. Considering this problem, a multi reservoir support vector echo state machine(MRSVESM) based on multi kernel learning and echo state networks is proposed in this paper. The single reservoir approach may be ineffective on multivariate time series prediction, as it is not able to character multi time scale dynamics. The MRSVESM use multi different time scale reservoirs to present the dynamics of multivariate time series and replaced the "kernel trick" with "reservoir trick", that is, performed multi kernel learning in the high dimension "reservoir"state space. Two simulation examples, prediction of Lorenz chaotic time series and prediction of sunspots and the Yellow River annual runoff time series are conducted to demonstrate the effectiveness of the proposed method.	[Han, Min; Wang, Xinying] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Liaoning, Peoples R China	Han, M (reprint author), Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Liaoning, Peoples R China.	minhan@dlut.edu.cn; xinying@mail.dlut.edu.cn	Wang, Xinying/C-8214-2012				Alpaydin E., 2011, J MACH LEARN RES, V12, P2211; Bellocchio F, 2012, IEEE T NEUR NET LEAR, V23, P1448, DOI 10.1109/TNNLS.2012.2205018; Bengio Y., 2007, LARGE SCALE KERNEL M, V34; Boccato L., 2012, NEURAL NETWORKS; Cao LY, 1998, PHYSICA D, V121, P75, DOI 10.1016/S0167-2789(98)00151-1; Chatzis SP, 2011, IEEE T NEURAL NETWOR, V22, P1435, DOI 10.1109/TNN.2011.2162109; Deyle ER, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018295; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Hermans M, 2012, NEURAL COMPUT, V24, P104, DOI 10.1162/NECO_a_00200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277; Jamshidi AA, 2011, NEURAL COMPUT, V23, P97, DOI 10.1162/NECO_a_00060; Li DC, 2012, IEEE T NEUR NET LEAR, V23, P787, DOI 10.1109/TNNLS.2012.2188414; Lukosevicius M., 2009, COMPUTER SCI REV, V3, P127, DOI DOI 10.1016/J.COSREV.2009.03.005; Orabona F, 2012, J MACH LEARN RES, V13, P227; Ozturk MC, 2007, NEURAL COMPUT, V19, P111, DOI 10.1162/neco.2007.19.1.111; Prokhorov D, 2005, IEEE IJCNN, P1463; Qiu SB, 2009, IEEE ACM T COMPUT BI, V6, P190, DOI 10.1109/TCBB.2008.139; Rakotomamonjy A., 2007, P INT C MACH LEARN, V772, P775; Rodan A, 2011, IEEE T NEURAL NETWOR, V22, P131, DOI 10.1109/TNN.2010.2089641; Schmichuber J, 2007, NEURAL COMPUT, V19, P757, DOI 10.1162/neco.2007.19.3.757; Shi ZW, 2007, IEEE T NEURAL NETWOR, V18, P359, DOI 10.1109/TNN.2006.885113; Slavakis K, 2012, IEEE T NEUR NET LEAR, V23, P260, DOI 10.1109/TNNLS.2011.2178321; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Song Y, 2011, IEEE T CIRC SYST VID, V21, P1193, DOI 10.1109/TCSVT.2011.2130230; Takens F., 1981, LECT NOTES MATH, V898, P366, DOI DOI 10.1007/BFB0091924; Venayagamoorthy GK, 2009, NEURAL NETWORKS, V22, P861, DOI 10.1016/j.neunet.2009.03.021; Verstraeten D, 2007, NEURAL NETWORKS, V20, P391, DOI 10.1016/j.neunet.2007.04.003; Xia Y., 2010, NEURAL NETWORKS IEEE, V22, P74; Xue YB, 2007, NEURAL NETWORKS, V20, P365, DOI 10.1016/j.neunet.2007.04.014	30	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4799-0652-9	IEEE SYS MAN CYBERN			2013							983	987		10.1109/SMC.2013.172		5	Computer Science, Cybernetics; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BA0SU	WOS:000332201901018		
S	Jalali, S; Seekings, PJ; Tan, C; Ratheesh, A; Lim, JH; Taylor, EA			IEEE	Jalali, Sepehr; Seekings, Paul J.; Tan, Cheston; Ratheesh, Aiswarya; Lim, Joo-Hwee; Taylor, Elizabeth A.			The Use of Optical and Sonar Images in the Human and Dolphin Brain for Image Classification	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc			PRIMARY AUDITORY-CORTEX; RECEPTIVE-FIELDS; HIERARCHY; RECOGNITION; STREAMS; SPEECH; SOUNDS; SYSTEM; AREAS	In this paper we propose a new biologically inspired model which simulates the visual pathways in the human brain used for classification of matching optical and sonar derived images. Marine mammals, such as dolphins, that live in waters with poor optical clarity and low light levels such as littoral zones, use a combination of optical vision and biosonar to navigate and hunt for prey. Given that dolphins have evolved a synergistic combination of optical visual input and acoustic/sonar input, the primary focus of this paper is on reaching a similar level of synergy for a diver or Autonomous Underwater Vehicle (AUV) platform equipped with a system to extend the range and resolution of vision in poor ambient visibility. We propose a biologically inspired model that combines and processes visual images acquired via optical and acoustic pathways and show that the combined model enhances the accuracy of automatic classification of target objects in underwater images.	[Jalali, Sepehr; Seekings, Paul J.; Ratheesh, Aiswarya; Taylor, Elizabeth A.] Natl Univ Singapore, Trop Marine Sci Inst, Singapore 117548, Singapore	Jalali, S (reprint author), Natl Univ Singapore, Trop Marine Sci Inst, Singapore 117548, Singapore.	tmssj@nus.edu.sg; mmrl@nus.edu.sg; cheston-tan@i2r.a-star.edu.sg; tmsar@nus.edu.sg; joohwee@i2r.a-star.edu.sg; tmshoe@nus.edu.sg					Au W. W., 1980, ANIMAL SONAR SYSTEMS, P251; AU WWL, 1974, J ACOUST SOC AM, V56, P1280, DOI 10.1121/1.1903419; Chevillet M, 2011, J NEUROSCI, V31, P9345, DOI 10.1523/JNEUROSCI.1448-11.2011; Herman L. M., 1980, CETACEAN BEHAV MECH; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Jalali S., 2013, P ANN C COG IN PRESS; Jalali S., 2013, P INT JOINT IN PRESS; King AJ, 2009, NAT NEUROSCI, V12, P698, DOI 10.1038/nn.2308; Kusmierek P, 2012, J NEUROPHYSIOL, V107, P1123, DOI 10.1152/jn.00793.2011; Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Nelken I, 2004, CURR OPIN NEUROBIOL, V14, P474, DOI 10.1016/j.conb.2004.06.005; Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318; Popper A. N., 2000, HEARING WHALES DOLPH, V12; Rauschecker JP, 2000, P NATL ACAD SCI USA, V97, P11800, DOI 10.1073/pnas.97.22.11800; Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331; Rauschecker JP, 1998, CURR OPIN NEUROBIOL, V8, P516, DOI 10.1016/S0959-4388(98)80040-8; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; ROE AW, 1992, J NEUROSCI, V12, P3651; ROE AW, 1990, SCIENCE, V250, P818, DOI 10.1126/science.2237432; Romanski LM, 2009, ANNU REV NEUROSCI, V32, P315, DOI 10.1146/annurev.neuro.051508.135431; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Sharma J, 2000, NATURE, V404, P841, DOI 10.1038/35009043; Shirihai H., 2006, WHALES DOLPHINS OTHE; Sur M, 2001, NAT REV NEUROSCI, V2, P251, DOI 10.1038/35067562; Talkington WJ, 2012, J NEUROSCI, V32, P8084, DOI 10.1523/JNEUROSCI.1118-12.2012; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Theriault C., 2011, INT C IM PROC, P3	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200185		
J	Jiang, XJ; Zhang, YH; Zhang, WS; Xiao, X			IEEE	Jiang, Xiaojuan; Zhang, Yinghua; Zhang, Wensheng; Xiao, Xian			A Novel Sparse Auto-Encoder for Deep Unsupervised Learning	2013 SIXTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI)			English	Proceedings Paper	6th International Conference on Advanced Computational Intelligence (ICACI)	OCT 19-21, 2013	Hangzhou, PEOPLES R CHINA	Zhejiang University, Xian Jiaotong Liverpool Univ, Chinese Univ Hong, IEEE Nanjing Sect				This paper proposes a novel sparse variant of auto-encoders as a building block to pre-train deep neural networks. Compared with sparse auto-encoders through KL-divergence, our method requires fewer hyper-parameters and the sparsity level of the hidden units can be learnt automatically. We have compared our method with several other unsupervised leaning algorithms on the benchmark databases. The satisfactory classification accuracy (97.92% on MNIST and 87.29% on NORB) can be achieved by a 2-hidden-layer neural network pre-trained using our algorithm, and the whole training procedure (including pre-training and fine-tuning) takes far less time than the state-of-art results.	[Jiang, Xiaojuan; Zhang, Yinghua; Zhang, Wensheng; Xiao, Xian] Chinese Acad Sci, Inst Automat, State Key Lab Intelligent Control & Management Co, Beijing 100190, Peoples R China	Jiang, XJ (reprint author), Chinese Acad Sci, Inst Automat, State Key Lab Intelligent Control & Management Co, Beijing 100190, Peoples R China.	xiaojuan.jiang@ia.ac.cn; yinghua.zhang@ia.ac.cn; wensheng.zhang@ia.ac.cn; 13501147456@163.com					Bengio Y., 2007, ADV NEURAL INFORM PR, V19; Bengio Y., 2007, LARGE SCALE KERNEL M, V34; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2013, IEEE T PATTERN ANAL; BYRD RH, 1994, MATH PROGRAM, V63, P129, DOI 10.1007/BF01582063; Chu C. T., 2007, ADV NEURAL INFORM PR, V19; Ciresan D., 2010, CORR; Hinton G., 2010, MOMENTUM, V9; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; LeCun Y., 2004, COMPUTER VISION PATT; Lee H., 2007, ADV NEURAL INFORM PR, V20, P873; Lee H., 2006, ADV NEURAL INFORM PR, V19, P801; Lee Q. V., 2011, P 28 INT C MACH LEAR, P265; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Nair V., 2008, ADV NEURAL INFORM PR, P1145; Ng A. Y., 2004, P 21 INT C MACH LEAR; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Raina R., 2009, P 26 INT C MACH LEAR, V9, P873; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov R., 2009, INT C ART INT STAT, V5, P448; Simard P., 2003, ICDAR, V3, P958; Taylor G., 2009, P 26 ANN INT C MACH, P1025; Taylor G. W., 2006, ADV NEURAL INF PROCE, V19, P1345	24	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-6343-3				2013							256	261				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BC3MP	WOS:000351734600049		
S	Jing, H; Tsao, Y			IEEE	Jing, How; Tsao, Yu			Sparse Maximum Entropy Deep Belief Nets	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc			LEARNING ALGORITHM; MACHINES	In this paper, we present a sparse maximum entropy (SME) learning algorithm for deep belief net (DBN). The SME algorithm aims to maximize the entropy and encourage sparsity of the model. Compared with the conventional maximum likelihood (ML) learning, the proposed SME algorithm enables DBN to be more unbiased to data distributions and robust to over-fitting issues, and accordingly provide a better generalization capability. M N I S T and N O R B data sets were used to evaluated the proposed SME algorithm. Experimental results show that SME-trained DBN outperforms ML-trained DBN on both data sets.	[Jing, How; Tsao, Yu] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei, Taiwan	Jing, H (reprint author), Acad Sinica, Res Ctr Informat Technol Innovat, Taipei, Taiwan.	jingt1228@gmail.com; yu.tsao@citi.sinica.edu.tw					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bengio Y., 2007, SCALING LEARNING ALG; Bengio Y., 2009, LEARNING DEEP ARCHIT; Berger A., 1997, IMPROVED ITERATIVE S; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bilmes J. A., 1997, TECHNICAL REPORT; Carreira-Perpinan M. A., CONTRASTIVE DIVERGEN; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2010, TECHNICAL REPORT; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Krizhevsky A., 2010, CONVOLUTIONAL DEEP B; LeCun Y., MNIST DATABASE HANDW; LeCun Y, 2004, PROC CVPR IEEE, P97; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2009, ADV NEURAL INFORM PR, V22; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; Nigam K., 1999, IJCAI 99 WORKSH MACH, V1, P61; Ratnaparkhi A., 1998, THESIS; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov R., QUANTITATIVE ANAL DE; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Simard P., 2003, INT C DOC AN REC, V2, P958, DOI DOI 10.1109/ICDAR.2003.1227801; Sutskever I., 2010, P C AI STAT AI STAT; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vinod N., IMPLICIT MIXTURES RE; Wang S., LATENT MAXIMUM ENTRO	30	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200042		
J	Kamal, S; Mohammed, SK; Pillai, PRS; Supriya, MH			IEEE	Kamal, Suraj; Mohammed, Shameer K.; Pillai, P. R. Saseendran; Supriya, M. H.			Deep Learning Architectures for Underwater Target Recognition	2013 OCEAN ELECTRONICS (SYMPOL)	Ocean Electronics		English	Proceedings Paper	12th Symposium on Ocean Electronics (SYMPOL)	OCT 23-25, 2013	Kochi, INDIA	Dept Sci & Engn Res Council, Dept Sci & Technol, Naval Res Board, Univ Grants Commiss, Council Sci & Ind Res, Kerala State Council Sci, Technol & Environm, IEEE Ocean Engn Soc, Acoust Soc Amer		Deep learning; Deep Belief Networks; Sonar target recognition; Unsupervised feature learning		Passive sonar target recognition is a challenging task due to the complex milieu of the ocean. Most of the state of the art target recognition systems depend on hand engineered feature extraction schemes in order to effectively represent the target signatures, based on expert knowledge. Due to the whimsical nature of the sources and medium, such feature engineering methods often fail to yield invariant features from the observations. In this paper, a deep unsupervised feature learning approach capable of capturing invariant features from the sensory signal stream through multi layered hierarchical abstraction has been adopted. These abstractions learned by the higher layers are mostly invariant and can be used as the discriminative features for the purpose of classification.	[Kamal, Suraj; Mohammed, Shameer K.; Pillai, P. R. Saseendran; Supriya, M. H.] Cochin Univ Sci & Technol, Dept Elect, Kochi 682021, Kerala, India	Kamal, S (reprint author), Cochin Univ Sci & Technol, Dept Elect, Kochi 682021, Kerala, India.	surajkamal.cucentol@gmail.com; shameer.hyderali@gmail.com; prspillai@cusat.ac.in; supriya@cusat.ac.in					Bengio Y., 2007, LARGE SCALE KERNEL M, V34; David H. A., 1985, LEARNING ALGORITHM B; Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton G., 2010, MOMENTUM 9 1; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., NEW WAY LEARN ACOUST; Mohamed A., 2011, IEEE T AUDIO SPEECH; Mus D., AUDIO FEATURE EXTRAC; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2326-5558		978-93-80095-45-5	OCEAN ELECTR			2013							48	54				7	Engineering, Ocean; Engineering, Electrical & Electronic	Engineering	BC0UQ	WOS:000349632700008		
J	Kashiwagi, Y; Saito, D; Minematsu, N; Hirose, K			IEEE	Kashiwagi, Yosuke; Saito, Daisuke; Minematsu, Nobuaki; Hirose, Keikichi			DISCRIMINATIVE PIECEWISE LINEAR TRANSFORMATION BASED ON DEEP LEARNING FOR NOISE ROBUST AUTOMATIC SPEECH RECOGNITION	2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU)			English	Proceedings Paper	IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)	DEC 08-13, 2013	Olomouc, CZECH REPUBLIC	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		Automatic speech recognition; Noise robustness; feature enhancement; Deep learning		In this paper, we propose the use of deep neural networks to expand conventional methods of statistical feature enhancement based on piecewise linear transformation. Stereo-based piecewise linear compensation for environments (SPLICE), which is a powerful statistical approach for feature enhancement, models the probabilistic distribution of input noisy features as a mixture of Gaussians. However, soft assignment of an input vector to divided regions is sometimes done inadequately and the vector comes to go through inadequate conversion. Especially when conversion has to be linear, the conversion performance will be easily degraded. Feature enhancement using neural networks is another powerful approach which can directly model a non-linear relationship between noisy and clean feature spaces. In this case, however, it tends to suffer from over-fitting problems. In this paper, we attempt to mitigate this problem by reducing the number of model parameters to estimate. Our neural network is trained whose output layer is associated with the states in the clean feature space, not in the noisy feature space. This strategy makes the size of the output layer independent of the kind of a given noisy environment. Firstly, we characterize the distribution of clean features as a Gaussian mixture model and then, by using deep neural networks, estimate discriminatively the state in the clean space that an input noisy feature corresponds to. Experimental evaluations using the Aurora 2 dataset demonstrate that our proposed method has the best performance compared to conventional methods.	[Kashiwagi, Yosuke; Minematsu, Nobuaki] Univ Tokyo, Grad Sch Engn, Tokyo 1138654, Japan	Kashiwagi, Y (reprint author), Univ Tokyo, Grad Sch Engn, Tokyo 1138654, Japan.	kashiwagi@gavo.t.u-tokyo.ac.jp; dsk_saito@gavo.t.u-tokyo.ac.jp; mine@gavo.t.u-tokyo.ac.jp; hirose@gavo.t.u-tokyo.ac.jp					AFIFY M, 2009, AUDIO SPEECH LANGUAG, V17, P1325; Droppo Jasha, 2002, INT C SPOK LANG PROC, P29; Gales MJF, 2011, ROBUST SPEECH RECOGNITION OF UNCERTAIN OR MISSING DATA: THEORY AND APPLICATIONS, P101, DOI 10.1007/978-3-642-21317-5_5; Gemmeke Jort F, 2011, AUDIO SPEECH LANGUAG, V19, P2067; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Li Jinyu, 2012, AC SPEECH SIGN PROC, P4677; Maas A. L., 2012, INTERSPEECH; Masayuki Suzuki, IEEE TASLP IN PRESS; Povey, 2011, IEEE 2011 WORKSH AUT; Senior Andrew, 2012, AC SPEECH SIGN PROC, P1957; Suzuki Masayuki, 2012, AC SPEECH SIGN PROC, P4109; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2756-2				2013							350	355				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BA4DR	WOS:000335410800060		
J	Klefenz, F; Williamson, A				Klefenz, Frank; Williamson, Adam			Modeling the Formation Process of Grouping Stimuli Sets through Cortical Columns and Microcircuits to Feature Neurons	COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE			English	Review							TIMING-DEPENDENT PLASTICITY; VISUAL-CORTEX; IN-VITRO; ORIENTATION SELECTIVITY; HOUGH TRANSFORM; FUNCTIONAL ARCHITECTURE; BINOCULAR INTERACTION; TEMPORAL PATTERNS; RECEPTIVE-FIELDS; NETWORK ACTIVITY	A computational model of a self-structuring neuronal net is presented in which repetitively applied pattern sets induce the formation of cortical columns and microcircuits which decode distinct patterns after a learning phase. In a case study, it is demonstrated how specific neurons in a feature classifier layer become orientation selective if they receive bar patterns of different slopes from an input layer. The input layer is mapped and intertwined by self-evolving neuronal microcircuits to the feature classifier layer. In this topical overview, several models are discussed which indicate that the net formation converges in its functionality to a mathematical transform which maps the input pattern space to a feature representing output space. The self-learning of the mathematical transform is discussed and its implications are interpreted. Model assumptions are deduced which serve as a guide to apply model derived repetitive stimuli pattern sets to in vitro cultures of neuron ensembles to condition them to learn and execute a mathematical transform.	[Klefenz, Frank] Fraunhofer IDMT, Div Bioinspired Comp, D-98693 Ilmenau, Germany; [Williamson, Adam] Ilmenau Univ Technol, Dept Nanobiosyst Technol, D-98693 Ilmenau, Germany	Klefenz, F (reprint author), Fraunhofer IDMT, Div Bioinspired Comp, D-98693 Ilmenau, Germany.	klz@idmt.fraunhofer.de			3DNeuroN project in the European Union's Seventh Framework Programme, Future and Emerging Technologies [296590]	This research has been supported by the 3DNeuroN project in the European Union's Seventh Framework Programme, Future and Emerging Technologies (Grant agreement no. 296590).	Adhikari SP, 2012, IEEE T NEUR NET LEAR, V23, P1426, DOI 10.1109/TNNLS.2012.2204770; Bi GQ, 1999, NATURE, V401, P792, DOI 10.1038/44573; Bichler O, 2012, NEURAL NETWORKS, V32, P339, DOI 10.1016/j.neunet.2012.02.022; BIENENSTOCK EL, 1982, J NEUROSCI, V2, P32; BLASDEL GG, 1992, J NEUROSCI, V12, P3139; Bonifazi P, 2009, SCIENCE, V326, P1419, DOI 10.1126/science.1175509; Branco T, 2010, CURR OPIN NEUROBIOL, V20, P494, DOI 10.1016/j.conb.2010.07.009; Brette R, 2007, J COMPUT NEUROSCI, V23, P349, DOI 10.1007/s10827-007-0038-6; BRUCKMANN A, 2004, INT SCI J COMPUTING, V3, P21; Buonomano DV, 2009, NAT REV NEUROSCI, V10, P113, DOI 10.1038/nrn2558; Butts DA, 2010, J NEUROPHYSIOL, V104, P3371, DOI 10.1152/jn.00078.2010; CHEIRDARIS S, 2011, P ML GARG 9 ANN STUD; Chen XW, 2011, NATURE, V475, P501, DOI 10.1038/nature10193; Chicca E, 2007, IEEE T CIRCUITS-I, V54, P981, DOI 10.1109/TCSI.2007.893509; CONRADT JC, 2009, P 5 IEEE WORKSH EMB, P780; Destexhe A, 2011, CURR OPIN NEUROBIOL, V21, P717, DOI 10.1016/j.conb.2011.06.002; DHOBLE K, P INT JOINT C NEUR N, P554; Dityatev A, 2011, CURR OPIN NEUROBIOL, V21, P353, DOI 10.1016/j.conb.2010.12.006; Epstein A, 2002, IEEE T NUCL SCI, V49, P339, DOI 10.1109/TNS.2002.1003733; Habib AG, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/3/036013; Hampson RE, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/5/056012; Hart PE, 2009, IEEE SIGNAL PROC MAG, V26, P18, DOI 10.1109/MSP.2009.934181; Havenith MN, 2011, J NEUROSCI, V31, P8570, DOI 10.1523/JNEUROSCI.2817-10.2011; Hierlemann A, 2011, P IEEE, V99, P252, DOI 10.1109/JPROC.2010.2066532; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; HUBEL DH, 1982, BIOSCIENCE REP, V2, P435, DOI 10.1007/BF01115245; Huberman AD, 2008, ANNU REV NEUROSCI, V31, P479, DOI 10.1146/annurev.neuro.31.060407.125533; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Hunzinger JF, 2012, J NEUROPHYSIOL, V108, P551, DOI 10.1152/jn.01150.2011; Ide AN, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/1/016008; Ikegaya Y, 2004, SCIENCE, V304, P559, DOI 10.1126/science.1093173; Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882; Jia HB, 2010, NATURE, V464, P1307, DOI 10.1038/nature08947; Johnson HA, 2010, NAT NEUROSCI, V13, P917, DOI 10.1038/nn.2579; Kandler K, 2009, NAT NEUROSCI, V12, P711, DOI 10.1038/nn.2332; Kawakami S, 1996, VISION RES, V36, P117, DOI 10.1016/0042-6989(95)00086-F; Kayser C, 2009, NEURON, V61, P597, DOI 10.1016/j.neuron.2009.01.008; King AJ, 2009, NAT NEUROSCI, V12, P698, DOI 10.1038/nn.2308; Klefenz F, 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, DOI 10.1109/ICASSP.2010.5495004; KLEFENZ F, 1993, IEEE T NUCL SCI, V40, P688, DOI 10.1109/23.256642; Kozorovitskiy Y, 2012, NATURE, V485, P646, DOI 10.1038/nature11052; Lazar AA, 2011, IEEE T NEURAL NETWOR, V22, P461, DOI 10.1109/TNN.2010.2103323; London M, 2005, ANNU REV NEUROSCI, V28, P503, DOI 10.1146/annurev.neuro.28.061604.135703; LONG LN, 2008, P 46 AIAA AER SCI M, P1; Mariani J, 2012, P NATL ACAD SCI USA, V109, P12770, DOI 10.1073/pnas.1202944109; Markram Henry, 2011, Front Synaptic Neurosci, V3, P4, DOI 10.3389/fnsyn.2011.00004; Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213; Masquelier T, 2012, J COMPUT NEUROSCI, V32, P425, DOI 10.1007/s10827-011-0361-9; Min R, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00093; Min R, 2012, NAT NEUROSCI, V15, P746, DOI 10.1038/nn.3075; Moore DR, 2009, NAT NEUROSCI, V12, P686, DOI 10.1038/nn.2326; Nere A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036958; Ochse M., 2006, MUSIC SCI, V10, P185, DOI DOI 10.1177/102986490601000109; Okamoto H, 1999, VISION RES, V39, P3465, DOI 10.1016/S0042-6989(99)00073-5; Pandarinath C, 2010, FRONT COMPUT NEUROSC, V4, DOI 10.3389/fncom.2010.00002; PARADISO MA, 1988, BIOL CYBERN, V58, P35, DOI 10.1007/BF00363954; Quiroga RQ, 2005, NATURE, V435, P1102, DOI 10.1038/nature03687; Rolston JD, 2007, NEUROSCIENCE, V148, P294, DOI 10.1016/j.neuroscience.2007.05.025; Rossi DJ, 2012, NAT NEUROSCI, V15, P649, DOI 10.1038/nn.3095; Ruaro ME, 2005, IEEE T BIO-MED ENG, V52, P371, DOI 10.1109/TBME.2004.842975; Sadeghi S, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P709, DOI 10.1109/IJCNN.2011.6033291; Sasai Y, 2012, SCI AM, V307, P44; SCHEFFER LK, 2012, P 49 ACM EDAC IEEE D, P717; Schober A, 2013, ENG LIFE SCI, V13, P352, DOI 10.1002/elsc.201200088; Stanley GB, 2012, J NEUROSCI, V32, P9073, DOI 10.1523/JNEUROSCI.4968-11.2012; Sun JJ, 2010, EUR J NEUROSCI, V32, P1289, DOI 10.1111/j.1460-9568.2010.07383.x; Trussell LO, 1999, ANNU REV PHYSIOL, V61, P477, DOI 10.1146/annurev.physiol.61.1.477; Vishwanathan A, 2011, LAB CHIP, V11, P1081, DOI [10.1039/c0lc00450b, 10.1039/c01c00450b]; Williamson A, 2013, NANOSCALE, V5, P7297, DOI 10.1039/c3nr01834b; Williamson A, 2013, LAB CHIP, V13, P3471, DOI 10.1039/c3lc50237f; WU Q, 2009, P 5 INT C NAT COMP I, P385; Zeki S, 2013, NEUROIMAGE, V73, P156, DOI 10.1016/j.neuroimage.2013.02.001	73	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1687-5265	1687-5273		COMPUT INTEL NEUROSC	Comput. Intell. Neurosci.		2013									UNSP 290358	10.1155/2013/290358		10	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	AE6MU	WOS:000334108700001		
S	Lam, D; Wunsch, D			IEEE	Lam, Dao; Wunsch, Donald			Unsupervised Feature Learning Classification Using An Extreme Learning Machine	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc				This paper presents a new approach, which we call UFL-ELM, to classification using both unsupervised and supervised learning. Unlike traditional approaches in which features are extracted, hand-crafted, and then trained using timeconsuming, iterated optimization, this proposed method leverages unsupervised feature learning to learn features from the data themselves and then train the classifier using an extreme learning machine to reach the analytic solution. The result is therefore widely and quickly applied to universal data. Experiments on a large dataset of images confirm the ease of use and speed of training of this unsupervised feature learning approach. Furthermore, the paper discusses how to speed up training, using massively parallel programming.	[Lam, Dao; Wunsch, Donald] Missouri Univ Sci & Technol, Dept Elect & Comp Engn, Appl Computat Intelligence Lab, Rolla, MO 65401 USA	Lam, D (reprint author), Missouri Univ Sci & Technol, Dept Elect & Comp Engn, Appl Computat Intelligence Lab, Rolla, MO 65401 USA.	dao.lam@mst.edu; dwunsch@mst.edu					Coates A., 2010, J MACH LEARN JMLR, V15, P48109; Dalal N, 2005, PROC CVPR IEEE, P886; Fahlman S. E., 1988, EMPIRICAL STUDY LEAR; Goodfellow I., 2010, NIPS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsu Chih-Wei, 2002, NEURAL NETWORKS IEEE, V13, P415; HUANG G, 2004, NEUR NETW 2004 P 200, V2, P985; Huang G B, 2012, SYSTEMS MAN CYBERN B, V42, P513; Huang GB, 2010, NEUROCOMPUTING, V74, P155, DOI 10.1016/j.neucom.2010.02.019; Huang Guang Bin, 2006, NEUROCOMPUTING; HUYNH HT, 2008, NEUR NETW 2008 IJCNN, P3028; Inoue T, 2001, IEEE IJCNN, P1449, DOI 10.1109/IJCNN.2001.939575; Le Q.V., 2011, P IEEE C COMP VIS PA, P3361; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Raina R, 2009, 26 ANN INT C MACH LE, V382, P873; Schapire R., 1996, P ICML, V13, P148; Xu R., 2009, CLUSTERING	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												5	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200270		
J	Lammert, A; Goldstein, L; Narayanan, S; Iskarous, K				Lammert, Adam; Goldstein, Louis; Narayanan, Shrikanth; Iskarous, Khalil			Statistical methods for estimation of direct and differential kinematics of the vocal tract	SPEECH COMMUNICATION			English	Article						Speech production; Direct kinematics; Differential kinematics; Task dynamics; Articulatory synthesis; Kinematic estimation; Statistical machine learning; Locally-weighted regression; Artificial neural networks	TO-ARTICULATORY INVERSION; LOCALLY WEIGHTED REGRESSION; NEURAL-NETWORK MODEL; SPEECH PRODUCTION-MODEL; MARQUARDT ALGORITHM; MOTOR CONTROL; MOVEMENTS; ACOUSTICS; MANIPULATORS; GESTURES	We present and evaluate two statistical methods for estimating kinematic relationships of the speech production system: artificial neural networks and locally-weighted regression. The work is motivated by the need to characterize this motor system, with particular focus on estimating differential aspects of kinematics. Kinematic analysis will facilitate progress in a variety of areas, including the nature of speech production goals, articulatory redundancy and, relatedly, acoustic-to-articulatory inversion. Statistical methods must be used to estimate these relationships from data since they are infeasible to express in closed form. Statistical models are optimized and evaluated - using a heldout data validation procedure on two sets of synthetic speech data. The theoretical and practical advantages of both methods are also discussed. It is shown that both direct and differential kinematics can be estimated with high accuracy, even for complex, nonlinear relationships. Locally-weighted regression displays the best overall performance, which may be due to practical advantages in its training procedure. Moreover, accurate estimation can be achieved using only a modest amount of training data, as judged by convergence of performance. The algorithms are also applied to real-time MRI data, and the results are generally consistent with those obtained from synthetic data. (C) 2012 Elsevier B.V. All rights reserved.	[Lammert, Adam; Narayanan, Shrikanth] Univ So Calif, SAIL, Los Angeles, CA 90089 USA; [Goldstein, Louis; Narayanan, Shrikanth; Iskarous, Khalil] Univ So Calif, Dept Linguist, Los Angeles, CA 90089 USA; [Goldstein, Louis; Iskarous, Khalil] Haskins Labs Inc, New Haven, CT 06511 USA	Lammert, A (reprint author), Univ So Calif, SAIL, 3710 McClintock Ave, Los Angeles, CA 90089 USA.	lammert@usc.edu			NIH NIDCD [02717]; NIH [DC008780, DC007124]; Annenberg Foundation	This work was supported by NIH NIDCD Grant 02717, NIH R01 Grant DC008780, NIH Grant DC007124, as well as a graduate fellowship from the Annenberg Foundation. We would also like to acknowledge Elliot Saltzman for his technical insights, and Hosung Nam for his help with understanding TADA.	ABBS JH, 1984, J NEUROPHYSIOL, V51, P705; Al Moubayed S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P937; Ananthakrishnan G., 2009, P INT BRIGHT UK, P2799; ATAL BS, 1978, J ACOUST SOC AM, V63, P1535, DOI 10.1121/1.381848; Atal B.S., 1989, J ACOUSTICAL SOC AM, P86; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAILLY G, 1991, J PHONETICS, V19, P9; Balestrino A., 1984, P 9 IFAC WORLD C, V5, P2435; BENNETT DJ, 1991, IEEE T ROBOTIC AUTOM, V7, P597, DOI 10.1109/70.97871; Bernstein N. A., 1967, COORDINATION REGULAT; Bishop CM, 2006, PATTERN RECOGNITION; BOE LJ, 1992, J PHONETICS, V20, P27; Bresch E, 2009, IEEE T MED IMAGING, V28, P323, DOI 10.1109/TMI.2008.928920; BULLOCK D, 1993, J COGNITIVE NEUROSCI, V5, P408, DOI 10.1162/jocn.1993.5.4.408; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; CLEVELAND WS, 1988, J ECONOMETRICS, V37, P87, DOI 10.1016/0304-4076(88)90077-2; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; D'Souza A., 2001, P CIRAS; Duch W., 1999, NEURAL COMPUTING SUR, V2, P163; Fels S., 2005, P AUD VIS SPEECH PRO, P119; Gerard J.-M., 2006, SPEECH PRODUCTION MO, P85; Gerard JM, 2003, REC RES DEV BIOMECH, V1, P49; Ghosh PK, 2010, J ACOUST SOC AM, V128, P2162, DOI 10.1121/1.3455847; Ghosh PK, 2011, J ACOUST SOC AM, V130, pEL251, DOI 10.1121/1.3634122; GUENTHER FH, 1994, BIOL CYBERN, V72, P43, DOI 10.1007/BF00206237; Guenther FH, 1998, PSYCHOL REV, V105, P611; GUENTHER FH, 1995, PSYCHOL REV, V102, P594; Guigon E, 2007, J NEUROPHYSIOL, V97, P331, DOI 10.1152/jn.00290.2006; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HIROYA S, 2002, ACOUST SPEECH SIG PR, P437; Hiroya S, 2004, IEEE T SPEECH AUDI P, V12, P175, DOI 10.1109/TSA.2003.822636; Hiroya S., 2003, P INT WORKSH SPEECH, P9; Hiroya S., 2002, P ICSLP, P2305; Hogden J, 1996, J ACOUST SOC AM, V100, P1819, DOI 10.1121/1.416001; HOLLERBACH JM, 1982, TRENDS NEUROSCI, V5, P189, DOI 10.1016/0166-2236(82)90111-4; Hollerbach JM, 1996, INT J ROBOT RES, V15, P573, DOI 10.1177/027836499601500604; Homilc K., 1989, NEURAL NETWORKS, V2; Iskarous K., 2003, P ICPHS; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; JORDAN MI, 1992, J MATH PSYCHOL, V36, P396, DOI 10.1016/0022-2496(92)90029-7; JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1; Jordan M.I., 1995, HDB BRAIN THEORY NEU; Kaburagi T., 1998, P ICSLP; Kello CT, 2004, J ACOUST SOC AM, V116, P2354, DOI 10.1121/1.1715112; Kelso S., 1984, J EXP PSYCHOL, V10, P812; KHATIB O, 1987, IEEE T ROBOTIC AUTOM, V3, P43; Lammert A., 2011, J ACOUST SOC AM, V130, P2549; Lammert A., 2010, P INTERSPEECH; Lammert A.C., 2008, P SAPA 08, P29; Lawrence S., 1996, Proceedings of the Seventh Australian Conference on Neural Networks (ACNN'96); McGowan RS, 2009, J ACOUST SOC AM, V126, P2011, DOI 10.1121/1.3184581; MERMELST.P, 1965, J ACOUST SOC AM, V37, P1186, DOI 10.1121/1.1939448; MERMELST.P, 1973, J ACOUST SOC AM, V53, P1070, DOI 10.1121/1.1913427; Mitra V, 2010, IEEE J-STSP, V4, P1027, DOI 10.1109/JSTSP.2010.2076013; Mitra V., 2009, P ICASSP; Mitra V., 2011, IEEE T AUDIO SPEECH; Mooring B. W., 1991, FUNDAMENTALS MANIPUL; Mottet D, 2001, J EXP PSYCHOL HUMAN, V27, P1275, DOI 10.1037/0096-1523.27.6.1275; Nakamura K., 2006, P ICASSP; NAKAMURA Y, 1986, J DYN SYST-T ASME, V108, P163; Nakanishi J, 2008, INT J ROBOT RES, V27, P737, DOI 10.1177/0278364908091463; Nam H., 2004, J ACOUST SOC AM, V115, P2430, DOI DOI 10.1016/J.SPECOM.2005.07.003; Nam H., 2006, TADA TASK DYNAMICS A; Nam H., 2010, P ICASSP; Narayanan S., 2004, JASA, V109, P2446; Narayanan S., 2011, P INTERSPEECH; Panchapagesan S, 2011, J ACOUST SOC AM, V129, P2144, DOI 10.1121/1.3514544; PAPCUN G, 1992, J ACOUST SOC AM, V92, P688, DOI 10.1121/1.403994; Payan Y., 1997, SPEECH COMMUN, V22, P187; Perrier P, 1996, J PHONETICS, V24, P53, DOI 10.1006/jpho.1996.0005; Perrier P, 2003, J ACOUST SOC AM, V114, P1582, DOI 10.1121/1.1587737; Qin C., 2007, P INTERSPEECH; Qin C., 2010, P INTERSPEECH; Rahim M. G., 1991, P IEEE INT C AC SPEE, P485, DOI 10.1109/ICASSP.1991.150382; Richmond K., 2010, P INTERSPEECH, P577; Rubin P., 1996, P 1 ETRW SPEECH PROD; Rumelhart D., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D., 1986, NATURE, V323; Saltzman E, 2000, HUM MOVEMENT SCI, V19, P499, DOI 10.1016/S0167-9457(00)00030-0; Saltzman E., 2006, DYNAMICS SPEECH PROD; SALTZMAN E, 1987, PSYCHOL REV, V94, P84, DOI 10.1037//0033-295X.94.1.84; Saltzman E. L., 1989, ECOL PSYCHOL, V1, P333, DOI 10.1207/s15326969eco0104_2; Scholz J. P., 1999, EXP BRAIN RES, V126, P189; Schroeter J, 1994, IEEE T SPEECH AUDI P, V2, P133, DOI 10.1109/89.260356; Sciavicco L., 2005, MODELLING CONTROL RO; Shiga Y., 2004, P INTERSPEECH; Sklar M.E., 1989, P 2 C REC ADV ROB, P178; SOECHTING JF, 1982, BRAIN RES, V248, P392, DOI 10.1016/0006-8993(82)90601-1; Ting J.A., 2008, P ICRA PAS CA; Toda T., 2004, P 5 ISCA SPEECH SYNT, P31; Toda T., 2008, SPEECH COMMUNICATION, V50; Toledo A, 2005, IEEE T NEURAL NETWOR, V16, P988, DOI 10.1109/TNN.2005.849849; Vogt F., 2005, J ACOUST SOC AM, V117, P2542; Vogt F., 2006, P ISSP, P51; WAKITA H, 1973, IEEE T ACOUST SPEECH, VAU21, P417, DOI 10.1109/TAU.1973.1162506; WAMPLER CW, 1986, IEEE T SYST MAN CYB, V16, P93, DOI 10.1109/TSMC.1986.289285; WHITNEY DE, 1969, IEEE T MAN MACHINE, VMM10, P47, DOI 10.1109/TMMS.1969.299896; Wilamowski BM, 2008, IEEE T IND ELECTRON, V55, P3784, DOI 10.1109/TIE.2008.2003319; Winkler R., 2011, P INTERSPEECH; Winkler R., 2011, P ISSP; Wolovich W. A., 1984, Proceedings of the 23rd IEEE Conference on Decision and Control (Cat. No. 84CH2093-3); Wrench A. A., 2000, P 5 SEM SPEECH PROD, P305; Wu JM, 2008, IEEE T NEURAL NETWOR, V19, P2032, DOI 10.1109/TNN.2008.2003271	106	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393	1872-7182		SPEECH COMMUN	Speech Commun.	JAN	2013	55	1					147	161		10.1016/j.specom.2012.08.001		15	Acoustics; Computer Science, Interdisciplinary Applications	Acoustics; Computer Science	055NF	WOS:000312422900012		
S	Le, HM; Duong, AT; Tran, ST		Kamel, M; Campilho, A		Le, Hieu M.; Duong, An T.; Tran, Son T.			Multiple-Classifier Fusion Using Spatial Features for Partially Occluded Handwritten Digit Recognition	IMAGE ANALYSIS AND RECOGNITION	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Image Analysis and Recognition (ICIAR)	JUN 26-28, 2013	Povoa do Varzim, PORTUGAL	Assoc Image & Machine Intelligence		Digit Recognition; Neural Network; Denoising; Particially Occluded Handwritten Digit; Spatial Feature		The subject of handwritten digit recognition is a great concern and has many applications in various fields. Although highly restricted forms of digit recognition are widely utilized, reading incomplete and occluded digit image is still a challenge for both academia and industries. In this paper, we attack the problems of recognizing occluded handwritten digits by finding the influence of small patches in digit images to the recognition results. We apply one-hidden-layer neural networks to train and validate each patch independently and enhance the performance of each classifier by the results of its correlated patches. This method allows us to restrict the effect of false information solely into areas that small patches lay on and then correct recognition results by their neighbors. The result of the proposed method shows a noticeable improvement in the stable ability of recognition model with different kinds of simulated distortions.	[Le, Hieu M.; Duong, An T.; Tran, Son T.] Univ Sci, Thanh Pho Ho Chi Minh, Vietnam	Le, HM (reprint author), Univ Sci, Thanh Pho Ho Chi Minh, Vietnam.	0812141@student.hcmus.edu.vn; 0912019@student.hcmus.edu.vn; ttson@fit.hcmus.edu.vn					Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Ciresan D.C., 2010, ABS10030358 CORR; Coates A., 2011, ICDAR 2011; DeCoste D., 2002, MACHINE LEARNING J M, V46; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jolliffe I. T., 1986, PRINCIPAL COMPONENT, P487, DOI [DOI 10.1007/B98835, 10.1007/b98835]; Kegl B., 2009, P 26 ANN INT C MACH, P497; Lauer F, 2007, PATTERN RECOGN, V40, P1816, DOI 10.1016/j.patcog.2006.10.011; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1985, P COGNITIVA, V85, P599; Netzer Y., 2011, NIPS 2011 WORKSH DEE; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Ranzato M., 2006, ADV NEURAL INFORM PR, V19; Salakhutdinov R., 2007, AI STATISTICS; Simard P. Y., 2003, INT C DOC AN REC ICD, P958; Vincent P, 2010, J MACH LEARN RES, V11, P3371	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-39094-4; 978-3-642-39093-7	LECT NOTES COMPUT SC			2013	7950						124	132				9	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BB3QC	WOS:000342993000015		
J	Lee, K; Hyung, Z; Nam, J			IEEE	Lee, Kyogu; Hyung, Ziwon; Nam, Juhan			ACOUSTIC SCENE CLASSIFICATION USING SPARSE FEATURE LEARNING AND EVENT-BASED POOLING	2013 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA)	IEEE Workshop on Applications of Signal Processing to Audio and Acoustics		English	Proceedings Paper	14th IEEE Workshop on Applications of Signal Processing to AudNew Paltzio and Acoustics (WASPAA)	OCT 20-23, 2013	New Paltz, NY	IEEE		acoustic scene classification; environmental sound; feature learning; restricted Boltzmann machine; sparse feature representation; max-pooling; event detection		Recently unsupervised learning algorithms have been successfully used to represent data in many of machine recognition tasks. In particular, sparse feature learning algorithms have shown that they can not only discover meaningful structures from raw data but also outperform many hand-engineered features. In this paper, we apply the sparse feature learning approach to acoustic scene classification. We use a sparse restricted Boltzmann machine to capture manyfold local acoustic structures from audio data and represent the data in a high-dimensional sparse feature space given the learned structures. For scene classification, we summarize the local features by pooling over audio scene data. While the feature pooling is typically performed over uniformly divided segments, we suggest a new pooling method, which first detects audio events and then performs pooling only over detected events, considering the irregular occurrence of audio events in acoustic scene data. We evaluate the learned features on the IEEE AASP Challenge development set, comparing them with a baseline model using mel-frequency cepstral coefficients (MFCCs). The results show that learned features outperform MFCCs, event-based pooling achieves higher accuracy than uniform pooling and, furthermore, a combination of the two methods performs even better than either one used alone.	[Lee, Kyogu; Hyung, Ziwon] Seoul Natl Univ, Mus & Audio Res Grp, Seoul 151, South Korea; [Nam, Juhan] Stanford Univ, CCRMA, Stanford, CA 94305 USA	Lee, K (reprint author), Seoul Natl Univ, Mus & Audio Res Grp, Seoul 151, South Korea.	ziotoss@snu.ac.kr; kglee@snu.ac.kr; juhan@ccrma.stanford.edu					Cotton C. V., 2011, P IEEE INT C AC SPEE; Henaff M., 2011, P 12 INT C MUS INF R; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee H., 2009, P 23 ANN C NEUR INF, V9, P1096; Lyon R. F., 2010, NEURAL COMPUTATION, V22; Nam J., 2012, P 13 INT C MUS INF R; Wulng J., 2012, P 13 INT C MUS INF R	8	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1931-1168		978-1-4799-0972-8	IEEE WORK APPL SIG			2013												4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BC0SP	WOS:000349479800085		
J	Li, LF; Zhao, Y; Jiang, DM; Zhang, YN; Wang, FN; Gonzalez, I; Valentin, E; Sahli, H			IEEE	Li, Longfei; Zhao, Yong; Jiang, Dongmei; Zhang, Yanning; Wang, Fengna; Gonzalez, Isabel; Valentin, Enescu; Sahli, Hichem			Hybrid Deep Neural Network - Hidden Markov Model (DNN-HMM) Based Speech Emotion Recognition	2013 HUMAINE ASSOCIATION CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION (ACII)	International Conference on Affective Computing and Intelligent Interaction		English	Proceedings Paper	5th Biannual Conference of the Humaine-Association on Affective Computing and Intelligent Interaction (ACII)	SEP 02-05, 2013	Geneva, SWITZERLAND	Humaine Assoc, IEEE Comp Soc, Comp Vis, Multimedia Lab, Univ Geneva, Swiss Ctr Affect Sci, GFK Verein, Technicolor, Telono, Brain Prod, Inst Telecom, Telecom ParisTech, Swiss Natl Sci Fdn, Soc Academique Geneve, Amer Assoc Artificial Intelligence				Deep Neural Network Hidden Markov Models, or DNN-HMMs, are recently very promising acoustic models achieving good speech recognition results over Gaussian mixture model based HMMs (GMM-HMMs). In this paper, for emotion recognition from speech, we investigate DNN-HMMs with restricted Boltzmann Machine (RBM) based unsupervised pre-training, and DNN-HMMs with discriminative pre-training. Emotion recognition experiments are carried out on these two models on the eNTERFACE'05 database and Berlin database, respectively, and results are compared with those from the GMM-HMMs, the shallow-NN-HMMs with two layers, as well as the Multi-layer Perceptrons HMMs (MLP-HMMs). Experimental results show that when the numbers of the hidden layers as well hidden units are properly set, the DNN could extend the labeling ability of GMM-HMM. Among all the models, the DNN-HMMs with discriminative pre-training obtain the best results. For example, for the eNTERFACE'05 database, the recognition accuracy improves 12.22% from the DNN-HMMs with unsupervised pre-training, 11.67% from the GMM-HMMs, 10.56% from the MLP-HMMs, and even 17.22% from the shallow-NN-HMMs, respectively.	[Li, Longfei; Zhao, Yong; Jiang, Dongmei; Zhang, Yanning] Northwestern Polytech Univ, VUB NPU Joint AVSP Res Lab, Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian 710072, Peoples R China	Li, LF (reprint author), Northwestern Polytech Univ, VUB NPU Joint AVSP Res Lab, Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian 710072, Peoples R China.	jiangdm@nwpu.edu.cn; hsahli@vub.ac.be					Burkhardt F., 2005, P INTERSPEECH, V2005; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Martin O., 2006, DAT ENG WORKSH 2006, P8; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; Nicholson J, 2000, NEURAL COMPUT APPL, V9, P290, DOI 10.1007/s005210070006; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S01167-6393(03)00099-2; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Schwarz P., 2006, ATOMIC STATIC DIPOLE, V1, pI; Seide F., 2011, ASRU, P24; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Young S., 2002, HTK BOOK, V3	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2156-8103		978-0-7695-5048-0	INT CONF AFFECT			2013							312	317		10.1109/ACII.2013.58		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BA2RH	WOS:000333833400052		
J	Li, Q; Cai, WD; Feng, DD			IEEE	Li, Qing; Cai, Weidong; Feng, David Dagan			Lung Image Patch Classification with Automatic Feature Learning	2013 35TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY (EMBC)	IEEE Engineering in Medicine and Biology Society Conference Proceedings		English	Proceedings Paper	35th Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society (EMBC)	JUL 03-07, 2013	Osaka, JAPAN	IEEE Engn Med Biol Soc, Japanese Soc Med & Biol Engn			LOCAL BINARY PATTERNS; TEXTURE CLASSIFICATION; EMPHYSEMA; NETWORKS; SCALE	Image patch classification is an important task in many different medical imaging applications. The classification performance is usually highly dependent on the effectiveness of image feature vectors. While many feature descriptors have been proposed over the past years, they can be quite complicated and domain-specific. Automatic feature learning from image data has thus emerged as a different trend recently, to capture the intrinsic image features without manual feature design. In this paper, we propose to create multi-scale feature extractors based on an unsupervised learning algorithm; and obtain the image feature vectors by convolving the feature extractors with the image patches. The auto-generated image features are data-adaptive and highly descriptive. A simple classification scheme is then used to classify the image patches. The proposed method is generic in nature and can be applied to different imaging domains. For evaluation, we perform image patch classification to differentiate various lung tissue patterns commonly seen in interstitial lung disease (ILD), and demonstrate promising results.	[Li, Qing; Cai, Weidong; Feng, David Dagan] Univ Sydney, Biomed & Multimedia Informat Technol BMIT Res Grp, Sch Informat Technol, Sydney, NSW 2006, Australia	Li, Q (reprint author), Univ Sydney, Biomed & Multimedia Informat Technol BMIT Res Grp, Sch Informat Technol, Sydney, NSW 2006, Australia.						Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Dalal N, 2005, PROC CVPR IEEE, P886; Depeursinge A, 2011, LECT NOTES COMPUT SC, V6893, P231, DOI 10.1007/978-3-642-23626-6_29; Depeursinge A, 2012, COMPUT MED IMAG GRAP, V36, P227, DOI 10.1016/j.compmedimag.2011.07.003; Depeursinge A, 2012, IEEE T INF TECHNOL B, V16, P665, DOI 10.1109/TITB.2012.2198829; Geoffrey Hinton, 2010, 2010003 UTML TR U TO; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jacobs C, 2011, LECT NOTES COMPUT SC, V6893, P207, DOI 10.1007/978-3-642-23626-6_26; Krizhevsky A., 2009, THESIS U TORONTO; Krizhevsky A., 2011, P ESANN, P489; Krizhevsky A., 2012, P NIPS, P1; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Song Y, 2012, IEEE T MED IMAGING, V31, P1061, DOI 10.1109/TMI.2012.2185057; Song Y, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P482; Song Y, 2013, IEEE T MED IMAGING, V32, P797, DOI 10.1109/TMI.2013.2241448; SONG Y, 2012, 2012 9 IEEE INT S, P1439; Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575; Webb W. R., 2008, HIGH RESOLUTION CT L; Xu Y, 2006, IEEE T MED IMAGING, V25, P464	22	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1557-170X		978-1-4577-0216-7	IEEE ENG MED BIO			2013							6079	6082				4	Engineering, Biomedical; Engineering, Electrical & Electronic	Engineering	BB2DX	WOS:000341702106119		
J	Lin, ZH; Chen, YS; Zhao, X; Wang, G			IEEE	Lin, Zhouhan; Chen, Yushi; Zhao, Xing; Wang, Gang			Spectral-Spatial Classification of Hyperspectral Image Using Autoencoders	2013 9TH INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING (ICICS)			English	Proceedings Paper	9th International Conference on Information, Communications and Signal Processing (ICICS)	NOV 10-13, 2013	Tainan, TAIWAN	Nanyang Technolog Univ, Sch Elect & Elect Engn, Natl Cheng Kung Univ, Dept Elect Engn, IEEE Tainan Sect, IEEE Circuits & Syst Soc, Tainan Chapter, IEEE Computat Intelligence Soc, Tainan Chapter, IEEE Commun Soc, Singapore Chapter, IEEE Commun Soc, Tainan Chapter, IEEE Signal Proc Soc, Singapore Chapter, IEEE Signal Proc Soc, Tainan Chapter		autoencoders; deep learning; hyperspectral; image classification; neural networks; stacked autoencoders	SUPPORT VECTOR MACHINES; REMOTE-SENSING IMAGES; NETWORK	Hyperspectral image (HSI) classification is a hot topic in the remote sensing community. This paper proposes a new framework of spectral-spatial feature extraction for HSI classification, in which for the first time the concept of deep learning is introduced. Specifically, the model of autoencoder is exploited in our framework to extract various kinds of features. First we verify the eligibility of autoencoder by following classical spectral information based classification and use autoencoders with different depth to classify hyperspectral image. Further in the proposed framework, we combine PCA on spectral dimension and autoencoder on the other two spatial dimensions to extract spectral-spatial information for classification. The experimental results show that this framework achieves the highest classification accuracy among all methods, and outperforms classical classifiers such as SVM and PCA-based SVM.	[Lin, Zhouhan; Chen, Yushi; Zhao, Xing] Harbin Inst Technol, Dept Informat Engn, Harbin 150006, Peoples R China; [Wang, Gang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Lin, ZH (reprint author), Harbin Inst Technol, Dept Informat Engn, Harbin 150006, Peoples R China.	lin.zhouhan@gmail.com; chenyushi@hit.edu.cn; xintongzhaoxing@126.com; wanggang@ntu.edu.sg					Benediktsson JA, 2003, IEEE T GEOSCI REMOTE, V41, P1940, DOI 10.1109/TGRS.2003.814625; Bengio Y., 2012, ARXIV12065538; Bengio Y., 2007, NIPS, V19, P153; Bergstra J., 2010, P PYTH SCI COMP C SC; Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Hinton G. E., 2010, TR2010003 UTML DEP C; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Mohamed A., 2009, P NIPS WORKSH DEC; Rajan S, 2008, IEEE T GEOSCI REMOTE, V46, P1231, DOI 10.1109/TGRS.2007.910220; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Smith R. B., 2006, INTRO HYPERSPECTRAL; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Ying Liu, 2006, INN COMP INF CONTR 1; Yu D., 2009, P NIPS WORKSH DEC	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-0434-1				2013												5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BC5JU	WOS:000353339000010		
J	Liong, VE; Lu, JW; Wang, G			IEEE	Liong, Venice Erin; Lu, Jiwen; Wang, Gang			Face Recognition Using Deep PCA	2013 9TH INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING (ICICS)			English	Proceedings Paper	9th International Conference on Information, Communications and Signal Processing (ICICS)	NOV 10-13, 2013	Tainan, TAIWAN	Nanyang Technolog Univ, Sch Elect & Elect Engn, Natl Cheng Kung Univ, Dept Elect Engn, IEEE Tainan Sect, IEEE Circuits & Syst Soc, Tainan Chapter, IEEE Computat Intelligence Soc, Tainan Chapter, IEEE Commun Soc, Singapore Chapter, IEEE Commun Soc, Tainan Chapter, IEEE Signal Proc Soc, Singapore Chapter, IEEE Signal Proc Soc, Tainan Chapter			ALGORITHMS; NETWORKS; ICA	In this paper, we propose a new deep learning method called Deep PCA (DPCA) for face recognition. Our method performs deep learning through hierarchically projecting face image vectors to different feature subspaces and obtaining the representations from different projections. Specifically, we perform a two-layer ZCA whitening plus PCA structure for learning hierarchical features. The whole feature representation of each face image can be extracted by concatenating the representations from the first and second layers. Our approach learns deep representations from the data, by utilizing information from the first layer to produce a new and different representation, making it more discriminative. Experimental results on the widely used FERET and AR databases are presented to show the efficiency of the proposed approach.	[Liong, Venice Erin; Lu, Jiwen; Wang, Gang] Adv Digital Sci Ctr, Singapore, Singapore; [Wang, Gang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Liong, VE (reprint author), Adv Digital Sci Ctr, Singapore, Singapore.	venice.l@adsc.com.sg; jiwen.lu@adsc.com.sg; wangang@ntu.edu.sg					Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Coates A., 2011, J MACHINE LEARNING R, V15, P215; Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968; Krizhevsky A., 2009, THESIS U TORONTO; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Liu CJ, 1998, INT C PATT RECOG, P1368; Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926; Lu JW, 2010, IEEE T INF FOREN SEC, V5, P71, DOI 10.1109/TIFS.2009.2035976; Lu JW, 2010, PATTERN RECOGN LETT, V31, P382, DOI 10.1016/j.patrec.2009.11.006; Lu JW, 2007, PATTERN RECOGN LETT, V28, P2401, DOI 10.1016/j.patrec.2007.08.004; Lu JW, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1943; Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70; Lu JW, 2010, IEEE SIGNAL PROC LET, V17, P185, DOI 10.1109/LSP.2009.2035017; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647; Lu JW, 2010, PROC CVPR IEEE, P2661, DOI 10.1109/CVPR.2010.5539983; Martinez A., 1998, 24 CVC; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Sohn K, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2643; Turk M. A., 1991, IEEE C COMP VIS PATT, V591, P586, DOI DOI 10.1109/CVPR.1991.139758; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	27	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-0434-1				2013												5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BC5JU	WOS:000353339000009		
J	Luo, YX; Wan, Y		Yuan, Z; Wang, L; Xu, W; Yu, K		Luo, Yuxi; Wan, Yi			A Novel Efficient Method for Training Sparse Auto-Encoders	2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3			English	Proceedings Paper	6th International Congress on Image and Signal Processing (CISP)	DEC 16-18, 2013	Hangzhou, PEOPLES R CHINA	IEEE, Hangzhou Normal Univ, EMB		representation learning; feature learning; unsupervised learning; sparse auto-encoders; neural network		The success of machine learning algorithms generally depends on data representation. So far there has been a great deal of literature on unsupervised feature learning and joint training of deep learning. There is little specific guidance, however, on combining hand-designed features or the operations on them with features which are learned from unsupervised learning. In this paper, using MNIST ("Modified National Institute of Standards and Technology") handwritten digit database as an example, we propose a novel method for training sparse auto-encoders. In this method, we first get some small-scale features through training, then generate more features through operations such as rotation and translation. Finally, we use the whole dataset to fine-tune the network. This approach avoids optimizing cost function for all nodes in the traditional sparse auto-encoder training process, which is very time-consuming. Simulation results show that the proposed method can speed up the training process by over 50%, while keeping the recognition accuracy at the same level or even better. The present findings also contribute to the field's understanding of sparse representation that large-scale sparse features can be generated by small-scale sparse features.	[Luo, Yuxi; Wan, Yi] Lanzhou Univ, Sch Informat Sci & Engn, Inst Signals & Informat Proc, Lanzhou 730000, Peoples R China	Luo, YX (reprint author), Lanzhou Univ, Sch Informat Sci & Engn, Inst Signals & Informat Proc, Lanzhou 730000, Peoples R China.	yuxi.luo@gmail.com; wanyi@lzu.edu.cn					Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Coates A, 2011, INT C ART INT STAT, P215; Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755; Erhan D., 2009, TECHNICAL REPORT; Hinton G., 2010, MOMENTUM, V9; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang JP, 1997, J METEOROL SOC JPN, V75, P701; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; LeCun Y., 1998, MNIST DATABASE HANDW; MALLAT SG, 1989, PATTERN ANAL MACHINE, V11, P674; Mikolov T., 2011, INTERSPEECH, P605; Ng A., UFLDL TUTORIAL; Ngiam J., 2011, P 28 INT C MACH LEAR, P265; Schmidt M, 2005, MINFUNC; Simard P., 2003, ICDAR, V3, P958	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2763-0				2013							1019	1023				5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BB1GK	WOS:000341115000189		
J	Nakashika, T; Takiguchi, T; Ariki, Y		Yetongnon, K; Dipanda, A; Chbeir, R		Nakashika, Toru; Takiguchi, Tetsuya; Ariki, Yasuo			High-frequency Restoration Using Deep Belief Nets for Super-resolution	2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS)			English	Proceedings Paper	9th International Conference on Signal-Image Technology and Internet-Based Systems (SITIS)	DEC 02-05, 2013	Kyoto, JAPAN			super-resolution; deep-learning; deep-belief-nets; image-restoration		Super-resolution technology, which restores high-frequency information given a low-resolved image, has attracted much attention recent years. Various super-resolution algorithms were proposed so far: example-based approach, sparse-coding-based, GMM (Gaussian Mixture Model), BPLP (Back Projection for Lost Pixels), and so on. Most of these statistical approaches rely on the training (or just preparing) of the correspondence relationships between low-resolved/high-resolved images. In this paper, we propose a novel super-resolution method that is based on a statistical model but does not require any pairs of low and high-resolved images in the database. In our approach, Deep Belief Bets are used to restore high-frequency information from a low-resolved image. The idea is that only using high-resolved images, the trained networks seek the high-order dependencies among the observed nodes (each spatial frequency: e.g., high and low frequencies). Experimental results show the high performance of our proposed method.	[Nakashika, Toru] Kobe Univ, Grad Sch Syst Informat, Kobe, Hyogo 657, Japan	Nakashika, T (reprint author), Kobe Univ, Grad Sch Syst Informat, 1-1 Rokkodai, Kobe, Hyogo 657, Japan.	nakashika@me.cs.scitec.kobe-u.ac.jp; takigu@kobe-u.ac.jp; ariki@kobe-u.ac.jp					Babacan SD, 2008, IEEE IMAGE PROC, P641, DOI 10.1109/ICIP.2008.4711836; Deepu R., 2002, J MATH IMAGING VIS, V16, P5; Deselaers T., 2009, P EACL 2009 WORKSH S, P233, DOI 10.3115/1626431.1626476; Eslami S. M., 2012, IEEE C COMP VIS PATT; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Gao JB, 2013, IEEE IMAGE PROC, P499; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang YZ, 2006, J COMPUT ELECTRON, V5, P275, DOI 10.1007/s10825-006-0145-z; Kasturiwala S. B., 2010, INT J COMPUTATIONAL, V5, P1659; Kawano H., 2010, IM VID TECHN PSIVT, P404; Li H., 2013, COMPUTER VISION PATT, P23; Liangpei Z., 2010, J SIGNAL PROCESSING, V90, P848; Lin Z., 2012, IEEE C COMP VIS PATT, P2360; Mario Figueiredo A. T., 2010, P IEEE, V98, P972; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Ogawa Y, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1285; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-3211-5				2013							38	42		10.1109/SITIS.2013.18		5	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BB7ZQ	WOS:000346159700007		
J	Ni, JC; Xu, YL		Yuan, Z; Wang, L; Xu, W; Yu, K		Ni, Jia Cheng; Xu, Yue Lei			SAR Automatic Target Recognition Based on a Visual Cortical System	2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3			English	Proceedings Paper	6th International Congress on Image and Signal Processing (CISP)	DEC 16-18, 2013	Hangzhou, PEOPLES R CHINA	IEEE, Hangzhou Normal Univ, EMB		SAR; Object Recognition; Visual Cortex; ICM; Sparse Autoencoder		Human Vision system is the most complex and accurate system. In order to extract better features about Synthetic Aperture Radar (SAR) targets, a SAR automatic target recognition (ATR) algorithm based on human visual cortical system is proposed. This algorithm contains three stages: (1) Image preprocessing (we use a Kuan filter to do the enhancement and an adaptive Intersecting Cortical Model (ICM) to do the segmentation) (2) Feature extraction using a sparse autoencoder. (3) Classification using a softmax regression classifier. Experiment result of MSTAR public data shows a better performance of recognition.	[Ni, Jia Cheng; Xu, Yue Lei] Air Force Engn Univ, Inst Aeronaut & Astronaut Engn, Xian, Peoples R China	Ni, JC (reprint author), Air Force Engn Univ, Inst Aeronaut & Astronaut Engn, Xian, Peoples R China.	littlenjc@gmail.com; yueleixu@sina.com					CAO ZJ, 2012, GC 12 WORKSH RAD SON, P1450; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Ekblad U, 2004, SIGNAL PROCESS, V84, P1131, DOI 10.1016/j.sigpro.2004.03.012; Gong Cheng, 2009, J IMAGE GRAPHICS, V14, P317; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Krizhevsky Alex, 2012, ADV NEURAL INFORM PR, V12, P1326; Lee T., 2003, JOSAA, P425; Papson S, 2012, IEEE T AERO ELEC SYS, V48, P969, DOI 10.1109/TAES.2012.6178042; Tang T, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P1073; Thiagarajan J, 2010, P 4 INT S COMM CONTR, P1512; Wallis G., 1999, TRENDS COGN SCI, V2, P642; Ye Xiaoming, 2012, 7 IEEE C IND EL APPL, P1888	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2763-0				2013							778	782				5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BB1GK	WOS:000341115000145		
J	Ogata, T; Okuno, HG			IEEE	Ogata, Tetsuya; Okuno, Hiroshi G.			Integration of behaviors and languages with a hierarchal structure self-organized in a neuro-dynamical model	PROCEEDINGS OF THE 2013 IEEE WORKSHOP ON ROBOTIC INTELLIGENCE IN INFORMATIONALLY STRUCTURED SPACE (RIISS)			English	Proceedings Paper	3rd IEEE Workshop on Robotic Intelligence In Informationally Structured Space (RiiSS)	APR 16-19, 2013	Singapore, SINGAPORE	IEEE, IEEE Computat Intelligence Soc		neuro-dynamical systems; behaviors; language grammer; word contents; symbol grounding		This paper proposes an approach for robots to ac-quire language grounding in their robot's sensory-motor flow using neuro-dynamical models. We trained our neuro-dynamical model over a set of sentences represented as sequences of characters. For the integrated recognition, we introduced a cognitive hypothesis for integrated recognition where a human's brain separately processed the "structure" and "contents" of a sentence. Our model was trained with the spelling of words and their semantic role emerged in the first model. As a result of binding the model with sensory-motion patterns, we confirmed that it could associate proper word spellings with a sensory-motor flows and a semantic roles, even if an observed flow had not been learned.	[Ogata, Tetsuya] Waseda Univ, Sch Fundamental Sci & Engn, Tokyo, Japan	Ogata, T (reprint author), Waseda Univ, Sch Fundamental Sci & Engn, Tokyo, Japan.	ogata@waseda.jp; okuno@i.kyoto-u.ac.jp					Cangelosi A, 2010, IEEE T AUTON MENT DE, V2, P167, DOI 10.1109/TAMD.2010.2053034; Dominey PF, 2000, LANG COGNITIVE PROC, V15, P87; ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; Hinoshita W, 2011, NEURAL NETWORKS, V24, P311, DOI 10.1016/j.neunet.2010.12.006; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Inui Toshio, 2010, Japanese Journal of Animal Psychology, V60, P59, DOI 10.2502/janip.60.1.4; Kohonen T., 1976, ASS MEMORY SYSTEM TH; Kozima H., 2005, AAAI SPRING S DEV RO; Ogata T., 2007, P IEEE RSJ INT C INT, P1858; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Sugita Y, 2005, ADAPT BEHAV, V13, P33, DOI 10.1177/105971230501300102; Takano W, 2009, P IEEE INT C ROB AUT, P646; Tani J, 2003, IEEE T SYST MAN CY A, V33, P481, DOI 10.1109/TSMCA.2003.809171; Yamashita Y., 2008, PLOS COMPUT BIOL, V4	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-5877-4				2013							89	95				7	Engineering, Electrical & Electronic; Robotics	Engineering; Robotics	BA1YY	WOS:000333189400014		
J	Palangi, H; Ward, R; Deng, L			IEEE	Palangi, Hamid; Ward, Rabab; Deng, Li			USING DEEP STACKING NETWORK TO IMPROVE STRUCTURED COMPRESSED SENSING WITH MULTIPLE MEASUREMENT VECTORS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Compressed Sensing; Multiple Measurement Vectors; Deep Learning	NEURAL-NETWORKS; ALGORITHMS; SIGNAL	We study the MMV (Multiple Measurement Vectors) compressive sensing setting with a specific sparse structured support. The locations of the non-zero rows in the sparse matrix are not known. All that is known is that the locations of the non-zero rows have probabilities that vary from one group of rows to another. We propose two novel greedy algorithms for the exact recovery of the sparse matrix in this structured MMV compressive sensing problem. The first algorithm models the matrix sparse structure using a shallow non-linear neural network. The input of this network is the residual matrix after the prediction and the output is the sparse matrix to be recovered. The second algorithm improves the shallow neural network prediction by using the stacking operation to form a deep stacking network. Experimental evaluation demonstrates the superior performance of both new algorithms over existing MMV methods. Among all, the algorithm using the deep stacking network for modelling the structure in MMV compressive sensing performs the best.	[Palangi, Hamid; Ward, Rabab] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V5Z 1M9, Canada	Palangi, H (reprint author), Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V5Z 1M9, Canada.						Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Candes EJ, 2011, APPL COMPUT HARMON A, V31, P59, DOI 10.1016/j.acha.2010.10.002; Deng L, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2133; Deng L., 2013, AC SPEECH SIGN PROC; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Duarte MF, 2011, IEEE T SIGNAL PROCES, V59, P4053, DOI 10.1109/TSP.2011.2161982; Freund Y., 1994, UNSUPERVISED LEARNIN; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang Po-Sen, 2013, AC SPEECH SIGN PROC; Merhej D, 2011, IEEE T NEURAL NETWOR, V22, P1638, DOI 10.1109/TNN.2011.2164810; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Yu D, 2012, PATTERN RECOGN LETT, V33, P554, DOI 10.1016/j.patrec.2011.12.002; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							3337	3341				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611503099		
S	Pedroni, BU; Das, S; Neftci, E; Kreutz-Delgado, K; Cauwenberghs, G			IEEE	Pedroni, Bruno U.; Das, Srinjoy; Neftci, Emre; Kreutz-Delgado, Kenneth; Cauwenberghs, Gert			Neuromorphic Adaptations of Restricted Boltzmann Machines and Deep Belief Networks	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc			LEARNING ALGORITHM	Restricted Boltzmann Machines (RBMs) and Deep Belief Networks (DBNs) have been demonstrated to perform efficiently on a variety of applications, such as dimensionality reduction and classification. Implementation of RBMs on neuromorphic platforms, which emulate large-scale networks of spiking neurons, has significant advantages from concurrency and low-power perspectives. This work outlines a neuromorphic adaptation of the RBM, which uses a recently proposed neural sampling algorithm (Buesing et al. 2011), and examines its algorithmic efficiency. Results show the feasibility of such alterations, which will serve as a guide for future implementation of such algorithms in neuromorphic very large scale integration (VLSI) platforms.	[Pedroni, Bruno U.; Cauwenberghs, Gert] Univ Calif San Diego, Dept Bioengn, San Diego, CA 92103 USA; [Das, Srinjoy] Univ Calif San Diego, Inst Neural Computat, Elect & Comp Engn Dept, La Jolla, CA USA; [Neftci, Emre] Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA; [Kreutz-Delgado, Kenneth] Univ Calif San Diego, Elect & Comp Engn Dept, La Jolla, CA 92093 USA	Pedroni, BU (reprint author), Univ Calif San Diego, Dept Bioengn, San Diego, CA 92103 USA.	bpedroni@eng.ucsd.edu; s2das@ucsd.edu; nemre@ucsd.edu; kreutz@eng.ucsd.edu; gert@ucsd.edu					Aarts E.H.L., 1987, PARLE PARALLEL ARCHI; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Buesing L., 2011, PLOS COMPUTATIONAL B, V7; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1984, CMUCS84119; Hinton G.E., NEURAL COMPUTATION, V14, P1771; La Rochelle H., 2008, P 25 INT C MACH LEAR; Mead C., 1989, ANALOG VLSI NEURAL S; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200360		
S	Pei, DL; Liu, HP; Liu, YL; Sun, FC			IEEE	Pei, Deli; Liu, Huaping; Liu, Yulong; Sun, Fuchun			Unsupervised Multimodal Feature Learning for Semantic Image Segmentation	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc				In this paper, we address the semantic segmentation problem using single-layer networks. This network is used for unsupervised feature learning for the available RGB image and the depth image. A significant contribution of the proposed approach is that the dictionary is selected from the existing samples using the L-2,L-1 optimization. Such a dictionary can capture more meaningful representative samples and exploit intrinsic correlation between features from different modalities. The experimental results on the public NYU dataset show that this strategy dramatically improves the classification performance, compared with existing dictionary learning approach. In addition, we perform experimental verification using the practical robot platforms and show promising results.	[Pei, Deli] Tsinghua Univ, Dept Comp Sci & Technol, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Pei, DL (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.	derrypei@gmail.com					Bo LF, 2011, IEEE INT C INT ROBOT, P821; Boix X, 2012, INT J COMPUT VISION, V96, P83, DOI 10.1007/s11263-011-0449-8; Coates A., 2011, INT C ART INT STAT A; Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Gabay D., 1976, Computers & Mathematics with Applications, V2, DOI 10.1016/0898-1221(76)90003-1; Henry P., 2010, INT S EXP ROB ISER; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Izadi S., 2011, ACM S US INT SOFTW T; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Koppula H., 2011, ADV NEURAL INFORM PR; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Li Z., 2012, IEEE C COMP VIS PATT; Ngiam J., 2011, INT C MACH LEARN; Ren XF, 2012, PROC CVPR IEEE, P2759; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Silberman N., 2011, ICCV WORKSH, P601; Socher R., 2012, ADV NEURAL INFORM PR; Srivastava N., 2012, ADV NEURAL INFORM PR; Stallkamp J., 2011, INT JOINT C NEUR NET, P1453	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200041		
J	Pei, YR; Liu, B; Zha, HB; Han, B; Xu, TM		Burghardt, T; Damen, D; MayolCuevas, W; Mirmehdi, M		Pei, Yuru; Liu, Bin; Zha, Hongbin; Han, Bing; Xu, Tianmin			Anatomical Structure Sketcher for Cephalograms by Bimodal Deep Learning	PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013			English	Proceedings Paper	24th British Machine Vision Conference	SEP 09-13, 2013	Bristol, ENGLAND	Qualcomm, Dyson, Microsoft Res, Inst Engn Technol Journals, HP			CEPHALOMETRIC ANALYSIS; NEURAL-NETWORKS; LANDMARKS; SYSTEM	The lateral cephalogram is a commonly used medium to acquire patient-specific morphology for diagnose and treatment planning in clinical dentistry. The robust anatomical structure detection and accurate annotation remain challenging considering the personal skeletal variations and image blurs caused by device-specific projection magnification, together with structure overlapping in the lateral cephalograms. We propose a novel cephalogram sketcher system, where the contour extraction of anatomical structures is formulated as a cross-modal morphology transfer from regular image patches to arbitrary curves. Specifically, the image patches of structures of interest are located by a hierarchical pictorial model. The automatic contour sketcher converts the image patch to a morphable boundary curve via a bimodal deep Boltzmann machine. The deep machine learns a joint representation of patch textures and contours, and forms a path from one modality (patches) to the other (contours). Thus, the sketcher can infer the contours by alternating Gibbs sampling along the path in a manner similar to the data completion. The proposed method is robust not only to structure detection, but also tends to produce accurate structure shapes and landmarks even in blurry X-ray images. The experiments performed on clinically captured cephalograms demonstrate the effectiveness of our method.	[Pei, Yuru; Liu, Bin; Zha, Hongbin] Peking Univ, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China	Pei, YR (reprint author), Peking Univ, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.	peiyuru@cis.pku.edu.cn; liubin@cis.pku.edu.cn; zha@cis.pku.edu.cn; orthohanks@sina.com; tmxuortho@gmail.com					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; CARDILLO J, 1994, IEEE T MED IMAGING, V13, P275, DOI 10.1109/42.293920; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; Deng L., 2011, P AS PAC SIGN INF PR; Edwards G. J., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670965; Eslami SMA, 2012, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2012.6247702; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Forsyth DB, 1996, EUR J ORTHODONT, V18, P471; Giordano D, 2005, LECT NOTES ARTIF INT, V3581, P333; Grau V, 2001, J BIOMED INFORM, V34, P146, DOI 10.1006/jbin.2001.1014; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Innes A., 2003, P INT C ART INT, V2; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Leonardi R., 2009, J BIOMEDICINE BIOTEC; Luo P, 2012, PROC CVPR IEEE, P2480; Milborrow S., 2008, ECCV; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Ngiam Jiquan, 2012, P 28 INT C MACH LEAR, V11, P1105; Platt J., 1999, ADV LARGE MARGIN CLA, V10, P61; Ren JC, 1998, P ANN INT IEEE EMBS, V20, P723; Saad AA, 2006, ICGST INT J GRAPHICS, V6, P51; Salakhutdinov R., 2010, P INT C ART INT STAT; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Srivastava N., 2012, P ADV NEUR INF PROC, V25, P2231; Tam WK, 2012, P SPIE, V8314; Yang J, 2001, MED BIOL ENG COMPUT, V39, P279, DOI 10.1007/BF02345280; Yue WN, 2006, IEEE T BIO-MED ENG, V53, P1615, DOI 10.1109/TBME.2006.876638	29	0	0	B M V A PRESS	GUILDFORD	49A ELMSIDE ONSLOW VILLAGE, GUILDFORD, SURREY GU2 5SX, ENGLAND							2013										10.5244/C.27.102		12	Computer Science, Artificial Intelligence	Computer Science	BB8CH	WOS:000346352700099		
J	Qi, P; Su, SC; Hu, XL			IEEE	Qi, Peng; Su, Shuochen; Hu, Xiaolin			Modeling Outer Products of Features for Image Classification	2013 SIXTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI)			English	Proceedings Paper	6th International Conference on Advanced Computational Intelligence (ICACI)	OCT 19-21, 2013	Hangzhou, PEOPLES R CHINA	Zhejiang University, Xian Jiaotong Liverpool Univ, Chinese Univ Hong, IEEE Nanjing Sect				Recent studies have shown that sparse coding is an efficient method for feature quantization in image classification tasks. However, sparse coding can only capture linear statistical regularities among the features. In the paper, we show that features can be quantized in a nonlinear way by modeling their outer products. Experiments on some public datasets show that the proposed method can achieve comparable or better results than sparse coding.	[Qi, Peng; Su, Shuochen; Hu, Xiaolin] Tsinghua Univ, Dept Comp Sci & Technol, State Key Lab Intelligent Syst & Technol, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China	Qi, P (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, State Key Lab Intelligent Syst & Technol, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.	xlhu@tsinghua.edu.cn					Coates A., 2011, ICML, V8, P10; Dalal N., 2005, CVPR, V1, P886, DOI DOI 10.1109/CVPR.2005.177; Fei-Fei L., 2004, COMP VIS PATT REC WO, P178; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Karklin Y., 2008, NATURE, V457, P83; Lazebnik S., 2006, CVPR, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Lee H., 2007, ADV NEURAL INFORM PR, V20; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Qi P., 2013, LEARNING NONLI UNPUB; Yang JC, 2009, PROC CVPR IEEE, P1794	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-6343-3				2013							334	338				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BC3MP	WOS:000351734600063		
J	Sazal, MMR; Biswas, SK; Amin, MF; Murase, K			IEEE	Sazal, Md. Musfiqur Rahman; Biswas, Sujan Kumar; Amin, Md. Faijul; Murase, Kazuyuki			Bangla Handwritten Character Recognition Using Deep Belief Network	2013 INTERNATIONAL CONFERENCE ON ELECTRICAL INFORMATION AND COMMUNICATION TECHNOLOGY (EICT)			English	Proceedings Paper	International Conference on Electrical Information and Communication Technology (EICT)	FEB 13-15, 2014	Khulna, BANGLADESH	Fac Elect & Elect Engn, Khulna Univ Engn & Technol, IEEE, Bangladesh EDS SSCS Chapter		Deep belief network; unsupervised feature learning; Bangla handwritten character recognition; supervised learning; backpropagation	NEURAL-NETWORKS	Recognition of Bangla handwritten characters is a difficult but important task for various emerging applications. For better recognition performance, good feature representation of the character images is a primary requirement. In this study, we investigate a recently proposed machine learning approach called deep learning [1] for Bangla hand written character recognition, with a focus on automatic learning of good representations. This approach differs from the traditional methods of preprocessing the characters for constructing the handcrafted features such as loops and strokes. Among different deep learning structures, we employ the deep belief network (DBN) that takes the raw character images as input and learning proceeds in two steps - an unsupervised feature learning followed by a supervised fine tuning of the network parameters. Unlike traditional neural networks, the DBN is a probabilistic generative model, i.e., we can generate samples from the model and it can fit both the semi-supervised and supervised learning settings. We demonstrate the advantages of unsupervised feature learning through the experimental studies carried on the Bangla basic characters and numerals dataset collected from the Indian Statistical Institute.	[Sazal, Md. Musfiqur Rahman; Biswas, Sujan Kumar; Amin, Md. Faijul] Khulna Univ Engn & Technol, Khulna, Bangladesh	Sazal, MMR (reprint author), Khulna Univ Engn & Technol, Khulna, Bangladesh.	musfiqsazal@msdn.net.bd; sujan.kuet@msdn.net.bd; mdfaijulamin@yahoo.com; murase@u-fukui.ac.jp					Alam Fahim Irfan, 2013, P IEEE INT C INF EL, P1; Bhowmik T. K., 2004, NEURAL INFORM PROCES, V3316, P814, DOI 10.1007/978-3-540-30499-9_125; Bhowmik TK, 2009, INT J DOC ANAL RECOG, V12, P97, DOI 10.1007/s10032-009-0084-x; Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253; MATAN O, 1992, COMPUTER, V25, P59, DOI 10.1109/2.144441; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Rahman AFR, 2002, PATTERN RECOGN, V35, P997, DOI 10.1016/S0031-3203(01)00089-9; Raina R., 2007, LEARNING, P759; Rajput G. G., 2013, P INT C VLSI COMM AD, P363; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shaikh S H, 2009, Proceedings of the 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009), DOI 10.1109/NABIC.2009.5393890; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Welling M., 2005, P 2005 C NEUR INF PR, P1481; Yuan AQ, 2012, INT CONF FRONT HAND, P207, DOI 10.1109/ICFHR.2012.210	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2299-4				2013												5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BB2SH	WOS:000342218600097		
S	Shou, Z; Zhang, YH; Cai, HJ			IEEE	Shou, Zheng; Zhang, Yuhao; Cai, H. J.			A Study of Transformation-invariances of Deep Belief Networks	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc			BOLTZMANN MACHINES; IMAGES	In order to learn transformation-invariant features, several effective deep architectures like hierarchical feature learning and variant Deep Belief Networks (DBN) have been proposed. Considering the complexity of those variants, people are interested in whether DBN itself has transformation-invariances. First of all, we use original DBN to test original data. Almost same error rates will be achieved, if we change weights in the bottom interlayer according to transformations occurred in testing data. It implies that weights in the bottom interlayer can store the knowledge to handle transformations such as rotation, shifting, and scaling. Along with the continuous learning ability and good storage of DBN, we present our Weight-Transformed Training Algorithm (WTTA) without augmenting other layers, units or filters to original DBN. Based upon original training method, WTTA is aiming at transforming weights and is still unsupervised. For MNIST handwritten digits recognizing experiments, we adopted 784-100-100-100 DBN to compare the differences of recognizing ability in weights-transformed ranges. Most error rates generated by WTTA were below 25% while most rates generated by original training algorithm exceeded 25%. Then we also did an experiment on part of MIT-CBCL face database, with varying illumination, and the best testing accuracy can be achieved is 87.5%. Besides, similar results can be achieved by datasets covering all kinds of transformations, but WTTA only needs original training data and transform weights after each training loop. Consequently, we can mine inherent transformation-invariances of DBN by WTTA, and DBN itself can recognize transformed data at satisfying error rates without inserting other components.	[Shou, Zheng; Zhang, Yuhao; Cai, H. J.] Wuhan Univ, Int Sch Software, Wuhan 430070, Hubei, Peoples R China	Cai, HJ (reprint author), Wuhan Univ, Int Sch Software, Wuhan 430070, Hubei, Peoples R China.	zhengshou@whu.edu.cn; stevenzhang027@gmail.com; hjcai@whu.edu.cn					Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Azzopardi George, 2013, IEEE T PATTERN ANAL, V35; Bauer Felix, 2013, INT C LEARN REPR SCO; Bengio Yoshua, 1312 U MONTR; Berry J, 2011, INT CONF ACOUST SPEE, P557; Hinton G. E., TRENDS COGNITIVE SCI, V11, P428; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Kivinen JJ, 2011, LECT NOTES COMPUT SC, V6791, P1; Larochelle H., 2007, P 24 INT C MACH LEAR, V227, P473; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; LeCun Y., MNIST DATABASE HANDW; LeCun Yann, 2012, P EUR C COMP VIS WOR, P496; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Memisevic Roland, 2007, P IEEE COMP SOC C CO; Ranzato Marc'Aurelio, 2007, P IEEE COMP SOC C CO; SMITH PR, 1981, ULTRAMICROSCOPY, V6, P201, DOI 10.1016/0304-3991(81)90061-9; Weyrauch B., 2004, P IEEE COMP SOC C VI, V5	22	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200177		
S	Solgi, M; Weng, JY			IEEE	Solgi, Mojtaba; Weng, Juyang			Stereo Where-What Networks: Unsupervised Binocular Feature Learning	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc			CATS STRIATE CORTEX; RECEPTIVE-FIELDS; VISUAL-CORTEX; COMPONENT ANALYSIS; DISPARITY; PHASE; ALGORITHM; COLOR	Unsupervised feature learning has been shown promising in the field of machine learning. However, the learning algorithms used in these methods, e.g., Deep Belief Networks based on Restricted Boltzman Machines, are typically restricted in different ways, e. g., hard to train and calculate the partition function [1]. In this article, we present a cortexinspired learning network, Where-What Networks (WWN), for the problem of unsupervised learning of binocular local features. The results show that the learned features autonomously developed selectivity for disparity, profile and location of the input patterns. We present a novel algorithm, Dynamic Synapse Lobe Component Analysis (DSLCA), which not only resembles the pattern of neural connections in the visual cortex, but also results in the autonomous development of "domain disparity". To our knowledge, this work is the first to introduce unsupervised learning of both domain and weight disparities between left and right local receptive fields. Moreover, given the theoretical optimality of WWNs [2] and their empirically proven strength in supervised learning, the presented work is the first step towards creating a semi-supervised learning network for simultaneous type, location (including distance) and 3D shape perception.	[Solgi, Mojtaba; Weng, Juyang] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Solgi, M (reprint author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	solgi@cse.msu.edu; weng@cse.msu.edu					Anzai A, 1999, J NEUROPHYSIOL, V82, P874; Blakemore H., 1967, J PHYSL, V193, P327; DEANGELIS GC, 1993, J NEUROPHYSIOL, V69, P1091; DEVALOIS RL, 1982, VISION RES, V22, P531, DOI 10.1016/0042-6989(82)90112-2; Dhond U.R., 1989, SYST MAN CYBERN IEEE, V19, P1489; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; FLEET DJ, 1991, CVGIP-IMAG UNDERSTAN, V53, P198, DOI 10.1016/1049-9660(91)90027-M; Franz A., 2007, IEEE 6 INT C DEV LEA, P31; Grimson W. E. L., 1981, IMAGES SURFACES COMP; Grimson W. E. L., 1979, P IM UND WORKSH, P41; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoyer PO, 2000, NETWORK-COMP NEURAL, V11, P191, DOI 10.1088/0954-898X/11/3/302; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Ji Z., 2008, P IEEE INT C DEV LEA; Lippert J, 2000, BIOL CYBERN, V83, P61, DOI 10.1007/s004220000146; LIVINGSTONE MS, 1984, J NEUROSCI, V4, P309; Luciw M., 2010, P IJCNN IN PRESS; OHZAWA I, 1990, SCIENCE, V249, P1037, DOI 10.1126/science.2396096; PETTIGRE.JD, 1968, EXP BRAIN RES, V6, P391; POGGIO GF, 1977, J NEUROPHYSIOL, V40, P1392; Read JCA, 2007, NAT NEUROSCI, V10, P1322, DOI 10.1038/nn1951; Solgi M., 2010, IEEE T AUTON MENT DE, V1, P238; Wang Y., 2011, P INT JOINT C NEUR N, P2823; Weng J., 2010, P INT JOINT C NEUR N, P1; Weng J., 2006, P WORLD C COMP INT V; WENG J, 1993, INT J COMPUT VISION, V11, P211, DOI 10.1007/BF01469343; Weng JY, 2009, IEEE T AUTON MENT DE, V1, P68, DOI 10.1109/TAMD.2009.2021698; Werth P, 1999, LECT NOTES COMPUT SC, V1689, P641; Wiemer T. B. J., 2000, BIOL CYBERN, V82, P97; Zikidis KC, 1996, FUZZY SET SYST, V83, P63, DOI 10.1016/0165-0114(95)00296-0; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184	31	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200141		
S	Sun, YY; Bo, LF; Fox, D			IEEE	Sun, Yuyin; Bo, Liefeng; Fox, Dieter			Attribute Based Object Identification	2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation (ICRA)	MAY 06-10, 2013	Karlsruhe, GERMANY	IEEE			ALGORITHM	Over the last years, the robotics community has made substantial progress in detection and 3D pose estimation of known and unknown objects. However, the question of how to identify objects based on language descriptions has not been investigated in detail. While the computer vision community recently started to investigate the use of attributes for object recognition, these approaches do not consider the task settings typically observed in robotics, where a combination of appearance attributes and object names might be used in referral language to identify specific objects in a scene. In this paper, we introduce an approach for identifying objects based on natural language containing appearance and name attributes. To learn rich RGB-D features needed for attribute classification, we extend recently introduced sparse coding techniques so as to automatically learn attribute-dependent features. We introduce a large data set of attribute descriptions of objects in the RGB-D object dataset. Experiments on this data set demonstrate the strong performance of our approach to language based object identification. We also show that our attribute-dependent features provide significantly better generalization to previously unseen attribute values, thereby enabling more rapid learning of new attribute values.	[Sun, Yuyin; Fox, Dieter] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Sun, YY (reprint author), Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.	sunyuyin@cs.washington.edu; liefeng.bo@intel.com; fox@cs.washington.edu					Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Berg A.C., 2009, IEEE INT C COMP VIS; Blum M., 2012, IEEE INT C ROB AUT; Bo L., 2012, INT S EXP ROB; Bo L., 2011, ADV NEURAL INFORM PR; Bo L., 2011, IEEE RSJ INT C INT R; Chen X., 2009, IEEE INT C DAT MIN; Dalal Navneet, 2005, IEEE INT C COMP VIS; Dale A., 1995, CONGNITIVE SCI, V18, P233; Duan K., 2012, IEEE C COMP VIS PATT; Farhadi A., 2009, IEEE INT C COMP VIS; Fellbaum C., 1998, WORDNET ELECT LEXICA; Ferrari V., 2007, ADV NEURAL INFORM PR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holzer S., 2011, IEEE INT C COMP VIS; Kwiatkowski T., 2010, EMPIRICAL METHODS NA; Lai K., 2011, IEEE INT C ROB AUT; Lai K., 2011, AAAI C ART INT; Lampert C.H., 2009, IEEE INT C COMP VIS; Liu J., 2009, SLEP SPARSE LEARNING; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matuszek C., 2012, INT C MACH LEARN; Obozinski G, 2010, STAT COMPUT, V20, P231, DOI 10.1007/s11222-008-9111-x; Parikh D., 2011, IEEE INT C COMP VIS; Toutanova K., 2000, JOINT SIGD C EMP MET; Yu K., 2011, IEEE C COMP VIS PATT	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729		978-1-4673-5641-1; 978-1-4673-5643-5	IEEE INT CONF ROBOT			2013							2096	2103				8	Automation & Control Systems; Engineering, Electrical & Electronic; Robotics	Automation & Control Systems; Engineering; Robotics	BA7KQ	WOS:000337617302016		
J	Tanaka, K; Hotta, S			IEEE	Tanaka, Kouta; Hotta, Seiji			Local Subspace Classifier with Gabor Filter Decomposition for Image Classification	2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013)			English	Proceedings Paper	2nd IAPR Asian Conference on Pattern Recognition (ACPR)	NOV 05-08, 2013	Naha, JAPAN	Int Assoc Pattern Recognit, IEEE, IEEE Comp Soc, KDDI Fdn, Support Ctr Adv Telecommunicat Technol Res, Pattern Recognit & Media Understanding, IEICE ISS, Comp Vis & Image Media, IPSJ, IEEE Comp Soc Fukuoka Chapter		Image classification; Gabor filter; Local subspace classifar		This paper presents a local subspace classifier (LSC) with Gabor filter decomposition for image classification. In our method, first, the training images are decomposed into different directions by Gabor filters. By the same way as training images, an input image is decomposed into different directions with Gabor filters. After this, LSC is applied to each direction domain independently. The total sum of distances calculated from each direction is used for final classification. This method may be simple but we can improve accuracy by it. Experimental results on modified USPS, CIFAR-10, and SVI-IN datasets show that Gabor decomposition is effective for improving image classification accuracy of LSC.	[Tanaka, Kouta; Hotta, Seiji] Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, Koganei, Tokyo 1848588, Japan	Tanaka, K (reprint author), Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, 2-24-16 Naka Cho, Koganei, Tokyo 1848588, Japan.	triangle_hty@yahoo.co.jp; s-hotta@cc.tuat.ac.jp					Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Duda R, 2001, PATTERN CLASSIFICATI; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hotta K, 2004, IEEE IMAGE PROC, P597; Laaksonen J., 1997, THESIS HELSINKI U TE; Laaksonen J., 1997, P INT C ART NEUR NET, P637; Lee H., 2006, NIPS; Netzer Y., 2011, NIPS WORKSH DEEP LEA; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Snoek J., 2012, NIPS; Wan L, 2013, INT C MACH LEARN	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-1-4799-2190-4				2013							823	827		10.1109/ACPR.2013.149		5	Computer Science, Artificial Intelligence	Computer Science	BA9KJ	WOS:000339501000170		
J	Toth, L			IEEE	Toth, Laszlo			PHONE RECOGNITION WITH DEEP SPARSE RECTIFIER NEURAL NETWORKS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Deep neural networks; sparse rectifier neural networks; phone recognition		Rectifier neurons differ from standard ones only in that the sigmoid activation function is replaced by the rectifier function, max(0, x). This modification requires only minimal changes to any existing neural net implementation, but makes it more effective. In particular, we show that a deep architecture of rectifier neurons can attain the same recognition accuracy as deep neural networks, but without the need for pre-training. With 4-5 hidden layers of rectifier neurons we report 20.8% and 19.8% phone error rates on TIMIT (with CI and CD units, respectively), which are competitive with the best results on this database.	Hungarian Acad Sci, MTA SZTE Res Grp Artificial Intelligence, H-1051 Budapest, Hungary	Toth, L (reprint author), Hungarian Acad Sci, MTA SZTE Res Grp Artificial Intelligence, H-1051 Budapest, Hungary.	tothl@inf.u-szeged.hu					Bishop C.M., 1995, NEURAL NETWORKS PATT; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Dahl G., 2010, NIPS, V23, P469; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Glorot X., 2010, P AISTATS, V9, P249; Glorot X., 2011, P AISTATS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ly D. L., 2009, TECHNICAL REPORT; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed AR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4273; Nair V., 2010, P 27 INT C MACH LEAR, P807; Plahl C, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4165; Seide F., 2011, P ASRU, P24; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Vinyals O., 2012, P INTERSPEECH; Yu D, 2010, NIPS 2010 WORKSH DEE	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							6985	6989				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507029		
S	Toth, L; Grosz, T		Habernal, I; Matousek, V		Toth, Laszlo; Grosz, Tamas			A Comparison of Deep Neural Network Training Methods for Large Vocabulary Speech Recognition	TEXT, SPEECH, AND DIALOGUE, TSD 2013	Lecture Notes in Computer Science		English	Proceedings Paper	16th International Conference on Text, Speech, and Dialogue (TSD)	SEP 01-05, 2013	Pilsen, CZECH REPUBLIC	Int Speech Commun Assoc, Czech Soc Cybernet & Informat, Univ W Bohemia, Fac Appl Sci, Masaryk Univ, Fac Informat		deep neural networks; TIMIT; LVCSR		The introduction of deep neural networks to acoustic modelling has brought significant improvements in speech recognition accuracy. However, this technology has huge computational costs, even when the algorithms are implemented on graphic processors. Hence, finding the right training algorithm that offers the best performance with the lowest training time is now an active area of research. Here, we compare three methods; namely, the unsupervised pre-training algorithm of Hinton et al., a supervised pre-training method that constructs the network layer-by-layer, and deep rectifier networks, which differ from standard nets in their activation function. We find that the three methods can achieve a similar recognition performance, but have quite different training times. Overall, for the large vocabulary speech recognition task we study here, deep rectifier networks offer the best tradeoff between accuracy and training time.	[Toth, Laszlo] Hungarian Acad Sci, MTA SZTE Res Grp Artificial Intelligence, H-1051 Budapest, Hungary	Toth, L (reprint author), Hungarian Acad Sci, MTA SZTE Res Grp Artificial Intelligence, H-1051 Budapest, Hungary.	tothl@inf.u-szeged.hu; groszt@sol.cc.u-szeged.hu					Abari K., 2006, P MSZNY, P223; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Glorot X., 2010, P AISTATS, P249; Glorot Xavier, 2011, P AISTATS, P315; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2012, TECHNICAL REPORT; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2010, P 27 INT C MACH LEAR, P807; Seide F., 2011, P ASRU, P24; Toth L., 2013, P ICASSP IN PRESS; Young S., 2005, HTK BOOK	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-40584-6; 978-3-642-40585-3	LECT NOTES COMPUT SC			2013	8082						36	43				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BA6WK	WOS:000337294900006		
J	Verma, NK; Gupta, VK; Sharma, M; Sevakula, RK			IEEE	Verma, Nishchal K.; Gupta, Vishal Kwnar; Sharma, Mayank; Sevakula, Rahul Kumar			Intelligent Condition Based Monitoring of Rotating Machines using Sparse Auto-encoders	2013 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT			English	Proceedings Paper	IEEE International Conference on Prognostics and Health Management (PHM)	JUN 24-27, 2013	Gaithersburg, MD	IEEE, Reliabil Soc		sparse autoencoders; support vector machines; mahalanobis distance; feature extraction; feature selection	NETWORKS	Support Vector Machine (SVM) has been very popular for use in machine fault diagnosis as classifier. In most of the complex machine learning problems, the main challenge lies in finding good features. Sparse autoencoders have the ability to learn good features from the input data in an unsuperivised fashion. Sparse auto-encoders and other deep architectures are already showing very good results in text classification, speaker and speech recognition and face recognition as well. In this paper, we compare the performance of sparse autoencoders with soft max regression, fast classifier based on Mahalanobis distance and SVM in fault diagnosis of air compressors.	[Verma, Nishchal K.; Gupta, Vishal Kwnar; Sevakula, Rahul Kumar] IIT Kanpur, Dept Elect Engn, Kanpur, Uttar Pradesh, India	Verma, NK (reprint author), IIT Kanpur, Dept Elect Engn, Kanpur, Uttar Pradesh, India.	nishchal@iitk.ac.in; vishalkg@iitk.ac.in; mayank.sharma@iitkgp.ac.in; srahulk@iitk.ac.in					Bengio Y., 2007, ADV NEURAL INFORM PR, V19; Bengio Y., 2007, LARGE SCALE KERNEL M, V34; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Yoshua, 2010, P AISTATS 2010 CHIN, P249; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Duan K., 2003, MULTIPLE CLASSIFIER, P160; Glorot X., 2011, JMLR W CP P 14 INT C; Hinton G., 2000, 2007 NIPS TUTORIAL D; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Luo W., 2006, P CHINESE SOC ELECT, P164; MarcAurelio Ranzato Y., 2007, ADV NEURAL INFORM PR, V20, P1185; McLachlan G.-J., 1999, RESONANCE, V4, P20, DOI 10.1007/BF02834632; Ng A., 2011, LECT NOTES SPARSE AU; Ranzato Y., 2007, J MACHINE LEARNING R, V2, P371; Roy Abhishek, 2011, IEEE INT C SYST ENG, P65; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schimdt M., 2012, MINFUNC; Shen N. E., 1998, P ROYAL SOC LONDON, V454, P903; Singh S., 2012, 6 IEEE INT C SENS TE; Song F., 2010, INF SCI ENG ISISE 20, P255; Suykens K., 2002, LS SVMLAB MATLAB C T, P6; Vincent P., 2008, EXTRACTING COMPOSING; Yang P. W., 2004, J SOUND VIBRATION, V227, P1005	24	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-5722-7				2013												7	Computer Science, Information Systems; Medical Informatics	Computer Science; Medical Informatics	BA1FZ	WOS:000332461600039		
J	Vesely, K; Hannemann, M; Burget, L			IEEE	Vesely, Karel; Hannemann, Mirko; Burget, Lukas			SEMI-SUPERVISED TRAINING OF DEEP NEURAL NETWORKS	2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU)			English	Proceedings Paper	IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)	DEC 08-13, 2013	Olomouc, CZECH REPUBLIC	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		semi-supervised training; self-training; deep network; DNN; Babel program		In this paper we search for an optimal strategy for semi-supervised Deep Neural Network (DNN) training. We assume that a small part of the data is transcribed, while the majority of the data is untranscribed. We explore self-training strategies with data selection based on both the utterance-level and frame-level confidences. Further on, we study the interactions between semi-supervised frame-discriminative training and sequence-discriminative sMBR training. We found it beneficial to reduce the disproportion in amounts of transcribed and untranscribed data by including the transcribed data several times, as well as to do a frame-selection based on per-frame confidences derived from confusion in a lattice. For the experiments, we used the Limited language pack condition for the Surprise language task (Vietnamese) from the IARPA Babel program. The absolute Word Error Rate (WER) improvement for frame cross-entropy training is 2.2%, this corresponds to WER recovery of 36% when compared to the identical system, where the DNN is built on the fully transcribed data.	[Vesely, Karel; Hannemann, Mirko; Burget, Lukas] Brno Univ Technol, Speech FIT & IT4I Ctr Excellence, CS-61090 Brno, Czech Republic	Vesely, K (reprint author), Brno Univ Technol, Speech FIT & IT4I Ctr Excellence, CS-61090 Brno, Czech Republic.						Bourlard Ha, 1994, CONNECTIONIST SPEECH; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Gibson M., 2006, P INTERSPEECH; Grandvalet Y., 2004, P NIPS; Grezl F., 2013, P ASRU; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsiao R., 2013, P ASRU; Huang JT, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1353; Huang Y., 2013, P INTERSPEECH; Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445; Malkin J., 2009, P INTERSPEECH, P660; Mohamed A. R., 2011, P IEEE ICASSP; Ng T., 2012, P INTERSPEECH; Novotney S, 2009, INT CONF ACOUST SPEE, P4297, DOI 10.1109/ICASSP.2009.4960579; Novotney S., 2009, P INTERSPEECH, P244; Povey D., 2011, P IEEE ASRU; POVEY D, 2006, P INTERSPEECH; Sainath T.N., 2011, P ASRU, P30; Seide F., 2011, P INTERSPEECH; Swietojanski P, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P246, DOI 10.1109/SLT.2012.6424230; Swietojanski P., 2013, P IEEE ICASSP; Talkin D., 1995, SPEECH CODING SYNTHE; Vesely K., 2013, P INTERSPEECH 2013; Xu HH, 2010, INT CONF ACOUST SPEE, P4938, DOI 10.1109/ICASSP.2010.5495100; Yu D, 2010, COMPUT SPEECH LANG, V24, P433, DOI 10.1016/j.csl.2009.03.004; Yu D., 2010, P NIPS	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2756-2				2013							267	272				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BA4DR	WOS:000335410800046		
S	Wagner, R; Thom, M; Schweiger, R; Palm, G; Rothermel, A			IEEE	Wagner, Raimar; Thom, Markus; Schweiger, Roland; Palm, Guenther; Rothermel, Albrecht			Learning Convolutional Neural Networks From Few Samples	2013 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	AUG 04-09, 2013	Dallas, TX	Int Neural Network Soc, IEEE Computat Intelligence Soc			RECEPTIVE FIELDS; DEEP; CORTEX; NETS	Learning Convolutional Neural Networks (CNN) is commonly carried out by plain supervised gradient descent. With sufficient training data, this leads to very competitive results for visual recognition tasks when starting from a random initialization. When the amount of labeled data is limited, CNNs reveal their strong dependence on large amounts of training data. However, recent results have shown that a well chosen optimization starting point can be beneficial for convergence to a good generalizing minimum. This starting point was mostly found using unsupervised feature learning techniques such as sparse coding or transfer learning from related recognition tasks. In this work, we compare these two approaches against a simple patch based initialization scheme and a random initialization of the weights. We show that pre-training helps to train CNNs from few samples and that the correct choice of the initialization scheme can push the network's performance by up to 41% compared to random initialization.	[Wagner, Raimar; Rothermel, Albrecht] Univ Ulm, DriveU Inst Microelect, D-89069 Ulm, Germany; [Thom, Markus] Univ Ulm, DriveU Inst Measurement Control & Microtechnol, D-89069 Ulm, Germany; [Palm, Guenther] Univ Ulm, Inst Neural Informat Proc, D-89069 Ulm, Germany; [Schweiger, Roland] Daimler AG, Ulm, Germany	Wagner, R (reprint author), Univ Ulm, DriveU Inst Microelect, D-89069 Ulm, Germany.	raimar.wagner@uni-ulm.de; markus.thom@uni-ulm.de; roland.schweiger@daimler.com; guenther.palm@uni-ulm.de; albrecht.rothermel@uni-ulm.de					Ahmed A., 2008, P ECCV; Bengio Y., 2007, P NIPS; Bishop C.M., 1995, NEURAL NETWORKS PATT; Ciresan D., 2011, P IJCNN; Ciresan D., 2012, P IJCNN; Coates A., 2011, P ICML; DENOEUX T, 1993, NEURAL NETWORKS, V6, P351, DOI 10.1016/0893-6080(93)90003-F; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gutstein S, 2008, INT J ARTIF INTELL T, V17, P555, DOI 10.1142/S0218213008004059; Hinton G., 2006, SCIENCE, V313, P1527; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Hyvarinen A, 2009, NATURAL IMAGE STAT P; Jarrett K., 2009, P ICCV; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Krizhevsky A., 2012, P NIPS; Le Q., 2010, P NIPS; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; LeCun Y., 1998, MNIST DATABASE HANDW; LeCun Y., 2004, P CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lennie P, 2003, CURR BIOL, V13, P493, DOI 10.1016/S0960-9822(03)00135-0; Levy WB, 1996, NEURAL COMPUT, V8, P531, DOI 10.1162/neco.1996.8.3.531; Masci J., 2011, P ICANN; Nguyen G., 2009, P ICITA; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; Raina R., 2007, P ICML; Ranzato M., 2006, P NIPS; Ranzato M., 2007, P CVPR; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Scherer D., 2010, P ICANN; Simard P. Y., 2003, P ICDAR; Thom M., 2011, P IJCNN; Thrun S., 1996, P NIPS; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vincent P, 2010, J MACH LEARN RES, V11, P3371	39	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-4673-6129-3; 978-1-4673-6128-6	IEEE IJCNN			2013												7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BC0TZ	WOS:000349557200262		
S	Wang, T; Iqbal, MS; Silver, DL		Ciucci, D; Inuiguchi, M; Yao, Y; Slezak, D; Wang, G		Wang, Ti; Iqbal, Mohammed Shameer; Silver, Daniel L.			An Unsupervised Deep-Learning Architecture That Can Reconstruct Paired Images	ROUGH SETS, FUZZY SETS, DATA MINING, AND GRANULAR COMPUTING	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	14th Rough Sets, Fuzzy Sets, Data Mining and Granular Computing (RSFDGrC)	OCT 11-14, 2013	Halifax, CANADA					This paper presents an unsupervised learning system that develops an associative memory structure that combines two or more channels of input/output such that input on one channel will correctly generate the associated response at the other channel and vice versa. A deep learning architecture is described that can reconstruct an image of a MNIST handwritten digit from another paired handwritten digit image. In this way, the system develops a kind of supervised classification model meant to simulate aspects of human associative memory. The system uses stacked layers of unsupervised Restricted Boltzmann Machines connected by a hybrid associative-supervised top layer to ensure the development of a set of high-level features that can reconstruct one image given another in either direction. Experimentation shows that the system reconstructs accurate matching paired-images that compares favourably to a back-propagation network solution.	[Wang, Ti; Iqbal, Mohammed Shameer; Silver, Daniel L.] Acadia Univ, Jodrey Sch Comp Sci, Wolfville, NS B4P 2R6, Canada	Wang, T (reprint author), Acadia Univ, Jodrey Sch Comp Sci, Wolfville, NS B4P 2R6, Canada.	danny.silver@acadiau.ca					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1986, LEARNING RELEARNING, V1, P282; Ngiam J., 2011, ICML, P689; Rosenzweig M.R., 1984, AM PSYCHOL, V39; Serre T, 2007, PROG BRAIN RES, V165, P33, DOI 10.1016/S0079-6123(06)65004-8; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2231	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-41218-9; 978-3-642-41217-2	LECT NOTES ARTIF INT			2013	8170						388	396				9	Computer Science, Artificial Intelligence	Computer Science	BB5HN	WOS:000343874800042		
J	Wang, ZH; Li, YQ; Wang, SF; Ji, Q			IEEE	Wang, Ziheng; Li, Yongqiang; Wang, Shangfei; Ji, Qiang			Capturing Global Semantic Relationships for Facial Action Unit Recognition	2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	DEC 01-08, 2013	Sydney, AUSTRALIA	IEEE, CVF, IEEE Comp Soc, APRS, Australiasn Natl Univ, NICTA, FACE++, Natl Robot Engn Ctr, Google, Disney Res, nVIDIA, Raytheon BBN Technologies, Facebook, Adobe, Kitware, OMRON, SRI Int			EXPRESSION ANALYSIS	In this paper we tackle the problem of facial action unit (AU) recognition by exploiting the complex semantic relationships among AUs, which carry crucial top-down information yet have not been thoroughly exploited. Towards this goal, we build a hierarchical model that combines the bottom-level image features and the top-level AU relationships to jointly recognize AUs in a principled manner. The proposed model has two major advantages over existing methods. 1) Unlike methods that can only capture local pair-wise AU dependencies, our model is developed upon the restricted Boltzmann machine and therefore can exploit the global relationships among AUs. 2) Although AU relationships are influenced by many related factors such as facial expressions, these factors are generally ignored by the current methods. Our model, however, can successfully capture them to more accurately characterize the AU relationships. Efficient learning and inference algorithms of the proposed model are also developed. Experimental results on benchmark databases demonstrate the effectiveness of the proposed approach in modelling complex AU relationships as well as its superior AU recognition performance over existing approaches.	[Wang, Ziheng; Ji, Qiang] Rensselaer Polytech Inst, ECSE Dept, Troy, NY 12181 USA; [Li, Yongqiang] Harbin Inst Technol, Sch Elect Engn & Automat, Harbin 150006, Peoples R China; [Wang, Shangfei] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei, Peoples R China	Wang, ZH (reprint author), Rensselaer Polytech Inst, ECSE Dept, Troy, NY 12181 USA.	wangz10@rpi.edu; liy23@rpi.edu; sfwang@ustc.edu.cn; jiq@rpi.edu					Bartlett MS, 2005, PROC CVPR IEEE, P568; Bazzo J., 2004, AUT FAC GEST REC 200, P505; Cootes T., PATTERN ANAL MACHINE, V23, P681; Ekman P., 1978, FACIAL ACTION CODING; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jiang B., 2011, AUT FAC GEST REC WOR, P314; Kanade T., 2000, AUTOMATIC FACE GESTU, P46; Li Y., 2013, IMAGE PROCESSING IEE; Lien J.-J. J., 1999, J ROBOTICS AUTONOMOU; Lucey P., 2010, CVPR WORKSH; Mahoor M. H., 2011, AUT FAC GEST REC WOR, P336; McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931; Pantic M., 2005, MULT EXP IEEE INT C; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Susskind Joshua M., 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Tong Y., 2008, CVPR 2008, P1; Valstar M., 2011, AUT FAC GEST REC WOR, P921; Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710; Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042; Whitehill J., 2006, AUT FAC GEST REC 7 I, P97	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-5499		978-1-4799-2839-2	IEEE I CONF COMP VIS			2013							3304	3311		10.1109/ICCV.2013.410		8	Computer Science, Artificial Intelligence	Computer Science	BC3PE	WOS:000351830500413		
J	Xu, Y; Xiang, SM; Huo, CL; Pan, CH		Cao, Z		Xu, Yuan; Xiang, Shiming; Huo, Chunlei; Pan, Chunhong			Change Detection Based on Auto-encoder Model for VHR Images	MIPPR 2013: PATTERN RECOGNITION AND COMPUTER VISION	Proceedings of SPIE		English	Proceedings Paper	8th Symposium on Multispectral Image Processing and Pattern Recognition (MIPPR) - Pattern Recognition and Computer Vision	OCT 26-27, 2013	Wuhan, PEOPLES R CHINA	Huazhong Univ Sci & Technol, Natl Key Lab Sci & Technol Multi Spectral Informat Proc, SPIE		Change detection; deep learning; Auto-encoder Model; VHR image; multi-temporal images; unsupervised		Change detection of VHR (Very High Resolution) images is very difficult due to the impacts caused by the seasonal changes, the imaging condition, and so on. To address the above difficulty, a novel unsupervised change detection algorithm is proposed based on deep learning, where the complex correspondence between the images is established by Auto-encoder Model. By taking advantages of the powerful ability of deep learning in compensating the impacts implicitly, the multi-temporal images can be compared fairly. Experiments demonstrate the effectiveness of the proposed approach.	[Xu, Yuan; Xiang, Shiming; Huo, Chunlei; Pan, Chunhong] Chinese Acad Sci, Inst Automat, NLPR, Beijing 100864, Peoples R China	Xu, Y (reprint author), Chinese Acad Sci, Inst Automat, NLPR, Beijing 100864, Peoples R China.	yxu@nlpr.ia.ac.cn; smxiang@nlpr.ia.ac.cn; clhuo@nlpr.ia.ac.cn; chpan@nlpr.ia.ac.cn					Allen TR, 2000, REMOTE SENS ENVIRON, V74, P482, DOI 10.1016/S0034-4257(00)00140-1; Falco N., 2012, IEEE GEOSCI REMOTE S, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Lange S., 2010, NEURAL NETWORKS, P18; Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863; Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195; Otsu N., 1975, AUTOMATICA, P23; Roux N. L., 2010, NEURAL COMPUT, V23, P593; SINGH A, 1989, INT J REMOTE SENS, V10, P989; Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013; Wang N., 2012, EUR S ART NEUR NETW, P287	12	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-9804-5	PROC SPIE			2013	8919								UNSP 891902	10.1117/12.2031104		7	Computer Science, Artificial Intelligence; Optics	Computer Science; Optics	BIC81	WOS:000327427100002		
J	Yanagimoto, H; Shimada, M; Yoshimura, A		Matsuo, T; Ishii, N; Lee, R		Yanagimoto, Hidekazu; Shimada, Mika; Yoshimura, Akane			Document Similarity Estimation for Sentiment Analysis Using Neural Network	2013 IEEE/ACIS 12TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS)			English	Proceedings Paper	IEEE/ACIS 12th International Conference on Computer and Information Science (ICIS)	AUG 16-20, 2010	Niigata, JAPAN	Inst Elect & Elect Engineers, Int Assoc Comp & Informat Sci, IEEE Comp Soc			MODEL; NETS	It is important to classify documents according to their contents because of finding necessary documents efficiently. To achieve good classification document similarity estimation is one of key techniques since classification is executed based on the document similarity. In natural language processing bag-of-words model is used to extract features from documents and term occurrence frequency based value is used as a weight of each features. However, the term weight methodologies usually use predefined models and include some limitations. New approaches to construct feature vectors based on data distribution are desired to achieve high performance of natural language processing. These days many researchers pay attention to deep learning. Deep learning is a new approach to transform raw data to feature vectors using many unlabeled data. This characteristics is desirable to satisfy a previous need. In natural language processing a main aim is to construct a language model on a deep architecture neural network. In this paper we use a deep architecture neural network to estimate document similarity. To obtain good article similarity estimation we have to generate good article vectors that can represent all article characteristics. Hence, we use many stock market news to train the deep architecture neural network and generate article vectors with the trained neural network. And we calculate cosine similarity between labeled articles and discuss performance of the deep architecture neural network. In evaluation we do not focus on articles' contents but on their sentiment polarity. Hence, we discuss whether the proposed method classifies articles according to their sentiment polarity or not. We confirmed though the proposed method is an unsupervised learning approach, it achieves good performance in stock market news similarity estimation. The results show a deep architecture neural network can be applied to more natural language processing tasks.	[Yanagimoto, Hidekazu; Shimada, Mika; Yoshimura, Akane] Osaka Prefecture Univ, Sch Engn, Osaka 5998531, Japan	Yanagimoto, H (reprint author), Osaka Prefecture Univ, Sch Engn, Osaka 5998531, Japan.	hidekazu@cs.osakafu-u.ac.jp; shimada@sig.cs.osakafu-u.ac.jp; yoshimura@sig.cs.osakafu-u.ac.jp					Arisoy E., 2012, P NAACL HLT 2012 WOR, P20; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Blei D. M., 2003, J MACH LEARN RES, V3, P933; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094; Hofmann T, 2000, ADV NEUR IN, V12, P914; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25; Lee H., 2006, ADV NEURAL INFORM PR, V19, P801; Lee Q. V, 2012, P 29 INT C MACH LEAR; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Robertson S.E., 1994, P 3 TEXT RETRIEVAL C; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shoelkopf B., 2001, LEARNING KERNELS SUP; Jones K. S., 1972, Journal of Documentation, V28, DOI 10.1108/eb026526	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-1-4799-0174-6				2013							105	110				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BA4CI	WOS:000335328200020		
J	You, Z; Wang, XR; Xu, B			IEEE	You, Zhao; Wang, Xiaorui; Xu, Bo			INVESTIGATION OF DEEP BOLTZMANN MACHINES FOR PHONE RECOGNITION	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		phone recognition; acoustic modeling; Deep Boltzmann Machines; Deep Neural Networks		In the past few years, deep neural networks (DNNs) achieved great successes in speech recognition. The layer-wise pre-trained deep belief network (DBN) is known as one of the critical factor to optimize the DNN. However, the DBN has one shortcoming that the pre-training procedure is in a greedy forward pass. The top-down influences on the inference process are ignored, thus the pre-trained DBN is suboptimal. In this paper, we attempt to apply deep Boltzmann machine (DBM) on acoustic modeling. DBM has the advantages that a top-down feedback is incorporated and the parameters of all layers can be jointly optimized. Experiments are conducted on the TIMIT phone recognition task to investigate the DBM-DNN acoustic model. Comparing with the DBN-DNN with same amount of parameters, phone error rate on the core test set is reduced by 3.8% relatively, and additional 5.1% by dropout fine-tuning.	[You, Zhao; Wang, Xiaorui; Xu, Bo] Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr, Beijing, Peoples R China	You, Z (reprint author), Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr, Beijing, Peoples R China.	zhao.you@ia.ac.cn; xiaorui.wang@ia.ac.cn; xubo@ia.ac.cn					Cho K, 2011, LECT NOTES COMPUT SC, V6791, P10; Hinton G. E., 2012, CORR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Sainath T. N., 2011, ASRU, P30; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Salakhutdinov R., 2009, JMLR W CP AISTATS 20, V5, P448; Salakhutdinov Ruslan, 2010, JMLR, V9, P693; Seide F., 2011, INTERSPEECH, P437; Zhang YD, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5161	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							7600	7603				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507154		
J	Yu, H; Hong, RX; Huang, XL; Wang, ZY			IEEE	Yu, Hong; Hong, Ruxia; Huang, XiaoLei; Wang, Zhengyou			Obstacle Detection with Deep Convolutional Neural Network	2013 SIXTH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN (ISCID), VOL 1	International Symposium on Computational Intelligence and Design		English	Proceedings Paper	6th International Symposium on Computational Intelligence and Design (ISCID)	OCT 28-29, 2013	Hangzhou, PEOPLES R CHINA	IEEE Nanjing Computat Intelligence Chapter, Univ Bristol, Zhejiang Univ, Zhejiang Sci Tech Univ, Zhejiang Univ, Coll Comp Sci		obstacle detection; convolutional neural network; deep architecture		The difficulty of obstacle detection is how to locate and separate the obstacle from the complex background. Traditional computer vision algorithms can not handle this problem very well due to the handcrafted designed features are vulnerable in complex background. In this article, we use deep convolutional neural network (CNN) to detect obstacle in complex scene. The deep architecture of the CNN guarantees the features learned by the network are rich and effective for detecting the obstacle. The results show that the model achieved a good performance.	[Yu, Hong; Hong, Ruxia; Huang, XiaoLei] Nanchang Teachers Coll, Dept Informat Sci, Nanchang 330103, Peoples R China; [Wang, Zhengyou] Shijiazhuang Tiedao Univ, Dept Elect & Informat Engn, Shijiazhuang 050043, Peoples R China	Yu, H (reprint author), Nanchang Teachers Coll, Dept Informat Sci, Nanchang 330103, Peoples R China.	pdc1028@gmail.com; hongruxia2006@163.com					Asayama Y., 1995, United States Patent, Patent No. 5386285; Coates A., 2012, LNCS, V7700, P561; Graham A., 1982, KRONECKER PRODUCTS M; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Jung J H.G., 2007, INT J AUTOMOTIVE TEC, V8, P493; Kavukcuoglu Koray, 2010, ADV NEURAL INFORM PR, V23, P14; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Murray D, 1997, IEEE INT CONF ROBOT, P1694; Niblack C. W., 1993, IS T SPEIS S EL IM S, P173; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Palmer S.E, 1999, VISION SCI PHOTONS P, V1; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sun Z.T, 2002, P 2002 IEEE INT C IN, P49; Yu Q, 2005, AUTON ROBOT, V19, P141, DOI 10.1007/s10514-005-0612-6; Yu R C.H, 2007, P 2007 IEEE INT C RO, P218; Yutaka H., 2008, ISHIKAWAJIMA HARIMA, V41, P51; Zielke T, 1994, ROBOTICS MOTION VISI, P431	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2165-1701		978-0-7695-5079-4	INT SYM COMPUT INTEL			2013							265	268		10.1109/ISCID.2013.73		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BC7XS	WOS:000355314400063		
S	Yu, Z; Lee, M		Yin, H; Tang, K; Gao, Y; Klawonn, F; Lee, M; Li, B; Weise, T; Yao, X		Yu, Zhibin; Lee, Minho			Continuous Motion Recognition Using Multiple Time Constant Recurrent Neural Network with a Deep Network Model	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2013	Lecture Notes in Computer Science		English	Proceedings Paper	14th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL)	OCT 20-23, 2013	Hefei, PEOPLES R CHINA			Motion recognition; MTRNN; Classification; Deep learning neural network; hybrid neural network		Multiple timescale recurrent neural network (MTRNN) model is a useful tool to model a continuous signal for a dynamic task such as human action recognition. Different setting of initial states in the MTRNN brings us convenience to predict multiple signals using the same network model. On the contrary, optimal switching for suitable initial states in the slow context unit of the MTRNN becomes critical condition to achieve desired multiple dynamic tasks. In this paper, we propose a hybrid neural network model combining the MTRNN with a deep learning neural network (DN), which is to overcome the problem related to the initial state setting in the MTRNN. The DN together with MTRNN generates a suitable initial state for the slow context units in the MTRNN according to automatically detected situation change. We apply our approach to 20 motion skeleton units, which is obtained by KINECT, to construct three kinds of human motion sequences. The results show that the proposed method is able to recognize various motions using proper initial state information in a real-time procedure.	[Yu, Zhibin; Lee, Minho] Kyungpook Natl Univ, Sch Elect Engn, Taegu 702701, South Korea	Lee, M (reprint author), Kyungpook Natl Univ, Sch Elect Engn, 1370 Sankyuk Dong, Taegu 702701, South Korea.	ahriman1985abr@gmail.com; mholee@gmail.com					Behnke S., 2003, HIERARCHICAL NEURAL; Cleeremans A., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.372; Cruz L., 2012, 2012 25 SIBGRAPI C G, P22; DOYA K, 1989, NEURAL NETWORKS, V2, P375, DOI 10.1016/0893-6080(89)90022-1; Fukushima K., 1980, BIOL CYBERN, V36, P93; Hinoshita W, 2011, NEURAL NETWORKS, V24, P311, DOI 10.1016/j.neunet.2010.12.006; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Joslin C., 2005, INSTR MEAS TECHN C 2, P17; Kendon A, 1990, CONDUCTING INTERACTI; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Laptev I, 2001, LECT NOTES COMPUT SC, V2106, P63; Li P, 2012, 2012 IEEE 9 INT C AD, P18; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Wei Wang, 2009, 2009 Conference on Lasers & Electro-Optics Europe & 11th European Quantum Electronics Conference (CLEO/EQEC), DOI 10.1109/CLEOE-EQEC.2009.5196307; Yamashita Y., 2008, PLOS COMPUTATIONAL B, V4; Zhang Y., 2010, 28 ANN C ROB SOC JAP	16	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	0302-9743		978-3-642-41278-3; 978-3-642-41277-6	LECT NOTES COMPUT SC			2013	8206						118	125				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BJS17	WOS:000329908900015		
J	Yuan, ZQ; Sang, JT; Xu, CS			IEEE	Yuan, Zhaoquan; Sang, Jitao; Xu, Changsheng			TAG-AWARE IMAGE CLASSIFICATION VIA NESTED DEEP BELIEF NETS	2013 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME 2013)	IEEE International Conference on Multimedia and Expo		English	Proceedings Paper	IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	JUL 15-19, 2013	San Jose, CA	IEEE		Deep belief network; image classification; deep learning; singular value decomposition	NEURAL-NETWORKS; ALGORITHM	With the rising of internet photos-sharing web sites, the rich aware text information surrounding images on the sites are proved helpful to improve the image classification. This paper presents a novel nested deep learning model called Nested Deep Belief Network(NDBN) for tag-aware image classification. A multi-layer structure of Deep Belief Network(DBN) is established to learn a unified representation of visual feature and tag feature for an image, and an additional Gaussian Restricted Boltzmann Machine is built to capture the tag-tag dependency. Compared with conventional methods, the proposed model can not only find correlations across modalities, but mine the importance for different tags, and also bring about low-rank tag feature representation. We conduct experiments over the MIR Flickr dataset and the results show that the proposed NDBN model outperforms the existing image classification techniques.	[Yuan, Zhaoquan; Sang, Jitao; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Yuan, ZQ (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	zqyuan@nlpr.ia.ac.cn; jtsang@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn					Bao Bingkun, 2013, ROBUST IMAGE ANAL SP; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Burgard Wolfram, 2011, P 25 AAAI C ART INT; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; GUILLAUMIN M, 2010, CVPR, P902; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huiskes M. J., 2008, P 1 ACM INT C MULT I, P39, DOI DOI 10.1145/1460096.1460104; Kumar Ankita, 2007, IEEE INT C COMP VIS, P1; Li YP, 2009, IEEE I CONF COMP VIS, P1957, DOI 10.1109/ICAL.2009.5262626; Ngiam J., 2011, ICML, P689; Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71; Smolensky P., 1986, INFORM PROCESSING DY, V1, P194; Srivastava Nitish, 2012, INT C MACH LEARN WOR; Wang G, 2009, PROC CVPR IEEE, P1367; Wang SH, 2012, PROC CVPR IEEE, P2240	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1945-7871		978-1-4799-0015-2	IEEE INT CON MULTI			2013												6	Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BB8FR	WOS:000346507500082		
J	Zeng, XY; Ouyang, WL; Wang, XG			IEEE	Zeng, Xingyu; Ouyang, Wanli; Wang, Xiaogang			Multi-Stage Contextual Deep Learning for Pedestrian Detection	2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	DEC 01-08, 2013	Sydney, AUSTRALIA	IEEE, CVF, IEEE Comp Soc, APRS, Australiasn Natl Univ, NICTA, FACE++, Natl Robot Engn Ctr, Google, Disney Res, nVIDIA, Raytheon BBN Technologies, Facebook, Adobe, Kitware, OMRON, SRI Int			FEATURES; PATTERNS	Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.	[Zeng, Xingyu; Ouyang, Wanli; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China	Zeng, XY (reprint author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.	xyzeng@ee.cuhk.edu.hk; wlouyang@ee.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk					Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Benenson R., 2012, CVPR; Bourdev L., 2005, CVPR; Bourdev L., 2010, ECCV; Chopra S., 2005, CVPR; Dalal N., 2005, CVPR; Dalal N., 2006, ECCV; Desai C., 2012, ECCV; Ding Y., 2012, CVPR; Dollar P., 2009, BMVC; Dollar P., 2007, CVPR, P1; Dollar P., 2012, ECCV; Dollar P., 2010, BMVC; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Duan G., 2010, ECCV; Enzweiler M., 2008, CVPR; Enzweiler M., 2010, CVPR; Enzweiler M, 2011, IEEE T IMAGE PROCESS, V20, P2967, DOI 10.1109/TIP.2011.2142006; Erhan D, 2010, J MACH LEARN RES, V11, P625; Ess A., 2007, ICCV; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Felzenszwalb P., 2008, CVPR; Felzenszwalb P. F., 2010, CVPR, P2; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Garcia C, 2004, IEEE T PATTERN ANAL, V26, P1408, DOI 10.1109/TPAMI.2004.97; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jarrett K., 2009, CVPR; Krizhevsky A., 2012, NIPS; Le Q.V., 2012, ICML; Lee H., 2009, ICML; Lin Z, 2008, LECT NOTES COMPUT SC, V5305, P423; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo P., 2012, CVPR; Luo P., 2013, ICCV; Maji S., 2008, CVPR; Norouzi M., 2009, CVPR; Ouyang W., 2012, CVPR; Ouyang W., 2013, CVPR; Ouyang W., 2013, ICCV; Park D., 2010, ECCV; Ranzato M., 2011, CVPR; Sabzmeydani P., 2007, CVPR; Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205; Sermanet P, 2013, CVPR; Sun Y., 2013, ICCV, P2; Vedaldi A., 2009, ICCV; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walk S., 2010, CVPR; Wang X., 2009, ICCV; Wojek C., 2009, CVPR; Wojek C., 2008, PATTERN RECOGNITION; Wu B., 2005, ICCV; Zhu L., 2010, CVPR; Zhu Z., 2013, ICCV	56	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-5499		978-1-4799-2839-2	IEEE I CONF COMP VIS			2013							121	128		10.1109/ICCV.2013.22		8	Computer Science, Artificial Intelligence	Computer Science	BC3PE	WOS:000351830500016		
S	Zhang, B; Zhang, L		Ciucci, D; Inuiguchi, M; Yao, Y; Slezak, D; Wang, G		Zhang, Bo; Zhang, Ling			Multi-granular Computing in Web Age	ROUGH SETS, FUZZY SETS, DATA MINING, AND GRANULAR COMPUTING	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	14th Rough Sets, Fuzzy Sets, Data Mining and Granular Computing (RSFDGrC)	OCT 11-14, 2013	Halifax, CANADA			Granular computing; structure mining; structured prediction; data driven; knowledge driven; deep learning		In web age, the traditional information processing faces a new challenge. Due to the change of man-machine interaction modes, computers have to know the intention or interest of users. So computer information processing has to use the human brain processing principle for reference. One of its key principles is the multi-granular computing. In the talk, we will discuss the problem both from artificial intelligence and traditional information processing viewpoints. And we show that the new trend of information processing is to combine these two methods.	[Zhang, Bo] Tsinghua Univ, Coll Informat Sci & Technol, Beijing 100084, Peoples R China	Zhang, B (reprint author), Tsinghua Univ, Coll Informat Sci & Technol, Beijing 100084, Peoples R China.						Benjio Y., 2007, ADV NEURAL INFORM PR, V19, P153; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hobbs J. R., 1985, P 9 INT JOINT C ART, P432; Hu X., 2012, 19 INT C NEUR INF PR; Lafferty J, 2001, P INT C MACH LEARN I; Le Q. V., 2012, P 29 ICML ED SCOTL U; Olshausen B.A., 1996, NATURE; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Taskar B., 2003, ADV NEURAL INFORM PR; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Xu M., 2013, ICML; Xu M., 2012, ADV NEURAL INFORM PR; Yao J., 2012, IEEE T CYBE IN PRESS; Zhang B., 1992, THEORY APPL PROBLEMS; Zhu J., 2013, ICML; Zhu J., 2013, SIGKDD; Zhu J., 2008, P INT C MACH LEARN I	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-41218-9; 978-3-642-41217-2	LECT NOTES ARTIF INT			2013	8170						11	14				4	Computer Science, Artificial Intelligence	Computer Science	BB5HN	WOS:000343874800002		
J	Zhang, LL; Wu, HJ; Feng, J; Zhang, XW		Datta, A		Zhang, Liangliang; Wu, Haijia; Feng, Jing; Zhang, Xiongwei			A method based on compressive sensing to detect community structure using deep belief network	PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON CLOUD COMPUTING AND INFORMATION SECURITY (CCIS 2013)	Advances in Intelligent Systems Research		English	Proceedings Paper	1st International Workshop on Cloud Computing and Information Security (CCIS)	NOV 09-11, 2013	Shanghai, PEOPLES R CHINA	Jiangsu Comp Soc		compressive sensing; community structure; social network; deep belief network(DBN)	RESTRICTED ISOMETRY PROPERTY; ALGORITHM	A deep learning scheme based on compressive sensing to detect community structure of large-scale social network is presented. Our contributions in this work are as follows: First, we reduced the high-dimensional feature of social media data via compressive sensing by using random measurement matrix; Second, deep belief network is employed to learn unsupervised from the low-dimensional samples; Finally the model is fine-tuned by supervised learning from a small scale sample sets with class labels. The effectiveness of the proposed scheme is confirmed by the experiment results.	[Zhang, Liangliang; Wu, Haijia; Feng, Jing; Zhang, Xiongwei] PLA Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China	Zhang, LL (reprint author), PLA Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.	vermouthlove@hotmail.com; wu_haijia@163.com					Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x; Candes E J, 2006, P INT C MATH MADR SP, P1434; Candes EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kuang D., 2012, P SIAM INT C DAT MIN, P106; Mohamed AR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4273; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066133; Quoc V. L, 2012, 29 INT C MACH LEARN; Shiga M, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P647	12	0	0	ATLANTIS PRESS	PARIS	29 AVENUE LAVMIERE, PARIS, 75019, FRANCE	1951-6851		978-90-78677-88-8	ADV INTEL SYS RES			2013	52						10	13				4	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	BA4KR	WOS:000335910400003		
J	Zhang, Y; Zhang, SZ			IEEE	Zhang, Ying; Zhang, Saizheng			Optimized Deep Learning Architectures with Fast Matrix Operation Kernels on Parallel Platform	2013 IEEE 25TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE (ICTAI)	Proceedings-International Conference on Tools With Artificial Intelligence		English	Proceedings Paper	25th International Conference on Tools with Artificial Intelligence (ICTAI)	NOV 04-06, 2013	Washington, DC	Biolog & Artificial Intelligence Fdn, IEEE, IEEE Comp Soc			DENOISING AUTOENCODERS; REPRESENTATIONS; RECOGNITION; ALGORITHM; NETWORKS; NETS	In this paper, we introduce an optimized deep learning architecture with flexible layer structures and fast matrix operation kernels on parallel computing platform (e.g. NVIDIA's GPU). Carefully designed layer-wise strategies are conducted to integrate different kinds of deep architectures into a uniform neural training-testing system. Our fast matrix operation kernels are implemented in deep architecture's propagation processes. In our experiment, these kernels save 70% time on average comparing with the kernels in NVIDIA's CUBLAS library (widely used by many other neural network toolkits), and help our parallel deep architecture beats the neural structures using CUBLAS kernels in practical problems.	[Zhang, Ying] Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China	Zhang, Y (reprint author), Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.	zhy0927@mail.ustc.edu.cn; saizheng.zhang@stonybrook.edu					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2007, NIPS; Boureau Y.L., 2010, CVPR; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Coates A., 2011, AISTATS; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gunnels J, 1998, FIRST MERGED INTERNATIONAL PARALLEL PROCESSING SYMPOSIUM & SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING, P110; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton G.E., NEURAL NETWORKS TRIC, V7700, P599; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang G. B., 2012, CVPR; Krizhevsky A., 2009, TECHNICAL REPORT; Le Q.V., 2012, ICML; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, ICML; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo P., 2012, CVPR; Martinez A., 1998, 24 CVC; Samaria F., 1994, 2 IEEE WORKSH APPL C; Sierra-Canto X., 2010, INT C MACH LEARN APP; Strigl D., 2010, EUR INT C PAR DISTR; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2011, NEURAL COMPUT, V23, P1661, DOI 10.1162/NECO_a_00142; Vincent P., 2008, ICML; Wright J., 2008, TPAMI, V31, P210; Xie J., 2012, NIPS; Yang J., 2009, CVPR	31	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1082-3409		978-1-4799-2971-9	PROC INT C TOOLS ART			2013							71	78		10.1109/ICTAI.2013.21		8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BB5CS	WOS:000343670500010		
S	Zhang, Y; Du, N; Li, K; Feng, JC; Jia, KB; Zhang, AD		Li, GZ; Kim, S; Hughes, M; McLachlan, G; Sun, H; Hu, X; Ressom, H; Liu, B; Liebman, M		Zhang, Yuan; Du, Nan; Li, Kang; Feng, Jinchao; Jia, Kebin; Zhang, Aidong			Critical Protein Detection in Dynamic PPI Networks with Multi-source Integrated Deep Belief Nets	2013 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE (BIBM)	IEEE International Conference on Bioinformatics and Biomedicine-BIBM		English	Proceedings Paper	IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM)	DEC 18-21, 2013	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Tongji Univ, IEEE Comp Soc Tech Comm Life Sci, China Acad Chinese Med Sci, Shanghai Assoc Syst Simulat			TIME-COURSE; MODULARITY; GENES; CYCLE	Critical node detection in dynamic networks is of great value in many areas, such as the evolving of friendship in social networks, the development of epidemics, molecular pathogenesis of diseases and so on. As for detecting critical nodes in dynamic Protein-Protein Interaction Networks (PPINs), there are mainly two challenges: the first is to construct the dynamic PPINs that are not available directly from biological experiments in laboratories; and the second is how to identify the most critical units that are responsible for the dynamic processes. This paper proposes effective framework to tackle these two problems. First of all, this paper proposes to construct the dynamic PPINs by simultaneously modeling the activity of proteins and assembling the dynamic co-regulation protein network at each time point. As result, more comprehensive dynamic PPINs are built. Besides, a novel critical protein detection method that integrates multiple PPI networks into a Deep Belief Network model (referred to as MIDBN) is developed. The integrated model is trained to get hierarchical common representations of multiple sources which are used to reconstruct the original data. The variabilities of the reconstruction errors across the time courses are ranked to finally get the top proteins that have significantly different evolving structural patterns than the other nodes in the dynamic networks. We evaluated our network construction method by comparing the functional representations of the derived networks with that of two other traditional construction methods, and our method achieved superior function analysis results. The ranking results of critical proteins from MIDBN were compared with results from two baseline methods and the comparison results showed that MIDBN had better reconstruction rate and identified more proteins of critical value to yeast cell cycle process.	[Zhang, Yuan; Feng, Jinchao; Jia, Kebin] Beijing Univ Technol, Coll Elect Informat & Control Engn, Beijing, Peoples R China; [Du, Nan; Li, Kang; Zhang, Aidong] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Zhang, Y (reprint author), Beijing Univ Technol, Coll Elect Informat & Control Engn, Beijing, Peoples R China.	zhangyuan@emails.bjut.edu.cn; nandu@buffalo.edu; kli22@buffalo.edu; feng@bjut.edu.cn; kebinj@bjut.edu.cn; azhang@buffalo.edu					Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bhardwaj N, 2005, BIOINFORMATICS, V21, P2730, DOI 10.1093/bioinformatics/bti398; Chang X., 2013, SCI REPORTS, V3; Cho YR, 2009, IEEE DATA MINING, P91, DOI 10.1109/ICDM.2009.39; de Lichtenberg U, 2005, SCIENCE, V307, P724, DOI 10.1126/science.1105103; Du N., 2012, P ACM C BIO COMP BIO, P250; Ge L., 2013, KDD 13, P766; Ge L, 2012, IEEE DATA MINING, P876, DOI 10.1109/ICDM.2012.151; Han JDJ, 2004, NATURE, V430, P88, DOI 10.1038/nature02555; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Komurov K., 2007, MOL SYSTEMS BIOL, V3; Lee HK, 2004, GENOME RES, V14, P1085, DOI 10.1101/gr.1910904; Markowetz F, 2007, MOL BIOSYST, V3, P478, DOI 10.1039/b617014p; Pan W, 2002, BIOINFORMATICS, V18, P546, DOI 10.1093/bioinformatics/18.4.546; Pu SY, 2009, NUCLEIC ACIDS RES, V37, P825, DOI 10.1093/nar/gkn1005; Smolensky P., 1986, INFORM PROCESSING DY, V1, P194; Sutskever I., 2010, P 13 INT C ART INT S; Tang XW, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-339; Tarassov K, 2008, SCIENCE, V320, P1465, DOI 10.1126/science.1153878; Taylor IW, 2009, NAT BIOTECHNOL, V27, P199, DOI 10.1038/nbt.1522; Tu BP, 2005, SCIENCE, V310, P1152, DOI 10.1126/science.1120499; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Wang JX, 2013, PROTEOMICS, V13, P301, DOI 10.1002/pmic.201200277; Yuille A., 2004, P NIPS	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2156-1125		978-1-4799-1309-1; 978-1-4799-1310-7	IEEE INT C BIOINFORM			2013												8	Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BB9FD	WOS:000348252400158		
J	Zhao, K; Wu, ZY; Cai, LH			IEEE	Zhao, Kai; Wu, Zhiyong; Cai, Lianhong			A Real-time Speech Driven Talking Avatar based on Deep Neural Network	2013 ASIA-PACIFIC SIGNAL AND INFORMATION PROCESSING ASSOCIATION ANNUAL SUMMIT AND CONFERENCE (APSIPA)			English	Proceedings Paper	Annual Summit and Conference of the Asia-Pacific-Signal-and-Information-Processing-Association (APSIPA)	OCT 29-NOV 01, 2013	Kaohsiung, TAIWAN	Asia Pacific Signal & Informat Proc Assoc				This paper describes our initial work in developing a real-time speech driven talking avatar system with deep neural network. The input of the system is the acoustic speech and the output is the articulatory movements (that are synchronized with the input speech) on a 3-dimentional avatar. The mapping from the input acoustic features to the output articulatory features is achieved by virtue of deep neural network (DNN). Experiments on the well known acoustic-articulatory English speech corpus MNGU0 demonstrate that the proposed audio-visual mapping method based on DNN can achieve good performance.	[Zhao, Kai; Wu, Zhiyong; Cai, Lianhong] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen Key Lab Informat Sci & Technol, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Shenzhen 518057, Peoples R China	Zhao, K (reprint author), Tsinghua Univ, Grad Sch Shenzhen, Shenzhen Key Lab Informat Sci & Technol, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Shenzhen 518057, Peoples R China.	zk69052@l63.com; zywu@sz.tsinghua.edu.cn; clh-dcs@tsinghua.edu.cn					Deng L., 2011, P AS PAC SIGN INF PR, P1; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hiroya S., 2002, 7 INT C SPOK LANG PR; Karlsson I., 2003, P EUR, P1297; KAWAHARA H, 2001, P INT WORKSH MOD AN; Mohamed A., 2009, P NIPS 2009 WORKSH D; Richmond K., 2011, P INTERSPEECH, P1505; Richmond K., 2002, THESIS EDINBURGH U; Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001; Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009; Zhang L, 2008, IEEE SIGNAL PROC LET, V15, P245, DOI 10.1109/LSP.2008.917004	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA							2013												4	Engineering, Electrical & Electronic	Engineering	BA0ES	WOS:000331094400232		
J	Zheng, X; Wu, ZY; Shen, BB; Meng, H; Cai, LH			IEEE	Zheng, Xin; Wu, Zhiyong; Shen, Binbin; Meng, Helen; Cai, Lianhong			INVESTIGATION OF TANDEM DEEP BELIEF NETWORK APPROACH FOR PHONEME RECOGNITION	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		phoneme recognition; deep belief network (DBN); tandem; Restricted Boltzmann Machine (RBM)	HIDDEN MARKOV-MODELS; NEURAL-NETWORKS; SYSTEMS	This paper proposes using tandem DBN approach - a hierarchical architecture that consists of two or more deep belief networks (DBNs) in tandem manner - for phoneme recognition task on TIMIT. First we describe the standard DBN approach applied in phoneme recognition and discuss the motivation of combining it with tandem classifier approach. We then perform series of experiments to find out the best configuration for the DBN in the second level and discover the full potential of this method. The experiments show that for the DBN in the second level, (a) 2048 units in each hidden layer is better than 1024 and 512 units, (b) for sufficient length of temporal context, two hidden layers are better, (c) the one gives best performance on development set shows 4% relative improvement on coretest set.	[Zheng, Xin; Wu, Zhiyong; Shen, Binbin; Meng, Helen; Cai, Lianhong] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen Key Lab Informat Sci & Technol, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Shenzhen 518055, Peoples R China	Zheng, X (reprint author), Tsinghua Univ, Grad Sch Shenzhen, Shenzhen Key Lab Informat Sci & Technol, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Shenzhen 518055, Peoples R China.	zhengx11@mails.tsinghua.edu.cn; zywu@sz.tsinghua.edu.cn; cbb09@mails.tsinghua.edu.cn; hmmeng@se.cuhk.edu.hk; clh-dcs@tsinghua.edu.cn					Bengio Y., 2007, 1312 U MONTR; Dahl G., 2011, P ICASSP; Dahl G.E., 2012, NIPS; Fosler-Lussier E, 2008, INT CONF ACOUST SPEE, P4049; Halberstadt A., 1998, THESIS MIT; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton G., 2012, IEEE SIGNAL PROCESSI; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Mohamed A., 2012, P ICASSP; Mohamed A., 2011, IEEE T AUDIO SPEECH; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; Pinto J., 2011, IEEE T AUDIO SPEECH, V19; Pinto J, 2008, INT CONF ACOUST SPEE, P4449, DOI 10.1109/ICASSP.2008.4518643; Psutka J., 2001, P EUR, P1813; Schwarz P, 2006, INT CONF ACOUST SPEE, P325; Sivaram G.S.V.S., 2011, P ICASSP; Young S., 2002, HTK BOOK, P3; Yu D, 2010, NIPS 2010 WORKSH DEE	21	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							7586	7590				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507151		
S	Zhu, XL; Sang, RX; Jia, XH; Wong, KYK		Rhee, T; Rayudu, R; Hollitt, C; Lewis, J; Zhang, M		Zhu, Xiaolong; Sang, Ruoxin; Jia, Xuhui; Wong, Kwan-Yee K.			A Hand Shape Recognizer from Simple Sketches	PROCEEDINGS OF 2013 28TH INTERNATIONAL CONFERENCE ON IMAGE AND VISION COMPUTING NEW ZEALAND (IVCNZ 2013)	International Conference on Image and Vision Computing New Zealand		English	Proceedings Paper	28th International Conference on Image and Vision Computing New Zealand (IVCNZ)	NOV 27-29, 2013	Wellington, NEW ZEALAND	IEEE, Victoria Univ Wellington, Sch Engn & Comp Sci		hand shape; sketch; generative model		Hand shape recognition is one of the most important techniques used in human-computer interaction. However, it often takes developers great efforts to customize their hand shape recognizers. In this paper, we present a novel method that enables a hand shape recognizer to be built automatically from simple sketches, such as a "stick-figure" of a hand shape. We introduce the Hand Boltzmann Machine (HBM), a generative model built upon unsupervised learning, to represent the hand shape space of a binary image, and formulate the user provided sketches as an initial guidance for sampling to generate realistic hand shape samples. Such samples are then used to train a hand shape recognizer. We evaluate our method and compare it with other state-of-the-art models in three aspects, namely i) its capability of handling different sketch input, ii) its classification accuracy, and iii) its ability to handle occlusions. Experimental results demonstrate the great potential of our method in real world applications.	[Zhu, Xiaolong; Sang, Ruoxin; Jia, Xuhui; Wong, Kwan-Yee K.] Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Zhu, XL (reprint author), Univ Hong Kong, Dept Comp Sci, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.	xlzhu@cs.hku.hk; rxsang@cs.hku.hk; xhjia@cs.hku.hk; kykwong@cs.hku.hk					Borenstein E., 2004, P EUR C COMP VIS, P1; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; BOYKOV YY, 2001, 8 IEEE INT C COMP VI, V1, P105; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Eslami SMA, 2012, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2012.6247702; Friedman J, 2010, J STAT SOFTW, V33, P1; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kumar MP, 2005, PROC CVPR IEEE, P18; Pugeault Nicolas, 2011, P ICCV 2011 WORKSH C; Ranzato M., 2011, P 2011 IEEE C COMP V, P2857; Salakhutdinov Ruslan, 2009, P 12 INT C ART INT S, P1; Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838; Wang Hai, 2010, P 18 ACM INT C MULT, P1605; Zhou Ren, 2011, P 19 ACM INT C MULT, P1093	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2151-2191		978-1-4799-0883-7; 978-1-4799-0882-0	INT CONF IMAG VIS			2013							130	135				6	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BC1NN	WOS:000350291600023		
J	Baldi, P				Baldi, P.			Boolean autoencoders and hypercube clustering complexity	DESIGNS CODES AND CRYPTOGRAPHY			English	Article						Autoencoders; Clustering; Boolean circuits; Computational complexity	NEURAL-NETWORKS; CODING PROBLEMS; CUBICAL GRAPHS; DEEP; INTRACTABILITY; ALGORITHM; CUBE	We introduce and study the properties of Boolean autoencoder circuits. In particular, we show that the Boolean autoencoder circuit problem is equivalent to a clustering problem on the hypercube. We show that clustering m binary vectors on the n-dimensional hypercube into k clusters is NP-hard, as soon as the number of clusters scales like m(epsilon) (epsilon > 0), and thus the general Boolean autoencoder problem is also NP-hard. We prove that the linear Boolean autoencoder circuit problem is also NP-hard, and so are several related problems such as: subspace identification over finite fields, linear regression over finite fields, even/odd set intersections, and parity circuits. The emerging picture is that autoencoder optimization is NP-hard in the general case, with a few notable exceptions including the linear cases over infinite fields or the Boolean case with fixed size hidden layer. However learning can be tackled by approximate algorithms, including alternate optimization, suggesting a new class of learning algorithms for deep networks, including deep networks of threshold gates or artificial neurons.	Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92717 USA	Baldi, P (reprint author), Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92717 USA.	pfbaldi@ics.uci.edu			NSF [IIS-0513376]; NIH [LM010235, NLM T15 LM07443]	Work supported in part by grants NSF IIS-0513376, NIH LM010235, and NIH NLM T15 LM07443 to PB.	AFRATI F, 1985, INFORM COMPUT, V66, P53, DOI 10.1016/S0019-9958(85)80012-7; Baldi P, 2012, NEURAL NETWORKS, V33, P136, DOI 10.1016/j.neunet.2012.04.011; Baldi P., 2012, J MACH LEARN RES P T, V27, P37; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Bengio Y., 2007, LARGE SCALE KERNEL M; BERLEKAMP ER, 1978, IEEE T INFORM THEORY, V24, P384, DOI 10.1109/TIT.1978.1055873; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda RO, 2000, PATTERN CLASSIFICATI; Erhan D, 2010, J MACH LEARN RES, V11, P625; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Garey M. R., 1979, COMPUTERS INTRACTABI; HARARY F, 1988, COMPUT MATH APPL, V15, P271, DOI 10.1016/0898-1221(88)90212-X; HARTMAN J, 1976, DISCRETE MATH, V16, P157, DOI 10.1016/0012-365X(76)90143-6; HAVEL I, 1972, CZECH MATH J, V22, P338; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; LIVINGSTON M, 1988, MATH COMPUT MODEL, V11, P222, DOI 10.1016/0895-7177(88)90486-4; Mahajan M, 2009, LECT NOTES COMPUT SC, V5431, P274; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; McEliece R. J., 1977, THEORY INFORM CODING; MEGIDDO N, 1984, SIAM J COMPUT, V13, P182, DOI 10.1137/0213014; NTAFOS SC, 1981, IEEE T INFORM THEORY, V27, P794, DOI 10.1109/TIT.1981.1056419; Scholkopf B., 2002, LEARNING KERNELS SUP; Slagle J. L., 1975, IEEE T SYST MAN CYB, V5, P121; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661; Vardy A, 1997, IEEE T INFORM THEORY, V43, P1757, DOI 10.1109/18.641542; Vattani A., 2010, SIMPLER PROOF HARDNE; WINKLER PM, 1983, COMBINATORICA, V3, P135, DOI 10.1007/BF02579350	29	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-1022			DESIGN CODE CRYPTOGR	Designs Codes Cryptogr.	DEC	2012	65	3			SI		383	403		10.1007/s10623-012-9719-x		21	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	064ER	WOS:000313055300016		
J	Rajtmajer, SM; Smith, B; Phoha, S				Rajtmajer, Sarah Michele; Smith, Brian; Phoha, Shashi			Non-negative sparse autoencoder neural networks for the detection of overlapping, hierarchical communities in networked datasets	CHAOS			English	Article							COMPLEX NETWORKS; RANDOM-WALKS; PLASTICITY; PARTS	We propose the first use of a non-negative sparse autoencoder (NNSAE) neural network for community structure detection in complex networks. The NNSAE learns a compressed representation of a set of fixed-length, weighted random walks over the network, and communities are detected as subsets of network nodes corresponding to non-negligible elements of the basis vectors of this compression. The NNSAE model is efficient and online. When utilized for community structure detection, it is able to uncover potentially overlapping and hierarchical community structure in large networks. (C) 2012 American Institute of Physics. [http://dx.doi.org/10.1063/1.4771600]	[Rajtmajer, Sarah Michele; Smith, Brian; Phoha, Shashi] Penn State Univ, Appl Res Lab, State Coll, PA 16804 USA	Rajtmajer, SM (reprint author), Penn State Univ, Appl Res Lab, POB 30, State Coll, PA 16804 USA.	smr48@psu.edu			Intelligence Community Postdoctoral Research Fellowship Program [2010*1043106*000]	This project was supported by a grant from the Intelligence Community Postdoctoral Research Fellowship Program, Award No. 2010*1043106*000. Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the sponsor.	Angelini L, 2007, CHAOS, V17, DOI 10.1063/1.2732162; Brandes U, 2008, IEEE T KNOWL DATA EN, V20, P172, DOI 10.1109/TKDE.2007.190689; Danon L, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.036103; Derenyi I, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.160202; Estrada E, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.036111; Estrada E, 2009, PHYSICA A, V388, P764, DOI 10.1016/j.physa.2008.11.011; Estrada E, 2009, APPL MATH COMPUT, V214, P500, DOI 10.1016/j.amc.2009.04.024; Estrada E, 2011, PHYS REP, V514, P90; Estrada E, 2011, CHAOS, V21, DOI 10.1063/1.3552144; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; FREEMAN LC, 1977, SOCIOMETRY, V40, P35, DOI 10.2307/3033543; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Guimera R, 2005, NATURE, V433, P895, DOI 10.1038/nature03288; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hoyer P. O., 2002, P IEEE WORKSH NEUR N, P557, DOI DOI 10.1109/NNSP.2002.1030067; Kumpula J. M., 2008, PHYS REV E, V78, P8; Le Q. V, 2012, PROCEEDINGS OF THE 2, V28, P61; Lee DD, 1999, NATURE, V401, P788; Lemme A, 2012, NEURAL NETWORKS, V33, P194, DOI 10.1016/j.neunet.2012.05.003; Lusseau D, 2003, BEHAV ECOL SOCIOBIOL, V54, P396, DOI 10.1007/s00265-003-0651-y; Lusseau D, 2004, P ROY SOC LOND B BIO, V271, P5477; Newman M. E. J., 2003, PHYS REV E PT 2, V69, P16; Palla G., 2005, NATURE, V435, P816; Porter M. A., 2009, NOT AM MATH SOC, V56, P1082, DOI DOI 10.1063/1.3194108; Raina R., 2007, LEARNING, P759; Ranzato M., 2007, ADV NEURAL INF PROCE, V20, P1; Rosvall M, 2008, P NATL ACAD SCI USA, V105, P1118, DOI 10.1073/pnas.0706851105; Salathe M, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000736; Thakur GS, 2009, IET SYST BIOL, V3, P266, DOI 10.1049/iet-syb.2007.0061; Triesch J, 2005, LECT NOTES COMPUT SC, V3696, P65; Triesch J, 2007, NEURAL COMPUT, V19, P885, DOI 10.1162/neco.2007.19.4.885; ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452; Zhou H, 2003, PHYS REV E PT 1, V67, P5; Zhou H, 2003, PHYS REV E, V67, P10	35	0	0	AMER INST PHYSICS	MELVILLE	CIRCULATION & FULFILLMENT DIV, 2 HUNTINGTON QUADRANGLE, STE 1 N O 1, MELVILLE, NY 11747-4501 USA	1054-1500			CHAOS	Chaos	DEC	2012	22	4							043141	10.1063/1.4771600		5	Mathematics, Applied; Physics, Mathematical	Mathematics; Physics	061EU	WOS:000312831600041		
J	Vervaeke, J; Lillicrap, TP; Richards, BA				Vervaeke, John; Lillicrap, Timothy P.; Richards, Blake A.			Relevance Realization and the Emerging Framework in Cognitive Science	JOURNAL OF LOGIC AND COMPUTATION			English	Article						relevance; constraints; self-organization; opponent processing; framework	NEURAL-NETWORKS; ALGORITHM; FODOR; MODEL; MIND	We argue that an explanation of relevance realization is a pervasive problem within cognitive science, and that it is becoming the criterion of the cognitive in terms of which a new framework for doing cognitive science is emerging. We articulate that framework and then make use of it to provide the beginnings of a theory of relevance realization that incorporates many existing insights implicit within the contributing disciplines of cognitive science. We also introduce some theoretical and potentially technical innovations motivated by the articulation of those insights. Finally, we show how the explication of the framework and development of the theory help to clear up some important incompleteness and confusions within both Montague's work and Sperber and Wilson's theory of relevance.	[Vervaeke, John] Univ Toronto, Univ Coll Toronto, Cognit Sci Program, Toronto, ON M5S 3H7, Canada; [Vervaeke, John] Univ Toronto, Univ Coll Toronto, Dept Psychol, Toronto, ON M5S 3H7, Canada; [Lillicrap, Timothy P.] Queens Univ, Ctr Neurosci Studies, Kingston, ON K7L 3N6, Canada; [Richards, Blake A.] Univ Oxford, Dept Pharmacol, Oxford OX1 3QT, England	Vervaeke, J (reprint author), Univ Toronto, Univ Coll Toronto, Cognit Sci Program, Toronto, ON M5S 3H7, Canada.	john.vervaeke@utoronto.ca; tim@biomed.queensu.ca; blake.richards@pharm.ox.ac.uk					Austin JL, 1962, DO THINGS WORDS; Barsalou L., 2005, HDB CATEGORIZATION C, P619, DOI 10.1016/B978-008044612-7/50083-4; Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Cherniak Christopher, 1986, MINIMAL RATIONALITY; Chiappe DL, 1997, THEOR PSYCHOL, V7, P799, DOI 10.1177/0959354397076004; Chiappe DL, 1996, BEHAV BRAIN SCI, V19, P529; Chomsky N., 1997, MINIMALIST PROGRAM; Dennett D., 1987, COGNITIVE WHEELS FRA; Doya K, 2000, NEURAL COMPUT, V12, P219, DOI 10.1162/089976600300015961; Doya K, 2002, NEURAL COMPUT, V14, P1347, DOI 10.1162/089976602753712972; Fodor J, 2006, DAEDALUS-US, V135, P86, DOI 10.1162/daed.2006.135.3.86; Fodor J. A., 1968, PSYCHOL EXPLANATION; FRENCH RM, 1990, MIND, V99, P53; Gardenfors P., 2000, CONCEPTUAL SPACES GE; Gleitman LR, 1995, INVITATION COGNITIVE, V1, P1, DOI DOI 10.1017/S1366728909004015; Goodman N., 1972, 7 STRICTURES SIMILAR; Green C. D., 1996, WHAT KIND EXPLANATIO, P201; Green CD, 1996, J EXP THEOR ARTIF IN, V8, P95, DOI 10.1080/09528139650042565; Grice H. Paul, 1989, STUDIES WAY WORDS; Harman Gilbert, 1988, CHANGE VIEW PRINCIPL; Haugeland J., 1985, ARTIFICIAL INTELLIGE; Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168306; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Holyoak K. J., 1995, INVITATION COGNITIVE, P267; Klein RM, 1999, PSYCHOL SCI, V10, P346, DOI 10.1111/1467-9280.00166; Li W., 2004, 1 INT C INF CONTR AU, V1, P222; Medin D., 2005, CAMBRIDGE HDB THINKI; MEDIN DL, 1989, AM PSYCHOL, V44, P1469, DOI 10.1037/0003-066X.44.12.1469; Montague R., 2006, YOUR BRAIN IS ALMOST; Newell A., 1972, HUMAN PROBLEM SOLVIN; Newell A., 1997, MIND DESIGN; Putnam Hilary, 1991, REPRESENTATION REALI; Pylyshyn Z. W., 1988, ROBOTS DILEMMA FRAME; Pylyshyn Z. W., 1984, COMPUTATION COGNITIO; Ramsey W., 1991, CONNECTIONISM ELIMIN, P199; Rumelhart D. E., 1977, REPRESENTATION KNOWL; Schank R. C., 1977, SCRIPTS PLANS GOALS; Shimansky YP, 2004, BIOL CYBERN, V90, P133, DOI 10.1007/s00422-003-0452-4; Siegel DJ, 2001, INFANT MENT HEALTH J, V22, P67, DOI 10.1002/1097-0355(200101/04)22:1<67::AID-IMHJ3>3.0.CO;2-G; Siegler R. S., 1995, DEV COGNITIVE COMPET, P31; Simon Howard A., 1983, REASONING HUMAN AFFA; Smith E., 1995, INVITATION COGNITIVE, V3; Smolensky P., 1991, CONNECTIONISM CONSTI, P201; SMOLENSKY P, 1988, BEHAV BRAIN SCI, V11, P1; Sperber D, 1996, BEHAV BRAIN SCI, V19, P530; Sperber Dan, 1995, RELEVANCE COMMUNICAT; Stich Stephen, 1993, FRAGMENTATION REASON; Sutton RS, 1998, REINFORCEMENT LEARNI; Thompson E., 2007, MIND LIFE BIOL PHENO; Todorov E, 2002, NAT NEUROSCI, V5, P1226, DOI 10.1038/nn963; Turing A., 1950, MIND, V49, p[433, 2099], DOI DOI 10.1093/MIND/LIX.236.433; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Vapnik V. N., 1998, STAT LEARNING THEORY; Varela F. J., 1991, EMBODIED MIND COGNIT; Vervaeke J., 1997, THESIS U TORONTO TOR; Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069; Wheeler M, 2005, RECONSTRUCTING COGNI; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893	60	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0955-792X			J LOGIC COMPUT	J. Logic Comput.	FEB	2012	22	1			SI		79	99		10.1093/logcom/exp067		21	Computer Science, Theory & Methods; Logic	Computer Science; Science & Technology - Other Topics	879QH	WOS:000299346400005		
J	Baccouche, M; Mamalet, F; Wolf, C; Garcia, C; Baskurt, A		Bowden, R; Collomosse, J; Mikolajczyk, K		Baccouche, Moez; Mamalet, Franck; Wolf, Christian; Garcia, Christophe; Baskurt, Atilla			Spatio-Temporal Convolutional Sparse Auto-Encoder for Sequence Classification	PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012			English	Proceedings Paper	23rd British Machine Vision Conference	SEP 03-07, 2012	Guildford, ENGLAND	PASCAL2, Microsoft Res, Stemmer Imaging, TOSHIBA, 3dMD, Springer, Scorpion Vis Ltd	University of Surrey		RECOGNITION; SCALE	We present in this paper a novel learning-based approach for video sequence classification. Contrary to the dominant methodology, which relies on hand-crafted features that are manually engineered to be optimal for a specific task, our neural model automatically learns a sparse shift-invariant representation of the local 2D + t salient information, without any use of prior knowledge. To that aim, a spatio-temporal convolutional sparse auto-encoder is trained to project a given input in a feature space, and to reconstruct it from its projection coordinates. Learning is performed in an unsupervised manner by minimizing a global parametrized objective function. The sparsity is ensured by adding a sparsifying logistic between the encoder and the decoder, while the shift-invariance is handled by including an additional hidden variable to the objective function. The temporal evolution of the obtained sparse features is learned by a long short-term memory recurrent neural network trained to classify each sequence. We show that, since the feature learning process is problem-independent, the model achieves outstanding performances when applied to two different problems, namely human action and facial expression recognition. Obtained results are superior to the state of the art on the GEMEP-FERA dataset and among the very best on the KTH dataset.	[Baccouche, Moez; Mamalet, Franck] Orange Labs R&D, F-35510 Lyon, France	Baccouche, M (reprint author), Orange Labs R&D, 4 Rue Clos Courtel, F-35510 Lyon, France.	moez.baccouche@orange.com; franck.mamalet@orange.com; christian.wolf@liris.cnrs.fr; christophe.garcia@liris.cnrs.fr; atilla.baskurt@liris.cnrs.fr	Garcia, christophe/; Garcia, christophe/	Garcia, christophe/0000-0001-7997-9837; Garcia, christophe/0000-0001-7997-9837			Baccouche M., 2011, INT WORKSH HUM BEH U, P29; Chen M., 2009, CMUCS09161; Collobert R., 2008, ICML 08, P160; Dhall A., 2011, INT C AUT FAC GEST A, P878; Dollar P., 2005, IEEE INT WORKSH VIS, P65; Duffner S., 2008, INT C COMP VIS THEOR; Gao Z, 2010, LECT NOTES COMPUT SC, V6219, P88; Garcia C, 2004, IEEE T PATTERN ANAL, V26, P1408, DOI 10.1109/TPAMI.2004.97; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Ikizler N., 2008, ICPR, P1; Jhuang H, 2007, ICCV, P1, DOI [DOI 10.1109/ICCV.2007.4408988, 10.1109/ICCV.2007.4408988]; Ji S., 2010, INT C MACH LEARN, P495; Kim T.-K., 2007, CVPR, P1; Laptev Ivan, 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587756; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, NIPS, P1096; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Littlewort G., 2011, INT C AUT FAC GEST A, P897; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu Jun-Li, 2008, Endocrine Metabolic & Immune Disorders-Drug Targets, V8, P1, DOI 10.2174/187153008783928361; Meng H., 2011, INT C AUT FAC GEST A, P854; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ranzato M, 2007, COMPUTER VISION PATT, P1; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Tariq U., 2011, INT C AUT FAC GEST A, P872; TAYLOR GW, 2010, EUR C COMP VIS, V6316, P140; Valstar M. F., 2011, IEEE INT C AUT FAC G, P921; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Yang S., 2011, INT C AUT FAC GEST R, P866	32	0	0	B M V A PRESS	GUILDFORD	49A ELMSIDE ONSLOW VILLAGE, GUILDFORD, SURREY GU2 5SX, ENGLAND							2012										10.5244/C.26.124		12	Computer Science, Artificial Intelligence	Computer Science	BB8CI	WOS:000346356200120		
J	Badino, L; Canevari, C; Fadiga, L; Metta, G			IEEE	Badino, Leonardo; Canevari, Claudia; Fadiga, Luciano; Metta, Giorgio			DEEP-LEVEL ACOUSTIC-TO-ARTICULATORY MAPPING FOR DBN-HMM BASED PHONE RECOGNITION	2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012)			English	Proceedings Paper	IEEE Workshop on Spoken Language Technology (SLT)	DEC 02-05, 2012	Miami, FL	Inst Elect & Elect Engineers (IEEE), IEEE Signal Processing Soc		Acoustic-to-articulatory mapping; phone recognition; deep belief networks	SPEECH RECOGNITION	In this paper we experiment with methods based on Deep Belief Networks (DBNs) to recover measured articulatory data from speech acoustics. Our acoustic-to-articulatory mapping (AAM) processes go through multi-layered and hierarchical (i.e., deep) representations of the acoustic and the articulatory domains obtained through unsupervised learning of DBNs. The unsupervised learning of DBNs can serve two purposes: (i) pre-training of the Multi-layer Perceptrons that perform AAM; (ii) transformation of the articulatory domain that is recovered from acoustics through AAM. The recovered articulatory features are combined with MFCCs to compute phone posteriors for phone recognition. Tested on the MOCHA-TIMIT corpus, the recovered articulatory features, when combined with MFCCs, lead to up to a remarkable 16.6% relative phone error reduction w.r.t. a phone recognizer that only uses MFCCs.	[Badino, Leonardo; Canevari, Claudia; Fadiga, Luciano; Metta, Giorgio] RBCS, Ist Italiano Tecnol, Genoa, Italy	Badino, L (reprint author), RBCS, Ist Italiano Tecnol, Genoa, Italy.						BROWMAN CP, 1992, PHONETICA, V49, P155; D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017; Erhan D., 2011, J MACHINE LEARNING R, V11; Hinton G. E., 2010, NIPS 22 WORKSH DEEP; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; King S, 2007, J ACOUST SOC AM, V121, P723, DOI 10.1121/1.2404622; Lindblom B., 1979, J PHONETICS, V7, P146; Markov K, 2006, SPEECH COMMUN, V48, P161, DOI 10.1016/j.specom.2005.07.003; Mitra V, 2012, J ACOUST SOC AM, V131, P2270, DOI 10.1121/1.3682038; Mitra V, 2010, IEEE J-STSP, V4, P1027, DOI 10.1109/JSTSP.2010.2076013; Ngiam J., 2011, ICML; Qin C., 2007, P INTERSPEECH; Richmond K, 2003, COMPUT SPEECH LANG, V17, P153, DOI 10.1016/S0885-2308(03)00005-6; Roweiss S., 1999, THESIS CALTECH PASAD; Toda T., 2007, SPEECH COMMUN, V50, P215; Uria B., 2011, P NIPS WORKSH DEEP L; Wrench A., 2000, P ICSLP BEIJ CHIN OC, V4, P145; Zlokarnik I., 1995, J ACOUST SOC AM, V97, P3246, DOI 10.1121/1.411699	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-5126-3				2012							370	375				6	Engineering, Electrical & Electronic	Engineering	BEL18	WOS:000317182800065		
B	Berry, J; Fasel, I; Fadiga, L; Archangeli, D			International Speech Communications Association	Berry, Jeff; Fasel, Ian; Fadiga, Luciano; Archangeli, Diana			Training Deep Nets with Imbalanced and Unlabeled Data	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		deep belief networks; ultrasound imaging; tongue imaging; speech processing; bootstrapping; class imbalance problem	ULTRASOUND IMAGES; TONGUE	Training deep belief networks (DBNs) is normally done with large data sets. Our goal is to predict traces of the surface of the tongue in ultrasound images of human speech. Hand-tracing is labor-intensive; the dataset is highly imbalanced since many images are extremely similar. We propose a bootstrapping method which handles this imbalance by iteratively selecting a small subset of images to be hand-traced (thereby reducing human labor time), then (re)training the DBN, making use of an entropy-based diversity measure for the initial selection, thereby achieving over a two-fold reduction in human time required for tracing with human-level accuracy.	[Berry, Jeff; Archangeli, Diana] Univ Arizona, Dept Linguist, Tucson, AZ 85721 USA	Berry, J (reprint author), Univ Arizona, Dept Linguist, Tucson, AZ 85721 USA.	jjberry@email.arizona.edu; ianfasel@sista.arizona.edu; fdl@unife.it; dba@u.arizona.edu					Cancho RFI, 2003, P NATL ACAD SCI USA, V100, P788, DOI 10.1073/pnas.0335980100; Chawla N. V., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI DOI 10.1145/1007730.1007733; Drummond C., 2003, ICML WORKSH LEARN IM; Erhan D, 2010, J MACH LEARN RES, V11, P625; Fasel I., 2010, INT C PAT REC; Gick B, 2006, J PHONETICS, V34, P49, DOI 10.1016/j.wocn.2005.03.005; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Iskarous K, 2005, CLIN LINGUIST PHONET, V19, P555, DOI 10.1080/02699200500113871; Li M, 2005, CLIN LINGUIST PHONET, V19, P545, DOI 10.1080/02699200500113616; LIU XY, 2009, SYSTEMS MAN CYBERN B, V39, P539, DOI DOI 10.1109/TSMCB.2008.2007853; Miellce J., 2011, LAB PHON, V10, P699; Salakhutdinov R., 2007, AI STAT, V3; Stone M, 2005, CLIN LINGUIST PHONET, V19, P455, DOI 10.1080/02699200500113558; Zipf GK, 1935, PSYCHOBIOLOGY LANGUA	15	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							1754	1757				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BFO97	WOS:000320827200439		
J	Brakel, P; Schrauwen, B		Huang, T; Zeng, Z; Li, C; Leung, CS		Brakel, Philemon; Schrauwen, Benjamin			Energy-Based Temporal Neural Networks for Imputing Missing Values	NEURAL INFORMATION PROCESSING, ICONIP 2012, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	19th International Conference on Neural Information Processing (ICONIP)	NOV 11-15, 2012	Doha, QATAR	IEEE Computat Intelligence Soc, United Dev Co PSC, Qatar Petrochem Co, ExxonMobil, Texas A&M Univ Qatar & Asia Pacif Neural Network Assembly, European Neural Network Soc, Japanese Neural Network Soc, Qatar Petr, Int Neural Network Soc		neural networks; energy-based models; time series; missing values; machine learning; optimization		Imputing missing values in high dimensional time series is a difficult problem. There have been some approaches to the problem [11,8] where neural architectures were trained as probabilistic models of the data. However, we argue that this approach is not optimal. We propose to view temporal neural networks with latent variables as energy-based models and train them for missing value recovery directly. In this paper we introduce two energy-based models. The first model is based on a one dimensional convolution and the second model utilizes a recurrent neural network. We demonstrate how ideas from the energy-based learning framework can be used to train these models to recover missing values. The models are evaluated on a motion capture dataset.	[Brakel, Philemon; Schrauwen, Benjamin] Univ Ghent, Dept Elect & Informat Syst, B-9000 Ghent, Belgium	Brakel, P (reprint author), Univ Ghent, Dept Elect & Informat Syst, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.	philemon.brakel@elis.ugent.be; benjamin.schrauwen@elis.ugent.be					BESAG J, 1986, J ROY STAT SOC B MET, V48, P259; Domke J, 2012, J MACHINE LEARNING R, V22, P318; Freund Y., 1994, UNSUPERVISED LEARNIN; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; LeCun Y., 2006, PREDICTING STRUCTURE; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Mirowski P, 2009, LECT NOTES ARTIF INT, V5782, P128; Ngiam J., 2011, P 28 INT C MACH LEAR, P1105; Sutskever I., 2008, ADV NEURAL INFORM PR, V21; Taylor G.W., 2007, ADV NEURAL INFORM PR, V19; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-34481-7	LECT NOTES COMPUT SC			2012	7664						575	582				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BB6WW	WOS:000345088900070		
B	Brueckner, R; Schuller, B			International Speech Communications Association	Brueckner, Raymond; Schuller, Bjoern			Likability Classification - A not so Deep Neural Network Approach	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		Likability; speaker trait challenge; restricted Boltzmann machines; deep belief networks		This papers presents results on the application of restricted Boltzmann machines (RBM) and deep belief networks (DBN) on the Likability Sub-Challenge of the Interspeech 2012 Speaker Trait Challenge [1]. RBMs are a particular form of log-linear Markov Random Fields and generative models which try to model the probability distribution of the underlying input data which can be trained in an unsupervised fashion. DBNs can be constructed by stacking RBMs and are known to yield an increasingly complex representation of the input data as the number of layers increases. Our results show that the Likability Sub-Challenge classification task does not benefit from the modeling power of DBN, but that the use of an RBM as the first stage of a two-layer neural network with subsequent fine-tuning improves the baseline result of 59.0 % to 64.0 %, i.e., a relative 8.5 % improvement of the unweighted average evaluation measure.	[Brueckner, Raymond] Tech Univ Munich, Inst Human Machine Commun, D-80290 Munich, Germany	Brueckner, R (reprint author), Tech Univ Munich, Inst Human Machine Commun, D-80290 Munich, Germany.	raymond.brueckner@web.de; schuller@tum.de					Abdel-rahman M., 2012, IEEE T AUDIO SPEECH, V20, P14; Burkhardt F., 2011, P INT SLOR IT, P1557; Cho K, 2011, LECT NOTES COMPUT SC, V6791, P10; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton G., 2010, 2010003 U TOR MACH L; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; Schuller B., 2012, P INT 2012 SEP; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688; Wollmer M., 2011, P INT 2011 FLOR AUG, P77	12	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							290	293				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BFO97	WOS:000320827200073		
J	Chartier, S; Leth-Steensen, C; Hebert, MF				Chartier, Sylvain; Leth-Steensen, Craig; Hebert, Marie-France			Performing complex associations using a generalised bidirectional associative memory	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE			English	Article						neural networks; bidirectional associative memory; complex associations; nonlinearly separable; n-parity task	HETEROASSOCIATIVE MEMORY; NEURAL-NETWORKS; ALGORITHM; MODEL; NOISE	Learning in bidirectional associative memory (BAM) is typically Hebbian-based. Since Kosko's 1988 ['Bidirectional Associative Memories', IEEE Transactions on Systems, Man and Cybernetics, 18, 49-60] paper on BAM in the late 1980s, many improvements have been proposed. However, none of the proposed modifications have allowed BAM to perform complex associative tasks that combine many-to-one with one-to-many associations. Even though BAMs are often deemed more plausible biologically, if they are not able to solve such mappings they will have difficulties establishing themselves as good models of cognition. This article presents a BAM that can perform complex associations using only covariance matrices. It will be shown that a single network can be trained to learn both the 2- and 3-bit parity problems, while its extension into a generalised BAM with a hidden layer allows the model to learn even more complex associations with perfect performance. The conditions that provide optimal learning performance within both network frameworks are explored. Results show that contrary to other associative memory network models, the proposed model is able to learn nonlinearly separable tasks perfectly while maintaining the same learning and output functions.	[Chartier, Sylvain; Hebert, Marie-France] Univ Ottawa, Sch Psychol, Ottawa, ON K1N 6N5, Canada; [Leth-Steensen, Craig] Carleton Univ, Dept Psychol, Ottawa, ON K1S 5B6, Canada	Chartier, S (reprint author), Univ Ottawa, Sch Psychol, 136 Jean Jacques Lussier, Ottawa, ON K1N 6N5, Canada.	schartie@uottawa.ca			Natural Sciences and Engineering Research Council (NSERC) of Canada	This research was supported in part by Natural Sciences and Engineering Research Council (NSERC) of Canada grants to both S. Chartier and C. Leth-Steensen.	Arik S, 2005, IEEE T NEURAL NETWOR, V16, P580, DOI 10.1109/TNN.2005.844910; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Chartier S, 2008, NEW IDEAS PSYCHOL, V26, P252, DOI 10.1016/j.newideapsych.2007.07.005; Chartier S, 2006, IEEE T NEURAL NETWOR, V17, P59, DOI 10.1109/TNN.2005.860855; Chartier S., 2010, IEEE T NEURAL NETWOR, V20, P1281; Chartier S, 2007, IEEE IJCNN, P1679, DOI 10.1109/IJCNN.2007.4371210; Chartier S, 2006, IEEE T NEURAL NETWOR, V17, P385, DOI 10.1109/TNN.2005.863420; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Costantini G, 2003, IEEE T NEURAL NETWOR, V14, P703, DOI 10.1109/TNN.2003.810596; Dandurand F., 2009, P 31 ANN C COGN SCI, P1541; Diamantaras K.I., 1996, PRINCIPAL COMPONENT; Du SZ, 2005, IEEE T NEURAL NETWOR, V16, P887, DOI 10.1109/TNN.2005.849832; Gerstner W., 2002, SPIKING NEURON MODEL; Giguere G., 2007, P 29 ANN C COGN SCI, P1025; Giguere G., 2007, P 8 INT C COGN MOD, P97; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G. E., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.143; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Karhunen J, 1998, NEUROCOMPUTING, V22, P5, DOI 10.1016/S0925-2312(98)00046-0; Klemm K, 2000, PHYS REV LETT, V84, P3013, DOI 10.1103/PhysRevLett.84.3013; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOSKO B, 1988, IEEE T SYST MAN CYB, V18, P49, DOI 10.1109/21.87054; Labib R, 1999, P INT JOINT C NEUR N, P617; LEUNG CS, 1994, IEEE T SYST MAN CYB, V24, P791; Li CF, 2005, CHEM ENG TECHNOL, V28, P141, DOI 10.1002/ceat.200407027; Matsuka T, 2008, NEURAL NETWORKS, V21, P289, DOI 10.1016/j.neunet.2007.12.035; Minsky M, 1969, PERCEPTRONS; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; OReilly RC, 1996, NEURAL COMPUT, V8, P895, DOI 10.1162/neco.1996.8.5.895; Park J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.246; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shen D, 2005, IEEE T NEURAL NETWOR, V16, P293, DOI 10.1109/TNN.2004.841793; Shen YJ, 2004, NEURAL PROCESS LETT, V20, P85, DOI 10.1007/s11063-004-0637-4; SIEGLER RS, 1976, COGNITIVE PSYCHOL, V8, P481, DOI 10.1016/0010-0285(76)90016-5; Smith JD, 2004, J EXP PSYCHOL GEN, V133, P398, DOI 10.1037/0096-3445-133.3.398; Wang ZO, 1996, IEEE T COMPUT, V45, P1171; Zhang D., 2003, J ELECT, V20, P220, DOI 10.1007/BF02687708	39	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0952-813X			J EXP THEOR ARTIF IN	J. Exp. Theor. Artif. Intell.		2012	24	1					23	42		10.1080/0952813X.2010.535712		20	Computer Science, Artificial Intelligence	Computer Science	882DO	WOS:000299541900002		
J	Chen, JF; Jin, QJ; Chao, J				Chen, Junfei; Jin, Qiongji; Chao, Jing			Design of Deep Belief Networks for Short-Term Prediction of Drought Index Using Data in the Huaihe River Basin	MATHEMATICAL PROBLEMS IN ENGINEERING			English	Article							STANDARDIZED PRECIPITATION INDEX; HYDROLOGICAL TIME-SERIES; LOGLINEAR MODELS; NEURAL-NETWORKS; ALGORITHM; MULTIPLE; NOISES; CHINA	With the global climate change, drought disasters occur frequently. Drought prediction is an important content for drought disaster management, planning and management of water resource systems of a river basin. In this study, a short-term drought prediction model based on deep belief networks (DBNs) is proposed to predict the time series of different time-scale standardized precipitation index (SPI). The DBN model is applied to predict the drought time series in the Huaihe River Basin, China. Compared with BP neural network, the DBN-based drought prediction model has shown better predictive skills than the BP neural network for the different time-scale SPI. This research can improve drought prediction technology and be helpful for water resources managers and decision makers in managing drought disasters.	[Chen, Junfei; Jin, Qiongji] Hohai Univ, State Key Lab Hydrol Water Resources & Hydraul En, Nanjing 210098, Jiangsu, Peoples R China; [Chen, Junfei; Jin, Qiongji] Hohai Univ, Sch Business, Nanjing 210098, Jiangsu, Peoples R China; [Chao, Jing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China	Chen, JF (reprint author), Hohai Univ, Sch Business, Nanjing 210098, Jiangsu, Peoples R China.	chenjunfei@yahoo.com.cn			National Society Science Fund of China [09CJY020]; National Nature Science Foundation of China [90924027]; State Key Laboratory of Hydrology-Water Resources and Hydraulic Engineering, China [2011585312]; Chinese Ministry of Water Resources [200801027]; Science and Technology Projects of Yunnan Province [2010CA013]; Hohai University; Jiangsu Province Qing Lan Project	This work was supported partially by the National Society Science Fund of China (09CJY020), the National Nature Science Foundation of China (90924027), the Special Fund of State Key Laboratory of Hydrology-Water Resources and Hydraulic Engineering, China (2011585312), Public-Interest Industry Project of Chinese Ministry of Water Resources (200801027), the Science and Technology Projects of Yunnan Province (2010CA013), the Fundamental Research Funds for the Central Universities of Hohai University, and 2010 Jiangsu Province Qing Lan Project.	Barros AP, 2008, J HYDROL, V357, P349, DOI 10.1016/j.jhydrol.2008.05.026; Beran J., 1992, STAT SCI, V7, P404, DOI 10.1214/ss/1177011122; Chao J., 2011, P INT JOINT C NEUR N, P1259; Chen H., 2002, P 12 INT C ART NEUR, P358; Edwards D. C., 1997, 972 COL STAT U; Frey BJ, 1997, ADV NEUR IN, V9, P452; Ge Zhexue, 2007, NEURAL NETWORK THEOR; Guttman NB, 1999, J AM WATER RESOUR AS, V35, P311, DOI 10.1111/j.1752-1688.1999.tb03592.x; Hagman G, 1984, PREVENTION BETTER CU; Han P., 2010, MATH COMPUT MODEL, V51, P1398; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang R. H, 2003, CLIMATIC DISASTERS; HURST HE, 1951, T AM SOC CIV ENG, V116, P770; Jia H. F., 1998, SYSTEMS ENG THEORY P, V8, P122; Jiang LH, 2011, J IRON STEEL RES INT, V18, P25, DOI 10.1016/S1006-706X(11)60099-X; Kang Y, 2011, LECT NOTES ARTIF INT, V6912, P130; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Li M, 2008, PHYSICA A, V387, P2584, DOI 10.1016/j.physa.2008.01.026; Li M, 2012, MATH PROBL ENG, DOI 10.1155/2012/302786; Li M, 2010, MATH PROBL ENG, DOI 10.1155/2010/157264; Li M, 2011, MATH PROBL ENG, DOI 10.1155/2011/654284; Liu T, 2010, LECT NOTES COMPUT SC, V6443, P314; Lloyd-Hughes B, 2002, INT J CLIMATOL, V22, P1571, DOI 10.1002/joc.846; Lohani VK, 1997, J AM WATER RESOUR AS, V33, P1375, DOI 10.1111/j.1752-1688.1997.tb03560.x; Mandelbrot B. B., 1968, WATER RESOUR RES, V4, P908; MANDELBR.BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; MANDELBR.BB, 1969, WATER RESOUR RES, V5, P228, DOI 10.1029/WR005i001p00228; McKee T.B., 1993, P 8 C APPL CLIM 17 2, P179; Mishra AK, 2006, ECOL MODEL, V198, P127, DOI 10.1016/j.ecolmodel.2006.04.017; Moreira EE, 2008, J HYDROL, V354, P116, DOI 10.1016/j.jhydrol.2008.03.002; Nair V., 2010, P 27 INT C MACH LEAR, P807; Paulo AA, 2005, AGR WATER MANAGE, V77, P59, DOI 10.1016/j.agwat.2004.09.039; Pelletier JD, 1997, J HYDROL, V203, P198, DOI 10.1016/S0022-1694(97)00102-9; Peng S. Z., 2009, XITONG GONGCHENG LIL, V29, P173; Radziejewski M, 1997, J HYDROL, V200, P280, DOI 10.1016/S0022-1694(97)00024-3; Song L. C., 2003, DROUGHT DISASTER; Tang Q. Y., 2007, DPS DATA PROCESSING; Vicente-Serrano S, 2006, WATER RESOUR MANAG, V20, P37, DOI 10.1007/s11269-006-2974-8; Wang M. C., 2006, MACHINERY, V12, P71; Wang Y. J., 2007, AGR RES ARID AREAS, V5, P198; Wilhite D., 2000, DROUGHT GLOBAL ASSES; Wu H, 2007, INT J CLIMATOL, V27, P65, DOI 10.1002/joe.1371; Xu YP, 2011, J ZHEJIANG UNIV-SC A, V12, P483, DOI 10.1631/jzus.A1000450; Yang XH, 2009, INT J NONLIN SCI NUM, V10, P1595; Zhai LX, 2009, NAT HAZARDS, V49, P1, DOI 10.1007/s11069-008-9274-y; Zhang L, 2002, COMPUT METHOD APPL M, V191, P2873, DOI 10.1016/S0045-7825(01)00372-3; Zhou SS, 2010, IEEE IMAGE PROC, P1561, DOI 10.1109/ICIP.2010.5649922	49	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1024-123X			MATH PROBL ENG	Math. Probl. Eng.		2012									235929	10.1155/2012/235929		16	Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications	Engineering; Mathematics	954IH	WOS:000304939500001		
J	Dewan, S; Chakravarthy, S		Huang, T; Zeng, Z; Li, C; Leung, CS		Dewan, Sagar; Chakravarthy, Srinivasa			A System for Offline Character Recognition Using Auto-encoder Networks	NEURAL INFORMATION PROCESSING, ICONIP 2012, PT IV	Lecture Notes in Computer Science		English	Proceedings Paper	19th International Conference on Neural Information Processing (ICONIP)	NOV 11-15, 2012	Doha, QATAR	IEEE Computat Intelligence Soc, United Dev Co PSC, Qatar Petrochem Co, ExxonMobil, Texas A&M Univ Qatar & Asia Pacif Neural Network Assembly, European Neural Network Soc, Japanese Neural Network Soc, Qatar Petr, Int Neural Network Soc		Autoencoder Neural Networks; ANN; Deep Networks; Offline Telugu Character Recognition	ALGORITHM	We present a technique of using Deep Neural Networks (DNNs) for offline character recognition of Telugu characters. We construct DNNs by stacking Auto-encoders that are trained in a greedy layer-wise fashion in an unsupervised manner. We then perform supervised fine-tuning to train the entire network. We provide results on Consonant and Vowel Modifier Datasets using two and three hidden layer DNNs. We also construct an ensemble classifier to increase the classification performance further. We observe 94.25% accuracy for the two hidden layer network on Consonant data and 94.1% on Vowel Modifier Dataset which increases to 95.4% for Consonant and 94.8% for Vowel Modifier Dataset after combining classifiers to form an ensemble classifier of 4 different two hidden layer networks.	[Dewan, Sagar] Indian Inst Technol, Dept Elect Engn, Chennai 600036, Tamil Nadu, India	Dewan, S (reprint author), Indian Inst Technol, Dept Elect Engn, Chennai 600036, Tamil Nadu, India.	sagar.dewan@outlook.com; srinivasa.chakravarthy@gmail.com					Banashree NP, 2007, PROC WRLD ACAD SCI E, V20, P46; Bengio Y, 2007, ADV NEURAL INFORM PR; Erhan D, 2010, J MACH LEARN RES, V11, P625; Guo XJ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P192, DOI 10.1109/ICNC.2008.871; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ng A., 2011, UFLDL TUTORIAL NEURA; Pal U, 2004, PATTERN RECOGN, V37, P1887, DOI 10.1016/j.patcog.2004.02.003; Pal U., 2012, ACM T ASIAN LANGUAGE, V11, P1; Rajashekararadhya S.V., 2008, IEEE REG 10 C, P1; Vincent P, 2010, J MACH LEARN RES, V11, P3371	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-34478-7	LECT NOTES COMPUT SC			2012	7666						91	99				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BB6XA	WOS:000345091300012		
S	Han, L; Wilson, R; Hancock, E; Bai, L; Ren, P			IEEE	Han, Lin; Wilson, Richard; Hancock, Edwin; Bai, Lu; Ren, Peng			Sampling Graphs From a Probabilistic Generative Model	2012 21ST INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR 2012)	International Conference on Pattern Recognition		English	Proceedings Paper	21st International Conference on Pattern Recognition (ICPR)	NOV 11-15, 2012	Tsukuba, JAPAN	IAPR, Sci Council Japan, Inst Elect, Informat & Commun Engineers, Informat & Syst Soc, IEEE Comp Soc, AIST, Informat Proc Soc Japan, IEEE, Japan Soc Promot Sci, Telecommunicat Advancement Fdn, Tsukuba Tourist & Convent Assoc	Univ Tsukuba		ALGORITHM	In this paper we present a method of sampling from a probabilistic generative model for a set of graphs. Our method is based on the assumption that the nodes and edges of graphs arise under independent Bernoulli distributions. We sample graphs from the generative model according to the node and edge occurrence probabilities. We explain the construction of our generative model and then compute the node and edge occurrence probabilities which allow us to formulate a sampling procedure. We demonstrate experimentally to what extent the graphs sampled by our method reproduce the salient properties of the graphs in the original training sample.	[Han, Lin; Wilson, Richard; Hancock, Edwin; Bai, Lu] Univ York, York YO10 5DD, N Yorkshire, England	Han, L (reprint author), Univ York, York YO10 5DD, N Yorkshire, England.	hanlin@cs.york.ac.uk; wilson@cs.york.ac.uk; erh@cs.york.ac.uk; lu@cs.york.ac.uk; pengren@upc.edu.cn	Hancock, Edwin/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028			Ahuja N., 2007, ICCV, P1; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Erdos P., 1959, PUBL MATH-DEBRECEN, V6, P290; Estrada FJ, 2009, INT J COMPUT VISION, V85, P167, DOI 10.1007/s11263-009-0251-z; HAN L, 2011, LECT NOTES COMPUT SC, V7005, P133; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120; Nene S.A., 1996, CUCS00696; Ren P, 2011, IEEE T NEURAL NETWOR, V22, P233, DOI 10.1109/TNN.2010.2091969; Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125; Xiao B, 2009, PATTERN RECOGN, V42, P2589, DOI 10.1016/j.patcog.2008.12.029; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1051-4651		978-4-9906441-0-9; 978-1-4673-2216-4	INT C PATT RECOG			2012							1643	1646				4	Computer Science, Artificial Intelligence	Computer Science	BB5CC	WOS:000343660601180		
S	Hashmi, A; Lipasti, M		Madani, K; Correia, AD; Rosa, A; Filipe, J		Hashmi, Atif; Lipasti, Mikko			A Cortically Inspired Learning Model	COMPUTATIONAL INTELLIGENCE	Studies in Computational Intelligence		English	Proceedings Paper	2nd International Joint Conference on Computational Intelligence (IJCCI 2010)	OCT 24-26, 2010	Valencia, SPAIN			Cortical algorithms; Cortical columns; Invariant representation; Feedforward and feedback processing; Pruning; Automatic abstraction; Fault tolerance	FUNCTIONAL ARCHITECTURE; RECEPTIVE FIELDS; VISUAL-CORTEX; RECOGNITION; ALGORITHM	We describe a biologically plausible learning-model inspired by the structural and functional properties of the cortical columns present in the mammalian neocortex. The strength and robustness of our model is ascribed to its biologically plausible, uniformly structured, and hierarchically distributed processing units with their localized learning rules. By modeling cortical columns rather than individual neurons as our fundamental processing units, we get hierarchical learning networks that are computationally less demanding and better suited for studying higher cortical properties like independent feature detection, plasticity, etc. Another interesting attribute of our model is the use of feedback processing paths to generate invariant representation to robustly recognize variations of the same patterns and to determine the set of features sufficient for recognizing different patterns in the input dataset. We train and test our hierarchical networks using synthetic digit images as well as a subset of handwritten digit images obtained from the MNIST database. Our results show that our cortical networks use unsupervised feedforward processing as well as supervised feedback processing to robustly recognize handwritten digits.	[Hashmi, Atif; Lipasti, Mikko] Univ Wisconsin, Dept Elect & Comp Engn, Madison, WI 53706 USA	Hashmi, A (reprint author), Univ Wisconsin, Dept Elect & Comp Engn, 1415 Engn Dr, Madison, WI 53706 USA.	ahashmi@wisc.edu; mikko@engr.wise.edu					Aimone JB, 2009, NEURON, V61, P187, DOI 10.1016/j.neuron.2008.11.026; Arthur J., 2006, ADV NEURAL INFORM PR, V18, P75; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P493, DOI 10.1016/0893-6080(91)90045-7; Clopath C., 2007, P NEUR INF PROC SYST; DARPA, 2008, DARPA SYST NEUR AD P; Freeman WJ, 1996, INT J NEURAL SYST, V7, P473, DOI 10.1142/S0129065796000452; George D, 2005, IEEE IJCNN, P1812; Grill-Spector K, 1998, HUM BRAIN MAPP, V6, P316, DOI 10.1002/(SICI)1097-0193(1998)6:4<316::AID-HBM9>3.0.CO;2-6; Hawkins J., 2005, INTELLIGENCE; Hawkins J., 2006, HIERARCHICAL TEMPORA; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hirsch JA, 2006, CURR OPIN NEUROBIOL, V16, P377, DOI 10.1016/j.conb.2006.06.014; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; LeCun Y., 1998, MNIST DATABASE HANDW; Markram H., 2006, SC 2006, V53; Martinez T. M., 1993, INT C ART NEUR NETW, P427; Maw NN, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P927; Mountcastle V., 1978, MINDFUL BRAIN; Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701; MOUNTCASTLE VB, 1957, J NEUROPHYSIOL, V20, P408; Nicholls J. G., 2001, NEURON BRAIN; Peissig JJ, 2007, ANNU REV PSYCHOL, V58, P75, DOI 10.1146/annurev.psych.58.102904.190114; Rokni U, 2007, NEURON, V54, P653, DOI 10.1016/j.neuron.2007.04.030; Seung HS, 2003, NEURON, V40, P1063, DOI 10.1016/S0896-6273(03)00761-X; Sigala N, 2002, NATURE, V415, P318, DOI 10.1038/415318a; SWANSON LW, 1995, TRENDS NEUROSCI, V18, P471, DOI 10.1016/0166-2236(95)92766-J	27	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X		978-3-642-27533-3	STUD COMPUT INTELL			2012	399						373	388				16	Computer Science, Artificial Intelligence	Computer Science	BCC70	WOS:000309733800025		
J	Hu, XL; Qi, P; Zhang, B		Huang, T; Zeng, Z; Li, C; Leung, CS		Hu, Xiaolin; Qi, Peng; Zhang, Bo			Hierarchical K-Means Algorithm for Modeling Visual Area V2 Neurons	NEURAL INFORMATION PROCESSING, ICONIP 2012, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	19th International Conference on Neural Information Processing (ICONIP)	NOV 11-15, 2012	Doha, QATAR	IEEE Computat Intelligence Soc, United Dev Co PSC, Qatar Petrochem Co, ExxonMobil, Texas A&M Univ Qatar & Asia Pacif Neural Network Assembly, European Neural Network Soc, Japanese Neural Network Soc, Qatar Petr, Int Neural Network Soc		Neural network; Deep learning; Visual area; V1; V2	NATURAL SCENES; EMERGENCE	Computational studies about the properties of the receptive fields of neurons in the cortical visual pathway of mammals are abundant in the literature but most addressed neurons in the primary visual area (V1). Recently, the sparse deep belief network (DBN) was proposed to model the response properties of neurons in the V2 area. By investigating the factors that contribute to the success of the model, we find that a simple algorithm for data clustering, K-means algorithm can be stacked into a hierarchy to reproduce these properties of V2 neurons, too. In addition, it is computationally much more efficient than the sparse DBN.	[Hu, Xiaolin; Qi, Peng; Zhang, Bo] Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China	Hu, XL (reprint author), Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.	xiaolin.hu@gmail.com; pengrobertqi@163.com; dcszb@tsinghua.edu.cn	Hu, Xiaolin/K-2443-2013				Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Cadieu C, 2007, J NEUROPHYSIOL, V98, P1733, DOI 10.1152/jn.01265.2006; Coates A., 2011, P 14 INT C ART INT S; Ekanadham C, 2007, THESIS STANFORD U; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Karklin Y, 2009, NATURE, V457, P83, DOI 10.1038/nature07481; Karklin Yan, 2005, Neural Comput, V17, P397, DOI 10.1162/0899766053011474; Lee H., 2007, ADV NEURAL INFORM PR, V20; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Ranzato M., 2007, ADV NEURAL INFORM PR, V20; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Saxe A., 2011, ADV NEURAL INFORM PR, V24, P1971	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-34487-9	LECT NOTES COMPUT SC			2012	7665						373	381				9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BB6WY	WOS:000345089800046		
B	Huang, PS; Yang, JC; Hasegawa-Johnson, M; Liang, F; Huang, TS			International Speech Communications Association	Huang, Po-Sen; Yang, Jianchao; Hasegawa-Johnson, Mark; Liang, Feng; Huang, Thomas S.			Pooling Robust Shift-Invariant Sparse Representations of Acoustic Signals	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		sparse coding; pooling; acoustic event classification	CLASSIFICATION	In recent years, designing the coding and pooling structures in layered networks has been shown to be a useful method for learning high-level feature representations for visual data. Yet, such learning structures have not been extensively studied for audio signals. In this paper, we investigate different pooling strategies based on the sparse coding scheme and propose a temporal pyramid pooling method to extract discriminative and shift-invariant feature representations. We demonstrate the superiority of our new feature representation over traditional features on the acoustic event classification task.	[Huang, Po-Sen; Yang, Jianchao; Hasegawa-Johnson, Mark; Huang, Thomas S.] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL USA	Huang, PS (reprint author), Univ Illinois, Dept Elect & Comp Engn, Urbana, IL USA.	huang146@illinois.edu; jyang29@illinois.edu; jhasegaw@illinois.edu; liangf@illinois.edu; t-huang1@illinois.edu					Canton-Ferrer C., 2009, CVPR, P81; CLARKSON P, 1999, ACOUST SPEECH SIG PR, P585; Fletcher H, 1930, J ACOUST SOC AM, V1, P311, DOI 10.1121/1.1915186; Grosse R., 2007, UAI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang P.-S., 2011, FUSION, P1; Huang PS, 2011, INT CONF ACOUST SPEE, P349; Huang P.-S., 2011, HUM LIGHT VEH DET WO; Lazebnik S., 2006, CVPR, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Manzagol P. A., 2008, ISMIR; Slaney M., 1994, AUDITORY TOOLBOX; Smith E, 2005, NEURAL COMPUT, V17, P19, DOI 10.1162/0899766052530839; Smith EC, 2006, NATURE, V439, P978, DOI 10.1038/nature04485; Yang JC, 2009, PROC CVPR IEEE, P1794; Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958	16	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							2517	2520				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BFO97	WOS:000320827201184		
B	Jaitly, N; Nguyen, P; Senior, A; Vanhoucke, V			International Speech Communications Association	Jaitly, Navdeep; Patrick Nguyen; Senior, Andrew; Vanhoucke, Vincent			Application of Pretrained Deep Neural Networks to Large Vocabulary Speech Recognition	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		Deep Belief Networks; Acoustic Modeling; Artificial Neural Network; ANN/HMM		The use of Deep Belief Networks (DBN) to pretrain Neural Networks has recently led to a resurgence in the use of Artificial Neural Network - Hidden Markov Model (ANN/HMM) hybrid systems for Automatic Speech Recognition (ASR). In this paper we report results of a DBN-pretrained context-dependent ANN/HMM system trained on two datasets that are much larger than any reported previously with DBN-pretrained ANN/HMM systems - 5870 hours of Voice Search and 1400 hours of You Tube data. On the first dataset, the pretrained ANN/HMM system outperforms the best Gaussian Mixture Model - Hidden Markov Model (GMM/HMM) baseline, built with a much larger dataset by 3.7% absolute WER, while on the second dataset, it outperforms the GMM/HMM baseline by 4.7% absolute. Maximum Mutual Information (MMI) fine tuning and model combination using Segmental Conditional Random Fields (SCARF) give additional gains of 0.1% and 0.4% on the first dataset and 0.5% and 0.9% absolute on the second dataset.	[Jaitly, Navdeep] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada	Jaitly, N (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.	ndjaitly@cs.toronto.edu; drpng@google.com; andrewsenior@google.com; vanhoucke@google.com					Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; Dahl G. E., 2012, IEEE T AUDIO SPEECH; Dean J, 2008, COMMUN ACM, V51, P107, DOI 10.1145/1327452.1327492; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kingsbury B., P ICASSP 09, P3761; Mnih V., 2009, 004 U TOR DEP COMP S; Mohamed A., P ICASSP 11, P5060; Mohamed A., 2012, IEEE T AUDIO SPEECH, V99; Morgan N., P ICASSP 90, V1, P413; Povey D., P ICASSP 08, P4057; Seide F., 2011, INTERSPEECH, P437; Vanhoucke V., 2011, DEEP LEARN UNS FEAT, P272; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Zweig G., P ICASSP 11, P5044	16	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							2577	2580				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BFO97	WOS:000320827201199		
J	Ji, ZP; Huang, WT; Brumby, SP			IEEE	Ji, Zhengping; Huang, Wentao; Brumby, Steven P.			Learning Sparse Representation via a Nonlinear Shrinkage Encoder and a Linear Sparse Decoder	2012 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)/International Joint Conference on Neural Networks (IJCNN)/IEEE Congress on Evolutionary Computation (IEEE-CEC)/IEEE World Congress on Computational Intelligence (IEEE-WCCI)	JUN 10-15, 2012	Brisbane, AUSTRALIA	IEEE			ALGORITHM	Learning sparse representations for deep networks has drawn considerable research interest in recent years. In this paper, we present a novel framework to learn sparse representations via a generalized encoder-decoder architecture. The basic idea is to adopt a fast approximation to the iterative sparse coding solution and form an efficient nonlinear encoder to map an input to a sparse representation. A set of basis functions is then learned through the minimization of an energy function consisting of a sparseness prior and linear decoder constraints. Applying a greedy layer-wise learning scheme, this framework can be extended to more layers to learn deep networks. The proposed learning algorithm is also highly efficient as no iterative operations are required, and both batch and on-line learning are supported. Given the sparse representation and basis functions, an optimized decoding procedure is carried out to reconstruct and denoise the input signals. We evaluate our model on natural image patches to develop a dictionary of V1-like Gabor filters, and further show that basis functions in a higher layer (e.g., V2) combine the filters in a lower layer to generate more complex patterns to benefit the high-level tasks. We then use the sparse representations to recognize objects in two benchmark data sets (i.e., CIFAR-10 and NORB) via a linear SVM classifier, and demonstrate better or comparable recognition performances with respect to state-of-art algorithms. The image reconstruction of MNIST images and the restoration of corrupted versions are presented at the end.	[Ji, Zhengping] Los Alamos Natl Lab, Div Theoret, Los Alamos, NM 87545 USA	Ji, ZP (reprint author), Los Alamos Natl Lab, Div Theoret, T-5, Los Alamos, NM 87545 USA.	zji@lanl.gov; whuang21@jhmi.edu; brumby@lanl.gov					Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bengio Y, 2007, ADV NEURAL INFORM PR; Bo L, 2010, ADV NEURAL INFORM PR; Ciresan D., 2011, HIGHPERFORMANCE NEUR; Coates A., 2011, P INT C MACH LEARN; Engan K., 1999, IEEE INT C AC SPEECH; Gregor K., 2010, P INT C MACH LEARN; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Ji Z., 2011, P INT JOINT C NEUR N; Ji Z., 2008, P IEEE INT C DEV LEA; Kavukcuoglu K., 2009, P IEEE INT C COMP VI; Krizhevsky A., 2009, THESIS DEP COMPUTER; Larochelle H., 2009, P INT C MACH LEARN; Lazebnik S., 2006, P IEEE INT C COMP VI; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 2004, P IEEE INT C COMP VI; Lee H., 2008, ADV NEURAL INFORM PR, P873; Lee H., 2009, P INT C MACH LEARN; Lee H., 2007, ADV NEURAL INFORM PR, P1137; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; Masci J., 2011, P INT C ART NEUR NET; Nair V., 2009, ADV NEURAL INFORM PR; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Ranzato M., 2010, P IEEE INT C COMP VI; Ranzato M. A., 2006, ADV NEURAL INFORM PR; Ranzato M. A., 2007, P INT C ART INT STAT; Ranzato Marc'Aurelio, 2007, ADV NEURAL INFORM PR; Rao B. D., 2003, NEURAL COMPUT, V15, P349; Salakhutdinov R., 2009, P INT C ART INT STAT; Vincent P., 2008, P INT C MACH LEARN; Welling M., 2003, ADV NEURAL INFORM PR	33	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4673-1490-9	IEEE IJCNN			2012												8	Computer Science, Artificial Intelligence	Computer Science	BCA06	WOS:000309341303032		
J	Li, G; Zhu, HF; Cheng, G; Thambiratnam, K; Chitsaz, B; Yu, D; Seide, F			IEEE	Li, Gang; Zhu, Huifeng; Cheng, Gong; Thambiratnam, Kit; Chitsaz, Behrooz; Yu, Dong; Seide, Frank			CONTEXT-DEPENDENT DEEP NEURAL NETWORKS FOR AUDIO INDEXING OF REAL-LIFE DATA	2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012)			English	Proceedings Paper	IEEE Workshop on Spoken Language Technology (SLT)	DEC 02-05, 2012	Miami, FL	Inst Elect & Elect Engineers (IEEE), IEEE Signal Processing Soc		speech recognition; deep neural networks; deep learning; audio indexing		We apply Context-Dependent Deep-Neural-Network HMMs, or CD-DNN-HMMs, to the real-life problem of audio indexing of data across various sources. Recently, we had shown that on the Switchboard benchmark on speaker-independent transcription of phone calls, CD-DNN-HMMs with 7 hidden layers reduce the word error rate by as much as one-third, compared to discriminatively trained Gaussian-mixture HMMs, and by one-fourth if the GMM-HMM also uses fMPE features. This paper takes CD-DNN-HMM based recognition into a real-life deployment for audio indexing. We find that for our best speaker-independent CD-DNN-HMM, with 32k senones trained on 2000h of data, the one-fourth reduction does carry over to inhomogeneous field data (video podcasts and talks). Compared to a speaker-adaptive GMM system, the relative improvement is 18%, at very similar end-to-end runtime. In system building, we find that DNNs can benefit from a larger number of senones than the GMM-HMM; and that DNN likelihood evaluation is a sizeable runtime factor even in our wide-beam context of generating rich lattices: Cutting the model size by 60% reduces runtime by one-third at a 5% relative WER loss.	[Li, Gang; Zhu, Huifeng; Cheng, Gong; Seide, Frank] Microsoft Res Asia, Beijing 100080, Peoples R China	Li, G (reprint author), Microsoft Res Asia, 5 Danling St, Beijing 100080, Peoples R China.	ganl@microsoft.com; gocheng@microsoft.com; behroozc@microsoft.com; dongyu@microsoft.com; fseide@microsoft.com					Chen X., 2012, P INTERSPEECH; Dahl G., 2011, IEEE T SPEE IN PRESS; FRANCO H, 1994, COMPUT SPEECH LANG, V8, P211, DOI 10.1006/csla.1994.1010; Fritsch J., 1998, P ICASSP; Godfrey John J., 1997, SWITCHBOARD 1 RELEAS; Hinton G, 2010, 2010003 UTML TR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kingsbury B., 2009, P ICASSP; Meng S., 2010, P ICASSP; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Renals S., 1994, IEEE T SPEECH AU JAN; Rosenblatt F., 1961, PRINCIPLES NEURODYNA; Rumelhart D., 1986, NATURE, V323; Saul L. K., 1996, J ARTICIAL INTELLIGE, P61; Seide F., 2011, P ASRU WAIK VILL; Seide Frank, 2011, INTERSPEECH; Yu D., 2010, P NIPS WORKSH DEEP L; Yu P., 2008, P ACM SIGIR 2 WORKSH; Yu P., 2008, ICASSP	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-5126-3				2012							143	148				6	Engineering, Electrical & Electronic	Engineering	BEL18	WOS:000317182800025		
S	Liang, ZH; Zhang, G; Li, ZP; Yin, J; Fu, WB		Gao, J; Dubitzky, W; Wu, C; Liebman, M; Alhaij, R; Ungar, L; Christianson, A; Hu, X		Liang, Zhaohui; Zhang, Gang; Li, Ziping; Yin, Jian; Fu, Wenbin			Deep Learning for Acupuncture Point Selection Patterns based on Veteran Doctor Experience of Chinese Medicine	2012 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE WORKSHOPS (BIBMW)	IEEE International Conference on Bioinformatics and Biomedicine Workshop-BIBMW		English	Proceedings Paper	IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)	OCT 04-07, 2012	Philadelphia, PA	IEEE, IEEE Comp Soc (CS), Natl Sci Fdn (NSF), Omic Soft Corp, IEEE Comp Soc Tech Comm Bioinformat		deep learning; veteran doctor of Chinese medicine; knowledge discover; acupuncture point patterns; ICD-10		the inheritance of clinical experience of veteran doctors of Chinese medicine (CM) plays a key role in the development and effectiveness enhancement of Chinese medicine in the history. The clinical experience are classified as the patterns of disease diagnosis and Chinese medical Zheng diagnosis, the identification of core elements of Zheng, the treatment experience and relation of herbal medicine formulae, Zheng and disease, and the common law of diagnosis and treatment in real practice. The source of the experience mainly originates from literature and manuscripts of CM masters, which are being electronically recorded during the last two decades. As a result, it makes feasible to apply data mining to the knowledge discovery through the experience of veteran CM doctors. However, the current focus on this field is limited to the published literature such as journal papers, conference proceedings and textbooks, but the paper based manuscripts personally written by the veteran doctors are usually neglected. In this paper, we established a database for Dr Situ Ling, who is a deceased famous CM acupuncture master in southern China. The study objective is to discover the acupuncture point selection patterns which require profession knowledge and experience from senior CM doctors. It is believed these patterns are deposited as underlying knowledge with various middle level concepts that can be analyzed and discover by a serial of algorithms. Thus in this work, we formularized the patterns of acupuncture point selection as a learning task with deep architecture, which attempts to capture either existent or underlying concepts so as to simulate the planning process of the combined diagnosis of western medicine and Chinese medicine. The Restricted Boltzmann Machines (RBM) was used as the main model for deep learning to process to medical record data with international standard diagnosis (ICD-10) previously made by trained doctors. Then the ICD-10 based diagnosis dataset was introduced into our framework to enhance the concepts diversity. After applying this model, the learning accuracy based on the medical record data base of Dr Situ Ling was raised up to 75%. Thus this model can serve as a solution to discover the acupuncture point selection patterns of CM acupuncture veteran doctors. Furthermore, the data mining study model linked by international diagnosis standard (i.e. ICD-10), point selection patterns, and clinical symptoms will provide useful cues to reveal the essence of Zheng diagnosis through experience of CM veteran doctors.	[Liang, Zhaohui; Li, Ziping; Fu, Wenbin] Guangzhou Univ Chinese Med, Affiliated Hosp 2, Guangzhou 510120, Guangdong, Peoples R China	Fu, WB (reprint author), Guangzhou Univ Chinese Med, Affiliated Hosp 2, Guangzhou 510120, Guangdong, Peoples R China.	fuwenbin@139.com					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Chen J.W., 2011, CHINESE J MED LIB IN, V4, P42; Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu H., 2010, LIAONING J TRADITION, V37, P2144; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Ma H.X., 2012, CHINESE J EXPT TRADI, V18, P5; Tan Z.P., 2011, LIAONING J TRADITION, V38, P1276; Wang D.W., 2011, SHENZHEN J INTEGRATE, V21, P154; Wang Y.H., 2005, WORLD SCI TECHNOLOGY, V7, P98; Weston J., 2008, ICML 08, P1168; WHO, INT CLASS DIS ICD; Zhang R.S, 2008, WORLD SCI TECHNOLOGY, V10, P45	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2163-6966		978-1-4673-2746-6; 978-1-4673-2745-9	IEEE INT C BIO BIO W			2012												6	Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	BFL42	WOS:000320379600067		
J	Lopes, N; Ribeiro, B; Goncalves, J			IEEE	Lopes, Noel; Ribeiro, Bernardete; Goncalves, Joao			Restricted Boltzmann Machines and Deep Belief Networks on Multi-Core Processors	2012 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / International Joint Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary Computation (IEEE-CEC) / IEEE World Congress on Computational Intelligence (IEEE-WCCI)	JUN 10-15, 2012	Brisbane, AUSTRALIA	IEEE				Deep learning architecture models by contrast with shallow models draw on the insights of biological inspiration which has been a challenge since the inception of the idea of simulating the brain. In particular their (many) hierarchical levels of composition track the development of parallel implementation in an attempt to become accessibly fast. When it comes to performance enhancement Graphics Processing Units (GPU) have carved their own strength in machine learning. In this paper, we present an approach that relies mainly on three kernels for implementing both the Restricted Boltzmann Machines (RBM) and Deep Belief Networks (DBN) algorithms. Instead of considering the neuron as the smallest unit of computation each thread represents the connection between two (one visible and one hidden) neurons. Although conceptually it may seem weird, the rationale behind is to think of a connection as performing a simple function that multiplies the clamped input by its weight. Thus, we maximize the GPU workload avoiding idle cores. Moreover, we placed great emphasis on the kernels to avoid uncoalesced memory accesses as well as to take advantage of the shared memory to reduce global memory accesses. Additionally, our approach uses a step adaptive learning rate procedure which accelerates convergence. The approach yields very good speedups (up to 46x) as compared with a straightforward implementation when both GPU and CPU implementations are tested on the MINST database.	[Lopes, Noel; Ribeiro, Bernardete; Goncalves, Joao] Univ Coimbra, CISUC Ctr Informat & Syst, P-3000 Coimbra, Portugal	Lopes, N (reprint author), Univ Coimbra, CISUC Ctr Informat & Syst, P-3000 Coimbra, Portugal.	noel@ipg.pt; bribeiro@dei.uc.pt; jcgonc@student.dei.uc.pt					Almeida L., 1997, HDB NEURAL COMPUTATI, pC1; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Che S, 2008, J PARALLEL DISTR COM, V68, P1370, DOI 10.1016/j.jpdc.2008.05.014; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Lopes Noel, 2011, International Journal of Computer Information Systems and Industrial Management Applications, V3; Lopes N., 2010, HYBR INT SYST HIS 20, P229; Ranzato M., 2007, ADV NEURAL INFORM PR, V20; Roux N.L., 2010, NEURAL COMPUT, V22, P2192; Ryoo S, 2008, PPOPP'08: PROCEEDINGS OF THE 2008 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P73, DOI 10.1145/1345206.1345220; Swersky K., 2010, INF THEOR APPL WORKS	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4673-1490-9	IEEE IJCNN			2012												7	Computer Science, Artificial Intelligence	Computer Science	BCA06	WOS:000309341300069		
S	Lv, G			Atlantis Press	Lv, Gang			Deep learning in tiny image classification	2012 INTERNATIONAL CONFERENCE ON INTELLIGENCE SCIENCE AND INFORMATION ENGINEERING	Advances in Intelligent Systems Research		English	Proceedings Paper	International Conference on Intelligence Science and Information Engineering (ISIE 2012)	AUG 25-26, 2012	Lushan, PEOPLES R CHINA	Wuhan Univ, Wuhan Polytechn Univ		deep learning; CNN; brief networks; character recognition; image classification		This paper analyses two deep network architectures: CNN and DBN, tiny image classification experiments had been done on MNIST and Cifar-10. CNN's error rate is 0.98% and 33.13%, better than DBN's 1.44% and 47.96%. CNN's error rate on Cifar-10 is 33.13% better than 35.16% which is published before, with a improvement of 2 points, furthermore, no preprocessing is taken in our experiments. Experiments show that deep learning can effectively improve the network' s recognition rate, but compared to increase the network's depth simply, increase layer's size or change the connection way between nodes has more salient improvement.	Jinhua Radio & Televis Univ, Coll Technol, Jinhua, Zhejiang, Peoples R China	Lv, G (reprint author), Jinhua Radio & Televis Univ, Coll Technol, Jinhua, Zhejiang, Peoples R China.	lg2578@tom.com					Ackley H., 1985, COGNITIVE SCI, V9, P147; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Bengio Y., 2009, FDN TRENDS MACH LEAR, V2, P1; Bengio Y., 2007, NIPS; Bergstra T., 2010, PYTH SCI COMP C; Dahl G., 2011, IEEE T AUDIO SPEECH, V20, P30; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Lv G., 2011, COMP INT DES ISCID H; Poultney C., 2006, NIPS NEW YORK	11	0	0	ATLANTIS PRESS	PARIS	29 AVENUE LAVMIERE, PARIS, 75019, FRANCE	1951-6851		978-90-78677-53-6	ADV INTEL SYS RES			2012	20						5	8				4	Computer Science, Artificial Intelligence	Computer Science	BCK72	WOS:000310490100002		
J	Nadig, AS; Potetz, B			IEEE	Nadig, Ashwini Shikaripur; Potetz, Brian			A Hierarchical Bayesian Model for Pattern Recognition	2012 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUN 10-15, 2012	Brisbane, AUSTRALIA				INDEPENDENT COMPONENT ANALYSIS; DISCRIMINANT-ANALYSIS; FACE RECOGNITION; KERNEL; EIGENFACES; ALGORITHM; IMAGES	The success of automated classification hinges on the choice of the representation of the data. Much research has focused on feature extraction techniques that can identify highly informative representations of a dataset. In this paper, we adapt for the purposes of classification a hierarchical Bayesian model developed by Karklin and Lewicki to model the neurophysiological properties of the cortex. The hierarchical nature of the cortex enables it to capture successively abstract and nonlinear features within its stimulus. We show empirically that the properties of natural images that motivated this model are also present in non-homogenous data typical of classification tasks. We also propose a discriminative training method for the model that enables it to preferentially select features that best distinguish the output class labels. Finally, the performance of the model was tested on handwritten digit recognition and face recognition. We found that classification using features extracted from the model achieved greater performance than classification using the nonlinear features of Kernel Fisher Discriminant analysis alone.	[Nadig, Ashwini Shikaripur; Potetz, Brian] Univ Kansas, Dept Elect Engn & Comp Sci, Lawrence, KS 66045 USA	Nadig, AS (reprint author), Univ Kansas, Dept Elect Engn & Comp Sci, Lawrence, KS 66045 USA.	ashvini@ku.edu; potetz@ittc.ku.edu					Aizerman A, 1964, AUTOMAT REM CONTR, V25, P821; Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Coates A., 2010, NIPS WORKSH DEEP LEA, P1; Duda R, 2001, PATTERN CLASSIFICATI; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Karklin Y, 2009, NATURE, V457, P83, DOI 10.1038/nature07481; Karklin Yan, 2005, Neural Comput, V17, P397, DOI 10.1162/0899766053011474; Karklin Y., THESIS CARNEGIE MELL; Larochelle H., 2008, ICML, P536; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu Q., 2002, FGR 02, P197; Perkins S, 2000, P SOC PHOTO-OPT INS, V4120, P52, DOI 10.1117/12.403635; Phillips P. J., 1996, FERET FACE RECOGNITI, P4; Ratsch G., 1999, NEURAL NETWORKS SIGN, V9, P41, DOI DOI 10.1109/NNSP.1999.788121; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Simoncelli E, 1997, P 31 AS C SIGN SYST, P673; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Yang M., 2002, FGR 02, P215; Zhang BC, 2004, LECT NOTES COMPUT SC, V3332, P802	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4673-1490-9	IEEE IJCNN			2012												8	Computer Science, Artificial Intelligence	Computer Science	BCA06	WOS:000309341303061		
S	Nguyen, NT; Wang, YC; Li, HS; Liu, X; Han, Z			IEEE	Nam Tuan Nguyen; Wang, Yichuan; Li, Husheng; Liu, Xin; Han, Zhu			Extracting Typical Users' Moving Patterns Using Deep Learning	2012 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM)	IEEE Global Telecommunications Conference (Globecom)		English	Proceedings Paper	IEEE Global Communications Conference (GLOBECOM)	DEC 03-07, 2012	Anaheim, CA	IEEE			WIRELESS NETWORKS; PREDICTION; ALGORITHM	When GPS devices are widely integrated into smart phones, researchers stand a big chance of collecting massive location information, that is necessary in studying users' moving behavior and predicting the next location of the users. Once the next location of a user can be determined, it can serve as input for many applications, such as location based service, scheduling users access in a mobile network or even home automation. One important task in predicting the next location is to identify typical users' moving patterns. In this paper, we propose a novel method to extract the patterns using deep learning. Experiment results show significant performance improvement of the proposed method compared to the classical principal component analysis method.	[Nam Tuan Nguyen; Han, Zhu] Univ Houston, ECE Dept, Houston, TX USA	Nguyen, NT (reprint author), Univ Houston, ECE Dept, Houston, TX USA.						Abu-Ghazaleh H, 2010, IEEE T VEH TECHNOL, V59, P788, DOI 10.1109/TVT.2009.2037507; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Calabrese F., 2009, ENVIRON PLANN B, V36; Calabrese F., 2011, IEEE PERVAS COMPUT, V9, P78; Clarkson B., 2002, THESIS MIT; Eagle N, 2009, BEHAV ECOL SOCIOBIOL, V63, P1057, DOI 10.1007/s00265-009-0739-0; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Katsaros D, 2009, IEEE WIREL COMMUN, V16, P56, DOI 10.1109/MWC.2009.4907561; Le J. K., 2006, P 7 ACM INT S MOB HO, P85; Lee JW, 2004, J SYST SOFTWARE, V73, P481, DOI 10.1016/j.jss.2003.09.021; Peng WC, 2000, PROC INT CONF PARAL, P573	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1930-529X		978-1-4673-0921-9; 978-1-4673-0920-2	GLOB TELECOMM CONF			2012							5410	5414				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BGD24	WOS:000322375105130		
J	Ogino, M; Hikita, M; Fuke, S; Asada, M			IEEE	Ogino, Masaki; Hikita, Mai; Fuke, Sawa; Asada, Minoru			Generation of condition-dependent reaching movements based on layered associative networks	2012 IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL)			English	Proceedings Paper	IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL)	NOV 07-09, 2012	San Diego, CA	IEEE			BODY SCHEMA; TOOL USE; LANGUAGE	This paper proposes a hierarchical network that enables an information processing nesting structure for tool-use that represents a relationship between a hand end-effector and a tool target when reaching for the tool, and an additional relationship between the tip of the tool end-effector and an object target after taking the tool. The network consists of associative networks whose lower layer networks associate the multimodal information under various conditions. The higher layer network associates the temporal order of the lower network states. A simulation experiment shows that the proposed network successfully generates reaching movements regardless of the conditions.	[Ogino, Masaki] Kansai Univ, Fac Informat, Takatsuki, Osaka 5691095, Japan	Ogino, M (reprint author), Kansai Univ, Fac Informat, 2-1-1 Ryozenji, Takatsuki, Osaka 5691095, Japan.	ogino@res.kutc.kansai-u.ac.jp; hikita@er.ams.eng.osaka-u.ac.jp; fuke@er.ams.eng.osaka-u.ac.jp; asada@ams.eng.osaka-u.ac.jp					Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702; Baddeley A, 2000, TRENDS COGN SCI, V4, P417, DOI 10.1016/S1364-6613(00)01538-2; Cowan N., 2005, WORKING MEMORY CAPAC; GREENFIELD PM, 1991, BEHAV BRAIN SCI, V14, P531; Head H, 1911, BRAIN, V34, P102, DOI 10.1093/brain/34.2-3.102; Higuchi S, 2009, NEUROREPORT, V20, P1376, DOI 10.1097/WNR.0b013e3283315570; Hikita M, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2041; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Iriki A, 1996, NEUROREPORT, V7, P2325; Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008; Maxim S. I., 2005, BODY IMAGE BODY SCHE; Molnar-Szakacs I, 2006, NEUROIMAGE, V33, P923, DOI 10.1016/j.neuroimage.2006.07.035; Nabeshima C, 2010, ADV ROBOTICS, V24, P687, DOI 10.1163/016918610X493543; Nishide S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5376, DOI 10.1109/IROS.2009.5354655; Oztop E, 2006, ACTION TO LANGUAGE VIA THE MIRROR NEURON SYSTEM, P397, DOI 10.1017/CBO9780511541599.013; Tani J, 2003, IEEE T SYST MAN CY A, V33, P481, DOI 10.1109/TSMCA.2003.809171; Wolpert DM, 1998, NEURAL NETWORKS, V11, P1317, DOI 10.1016/S0893-6080(98)00066-5	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-4963-5				2012												6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BDK55	WOS:000313591500005		
J	Ren, JSJ; Wang, W; Wang, JW; Liao, S			IEEE	Ren, Jimmy S. J.; Wang, Wei; Wang, Jiawei; Liao, Stephen			An Unsupervised Feature Learning Approach to Improve Automatic Incident Detection	2012 15TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC)	IEEE International Conference on Intelligent Transportation Systems-ITSC		English	Proceedings Paper	15th International IEEE Conference on Intelligent Transportation Systems (ITSC)	SEP 16-19, 2012	Anchorage, AK					sophisticated automatic incident detection (AID) technology plays a key role in contemporary transportation systems. Though many papers were devoted to study incident classification algorithms, few study investigated how to enhance feature representation of incidents to improve AID performance. In this paper, we propose to use an unsupervised feature learning algorithm to generate higher level features to represent incidents. We used real incident data in the experiments and found that effective feature mapping function can be learnt from the data crosses the test sites. With the enhanced features, detection rate (DR), false alarm rate (FAR) and mean time to detect (MTTD) are significantly improved in all of the three representative cases. This approach also provides an alternative way to reduce the amount of labeled data, which is expensive to obtain, required in training better incident classifiers since the feature learning is unsupervised.	[Ren, Jimmy S. J.; Wang, Wei] City Univ Hong Kong, Dept Informat Syst, Hong Kong, Hong Kong, Peoples R China	Ren, JSJ (reprint author), City Univ Hong Kong, Dept Informat Syst, Hong Kong, Hong Kong, Peoples R China.	sjren2@student.cityu.edu.hk; wewang8@student.cityu.edu.hk; wangjw2@mail.ustc.edu.cn; issliao@cityu.edu.hk					Abdulhai B., 1999, Transportation Research Part C (Emerging Technologies), V7C, DOI 10.1016/S0968-090X(99)00022-4; Abdulhai B., 1999, TRANSPORT RES REC, V1678, P277, DOI 10.3141/1678-33; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Chen SY, 2009, EXPERT SYST APPL, V36, P10976, DOI 10.1016/j.eswa.2009.02.039; Cheu R. L., 2003, P IEEE INT C INT TRA, P238; Cheu RL, 1995, TRANSPORT RES C-EMER, V3, P371, DOI 10.1016/0968-090X(95)00016-C; Coates Adam, 2011, PROCEEDINGS OF INTER; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jin X, 2002, TRANSPORT RES C-EMER, V10, P121, DOI 10.1016/S0968-090X(01)00007-9; Lee Honglak, 2007, PROCEEDINGS OF NEURA; Lee Honglak, 2009, PROCEEDINGS OF NEURA; Luk James, 2010, TECHNICAL REPORT OF; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Ranzato M., 2007, PROCEEDINGS OF NEURA; Roy P, 2003, TRANSPORT RES REC, P96; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Socher Richard, 2011, PROCEEDINGS OF INTER; Stewart P., 2006, TECHNICAL REPORT OF; Vincent P., 2008, PROCEEDINGS OF INTER; Yuan F, 2003, TRANSPORT RES C-EMER, V11, P309, DOI 10.1016/S0968-090X(03)00020-2; Zhou Zhou, 2010, Proceedings 2010 International Symposium on Intelligence Information Processing and Trusted Computing (IPTC 2010), DOI 10.1109/IPTC.2010.97	22	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-0009		978-1-4673-3063-3	IEEE INT C INTELL TR			2012							172	177				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Transportation Science & Technology	Automation & Control Systems; Computer Science; Engineering; Transportation	BDC45	WOS:000312599600029		
B	Saon, G; Kingsbury, B			International Speech Communications Association	Saon, George; Kingsbury, Brian			Discriminative feature-space transforms using deep neural networks	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		speech recognition; deep neural networks	SPEECH RECOGNITION	We present a deep neural network (DNN) architecture which learns time-dependent offsets to acoustic feature vectors according to a discriminative objective function such as maximum mutual information (MMI) between the reference words and the transformed acoustic observation sequence. A key ingredient in this technique is a greedy layer-wise pretraining of the network based on minimum squared error between the DNN outputs and the offsets provided by a linear feature-space MMI (FMMI) transform. Next, the weights of the pretrained network are updated with stochastic gradient ascent by backpropagating the MMI gradient through the DNN layers. Experiments on a 50 hour English broadcast news transcription task show a 4% relative improvement using a 6-layer DNN transform over a state-of-the-art speaker-adapted system with FMMI and model-space discriminative training.	[Saon, George; Kingsbury, Brian] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Saon, G (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	gsaon@us.ibm.com; bedk@us.ibm.com					Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Grezl F., 2007, P ICASSP; Hermansky H., 2000, P ICASSP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kingsbury B., 2012, P INTERSPEECH; Martens J., 2010, P ICML; Povey D, 2005, P INT, P2977; Povey D, 2005, INT CONF ACOUST SPEE, P961; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; Saon G, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P920; Seide F., 2011, P INTERSPEECH	12	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							14	17				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BFO97	WOS:000320827200004		
J	Singh, L; Chetty, G; Sharma, D		Huang, T; Zeng, Z; Li, C; Leung, CS		Singh, Lavneet; Chetty, Girija; Sharma, Dharmendra			Using Hybrid Neural Networks for Identifying the Brain Abnormalities from MRI Structural Images	NEURAL INFORMATION PROCESSING, ICONIP 2012, PT V	Lecture Notes in Computer Science		English	Proceedings Paper	19th International Conference on Neural Information Processing (ICONIP)	NOV 11-15, 2012	Doha, QATAR	IEEE Computat Intelligence Soc, United Dev Co PSC, Qatar Petrochem Co, ExxonMobil, Texas A&M Univ Qatar & Asia Pacif Neural Network Assembly, European Neural Network Soc, Japanese Neural Network Soc, Qatar Petr, Int Neural Network Soc		Deep Machine Learning; Extreme Machine Learning; MRI; PCA		In this study, we present the investigations being pursued in our research laboratory on magnetic resonance images (MRI) of various states of brain by extracting the most significant features, and to classify them into normal and abnormal brain images. We propose a novel method based on deep and extreme machine learning on wavelet transform to initially decompose the images, and then use various features selection and search algorithms to extract the most significant features of brain from the MRI images. By using a comparative study with different classifiers to detect the abnormality of brain images from publicly available neuro-imaging dataset, we found that a principled approach involving wavelet based feature extraction, followed by selection of most significant features using PCA technique, and the classification using deep and extreme machine learning based classifiers results in a significant improvement in accuracy and faster training and testing time as compared to previously reported studies.	[Singh, Lavneet; Chetty, Girija; Sharma, Dharmendra] Univ Canberra, Fac Informat Sci & Engn, Canberra, ACT 2601, Australia	Singh, L (reprint author), Univ Canberra, Fac Informat Sci & Engn, Canberra, ACT 2601, Australia.	Lavneet.singh@canberra.edu.au; Girija.chetty@canberra.edu.au; Dharmendra.sharma@canberra.edu.au					Abdolmaleki P, 1997, CANCER LETT, V118, P69, DOI 10.1016/S0304-3835(97)00233-4; Anurag M., 2012, P IEEE WORLD C COMP; Cocosco CA, 2003, MED IMAGE ANAL, V7, P513, DOI 10.1016/S1361-8415(03)00037-9; Fletcher H.L.M., 2011, ARTIF INTELL, V21, P43; Gorunescu F, 2007, PROC WRLD ACAD SCI E, V25, P427; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Kara S, 2007, EXPERT SYST APPL, V32, P632, DOI 10.1016/j.eswa.2006.01.043; Lavneet S., 2012, LNCS; Lavneet S., 2012, LNCS BIOINFORMATICS; Lin M.B., 2005, NEUROCOMPUTING, V68, P306; Maitra M., 2007, MED ENG PHYS, DOI [10.1016/j.medengphy.06,009, DOI 10.1016/J.MEDENGPHY.06,009]; Rosenbaum T, 1999, BRAIN DEV-JPN, V21, P268, DOI 10.1016/S0387-7604(99)00024-8; Sandeep C, 2006, BIOMED SIGNAL PROCES, V1, P86; Serre D., 2002, MATRICES THEORY APPL	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-34500-5	LECT NOTES COMPUT SC			2012	7667						465	472				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BB6XC	WOS:000345092300055		
J	Szymanski, L; McCane, B			IEEE	Szymanski, Lech; McCane, Brendan			Deep, super-narrow neural network is a universal classifier	2012 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / International Joint Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary Computation (IEEE-CEC) / IEEE World Congress on Computational Intelligence (IEEE-WCCI)	JUN 10-15, 2012	Brisbane, AUSTRALIA	IEEE				Deep architecture models are known to be conducive to good generalisation for certain types of classification tasks. Existing unsupervised and semi-supervised training methods do not explain why and when deep internal representations will be effective. We investigate the fundamental principles of representation in deep architectures by devising a method for binary classification in multi-layer feed forward networks with limited breadth. We show that, given enough layers, a super-narrow neural network, with two neurons per layer, is capable of shattering any separable binary dataset. We also show that datasets that exhibit certain type of symmetries are better suited for deep representation and may require only few hidden layers to produce desired classification.	[Szymanski, Lech; McCane, Brendan] Univ Otago, Dept Comp Sci, Dunedin, New Zealand	Szymanski, L (reprint author), Univ Otago, Dept Comp Sci, POB 56, Dunedin, New Zealand.	lechszym@cs.otago.ac.nz; mccane@cs.otago.ac.nz					Anthony M., 1999, NEURAL NETWORK LEARN; Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Erhan D, 2010, J MACH LEARN RES, V11, P625; Erhan D, 2009, P 12 INT C ART INT S, P153; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Ilya Sutskever G. E. H., 2008, NEURAL COMPUT, V20, P2629; Larochelle H., 2007, P 24 INT C MACH LEAR, V227, P473; Minsky M., 1969, PERCEPTRONS INTRO CO; Nicolas Le Roux Y. B., 2010, NEURAL COMPUT, V22, P2192; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4673-1490-9	IEEE IJCNN			2012												8	Computer Science, Artificial Intelligence	Computer Science	BCA06	WOS:000309341301013		
J	Szymanski, L; McCane, B			IEEE	Szymanski, Lech; McCane, Brendan			Push-pull separability objective for supervised layer-wise training of neural networks	2012 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / International Joint Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary Computation (IEEE-CEC) / IEEE World Congress on Computational Intelligence (IEEE-WCCI)	JUN 10-15, 2012	Brisbane, AUSTRALIA	IEEE			RECOGNITION	Deep architecture neural networks have been shown to generalise well for many classification problems, however, outside the empirical evidence, it is not entirely clear how deep representation benefits these problems. This paper proposes a supervised cost function for an individual layer in a deep architecture classifier that improves data separability. From this measure, a training algorithm for a multi-layer neural network is developed and evaluated against backpropagation and deep belief net learning. The results confirm that the proposed supervised training objective leads to appropriate internal representation with respect to the classification task, especially for datasets where unsupervised pre-conditioning is not effective. Separability of the hidden layers offers new directions and insights in the quest to illuminate the black box model of deep architectures.	[Szymanski, Lech; McCane, Brendan] Univ Otago, Dept Comp Sci, Dunedin, New Zealand	Szymanski, L (reprint author), Univ Otago, Dept Comp Sci, POB 56, Dunedin, New Zealand.	lechszym@cs.otago.ac.nz; mccane@cs.otago.ac.nz					Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bishop CM, 2006, PATTERN RECOGNITION; Erhan D, 2010, J MACH LEARN RES, V11, P625; Erhan D, 2009, P 12 INT C ART INT S, P153; Frank A, 2010, UCI MACHINE LEARNING; Hadsell R., 2006, P COMP VIS PATT REC; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 2004, PROC CVPR IEEE, P97; Rasmussen C. E., 2006, MATLAB CODE MINIMIZA; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Scholkopf B., 2001, LEARNING KERNELS SUP; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4673-1490-9	IEEE IJCNN			2012												8	Computer Science, Artificial Intelligence	Computer Science	BCA06	WOS:000309341300004		
J	Tamilselvan, P; Wang, YB; Wang, PF			IEEE	Tamilselvan, Prasanna; Wang, Yibin; Wang, Pingfeng			Deep Belief Network Based State Classification for Structural Health Diagnosis	2012 IEEE AEROSPACE CONFERENCE	IEEE Aerospace Conference Proceedings		English	Proceedings Paper	IEEE Aerospace Conference	MAR 03-10, 2012	Big Sky, MT	IEEE, AIAA, Phmsoc, AESS		Fault diagnosis; artificial intelligence in diagnostic classification; deep belief networks	ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINES; SELF-ORGANIZING MAP; LEARNING ALGORITHM; FAULT-DIAGNOSIS; PROPAGATION	Effective health diagnosis provides multifarious benefits such as improved safety, improved reliability and reduced costs for the operation and maintenance of complex engineered systems. This paper presents a novel multi-sensor health diagnosis method using Deep Belief Networks (DBN). The DBN has recently become a popular approach in machine learning for its promised advantages such as fast inference and the ability to encode richer and higher order network structures. The DBN employs a hierarchical structure with multiple stacked Restricted Boltzmann Machines and works through a layer by layer successive learning process. The proposed multi-sensor health diagnosis methodology using the DBN based state classification can be structured in three consecutive stages: first, defining health states and preprocessing the sensory data for DBN training and testing; second, developing DBN based classification models for the diagnosis of predefined health states; third, validating DBN classification models with testing sensory dataset. The performance of health diagnosis using DBN based health state classification is compared with support vector machine technique and demonstrated with aircraft wing structure health diagnostics and aircraft engine health diagnosis using 2008 PHM challenge data.	[Tamilselvan, Prasanna; Wang, Yibin; Wang, Pingfeng] Wichita State Univ, Wichita, KS 67260 USA	Tamilselvan, P (reprint author), Wichita State Univ, 1845 Fairmount St, Wichita, KS 67260 USA.	pxtamilselvan@wichita.edu; yxwang5@wichita.edu; pingfeng.wang@wichita.edu	Wang, Pingfeng/D-3764-2011	Wang, Pingfeng/0000-0002-2160-4917			Abbasion S, 2007, MECH SYST SIGNAL PR, V21, P2933, DOI 10.1016/j.ymssp.2007.02.003; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; ALGUINDIGUE IE, 1993, IEEE T IND ELECTRON, V40, P209, DOI 10.1109/41.222642; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Booth C, 1998, NEUROCOMPUTING, V23, P97, DOI 10.1016/S0925-2312(98)00064-2; Breikin T, 2005, 16 IFAC WORLD C; Coit DW, 2000, IIE TRANS, V32, P1161, DOI 10.1080/07408170008967470; Dekker R, 1996, RELIAB ENG SYST SAFE, V51, P229, DOI 10.1016/0951-8320(95)00076-3; Ebeling C. E., 1997, INTRO RELIABILITY MA; Elsayed EA, 2000, INT J PROD RES, V38, P1953, DOI 10.1080/002075400188438; Gebraeel N., 2002, INTELLIGENT ENG SYST, V12, P543; Geramifard O, 2010, 8 IEEE INT C CONTR A, P1618; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang RQ, 2007, MECH SYST SIGNAL PR, V21, P193, DOI 10.1016/j.ymssp.2005.11.008; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Li Y, 1999, TRIBOL T, V42, P385, DOI 10.1080/10402009908982232; Licht T., 2003, AM SOC MECH ENG DYN, V71, P1059; MARTIN KF, 1994, INT J MACH TOOL MANU, V34, P527, DOI 10.1016/0890-6955(94)90083-3; Saimurugan M., 2010, EXPERT SYSTEMS APPL; Samanta B, 2004, MECH SYST SIGNAL PR, V18, P625, DOI 10.1016/S0888-3270(03)00020-7; Saxena A., 2008, PROGNOSTICS HLTH MAN; Wang P., 2010, ANN C PROGN HLTH MAN; Wong MLD, 2006, MECH SYST SIGNAL PR, V20, P593, DOI 10.1016/j.ymssp.2005.01.008; Yang BS, 2005, MECH SYST SIGNAL PR, V19, P371, DOI 10.1016/j.myssp.2004.06.002; Zhang L, 2010, EXPERT SYST APPL, V37, P6077, DOI 10.1016/j.eswa.2010.02.118; Zhao XL, 2007, SMART MATER STRUCT, V16, P1208, DOI 10.1088/0964-1726/16/4/032	28	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1095-323X		978-1-4577-0557-1	AEROSP CONF PROC			2012												11	Engineering, Aerospace	Engineering	BBZ12	WOS:000309105303086		
B	Tamilselvan, P; Wang, PF			ASME	Tamilselvan, Prasanna; Wang, Pingfeng			A HYBRID INFERENCE APPROACH FOR HEALTH DIAGNOSTICS WITH UNEXAMPLED FAULTY STATES	PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2012, VOL 3, PTS A AND B			English	Proceedings Paper	ASME International Design Engineering Technical Conferences/Computers Information in Engineering Conference	AUG 12-15, 2012	Chicago, IL	ASME, Design Engn Div, ASME, Comp & Informat Engn Div			ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINES; SELF-ORGANIZING MAP; POWER TRANSFORMERS; IN-SERVICE; CLASSIFICATION; PROPAGATION	System health diagnostics provides diversified benefits such as improved safety, improved reliability and reduced costs for the operation and maintenance of engineered systems. Successful health diagnostics requires the knowledge of system failures. However, with an increasing complexity it is extraordinarily difficult to have a well-tested system so that all potential faulty states can be realized and studied at product testing stage. Thus, real time health diagnostics requires automatic detection of unexampled faulty states through the sensory signals to avoid sudden catastrophic system failures. This paper presents a hybrid inference approach (MA) for structural health diagnosis with unexampled faulty states, which employs a two-fold inference process comprising of preliminary statistical learning based anomaly detection and artificial intelligence based health state classification for real time condition monitoring. The HIA is able to identify and isolate the unexampled faulty states through interactively detecting the deviation of sensory data from the known health states and forming new health states autonomously. The proposed approach takes the advantages of both statistical approaches and artificial intelligence based techniques and integrates them together in a unified diagnosis framework. The performance of proposed MA is demonstrated with a power transformer and roller bearing health diagnosis case studies, where Mahalanobis distance serves as a representative statistical inference approach.	[Tamilselvan, Prasanna; Wang, Pingfeng] Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67260 USA	Wang, PF (reprint author), Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67260 USA.	pxtamilselvan@wichita.edu; pingfeng.wang@wichita.edu					ALGUINDIGUE IE, 1993, IEEE T IND ELECTRON, V40, P209, DOI 10.1109/41.222642; ALLAN D, 1992, IEEE T ELECTR INSUL, V27, P578, DOI 10.1109/14.142722; Alsabti K., 1997, ELECT ENG COMPUTER S; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Booth C, 1998, NEUROCOMPUTING, V23, P97, DOI 10.1016/S0925-2312(98)00064-2; Breikin T, 2005, 16 IFAC WORLD C; Chandola V., 2009, ACM COMPUTING SURVEY, V41; Dekker R, 1996, RELIAB ENG SYST SAFE, V51, P229, DOI 10.1016/0951-8320(95)00076-3; Ebeling C. E., 1997, INTRO RELIABILITY MA; Ge M, 2004, MECH SYST SIGNAL PR, V18, P143, DOI 10.1016/S0888-3270(03)00071-2; Geramifard O, 2010, 8 IEEE INT C CONTR A, P1618; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1007/s10462-004-4304-y; Huang RQ, 2007, MECH SYST SIGNAL PR, V21, P193, DOI 10.1016/j.ymssp.2005.11.008; Leibfried T, 1998, IEEE COMPUT APPL POW, V11, P36, DOI 10.1109/67.694934; Li Y, 1999, TRIBOL T, V42, P385, DOI 10.1080/10402009908982232; Licht T., 2003, AM SOC MECH ENG DYN, V71, P1059; MARTIN KF, 1994, INT J MACH TOOL MANU, V34, P527, DOI 10.1016/0890-6955(94)90083-3; Pawar PM, 2007, MECH SYST SIGNAL PR, V21, P2212, DOI 10.1016/j.ymssp.2006.09.006; Qiu H, 2003, ADV ENG INFORM, V17, P127, DOI 10.1016/j.aei.2004.08.001; Rivera HL, 2000, IEEE J SEL TOP QUANT, V6, P788, DOI 10.1109/2944.892619; Saimuragan M., 2010, EXPERT SYSTEMS APPL; Samanta B, 2004, MECH SYST SIGNAL PR, V18, P625, DOI 10.1016/S0888-3270(03)00020-7; Saxena A, 2007, APPL SOFT COMPUT, V7, P441, DOI 10.1016/j.asoc.2005.10.001; Srinivasan S, 2007, IRAN J ELECT COMPUTE, V6, P62; Tamilselvan P, 2011, ASME 2011 INT DES EN; Wang P., 2010, ANN C PROGN HLTH MAN; Wong MLD, 2006, MECH SYST SIGNAL PR, V20, P593, DOI 10.1016/j.ymssp.2005.01.008; Yang BS, 2005, MECH SYST SIGNAL PR, V19, P371, DOI 10.1016/j.myssp.2004.06.002; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525	30	0	0	AMER SOC MECHANICAL ENGINEERS	NEW YORK	THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA			978-0-7918-4502-8				2012							349	360				12	Engineering, Industrial; Engineering, Mechanical	Engineering	BA4KY	WOS:000335932800034		
B	Uria, B; Murray, I; Renals, S; Richmond, K			International Speech Communications Association	Uria, Benigno; Murray, Iain; Renals, Steve; Richmond, Korin			Deep Architectures for Articulatory Inversion	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		Articulatory inversion; deep neural network; deep belief network; deep regression network; pretraining	SPEECH SYNTHESIS; HMM	We implement two deep architectures for the acoustic-articulatory inversion mapping problem: a deep neural network and a deep trajectory mixture density network. We find that in both cases, deep architectures produce more accurate predictions than shallow architectures and that this is due to the higher expressive capability of a deep model and not a consequence of adding more adjustable parameters. We also find that a deep trajectory mixture density network is able to obtain better inversion accuracies than smoothing the results of a deep neural network. Our best model obtained an average root mean square error of 0.885 mm on the MNGU0 test dataset.	[Uria, Benigno; Murray, Iain] Univ Edinburgh, Inst Adapt & Neural Computat, Edinburgh EH8 9YL, Midlothian, Scotland	Uria, B (reprint author), Univ Edinburgh, Inst Adapt & Neural Computat, Edinburgh EH8 9YL, Midlothian, Scotland.	b.uria@ed.ac.uk; i.murray@ed.ac.uk; s.renals@ed.ac.uk; korin@cstr.ed.ac.uk					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bishop C., 1994, NCRG94004 AST U; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Grezl F, 2011, P IEEE ASRU; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hofer G, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P454; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; King S, 2007, J ACOUST SOC AM, V121, P723, DOI 10.1121/1.2404622; Ling ZH, 2009, IEEE T AUDIO SPEECH, V17, P1171, DOI 10.1109/TASL.2009.2014796; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; PERKELL JS, 1992, J ACOUST SOC AM, V92, P3078, DOI 10.1121/1.404204; Poort K. L., 1995, THESIS MIT; Richmond K, 2003, COMPUT SPEECH LANG, V17, P153, DOI 10.1016/S0885-2308(03)00005-6; Richmond K., 2006, P INTERSPEECH; Richmond K., 2011, P INTERSPEECH; Richmond K., 2009, P INTERSPEECH, P2835; Seide F, 2011, P IEEE ASRU; STRUBE HW, 1980, J ACOUST SOC AM, V68, P1071, DOI 10.1121/1.384992; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Zhang L, 2008, IEEE SIGNAL PROC LET, V15, P245, DOI 10.1109/LSP.2008.917004	23	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							866	869				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BFO97	WOS:000320827200217		
J	Wang, XY; Han, M			IEEE	Wang, Xinying; Han, Min			Multivariate Chaotic Time Series Prediction based on Hierarchic Reservoirs	PROCEEDINGS 2012 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC)	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man, and Cybernetics (SMC)	OCT 14-17, 2012	Seoul, SOUTH KOREA	IEEE Systems, Man, and Cybernetics Soc (SMC), IEEE, Korea Univ, Korean Soc Cognit Sci (KSCS), Korean Inst Informat Scientists and Engineers Soc Computat Intelligence (KSCI), Hi Seoul, Korea Tourism Org, Asian Off Aerosp Res and Dev (AOARD), Natl Res Fdn Korea (NRF), World Class Univ, Korea Univ, WCU Res Div Brain and Cognit Engn		Reservoirs; multivariate; chaotic time series; prediction; hierarchic structure	ECHO STATE NETWORKS; NEURONS	Chaotic time series prediction has received considerable attention in the last few years. Although many studies have been conducted in the field, there is little attention focused on multivariate time series prediction. Considering this problem, the Hierarchic Reservoirs (HR) prediction model is proposed for multivariate chaotic time series prediction in this paper. The basic idea is using multiple reservoirs to predict multivariate chaotic time series directly without using phase space reconstruction. Each single reservoir of the hierarchic reservoirs prediction model extract the features of a time series of the multivariate chaotic time series. Then, the features are composed to represent the target value of the time series. Two simulation examples, prediction of Lorenz chaotic time series and prediction of sunspots and the Yellow River annual runoff time series are conducted to demonstrate the effectiveness of the proposed method.	[Wang, Xinying; Han, Min] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Liaoning, Peoples R China	Wang, XY (reprint author), Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Liaoning, Peoples R China.	xinying@mail.dlut.edu.cn; minhan@dlut.edu.cn	Wang, Xinying/C-8214-2012				Bengio Y., 2007, LARGE SCALE KERNEL M, V34; Chatzis S., 2011, PATTERN RECOGN, V45, P570; Chatzis SP, 2011, IEEE T NEURAL NETWOR, V22, P1435, DOI 10.1109/TNN.2011.2162109; Gallicchio C, 2011, NEURAL NETWORKS, V24, P440, DOI 10.1016/j.neunet.2011.02.002; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holzmann G, 2010, NEURAL NETWORKS, V23, P244, DOI 10.1016/j.neunet.2009.07.004; Jaeger H., 2007, TECHNICAL REPORT; Jaegera H, 2007, NEURAL NETWORKS, V20, P335, DOI 10.1016/j.neunet.2007.04.016; Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277; Lin XW, 2011, EXPERT SYST APPL, V38, P11347, DOI 10.1016/j.eswa.2011.03.001; Lukosevicius M., 2009, COMPUTER SCI REV, V3, P127, DOI DOI 10.1016/J.COSREV.2009.03.005; Lukosevicius M., 2010, TECHNICAL REPORT; Ozturk MC, 2007, NEURAL COMPUT, V19, P111, DOI 10.1162/neco.2007.19.1.111; Pascanu R, 2011, NEURAL NETWORKS, V24, P199, DOI 10.1016/j.neunet.2010.10.003; Prokhorov D, 2005, IEEE IJCNN, P1463; Reinhart R., 2011, EUR S ART NEUR NETW, P27; Rodan A, 2011, IEEE T NEURAL NETWOR, V22, P131, DOI 10.1109/TNN.2010.2089641; Rodan A., 2010, NEURAL NETWORKS IEEE, P1; Shi ZW, 2007, IEEE T NEURAL NETWOR, V18, P359, DOI 10.1109/TNN.2006.885113; Shutin D., 2011, NEURAL COMPUT, P1; Song QS, 2010, NEUROCOMPUTING, V73, P2177, DOI 10.1016/j.neucom.2010.01.015; Steil JJ, 2007, NEURAL NETWORKS, V20, P353, DOI 10.1016/j.neunet.2007.04.011; Takens F, 1981, DYNAMICAL SYSTEMS TU, P366; Venayagamoorthy GK, 2009, NEURAL NETWORKS, V22, P861, DOI 10.1016/j.neunet.2009.03.021; Xia Y., 2010, NEURAL NETWORKS IEEE, P1	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4673-1714-6	IEEE SYS MAN CYBERN			2012							384	388				5	Computer Science, Cybernetics; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BEJ33	WOS:000316869200065		
B	Wang, YX; Wang, DL			International Speech Communications Association	Wang, Yuxuan; Wang, DeLiang			Boosting Classification Based Speech Separation Using Temporal Dynamics	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		Monaural speech separation; temporal dynamics; structured perceptron; deep neural networks	ALGORITHM; NOISE	Significant advances in speech separation have been made by formulating it as a classification problem, where the desired output is the ideal binary mask (IBM). Previous work does not explicitly model the correlation between neighboring time-frequency units and standard binary classifiers are used. As one of the most important characteristics of speech signal is its temporal dynamics, the IBM contains highly structured, instead of, random patterns. In this study, we incorporate temporal dynamics into classification by employing structured output learning. In particular, we use linear-chain structured perceptrons to account for the interactions of neighboring labels in time. However, the performance of structured perceptrons largely depends on the linear separability of features. To address this problem, we employ pre-trained deep neural networks to automatically learn effective feature functions for structured perceptrons. The experiments show that the proposed system significantly outperforms previous IBM estimation systems.	[Wang, Yuxuan; Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	Wang, YX (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	wangyuxu@cse.ohio-state.edu; dwang@cse.ohio-state.edu					Collins M., 2002, P EMNLP; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Han K., 2011, P IEEE ICASSP, P5212; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603; Mysore GJ, 2011, INT CONF ACOUST SPEE, P17; Seltzer ML, 2004, SPEECH COMMUN, V43, P379, DOI 10.1016/j.specom.2004.03.006; Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12; Wang Y., 2011, TR37 OH STAT U DEP C	10	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							1526	1529				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BFO97	WOS:000320827200382		
J	Picheny, M; Nahamoo, D; Goel, V; Kingsbury, B; Ramabhadran, B; Rennie, SJ; Saon, G				Picheny, M.; Nahamoo, D.; Goel, V.; Kingsbury, B.; Ramabhadran, B.; Rennie, S. J.; Saon, G.			Trends and advances in speech recognition	IBM JOURNAL OF RESEARCH AND DEVELOPMENT			English	Article							ELASTIC NET; MODEL; ALGORITHM; SELECTION; NOISE	One of the earliest successful applications of machine-learning techniques to pattern recognition was the application of information-theoretic principles to speech recognition. Previous approaches relied heavily on expert input through the painstaking analysis of data to relate speech signals to the word sequences that produced them. Such methodologies were completely displaced by casting the speech recognition problem in a probabilistic framework by modeling the joint probability distribution of speech signals and word sequences. At the beginning of the 21st century, the amount of data and computation to train and build models has increased exponentially, and the emergence of new machine-learning algorithms and methodologies has opened new vistas in approaching complex pattern recognition problems. This is enabled by a new set of machine-learning techniques referred to as graphical models, with computationally tractable training algorithms. Closely related are neural-network modeling techniques, and there has been a resurgence of interest in the application of neural-network concepts, such as deep networks to speech recognition. The explosion of data has caused the development of new ways to capture the key features in massive amounts of data using efficient methods deploying exemplar-based sparse representations. Lastly, all of these different approaches can be tied together in a principled fashion using another variation of graphical models: an exponential model framework. This paper describes the current state of the art in speech recognition systems and highlights the developments that are expected to produce major breakthroughs in our ability to automatically recognize speech using computers.	[Picheny, M.; Nahamoo, D.; Goel, V.; Kingsbury, B.; Ramabhadran, B.; Rennie, S. J.; Saon, G.] IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Picheny, M (reprint author), IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	picheny@us.ibm.com; nahamoo@us.ibm.com; vgoel@us.ibm.com; bedk@us.ibm.com; bhuvana@us.ibm.com; sjrennie@us.ibm.com; gsaon@us.ibm.com					Bahl L. R., 1978, P IEEE INT C AC SPEE, V3, P418; Bahl L. R., 1994, U.S. Patent, Patent No. [5 280 562, 5280562]; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179; BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; BAHL LR, 1974, IEEE T INFORM THEORY, V20, P284, DOI 10.1109/TIT.1974.1055186; Baker J. K., 1979, P SPRING C AC SOC AM, P547; Bakis Raimo, 2000, U.S. Patent, Patent No. 6023673; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y, 2001, ADV NEUR IN, V13, P932; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bilmes J., 2002, P ICASSP, V4, P3916; Bocchieri E., 1993, P ICASSP, V2, P692; Bridle J. S., 1991, P ICASSP, P277, DOI 10.1109/ICASSP.1991.150331; Brown P. F., 1990, Computational Linguistics, V16; Carmi A., 2009, ABCS APPROXIMATE BAY; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Cooke M, 2010, COMPUT SPEECH LANG, V24, P1, DOI 10.1016/j.csl.2009.02.006; Cover T. M., 1991, ELEMENTS INFORM THEO; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; DAVIS KH, 1952, J ACOUST SOC AM, V24, P637, DOI 10.1121/1.1906946; Deng L, 2004, IEEE T SPEECH AUDI P, V12, P133, DOI 10.1109/TSA.2003.820201; Deselaers T., 2007, P INT, P2093; De Wachter M, 2007, IEEE T AUDIO SPEECH, V15, P1377, DOI 10.1109/TASL.2007.894524; Fiscus J. G., 1997, P IEEE WORKSH AUT SP, P347; Frey B. J., 2001, P NIPS, P1165; G Saon., 2000, IEEE INT C AC SPEECH, V2, P1129; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Gales MJF, 1996, IEEE T SPEECH AUDI P, V4, P352, DOI 10.1109/89.536929; Gemmeke Jort F, 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, DOI 10.1109/ICASSP.2010.5495580; Ghahramani Z., 1995, ADV NEURAL INFORM PR, P472; Godl V., 2009, P INT BRIGHT UK, P1423; Goel V., 2010, P INT MAK JAP, P1345; GOPALAKRISHNAN PS, 1991, IEEE T INFORM THEORY, V37, P107, DOI 10.1109/18.61108; Grezl F., 2007, P IEEE INT C AC SPEE, V4, P757; Gunawardana A., 2005, P INTERSPEECH, P1117; Hermansky H, 2000, P ICASSP, V3, P1635; Hershey JR, 2010, COMPUT SPEECH LANG, V24, P45, DOI 10.1016/j.csl.2008.11.001; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Hwang M., 2007, P IEEE AUT SPEECH RE, P490; Johansen F. T., 1996, P ICSLP PHIL PA, VI, P498, DOI 10.1109/ICSLP.1996.607163; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kanevsky D., 2004, P ICASSP MAY, P821; Kanevsky D, 2010, P INT, P2842; Kingsbury B., 2011, P IEEE ICASSP, P4672; KINGSBURY B, 2009, P ICASSP, P3761; Konig Y., 1996, THESIS U CALIFORNIA; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kuo HKJ, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P327, DOI 10.1109/ASRU.2009.5373470; Lafferty J. D., 2001, ICML, P282; Lamel L. F., 1986, P DARPA SPEECH REC W, P100; Lauritzen S.L., 1996, GRAPHICAL MODELS; Lee C.-H., 2004, P LECT MAST SPEECH S; Leggetter C.J., 1994, P INT C SPOK LANG PR, P451; Li J, 2000, IEEE T SIGNAL PROCES, V48, P517; Li Q, 2010, BAYESIAN ANAL, V5, P151, DOI 10.1214/10-BA506; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Lippmann RP, 1997, SPEECH COMMUN, V22, P1, DOI 10.1016/S0167-6393(97)00021-6; Livescu K., 2003, P EUR GEN SWITZ, P2529; MORENO PJ, 1996, P ICASSP, P733; MORGAN N, 1995, IEEE SIGNAL PROC MAG, V12, P25; NADAS A, 1989, IEEE T ACOUST SPEECH, V37, P1495, DOI 10.1109/29.35387; Nahamoo D., 2008, SEM SPEECH TECHN IBM; Neal R., 1993, CRGTR931 U TOR DEP C; Povey D., 2008, P ICASSP, P4057; POVEY D, 2005, P ICASSP 05, V1, P961, DOI 10.1109/ICASSP.2005.1415275; Ranzato M., 2008, P C ADV NEUR INF PRO, V20, P1185; Rennie Steven J, 2009, Proceedings of the 2009 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU 2009), DOI 10.1109/ASRU.2009.5373446; Rennie S. J., 2009, P IEEE INT C AC SPEE, P3845; Rennie SJ, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.938081; Sainath T., 2011, P IEEE ICASSP PRAG C, P4492; SAINATH T, 2010, P INTERSPEECH, P2254; Sainath T. N., 2011, P IEEE ASRU WORKSH H; Sainath T. N., 2010, P IEEE ICASSP PRAG, P4492; Sainath Tara N, 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, DOI 10.1109/ICASSP.2010.5495638; Saon G., 2011, P IEEE ICASSP PRAG C, P5056; Seeger M., 2003, THESIS U EDINBURGH E; SHOLTZ PN, 1962, J ACOUST SOC AM, V34, P1, DOI 10.1121/1.1909006; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Valtchev V, 1997, SPEECH COMMUN, V22, P303, DOI 10.1016/S0167-6393(97)00029-0; Varga A.P., 1990, P ICASSP, P845; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wainwright Martin J, 2008, Foundations and Trends in Machine Learning, V1, DOI 10.1561/2200000001; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zweig Geoffrey, 2009, Proceedings of the 2009 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU 2009), DOI 10.1109/ASRU.2009.5372916; Zweig G, 2003, COMPUT SPEECH LANG, V17, P173, DOI 10.1016/S0885-2308(03)00007-X; Zweig G., 2010, P INTERSPEECH SEPT, P2858	88	0	1	IBM CORP	ARMONK	1 NEW ORCHARD ROAD, ARMONK, NY 10504 USA	0018-8646	2151-8556		IBM J RES DEV	IBM J. Res. Dev.	SEP-OCT	2011	55	5							2	10.1147/JRD.2011.2163277		18	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	908PA	WOS:000301501100011		
J	Wu, YN				Wu, Ying Nian			Data Augmentation, Internal Representation, and Unsupervised Learning	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Editorial Material									Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Wu, YN (reprint author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	ywu@stat.ucla.edu					Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Wu YN, 2010, INT J COMPUT VISION, V90, P198, DOI 10.1007/s11263-009-0287-0	3	0	0	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	SEP	2011	20	3					581	583		10.1198/jcgs.2011.203b		3	Statistics & Probability	Mathematics	835YP	WOS:000296073500003		
J	Eslami, SMA; Williams, CKI		Hoey, J; McKenna, S; Trucco, E		Eslami, S. M. Ali; Williams, Christopher K. I.			Factored Shapes and Appearances for Parts-based Object Understanding	PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011			English	Proceedings Paper	22nd British Machine Vision Conference	AUG 29-SEP 02, 2011	Dundee, SCOTLAND		Univ Dundee		IMAGE; SEGMENTATION; RECOGNITION	We present a novel generative framework for learning parts-based representations of object classes. Our model, Factored Shapes and Appearances (FSA), employs a highly factored representation to reason about appearance and shape variability across datasets of images. We propose Markov Chain Monte Carlo sampling schemes for efficient inference and learning, and evaluate the model on a number of datasets. Here we consider datasets that exhibit large amounts of variability, both in the shapes of objects in the scene, and in their appearances. We show that the FSA model extracts meaningful parts from training data, and that its parameters and representation can be used to perform a range of tasks, including object parsing, segmentation and fine-grained categorisation.	[Eslami, S. M. Ali; Williams, Christopher K. I.] Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland	Eslami, SMA (reprint author), Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland.	s.m.eslami@sms.ed.ac.uk; ckiw@inf.ed.ac.uk					Alexe B, 2010, LECT NOTES COMPUT SC, V6315, P380, DOI 10.1007/978-3-642-15555-0_28; Arora Himanshu, 2007, IEEE C COMP VIS PATT, P1; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037//0033-295X.94.2.115; Borenstein Eran, 2004, CVPR WORKSH PERC ORG; BOYKOV YY, 2001, 8 IEEE INT C COMP VI, V1, P105; Brand M, 1999, ADV NEUR IN, V11, P723; Cemgil Taylan, 2005, IEEE C COMP VIS PATT, P1158; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Fei-Fei L, 2004, IEEE C COMP VIS PATT; Fergus R, 2003, PROC CVPR IEEE, P264; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Frey BJ, 2003, PROC CVPR IEEE, P45; Graham Daniel, 1998, FACE RECOGNITION THE, V163, P446; He XM, 2006, LECT NOTES COMPUT SC, V3951, P338; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jimenez Manuel Marin, 2010, INT C PATT REC 2010, P979; Jojic N, 2009, PROC CVPR IEEE, P2044; Jojic N, 2004, PROC CVPR IEEE, P212; Kannan Anitha, 2006, ADV NEURAL INFORM PR, V19, P657; Kapoor A, 2006, LECT NOTES COMPUT SC, V3953, P302; Kumar Pawan, 2005, IEEE C COMP VIS PATT, P18; Le Roux Nicolas, 2010, MSRTR20107; Leibe B., 2004, ECCV WORKSH STAT LEA; Murray I., 2010, JMLR W CP, V9, P541; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Ross DA, 2006, J MACH LEARN RES, V7, P2369; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Williams CKI, 2004, NEURAL COMPUT, V16, P1039, DOI 10.1162/089976604773135096; Winn J, 2005, IEEE I CONF COMP VIS, P756	29	0	0	B M V A PRESS	GUILDFORD	49A ELMSIDE ONSLOW VILLAGE, GUILDFORD, SURREY GU2 5SX, ENGLAND							2011										10.5244/C.25.18		12	Computer Science, Artificial Intelligence	Computer Science	BB8CJ	WOS:000346360200021		
J	Ji, ZP; Huang, WT; Kenyon, G; Bettencourt, LMA			IEEE	Ji, Zhengping; Huang, Wentao; Kenyon, Garrett; Bettencourt, Luis M. A.			Hierarchical Discriminative Sparse Coding via Bidirectional Connections	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst			RECEPTIVE-FIELDS; NATURAL SCENES; REPRESENTATION; DICTIONARIES; ALGORITHM; CORTEX; NEURONS; IMAGES; CODE	Conventional sparse coding learns optimal dictionaries of feature bases to approximate input signals; however, it is not favorable to classify the inputs. Recent research has focused on building discriminative sparse coding models to facilitate the classification tasks. In this paper, we develop a new discriminative sparse coding model via bidirectional flows. Sensory inputs (from bottom-up) and discriminative signals (supervised from top-down) are propagated through a hierarchical network to form sparse representations at each level. The l(0)-constrained sparse coding model allows highly efficient online learning and does not require iterative steps to reach a fixed point of the sparse representation. The introduction of discriminative top-down information flows helps to group reconstructive features belonging to the same class and thus to benefit the classification tasks. Experiments are conducted on multiple data sets including natural images, handwritten digits and 3-D objects with favorable results. Compared with unsupervised sparse coding via only bottom-up directions, the two-way discriminative approach improves the recognition performance significantly.	[Ji, Zhengping; Bettencourt, Luis M. A.] Los Alamos Natl Lab, Div Theoret T 5, Los Alamos, NM USA	Ji, ZP (reprint author), Los Alamos Natl Lab, Div Theoret T 5, Los Alamos, NM USA.	jizhengp@gmail.com; hwtsch@gmail.com; garkenyon@gmail.com; lmbettencourt@gmail.com					Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Baddeley R, 1997, P ROY SOC B-BIOL SCI, V264, P1775; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bradley D. M., 2009, ADV NEURAL INFORM PR, V21, P113; Candes E., 2005, TECHNICAL REPORT CAL; Chen S, 1998, SIAM J SCI COMPUT, V1, P33; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Engan K., 1999, IEEE INT C AC SPEECH; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Ji Zhengping, 2011, IEEE T INTELL TRANSP, V99, P1; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2008, ADV NEURAL INFORM PR, P873; Lee H., 2007, ADV NEURAL INFORM PR, P1137; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; Mairal J., 2009, ADV NEURAL INFORM PR, P1033; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Pati Y. C., 1993, 27 AS C SIGN SYST CO; Ranzato M. A., 2007, ADV NEURAL INFORM PR, P1185; Rehn M, 2007, J COMPUT NEUROSCI, V22, P135, DOI 10.1007/s10827-006-0003-9; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; YOUNG MP, 1992, SCIENCE, V256, P1327, DOI 10.1126/science.1598577	28	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-9636-5				2011							2844	2851				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541202143		
J	Krys, S; Jankowski, S		Romaniuk, RS		Krys, Sebastian; Jankowski, Stanislaw			Extended Hierarchical Temporal Memory for Visual Object Tracking	PHOTONICS APPLICATIONS IN ASTRONOMY, COMMUNICATIONS, INDUSTRY, AND HIGH-ENERGY PHYSICS EXPERIMENTS 2011	Proceedings of SPIE		English	Proceedings Paper	Conference on Photonics Applications in Astronomy, Communications, Industry, and High-Energy Physics Experiments	MAY 23-29, 2011	Wilga, POLAND	Inst Elect Syst, Fac Elect & Informat Technol, Warsaw Univ Technol, Photon Soc Poland (PSP), Polish Acad Sci, Comm Elect & Telecommun, European Coordinat Accelerator R&D (EU FP7) (EuCARD), IEEE Poland Sect, Polish Comm Optoelect SEP (PKOpto)		Hierarchical temporal memory; robotics; tracking; computer vision; neural networks; artificial intelligence		A system for simultaneous multi-obstacle recognition and tracking is proposed. Based on the novel Hierarchical Temporal Memory algorithm, it is design for application in vision problems but generally not constrained to it. Thanks to its modular and mostly parallel architecture it can be easily implemented in distributed environment attaining significant computation speed and thus it is suited for real-time processing tasks like visual data processing in mobile robotics. Derived from standard neural network paradigm the system can extract information concerning position, relative speed and type of an obstacle in a dynamically changing environment. It can be easily enhanced for basic prediction tasks.	[Krys, Sebastian; Jankowski, Stanislaw] Warsaw Univ Technol, Inst Elect Syst, PL-00665 Warsaw, Poland	Krys, S (reprint author), Warsaw Univ Technol, Inst Elect Syst, Ul Nowowiejska 15-19, PL-00665 Warsaw, Poland.	S.Krys@stud.elka.pw.edu.pl; sjank@ise.pw.edu.pl					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bianchini M, 2005, NEURAL NETWORKS, V18, P1040, DOI 10.1016/j.neunet.2005.07.003; Carpenter G. A., HDB BRAIN THEORY NEU, P87; Chua L., 1988, IEEE T CIRCUITS SYST, V35; DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903; Diligenti M, 2001, PATTERN RECOGN, V34, P2049, DOI 10.1016/S0031-3203(00)00127-8; George D., 2007, HTM LEARNING ALGORIT; GROSSBERG S, 1987, Cognitive Science, V11, P23, DOI 10.1016/S0364-0213(87)80025-3; Hawk ins J., 2007, HIERARCHICAL TEMPORA; Hespanha JP, 2004, EFFICIENT MATLAB ALG; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1984, TRCMUCS84119 DEP COM; Malis E., 2002, ENSIETA NAVAL SHIP D; Russel S.J., 2003, PRENTICE HALL SERIES; Thrun S., 2005, PROBABILISTIC ROBOTI; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355	16	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-81948-582-3	PROC SPIE			2011	8008								80081C	10.1117/12.907004		9	Engineering, Electrical & Electronic; Optics; Physics, Applied	Engineering; Optics; Physics	BXX77	WOS:000297520000047		
B	Lo, C; Chow, P			ACM/SIGDA	Lo, Charles; Chow, Paul			Building a Multi-FPGA Virtualized Restricted Boltzmann Machine Architecture Using Embedded MPI	FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS			English	Proceedings Paper	19th Annual ACM International Symposium on Field-Programmable Gate Arrays	FEB 27-MAR 01, 2011	Monterey, CA	ACM SIGDA		Restricted Boltzmann Machines; Neural Network Hardware; FPGA; High Performance Computing	GENERATORS	Several FPGA architectures exist for accelerating Restricted Boltzmann Machines (RBMs). However, the network size for most is limited by the amount of available on-chip memory. Therefore, many FPGAs are required to implement very large networks for use in real-world applications. A virtualized design is able to time-multiplex the hardware resources and handle much larger networks but suffers a performance penalty due to the context switch. In this paper, we present a number of improvements to a virtualized FPGA architecture for RBMs. First, we take advantage of 16-bit arithmetic to pack larger networks onto a chip. Second, a custom DMA engine is designed to reduce the performance impact of the large amount of memory transactions. Finally, the architecture is scaled to multiple FPGAs to gain additional performance through coarse grain parallelism. The design effort required to implement these changes is minimized through the use of an embedded MPI framework. The architecture, tested on a Berkeley Emulation Engine 3 platform running at 100 Mhz, achieves a speed of 12.563 GCUPS on a 8192x8192 network.	[Lo, Charles; Chow, Paul] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 3G4, Canada	Lo, C (reprint author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 3G4, Canada.	locharl1@eecg.toronto.edu; pc@eecg.toronto.edu					Chang C, 2005, IEEE DES TEST COMPUT, V22, P114, DOI 10.1109/MDT.2005.30; Davis J. D., 2009, BEE3 REVITALIZING CO; Freund Y, 1991, ADV NEURAL INFORM PR, V4, P912; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kim S., 2010, P 2010 18 IEEE INT S, P201; KIM SK, 2009, P 19 INT C FIELD PRO, P367; LEcuyer P, 1996, MATH COMPUT, V65, P203, DOI 10.1090/S0025-5718-96-00696-5; LELY D, 2009, P 19 INT C FIELD PRO, P168; Le Ly D, 2010, IEEE T NEURAL NETWOR, V21, P1780, DOI 10.1109/TNN.2010.2073481; LELY D, 2009, P ACM SIGDA INT S FI, P73; MAYRAZ G, 2002, ANALYSIS, V24, P189; Moerland P., 1997, HDB NEURAL COMPUTATI; Raina R., 2009, P 26 ANN INT C MACH, P873; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Saldana M., 2008, P 2 INT WORKSH HIGH, P1; Srinivasan A, 2003, PARALLEL COMPUT, V29, P69, DOI 10.1016/S0167-8191(02)00163-1; XILINX, 2008, MULTIPORT MEMORY CON	17	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-4503-0554-9				2011							189	198				10	Engineering, Electrical & Electronic	Engineering	BVB04	WOS:000290931400031		
J	Ranzato, M; Susskind, J; Mnih, V; Hinton, G			IEEE	Ranzato, Marc'Aurelio; Susskind, Joshua; Mnih, Volodymyr; Hinton, Geoffrey			On Deep Generative Models with Applications to Recognition	2011 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 20-25, 2011	Colorado Springs, CO	IEEE				The most popular way to use probabilistic models in vision is first to extract some descriptors of small image patches or object parts using well-engineered features, and then to use statistical learning tools to model the dependencies among these features and eventual labels. Learning probabilistic models directly on the raw pixel values has proved to be much more difficult and is typically only used for regularizing discriminative methods. In this work, we use one of the best, pixel-level, generative models of natural images - a gated MRF - as the lowest level of a deep belief network (DBN) that has several hidden layers. We show that the resulting DBN is very good at coping with occlusion when predicting expression categories from face images, and it can produce features that perform comparably to SIFT descriptors for discriminating different types of scene. The generative ability of the model also makes it easy to see what information is captured and what is lost at each level of representation.	[Ranzato, Marc'Aurelio; Mnih, Volodymyr; Hinton, Geoffrey] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada	Ranzato, M (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.	ranzato@cs.toronto.edu; josh@mplab.ucsd.edu; vmnih@cs.toronto.edu; hinton@cs.toronto.edu					Bay H, 2008, COMPUTER VISION IMAG; Bosch A., 2007, CIVR; Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177; Dalal N., 2005, CVPR; DENG J, 2009, CVPR; EASEL B, 2005, CV IMAGE UNDERSTANDI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kanade T., 2000, INT C AUT FAC GEST R, P46; Kavukcuoglu K., 2009, CVPR; Larochelle H., 2008, ICML; Lazebnik S., 2006, CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, P ICML; LITTLEWORT G, 2004, C COMP VIS PATT REC, V5, P80; Lowe D. G., 2004, IJCV; Mnih V., 2009, 2009004 UTML TR DEP; Raina R., 2007, ICML; Ranzato M., 2010, NIPS, P3; Schmidt U., 2010, CVPR; Simoncelli EP, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P431, DOI 10.1016/B978-012119792-6/50089-9; Susskind J. M., 2010, TORONTO FACE DATABAS; TIELEMAN T, 2009, ICML; Vincent P., 2008, ICML; Wright J., 2008, IEEE T PATTERN ANAL; ZHU S, 1997, PAMI, P1236	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4577-0393-5	PROC CVPR IEEE			2011												8	Computer Science, Artificial Intelligence	Computer Science	BXB85	WOS:000295615803018		
S	Reichert, DP; Series, P; Storkey, AJ		Honkela, T; Duch, W; Girolami, M; Kaski, S		Reichert, David P.; Series, Peggy; Storkey, Amos J.			A Hierarchical Generative Model of Recurrent Object-Based Attention in the Visual Cortex	ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2011, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	21st International Conference on Artificial Neural Networks, ICANN 2011	JUN 14-17, 2011	Espoo, FINLAND	Aalto Univ Sch Sci, Dept Informat & Comp Sci	Aalto Univ Sch Sci		RECOGNITION	In line with recent work exploring Deep Boltzmann Machines (DBMs) as models of cortical processing, we demonstrate the potential of DBMs as models of object-based attention, combining generative principles with attentional ones. We show: (1) How inference in DBMs can be related qualitatively to theories of attentional recurrent processing in the visual cortex; (2) that deepness and topographic receptive fields are important for realizing the attentional state; (3) how more explicit attentional suppressive mechanisms can be implemented, depending crucially on sparse representations being formed during learning.	[Reichert, David P.; Series, Peggy; Storkey, Amos J.] Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Reichert, DP (reprint author), Univ Edinburgh, Sch Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.	d.p.reichert@sms.ed.ac.uk; pseries@inf.ed.ac.uk; a.storkey@ed.ac.uk					Chikkerur Sharat S., 2010, VISION RES; Deco G, 2004, VISION RES, V44, P621, DOI 10.1016/j.visres.2003.09.037; Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lamme VAF, 2000, TRENDS NEUROSCI, V23, P571, DOI 10.1016/S0166-2236(00)01657-X; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; REICHERT DP, 2010, ADV NEURAL INFORM PR, V23, P2020; Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Serences JT, 2006, TRENDS COGN SCI, V10, P38, DOI 10.1016/j.tics.2005.11.008; Tang Y., 2010, P 27 ANN INT C MACH, P1055; Tsotsos JK, 2008, BRAIN RES, V1225, P119, DOI 10.1016/j.brainres.2008.05.038	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-21734-0	LECT NOTES COMPUT SC			2011	6791						18	25				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BXM21	WOS:000296364500003		
S	Ribeiro, B; Lopes, N		Lu, BL; Zhang, LQ; Kwok, J		Ribeiro, Bernardete; Lopes, Noel			Deep Belief Networks for Financial Prediction	NEURAL INFORMATION PROCESSING, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	18th International Conference on Neural Information Processing (ICONIP 2011)	NOV 13-17, 2011	Shanghai, PEOPLES R CHINA	Asia Pacific Neural Network Assembly, Shanghai Jiao Tong Univ, Natl Nat Sci Fdn China, Shanghai Hyron Software Co Ltd, Microsoft Res Asia, Hitachi Res & Dev Corp, Fujitsu Res & Dev Ctr Co Ltd		Deep Learning; Neural Networks; Financial Prediction	BANKRUPTCY PREDICTION; NEURAL-NETWORKS	Financial business prediction has lately raised a great interest clue to the recent world crisis events. In spite of the many advanced shallow computational methods that have extensively been proposed, most algorithms have not yet attained a desirable level of applicability. All show a good performance for a given financial setup but fail in general to create better and reliable models. The main focus of this paper is to present a deep learning model with strong ability to generate high level feature representations for accurate financial prediction. The proposed Deep Belief Network (DBN) approach tested in a real dataset of French companies compares favorably to shallow architectures such as Support Vector Machines (SVM) and single Restricted Boltzmann Machine (RBM). We show that the underlying financial model with deep machine technology has a strong potential thus empowering the finance industry.	[Ribeiro, Bernardete; Lopes, Noel] Univ Coimbra, Dept Informat Engn, CISUC, P-3000 Coimbra, Portugal	Ribeiro, B (reprint author), Univ Coimbra, Dept Informat Engn, CISUC, P-3000 Coimbra, Portugal.	bribeiro@dei.uc.pt; noel@ipg.pt	Ribeiro, Bernardete/	Ribeiro, Bernardete/0000-0002-9770-7672			Atiya AF, 2001, IEEE T NEURAL NETWOR, V12, P929, DOI 10.1109/72.935101; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Colbert R., 2008, ICML, P160; Hawkings J., 2004, INTELLIGENCE; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Kumar PR, 2007, EUR J OPER RES, V180, P1, DOI 10.1016/j.ejor.2006.08.043; Ribeiro B., 2010, IEEE INT JOINT C NEU, P1; Yu K., 2009, NEURAL INFORM PROCES, P1889	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-24964-8	LECT NOTES COMPUT SC			2011	7064		III				766	773				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BBM00	WOS:000307328500086		
S	Ribeiro, B; Goncalves, I; Santos, S; Kovacec, A		Martin, CS; Kim, SW		Ribeiro, Bernardete; Goncalves, Ivo; Santos, Sergio; Kovacec, Alexander			Deep Learning Networks for Off-Line Handwritten Signature Recognition	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS	Lecture Notes in Computer Science		English	Proceedings Paper	16th Iberoamerican Congress on Pattern Recognition	NOV 15-18, 2011	Pucon, CHILE	Univ Frontera, Int Assoc Pattern Recognit (IAPR), Assoc Chilena Reconocimiento Patrones, Assoc Cubana Reconocimiento Patrones, Mexican Assoc Comp Vision, Neural Comp & Robot, Brazilian Comp Soc, Special Interest Grp, Assoc Espanola Reconocimientos Formas & Anal Imagenes, Portuguese Assoc Pattern Recognit, Sociedad Argentina Reconocimiento Patrones, Assoc Reconocimiento Patrones Uruguay, Assoc Peruana Reconocimiento Patrones		Deep Learning; Generative Models; Signature Recognition	NEURAL-NETWORKS; ALGORITHM; MACHINES	Reliable identification and verification of off-line handwritten signatures from images is a difficult problem with many practical applications. This task is a difficult vision problem within the field of biometrics because a signature may change depending on psychological factors of the individual. Motivated by advances in brain science which describe how objects are represented in the visual cortex, advanced research on deep neural networks has been shown to work reliably on large image data sets. In this paper, we present a deep learning model for off-line handwritten signature recognition which is able to extract high-level representations. We also propose a two-step hybrid model for signature identification and verification improving the misclassification rate in the well-known CPDS database.	[Ribeiro, Bernardete; Goncalves, Ivo; Santos, Sergio] Univ Coimbra, Dept Informat Engn, CISUC, P-3000 Coimbra, Portugal	Ribeiro, B (reprint author), Univ Coimbra, Dept Informat Engn, CISUC, P-3000 Coimbra, Portugal.	bribeiro@dei.uc.pt; icpg@dei.uc.pt; sdsantos@dei.uc.pt; kovacec@mat.uc.pt	Ribeiro, Bernardete/	Ribeiro, Bernardete/0000-0002-9770-7672			ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Armand S, 2007, IEEE COMPUT INTELL M, V2, P18, DOI 10.1109/MCI.2007.353417; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bluemenstein M., 2004, IEEE IJCNN, P2983; Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125; Gader PD, 1997, IEEE T SYST MAN CY B, V27, P158, DOI 10.1109/3477.552199; Goncalves I., 2011, 1011 U COIMBR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Longcamp M, 2008, J COGNITIVE NEUROSCI, V20, P802, DOI 10.1162/jocn.2008.20504; Lv H, 2005, PATTERN RECOGN LETT, V26, P2390, DOI 10.1016/j.patrec.2005.04.013; Nguyen V., 2009, INT C DOC AN REC, P1300; Yu K., 2009, NEURAL INFORM PROCES	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-25084-2	LECT NOTES COMPUT SC			2011	7042						523	532				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BBK95	WOS:000307257600062		
S	Rohrer, B		Samsonovich, AV; Johannsdottir, KR		Rohrer, Brandon			Biologically inspired feature creation for multi-sensory perception	BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES 2011	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	2nd Annual Meeting of the Biologically-Inspired-Cognitive-Architectures-Society (BICA)	NOV 04-06, 2011	Arlington, VA	Biologically Inspired Cognit Architectures Soc		feature creation; unsupervised learning; perception; abstraction; vision processing; sensor fusion	CORTEX	Automatic feature creation is a powerful tool for identifying and reaching goals in the natural world. This paper describes in detail a biologically-inspired method of feature creation that can be applied to sensory information of any modality. The algorithm is incremental and on-line; it enforces sparseness in the features it creates; and it can form features from other features, making a hierarchical feature set. Here it demonstrates the creation of both visual and auditory features.	Sandia Natl Labs, Albuquerque, NM 87185 USA	Rohrer, B (reprint author), Sandia Natl Labs, POB 5800, Albuquerque, NM 87185 USA.	rohrer@sandia.gov					Arel I., 2010, IEEE COMPUTATIONAL I; Arel I., 2009, P AAAI WORKSH BIOL I; Fasel I., 2010, P INT C PATT REC ICP; Griffin G., 2007, 7694 CAL I TECHN; Guyon I, 2007, PATTERN RECOGN LETT, V28, P1438, DOI 10.1016/j.patrec.2007.02.014; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Minsky M., 1969, PERCEPTRONS INTRO CO; Neural Information Processing Systems, 2003, NIPS FEAT EXTR CHALL; PHILLIPS JR, 1988, P NATL ACAD SCI USA, V85, P1317, DOI 10.1073/pnas.85.4.1317; Rohrer B., 2011, WATCH TASK FEATURES; Rohrer B., 2011, LISTEN TASK FEATURES; Rohrer B., 2011, AUTOMATICALLY CREATE; Rohrer B., 2011, WORKSH SELF PROGR 4; Sharma J, 2000, NATURE, V404, P841, DOI 10.1038/35009043; Torkkola K., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753742; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751	18	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		978-1-60750-959-2; 978-1-60750-958-5	FRONT ARTIF INTEL AP			2011	233						305	313		10.3233/978-1-60750-959-2-305		9	Computer Science, Artificial Intelligence; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BC0DP	WOS:000348931200054		
B	Seide, F; Li, G; Yu, D			Int Speech Commun Assoc	Seide, Frank; Li, Gang; Yu, Dong			Conversational Speech Transcription Using Context-Dependent Deep Neural Networks	12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5			English	Proceedings Paper	12th Annual Conference of the International-Speech-Communication-Association 2011 (INTERSPEECH 2011)	AUG 27-31, 2011	Florence, ITALY	Int Speech Commun Assoc		speech recognition; deep belief networks; deep neural networks		We apply the recently proposed Context-Dependent Deep-Neural-Network HMMs, or CD-DNN-HMMs, to speech-to-text transcription. For single-pass speaker-independent recognition on the RT03S Fisher portion of phone-call transcription benchmark (Switchboard), the word-error rate is reduced from 27.4%, obtained by discriminatively trained Gaussian-mixture HMMs, to 18.5%-a 33% relative improvement. CD-DNN-HMMs combine classic artificial-neural-network HMMs with traditional tied-state triphones and deep-belief-network pre-training. They had previously been shown to reduce errors by 16% relatively when trained on tens of hours of data using hundreds of tied states. This paper takes CD-DNN-HMMs further and applies them to transcription using over 300 hours of training data, over 9000 tied states, and up to 9 hidden layers, and demonstrates how sparseness can be exploited. On four less well-matched transcription tasks, we observe relative error reductions of 22-28%.	[Seide, Frank; Li, Gang] Microsoft Res Asia, Beijing, Peoples R China	Seide, F (reprint author), Microsoft Res Asia, Beijing, Peoples R China.	fseide@microsoft.com; ganl@microsoft.com; dongyu@microsoft.com					Zweig G, 2006, IEEE T AUDIO SPEECH, V14, P1490, DOI 10.1109/TASL.2006.882751; Dahl G., 2011, IEEE T SPEE IN PRESS; FRANCO H, 1994, COMPUT SPEECH LANG, V8, P211, DOI 10.1006/csla.1994.1010; Fritsch J., 1998, P ICASSP 1998 MAY; Geoffrey Hinton, 2010, 2010003 UTML TR U TO; Godfrey John J., 1997, SWITCHBOARD 1 RELEAS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hon H.-W., 1992, THESIS CARNEGIE MELL; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Padmanabhan M., 2002, VOICEMAIL CORPUS 1 2; Renals S., 1994, IEE T SPEECH AUD JAN; Rosenblatt F., 1961, PRINCIPLES NEURODYNA; Rumelhart D., 1986, NATURE, V323; Saul L. K., 1996, J ARTICIAL INTELLIGE, P61; Stolcke A., 2006, IEEE T AUDIO SPEECH, V14; Yu D., 2010, P NIPS WORKSH DEEP L	16	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-61839-270-1				2011							444	447				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BEG84	WOS:000316502200113		
J	Si, ZZ; Zhu, SC			IEEE	Si, Zhangzhang; Zhu, Song-Chun			Unsupervised Learning of Stochastic AND-OR Templates for Object Modeling	2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)			English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	NOV 06-13, 2011	Barcelona, SPAIN	IEEE, Toyota, Google, Microsoft Res, Siemens, Technicolor, Adobe, Alcatel Lucent, Gentex Corp, Kooaba Image Recognit, Mitsubishi Elect, Mobileye, Object Video (OV), Toshiba, Xerox, Zeiss, 2d3, SATURNUS			RECOGNITION	This paper presents a framework for unsupervised learning of a hierarchical generative image model called ANDOR Template (AOT) for visual objects. The AOT includes: (1) hierarchical composition as "AND" nodes, (2) deformation of parts as continuous "OR" nodes, and (3) multiple ways of composition as discrete "OR" nodes. These AND/OR nodes form the hierarchical visual dictionary. We show that both the structure and parameters of the AOT model can be learned in an unsupervised way from example images using an information projection principle. The learning algorithm consists two steps: i) a recursive Block-Pursuit procedure to learn the hierarchical dictionary of primitives, parts and objects, which form leaf nodes, AND nodes and structural OR nodes and ii) a Graph-Compression operation to minimize model structure for better generalizability, which produce additional OR nodes across the compositional hierarchy. We investigate the conditions under which the learning algorithm can identify, (i.e. recover) an underlying AOT that generates the data, and evaluate the performance of our learning algorithm through both artificial and real examples.	[Si, Zhangzhang; Zhu, Song-Chun] Univ Calif Los Angeles, Los Angeles, CA 90024 USA	Si, ZZ (reprint author), Univ Calif Los Angeles, Los Angeles, CA 90024 USA.	zzsi@stat.ucla.edu; sczhu@stat.ucla.edu					Brendel W., 2011, ICCV; Chen H., 2006, CVPR; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Felzenszwalb P. F., 2010, TPAMI; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Fidler S., 2007, CVPR; GUPTA A, 2009, CVPR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jin Y., 2006, CVPR; Pietra S. D., 1997, TPAMI; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Wu Y. N., 2009, IJCV; Zhu L., 2009, TPAMI; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0063-6				2011												8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BYS96	WOS:000300056700089		
B	Yang, XH; Chen, QC; Zhou, SS; Wang, XL			Int Speech Commun Assoc	Yang, Xiaohong; Chen, Qingcai; Zhou, Shusen; Wang, Xiaolong			Deep Belief Networks for Automatic Music Genre Classification	12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5			English	Proceedings Paper	12th Annual Conference of the International-Speech-Communication-Association 2011 (INTERSPEECH 2011)	AUG 27-31, 2011	Florence, ITALY	Int Speech Commun Assoc		deep belief networks; music genre classification; timbral texture feature; modulation spectral analysis		This paper proposes an approach to automatic music genre classification using deep belief networks. Based on the restricted Boltzmann machines, the deep belief networks is constructed and takes the acoustic features extracted through content-based analysis of music signals as input. The model parameters are initially determined after the deep belief network is trained by greedy layer-wise learning algorithm with feature vectors that are comprised of short-term and long-term features. Then the parameters are fine-tuned to local optimum according to back propagation algorithm. Experiments on GTZAN dataset show that the performance of music genre classification using deep belief networks is superior to those of widely used classification methods such as support vector machine, K-nearest neighbor, linear discriminant analysis and neural network.	[Yang, Xiaohong; Chen, Qingcai; Zhou, Shusen; Wang, Xiaolong] Shenzhen Grad Sch, Dept Comp Sci & Technol, Key Lab Network Oriented Intelligent Computat, Harbin Inst Technol, Shenzhen, Peoples R China	Yang, XH (reprint author), Shenzhen Grad Sch, Dept Comp Sci & Technol, Key Lab Network Oriented Intelligent Computat, Harbin Inst Technol, Shenzhen, Peoples R China.	yxh2008@gmail.com; qingcai.chen@gmail.com; zhoushusen@hitsz.edu.cn; wangxl@insun.hit.edu.cn					Ballan L, 2009, P ICME; Benetos E, 2010, IEEE T AUDIO SPEECH, V18, P1955, DOI 10.1109/TASL.2010.2040784; Bengio Y, 2006, P NIPS; Chang K., 2010, P 11 INT C MUS INF R, P387; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jang D., 2008, P ICME; Lee CH, 2009, IEEE T MULTIMEDIA, V11, P670, DOI 10.1109/TMM.2009.2017635; Lee H., 2009, PLOS ONE, P1; Li T, 2006, IEEE T MULTIMEDIA, V8, P564, DOI 10.1109/TMM.2006.870730; Li T., 2003, P 26 ANN INT ACM SIG, P282; Liu Y, 2010, PATTERN RECOGNITION; Panagakis Y, 2010, IEEE T AUDIO SPEECH, V18, P576, DOI 10.1109/TASL.2009.2036813; Panagakis Y., 2009, P 17 EUR SIGN PROC C; Panagakis Yannis, 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, DOI 10.1109/ICASSP.2010.5495984; Song YQ, 2008, IEEE T MULTIMEDIA, V10, P145, DOI 10.1109/TMM.2007.911305; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560	16	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-61839-270-1				2011							2444	2447				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BEG84	WOS:000316502201100		
J	Ye, XY; Yuille, A			IEEE	Ye, Xingyao; Yuille, Alan			Learning a Dictionary of Deformable Patches using GPUs	2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)			English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	NOV 06-13, 2011	Barcelona, SPAIN	IEEE, Toyota, Google, Microsoft Res, Siemens, Technicolor, Adobe, Alcatel Lucent, Gentex Corp, Kooaba Image Recognit, Mitsubishi Elect, Mobileye, Object Video (OV), Toshiba, Xerox, Zeiss, 2d3, SATURNUS				We propose a simple method for learning a dictionary of deformable patches for simultaneous shape recognition and reconstruction. Our approach relies on two key innovations introducing a pre-defined set of transformations on patches to enrich the search space, and designing a parallel framework on Graphical Processors (GPUs) for matching a large number of deformable templates to a large set of images efficiently. We illustrate our method on two handwritten digit databases - MNIST and USPS, and report state-of-art recognition performance without using any domain-specific knowledge on digits. We briefly show that our dictionary has many desirable properties: it includes intuitive low- and mid-level structures, it is sufficient to synthesize digits, it gives sparse representations of digits, and contains elements which are useful for discrimination. In addition, we are the first dictionary learning method to report good results when transferring the learned dictionary between different datasets.	[Ye, Xingyao] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90024 USA	Ye, XY (reprint author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90024 USA.	yexy@stat.ucla.edu; yuille@stat.ucla.edu					[Anonymous], MNIST HANDWRITTEN DI; [Anonymous], USPS HANDWRITTEN DIG; Bart E., 2008, CVPR; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Borenstein E., 2002, ECCV; Boureau Y.L., 2010, CVPR; Coates A., NIPS 2010 WORKSH DEE; Efros A., 2001, SIGGRAPH; Epshtein B., 2005, ICCV; Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining; Fidler S., 2007, CVPR; Frey B. J., 2003, IEEE T PATTERN ANAL, V25; Haasdonk B., 2002, ICPR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K., 2009, ICCV; Joachims T., SVM LIGHT PACKAGE; Lee H., 2009, ICML; Mairal J., 2008, NIPS; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Raina R., 2007, ICML; Ranzato M., 2007, CVPR; Wu Y. N., 2007, ICCV; Zhu L., 2010, CVPR	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0063-6				2011												8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BYS96	WOS:000300056700068		
J	Zibner, SKU; Faubel, C; Schoner, G			IEEE	Zibner, Stephan K. U.; Faubel, Christian; Schoener, Gregor			Making a robotic scene representation accessible to feature and label queries	2011 IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING (ICDL)			English	Proceedings Paper	IEEE International Conference on Development and Learning (ICDL)	AUG 24-27, 2011	GERMANY	IEEE, IEEE Computat Intelligence Soc, Frankfurt Inst Adv Studies (FIAS), CITEC, italk, Springer, Microsoft Res, IM CLeVeR			OBJECT RECOGNITION; DYNAMICS; VISION	We present a neural architecture for scene representation that stores semantic information about objects in the robot's workspace. We show how this representation can be queried both through low-level features such as color and size, through feature conjunctions, as well as through symbolic labels. This is possible by binding different feature dimensions through space and integrating these space-feature representations with an object recognition system. Queries lead to the activation of a neural representation of previously seen objects, which can then be used to drive object-oriented action. The representation is continuously linked to sensory information and autonomously updates when objects are moved or removed.	[Zibner, Stephan K. U.; Faubel, Christian; Schoener, Gregor] Ruhr Univ Bochum, Inst Neuroinformat, Bochum, Germany	Zibner, SKU (reprint author), Ruhr Univ Bochum, Inst Neuroinformat, Bochum, Germany.	stephan.zibner@ini.rub.de; christian.faubel@ini.rub.de; gregor.schoener@ini.rub.de					Acredolo L., 1977, Developmental Psychology, V14, P224; AMARI SI, 1977, BIOL CYBERN, V27, P77, DOI 10.1007/BF00337259; Arathorn D. W., 2002, THESIS STANFORD; Bartsch K., 1986, V51, P1; Deco G, 2005, J NEUROPHYSIOL, V94, P295, DOI 10.1152/jn.01095.2004; Erlhagen W, 2006, J NEURAL ENG, V3, pR36, DOI 10.1088/1741-2560/3/3/R02; Faubel C., 2009, IROS 09, P3162; Faubel C, 2010, IEEE INT C INT ROBOT, P1171; Henderson JM, 1999, ANNU REV PSYCHOL, V50, P243, DOI 10.1146/annurev.psych.50.1.243; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Johnson JS, 2008, NEW IDEAS PSYCHOL, V26, P227, DOI 10.1016/j.newideapsych.2007.07.007; Koch C., 2001, NATURE REV NEUROSCIE, V2, P1, DOI [10.1038/35058500, DOI 10.1038/35058500)]; Kurkova V., 2008, Invariant Object Recognition with Slow Feature Analysis, V5163, P961; Lipinski J, 2009, COGN NEURODYNAMICS, V3, P373, DOI 10.1007/s11571-009-9096-y; Meger D, 2008, ROBOT AUTON SYST, V56, P503, DOI 10.1016/j.robot.2008.03.008; Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777; Pfeifer R., 2001, UNDERSTANDING INTELL; Rasolzadeh B, 2010, INT J ROBOT RES, V29, P133, DOI 10.1177/0278364909346069; Riesenhuber M, 1999, NEURON, V24, P87, DOI 10.1016/S0896-6273(00)80824-7; Rodrigues J, 2009, COGN PROCESS, V10, P243, DOI 10.1007/s10339-009-0262-2; Schoner G, 2008, CAMB HANDB PSYCHOL, P101; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Wiskott L., 1997, IEEE T PATTERN ANAL; Zibner S. K. U., 2011, IEEE T AUTONOMOUS ME, V3; Zibner S. K. U., 2010, P 9 IEEE 2010 INT C, P244	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-61284-990-4				2011												7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX67	WOS:000297472300048		
J	Goertzel, B; Pitt, J; Ikle, M; Pennachin, C; Rui, L				Goertzel, Ben; Pitt, Joel; Ikle, Matthew; Pennachin, Cassio; Rui, Liu			Glocal memory A critical design principle for artificial brains and minds	NEUROCOMPUTING			English	Article						Glocal memory; Artificial brains; Attractor neural nets; Hopfield nets; Economic attention networks; OpenCog; Novamente cognition engine	REPRESENTATION; NETWORKS	The concept of glocal memory (i e memory involving systematic coordination between localized memory traces and globalized dynamical-attractor-based memory traces) is reviewed and is argued to be a critical principle for the design of artificial brains and artificial general intelligence systems Some exploratory experiments are reviewed involving introduction of glocal memory into Hopfield neural networks and also Into economic attention networks as utilized in the OpenCog and Novamente integrated AI architectures (C) 2010 Elsevier B V All rights reserved	[Goertzel, Ben; Pitt, Joel; Ikle, Matthew; Pennachin, Cassio; Rui, Liu] Novamente LLC, Rockville, MD 20851 USA; [Goertzel, Ben] Xiamen Univ, Fujian Key Lab Brain Intelligent Syst, Dept Cognit Sci, Xiamen, Peoples R China; [Ikle, Matthew] Adams State Coll, Alamosa, CO USA	Goertzel, B (reprint author), Novamente LLC, 1405 Bernerd Pl, Rockville, MD 20851 USA.				Singularity Institute for Artificial Intelligence	The authors would like to acknowledge Ulnas Vepstas Gustavo Gama and Jared Wigmore among others for their contributions to the open-source OpenCog framework Ben Goertzel would like to thank Jeffrey Epstein for his research support Joel Pitt would like to thank the Singularity Institute for Artificial Intelligence for their research funding	Amit DJ, 1989, MODELING BRAIN FUNCT; Anderson J. R., 1996, ARCHITECTURE COGNITI; BRANSFOR.JD, 1971, COGNITIVE PSYCHOL, V2, P331, DOI 10.1016/0010-0285(71)90019-3; Calvin W., 1996, CEREBRAL CODE; Damasio A, 2000, FEELING WHAT HAPPENS; DAVILAGARCEZ AS, 2008, NEURAL SYMBOLIC COGN; ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844; FREEMAN WJ, 1982, PSYCHOPHYSIOLOGY, V19, P44, DOI 10.1111/j.1469-8986.1982.tb02598.x; Goertzel B., 2008, DYNAMICAL PSYCHOL; Goertzel B., 2008, OPENCOG PRIME DESIGN; GOERTZEL B, 2001, CREATING INTERNET IN; Goertzel B., 1997, COMPLEXITY CREATIVIT; Goertzel B, 2009, PROBABILISTIC LOGIC NETWORKS: A COMPREHENSIVE FRAMEWORK FOR UNCERTAIN INFERENCE, P1, DOI 10.1007/978-0-387-76872-4; GOERTZEL B, AGI 06; Hammer B, 2007, STUD COMPUT INTELL, V77, P1, DOI 10.1007/978-3-540-73954-8; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOFSTADTER DR, 1979, ESCHER BACH ETERNAL; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Lenat D., 1990, BUILDING LARGE KNOWL; Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277; Quiroga RQ, 2008, TRENDS COGN SCI, V12, P87, DOI 10.1016/j.tics.2007.12.003; Quiroga RQ, 2005, NATURE, V435, P1102, DOI 10.1038/nature03687; ROEDIGER HL, 1995, J EXP PSYCHOL LEARN, V21, P803, DOI 10.1037/0278-7393.21.4.803; Rosenfield I., 1988, INVENTION MEMORY NEW; SANTORE JF, 2003, IJCAI 2003 WORKSH CO; Storkey A. J., 1999, Neural Networks, V12, DOI 10.1016/S0893-6080(99)00038-6; Sun R., 2000, HYBRID NEURAL SYSTEM	27	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	DEC	2010	74	1-3			SI		84	94		10.1016/j.neucom.2009.10.033		11	Computer Science, Artificial Intelligence	Computer Science	701GG	WOS:000285805800007		
J	Arel, I; Berant, S		Samsonovich, AV; Johannsdottir, KR; Chella, A; Goertzel, B		Arel, Itamar; Berant, Shay			Application Feedback in Guiding a Deep-Layered Perception Model	BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES 2010	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	1st Annual Meeting of the Biologically-Inspired-Cognitive-Architectures-Society (BICA)	NOV 13-14, 2010	Washington, DC	Biologically Inspired Cognit Architectures Soc		Deep-layered machine learning; perception; spatiotemporal inference		Deep-layer machine learning architectures continue to emerge as a promising biologically-inspired framework for achieving scalable perception in artificial agents. State inference is a consequence of robust perception, allowing the agent to interpret the environment with which it interacts and map such interpretation to desirable actions. However, in existing deep learning schemes, the perception process is guided purely by spatial regularities in the observations, with no feedback provided from the target application (e.g. classification, control). In this paper, we propose a simple yet powerful feedback mechanism, based on adjusting the sample presentation distribution, which guides the perception model in allocating resources for patterns observed. As a result, a much more focused state inference can be achieved leading to greater accuracy and overall performance. The proposed paradigm is demonstrated on a small-scale yet complex image recognition task, clearly illustrating the advantage of incorporating feedback in a deep-learning based cognitive architecture.	[Arel, Itamar] Univ Tennessee, Dept Elect Engn & Comp Sci, Knoxville, TN 37996 USA	Arel, I (reprint author), Univ Tennessee, Dept Elect Engn & Comp Sci, Knoxville, TN 37996 USA.						Arel I., 2009, IEEE COMPUT, V42, P104; Bellman R., 1957, DYNAMIC PROGRAMMING; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Ranzato M., 2007, P COMP VIS PATT REC; Wallis G., 1999, TRENDS COGN SCI, V3, P23	7	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		978-1-60750-661-4	FRONT ARTIF INTEL AP			2010	221						4	9		10.3233/978-1-60750-661-4-4		6	Computer Science, Artificial Intelligence	Computer Science	BHF21	WOS:000325220500002		
J	Bandinelli, N; Bianchini, M; Scarselli, F			IEEE	Bandinelli, Niccolo; Bianchini, Monica; Scarselli, Franco			Learning Long-Term Dependencies Using Layered Graph Neural Networks	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE			GENERAL FRAMEWORK; PROTEIN-STRUCTURE; PREDICTION; ALGORITHM	Graph Neural Networks (GNNs) are a powerful tool for processing graphs, that represent a natural way to collect information coming from several areas of science and engineering - e. g. data mining, computer vision, molecular chemistry, molecular biology, pattern recognition -, where data are intrinsically organized in entities and relationships among entities. Nevertheless, GNNs suffer, so as recurrent/recursive models, from the long-term dependency problem that makes the learning difficult in deep structures. In this paper, we present a new architecture, called Layered GNN (LGNN), realized by a cascade of GNNs: each layer is fed with the original data and with the state information calculated by the previous layer in the cascade. Intuitively, this allows each GNN to solve a subproblem, related only to those patterns that were misclassified by the previous GNNs. Some experimental results are reported, based on synthetic and real-world datasets, which assess a significant improvement in performances w.r.t. the standard GNN approach.	[Bandinelli, Niccolo; Bianchini, Monica; Scarselli, Franco] Univ Siena, Dipartimento Ingn Informaz, I-53100 Siena, Italy	Scarselli, F (reprint author), Univ Siena, Dipartimento Ingn Informaz, Via Roma 56, I-53100 Siena, Italy.	franco@dii.unisi.it					ALMEIDA L, 1987, IEEE INT C NEUR NETW, V2, P609; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; BENGIO Y, 2010, FDN TRENDS IN PRESS; Bianchini M, 2005, PATTERN RECOGN LETT, V26, P1885, DOI 10.1016/j.patrec.2005.03.010; Bianchini M., 2003, P 1 ANNPR WORKSH FLO; Bianchini M, 2005, NEURAL NETWORKS, V18, P1040, DOI 10.1016/j.neunet.2005.07.003; Bianchini M, 2006, ADV IMAG ELECT PHYS, V140, P1, DOI 10.1016/S1076-5670(05)4001-4; BIANCHINI M, 2009, MULTIMEDIA TECHNIQUE, P179, DOI 10.1007/978-0-387-88777-7_8; Bunke H., 2000, P VIS INT 2000 MONTR, P82; Cheng JL, 2005, DATA MIN KNOWL DISC, V11, P213, DOI 10.1007/s10618-005-0001-y; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; DIMASSA V, 2006, P INT JOINT C NEUR N, P778; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; GORI M, 2003, P INT JOINT C NEUR N, V2, P1351, DOI 10.1109/IJCNN.2003.1223892; HAGENBUCHNER M, 2004, P IEEE INT JOINT C N, V3, P1923; Hammer B, 2004, NEUROCOMPUTING, V57, P3, DOI 10.1016/j.neucom.2004.01.008; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Khamsi MA, 2001, INTRO METRIC SPACES; Kohonen T, 2002, NEURAL NETWORKS, V15, P945, DOI 10.1016/S0893-6080(02)00069-2; Mooney C, 2009, PROTEINS, V77, P181, DOI 10.1002/prot.22429; Pineda F. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.161; Pollastri G, 2005, BIOINFORMATICS, V21, P1719, DOI 10.1093/bioinformatics/bti203; Rhodes N, 2003, J CHEM INF COMP SCI, V43, P443, DOI 10.1021/ci025605o; Riedmiller M., 1993, P IEEE INT C NEUR NE, V1, P586, DOI DOI 10.1109/ICNN.1993.298623; Samudrala R, 1998, J MOL BIOL, V279, P287, DOI 10.1006/jmbi.1998.1689; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P81, DOI 10.1109/TNN.2008.2005141; SCHMITT T, 1998, WORKSH FUZZ NEUR 98; Sperduti A., 1997, IEEE T NEURAL NETWOR, V8, P429; Srinivasan A., 1994, P 4 INT WORKSH IND L, P217; Tsoi AC, 2009, STUD COMPUT INTELL, V247, P43; UWENTS W, 2006, EUR C MACH LEARN, P211	32	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-6917-8	IEEE IJCNN			2010												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421403017		
S	Connors, WA; Connor, PC; Trappenberg, T		Farzindar, A; Keselj, V		Connors, Warren A.; Connor, Patrick C.; Trappenberg, Thomas			Detection of Mine-Like Objects Using Restricted Boltzmann Machines	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	23rd Canadian Conference on Artificial Intelligence	MAY 31-JUN 02, 2010	Ottawa, CANADA	Canadian Artificial Intelligence Assoc, Univ Ottawa, NLP Technologies, MultiCopora R&D, Palomino Syst Innovat, Language Ind Assoc				Automatic target recognition (ATR) of objects in side scan sonar imagery typically employs image processing techniques (e.g. segmentation, Fourier transform) to extract features describing the objects. The features are used to discriminate between sea floor clutter and targets (e.g. sea mines). These methods are typically developed for a specific sonar, and are computationally intensive. The present work(1) used the Restricted Boltzmann Machine (RBM) to discriminate between images of targets and clutter, achieving a 90% probability of detection and a 15% probability of false alarm, which is comparable to the performance of a Support Vector Machine (SVM) and other state-of-the-art methods on the data. The RBM method uses raw image pixels and thus avoids the issue of manually selecting good representations (features) of the data.			warren.connors@drdc-rddc.gc.ca; patrick.connor@dal.ca; tt@cs.dal.ca					Chapple P., 2008, AUTOMATED DETECTION; FAWCETT J, 2007, P I AC; Fawcett J., 2007, 2007162 TM DEF RES D; Fawcett J., 2006, 2006115 TM DEF RES D; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; NAIR V, 2008, NIPS, P1145; SMOLENSKY P, 1986, INFORM PROCESSING DY, P194	8	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-13058-8	LECT NOTES ARTIF INT			2010	6085						362	365				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BQQ53	WOS:000281548500044		
J	Embrechts, MJ; Hargis, BJ; Linton, JD			IEEE	Embrechts, Mark J.; Hargis, Blake J.; Linton, Jonathan D.			Augmented Efficient BackProp for Backpropagation Learning in Deep Autoassociative Neural Networks	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE			PRINCIPAL COMPONENT ANALYSIS; NONLINEAR PCA; TETRAHYMENA-PYRIFORMIS; ALGORITHM	We introduce Augmented Efficient BackProp as a strategy for applying the backpropagation algorithm to deep autoencoders, i.e., autoassociators with many hidden layers, without relying on a weight initialization using restricted Boltzmann machines. This training method is an extension of Efficient BackProp, first proposed by LeCun et al. [1], and is benchmarked on three different types of application datasets.	[Embrechts, Mark J.; Hargis, Blake J.] Rensselaer Polytech Inst, Dept Ind & Syst Engn, Troy, NY 12180 USA	Embrechts, MJ (reprint author), Rensselaer Polytech Inst, Dept Ind & Syst Engn, Troy, NY 12180 USA.	embrem@rpi.edu; hargib@rpi.edu					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; [Anonymous], UCI MACH LEARN REP; Bengio Y., 2007, LARGE SCALE KERNEL M; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Carreira-Perpinan M, 1997, CS9609 U SHEFF DEP C; Daszykowski M, 2003, TALANTA, V59, P1095, DOI 10.1016/S0039-9140(03)00018-3; Erhan D., 2009, P 12 INT C ART INT S, V5, P153; Fazayeli F., 2008, P IEEE INT C NEUR NE, P5; Fodor I. K., 2002, SURVEY DIMENSION RED; FORINA M, 1982, ANN CHIM-ROME, V72, P127; GIANNAKOPOULOS X, 1999, INT JOINT C NEUR NET, V2, P888; HAYKIN S, 2009, NEURAL NETWORKS LEAR, P144; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Japkowicz N, 2000, NEURAL COMPUT, V12, P531, DOI 10.1162/089976600300015691; Jiang JH, 1996, ANAL CHIM ACTA, V336, P209, DOI 10.1016/S0003-2670(96)00359-5; Karhunen J, 1997, IEEE T NEURAL NETWOR, V8, P486, DOI 10.1109/72.572090; KARHUNEN J, 1995, NEURAL NETWORKS, V8, P549, DOI 10.1016/0893-6080(94)00098-7; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; KRAMER MA, 1992, COMPUT CHEM ENG, V16, P313, DOI 10.1016/0098-1354(92)80051-A; Larochelle H., 2009, J MACHINE LEARNING R; LECUN Y, 1985, COGNITIVA, V85, P559; LeCun Y., 1998, Neural networks: tricks of the trade; LEONARD J, 1990, COMPUT CHEM ENG, V14, P337, DOI 10.1016/0098-1354(90)87070-6; LERNER B, 1996, P 13 INT C PATT REC, V4, P320; Lerner B, 1999, PATTERN RECOGN LETT, V20, P7, DOI 10.1016/S0167-8655(98)00120-2; Malthouse EC, 1998, IEEE T NEURAL NETWOR, V9, P165, DOI 10.1109/72.655038; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Monahan AH, 2000, J CLIMATE, V13, P821, DOI 10.1175/1520-0442(2000)013<0821:NPCABN>2.0.CO;2; Oja E, 1997, NEUROCOMPUTING, V17, P25, DOI 10.1016/S0925-2312(97)00045-3; Oja E, 1998, NEUROCOMPUTING, V22, P187, DOI 10.1016/S0925-2312(98)00057-5; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, VI, P319; Scholz M, 2005, BIOINFORMATICS, V21, P3887, DOI 10.1093/bioinformatics/bti634; STONE JV, 1994, P IEEE WORLD C COMP, V1, P84, DOI 10.1109/ICNN.1994.374143; TAN CC, 2008, 2008 2 AS INT C MOD, P213, DOI 10.1109/AMS.2008.105; Tetko IV, 2008, J CHEM INF MODEL, V48, P1733, DOI 10.1021/ci800151m; Werbos P., 1974, THESIS HARVARD U; Yu C. C., 2002, P INT JOINT C NEUR N, P1218; Zhu H, 2008, J CHEM INF MODEL, V48, P766, DOI 10.1021/ci700443v	40	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-6917-8	IEEE IJCNN			2010												6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421401027		
S	Keck, C; Lucke, J		Diamantaras, K; Duch, W; Iliadis, LS		Keck, Christian; Luecke, Joerg			Learning of Lateral Connections for Representational Invariant Recognition	ARTIFICIAL NEURAL NETWORKS (ICANN 2010), PT III	Lecture Notes in Computer Science		English	Proceedings Paper	20th International Conference on Artificial Neural Networks	SEP 15-18, 2010	Thessaloniki, GREECE	European Neural Network Soc, Aristotle Univ Thessaloniki, Univ Macedonia, Technol Educ Inst Thess, Hellenic Int Univ, Democritus Univ Thrace, Alexander TEI Thessaloniki			VISUAL OBJECT RECOGNITION; SELF-ORGANIZATION; RECEPTIVE-FIELDS; CORTICAL COLUMNS; MODEL; CORTEX; SCALE	We study an artificial neural network that learns the invariance properties of objects from data. We start with a bag-of-features encoding of a specific object and repeatedly show the object in different transformations. The network then learns unsupervised from the data what the possible transformations are and what feature arrangements are typical for the object shown. The information about transformations and feature arrangements is hereby represented by a lateral network of excitatory connections among units that control the information exchange between an input and a down-stream neural layer. We build up on earlier work in this direction that kept a close relation to novel anatomical and physiological data on the cortical architecture and on its information processing and learning. At the same time we show, based on a new synaptic plasticity rules, that learning results in a strong increase of object finding rates in both artificial and more realistic experiments.	[Keck, Christian; Luecke, Joerg] Goethe Univ Frankfurt, Frankfurt Inst Adv Studies, D-60438 Frankfurt, Germany	Keck, C (reprint author), Goethe Univ Frankfurt, Frankfurt Inst Adv Studies, Ruth Moufang Str 1, D-60438 Frankfurt, Germany.	keck@fias.uni-frankfurt.de; luecke@fias.uni-frankfurt.de					BOUECKE JD, 2009, LNCS, V5769, P557; Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000211; HINTON GE, 1981, P 7 INT JOINT C ART, P683; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lucke J, 2009, NEURAL COMPUT, V21, P2805, DOI 10.1162/neco.2009.07-07-584; Lucke J, 2008, J MACH LEARN RES, V9, P1227; Lucke J, 2008, NEURAL COMPUT, V20, P2441, DOI 10.1162/neco.2008.06-07-539; Lucke J, 2004, NEURAL COMPUT, V16, P501, DOI 10.1162/089976604772744893; Lucke J, 2005, LECT NOTES COMPUT SC, V3696, P31; Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777; OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Ringach DL, 2002, J NEUROPHYSIOL, V88, P455, DOI 10.1152/jn.00881.2001; Sato YD, 2008, LECT NOTES COMPUT SC, V5163, P991, DOI 10.1007/978-3-540-87536-9_101; WISKOTT L, 1995, LATERAL INTERACTIONS; Wolfrum P, 2008, J VISION, V8, DOI 10.1167/8.7.34; Yoshimura Y, 2005, NATURE, V433, P868, DOI [10.1038/nature03252, 10.1038/nature03291]; Yuille A. L., 2003, HDB BRAIN THEORY NEU, P1228; Zhu JM, 2004, NEURAL NETWORKS, V17, P1311, DOI 10.1016/j.neunet.2004.06.010	19	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15824-7	LECT NOTES COMPUT SC			2010	6354		III				21	30				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BUS87	WOS:000290245400003		
J	Lange, S; Riedmiller, M			IEEE	Lange, Sascha; Riedmiller, Martin			Deep Auto-Encoder Neural Networks in Reinforcement Learning	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE				This paper discusses the effectiveness of deep auto-encoder neural networks in visual reinforcement learning (RL) tasks. We propose a framework for combining the training of deep auto-encoders (for learning compact feature spaces) with recently-proposed batch-mode RL algorithms (for learning policies). An emphasis is put on the data-efficiency of this combination and on studying the properties of the feature spaces automatically constructed by the deep auto-encoders. These feature spaces are empirically shown to adequately resemble existing similarities and spatial relations between observations and allow to learn useful policies. We propose several methods for improving the topology of the feature spaces making use of task-dependent information. Finally, we present first results on successfully learning good control policies directly on synthesized and real images.	[Lange, Sascha; Riedmiller, Martin] Univ Freiburg, Fac Engn, Dept Comp Sci, D-79194 Freiburg, Germany	Lange, S (reprint author), Univ Freiburg, Fac Engn, Dept Comp Sci, D-79194 Freiburg, Germany.	slange@informatik.uni-freiburg.de; riedmiller@informatik.uni-freiburg.de					Bengio Y., 2007, 1312 U MONTR DEP IRO; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Caruana R., 1993, P 10 INT C MACH LEAR, P41; Ernst D., 2006, INT WORKSH INT COMP, P446; Ernst D, 2005, J MACH LEARN RES, V6, P503; Gordon G. J., 1995, P 12 INT C MACH LEAR, P261; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jodogne S, 2007, J ARTIF INTELL RES, V28, P349; Kietzmann T., 2009, P 8 INT C MACH LEARN; Lagoudakis M. G., 2003, J MACHINE LEARNING R, V4, P1107, DOI DOI 10.1162/JMLR.2003.4.6.1107; Lange S., 2010, THESIS U OSNABRUCK; Lange S., 2010, EUR S ART NEUR NETW; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Ng A. Y., 2004, ADV NEURAL INFORM PR, V16; Ormoneit D, 2002, MACH LEARN, V49, P161, DOI 10.1023/A:1017928328829; Peters J, 2008, INT J ROBOT RES, V27, P197, DOI 10.1177/0278364907087548; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Riedmiller M., 2009, AUTONOMOUS ROBOTS, V27; RIEDMILLER M, 2005, P EUR C MACH LEARN E; Sutton RS, 1998, REINFORCEMENT LEARNI	21	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-6917-8	IEEE IJCNN			2010												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421401102		
S	Ludovic, A; Helene, PM; Michele, S		Coelho, H; Studer, R; Wooldridge, M		Ludovic, Arnold; Helene, Paugam-Moisy; Michele, Sebag			Unsupervised Layer-Wise Model Selection in Deep Neural Networks	ECAI 2010 - 19TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	19th European Conference on Artificial Intelligence (ECAI)/6th Conference on Prestigious Applications of Intelligent Systems (PAIS)	AUG 16-20, 2010	Lisbon, PORTUGAL	European Coordinating Comm Artificial Intelligence (ECCAI), Agreement Technol, Portuguese Assoc Artificial Intelligence (APPIA), Artificial Intelligence Journal (Elsevier), Fundacao Luso-Amer (FLAD), Lab Agent Modelling (LabMAg), PRIMAVERA Business Software Solut, SISCOG (Sistemas Cognitivos)	Univ Lisbon, Fac Sci		LEARNING ALGORITHM; BOLTZMANN MACHINES	Deep Neural Networks (DNN) propose a new and efficient ML architecture based on the layer-wise building of several representation layers. A critical issue for DNNs remains model selection, e. g. selecting the number of neurons in each DNN layer. The hyper-parameter search space exponentially increases with the number of layers, making the popular grid search-based approach used for finding good hyper-parameter values intractable. The question investigated in this paper is whether the unsupervised, layer-wise methodology used to train a DNN can be extended to model selection as well. The proposed approach, considering an unsupervised criterion, empirically examines whether model selection is a modular optimization problem, and can be tackled in a layer-wise manner. Preliminary results on the MNIST data set suggest the answer is positive. Further, some unexpected results regarding the optimal size of layers depending on the training process, are reported and discussed.	[Ludovic, Arnold] Univ Paris 11, CNRS, LIMSI, Paris, France	Ludovic, A (reprint author), Univ Paris 11, CNRS, LIMSI, Paris, France.	Ludovic.Arnold@lri.fr; Helene.Paugam-Moisy@univ-lyon2.fr; Michele.Sebag@lri.fr					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2007, P ADV NEUR INF PROC, P153; Bengio Y, 2004, J MACH LEARN RES, V5, P1089; Bengio Yoshua, 2009, P ICML 09; Dietterich T.G., 1998, NEURAL COMPUTATION; Efron B., 1993, MONOGRAPHS STAT APPL, V57; Erhan Dumitru, 2009, P AISTATS 09; Hastie T., 2001, SPRINGER SERIES STAT; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lee Honglak, 2009, P ICML 09, P77; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Mnih V., 2008, P ICML 08; Paugam-Moisy H., 1993, PARALLEL ALGORITHMS, P305; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Vapnik V. N., 1998, STAT LEARNING THEORY; Welling M., 2002, P INT C ART NEUR NET	21	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		978-1-60750-605-8	FRONT ARTIF INTEL AP			2010	215						915	920		10.3233/978-1-60750-606-5-915		6	Computer Science, Artificial Intelligence	Computer Science	BBB81	WOS:000306373200142		
B	Mohamed, AR; Yu, D; Deng, L			INST SPEECH COMMUN ASSOC	Mohamed, Abdel-rahman; Yu, Dong; Deng, Li			Investigation of Full-Sequence Training of Deep Belief Networks for Speech Recognition	11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4			English	Proceedings Paper	11th Annual Conference of the International-Speech-Communication-Association 2010	SEP 26-30, 2010	Makuhari, JAPAN	Japan World Exposit, Commemorat Org, Japan Soc Promot Sci, Telecommunicat Advancement Fdn, KDDI Fdn, Murata Sci Fdn, Adv Telecommunicat Technol Res Fdn, Support Ctr, Chiba Convent Bur & Int Ctr, Renesas Elect Corp, Google, Microsoft Corp, Nuance Commun Inc, Appen Pty Ltd, IBM Res, Sony Corp, Hitachi Ltd, Yahoo Japan Corp, Asahi Kasei Corp, KDDI R & D Lab Inc, Yamaha Corp, Toshiba Corp, Fujitsu Ltd, Mitsubishi Elect Corp, RION Co Ltd, NEC Corp		Deep Belief Networks; phone recognition; discriminative training; full-sequence optimization	ALGORITHM	Recently, Deep Belief Networks (DBNs) have been proposed for phone recognition and were found to achieve highly competitive performance. In the original DBNs, only frame-level information was used for training DBN weights while it has been known for long that sequential or full-sequence information can be helpful in improving speech recognition accuracy. In this paper we investigate approaches to optimizing the DBN weights, state-to-state transition parameters, and language model scores using the sequential discriminative training criterion. We describe and analyze the proposed training algorithm and strategy, and discuss practical issues and how they affect the final results. We show that the DBNs learned using the sequence-based training criterion outperform those with frame-based criterion using both three-layer and six-layer models, but the optimization procedure for the deeper DBN is more difficult for the former criterion.	[Mohamed, Abdel-rahman] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada	Mohamed, AR (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.	asamir@cs.toronto.edu; dongyu@microsoft.com; deng@microsoft.com					Baker J., 2009, IEEE SIG PROC MA JUL, V26; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166; Bilmes JA, 2005, IEEE SIGNAL PROC MAG, V22, P89; Bridle J. S., 1991, P ICASSP; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; Deng L., 2010, P INTERSPEECH; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kingsbury B., 2009, P ICASSP; Konig Y., 1996, THESIS U CALIFORNIA; Lee H., 2009, P NIPS DEC; Mohamed A., 2009, P NIPS WORKSH DEC; Mohamed A.-R., 2010, P ICASSP; Morgan N, 2005, IEEE SIGNAL PROC MAG, V22, P81, DOI 10.1109/MSP.2005.1511826; Prabhavalkar R., P ICASSP 2010, P5534; Schwarz P., 2006, P ICASSP, P325; Yu D., 2010, P INTERSPEECH; YU D, 2010, P ICASSP, P5030; Yu D., 2009, P NIPS WORKSH DEC; Yu D, 2009, IEEE SIGNAL PROC MAG, V26, P86, DOI 10.1109/MSP.2009.932793; Yu D, 2009, IEEE T AUDIO SPEECH, V17, P1348, DOI 10.1109/TASL.2009.2020890	22	0	0	ISCA-INST SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-61782-123-3				2010							2850	2853				4	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BDG18	WOS:000313086500325		
J	Muller, A; Schulz, H; Behnke, S			IEEE	Mueller, Andreas; Schulz, Hannes; Behnke, Sven			Topological Features in Locally Connected RBMs	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE			NONNEGATIVE MATRIX FACTORIZATION; RECOGNITION	Unsupervised learning algorithms find ways to model latent structure present in the data. These latent structures can then serve as a basis for supervised classification methods. A common choice for unsupervised feature discovery is the Restricted Boltzmann Machine (RBM). Since the RBM is a general purpose learning machine, it is not particularly tailored for image data. Representations found by RBMs are consequently not image-like. Since it is essential to exploit the known topological structure for image analysis, it is desirable not to discard the topology property when learning new representations. Then, the same learning methods can be applied to the latent representation in a hierarchical manner. In this work, we propose a modification to the learning rule of locally connected RBMs, which ensures that topological image structure is preserved in the latent representation. To this end, we use a Gaussian kernel to transfer topological properties of the image space to the feature space. The learned model is then used as an initialization for a neural network trained to classify the images. We evaluate our approach on the MNIST and Caltech 101 datasets and demonstrate that we are able to learn topological feature maps.	[Mueller, Andreas; Schulz, Hannes; Behnke, Sven] Univ Bonn, Autonomous Intelligent Syst Grp, D-53117 Bonn, Germany	Muller, A (reprint author), Univ Bonn, Autonomous Intelligent Syst Grp, Comp Sci 6,Romerstr 164, D-53117 Bonn, Germany.	amueller@ais.uni-bonn.de; schulz@ais.uni-bonn.de; behnke@ais.uni-bonn.de	Behnke, Sven/B-5509-2013	Behnke, Sven/0000-0002-5040-7525			Behnke S., 2003, HIERARCHICAL NEURAL; Bengio Y., 2009, LEARNING DEEP ARCHIT; Erhan D, 2009, P 12 INT C ART INT S, P153; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hosoda K, 2009, NEURAL COMPUT, V21, P2605, DOI 10.1162/neco.2009.03-08-722; Huang J., 1999, CVPR; Karklin Y., 2008, NATURE, V457, P83; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, ICML; Norouzi M., 2009, CVPR; RANZATO MA, 2007, ADV NEURAL INFORM PR, P20; Riedmiller M., 1993, DIRECT ADAPTIVE METH, P586; SCHULZ H, 2010, EUR S ART NEUR NETW; TIELEMAN T, 2008, ICML; Uetz R., 2009, NIPS 2009 WORKSH LAR; UETZ R, 2009, P INT COMP INT SYST; Zhang TP, 2008, IEEE T IMAGE PROCESS, V17, P574, DOI 10.1109/TIP.2008.918957	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-6917-8	IEEE IJCNN			2010												6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421403136		
J	Mulder, W; Adriaans, P		Sempere, JM; Garcia, P		Mulder, Wico; Adriaans, Pieter			Using Grammar Induction to Model Adaptive Behavior of Networks of Collaborative Agents	GRAMMATICAL INFERENCE: THEORETICAL RESULTS AND APPLICATIONS, ICGI 2010	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	10th International Colloquium on Grammatical Inference (ICGI)	SEP 13-16, 2010	Valencia, SPAIN	PASCAL2 Network Excellence, Spanish Minist Sci & Innovat, Tech Univ Valencia, Dept Informat Syst & Computat (DSIC, UPV), Sch Engn Comp Sci (ETSINF, UPV), BANCAJA, Tech Univ Valencia, Res Grp Formal Language Theory Computabil & Complex		collaborative agents; learning; grammar induction; self-organization	MDL	We introduce a formal paradigm to study global adaptive behavior of organizations of collaborative agents with local learning capabilities. Our model is based on an extension of the classical language learning setting in which a teacher provides examples to a student that must guess a correct grammar. In our model the teacher is transformed in to a workload dispatcher and the student is replaced by an organization of worker-agents. The jobs that the dispatcher creates consist of sequences of tasks that can be modeled as sentences of a language. The agents in the organization have language learning capabilities that can be used to learn local work-distribution strategies. In this context one can study the conditions under which the organization can adapt itself to structural pressure from an environment. We show that local learning capabilities contribute to global performance improvements. We have implemented our theoretical framework in a workbench that can be used to run simulations. We discuss some results of these simulations. We believe that this approach provides a viable framework to study processes of self-organization and optimization of collaborative agent networks.	[Mulder, Wico; Adriaans, Pieter] Univ Amsterdam, Dept Comp Sci, NL-1098 XG Amsterdam, Netherlands	Mulder, W (reprint author), Univ Amsterdam, Dept Comp Sci, Sci Pk 107, NL-1098 XG Amsterdam, Netherlands.	wico.mulder@logica.com; pietera@science.uva.nl					Adriaans P, 2006, LECT NOTES ARTIF INT, V4201, P293; Adriaans P, 2009, IEEE T INFORM THEORY, V55, P444, DOI 10.1109/TIT.2008.2008152; Adriaans P.W., 1995, P 6 INT C HUM COMP I, P1109; Anderson E, 1997, LOCAL SEARCH COMBINA, P361; denHeijer E, 1996, INT J HUM-COMPUT INT, V8, P343; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hopcroft J. E., 2001, INTRO AUTOMATA THEOR, Vsecond; Li M, 2008, INTRO KOLMOGOROV COM; Mulder W, 2009, GRIDS MEET AUTONOMIC COMPUTING WORKSHOP - GMAC 2009, P43; Mulder W, 2006, INT FED INFO PROC, V224, P491; Sim KM, 2003, IEEE T SYST MAN CY A, V33, P560, DOI 10.1109/TSMCA.2003.817391	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15487-4	LECT NOTES ARTIF INT			2010	6339						163	177				15	Computer Science, Artificial Intelligence	Computer Science	BDB34	WOS:000312462500014		
J	Stuhlsatz, A; Lippel, J; Zielke, T			IEEE	Stuhlsatz, Andre; Lippel, Jens; Zielke, Thomas			Discriminative Feature Extraction with Deep Neural Networks	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE			CLASSIFIER NETWORKS; LEARNING ALGORITHM	We propose a framework for optimizing Deep Neural Networks (DNN) with the objective of learning low-dimensional discriminative features from high-dimensional complex patterns. In a two-stage process that effectively implements a Nonlinear Discriminant Analysis (NDA), we first pretrain a DNN using stochastic optimization, partly supervised and unsupervised. This stage involves layer-wise training and stacking of single Restricted Boltzmann Machines (RBM). The second stage performs fine-tuning of the DNN using a modified back-propagation algorithm that directly optimizes a Fisher criterion in the feature space spanned by the units of the last hidden-layer of the network. Our experimental results show that the features learned by a DNN using the proposed framework greatly facilitate classification, even when the discriminative features constitute a substantial dimension reduction.	[Stuhlsatz, Andre; Lippel, Jens; Zielke, Thomas] Univ Appl Sci Dusseldorf, Dept Mech & Proc Engn, Dusseldorf, Germany	Stuhlsatz, A (reprint author), Univ Appl Sci Dusseldorf, Dept Mech & Proc Engn, Dusseldorf, Germany.	andre.stuhlsatz@fh-duesseldorf.de; jens.lippel@fh-duesseldorf.de; thomas.zielke@fh-duesseldorf.de					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Asoh H., 1989, P INT JOINT C NEUR N, V2, P411; Asuncion A., 2007, UCI MACHINE LEARNING; FUKUNAGA K, 1980, IEEE T INFORM THEORY, V26, P59, DOI 10.1109/TIT.1980.1056140; GALLINARI P, 1991, NEURAL NETWORKS, V4, P349, DOI 10.1016/0893-6080(91)90071-C; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jiang JH, 1996, J CHEMOMETR, V10, P281, DOI 10.1002/(SICI)1099-128X(199607)10:4<281::AID-CEM417>3.0.CO;2-D; Larochelle H., 2009, J MACHINE LEARNING R; LeCun Y., MNIST DATABASE HANDW; Liu J. S., 2001, MONTE CARLO STRATEGI; LOWE D, 1991, IEEE T PATTERN ANAL, V13, P355, DOI 10.1109/34.88570; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; OSMAN H, 1994, IEEE T PATTERN ANAL, V16, P837, DOI 10.1109/34.308481; WEBB AR, 1990, NEURAL NETWORKS, V3, P367, DOI 10.1016/0893-6080(90)90019-H; Welling M., 2005, NIPS, V17, P1481	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-6917-8	IEEE IJCNN			2010												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421402067		
S	Xie, JY; Lu, HT; Nan, D; Cai, NB		Wang, FL; Deng, H; Gao, Y; Lei, JS		Xie, Jiongyun; Lu, Hongtao; Nan, Deng; Cai Nengbin			Sparse Deep Belief Net for Handwritten Digits Classification	ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, PT I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	International Conference on Artificial Intelligence and Computational Intelligence	OCT 23-24, 2010	Sanya, PEOPLES R CHINA	Hainan Province Inst Comp, Qiongzhou Univ		Deep Belief Network; Restricted Boltzmann Machine; Sparse Coding		It has been shown that the Deep Belief Network is good at modeling input distribution, and can be trained efficiently by the greedy layer-wise unsupervised learning. Hoglak Lee et al. (2008) introduced a sparse variant of the Deep Belief Network, which applied the Gaussian linear units to model the input data with a sparsity constraint. However, it takes much more weight updates to train the RBM (Restricted Boltzmann Machine) with Gaussian visible units, and the reconstruction error is much larger than training an RBM with binary visible units. Here, we propose another version of Sparse Deep Belief Net which applies the differentiable sparse coding method to train the first level of the deep network, and then train the higher layers with RBM. This hybrid model, combining the advantage of the Deep architecture and the sparse coding model, leads to state-of-the-art performance on the classification of handwritten digits.	[Xie, Jiongyun; Lu, Hongtao] Shanghai Jiao Tong Univ, Dept Comp Sci, MOE MS Key Lab Intelligent Comp & Intelligent Sys, Shanghai 200030, Peoples R China	Xie, JY (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci, MOE MS Key Lab Intelligent Comp & Intelligent Sys, Shanghai 200030, Peoples R China.	andingxie@gmail.com; lu-ht@cs.sjtu.edu.cn; dengnan1985@sina.cn; cainengbin@sina.cn					[Anonymous], MNIST DATABASE HANDW; Bengio Y., 2007, NIPS; Bradley D. M., 2008, NIPS; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Larochelle H., 2008, ICML; Lee H., 2008, NIPS; Lee H., 2006, NIPS; NAIR V, 2008, NIPS; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Raina R., 2007, ICML; Ranzato M., 2007, NIPS; Ranzato M., 2006, NIPS; Teh Y. W., 2003, J MACHINE LEARNING R, V4, P1235, DOI 10.1162/jmlr.2003.4.7-8.1235; Welling M., 2005, NIPS	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-16529-0	LECT NOTES ARTIF INT			2010	6319						71	78				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BVV40	WOS:000292891700010		
S	Gass, T; Deselaers, T; Ney, H		Denzler, J; Notni, G; Sube, H		Gass, Tobias; Deselaers, Thomas; Ney, Hermann			Deformation-Aware Log-Linear Models	PATTERN RECOGNITION, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	31st DAGM Symposium on Pattern Recognition	SEP 09-11, 2009	Jena, GERMANY	OLYMPUS Europe Fdn Sci Life, STIFT Thuringia, MVTec Software GmbH, Telekom Lab, Allied Vis Technol, Desko GmbH, Jenoptik AG, Optonet e V			SUPPORT VECTOR MACHINES; RECOGNITION; ALGORITHM	In this paper, we present a novel deformation-aware discriminative model for handwritten digit recognition. Unlike previous approaches our model directly considers image deformations and allows discriminative training of all parameters, including those accounting for non-linear transformations of the image. This is achieved by extending a log-linear framework to incorporate a latent deformation variable. The resulting model has an order of magnitude less parameters than competing approaches to handling image deformations. We tune and evaluate our approach on the USPS task and show its generalization capabilities by applying the tuned model to the MNIST task. We gain interesting insights and achieve highly competitive results on both tasks.	[Gass, Tobias; Deselaers, Thomas; Ney, Hermann] Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit Grp, Aachen, Germany	Gass, T (reprint author), Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit Grp, Aachen, Germany.	gass@i6.informatik.rwth-aachen.de; deselaers@i6.informatik.rwth-aachen.de; ney@i6.informatik.rwth-aachen.de	Gass, Tobias/C-2244-2013				Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Haasdonk B, 2002, INT C PATT RECOG, P864; HAASDONK B, 2005, THESIS A LUBWIGS U F; Heigold G, 2008, INT CONF ACOUST SPEE, P4045, DOI 10.1109/ICASSP.2008.4518542; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; KEYSERS D, 2002, LECT NOTES COMPUTER, V2449, P498; Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153; Keysers D, 2004, IEEE T PATTERN ANAL, V26, P269, DOI 10.1109/TPAMI.2004.1262198; Lafferty J., 2001, ICML; Memisevic R., 2007, CVPR; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Riedmiller M., 1993, ICNN; Simard P. Y., 2003, INT C DOC AN REC ICD, P958; Uchida S, 2005, IEICE T INF SYST, VE88D, P1781, DOI 10.1093/ietisy/e88-d.8.1781	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-03797-9	LECT NOTES COMPUT SC			2009	5748						201	210				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPK79	WOS:000279102000021		
B	Labbe, B; Herault, R; Chatelain, C		Wani, MA; Kantardzic, M; Palade, V; Kurgan, L; Qi, Y		Labbe, Benjamin; Herault, Romain; Chatelain, Clement			Learning Deep Neural Networks for High Dimensional Output Problems	EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS			English	Proceedings Paper	8th International Conference on Machine Learning and Applications	DEC 13-15, 2009	Miami Beach, FL	IEEE SMCS, Cal State Univ, Assoc Machine Learning & Appl, Univ Louisville		High dimensional output; Neural Networks; Image Segmentation		State-of-the-art pattern recognition methods have difficulties dealing with problems where the dimension of the output space is large. In this article, we propose a framework based on deep architectures (e.g. Deep Neural Networks) in order to deal with this issue. Deep architectures have proven to be efficient for high dimensional input problems such as image classification, due to their ability to embed the input space. The main contribution of this article is the extension of the embedding procedure to both the input and output spaces to easily handle complex outputs. Using this extension, inter-output dependencies can be modelled efficiently. This provides an interesting alternative to probabilistic models such as HAIM and CRF. Preliminary experiments on toy datasets and USPS character reconstruction show promising results.	[Labbe, Benjamin; Herault, Romain; Chatelain, Clement] INSA, LITIS EA 4108, F-76800 St Etienne, France	Labbe, B (reprint author), INSA, LITIS EA 4108, F-76800 St Etienne, France.	benjamin.labbe@insa-rouen.fr; romain.herault@insa-rouen.fr; clement.chatelain@insa-rouen.fr					Bengio Y., 2007, NIPS; BESAG J, 1986, J ROY STAT SOC B MET, V48, P259; Blaschko M. B., 2008, ECCV; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; COLLOBERT R, 2008, TORCH 5; Duda RO, 2000, PATTERN CLASSIFICATI; El Yacoubi A., 2002, IEEE T PAMI, V24, P172; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Larochelle H, 2009, J MACH LEARN RES, V10, P1; NICOLAS S, 2006, ICPR, V3, P292; Rabiner L.R., 1990, READINGS SPEECH RECO, P267; SZUMMER M, 2004, IWFHR, P32; Tsechpenakis G., 2007, ICCV, P1, DOI [DOI 10.1109/OCEANSE.2007.4302271, 10.1109/oceanse.2007.4302271]; Weston J., 2008, ICML 08, P1168; WESTON J, 2002, NIPS	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3926-3				2009							63	68		10.1109/ICMLA.2009.48		6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BVC15	WOS:000291011600009		
S	Linsker, R			IEEE	Linsker, Ralph			Neural Learning of Kalman Filtering, Kalman Control, and System Identification	IJCNN: 2009 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1- 6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 14-19, 2009	Atlanta, GA	Int Neural Network Soc, IEEE Computat Intelligence Soc			VISUAL-CORTEX; BAYESIAN-INFERENCE; CIRCUITS; MODEL; INFORMATION; NETWORK	This paper shows how to implement Kalman estimation (including filtering and prediction) and control, and system identification, within a neural network (NN) whose only input is a stream of noisy measurement data. The operation of the fully-integrated algorithm is illustrated by a numerical example. The resulting network is a multilayer recurrent NN that may be useful for engineering applications. The algorithm is found to impose constraints on the NN circuitry and architecture. It is of interest that the derived circuit bears certain resemblances to the putative 'local circuit' of mammalian cerebral cortex. These similarities are discussed with reference to speculations on the possible fundamental operations of cerebral cortex.	IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA	Linsker, R (reprint author), IBM Corp, TJ Watson Res Ctr, POB 218, Yorktown Hts, NY 10598 USA.	linsker@us.ibm.com					Callaway EM, 1998, ANNU REV NEUROSCI, V21, P47, DOI 10.1146/annurev.neuro.21.1.47; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; George D., 2005, P INT JOINT C NEUR N, V3, P1812, DOI DOI 10.1109/IJCNN.2005.1556155; GILBERT CD, 1983, ANNU REV NEUROSCI, V6, P217, DOI 10.1146/annurev.ne.06.030183.001245; Grossberg S, 2001, CEREB CORTEX, V11, P37, DOI 10.1093/cercor/11.1.37; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Kalman R.E., 1960, T ASME D, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lewicki MS, 1997, ADV NEUR IN, V9, P529; Linsker R, 2005, NEURAL NETWORKS, V18, P261, DOI 10.1016/j.neunet.2005.01.002; Linsker R, 2008, NEURAL NETWORKS, V21, P1328, DOI 10.1016/j.neunet.2008.05.002; LINSKER R, 1992, NEURAL COMPUT, V4, P691, DOI 10.1162/neco.1992.4.5.691; LINSKER R, 2008, Patent No. 7395251; Mountcastle V.B., 1998, PERCEPTUAL NEUROSCIE; Murata N, 1997, ADV NEUR IN, V9, P599; Poggio T, 2004, NATURE, V431, P768, DOI 10.1038/nature03014; Raizada RDS, 2001, VIS COGN, V8, P431; Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rao RPN, 2004, NEURAL COMPUT, V16, P1, DOI 10.1162/08997660460733976; Rao RPN, 2005, NEUROREPORT, V16, P1843, DOI 10.1097/01.wnr.0000183900.92901.fc; Rao RPN, 1999, VISION RES, V39, P1963, DOI 10.1016/S0042-6989(98)00279-X; Szirtes G, 2005, NEUROCOMPUTING, V65, P349, DOI 10.1016/j.neucom.2004.10.028; Szita I, 2004, NEURAL COMPUT, V16, P491, DOI 10.1162/089976604772744884; Todorov E, 2005, NEURAL COMPUT, V17, P1084, DOI 10.1162/0899766053491887; Yu A. J., 2005, ADV NEURAL INFORM PR, V17, P1577; Zemel R, 2005, ADV NEURAL INFORM PR, V17, P1609	28	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-3549-4	IEEE IJCNN			2009							2476	2483				8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BQB78	WOS:000280591601102		
B	Marin-Jimenez, MJ; de la Blanca, NP; Mendoza, MA; Lucena, M; Fuertes, JM			IEEE	Marin-Jimenez, M. J.; Perez de la Blanca, N.; Mendoza, M. A.; Lucena, M.; Fuertes, J. M.			LEARNING ACTION DESCRIPTORS FOR RECOGNITION	2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES			English	Proceedings Paper	10th International Workshop on Image Analysis for Multimedia Interactive Services	MAY 06-08, 2009	London, ENGLAND					This paper evaluates different Restricted Boltzmann Machines models in unsupervised, Semi-supervised and supervised frameworks using information front human actions. After feeding these multilayer models with low level features, we infer high-level discriminating features that highly improve the classification performance. This approach eliminates the difficult process of selecting good mid-level feature descriptors, changing the feature selection and extraction process by a learning stage. Two main contributions are presented. First, a new sequence-descriptor from accumulated histo-rams of optical flow (aHOF) is presented. Second, comparative results using unsupervised, supervised and semi-supervised classification experiments are shown. The results show that the RBM architectures provide very good results in our classification task and present very good properties for semi-supervised learning.	[Marin-Jimenez, M. J.; Perez de la Blanca, N.; Mendoza, M. A.] Univ Granada, Dept Comp Sci & AI, Granada, Spain	Marin-Jimenez, MJ (reprint author), Univ Granada, Dept Comp Sci & AI, Granada, Spain.		Marin-Jimenez, Manuel J./	Marin-Jimenez, Manuel J./0000-0001-9294-6714			Dollar P, 2005, 2 JOINT IEEE INT WOR, P65, DOI DOI 10.1109/VSPETS.2005.1570899; Efros A.A., 2003, ICCV, V2, P726; FARNEBACK G, 2003, P 13 SCAND C IM AN S, V2749, P363; Fathi A., 2008, CVPR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jun Yang, 2008, Statistical Analysis and Data Mining, V1, DOI 10.1002/sam.103; Laptev I., 2008, P CVPR 08; Larochelle H., 2008, P ICML; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; RAO C, 2001, CVPR, V2, P316; Salakhutdinov R., 2007, AI STAT; Schuldt C, 2004, P INT C PATT REC, V3, P32; Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119; Torralba A. B., 2008, CVPR	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3609-5				2009							5	8		10.1109/WIAMIS.2009.5031418		4	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BLZ16	WOS:000271486000002		
S	Norouzi, M; Ranjbar, M; Mori, G			IEEE	Norouzi, Mohammad; Ranjbar, Mani; Mori, Greg			Stacks of Convolutional Restricted Boltzmann Machines for Shift-Invariant Feature Learning	CVPR: 2009 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-4	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE-Computer-Society Conference on Computer Vision and Pattern Recognition Workshops	JUN 20-25, 2009	Miami Beach, FL	IEEE Comp Soc			OBJECT RECOGNITION; ALGORITHM	In this paper we present a method for learning classs-pecific features for recognition. Recently a greedy layerwise procedure was proposed to initialize weights of deep belief networks, by viewing each layer as a separate Restricted Boltzmann Machine (RBM). We develop the Convolutional RBM (C-RBM), a variant of the RBM model in which weights are shared to respect the spatial structure of images. This framework learns a set of features that can generate the images of a specific object class. Our feature extraction model is a four layer hierarchy of alternating filtering and maximum subsampling. We learn feature parameters of the first and third layers viewing them as separate C-RBMs. The outputs of our feature extraction hierarchy are then fed as input to a discriminative classifier It is experimentally demonstrated that the extracted features are effective for object detection, using them to obtain performance comparable to the state-of-the-art on handwritten digit recognition and pedestrian detection.	[Norouzi, Mohammad; Ranjbar, Mani; Mori, Greg] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Norouzi, M (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	mohammad@cs.sfu.ca; mra33@cs.sfu.ca; mori@cs.sfu.ca					Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Chen H, 2003, IEE P-VIS IMAGE SIGN, V150, P153, DOI 10.1049/ip-vis:20030362; Dalai N., 2005, P IEEE C COMP VIS PA; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Larochelle H., 2008, P INT C MACH LEARN; Lauer F, 2007, PATTERN RECOGN, V40, P1816, DOI 10.1016/j.patcog.2006.10.011; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2007, ADV NEURAL INFO PROC, P873; Lowe D. G., 2004, INT J COMPUT VISION, V60; Maji S., 2008, P IEEE C COMP VIS PA; Mutch J, 2006, P IEEE C COMP VIS PA; Ranzato M., 2007, P IEEE C COMP VIS PA; RANZATO M, 2006, ADV NEURAL INFO PROC; ROTH M, 2005, P IEEE C COMP VIS PA; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Teh Y. W., 2003, J MACHINE LEARNING R, V4, P1235, DOI 10.1162/jmlr.2003.4.7-8.1235; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Weiss Y., 2007, P IEEE C COMP VIS PA, P1; WELLING M, 2002, ADV NEURAL INFO PROC, P1383	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-3992-8	PROC CVPR IEEE			2009							2727	2734				8	Computer Science, Artificial Intelligence	Computer Science	BPK14	WOS:000279038001158		
J	Tibshirani, R				Tibshirani, Robert			DISCUSSION OF: TREELETS - AN ADAPTIVE MULTI-SCALE BASIS FOR SPARSE UNORDERED DATA	ANNALS OF APPLIED STATISTICS			English	Editorial Material									[Tibshirani, Robert] Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA; [Tibshirani, Robert] Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Tibshirani, R (reprint author), Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA.	tibs@stanford.edu					Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527	3	0	0	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	JUN	2008	2	2					482	483		10.1214/07-AOAS137D		2	Statistics & Probability	Mathematics	374QC	WOS:000261057800005		
S	Bileschi, S			IEEE	Bileschi, Stanley			Object Detection at Multiple Scales Improves Accuracy	19TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOLS 1-6	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	19th International Conference on Pattern Recognition (ICPR 2008)	DEC 08-11, 2008	Tampa, FL	IEEE			CORTEX; RECOGNITION	For detecting objects in natural visual scenes, several powerful image features have been proposed which can collectively be described as spatial histograms of oriented energy. The HoG [3], HMAX Cl [12], SIFT [10], and Shape Context feature [2] all represent an input image using with a discrete set of bins which accumulate evidence for oriented structures over a spatial region and a range of orientations. In this work, we generalize these techniques to allow for a foveated input image, rather than a rectilinear raster in order to improve object detection accuracy. The system lever-ages a spectrum of image measurements, from sharp, fine-scale image sampling within a small spatial region to coarse-scale sampling of a wide field of view In the experiments we show that features generated from the foveoted input format produce detectors of greater accuracy, as measured for four object types from commonly available data-sets.	MIT, Cambridge, MA 02139 USA	Bileschi, S (reprint author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	bileschi@mit.edu					BELONGIE S, 2002, SHAPE MATCHING OBJEC; Dalal N., 2005, P CVPR, VII, P886; Everingham M., 2007, PASCAL VISUAL OBJECT, P4; Friedman J., 1998, ADDITIVE LOGISTIC RE; Fukushima K, 2004, NEURAL NETWORKS, V17, P37, DOI 10.1016/S0893-6080(03)00078-9; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; LECUN Y, 2004, LEARNING METHODS GEN; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Perko R, 2007, LECT NOTES ARTIF INT, V4840, P216; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Russell B., 2007, INT J COMPUTER VISIO; SCHNEIDERMAN H, 2000, STAT MODEL 3D OBJECT; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; SIVIC J, 2005, DISCOVERING OBJECTS, V1, P370; Torralba A., 2003, INT J COMPUT VISION, V53, P153; WOLF L, 2006, P IEEE C COMP VIS PA	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1051-4651		978-1-4244-2174-9	INT C PATT RECOG			2008							1046	1050				5	Computer Science, Artificial Intelligence	Computer Science	BJC36	WOS:000264729000257		
B	Jerry, CLL; Eizenman, M			IA ENG	Jerry, Chi Ling Lam; Eizenman, Moshe			Convolutional Neural Networks for eye detection in remote gaze estimation systems	IMECS 2008: INTERNATIONAL MULTICONFERENCE OF ENGINEERS AND COMPUTER SCIENTISTS, VOLS I AND II	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	International Multiconference of Engineers and Computer Scientists	MAR 19-21, 2008	Hong Kong, PEOPLES R CHINA	Int Assoc Engn, Int Assoc Engn, Soc Artificial Intelligence, Int Assoc Engn, Soc Bioinformat, Int Assoc Engn, Soc Comp Sci, Int Assoc Engn, Soc Data Mining, Int Assoc Engn, Soc Elect Engn, Int Assoc Engn, Soc Imaging Engn, Int Assoc Engn, Soc Info Syst Eng, Int Assoc Engn, Soc Internet Comp & Web Serv, Int Assoc Engn, Soc Mech Engn, Int Assoc Engn, Operat Res, Int Assoc Engn, Sci Comp, Int Assoc Engn, Soc Software Engn, Int Assoc Engn, Soc Wireless Networks		Convolutional Neural Networks; remote gaze estimation; eye detection; image processing	DEFORMABLE TEMPLATES; COMPUTER-INTERFACE; FEATURE-EXTRACTION; FACE DETECTION	An eye detection algorithm based on Convolutional Neural Networks (CNN) architecture was developed. The algorithm was designed to detect eyes in video images from a remote gaze estimation system that is part of a gaze-controlled human-computer interface. The CNN for eye detection has two stages of convolutional and sub-sampling layers followed by a fully connected feed forward neural network with a total of 1227 trainable parameters. Experiments with 3 subjects showed that for the full range of expected head movements, the CNN achieved a detection rate of 100%, for images with fully opened eyes, and a false alarm rate of 2.65 X 10-(4) %. The CNN failed to detect eyes that were either partially or completely covered by the eyelids. The CNN for eye detection did not require pre-processing or normalization and was shown to be robust to changes in scale, rotation and illumination of the eyes.	[Jerry, Chi Ling Lam; Eizenman, Moshe] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 3G9, Canada	Jerry, CLL (reprint author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 3G9, Canada.						Becker S., 1989, P 1988 CONN MOD SUMM, P29; BEYMER D, 1993, EXAMPLE BASED IMAGE; CLEVELAND D, 1999, P TECH C OC MEAS DRI, P57; COZZI A, 2001, P INT C ART NEUR NET, P993; EIZENMAN M, 1999, P 31 AN C ERG SAF HA; Eizenman M, 2003, PSYCHIAT RES, V118, P117, DOI 10.1016/S0165-1781(03)00068-4; FASEL B, 2002, P INT C PATT REC ICP, V2, P40; Feraud R, 2001, IEEE T PATTERN ANAL, V23, P42, DOI 10.1109/34.899945; FREY LA, 1990, IEEE T SYST MAN CYB, V20, P944, DOI 10.1109/21.105094; Goldberg JH, 1999, INT J IND ERGONOM, V24, P631, DOI 10.1016/S0169-8141(98)00068-7; Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952; HARBLUK JL, 2002, P TRANSP RES BOARD 8; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang J., 1998, P 14 INT C PATT REC, V1, P154, DOI 10.1109/ICPR.1998.711102; HUANG W, 1998, P INT C PATT REC, V1, P110; HUANG WM, 2000, P INT C PATT REC ICP, P722; HUTCHINSON TE, 1989, IEEE T SYST MAN CYB, V19, P1527, DOI 10.1109/21.44068; JI Q, 2002, P 16 INT C PATT REC, V4, P40310; Kin-Man Lam, 1996, Pattern Recognition, V29; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LEE DD, 1998, NIPS 97 P 1997 C ADV, V10, P908; Motwani M.C., 2004, P GSPX, P27; NOWLAN S, 1995, ADV NEURAL INFORMATI, V7, P901; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; PENG H, 1998, P ICSP 98 OCT, P1088; Sarle W. S., 1995, P 27 S INT COMP SCI, P352; Sharma R, 1998, P IEEE, V86, P853, DOI 10.1109/5.664275; Stiefelhagen R., 1997, P WORKSH PERC US INT, P98; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Wetzel P. A., 1997, ALHRTR19960145; XIE X, 1994, PATTERN RECOGN, V27, P791, DOI 10.1016/0031-3203(94)90164-3; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169	32	0	0	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA			978-988-98671-8-8	LECT NOTES ENG COMP			2008							601	606				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Manufacturing; Engineering, Electrical & Electronic; Mathematical & Computational Biology; Mathematics, Applied; Telecommunications	Automation & Control Systems; Computer Science; Engineering; Mathematical & Computational Biology; Mathematics; Telecommunications	BHV15	WOS:000256665700112		
J	Bellemare, MG; Precup, D		Veloso, MM		Bellemare, Marc G.; Precup, Doina			Context-Driven Predictions	20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE			English	Proceedings Paper	20th International Joint Conference on Artificial Intelligence	JAN 06-12, 2007	Hyderabad, INDIA			Prediction learning; associative memories; context-based model		Markov models have been a keystone in Artificial Intelligence for many decades. However, they remain unsatisfactory when the environment modelled is partially observable. There are pathological examples where no history of fixed length is sufficient for accurate prediction or decision making. On the other hand, working with a hidden state (like in Hidden Markov Models or Partially Observable Markov Decision Processes) has a high computational cost. In order to circumvent this problem, we suggest the use of a context-based model. Our approach replaces strict transition probabilities by influences on transitions. The method proposed provides a trade-off between a fully and partially observable model. We also discuss the capacity of our framework to model hierarchical knowledge and abstraction. Simple examples are given in order to show the advantages of the algorithm.	[Bellemare, Marc G.; Precup, Doina] McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2T5, Canada	Bellemare, MG (reprint author), McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2T5, Canada.	marcgb@cs.mcgill.ca; dprecup@cs.mcgill.ca					BARTO AG, 1981, BIOL CYBERN, V40, P201, DOI 10.1007/BF00453370; BOSE J, 2005, P INT JOINT C NEUR N; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; FAHLMAN SE, 1983, P NAT C ART INT; FURBER SB, 2004, NEURAL NETWORKS, V10; GOPALRATNAM K, 2007, IEEE INTELLIGENT SYS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X; KANERVA P, 1993, ASS NEURAL MEMORIES, pCH3; Littman ML, 2002, ADV NEUR IN, V14, P1555; McCallum A., 1995, THESIS U ROCHESTER; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAO RPN, 1996, 14 INT C SIM AD BEH; RATITCH B, 2004, P 15 EUR C MACH LEAR; Sutton R., 2005, ADV NEURAL INFORM PR, V17, P1377; Sutton R. S., 1995, P 12 INT C MACH LEAR, P531; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Taylor G.W., 2007, ADV NEURAL INFORM PR, V19	19	0	0	IJCAI-INT JOINT CONF ARTIF INTELL	FREIBURG	ALBERT-LUDWIGS UNIV FREIBURG GEORGES-KOHLER-ALLEE, INST INFORMATIK, GEB 052, FREIBURG, D-79110, GERMANY							2007							250	255				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BRU54	WOS:000283721000037		
S	Lasserre, J; Kannan, A; Winn, J			IEEE	Lasserre, Julia; Kannan, Anitha; Winn, John			Hybrid learning of large jigsaws	2007 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-8	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO				A jigsaw is a recently proposed generative model that describes an image as a composition of non-overlapping patches of varying shape, extracted from a latent image. By learning the latent jigsaw image which best explains a set of images, it is possible to discover the shape, size and appearance of repeated structures in the images. A challenge when learning this model is the very large space of possible jigsaw pixels which can potentially be used to explain each image pixel. The previous method of inference for this model scales linearly with the number of jigsaw pixels, making it unusable for learning the large jigsaws needed for many practical applications. In this paper, we make three contributions that enable the learning of large jigsaws - a novel sparse belief propagation algorithm, a hybrid method which significantly improves the sparseness of this algorithm, and a method that uses these techniques to make learning of large jigsaws feasible. We provide detailed analysis of how our hybrid inference method leads to significant savings in memory and computation time. To demonstrate the success of our method, we present experimental results applying large jigsaws to an object recognition task.	Univ Cambridge, Dept Engn, Cambridge CB2 1TN, England	Lasserre, J (reprint author), Univ Cambridge, Dept Engn, Cambridge CB2 1TN, England.	ja162@cam.ac.uk; ankannan@microsoft.com; jwinn@microsoft.com					Borenstein E., 2004, P IEEE WORKSH PERC O; Bouchard G., 2004, IASC INT S COMP STAT, P721; Boykov Y., 2001, PAMI, V23; COUGHLAN J, 2002, ECCV, V3, P453; Fergus R., 2003, CVPR, V2, pII, DOI DOI 10.1109/CVPR.2003.1211479; HINTON G, 2006, NIPS, V18, P515; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUTTENLOCHER D, 2005, P IEEE CVPR; Jojic N., 2003, ICCV; KANNAN A, 2007, NIPS, V19; KOMODAKIS N, 2006, IEEE CVPR; LASSERRE J, 2006, IEE CVPR; LEPETIT V, 2005, CVPR, P775; Pal C, 2006, P IEEE INT C AC SPEE; Shotton J., 2006, ECCV	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-1179-5	PROC CVPR IEEE			2007							996	1003				8	Computer Science, Software Engineering; Mathematical & Computational Biology; Remote Sensing; Imaging Science & Photographic Technology	Computer Science; Mathematical & Computational Biology; Remote Sensing; Imaging Science & Photographic Technology	BGT02	WOS:000250382802012		
B	Lecun, Y; Chopra, S; Ranzato, M; Huang, FJ		Werner, B		LeCun, Yann; Chopra, Sumit; Ranzato, Marc'Aurelio; Huang, Fu-Jie			Energy-based models in document recognition and computer vision	ICDAR 2007: NINTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS			English	Proceedings Paper	9th International Conference on Document Analysis and Recognition	SEP   23, 2007-SEP 26, 2009	Curitiba, BRAZIL	Int Assoc Pattern Recognit TC 10, Int Assoc Pattern Recognit TC 11				The Machine Learning and Pattern Recognition communities are facing two challenges: solving the normalization problem, and solving the deep learning problem. The normalization problem is related to the difficulty of training probabilistic models over large spaces while keeping them properly normalized. In recent years, the ML and Natural Language communities have devoted considerable efforts to circumventing this problem by developing "unnormalized" learning models for tasks in which the output is highly structured (e.g. English sentences). This class of models was in fact originally developed during the 90's in the handwriting recognition community, and includes Graph Tran former Networks, Conditional Random Fields, Hidden Markov SVMs, and Maximum Margin Markov Networks. We describe these models within the unifying framework, of "Energy-Based Models" (EBM). The Deep Learning Problem is related to the issue of training all the levels of a recognition system (e.g. segmentation, feature extraction, recognition, etc) in an integrated fashion. We first consider "traditional" methods for deep learning, such as convolutional networks and back-propagation, and show that, although they produce very low error rates for handwriting and object recognition, they require many training samples. We show that using unsupervised learning to initialize the layers of a deep network dramatically reduces the required number of training samples, particularly for such tasks as the recognition of everyday objects at the category level.	[LeCun, Yann; Chopra, Sumit; Ranzato, Marc'Aurelio; Huang, Fu-Jie] NYU, Courant Inst Math Sci, New York, NY 10011 USA	Lecun, Y (reprint author), NYU, Courant Inst Math Sci, New York, NY 10011 USA.						Altun Y., 2003, P EMNLP; Bahl L. R., 1986, P IEEE INT C AC SPEE, P49; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2007, NIPS; Bottou L., 1991, THESIS U PARIS 11; BREUEL TM, 1994, P 12 INT C PATT REC, V2, P129, DOI 10.1109/ICPR.1994.576889; COLIINS M, 2002, P EMLP; DENKER JS, 1995, MATH INDUCTION; DRIANCOURT X, 1991, P INT C ARTIFICIAL N; Garcia C., 2002, IEEE IAPR INT C PATT, P40; HADSELL R, 2006, P COMPUTER VISION PA; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HUANG FJ, 2006, P COMPUTER VISION PA; LAFFERTY J, 2001, P INT C MACHINE LEAR; LeCun Y, 1994, P 12 ICPR JER, VII, P88, DOI 10.1109/ICPR.1994.576881; LECUN Y, PREDICTING STRUCTURE; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 2005, ADV NEURAL INFORM PR; Lecun Y., 2004, P CVPR 04; Ljolje A., 1990, P ICASSP 90, P709; Marc'Aurelio R., 2006, ADV NEURAL INFORM PR; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; RANZATO M, 2007, P ICDAR; RANZATO M, 2007, P COMPUTER VISION PA; Simard P .Y, 2003, P INT C DOC AN REC, P958; Taskar B., 2003, P NIPS	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-2822-9				2007							337	341				5	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BHC21	WOS:000252162600068		
S	Ranzato, M; Huang, FJ; Boureau, YL; LeCun, Y			IEEE	Ranzato, Marc'Aurelio; Huang, Fu Jie; Boureau, Y-Lan; LeCun, Yann			Unsupervised learning of invariant feature hierarchies with applications to object recognition	2007 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-8	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO				We present an unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions. The resulting feature extractor consists of multiple convolution filters, followed by a feature-pooling layer that computes the max of each filter output within adjacent windows, and a point-wise sigmoid non-linearity. A second level of larger and more invariant features is obtained by training the same algorithm on patches of features from the first level. Training a supervised classifier on these features yields 0.64% error on MNIST and 54% average recognition rate on Caltech 101 with 30 training samples per category. While the resulting architecture is similar to convolutional networks, the layer-wise unsupervised training procedure alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples.	NYU, Courant Inst Math Sci, New York, NY 10011 USA	Ranzato, M (reprint author), NYU, Courant Inst Math Sci, New York, NY 10011 USA.	ranzato@cs.nyu.edu; jhuangfu@cs.nyu.edu; ylan@cs.nyu.edu; yann@cs.nyu.edu					AMIT A, 2005, POP PATCHWORK PARTS; Bengio Y., 2007, NIPS; Berg A., 2005, CVPR; DOI E, 2006, NIPS; Fei-Fei L., 2004, CVPR WORKSH; FUKUSHIMA K, 1982, PATTERN RECOGNITION; GRIFFIN G, 2006, CALTECH 256; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUANG FJ, 2006, CVPR; Lazebnik S., 2004, BMVC; Lazebnik S., 2006, CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lowe D., 2004, INT J COMPUTER VISIO; MOGHADDAM B, 1995, ICCV             JUN; Murphy K, 2005, CATEGORY LEVEL OBJEC; Mutch J., 2006, CVPR; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Ranzato M., 2006, NIPS; Serre T., 2005, CVPR; Zhang H., 2006, CVPR	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-1179-5	PROC CVPR IEEE			2007							1429	1436				8	Computer Science, Software Engineering; Mathematical & Computational Biology; Remote Sensing; Imaging Science & Photographic Technology	Computer Science; Mathematical & Computational Biology; Remote Sensing; Imaging Science & Photographic Technology	BGT02	WOS:000250382803001		
S	Tzortzis, G; Likas, A			IEEE Comp Soc	Tzortzis, Grigorios; Likas, Aristidis			Deep Belief Networks for spam filtering	19TH IEEE INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, VOL II, PROCEEDINGS	Proceedings-International Conference on Tools With Artificial Intelligence		English	Proceedings Paper	19th IEEE International Conference on Tools with Artificial Intelligence	OCT 29-31, 2007	Patras, GREECE	IEEE Comp Soc, Biol & Artificial Intelligence Soc, Univ Patras, Wright State Univ, ATRC				This paper proposes a novel approach for spam filtering based on the use of Deep Belief Networks (DBNs). In contrast to conventional feedfoward neural networks having one or two hidden layers, DBNs are feedforward neural networks with many hidden layers. Until recently it was not clear how to initialize the weights of deep neural networks, which resulted in poor solutions with low generalization capabilities. A greedy layer-wise unsupervised algorithm was recently proposed to tackle this problem with successful results. In this work we present a methodology for spam detection based on DBNs and evaluate its performance on three widely used datasets. We also compare our method to Support Vector Machines (SVMs) which is the state-of-the-art method for spam filtering in terms of classification performance. Our experiments indicate that using DBNs to filter spam e-mails is a viable methodology, since they achieve similar or even better performance than SVMs on all three datasets.	[Tzortzis, Grigorios; Likas, Aristidis] Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece	Tzortzis, G (reprint author), Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece.	gtzortzi@cs.uoi.gr; arly@cs.uoi.gr					ANDROUTSOPOULOS I, 2004, 20042 NCSR; Bengio Y., 2006, NEURAL INFORM PROCES; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Fumera G, 2006, J MACH LEARN RES, V7, P2699; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOVOLD J, 2005, 2 C EM ANT CEAS 2005; Metsis V., 2006, 3 C EM ANT CEAS 2006; Zhang L., 2004, ACM T ASIAN LANGUAGE, V3, P243, DOI 10.1145/1039621.1039625	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409			PROC INT C TOOLS ART			2007							306	309		10.1109/ICTAI.2007.65		4	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BHH43	WOS:000253293000048		
B	Zeng, XH; Luo, SW; Wang, J				Zeng, Xian-Hua; Luo, Si-Wei; Wang, Jiao			Auto-associative neural network system for recognition	PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7			English	Proceedings Paper	6th International Conference on Machine Learning and Cybernetics	AUG 19-22, 2007	Hong Kong, PEOPLES R CHINA	Machine Learning & Cybernet Res Inst, Hebei Univ, IEEE Syst Man & Cybernet Soc, Harbin Inst Technol Shenzhen Grad Sch, Chinese Univ Hong Kong, City Univ Hong Kong, Hong Kong Baptist Univ, Hong Kong Univ Sci & Technol, Int Fuzzy Syst Assoc, Hebei Univ Sci & Technol		Restricted Boltzman Machine (RBM); Autoencoder; Auto-Associative Neural Network System	NONLINEAR DIMENSIONALITY REDUCTION; COMPONENT ANALYSIS	Recently, a nonlinear dimension reduction technique, called Autoencoder, had been proposed. It can efficiently carry out mappings in both directions between the original data and low-dimensional code space. However, a single Autoencoder commonly maps all data into a single subspace. If the original data set have remarkable different categories (for example, characters and handwritten digits), then only one Autoencoder will not be efficient. To deal with the data of remarkable different categories, this paper proposes an Auto-Associative Neural Network System (AANNS) based on multiple Autoencoders. The novel technique has the functions of auto-association, incremental learning and local update. Excitingly, these functions are the foundations of cognitive science. Experimental results on benchmark MNIST digit dataset and handwritten character-digit dataset show the advantages of the proposed model.	[Zeng, Xian-Hua; Luo, Si-Wei; Wang, Jiao] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China	Zeng, XH (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.						GARRISON W, 2006, SCIENCE, V313, P545; Hinton G, 2006, COGNITIVE SCI, V30, P725, DOI 10.1207/s15516709cog0000_76; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; HINTON GE, 200604 UTML; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 2006, REDUCING DIMENSIONAL; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; KARHUNEN J, 1995, NEURAL NETWORKS, V8, P549, DOI 10.1016/0893-6080(94)00098-7; Memisevic R, 2005, NEURAL NETWORKS, V18, P702, DOI 10.1016/j.neunet.2005.06.034; *MNIST, MNIST DAT AV RES MAN; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; ZHANG JP, 2005, INTELLIGENT MULTIMED, P281	14	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0972-3				2007							2885	2890				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	BGZ09	WOS:000251433404088		
