PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
J	Fawcett, T				Fawcett, T			An introduction to ROC analysis	PATTERN RECOGNITION LETTERS			English	Article						ROC analysis; classifier evaluation; evaluation metrics	CLASSIFICATION; CURVE; AREA	Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research. (c) 2005 Elsevier B.V. All rights reserved.	Inst Study Learning & Expertise, Palo Alto, CA 94306 USA	Fawcett, T (reprint author), Inst Study Learning & Expertise, 2164 Staunton Court, Palo Alto, CA 94306 USA.	tfawcett@acm.org	Exarchos, Konstantinos/B-5978-2008				Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 1984, CLASSIFICATION REGRE; CLEARWATER SH, 1991, COMPUT PHYS COMMUN, V67, P159, DOI 10.1016/0010-4655(91)90014-C; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; EGAN JP, 1975, SIGNAL DETECTION THE; Fawcett T., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989510; FAWCETT T., 1996, P 2 INT C KNOWL DISC, P8; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Flach P., 2003, P 2003 UK WORKSH COM, P38; FORMAN G, 2002, P 1 INT WORKSH DAT M; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; HOLTE R, 2002, COMMUNICATION; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; LANE T, 2000, ICML 2000 WORKSH COS; LEWIS D, 1990, P WORKSH SPEECH NAT, P288, DOI 10.3115/116580.116681; Lewis D. D., 1991, P SPEECH NAT LANG WO, P312, DOI 10.3115/112405.112471; MACSKASSY S, 2004, P 1 WORKSH ROC AN AI; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; PROVOST F, 2001, IS0004 CEDER NEW YOR; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; Saitta L, 1998, MACH LEARN, V30, P133, DOI 10.1023/A:1007448122119; Spackman K.A., 1989, P 6 INT WORKSH MACH, P160; Srinivasan A., 1999, PRGTR299 OXF U COMP; Swets JA, 2000, SCI AM, V283, P82; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; VANDERPUTTEN P, 2000, 200009 U VANL LEID I; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609; Zou K. H., 2002, RECEIVER OPERATING C	31	1591	1655	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2006	27	8					861	874		10.1016/j.patrec.2005.10.010		14	Computer Science, Artificial Intelligence	Computer Science	041NL	WOS:000237462800002	
J	Kanungo, T; Mount, DM; Netanyahu, NS; Piatko, CD; Silverman, R; Wu, AY				Kanungo, T; Mount, DM; Netanyahu, NS; Piatko, CD; Silverman, R; Wu, AY			An efficient k-means clustering algorithm: Analysis and implementation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; machine learning; data mining; k-means clustering; nearest-neighbor searching; k-d tree; computational geometry; knowledge discovery	THEOREM	In k-means clustering, we are given a set of n data points in d-dimensional space R-d and an integer k and the problem is to determine a set of k points in R-d, called centers, so as to minimize the mean squared distance from each data point to its nearest center. A popular heuristic for k-means clustering is Lloyd's algorithm. In this paper, we present a simple and efficient implementation of Lloyd's k-means clustering algorithm, which we call the filtering algorithm. This algorithm is easy to implement, requiring a kd-tree as the only major data structure. We establish the practical efficiency of the filtering algorithm in two ways. First, we present a data-sensitive analysis of the algorithm's running time, which shows that the algorithm runs faster as the separation between clusters increases. Second, we present a number of empirical studies both on synthetically generated data and on real data sets from applications in color quantization, data compression, and image segmentation.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA; Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA; Bar Ilan Univ, Dept Math & Comp Sci, IL-52900 Ramat Gan, Israel; Johns Hopkins Univ, Appl Phys Lab, Laurel, MD 20723 USA; Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; American Univ, Dept Comp Sci & Informat Syst, Washington, DC 20016 USA	Kanungo, T (reprint author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.		gong, junie/G-5880-2010; Piatko, Christine/H-3422-2013				Agarwal P.K., 1998, P 9 ACM SIAM S DISCR, P658; Alsabti K., 1998, P 1 WORKSH HIGH PERF; Arora S., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276718; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Arya S, 2000, COMP GEOM-THEOR APPL, V17, P135, DOI 10.1016/S0925-7721(00)00022-5; Ball G.H., 1964, P INT C MICR CIRC TH; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bottou Lon, 1995, ADV NEURAL INFORMATI, V7, P585; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; CAPOYLEAS V, 1991, J ALGORITHM, V12, P341, DOI 10.1016/0196-6774(91)90007-L; COGGINS JM, 1985, PATTERN RECOGN LETT, V3, P195, DOI 10.1016/0167-8655(85)90053-4; Dasgupta S., 1999, P 40 ANN S FDN COMP, P634; Dasgupta S., 2000, P 16 C UNC ART INT, P152; Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836; Duda R., 1973, PATTERN CLASSIFICATI; Ester M., 1995, P 1 INT C KNOWL DISC, P94; Faber V., 1994, LOS ALAMOS SCI, V22, P138; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Feller W., 1968, INTRO PROBABILITY TH; FORGY EW, 1965, BIOMETRICS, V21, P768; Fukunaga K., 1990, INTRO STAT PATTERN R; Garey M. R., 1979, COMPUTERS INTRACTABI; Gersho A., 1992, VECTOR QUANTIZATION; INABA M, 1996, P 12 ANN ACM S COMP; Inaba M., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, DOI 10.1145/177424.178042; INABA M, 1997, COMMUNICATION; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; KANUNGO T, 1999, P 10 ANN ACM SIAM S, pS931; KANUNGO T, 2000, CARTR937 U MAR; Kanungo T., 2000, P 16 ANN ACM S COMP, P100, DOI 10.1145/336154.336189; Kaufman L., 1990, FINDING GROUPS DATA; Kohonen T., 1989, SELF ORG ASS MEMORY; Kolliopoulos S., 1999, P 7 ANN EUR S ALG JU, P362; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; MANEEWONGVATANA S, 1999, P WORKSH ALG ENG EXP; Mangasarian OL, 1997, DATA MIN KNOWL DISC, V1, P183, DOI 10.1023/A:1009735908398; Matousek J, 2000, DISCRETE COMPUT GEOM, V24, P61; MOORE A, 1998, P C NEUR INF PROC SY; MOUNT DM, 1997, P CTR GEOM COMP 2 AN; Ng R, 1994, P 20 INT C VER LARG, P144; Pelleg D., 2000, P 17 INT C MACH LEAR; PELLEG D, 1999, P ACM SIGKDD INT C K, P277, DOI 10.1145/312129.312248; POLLARD D, 1982, ANN PROBAB, V10, P919, DOI 10.1214/aop/1176993713; Preparata F.P., 1990, COMPUTATIONAL GEOMET; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328	50	585	637	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					881	892		10.1109/TPAMI.2002.1017616		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	566UF	WOS:000176446100002	
J	Vesanto, J; Alhoniemi, E				Vesanto, J; Alhoniemi, E			Clustering of the self-organizing map	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						clustering; data mining; exploratory data analysis; self-organizing map	QUANTIZATION; NETWORK	The self-organizing map (SOM) is an excellent tool in exploratory phase of data mining. It projects input space on prototypes of a low-dimensional regular grid that can be effectively utilized to visualize and explore properties of the data. When the number of SOM units is large, to facilitate quantitative analysis of the map and the data, similar units need to be grouped, i.e., clustered. In this paper, different approaches to clustering of the SOM are considered, In particular, the use of hierarchical agglomerative clustering and partitive clustering using Ic-means are investigated. The two-stage procedure-first using SOM to produce the prototypes that are then clustered in the second stage-is found to perform well when compared with direct clustering of the data and to reduce the computation time.	Helsinki Univ Technol, Neural Networks Res Ctr, Helsinki, Finland	Vesanto, J (reprint author), Helsinki Univ Technol, Neural Networks Res Ctr, Helsinki, Finland.						Alahakoon D., 1998, Proceedings of the 5th International Conference on Soft Computing and Information/Intelligent Systems. Methodologies for the Conception, Design and Application of Soft Computing; Bezdek J.C., 1992, FUZZY MODELS PATTERN; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Blackmore J., 1995, P 12 INT C MACH LEAR, P55; Blatt M, 1996, PHYS REV LETT, V76, P3251, DOI 10.1103/PhysRevLett.76.3251; BOUDAILLIER E, 1998, INTELL DATA ANAL, V2; BUHMANN J, 1993, NEURAL COMPUT, V5, P75, DOI 10.1162/neco.1993.5.1.75; CHENG Y, 1992, P INT JOINT C NEUR N, V4, P785, DOI 10.1109/IJCNN.1992.227222; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199; FLANAGAN JK, 1989, P INT C AC SPEECH SI, V3, P1759; FRITZKE B, 1991, ARTIFICIAL NEURAL NETWORKS, VOLS 1 AND 2, P403; FRITZKE B, 1995, NEURAL PROCESS LETT, V2, P9, DOI 10.1007/BF02332159; GERSHO A, 1979, IEEE T INFORM THEORY, V25, P373, DOI 10.1109/TIT.1979.1056067; Graepel T, 1997, PHYS REV E, V56, P3876, DOI 10.1103/PhysRevE.56.3876; IIVARINEN J, 1994, P C ART INT RES FINL, P122; JOCKUSCH S, 1990, PARALLEL PROCESSING IN NEURAL SYSTEMS AND COMPUTERS, P169; Kangas J A, 1990, IEEE Trans Neural Netw, V1, P93, DOI 10.1109/72.80208; KARYPIS G, 1999, IEEE COMPUT, V32, P68, DOI DOI 10.1109/2.781637; Kaski S., 1999, P 6 INT C NEUR INF P, P729; Kohonen T., 1995, SELF ORG MAPS, V30; KOHONEN T, 1999, NEURAL COMPUT, V11, P2171; KOHONEN T, 1991, ARTIFICIAL NEURAL NETWORKS, VOLS 1 AND 2, P981; KOHONEN T, 2000, IEEE T NEURAL NETWOR, V11, pR30; KOIKKALAINEN P, 1995, P ICANN 95 INT C ART, V2, P63; KRAAIJVELD MA, 1995, IEEE T NEURAL NETWOR, V6, P548, DOI 10.1109/72.377962; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Lampinen J., 1992, Journal of Mathematical Imaging and Vision, V2, DOI 10.1007/BF00118594; Lawrence RD, 1999, DATA MIN KNOWL DISC, V3, P171, DOI 10.1023/A:1009817804059; Luttrell S. P., 1989, P 1 IEE C ART NEUR N, P2; MANGIAMELI P, 1996, EUR J OPER RES, V93; MARTINETZ T, 1991, ARTIFICIAL NEURAL NETWORKS, VOLS 1 AND 2, P397; MCLAHLAN GJ, 1987, MIXTURE MODELS INFER, V84; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; MURTAGH F, 1995, PATTERN RECOGN LETT, V16, P399, DOI 10.1016/0167-8655(94)00113-H; Pyle D, 1999, DATA PREPARATION DAT; RITTER H, 1991, IEEE T NEURAL NETWOR, V2, P173, DOI 10.1109/72.80310; RODRIGUES JS, 1990, P INNC 90 INT NEUR N, P813; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Simula O, 1999, INT SER COMPUTAT INT, P87; Ultsch A, 1990, P INT NEUR NETW C IN, P305; Vaisey J., 1988, P INT C AC SPEECH SI, P1176; Varfis A, 1993, P NATO ASI WORKSH ST; Varfis A., 1992, NEURAL NETW WORLD, V2, P813; Vesanto J., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00013-X; ZADOR PL, 1982, IEEE T INFORM THEORY, V28, P139, DOI 10.1109/TIT.1982.1056490; ZHANG X, 1993, P INT JOINT C NEUR N, P2448	49	584	603	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2000	11	3					586	600		10.1109/72.846731		15	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	326JM	WOS:000087732100005	
J	Barnard, K; Duygulu, P; Forsyth, D; de Freitas, N; Blei, DM; Jordan, MI				Barnard, K; Duygulu, P; Forsyth, D; de Freitas, N; Blei, DM; Jordan, MI			Matching words and pictures	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article; Proceedings Paper	Workshop on Machine Learning Methods for Text and Images	2001	VANCOUVER, CANADA				IMAGE SEGMENTATION; ALGORITHM; VIDEO	We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et at.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data.	Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA; Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey; Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA; Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada; Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Barnard, K (reprint author), Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.						Armitage LH, 1997, J INFORM SCI, V23, P287, DOI 10.1177/016555159702300403; Barnard K., 2001, INT C COMP VIS, P408; BARNARD K, 2001, IEEE C COMP VIS PATT, P434; Brown P. F., 1993, Computational Linguistics, V19; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Celeux G., 1995, 2514 INRIA; CHEN F, 1999, SPIE DOCUMENT RECOGN; Chen JY, 2000, IEEE T IMAGE PROCESS, V9, P442, DOI 10.1109/83.826781; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duygulu P, 2002, 7 EUR C COMP VIS, P97; Enser P. G. B., 1993, Journal of Document and Text Management, V1; ENSER PGB, 1995, J DOC, V51, P126, DOI 10.1108/eb026946; Forsyth D., 2002, COMPUTER VISION MODE; Forsyth DA, 1999, LIBR TRENDS, V48, P326; Hofmann T., 1998, WORKSH LEARN TEXT WE; JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710; Jurafsky D., 2000, SPEECH LANGUAGE PROC; KEISTER LH, 1994, CHALLENGES INDEXING; La Cascia M, 1998, IEEE WORKSH CONT BAS; Manning C. D., 1999, FDN STAT NATURAL LAN; Markkula M., 2000, Information Retrieval, V1, DOI 10.1023/A:1009995816485; Maron O., 1998, THESIS MIT; Maron O., 1998, 15 INT C MACH LEARN; MELAMED D, 2001, EMPIRICAL METHODS EX; MORI Y, 1999, 1 INT WORKSH MULT IN; Frost C. O., 2000, Information Retrieval, V1, DOI 10.1023/A:1009979200555; Oren M., 1997, COMPUTER VISION PATT, P193; ORNAGER S, 1996, SWEDIS LIB RES, V2, P31; Satoh S, 1997, PROC CVPR IEEE, P368, DOI 10.1109/CVPR.1997.609351; SCHNIEDERMAN H, 2000, IEEE C COMPUTER VISI, P100; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; SRIHARI R, 1991, THESIS SUNY BUFFALO; SWAIN MJ, 1996, TR9614 U CHIC COMP S	39	478	489	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	AUG 15	2003	3	6					1107	1135		10.1162/153244303322533214		29	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	733LT	WOS:000186002400005	
J	Halkidi, M; Batistakis, Y; Vazirgiannis, M				Halkidi, M; Batistakis, Y; Vazirgiannis, M			On clustering validation techniques	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article; Proceedings Paper	13th International Conference on Scientific and Statistical Database Management (SSDBM 2001)	JUL 18-20, 2001	FAIRFAX, VIRGINIA	Ctr Earth Observing & Space Res, Ctr Informat Syst Integrat & Evolut, E Ctr for E Business, George Mason Univ, ACM SIGMOD, IEEE TC Data Engn, VLDB Endowment		clustering algorithms; unsupervised learning; cluster validity; validity indices	FUZZY; ALGORITHM; NUMBER	Cluster analysis aims at identifying groups of similar objects and, therefore helps to discover distribution of patterns and interesting correlations in large data sets. It has been subject of wide research since it arises in many application domains in engineering, business and social sciences. Especially, in the last years the availability of huge transactional and experimental data sets and the arising requirements for data mining created needs for clustering algorithms that scale and can be applied in diverse domains. This paper introduces the fundamental concepts of clustering while it surveys the widely known clustering algorithms in a comparative way. Moreover, it addresses an important issue of clustering process regarding the quality assessment of the clustering results. This is also related to the inherent features of the data set under concern. A review of clustering validity measures and approaches available in the literature is presented. Furthermore, the paper illustrates the issues that are under-addressed by the recent algorithms and gives the trends in clustering process.	Athens Univ Econ & Business, Dept Informat, Athens 10434, Greece	Halkidi, M (reprint author), Athens Univ Econ & Business, Dept Informat, Patision 76, Athens 10434, Greece.						Berry M. J. A, 1996, DATA MINING TECHNIQU; BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; Dave RN, 1996, PATTERN RECOGN LETT, V17, P613, DOI 10.1016/0167-8655(96)00026-8; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Dunn J. C., 1974, Journal of Cybernetics, V4; Ester M, 1998, P 24 VLDB C NEW YORK; Ester M, 1996, P 2 INT C KNOWL DISC, P226; FAYYAD M, 1996, ADV KNOWLEDGE DISCOV; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GUHA S, 1998, P ACM SIGMOD C; GUHA S, 1999, P IEEE C DAT ENG; HALKIDI M, 2000, P PKDD LYON FRANC; Han J., 2001, DATA MINING CONCEPTS; HINNEBURG A, 1998, P KDD C; Huang Z., 1997, FAST CLUSTERING ALGO; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; KRISHNAPURAM R, 1993, PATTERN RECOGN LETT, V14, P545, DOI 10.1016/0167-8655(93)90103-K; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; MILLIGAN GW, 1983, IEEE T PATTERN ANAL, V5, P40; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Mitchell T. M, 1997, MACHINE LEARNING; NG R, 1994, P 20 VLDB C SANT CHI; Pal NR, 1997, PATTERN RECOGN, V30, P847, DOI 10.1016/S0031-3203(96)00127-6; Rezaee MR, 1998, PATTERN RECOGN LETT, V19, P237; Sharma S, 1996, APPL MULTIVARIATE TE; SHEIKHOLESLAMI C, 1998, P 24 VLDB C NEW YORK; SMYTH P, 1996, P KDD C; Theodoridis S., 1999, PATTERN RECOGNITION; THEODORIDIS Y, 1999, SPATIAL DATASETS UNO; WANG W, 1997, P 23 VLDB C; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; ZHANG T, 1996, ACM SIGMOD MONTR CAN	32	437	453	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.		2001	17	2-3					107	145		10.1023/A:1012801612483		39	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	493ZC	WOS:000172252500002	
J	Fayyad, U; PiatetskyShapiro, G; Smyth, P				Fayyad, U; PiatetskyShapiro, G; Smyth, P			From data mining to knowledge discovery in databases	AI MAGAZINE			English	Article							NEURAL NETWORKS	Data mining and knowledge discovery in databases have been attracting a significant amount of research, industry, and media attention of late. What is all the excitement about? This article provides an overview of this emerging field, clarifying how data mining and knowledge discovery in databases are related both to each other and to related fields, such as machine learning, statistics, and databases. The article mentions particular real-world applications, specific data-mining techniques, challenges involved in real-world applications of knowledge discovery, and current and future research directions in the field.	UNIV CALIF IRVINE, DEPT COMP & INFORMAT SCI, IRVINE, CA 92717 USA; GTE LABS INC, KNOWLEDGE DISCOVERY DATABASES KDD PROJECT, TECH STAFF, WALTHAM, MA 02254 USA							AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Apte C, 1996, ADV KNOWLEDGE DISCOV, P514; Basseville M., 1993, DETECTION ABRUPT CHA; Berndt D. J., 1996, ADV KNOWLEDGE DISCOV, P229; BERRY J, 1994, BUSINESS WEEK   0905, P56; Brachman R., 1996, ADV KNOWLEDGE DISCOV, P37; Breiman L, 1984, CLASSIFICATION REGRE; BRODLEY CE, 1996, IN PRESS STAT COMPUT; BUNTINE W, 1996, ADV KNOWLEDGE DISCOV, P59; CHEESEMAN P, 1996, ADV KNOWLEDGE DISCOV, P73; CHEESEMAN P, 1990, MOR KAUF M, P73; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; CODD E, 1993, PROVIDING OLAP ON LI; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Djoko Surnjani, 1995, P 1 INT C KNOWL DISC, P75; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P59; ETZIONI O, 1996, IN PRESS COMMUNI NOV; FAYYAD U, 1996, P 2 INT C KNOWL DISC, P50; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Fayyad UM, 1996, AI MAG, V17, P51; FRIEDMAN JH, 1989, ANN STAT, V19, P1; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GLYMOUR C, 1996, IN PRESS COMMUNI NOV; GLYMOUR C, 1987, DISCOVERNG CAUSAL ST; GUYON C, 1996, ADV KNOWLEDGE DISCOV, P181; HALL J, 1996, P CIFER96 COMP INT F; HAND DJ, 1994, J ROY STAT SOC A STA, V157, P317, DOI 10.2307/2983526; Hand D. J., 1981, DISCRIMINATION CLASS; Heckerman D., 1996, ADV KNOWLEDGE DISCOV, P273; Hernandez M., 1995, P 1995 ACM SIGMOD IN, P127, DOI 10.1145/223784.223807; HOLSHEIMER M, 1996, ADV KNOWLEDGE DISCOV, P447; HORVITZ E, 1996, P 12 C UNC ART INT S; IV Elder J.F., 1996, ADV KNOWLEDGE DISCOV, P83; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kloesgen W., 1996, ADV KNOWLEDGE DISCOV, P249; KLOESGEN W, 1996, ADV KNOWLEDGE DISCOV, P569; Kolodner J. L., 1993, CASE BASED REASONING; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LANGLEY P, 1995, COMMUN ACM, V38, P55; Major J. A., 1995, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V4, DOI 10.1007/BF00962821; MANAGO M, 1996, ORMS TODAY       FEB, P28; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Matheus C., 1996, ADV KNOWLEDGE DISCOV, P495; Pearl J., 1988, PROBABILISTIC REASON; PIATETSKYSHAPIR. G, 1996, P 2 INT C KNOWL DISC, P89; PIATETSKYSHAPIR.G, 1994, P KDD94; PIATETSKYSHAPIR.G, 1995, IEEE EXPERT, V10; PIATETSKYSHAPIRO G, 1991, AI MAG, V11, P68; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Scheines R., 1993, CAUSATION PREDICTION; Senator TE, 1995, AI MAG, V16, P21; Shragerand J., 1990, COMPUTATIONAL MODELS; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; Silverman B. W., 1986, DENSITY ESTIMATION S; SIMOUDIS E, 1995, P KDD95 1 INT C KNOW, P275; SMYTH P, 1996, ADV KNOWLEDGE DISCOV, P517; Stolorz P., 1995, P 1 INT C KNOWL DISC, P300; TITTERINGTON DM, 1985, STAT ANAL FINTIE MIX; WEIGEND A, 1993, PREDICTING FUTURE UN; Whittaker J., 1990, GRAPHICAL MODELS APP; Zembowicz R., 1996, ADV KNOWLEDGE DISCOV, P329; 1995, US NEWS WORLD R 1211	65	403	418	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602		AI MAG	AI Mag.	FAL	1996	17	3					37	54				18	Computer Science, Artificial Intelligence	Computer Science	VJ671	WOS:A1996VJ67100006	
J	Liu, H; Yu, L				Liu, H; Yu, L			Toward integrating feature selection algorithms for classification and clustering	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						feature selection; classification; clustering; categorizing framework; unifying platform; real-world applications	FEATURE SUBSET-SELECTION; INSTANCE SELECTION; MINING ALGORITHMS; PERFORMANCE	This paper introduces concepts and algorithms of feature selection, surveys existing feature selection algorithms for classification and clustering, groups and compares different algorithms with a categorizing framework based on search strategies, evaluation criteria, and data mining tasks, reveals unattempted combinations, and provides guidelines in selecting feature selection algorithms. With the categorizing framework, we continue our efforts toward building an integrated system for intelligent feature selection. A unifying platform is proposed as an intermediate step. An illustrative example is presented to show how existing feature selection algorithms can be integrated into a meta algorithm that can take advantage of individual algorithms. An added advantage of doing so is to help a user employ a suitable algorithm without knowing details of each algorithm. Some real-world applications are included to demonstrate the use of feature selection in data mining. We conclude this work by identifying trends and challenges of feature selection research and development.	Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA	Liu, H (reprint author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.	hliu@asu.edu; leiyu@asu.edu					AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Almuallim H., 1991, P 9 NAT C ART INT AA, V2, P547; ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Apte C, 2002, COMMUN ACM, V45, P49; Ben-Bassat M., 1982, HDB STATISTICS, V2, P773, DOI 10.1016/S0169-7161(82)02038-0; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BOBROWSKI L, 1988, P 9 INT C PATT REC, P544; Bradley P, 2002, COMMUN ACM, V45, P38; Brassard G., 1996, FUNDAMENTALS ALGORIT; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Caruana R., 1994, P 11 INT C MACH LEAR, P28; Cochran W.G., 1977, SAMPLING TECHNIQUES; Das S., 2001, P 18 INT C MACH LEAR, P74; Dash M., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183893; Dash M., 1997, Proceedings. 1997 IEEE Knowledge and Data Engineering Exchange Workshop (Cat. No.97TB100208), DOI 10.1109/KDEX.1997.629862; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Dash M, 1997, PROC INT C TOOLS ART, P532, DOI 10.1109/TAI.1997.632300; Dash M., 2000, P 4 PAC AS C KNOWL D, P98; DASH M, 1999, P 1999 SIGMOD RES IS; Dash M., 2000, P 4 PAC AS C KNOWL D, P110; DAVENEY M, 1997, P 14 INT C MACH LEAR, P92; Devijver PA, 1982, PATTERN RECOGNITION; DOAK J, 1992, EVALUATION FEATURE S; DOMINGOS P, 1997, AI REV, V14, P227; Dy J, 2000, P 17 INT C MACH LEAR, P247; Fayyad U, 2002, COMMUN ACM, V45, P28; Fayyad U, 1996, ADV KNOWLEDGE DISCOV, P495; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FOROUTAN I, 1987, IEEE T SYST MAN CYB, V17, P187, DOI 10.1109/TSMC.1987.4309029; Friedman J.H., 2002, CLUSTERING OBJECTS S; GU B, 2001, INSTANCE SELECTION C, P21; Hall M. A., 2000, P 17 INT C MACH LEAR, P359; Han J., 2001, DATA MINING CONCEPTS; Han J., 1996, ADV KNOWLEDGE DISCOV, P399; Hastie T., 2001, ELEMENTS STAT LEARNI; ICHINO M, 1984, P 7 INT C PATT REC, P124; ICHINO M, 1984, IEEE T SYST MAN CYB, V14, P737; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; Kim Y., 2000, P 6 ACM SIGKDD INT C, P365, DOI 10.1145/347090.347169; Kira K, 1992, P 10 NAT C ART INT, P129; Kohavi R, 2002, COMMUN ACM, V45, P45; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, P 13 INT C MACH LEAR, P284; Kononenko I, 1994, P EUR C MACH LEARN, P171; Langley P., 1994, P AAAI FALL S REL, P140; Lee WK, 2000, ARTIF INTELL REV, V14, P533, DOI 10.1023/A:1006624031083; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Liu H., 2001, INSTANCE SELECTION C; LIU H, 2003, P 7 PAC AS C KNOWL D, P474; Liu H, 1996, P 13 INT C MACH LEAR, P319; Liu H., 1998, FEATURE SELECTION KN; Liu H., 1998, FEATURE EXTRACTION C; Liu H, 2002, P 19 INT C MACH LEAR, P395; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; Liu H., 1996, P 9 INT C IND ENG AP, P419; Liu YZ, 1998, CHINA OCEAN ENG, V12, P1; LIU Z, 1998, INT IMMUNOL, V10, P101; Madigan D, 2002, DATA MIN KNOWL DISC, V6, P173, DOI 10.1023/A:1014095614948; Miller A. J, 2002, SUBSET SELECTION REG; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Modrzejewski M., 1993, P EUR C MACH LEARN, P213; Moore A. W., 1994, P 11 INT C MACH LEAR, P190; MUCCIARD.AN, 1971, IEEE T COMPUT, VC 20, P1023, DOI 10.1109/T-C.1971.223398; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Ng A.Y., 1998, P 15 INT C MACH LEAR, P404; Ng K, 2000, ARTIF INTELL REV, V14, P569, DOI 10.1023/A:1006676015154; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Oliveira A.L., 1992, P 9 INT C MACH LEARN, P355; Parsons L., 2004, SIGKDD EXPLORATIONS, V6, P90, DOI DOI 10.1145/1007730.1007731; PUDIL P, 2001, FEATURE EXTRACTION C, P101; Pyle D, 1999, DATA PREPARATION DAT; QUEIROS CE, 1984, P 7 INT C PATT REC, P128; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413; Schlimmer J.C., 1993, P 10 INT C MACH LEAR, P284; SEGEN J, 1984, P 7 INT C PATT REC M, P1344; Sheinvald J., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), DOI 10.1109/ICPR.1990.118160; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; SLONIM N, 2002, P 19 INT C MACH LEAR, P578; Smyth P, 2002, COMMUN ACM, V45, P33; STRACUZZI DJ, 2002, P 19 INT C MACH LEAR, P594; SWETS DL, 1995, IEEE INT S COMP VIS, P85; Talavera L, 1999, MACHINE LEARNING, PROCEEDINGS, P389; Vafaie H., 1994, P INT C FUZZ INT CON; Witten IH, 2000, DATA MINING PRACTICA; Wyse N., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop; Xing E. P., 2001, P 18 INT C MACH LEAR, P601; Xu L, 1988, P 9 INT C PATT REC, P706; YANG J, 2001, FEATURE EXTRACTION C, P117; Yang Y, 1997, P 14 INT C MACH LEAR, P412; YU L, 2004, P 10 ACM SIGKDD C KN; Yu L., 2003, P 20 INT C MACH LEAR, P856	96	381	429	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2005	17	4					491	502				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	897IB	WOS:000226996100004	
J	Han, JW; Pei, J; Yin, YW; Mao, RY				Han, JW; Pei, J; Yin, YW; Mao, RY			Mining frequent patterns without candidate generation: A frequent-pattern tree approach	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						frequent pattern mining; association mining; algorithm; performance improvements; data structure	SEQUENTIAL PATTERNS	Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist a large number of patterns and/or long patterns. In this study, we propose a novel frequent-pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a condensed, smaller data structure, FP-tree which avoids costly, repeated database scans, (2) our FP-tree-based mining adopts a pattern-fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space. Our performance study shows that the FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent-pattern mining methods.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; SUNY Buffalo, Buffalo, NY 14260 USA; Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada; Microsoft Corp, SQL Server Grp, Redmond, WA 98052 USA; China Telecom, Beijing, Peoples R China	Pei, J (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	hanj@cs.uiuc.edu; jianpei@cse.buffalo.edu; yiweny@cs.sfu.ca; runyingm@microsoft.com	Yan, Caspar/A-3130-2012				Agarwal RC, 2001, J PARALLEL DISTR COM, V61, P350, DOI 10.1006/jpdc.2000.1693; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Grahne G., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839450; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han JW, 1999, PROC INT CONF DATA, P106; Kamber M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J, 2001, PROC INT CONF DATA, P433; Pei J, 2001, PROC INT CONF DATA, P215; Pei J, 2001, P IEEE INT C DAT MIN, P441; Pei J., 2000, P 2000 ACM SIGMOD IN, P11; Sarawagi S, 1998, P ACM SIGMOD INT C M, P343, DOI 10.1145/276304.276335; Savasere A, 1995, P 21 INT C VER LARG, P432; Silverstein C., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zaki MJ, 2002, SIAM PROC S, P457	28	363	425	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2004	8	1					53	87		10.1023/B:DAMI.0000005258.31418.83		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	746RB	WOS:000186759800003	
J	Kohonen, T; Kaski, S; Lagus, K; Salojarvi, J; Honkela, J; Paatero, V; Saarela, A				Kohonen, T; Kaski, S; Lagus, K; Salojarvi, J; Honkela, J; Paatero, V; Saarela, A			Self organization of a massive document collection	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						data mining; exploratory data analysis; knowledge discovery; large databases; parallel implementation; random projection; self-organizing map (SOM); textual documents	ORGANIZING MAPS; QUANTIZATION	This article describes the implementation of a system that is able to organize vast document collections according to textual similarities. It is based on the self-organizing map (SOM) algorithm. As the feature vectors for the documents statistical representations of their vocabularies are used. The main goal in our work: has been to scale up the SOM algorithm to be able to deal with large amounts of high-dimensional data. In a practical experiment we mapped 6 840 568 patent abstracts onto a 1 002 240-node SOM, As the feature vectors we used 500-dimensional vectors of stochastic figures obtained as random projections of weighted word histograms.	Helsinki Univ Technol, Neural Networks Res Ctr, FIN-02150 Espoo, Finland	Kohonen, T (reprint author), Helsinki Univ Technol, Neural Networks Res Ctr, FIN-02150 Espoo, Finland.						Chen HC, 1996, J VIS COMMUN IMAGE R, V7, P88, DOI 10.1006/jvci.1996.0008; CHEN H, 1998, IEEE COMPUTER    AUG, P75; Cheng YZ, 1997, NEURAL COMPUT, V9, P1667, DOI 10.1162/neco.1997.9.8.1667; de Leeuw J., 1982, HDB STATISTICS, V2, P285, DOI 10.1016/S0169-7161(82)02016-1; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Drineas P, 1999, PROCEEDINGS OF THE TENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P291; GERSHO A, 1979, IEEE T INFORM THEORY, V25, P373, DOI 10.1109/TIT.1979.1056067; Gray Robert M., 1984, IEEE ASSP MAG    APR, P4; Honkela T., 1997, P WSOM 97 WORKSH SEL, P310; HONKELA TK, 1996, A32 HELS U TECHN LAB; Kaski S, 1998, NEUROCOMPUTING, V21, P101, DOI 10.1016/S0925-2312(98)00039-3; Kaski S., 1998, P IJCNN 98 INT JOINT, V1, P413; KASKI S, 1996, P WCNN 96 WORLD C NE, P814; Kaski S., 1997, THESIS HELSINKI U TE; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T, 1999, KOHONEN MAPS, P171, DOI 10.1016/B978-044450270-4/50013-9; Kohonen T., 1998, P ICANN98 8 INT C AR, V1, P65; KOHONEN T, 1999, NEURAL COMPUT, V11, P2171; Kohonen T., 1993, P IEEE INT C NEUR NE, P1147; KOHONEN T, 1996, P INT C ART NEUR NET, P269; KOHONEN T, 1992, S NEUR NETW ALL PERS; Kohonen T., 1997, SELF ORG MAPS; Kohonen T., 1996, A31 HELS U TECHN LAB; Kohonen T., 1982, Proceedings of the 6th International Conference on Pattern Recognition; KOHONEN T, 1997, P ICNN 97 INT C NEUR, pPL1; Koikkalainen P., 1994, P 11 EUR C ART INT A, P211; KOIKKALAINEN P, 1995, P ICANN 95 INT C ART, V2, P63; Koller D., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Koskenniemi K., 1983, THESIS U HELSINKI; Kruskal J. B., 1978, SAGE U PAPERS SERIES; LAGUS K, 1996, P 2 INT C KNOWL DISC, P238; Lagus K, 1999, ARTIF INTELL REV, V13, P345, DOI 10.1023/A:1006586221250; Lagus K., 1999, P ICANN99 9 INT C AR, V1, P371; Lesteven S., 1996, VISTAS ASTRON, V40, P395, DOI 10.1016/S0083-6656(96)90140-3; Lin X., 1991, P 14 ANN INT ACM SIG, P262, DOI 10.1145/122860.122887; Lin X, 1997, J AM SOC INFORM SCI, V48, P40, DOI 10.1002/(SICI)1097-4571(199701)48:1<40::AID-ASI6>3.0.CO;2-1; MAKHOUL J, 1985, P IEEE, V73, P1551, DOI 10.1109/PROC.1985.13340; MERKL D, 1994, P FID 94 GEN ASS C C; Merkl D, 1998, NEUROCOMPUTING, V21, P61, DOI 10.1016/S0925-2312(98)00032-0; Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275505; RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171; RODRIGUES JS, 1990, P INNC 90 INT NEUR N, P813; Roussinov D. G., 1998, CC-AI, The Journal for the Integrated Study of Artificial Intelligence, Cognitive Science and Applied Epistemology, V15; SALTON G, 1983, INTRO MODERN INFORMA; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SCHOLTES JC, 1991, P IJCNN 91 INT JOINT, V1, P95; Torgerson W. S., 1952, PSYCHOMETRIKA, V14, P401, DOI DOI 10.1007/BF02288916; Tukey J.W., 1977, EXPLORATORY DATA ANA; Wish M., 1982, HDB STATISTICS, P317, DOI 10.1016/S0169-7161(82)02017-3; Young FW, 1985, ENCY STAT SCI, V5, P649; Young G, 1938, PSYCHOMETRIKA, V3, P19, DOI 10.1007/BF02287916	51	345	358	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2000	11	3					574	585		10.1109/72.846729		12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	326JM	WOS:000087732100004	
J	Agrawal, R; Shafer, JC				Agrawal, R; Shafer, JC			Parallel mining of association rules	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; association rules; parallel algorithms		We consider the problem of mining association rules on a shared-nothing multiprocessor. We present three algorithms that explore a spectrum of trade-offs between computation, communication, memory usage, synchronization, and the use of problem-specific information. The best algorithm exhibits near perfect scaleup behavior, yet requires only minimal overhead compared to the current best serial algorithm.		Agrawal, R (reprint author), IBM CORP,ALMADEN RES CTR,650 HARRY RD,SAN JOSE,CA 95120, USA.						Agrawal R., 1994, P 20 INT C VER LARG; AGRAWAL R, 1996, 10004 RJ IBM ALM RES; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; HAN J, 1995, P 21 INT C VER LARG; HOUSTSMA M, 1995, P INT C DAT ENG TAIP; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Message Passing Interface Forum, 1994, MPI MESS PASS INT ST; Park J., 1995, P 4 INT C INF KNOWL; PARK JS, 1995, P ACM SIGMOD C MAN D; SAVASERE A, 1995, P VLDB C ZUR SEPT; Srikant R., 1995, P 21 INT C VER LARG; *INT BUS MACH, 1995, SCAL POW PAR SYST	12	345	421	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	DEC	1996	8	6					962	969		10.1109/69.553164		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	WC057	WOS:A1996WC05700011	
J	Zaki, MJ				Zaki, MJ			SPADE: An efficient algorithm for mining frequent sequences	MACHINE LEARNING			English	Article						sequence mining; sequential patterns; frequent patterns; data mining; knowledge discovery		In this paper we present SPADE, a new algorithm for fast discovery of Sequential Patterns. The existing solutions to this problem make repeated database scans, and use complex hash structures which have poor locality. SPADE utilizes combinatorial properties to decompose the original problem into smaller sub-problems, that can be independently solved in main-memory using efficient lattice search techniques, and using simple join operations. All sequences are discovered in only three database scans. Experiments show that SPADE outperforms the best previous algorithm by a factor of two, and by an order of magnitude with some pre-processed data. It also has linear scalability with respect to the number of input-sequences, and a number of other database parameters. Finally, we discuss how the results of sequence mining can be applied in a real application domain.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Zaki, MJ (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.						Agrawal R., 1995, 11 INT C DAT ENG; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Davey B. A., 1990, INTRO LATTICES ORDER; FERGUSON G, 1998, 15 NAT C ART INT; HATONEN K, 1996, 12 INT C DAT ENG; LESH N, 1998, 15 NAT C ART INT; Mannila H., 1996, 2 INT C KNOWL DISC D; Mannila H., 1995, 1 INT C KNOWL DISC D; OATES T, 1997, 6 INT WORKSH AI STAT; PARTHASARATHY S, 1998, 4 INT C KNOWL DISC D; Savasere A., 1995, 21 INT C VER LARG DA; Srikant R, 1996, 5 INT C EXT DAT TECH; Zaki M. J., 1997, 3 INT C KNOWL DISC D; ZAKI MJ, 1998, 4 INT C KNOWL DISC D; ZAKI MJ, 1998, 7 INT C INF KNOWL MA	15	338	365	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	JAN	2001	42	1-2					31	60		10.1023/A:1007652502315		30	Computer Science, Artificial Intelligence	Computer Science	387GD	WOS:000166114100003	
J	van der Aalst, WMP; van Dongen, BF; Herbst, J; Maruster, L; Schimm, G; Weijters, AJMM				van der Aalst, WMP; van Dongen, BF; Herbst, J; Maruster, L; Schimm, G; Weijters, AJMM			Workflow mining: A survey of issues and approaches	DATA & KNOWLEDGE ENGINEERING			English	Article						workflow mining; workflow management; data mining; Petri nets	MANAGEMENT; LOGS	Many of today's information systems are driven by explicit process models. Workflow management systems, but also ERP, CRM, SCM, and B2B, are configured on the basis of a workflow model specifying the order in which tasks need to be executed. Creating a workflow design is a complicated time-consuming process and typically there are discrepancies between the actual workflow processes and the processes as perceived by the management. To support the design of workflows, we propose the use of workflow mining. Starting point for workflow mining is a so-called "workflow log" containing information about the workflow process as it is actually being executed. In this paper, we introduce the concept of workflow mining and present a common format for workflow logs. Then we discuss the most challenging problems and present some of the workflow mining approaches available today. (C) 2003 Elsevier B.V. All rights reserved.	Eindhoven Univ Technol, Dept Technol Management, NL-5600 MB Eindhoven, Netherlands; DaimlerChrysler AG, Res & Technol, D-89013 Ulm, Germany; OFFIS, D-26121 Oldenburg, Germany	van der Aalst, WMP (reprint author), Eindhoven Univ Technol, Dept Technol Management, POB 513, NL-5600 MB Eindhoven, Netherlands.	w.m.p.v.d.aalst@tm.tue.nl; joachim.j.herbst@daimlerchrysler.com; schimm@offis.de	weijters, ton/D-1779-2010; van Dongen, Boudewijn/C-2133-2011; van der Aalst, Wil/G-1248-2011	van der Aalst, Wil/0000-0002-0955-6940			Agostini A, 2000, LECT NOTES COMPUT SC, V1806, P218; Agrawal R., 1998, 6 INT C EXT DAT TECH, P469; BRAY T, 2000, EXTENSIBLE MARKUP LA; Casati F., 1996, P 15 INT C CONC MOD, P438; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Cook J.E., 1998, P 6 INT S FDN SOFTW, P35, DOI 10.1145/288195.288214; Cook JE, 1999, ACM T SOFTW ENG METH, V8, P147, DOI 10.1145/304399.304401; DESEL J, 1995, CAMBRIDGE TRACTS THE, V40; Eder J, 2002, LECT NOTES COMPUT SC, V2480, P1; Ellis CA, 2000, LECT NOTES COMPUT SC, V1806, P201; Fischer Layna, 2001, WORKFLOW HDB 2001; Grigori D., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Hammer M., 1993, REENGINEERING CORPOR; Herbst J, 2000, LECT NOTES ARTIF INT, V1810, P183; Herbst J., 2000, EUR CONC ENG C SCS E; Herbst J., 2001, THESIS U ULM; Herbst J., 1999, P IJCAI 99 WORKSH IN, P52; Herbst J., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<67::AID-ISAF186>3.0.CO;2-7; Herbst J., 1998, Proceedings Ninth International Workshop on Database and Expert Systems Applications (Cat. No.98EX130), DOI 10.1109/DEXA.1998.707491; Herrmann T, 2000, FR ART INT, V58, P159; HULSMAN BJP, 1994, PERSONEELSINFORMATIE; Jablonski S., 1996, WORKFLOW MANAGEMENT; Junginger S, 2000, WIRTSCHAFTSINF, V42, P392; KIEPUSZEWSKI B, 2002, IN PRESS ACTA INFORM; Kiepuszewski B., 2002, THESIS QUEENSLAND U; KLEIN M, 2000, J COMPUTER SUPPORTED, V9; KLEIN M, 1998, P CSCW 98 WORKSH AD; Leymann F., 1999, PRODUCTION WORKFLOW; Maruster L., 2001, P 13 BELG NETH C ART, P183; Maruster L, 2002, LECT NOTES COMPUT SC, V2534, P364; Maxeiner M.K., 2001, P DAT BUR TECHN WISS, P75; Milner R., 1999, COMMUNICATING MOBILE; PAREKH R, 2000, HDB NATURAL LANGUAGE; Reisig W., 1998, LECT NOTES COMPUTER, V1491; Rosemann M., 2000, P 33 HAW INT C SYST, P1; SAUERWEIN LB, 2001, GUIDELINES PERSONAL; Sayal M., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; SCHEER IDS, 2002, ARIS PROCESS PERFORM; SCHIMM G, 2001, PROCEEDINGS, V1; Schimm G, 2000, LECT NOTES COMPUT SC, V1921, P31; SCHIMM G, 2002, P 8 EUR C ART INT JE, V2424, P525; SCHIMM G, PROCESS MINING; SCHIMM G, 2001, P EL GESCH; Staffware, 2002, STAFFW PROC MON SPM; van der Aalst W. M. P., 2002, WORKFLOW MANAGEMENT; van der Aalst W.M.P., 2002, BETA WORKING PAPER S, VWP 74; van der Aalst WMP, 2000, COMPUT SYST SCI ENG, V15, P267; VANDERAALST WMP, 2002, SCOPE, V10, P38; Van der Aalst WMP, 1998, J CIRCUIT SYST COMP, V8, P21, DOI 10.1142/S0218126698000043; van der Aalst WMP, 2002, LECT NOTES COMPUT SC, V2480, P45; VANDERAALST WMP, 2000, LECT NOTES COMP SCI, V1806; VANDERAALST WMP, 2002, FITTR200202 QUEENSL; Weijters A., 2001, P 13 BELG NETH C ART, P283; Weijters A. J. M. M., 2002, P ECAI WORKSH KNOWL, P78; Weijters A.J.M.M., 2001, P 11 DUTCH BELG C MA, P93; Weske M., 2001, P 34 ANN HAW INT C S; zur M''uhlen M., 2001, P INT C EL COMM RES, P550; zur Muehlen M, 2001, WORKFLOW HDB 2001, P61; *IBM, 1999, IBM MQ SER WORKFL GE; *IBM, 2001, IBM MQ SER WORKFL PR; *STAFFW PLC, 2000, STAFFW 2000 GWD US M; *TIBC SOFTW INC, 2000, CONC PROC DES US GUI	62	333	333	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	NOV	2003	47	2					237	267		10.1016/S0169-023X(03)00066-1		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	730AY	WOS:000185808100004	
J	Huang, ZX				Huang, ZX			Extensions to the k-means algorithm for clustering large data sets with categorical values	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; cluster analysis; clustering algorithms; categorical data		The k-means algorithm is well known for its efficiency in clustering large data sets. However, working only on numeric values prohibits it from being used to cluster real world data containing categorical values. In this paper we present two algorithms which extend the k-means algorithm to categorical domains and domains with mixed numeric and categorical values. The k-modes algorithm uses a simple matching dissimilarity measure to deal with categorical objects, replaces the means of clusters with modes, and uses a frequency-based method to update modes in the clustering process to minimise the clustering cost function. With these extensions the k-modes algorithm enables the clustering of categorical data in a fashion similar to k-means. The k-prototypes algorithm, through the definition of a combined dissimilarity measure, further integrates the k-means and k-modes algorithms to allow for clustering objects described by mixed numeric and categorical attributes. We use the well known soybean disease and credit approval data sets to demonstrate the clustering performance of the two algorithms. Our experiments on two real world data sets with half a million objects each show that the two algorithms are efficient when clustering large data sets, which is critical to data mining applications.	CSIRO, ACsys CRC, Canberra, ACT 2601, Australia	Huang, ZX (reprint author), CSIRO, ACsys CRC, GPO Box 664, Canberra, ACT 2601, Australia.						Anderberg M.R., 1973, CLUSTER ANAL APPL; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bezdek J., 1981, PATTERN RECOGNITION; BOBROWSKI L, 1991, IEEE T SYST MAN CYB, V21, P545, DOI 10.1109/21.97475; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; DUBES R, 1979, PATTERN RECOGN, V11, P235, DOI 10.1016/0031-3203(79)90034-7; DUBES RC, 1987, PATTERN RECOGN, V20, P645, DOI 10.1016/0031-3203(87)90034-3; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Everitt B., 1974, CLUSTER ANAL; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; Huang Z., 1997, P SIGMOD WORKSH RES, P1; Huang Z., 1997, P 1 PAC AS KNOWL DIS, P21; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kaufman L., 1990, FINDING GROUPS DATA; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, p573{592; KODRATOFF Y, 1988, IEEE T PATTERN ANAL, V10, P697; Lebowitz M., 1987, Machine Learning, V2, DOI 10.1007/BF00114264; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; MICHALSKI RS, 1983, IEEE T PATTERN ANAL, V5, P396; MILLIGAN GW, 1981, PSYCHOMETRIKA, V46, P187, DOI 10.1007/BF02293899; MILLIGAN GW, 1980, PATTERN RECOGN, V12, P41, DOI 10.1016/0031-3203(80)90001-1; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P123, DOI 10.1007/BF02294153; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Ng R, 1994, P 20 INT C VER LARG, P144; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RALAMBONDRAINY H, 1995, PATTERN RECOGN LETT, V16, P1147, DOI 10.1016/0167-8655(95)00075-R; RUSPINI EH, 1973, INFORM SCIENCES, V6, P273, DOI 10.1016/0020-0255(73)90043-1; Ruspini E. R., 1969, INFORM CONTR, V15, P22; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; WILLIAMS GJ, 1996, P PAC RIM KNOWL ACQ, P117; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324; *IBM, 1996, DAT MAN SOL	34	325	392	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1998	2	3					283	304		10.1023/A:1009769707641		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	155ZE	WOS:000077976300004	
J	van der Aalst, W; Weijters, T; Maruster, L				van der Aalst, W; Weijters, T; Maruster, L			Workflow mining: Discovering process models from event logs	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						workflow mining; workflow management; data mining; Petri nets	PETRI NETS; IDENTIFICATION	Contemporary workflow management systems are driven by explicit process models, i.e., a completely specified workflow design is required in order to enact a given workflow process. Creating a workflow design is a complicated time-consuming process and, typically, there are discrepancies between the actual workflow processes and the processes as perceived by the management. Therefore, we have developed techniques for discovering workflow models. The starting point for such techniques is a so-called "workflow log" containing information about the workflow process as it is actually being executed. We present a new algorithm to extract a process model from such a log and represent it in terms of a Petri net. However, we will also demonstrate that it is not possible to discover arbitrary workflow processes. In this paper, we explore a class of workflow processes that can be discovered. We show that the alpha-algorithm can successfully mine any workflow represented by a so-called SWF-net.	Eindhoven Univ Technol, Dept Technol Management, NL-5600 MB Eindhoven, Netherlands	van der Aalst, W (reprint author), Eindhoven Univ Technol, Dept Technol Management, POB 513, NL-5600 MB Eindhoven, Netherlands.	w.m.p.v.d.aalst@tm.tue.nl; A.J.M.M.Weijters@tm.tue.nl; l.maruster@tm.tue.nl	weijters, ton/D-1779-2010; van der Aalst, Wil/G-1248-2011	van der Aalst, Wil/0000-0002-0955-6940			Agrawal R., 1998, P 6 INT C EXT DAT TE, P469; ANGLUIN D, 1983, ACM COMPUT SURV, V15, P237, DOI 10.1145/356914.356918; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Cook J.E., 1998, P 6 INT S FDN SOFTW, P35, DOI 10.1145/288195.288214; Cook JE, 1999, ACM T SOFTW ENG METH, V8, P147, DOI 10.1145/304399.304401; DESEL J, 1995, CAMBRIDGE TRACTS THE, V40; EDER J, 2002, P INT C ENG DEPL COO, P1; EHRENFEUCHT A, 1990, ACTA INFORM, V27, P315, DOI 10.1007/BF00264611; Fischer L., 2001, WORKFLOW HDB 2001 WO; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Grigori D., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; HERBST J, 2000, P 11 EUR C MACH LEAR, P183; Herbst J., 2001, THESIS U ULM; Herbst J., 1999, P IJCAI 99 WORKSH IN, P52; Herbst J., 2000, P EUR CONC ENG C; Herbst J., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<67::AID-ISAF186>3.0.CO;2-7; Herbst J., 1998, Proceedings Ninth International Workshop on Database and Expert Systems Applications (Cat. No.98EX130), DOI 10.1109/DEXA.1998.707491; IDS SCHEER Whitepaper, 2002, ARIS PROC PERF MAN; Jablonski S., 1996, WORKFLOW MANAGEMENT; Kiepuszewski B., 2002, THESIS QUEENSLAND U; Leymann F., 1999, PRODUCTION WORKFLOW; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; Maruster L., 2001, P 13 BELG NETH C ART, P183; MARUSTER L, 2002, P 5 INT C DISC SCI D, P364; Maxeiner M.K., 2001, P DAT BUR TECHN WISS, P75; MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143; PITT L, 1989, P 1989 INT WORKSH AN, P18; Reisig W., 1998, LECT NOTES COMPUTER, V1491; Rosemann M., 2000, P 33 HAW INT C SYST, P1; Rusakov D., 2001, P 1 SIAM C DAT MIN S, P1; Sayal M., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; SCHIMM G, 2004, PROCESS MINING; SCHIMM G, 2001, P 1 K PROF WISS; SCHIMM G, 2002, P 8 EUR C ART INT JE, P525; SCHIMM G, 2000, P ER 2000 WORKSH CON, P31; SCHIMM G, 2001, P EL GESCH; Staffware, 2002, STAFFW PROC MON SPM; van der Aalst WMP, 1997, LECT NOTES COMPUT SC, V1248, P407; van der Aalst W. M. P., 2002, WORKFLOW MANAGEMENT; van der Aalst Wil M. P., 2000, LECT NOTES COMPUTER, V1806; van der Aalst W.M.P., 2002, BETA WORKING PAPER S, VWP 74; Van der Aalst WMP, 1998, J CIRCUIT SYST COMP, V8, P21, DOI 10.1142/S0218126698000043; VANDERAALST WMP, 2002, P INT C ENG DEPL COO, V2480, P45; Verbeek HMW, 2001, COMPUT J, V44, P246, DOI 10.1093/comjnl/44.4.246; Weijters A., 2001, P 13 BELG NETH C ART, P283; Weijters A. J. M. M., 2002, P ECAI WORKSH KNOWL, P78; Weijters A.J.M.M., 2001, P 11 DUTCH BELG C MA, P93; zur M''uhlen M., 2001, P INT C EL COMM RES, P550; zur Muehlen M, 2001, WORKFLOW HDB 2001, P61	50	324	324	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP	2004	16	9					1128	1142		10.1109/TKDE.2004.47		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	839FA	WOS:000222767700008	
S	Pei, J; Han, JW; Mortazavi-Asl, B; Pinto, H; Chen, QM; Dayal, U; Hsu, MC			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Pei, J; Han, JW; Mortazavi-Asl, B; Pinto, H; Chen, QM; Dayal, U; Hsu, MC			PrefixSpan: Mining sequential patterns efficiently by prefix-projected pattern growth	17TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING, PROCEEDINGS	IEEE International Conference on Data Engineering		English	Proceedings Paper	17th International Conference on Data Engineering	APR 02-06, 2001	HEIDELBERG, GERMANY	IEEE Comp Soc, Tech Comm Data Engn, ABB, HP Invent, Software AG, XML Co, EML, IBM, Microsoft, Software Design & Management				Sequential pattern mining is an important data mining problem with broad applications. It is challenging since one may need to examine a combinatorially explosive number of possible subsequence patterns. Most of the previously developed sequential pattern mining methods follow the methodology of Apriori which may substantially reduce the number of combinations to be examined. However Apriori still encounters problems when a sequence database is large and/or when sequential patterns to be mined are numerous and/or long. In this paper; we propose a novel sequential pattern mining method, called PrefixSpan (i.e., Prefix-projected Sequential pattern mining), which explores prefix-projection in sequential pattern mining. PrefixSpan mines the complete set of patterns but greatly reduces the efforts of candidate subsequence generation. Moreover, prefix-projection substantially reduces the size of projected databases and leads to efficient processing. Our performance study shows that PrefixSpan outperforms both the Apriori-based GSP algorithm and another recently proposed method, FreeSpan, in mining large sequence databases.	Simon Fraser Univ, Intelligent Database Syst Res Lab, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Pei, J (reprint author), Simon Fraser Univ, Intelligent Database Syst Res Lab, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	peijian@cs.sfu.ca; han@cs.sfu.ca; mortazav@cs.sfu.ca; hlpinto@cs.sfu.ca; qchen@hpl.hp.com; dayal@hpl.hp.com; mchsu@hpl.hp.com					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bettini C, 1998, DATA ENG B, V21, P32; Garofalakis MN, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P223; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J., 2000, P 6 ACM SIGKDD INT C, P355, DOI 10.1145/347090.347167; Han JW, 1999, PROC INT CONF DATA, P106; LU H, 1998, P 1998 SIGMOD WORKSH; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; Srikant R., 1996, P 5 INT C EXT DAT TE, P3	11	285	353	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1084-4627	0-7695-1001-9	PROC INT CONF DATA			2001							215	224				10	Computer Science, Information Systems	Computer Science	BR97Q	WOS:000168248100023	
J	Zaki, MJ				Zaki, MJ			Scalable algorithms for association mining	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						association rules; frequent itemsets; equivalence classes; maximal cliques; lattices; data mining	RULES	Association rule discovery has emerged as an important problem in knowledge discovery and data mining. The association mining task consists of identifying the frequent itemsets and then, forming conditional implication rules among them. In this paper. we present efficient algorithms for the discovery of frequent itemsets which forms the compute intensive phase of the task. The algorithms utilize the structural properties of frequent itemsets to facilitate fast discovery. The items are organized into a subset lattice search space, which is decomposed into small independent chunks or sublattices, which can be solved in memory. Efficient lattice traversal techniques are presented which quickly identify all the long frequent itemsets and their subsets if required. We also present the effect of using different database layout schemes combined with the proposed decomposition and traversal techniques. We experimentally compare the new algorithms against the previous approaches, obtaining improvements of more than an order of magnitude for our test databases.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Zaki, MJ (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.						AGRAWAL R, 1993, ACM SIGMOD C MAN DAT; Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Agrawal Rakesh, 1994, P 20 VER LARG DAT BA; Bayardo Jr Roberto J., 1998, ACM SIGMOD C MAN DAT; Brin Sergey, 1997, ACM SIGMOD C MAN DAT; CHEUNG D, 1996, 4 INT C PAR DISTR IN; Davey B. A., 1990, INTRO LATTICES ORDER; EPPSTEIN D, 1994, INFORM PROCESS LETT, V51, P207, DOI 10.1016/0020-0190(94)90121-X; Garey M. R., 1979, COMPUTERS INTRACTABI; GUNOPULOS D, 1997, INT C DAT THEOR JAN; GUNOPULOS D, 1997, P 16 ACM S PRINC DAT; HAN EHK, 1997, ACM SIGMOD C MAN DAT; HOLSHEIMER M, 1995, 1 INT C KNOWL DISC D; HOUTSMA M, 1995, 11 INT C DAT ENG; KASHIWABARA T, 1992, J ALGORITHM, V13, P161, DOI 10.1016/0196-6774(92)90012-2; KUZNETSOV SO, 1989, NAUCHN TEKH INF 2, V23, P23; LAFORGE LE, 1994, SOCS94 MCG U; LIN D, 1998, 6 INT C EXT DAT TECH; LIN JL, 1998, 14 INT C DAT ENG FEB; MUELLER A, 1995, CSTR3515 U MAR COLL; MULLIGAN GD, 1972, J ACM, V19, P244, DOI 10.1145/321694.321698; PARK JS, 1995, ACM SIGMOD INT C MAN; PARTHASARATHY S, 1998, 4 INT C KNOWL DISC D; Sarawagi S., 1998, ACM SIGMOD INT C MAN; SAVASERE A, 1995, P 21 VER LARG DAT BA; TOIVONEN H, 1996, P 22 VER LARG DAT BA; YEN SJ, 1996, 4 INT C PAR DISTR IN; ZAKI M, 1997, 7 INT WORKSH RES ISS; Zaki M. J., 1997, 3 INT C KNOWL DISC D; Zaki MJ, 1997, DATA MIN KNOWL DISC, V1, P343, DOI 10.1023/A:1009773317876	31	279	318	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY-JUN	2000	12	3					372	390		10.1109/69.846291		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	325GQ	WOS:000087668200003	
J	Gray, J; Chaudhuri, S; Bosworth, A; Layman, A; Reichart, D; Venkatrao, M; Pellow, F; Pirahesh, H				Gray, J; Chaudhuri, S; Bosworth, A; Layman, A; Reichart, D; Venkatrao, M; Pellow, F; Pirahesh, H			Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data cube; data mining; aggregation; summarization; database; analysis; query		Data analysis applications typically aggregate data across many dimensions looking for anomalies or unusual patterns. The SQL aggregate functions and the GROUP BY operator produce zero-dimensional or one-dimensional aggregates. Applications need the N-dimensional generalization of these operators. This paper defines that operator, called the data cube or simply cube. The cube operator generalizes the histogram, cross-tabulation, roll-up, drill-down, and sub-total constructs found in most report writers. The novelty is that cubes are relations. Consequently, the cube operator can be imbedded in more complex non-procedural data analysis programs. The cube operator treats each of the N aggregation attributes as a dimension of N-space. The aggregate of a particular set of attribute values is a point in this space. The set of points forms an N-dimensional cube. Super-aggregates are computed by aggregating the N-cube to lower dimensional spaces. This paper (1) explains the cube and roll-up operators, (2) shows how they fit in SQL, (3) explains how users can define new aggregate functions for cubes, and (4) discusses efficient techniques to compute the cube. Many of these features are being added to the SQL Standard.	Microsoft Corp, Adv Technol Div, Microsoft Res, Redmond, WA 98052 USA; IBM Res Corp, San Jose, CA 95120 USA	Gray, J (reprint author), Microsoft Corp, Adv Technol Div, Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.						AGRAWAL R, 1996, P 21 VLDB BOMB; CHAMBERLIN D, 1996, USING NEW DB2 IBMS O; Date C.J., 1995, INTRO DATABASE SYSTE; DATE CJ, 1996, DATABASE PROGRAMMING, V9, P17; EARLE RJ, 1994, Patent No. [5359724, 05359724]; GRAEFE G, 1993, COMPUT SURV, V25, P73; GRAY J, 1991, BENCHMARK HDB; GRAY J, 1996, P INT C DAT ENG NEW; Gray J., 1993, BENCHMARK HDB DATABA; Harinarayan V., 1996, P ACM SIGMOD INT C M, P205, DOI 10.1145/233269.233333; MELTON J, 1996, MCI006 ISO IEC DBL 4; MELTON J, 1992, 9077 ISO IEC; Melton J, 1993, UNDERSTANDING NEW SQ; SHUKLA A, 1996, P 21 VLDB BOMB; *INF SOFTW, 1996, DAT DEV KIT US GUID; *MICR, 1994, MICR ACC REL DAT MAN; *MICR, 1995, MICR EXC US GUID; *MICR CORP, 1996, 63900 MICR CORP; *RED BRICK SYST, 1994, RISQL REF GUID RED B	19	275	298	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					29	53		10.1023/A:1009726021843		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900003	
J	Shim, JP; Warkentin, M; Courtney, JF; Power, DJ; Sharda, R; Carlsson, C				Shim, JP; Warkentin, M; Courtney, JF; Power, DJ; Sharda, R; Carlsson, C			Past, present, and future of decision support technology	DECISION SUPPORT SYSTEMS			English	Article						decision support technology; DSS development; collaborative support systems; virtual teams; optimization-based decision support	COMPUTER-MEDIATED COMMUNICATION; SYSTEMS; ORGANIZATIONS; PERFORMANCE; DSS	Since the early 1970s, decision support systems (DSS) technology and applications have evolved significantly. Many technological and organizational developments have exerted an impact on this evolution. DSS once utilized more limited database, modeling, and user interface functionality, but technological innovations have enabled far more powerful DSS functionality. DSS once supported individual decision-makers, but later DSS technologies were applied to workgroups or team, especially virtual teams. The advent of the Web has enabled inter-organizational decision support systems, and has given rise to numerous new applications of existing technology as well as many new decision support technologies themselves. It seems likely that mobile tools, mobile e-services, and wireless Internet protocols will mark the next major set of developments in DSS. This paper discusses the evolution of DSS technologies and issues related to DSS definition, application, and impact. It then presents four powerful decision support tools, including data warehouses, OLAP, data mining, and Web-based DSS. Issues in the field of collaborative support systems and virtual teams are presented. This paper also describes the state of the art of optimization-based decision support and active decision support for the next millennium. Finally, some implications for the future of the field are discussed. (C) 2002 Published by Elsevier Science B.V.	Mississippi State Univ, Mississippi State, MS 39762 USA; Univ Cent Florida, Orlando, FL 32816 USA; Univ No Iowa, Cedar Falls, IA 50614 USA; Oklahoma State Univ, Stillwater, OK 74078 USA; Abo Akad Univ, IAMSR, FIN-20520 Turku, Finland	Shim, JP (reprint author), Mississippi State Univ, Mississippi State, MS 39762 USA.		mchugh, fearghal/D-1070-2012				Alavi M., 1989, Information Society, V6; Anthony R.N., 1965, PLANNING CONTROL SYS; Baecker Ronald M., 1993, READINGS GROUPWARE C; Bhargava HK, 1997, DECIS SUPPORT SYST, V19, P193, DOI 10.1016/S0167-9236(96)00056-5; Bonczek R., 1981, FDN DECISION SUPPORT; Chidambaram L, 1996, MIS QUART, V20, P143, DOI 10.2307/249476; Chinneck J. W., 1991, ORSA Journal on Computing, V3; CODD EF, 1970, COMMUN ACM, V13, P370; Cohen MD, 2001, INTERFACES, V31, P109, DOI 10.1287/inte.31.2.109.10625; Courtney JF, 2001, DECIS SUPPORT SYST, V31, P17, DOI 10.1016/S0167-9236(00)00117-2; COURTNEY JF, 1993, DECIS SUPPORT SYST, V9, P413, DOI 10.1016/0167-9236(93)90050-D; DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554; DESANCTIS G, 1987, MANAGE SCI, V33, P1589; EARLE N, 2000, DOT COM DOT PROFIT I; EDELSTEIN H, 1996, INFORMATION WEE 0108; FOURER R, INFORMS CSTS C MONT; FOURER R, 1999, OR MS TODAY, V26, P64; FULK J, 1991, J MANAGE, V17, P407, DOI 10.1177/014920639101700207; GALEGHER J, 1994, INFORM SYST RES, V5, P110, DOI 10.1287/isre.5.2.110; Glover F., 1997, Journal of Heuristics, V2, DOI 10.1007/BF00132504; Glover F., 1997, Journal of Heuristics, V3, DOI 10.1023/A:1009631530787; Gorry G.A., 1971, SLOAN MANAGE REV, V13, P50; GREENBERG HJ, 1992, COMPUT CHEM ENG, V16, P659, DOI 10.1016/0098-1354(92)80015-2; HIGHTOWER R, 1995, COMPUT HUM BEHAV, V11, P33, DOI 10.1016/0747-5632(94)00019-E; Hightower R, 1996, INFORM SYST RES, V7, P451, DOI 10.1287/isre.7.4.451; Hiltz S. R., 1978, NETWORK NATION HUMAN; HOLLINGSHEAD AB, 1993, SMALL GR RES, V24, P307, DOI 10.1177/1046496493243003; Inmon W. H., 1992, BUILDING DATA WAREHO; Johansen R., 1988, GROUPWARE COMPUTER S; Keen P., 1978, DECISION SUPPORT SYS; Keen P. G. W., 1987, Decision Support Systems, V3, DOI 10.1016/0167-9236(87)90180-1; Kimball Ralph, 1996, DATA WAREHOUSE TOOLK; Kinney S. T., 1996, Proceedings of the Twenty-Ninth Hawaii International Conference on System Sciences, DOI 10.1109/HICSS.1996.493184; Kraut R.E., 1993, READINGS GROUPWARE C, P287; Laughlin P., 1980, PROGR SOCIAL PSYCHOL, V1; Malone T.W., 1990, P C COMP SUPP COOP W; MALONE TW, 1994, ACM COMPUT SURV, V26, P87, DOI 10.1145/174666.174668; McGrath J. E., 1993, GROUP SUPPORT SYSTEM; McGrath J. E, 1990, INTELLECTUAL TEAMWOR, P23; MCGRATH JE, 1991, SMALL GR RES, V22, P147, DOI 10.1177/1046496491222001; McGrath Joseph E., 1994, GROUPS INTERACTING T; Mitroff I. I., 1993, UNBOUNDED MIND BREAK; Nolan RL, 1995, CREATIVE DESTRUCTION, DOI Creative destruction: A six-stage process for transforming the organization; Panko R. R., 1992, Journal of Organizational Computing, V2; Paradice D. B., 1989, Information Resources Management Journal, V2; PARTYKA JC, 2000, ORMS TODAY, V27, P26; PEARSON JM, 1995, DECIS SUPPORT SYST, V13, P141, DOI 10.1016/0167-9236(93)E0042-C; POWER DJ, 1999, DECISION SUPPORT SYS; RICE RE, 1987, COMMUN RES, V14, P85, DOI 10.1177/009365087014001005; ROGERS EM, 1986, COMMUNICATIONS TECHN; Sharda R, 1996, INFORM SYST RES, V7, P328, DOI 10.1287/isre.7.3.328; Simon H.A., 1960, NEW SCI MANAGEMENT D; Thomsen E., 1997, OLAP SOLUTIONS BUILD; VANDEVEN AH, 1976, AM SOCIOL REV, V41, P322; WALTHER JB, 1992, HUM COMMUN RES, V19, P50, DOI 10.1111/j.1468-2958.1992.tb00295.x; Warkentin ME, 1997, DECISION SCI, V28, P975, DOI 10.1111/j.1540-5915.1997.tb01338.x; WATSON H, 1997, DECISION SUPPORT DAT; Wilson P., 1994, COMPUTER SUPPORTED C; Zack M. H., 1993, INFORMATION SYSTEMS, V4, P207, DOI 10.1287/isre.4.3.207; *EF CODD ASS, 1993, PROV OLAP ON LIN AN; *OLAP COUNC, 1997, DEF	61	268	291	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	JUN	2002	33	2					111	126		10.1016/S0167-9236(01)00139-7		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	552YN	WOS:000175648000002	
J	Pasquier, N; Bastide, Y; Taouil, R; Lakhal, L				Pasquier, N; Bastide, Y; Taouil, R; Lakhal, L			Efficient mining of association rules using closed itemset lattices	INFORMATION SYSTEMS			English	Article						data mining; knowledge discovery; association rules; data clustering; lattices; algorithms		Discovering association rules is one of the most important task in data mining. Many efficient algorithms have been proposed in the literature. The most noticeable are Apriori, Mannila's algorithm, Partition, Sampling and DIG, that are all based on the Apriori mining:method: pruning the subset lattice (itemset lattice). In this paper we propose an efficient algorithm, called Close, based on a new mining method: pruning the closed set lattice (closed itemset lattice). This lattice, which is a sub-order of the subset lattice, is closely related to Wille's concept lattice in formal concept analysis. Experiments comparing Close to-an optimized version of Apriori showed that Close is very efficient for mining dense and/or correlated data such as census style data, and performs reasonably well for market basket style data. (C)1999 Elsevier Science Ltd. All rights reserved.	Univ Clermont Ferrand 2, Lab Informat, LIMOS, F-63177 Clermont Ferrand, France	Pasquier, N (reprint author), Univ Clermont Ferrand 2, Lab Informat, LIMOS, Complexe Sci Cezeaux, F-63177 Clermont Ferrand, France.		Yan, Caspar/A-3130-2012				Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P478; Birkhoff G., 1967, C PUBLICATIONS AM MA, V25; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Davey B.A., 1994, INTRO LATTICES ORDER; DUQUENNE V, 1986, MATH SCI HUM, V95, P5; Duquenne V., 1987, BEITRAGE BEGRIFFSANA, P213; GANTER B, 1991, ORDER, P283; GODIN R, 1995, COMPUT INTELL, V11, P246, DOI 10.1111/j.1467-8640.1995.tb00031.x; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; MANNILA H, 1997, P INT C DAT THEOR, P41; MUELLER AM, 1995, THESIS U MARYLAND; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Savasere A, 1995, P 21 INT C VER LARG, P432; SHOSHANI A, 1985, IEEE T SOFTWARE ENG, V11, P1071; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Wille R., 1982, ORDERED SETS, P445; WILLE R, 1992, COMPUT MATH APPL, V23, P493, DOI 10.1016/0898-1221(92)90120-7; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	21	259	290	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	MAR	1999	24	1					25	46		10.1016/S0306-4379(99)00003-4		22	Computer Science, Information Systems	Computer Science	181PQ	WOS:000079451200002	
J	Jiang, DX; Tang, C; Zhang, AD				Jiang, DX; Tang, C; Zhang, AD			Cluster analysis for gene expression data: A survey	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						microarray technology; gene expression data; clustering	TRANSCRIPTIONAL PROGRAM; OLIGONUCLEOTIDE ARRAYS; MICROARRAY EXPERIMENTS; CELL-CYCLE; PATTERNS; CLASSIFICATION; SCALE; IDENTIFICATION; HYBRIDIZATION; PROFILES	DNA microarray technology has now made it possible to simultaneously monitor the expression levels of thousands of genes during important biological processes and across collections of related samples. Elucidating the patterns hidden in gene expression data offers a tremendous opportunity for an enhanced understanding of functional genomics. However, the large number of genes and the complexity of biological networks greatly increases the challenges of comprehending and interpreting the resulting mass of data, which often consists of millions of measurements. A first step toward addressing this challenge is the use of clustering techniques, which is essential in the data mining process to reveal natural structures and identify interesting patterns in the underlying data. Cluster analysis seeks to partition a given data set into groups based on specified features so that the data points within a group are more similar to each other than the points in different groups. A very rich literature on cluster analysis has developed over the past three decades. Many conventional clustering algorithms have been adapted or directly applied to gene expression data, and also new algorithms have recently been proposed specifically aiming at gene expression data. These clustering algorithms have been proven useful for identifying biologically relevant groups of genes and samples. In this paper, we first briefly introduce the concepts of microarray technology and discuss the basic elements of clustering on gene expression data. In particular, we divide cluster analysis for gene expression data into three categories. Then, we present specific challenges pertinent to each clustering category and introduce several representative approaches. We also discuss the problem of cluster validation in three aspects and review various methods to assess the quality and reliability of clustering results. Finally, we conclude this paper and suggest the promising trends in this field.	SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Jiang, DX (reprint author), SUNY Buffalo, Dept Comp Sci & Engn, 201 Bell Hall, Buffalo, NY 14260 USA.	djiang3@cse.buffalo.edu; chuntang@cse.buffalo.edu; azhang@cse.buffalo.edu					AGARWAL R, 1998, SIGMOD 1998 P ACM SI, P94; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; BENDOR A, 2001, P 5 ANN INT C COMP M, P31, DOI DOI 10.1145/369133.369167; BICKEL DR, 2001, P JOINT STAT M AM ST; Blatt M, 1996, PHYS REV LETT, V76, P3251, DOI 10.1103/PhysRevLett.76.3251; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cheng Y., 2000, ISMB, V8, P93; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Chu S, 1998, SCIENCE, V282, P699, DOI 10.1126/science.282.5389.699; DeRisi JL, 1997, SCIENCE, V278, P680, DOI 10.1126/science.278.5338.680; D'haeseleer P, 1998, INFORMATION PROCESSING IN CELLS AND TISSUES, P203; DING C, 2002, P INT C COMP MOL BIO, P27; Dubes R.C., 1988, ALGORITHMS CLUSTERIN; EFRON B, 1982, P CBMS NSF REGIONAL, V38; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797; Ghosh D, 2002, BIOINFORMATICS, V18, P275, DOI 10.1093/bioinformatics/18.2.275; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HALKIDI M, 2001, INTELLIGENT INFORMAT; Hartuv E, 2000, INFORM PROCESS LETT, V76, P175, DOI 10.1016/S0020-0190(00)00142-3; Hastie T., 2001, GENOME BIOL, V2; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; Heyer LJ, 1999, GENOME RES, V9, P1106, DOI 10.1101/gr.9.11.1106; Heyer L.J., 1999, GENOME RES; HILL AA, 2001, GENOME BIOL, V2, P13; Iyer VR, 1999, SCIENCE, V283, P83, DOI 10.1126/science.283.5398.83; JAIN AK, 1999, ACM COMPUT SURV, V31, P254; JAKT LM, 2001, GENOME RES, V11, P1112; JIANG D, 2003, P BIBE2003 3 IEEE IN; Jiang D., 2003, P 9 ACM SIGKDD INT C; Kaufman L., 1990, FINDING GROUPS DATA; Kohonen T, 1984, SELF ORG ASS MEMORY; Lazzeroni L, 2002, STAT SINICA, V12, P61; Levine E, 2001, NEURAL COMPUT, V13, P2573, DOI 10.1162/089976601753196030; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; LI W, 2001, ZIPS LAW IMPORTANCE; Lockhart DJ, 1996, NAT BIOTECHNOL, V14, P1675, DOI 10.1038/nbt1296-1675; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; McQueen J, 2007, 5TH BERK S MATH STAT, V1, P281; Moler EJ, 2000, PHYSIOL GENOMICS, V4, P109; Nguyen LT, 1999, J CLIN IMMUNOL, V19, P179, DOI 10.1023/A:1020555711228; Park P J, 2001, Pac Symp Biocomput, P52; Perou CM, 1999, P NATL ACAD SCI USA, V96, P9212, DOI 10.1073/pnas.96.16.9212; RALFHERWIG PA, 1999, GENOME RES, V9, P1093; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; SCHUCHHARDT J, 2000, NUCL ACIDS RES, V28; Shamir R, 2000, P 8 INT C INT SYST M; Sherlock G, 2000, CURR OPIN IMMUNOL, V12, P201, DOI 10.1016/S0952-7915(99)00074-6; SIEDOW JN, 2001, GENOME BIOL, V2, DOI UNSP 4003.1-4003.2; Smet F.D., 2002, BIOINFORMATICS, V18, P735; SOKAL RR, 1977, CLASSIFICATION CLUST; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; TANG C, 2002, P 11 INT C INF KNOWL; TANG C, 2003, P 9 ACM SIGKDD INT C; Tang C, 2001, P 2 IEEE INT S BIOIN, P41; Tavazoie S, 1999, NAT GENET, V22, P281; Tefferi A, 2002, MAYO CLIN PROC, V77, P927; Thomas JG, 2001, GENOME RES, V11, P1227, DOI 10.1101/gr.165101; TROYANSKAYA O, IN PRESS BIOINFORMAT; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; WANG H, 2002, SIGMOD, P394; Wen XL, 1998, P NATL ACAD SCI USA, V95, P334, DOI 10.1073/pnas.95.1.334; Xing E.P., 2001, BIOINFORMATICS, V17, P306; Yang J, 2002, PROC INT CONF DATA, P517; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309; YEUNG KY, 2000, UWCSE20001103 U WASH	77	255	277	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2004	16	11					1370	1386				17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	855ML	WOS:000223977300005	
J	Mitra, P; Murthy, CA; Pal, SK				Mitra, P; Murthy, CA; Pal, SK			Unsupervised feature selection using feature similarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data mining; pattern recognition; dimensionality reduction; feature clustering; multiscale representation; entropy measures		In this article, we describe an unsupervised feature selection algorithm suitable for data sets, large in both dimension and size. The method is based on measuring similarity between features whereby redundancy therein is removed. This does not need any search and, therefore, is fast. A new feature similarity measure, called maximum information compression index, is introduced. The algorithm is generic in nature and has the capability of multiscale representation of data sets. The superiority of the algorithm, in terms of speed and performance, is established extensively over various real-life data sets of different sizes and dimensions. It is also demonstrated how redundancy and information loss in feature selection can be quantified with an entropy measure.	Indian Stat Inst, Inst Machine Intelligence, Calcutta 700035, W Bengal, India	Mitra, P (reprint author), Indian Stat Inst, Inst Machine Intelligence, Calcutta 700035, W Bengal, India.						AHA DW, 1996, ARTIFICIAL INTELLIGE; Aspin A., 1949, BIOMETRIKA, V36, P245; Basu S., 2000, P IEEE INT S CIRC SY, P267; Blake C, 1998, UCI REPOSITORY MACHI; Das S.K., 1971, IEEE T COMPUT, P1106; Dash M., 2000, P 4 PAC AS C KNOWL D, P110; Devijver PA, 1982, PATTERN RECOGNITION; DY JG, 2000, P 17 INT C MACH LEAR, P84479; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; Hall M.A., 2000, P 17 INT C MACH LEAR; Heydorn R.P., 1971, IEEE T COMPUT, P1051; KING B, 1967, J AM STAT ASSOC, P86; Kira K., 1992, P 9 INT C MACH LEARN, P249; Koller D., 1996, P 13 INT C MACH LEAR, P284; Kononenko I, 1994, P EUR C MACH LEARN, P171; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Lehmann E.L., 1976, TESTING STAT HYPOTHE; Liu HA, 1998, EXPERT SYST APPL, V15, P333, DOI 10.1016/S0957-4174(98)90049-5; Moore A, 1994, P 11 INT C MACH LEAR; Pal S K, 1996, GENETIC ALGORITHMS P; Pal SK, 2000, IEEE T NEURAL NETWOR, V11, P366, DOI 10.1109/72.839007; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Rao C. R., 1973, LINEAR STAT INFERENC; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; TOUSSAINT GT, 1972, IEEE T COMPUT, P408	25	245	286	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					301	312		10.1109/34.990133		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	524WM	WOS:000174035900002	
J	Cilibrasi, RL; Vitanyi, PMB				Cilibrasi, Rudi L.; Vitanyi, Paul M. B.			The Google similarity distance	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article; Proceedings Paper	IEEE Information Theory Workshop on Coding and Complexity	AUG-SEP -, 2005	Rotorua, NEW ZEALAND	IEEE		accuracy comparison with WordNet categories; automatic classification and clustering; automatic meaning discovery using Google; automatic relative semantics; automatic translation; dissimilarity semantic distance; Google search; Google distribution via page hit counts; Google code; Kolmogorov complexity; normalized compression distance (NCD); normalized information distance (NID); normalized Google distance (NGD); meaning of words and phrases extracted from the Web; parameter-free data mining; universal similarity metric	MATHEMATICAL-THEORY; COMMUNICATION; COMPRESSION; KNOWLEDGE	Words and phrases acquire meaning from the way they are used in society, from their relative semantics to other words and phrases. For computers, the equivalent of "society" is "database," and the equivalent of " use" is "a way to search the database." We present a new theory of similarity between words and phrases based on information distance and Kolmogorov complexity. To fix thoughts, we use the World Wide Web (WWW) as the database, and Google as the search engine. The method is also applicable to other search engines and databases. This theory is then applied to construct a method to automatically extract similarity, the Google similarity distance, of words and phrases from the WWW using Google page counts. The WWW is the largest database on earth, and the context information entered by millions of independent users averages out to provide automatic semantics of useful quality. We give applications in hierarchical clustering, classification, and language translation. We give examples to distinguish between colors and numbers, cluster names of paintings by 17th century Dutch masters and names of books by English novelists, the ability to understand emergencies and primes, and we demonstrate the ability to do a simple automatic English-Spanish translation. Finally, we use the WordNet database as an objective baseline against which to judge the performance of our method. We conduct a massive randomized trial in binary classification using support vector machines to learn categories based on our Google distance, resulting in an a mean agreement of 87 percent with the expert crafted WordNet categories.	Ctr Wiskunde & Informat, NL-1098 SJ Amsterdam, Netherlands	Cilibrasi, RL (reprint author), Ctr Wiskunde & Informat, Kruislaan 413, NL-1098 SJ Amsterdam, Netherlands.	cilibrar@cwi.nl; paulv@cwi.nl	Vitanyi, Paul/A-9037-2012	Vitanyi, Paul/0000-0002-5712-7585			Bagrow JR, 2005, AIP CONF PROC, V779, P81; Bennett C., 2003, SCI AM           JUN, P76; Bennett CH, 1998, IEEE T INFORM THEORY, V44, P1407, DOI 10.1109/18.681318; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C., 2004, LIBSVM LIB SUPPORT V; Cilibrasi R, 2004, COMPUT MUSIC J, V28, P49, DOI 10.1162/0148926042728449; CILIBRASI R, 2005, COMPLEARN HOME; Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059; CILIBRASI R, 2006, NEW QUARTET TREE HEU; CILIBRASI R, 2004, AUTOMATIC MEANING DI; Cimiano P., 2004, SIGKDD EXPLORATIONS, V6, P24; Cover T. M., 1991, ELEMENTS INFORM THEO; DELAHAYE JP, 2004, SCIENCE, V317, P98; GRAHAMROWE D, 2005, NEW SCI         0129, P21; Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Kolmogorov A.N., 1965, Problems of Information Transmission, V1; Kraft L.G., 1949, THESIS MIT CAMBRIDGE; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211; LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745; LESK ME, 1969, AM DOC, V20, P27, DOI 10.1002/asi.4630200106; LI M, 2001, INT ENCY SOCIAL BEHA, P376; Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101; Li M, 2001, BIOINFORMATICS, V17, P149, DOI 10.1093/bioinformatics/17.2.149; Li M, 1996, P ROY SOC A-MATH PHY, V452, P769, DOI 10.1098/rspa.1996.0039; Li Ming, 1997, INTRO KOLMOGOROV COM; Miller G.A., 2006, WORDNET LEXICAL DATA; MUIR H, 2003, NEW SCI          APR; PATCH K, 2003, TECHNOLOGY RES  0423; REED SL, 2002, P 18 NAT C ART INT W; RUMSFELD DH, 2001, DIGITAL REVOLUTION; SANTOS CC, 2006, P 19 IEEE S COMP BAS, P685; SEELY H, 2003, POETRY DH RUMSFELD; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHANNON CE, 1948, AT&T TECH J, V27, P623; Tan PN, 2002, P ACM SIGKDD C KNOWL, P491; Terra E., 2003, P HUM LANG TECHN C H, P165; BASICS GOOGLE SEARCH; 2005, ECONOMIST       0120; 2004, AUTOMATIC MEANING DI; 2005, SLASHDOT        0129	41	244	257	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2007	19	3					370	383		10.1109/TKDE.2007.48		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	126HS	WOS:000243504100003	
J	Likas, A; Vlassis, N; Verbeek, JJ				Likas, A; Vlassis, N; Verbeek, JJ			The global k-means clustering algorithm	PATTERN RECOGNITION			English	Article						clustering; k-means algorithm; global optimization; k-d trees; data mining	TREES	We present the global k-means algorithm which is an incremental approach to clustering that dynamically adds one cluster center at a time through a deterministic global search procedure consisting of N (with N being the size of the data set) executions of the k-means algorithm from suitable initial positions. We also propose modifications of the method to reduce the computational load without significantly affecting solution quality. The proposed clustering methods are tested on well-known data sets and they compare favorably to the k-means algorithm with random restarts. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece; Univ Amsterdam, Inst Comp Sci, NL-1098 SJ Amsterdam, Netherlands	Likas, A (reprint author), Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece.						BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Blake C, 1998, UCI REPOSITORY MACHI; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Dasgupta S., 1999, P IEEE S FDN COMP SC; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Lozano J.A., 1999, PATTERN RECOGN, V20, P1027; McLachlan G., 2000, FINITE MIXTURE MODEL; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Ripley B., 1996, PATTERN RECOGNITION; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; VERBEEK JJ, 2000, IASUVA0011 U AMST CO; Vlassis N, 2002, NEURAL PROCESS LETT, V15, P77, DOI 10.1023/A:1013844811137; Vlassis N, 1999, IEEE T SYST MAN CY A, V29, P393, DOI 10.1109/3468.769758	13	243	276	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	FEB	2003	36	2					451	461				11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	615BH	WOS:000179225600015	
J	Parpinelli, RS; Lopes, HS; Freitas, AA				Parpinelli, RS; Lopes, HS; Freitas, AA			Data mining with an ant colony optimization algorithm	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article; Proceedings Paper	2nd International Workshop on Ant Algorithms (ANTS 2000)	SEP, 2000	BRUSSELS, BELGIUM			ant colony optimization; classification; data mining; knowledge discovery	DECISION	This paper proposes an algorithm for data mining called Ant-Miner (ant-colony-based data miner). The goal of Ant-Miner is to extract classification rules from data. The algorithm is inspired by both research on the behavior of real ant colonies and some data mining concepts as well as principles. We compare the performance of Ant-Miner with CN2, a well-known data mining algorithm for classification, in six public domain data sets. The results provide evidence that: 1) Ant-Miner is competitive with CN2 with respect to predictive accuracy and 2) the rule lists discovered by Ant-Miner are considerably simpler (smaller) than those discovered by CN2.	Ctr Fed Educ Tecnol Parana, Coordenacao Posgrad Engn Elect & Informat Ind, BR-80230901 Curitiba, Parana, Brazil; Pontificia Univ Catolica Parana, Ctr Ciencias Exatas & Tecnol, Programa Posgrad Informat Aplicada, BR-80215901 Curitiba, Parana, Brazil	Parpinelli, RS (reprint author), Ctr Fed Educ Tecnol Parana, Coordenacao Posgrad Engn Elect & Informat Ind, BR-80230901 Curitiba, Parana, Brazil.		Freitas, Alex/H-1249-2011				BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1007/BF00993345; Bonabeau E., 1999, SWARM INTELLIGENCE N; Brewlow L.A., 1997, KNOWL ENG REV, V12, P1; CATLETT J, 1991, P 12 INT JOINT C ART, P764; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; CLARK P, 1991, LECT NOTES ARTIF INT, V482, P151; Cover T. M., 1991, ELEMENTS INFORMATION; Dhar V, 2000, DATA MIN KNOWL DISC, V4, P251, DOI 10.1023/A:1009848126475; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; Dorigo M, 1999, ARTIF LIFE, V5, P137, DOI 10.1162/106454699568728; Dorigo Marco, 1999, NEW IDEAS OPTIMIZATI, P11; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Freitas A. A, 1998, MINING VERY LARGE DA; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Lopes H.S., 1998, GENETIC ALGORITHMS F, P193; Monmarche N., 1999, DATA MINING EVOLUTIO, P23; Quinlan J. R., 1987, P 10 INT JOINT C ART, P304; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; Stutzle T., 1999, EVOLUTIONARY ALGORIT, P163	24	236	285	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	AUG	2002	6	4					321	332		10.1109/TEVC.2002.802452		12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	587LG	WOS:000177641600002	
J	Liu, H; Hussain, F; Tan, CL; Dash, M				Liu, H; Hussain, F; Tan, CL; Dash, M			Discretization: An enabling technique	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						discretization; continuous feature; data mining; classification	ATTRIBUTES; SELECTION	Discrete values have important roles in data mining and knowledge discovery. They are about intervals of numbers which are more concise to represent and specify, easier to use and comprehend as they are closer to a knowledge-level representation than continuous values. Many studies show induction tasks can benefit from discretization: rules with discrete values are normally shorter and more understandable and discretization can lead to improved predictive accuracy. Furthermore, many induction algorithms found in the literature require discrete features. All these prompt researchers and practitioners to discretize continuous features before or during a machine learning or data mining task. There are numerous discretization methods available in the literature. It is time for us to examine these seemingly different methods for discretization and find out how different they really are, what are the key components of a discretization process, how we can improve the current level of research for new development as well as the use of existing methods. This paper aims at a systematic study of discretization methods with their history of development, effect on classification, and trade-off between speed and accuracy. Contributions of this paper are an abstract description summarizing existing discretization methods, a hierarchical framework to categorize the existing methods and pave the way for further development, concise discussions of representative discretization methods, extensive experiments and their analysis, and some guidelines as to how to choose a discretization method under various circumstances. We also identify some issues yet to solve and future research for discretization.	Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore	Liu, H (reprint author), Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.	hliu@asu.edu; farhad@comp.nus.edu.sg; tancl@comp.nus.edu.sg; manoranj@comp.nus.edu.sg					BAILEY TL, 1993, P INT JOINT C ART IN, P95; BREIMAN L, 1992, INT STAT REV, V60, P291, DOI 10.2307/1403680; Breiman L, 1984, CLASSIFICATION REGRE; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Cerquides J., 1997, KDD97, P139; Chan C.C., 1991, P IEEE C SYST MAN CY, P1719; Chiu D. K. Y., 1990, Journal of Experimental and Theoretical Artificial Intelligence, V2, DOI 10.1080/09528139008953718; Chmielewski M.R., 1994, 3 INT WORKSH ROUGH S, P294; CHOU P, 1991, IEEE T PATTERN ANAL, V4, P340; DOMINGOS B, 1996, MACH LEARN, P105; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; FAYYAD U, 1996, P 13 INT C MACH LEAR, P157; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; Fulton T., 1995, P 12 INT C MACH LEAR, P244; Ho K. M., 1997, KDD97 3 INT C KNOWL, P191; Holte RC, 1989, P 11 INT JOINT C ART, P813; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kerber R., 1992, P 10 NAT C ART INT, P123; KONTKAREN P, 1998, 4 INT C KNOWL DISC D, P254; LANGLEY P, 1994, P C UNC AI, P255; Langley P, 1992, P 10 NAT C ART INT, P223; LIU H, 1997, IEEE T KNOWL DATA EN, V9, P1; Liu H, 1995, PROC INT C TOOLS ART, P388; Maass W., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181016; MANTARAS RL, 1991, MACH LEARN, P103; Merz C. J., 1996, UCI REPOSITORY MACHI; OATES T, 1999, P 4 INT C KNOWL DISC, P294; Pfahringer B, 1995, P 12 INT C MACH LEAR, P456; PFAHRINGER B, 1995, ECML95, P331; QINLAN JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1988, MACH INTELL, V11, P305; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Richeldi M., 1995, P 8 EUR C MACH LEARN, P335; Schaffer C., 1994, MACH LEARN, P259; SHANNON C, 1949, MATH THEORY INFORMAT; Simon Herbert A., 1981, SCI ARTIFICIAL; Thornton C.J., 1992, TECHNIQUES COMPUTATI; Utogoff P, 1989, MACH LEARN, V4, P161; VANDEMERCKT T, 1990, MACH LEARN, P1016; Wang K, 1998, LECT NOTES ARTIF INT, V1531, P250; WEISS SM, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P626	45	234	250	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2002	6	4					393	423		10.1023/A:1016304305535		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	574AB	WOS:000176865200003	
J	Chen, MS; Park, JS; Yu, PS				Chen, MS; Park, JS; Yu, PS			Efficient data mining for path traversal patterns	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; traversal patterns; distributed information system; World Wide Web; performance analysis		In this paper, we explore a new data mining capability that involves mining path traversal patterns in a distributed information-providing environment where documents or objects are linked together to facilitate interactive access. Our solution procedure consists of two steps. First, we derive an algorithm to convert the original sequence of log data into a set of maximal forward references. By doing so, we can filter out the effect of some backward references, which are mainly made for ease of traveling and concentrate on mining meaningful user access sequences. Second, we derive algorithms to determine the frequent traversal patterns-i.e., large reference sequences-from the maximal forward references obtained. Two algorithms are devised for determining large reference sequences; one is based on some hashing and pruning techniques, and the other is further improved with the option of determining large reference sequences in batch so as to reduce the number of database scans required. Performance of these two methods is comparatively analyzed. It is shown that the option of selective scan is very advantageous and can lead to prominent performance improvement. Sensitivity analysis on various parameters is conducted.	Natl Taiwan Univ, Dept Elect Engn, Taipei 10764, Taiwan; Sungshin Womens Univ, Dept Comp Sci, Seoul, South Korea; IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Chen, MS (reprint author), Natl Taiwan Univ, Dept Elect Engn, Taipei 10764, Taiwan.	mschen@cc.ee.ntu.edu.tw; jpark@cs.sungshin.ac.kr; psyu@watson.ibm.com	Yu, Philip/A-2815-2012				AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 1993, P 4 INT C FDN DAT OR; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; Agrawal R., 1994, P 20 INT C VER LARG, P478; ANWAR TM, 1992, P INT C DAT ENG TAMP, P622; BERNERSLEE T, 1996, INTERNET DRAFT   FEB; Bieber M., 1994, ACM European Conference on Hypermedia Technology 1994 Proceedings ECHT 94; Caramel E., 1992, IEEE T SYST MAN CYB, V22, P865; CATLEDGE LD, 1995, P 3 WWW C APR; DECEMBER J, 1994, WORLD WIDE WEB UNLEA; HAN JW, 1992, PROC INT CONF VERY L, P547; Han J, 1995, P 21 INT C VER LARG, P420; Ng R, 1994, P 20 INT C VER LARG, P144; Park JS, 1997, IEEE T KNOWL DATA EN, V9, P813; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; TRIO NR, 1995, COMMUNICATION    MAY; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; Wu KL, 1998, IBM SYST J, V37, P89	20	233	276	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR-APR	1998	10	2					209	221				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	ZU581	WOS:000074212400002	
J	Felzenszwalb, PF; Girshick, RB; McAllester, D; Ramanan, D				Felzenszwalb, Pedro F.; Girshick, Ross B.; McAllester, David; Ramanan, Deva			Object Detection with Discriminatively Trained Part-Based Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; deformable models; pictorial structures; discriminative training; latent SVM	PICTORIAL STRUCTURES; RECOGNITION; TEMPLATES	We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI-SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.	[Felzenszwalb, Pedro F.; Girshick, Ross B.] Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA; [McAllester, David] Toyota Technol Inst, Chicago, IL 60637 USA; [Ramanan, Deva] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA	Felzenszwalb, PF (reprint author), Univ Chicago, Dept Comp Sci, 1100 E 58th St, Chicago, IL 60637 USA.	pff@cs.uchicago.edu; rbg@cs.uchicago.edu; mcallester@tti-c.org; dramanan@ics.uci.edu			US National Science Foundation [IIS 0746569, IIS 0811340, IIS 0812428]	This material is based upon work supported by the US National Science Foundation under Grant No. IIS 0746569 (Pedro J. Felzenszwalb and Ross B. Girshick), IIS 0811340 (David McAllester), and IIS 0812428 (Deva Ramanan).	Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Andrews S., 2003, P ADV NEUR INF PROC; Bar-Hillel A, 2008, INT J COMPUT VISION, V77, P175, DOI 10.1007/s11263-007-0091; BERNSTEIN E, 2005, P IEEE C COMP VIS PA; Burl M., 1998, P EUR C COMP VIS; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; Crandall D., 2005, P IEEE C COMP VIS PA; Dalal N, 2005, P IEEE C COMP VIS PA; Everingham M., 2006, PASCAL VISUAL OBJECT; Everingham M., 2008, PASCAL VISUAL OBJECT; Everingham M, 2007, PASCAL VISUAL OBJECT; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Felzenszwalb P., 2004, 20041963 CORN U CIS; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2007, J ARTIF INTELL RES, V29, P153; Fergus R, 2005, P IEEE C COMP VIS PA; Fergus R., 2003, P IEEE C COMP VIS PA; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Grenander U., 1991, HANDS PATTERN THEORE; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; HOLUB A, 2005, P IEEE C COMP VIS PA; Jin Y., 2006, P IEEE C COMP VIS PA; Joachims T., 1999, ADV KERNEL METHODS S; Ke Y., 2004, P IEEE C COMP VIS PA; LeCun Y., 2006, PREDICTING STRUCTURE; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Lowe D. G., 2004, INT J COMPUT VISION, V60, P2004; PAPAGEORGIOU C, 1998, P IEEE INT C COMP VI; PLANTINGA WH, 1986, P 27 IEEE S FDN COMP, P123; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Rabinovich A., 2007, P IEEE INT C COMP VI; Ramanan D., 2006, P IEEE C COMP VIS PA; Rowley HA, 1995, CMUCS95158R; Schneiderman H., 2000, P IEEE C COMP VIS PA; Shalev-Shwartz S., 2007, P INT C MACH LEARN; SUNG KK, 1994, 1521 MIT; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P., 2005, P ADV NEUR INF PROC; Weber M., 2000, P IEEE C COMP VIS PA; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhu S.-C., 2007, FDN TRENDS COMPUT GR, V2, P259	45	231	243	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1627	1645		10.1109/TPAMI.2009.167		19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	626MB	WOS:000279969000007	
J	Wu, XD; Kumar, V; Quinlan, JR; Ghosh, J; Yang, Q; Motoda, H; McLachlan, GJ; Ng, A; Liu, B; Yu, PS; Zhou, ZH; Steinbach, M; Hand, DJ; Steinberg, D				Wu, Xindong; Kumar, Vipin; Quinlan, J. Ross; Ghosh, Joydeep; Yang, Qiang; Motoda, Hiroshi; McLachlan, Geoffrey J.; Ng, Angus; Liu, Bing; Yu, Philip S.; Zhou, Zhi-Hua; Steinbach, Michael; Hand, David J.; Steinberg, Dan			Top 10 algorithms in data mining	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article							NEAREST NEIGHBOR RULES; ASSOCIATION RULES; CLASSIFICATION; QUANTIZATION; CLASSIFIERS; CONFIDENCE; REGRESSION; FRAMEWORK; PATTERNS; TREES	This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development.	[Wu, Xindong] Univ Vermont, Dept Comp Sci, Burlington, VT USA; [Kumar, Vipin] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN USA; [Quinlan, J. Ross] Rulequest Res pty Ltd, St Ives, NSW, Australia; [Ghosh, Joydeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Yang, Qiang] Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Peoples R China; [Motoda, Hiroshi] Osaka Univ, AFORS AOARD, Tokyo 10600326, Japan; [McLachlan, Geoffrey J.] Univ Queensland, Dept Math, Brisbane, Qld, Australia; [Ng, Angus] Griffith Univ, Sch Med, Brisbane, Qld, Australia; [Liu, Bing] Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA; [Yu, Philip S.] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA; [Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210008, Peoples R China; [Steinbach, Michael] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; [Hand, David J.] Univ London Imperial Coll Sci & Technol, Dept Math, London, England; [Steinberg, Dan] Maxwell Labs Inc, Salford Syst, San Diego, CA 92123 USA	Wu, XD (reprint author), Univ Vermont, Dept Comp Sci, Burlington, VT USA.	xwu@cs.uvm.edu; kumar@cs.umn.edu; quinlan@rulequest.com; ghosh@ece.utexas.edu; qyang@cs.ust.hk; motoda@ar.sanken.osaka-u.ac.jp; gjm@maths.uq.edu.au; psyu@us.ibm.com; steinbac@cs.umn.edu; d.j.hand@imperial.ac.uk; dsx@salford-systems.com	Adams, Niall/D-2472-2010; McLachlan, Geoffrey/A-1491-2008				Agrawal R., 1994, P 20 INT C VER LARG, P487; Ahmed S, 2006, KNOWL INF SYST, V10, P315, DOI 10.1007/s10115-006-0010-1; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bloch DA, 2002, J COMPUT GRAPH STAT, V11, P263, DOI 10.1198/106186002760180509; Bonchi F, 2006, KNOWL INF SYST, V9, P180, DOI 10.1007/s10115-005-0201-1; BREIMAN L, 1968, CLASSICS MATH; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; BRIN S., 1998, COMPUTER NETWORKS IS, V30, p[1, 107]; Chen JR, 2007, KNOWL INF SYST, V11, P369, DOI 10.1007/s10115-006-0042-6; CHEUNG DW, 1996, P ACM SIGMOD INT C D, P13; Chi Y, 2006, KNOWL INF SYST, V10, P265, DOI 10.1007/s10115-006-0003-0; COST S, 1993, MACH LEARN, V10; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NN PATTERN CLASSIFIC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devroye L, 1996, PROBABILISTIC THEORY; Dhillon I. S., 2004, KDD, P551; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fix E., 1951, 4 USAF SCH AV MED; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fung G, 2007, KNOWL INF SYST, V11, P243, DOI 10.1007/s10115-006-0043-5; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Golub G. H., 1983, MATRIX COMPUTATIONS; Gondek D, 2007, KNOWL INF SYST, V12, P1, DOI 10.1007/s10115-006-0009-7; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Han E.H., 1999, THESIS U MINNESOTA; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.1111/j.1751-5823.2001.tb00465.x; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Herbrich R, 2000, ADV NEUR IN, P115; Hu TM, 2006, KNOWL INF SYST, V10, P505, DOI 10.1007/s10115-006-0017-7; Hunt EB, 1966, EXPT INDUCTION; Inokuchi A, 2005, FUND INFORM, V66, P53; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jin RM, 2006, KNOWL INF SYST, V10, P17, DOI 10.1007/s10115-005-0210-0; Kobayashi M, 2006, KNOWL INF SYST, V10, P295, DOI 10.1007/s10115-006-0005-y; Koga H, 2007, KNOWL INF SYST, V12, P25, DOI 10.1007/s10115-006-0027-5; Kriegel H.-P., 1998, P ACM SIGMOD INT C M, P154, DOI 10.1145/276304.276319; Kukar M, 2006, KNOWL INF SYST, V9, P364, DOI 10.1007/s10115-005-0203-z; Kuramochi M, 2005, INT J ARTIF INTELL T, V14, P641, DOI 10.1142/S0218213005002302; Leung CKS, 2007, KNOWL INF SYST, V11, P287, DOI 10.1007/s10115-006-0032-8; Leung CWK, 2006, KNOWL INF SYST, V10, P357, DOI 10.1007/s10115-006-0002-1; Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y; Liu Bing, 2007, WEB DATA MINING EXPL; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; McLachlan G., 2000, FINITE MIXTURE MODEL; MCLACHLAN GJ, 1987, APPL STAT-J ROY ST C, V36, P318, DOI 10.2307/2347790; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; MESSENGE.R, 1972, J AM STAT ASSOC, V67, P768, DOI 10.2307/2284634; Meyer C.D., 2006, GOOGLES PAGE RANK SC; Morishita S., 2000, P 19 ACM SIGACT SIGM, P226, DOI 10.1145/335168.335226; Olshen R, 2001, STAT SCI, V16, P184, DOI 10.1214/ss/1009213290; PAGE L, 1999, 19990120 STANF U; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; QUINLAN R, 1989, UNKNOWN ATTRIBUTE VA, P164; Reyzin Lev, 2006, P 23 INT C MACH LEAR, P753, DOI 10.1145/1143844.1143939; Ridgeway G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scholkopf B., 2002, LEARNING KERNELS; Srikant R., 1995, P 21 INT C VER LARG, P407; STEINBACH M, 2000, P KDD WORKSH TEXT MI; Steinbach M, 2007, KNOWL INF SYST, V12, P279, DOI 10.1007/s10115-006-0041-7; Tan P-N, 2006, INTRO DATA MINING; Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6; Thabtah FA, 2006, KNOWL INF SYST, V9, P109, DOI 10.1007/s10115-005-0213-x; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659; TOUSSAINT G, 2002, INT 2002 34 S COMP S; TOUSSAINT GT, 2002, JCDCG, P273; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Uno T, 2004, LECT NOTES COMPUT SC, V3245, P16; Vapnik V.N., 1995, NATURE STAT LEARNING; Viola P, 2001, PROC CVPR IEEE, P511; Washio T, 2005, LECT NOTES ARTIF INT, V3721, P692; Wasserman S, 1994, SOCIAL NETWORK ANAL; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yan X., 2002, P 2002 IEEE INT C DA, P721; Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258; YU PS, 2005, P WEB INT WI 05; Zhang J, 2006, KNOWL INF SYST, V9, P157, DOI 10.1007/s10115-005-0211-z	92	227	249	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	JAN	2008	14	1					1	37		10.1007/s10115-007-0114-2		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	243KS	WOS:000251795900001	
J	Huang, CL; Wang, CJ				Huang, CL; Wang, CJ			A GA-based feature selection and parameters optimization for support vector machines	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						support vector machines; classification; feature selection; genetic algorithm; data mining	FEATURE SUBSET-SELECTION; GENETIC ALGORITHMS; RECOGNITION	Support Vector Machines, one of the new techniques for pattern classification, have been widely used in many application areas. The kernel parameters setting for SVM in a training process impacts on the classification accuracy. Feature selection is another factor that impacts classification accuracy. The objective of this research is to simultaneously optimize the parameters and feature subset without degrading the SVM classification accuracy. We present a genetic algorithm approach for feature selection and parameters optimization to solve this kind of problem. We tried several real-world datasets using the proposed GA-based approach and the Grid algorithm, a traditional method of performing parameters searching. Compared with the Grid algorithm, our proposed GA-based approach significantly improves the classification accuracy and has fewer input features for support vector machines. (C) 2005 Elsevier Ltd. All rights reserved.	Natl Kaohsiung First Univ Sci & Technol, Dept Informat Management, Kaohsiung 811, Taiwan; Huafan Univ, Dept Informat Management, Shihtin Hsiang 223, Taipei Hsien, Taiwan	Huang, CL (reprint author), Natl Kaohsiung First Univ Sci & Technol, Dept Informat Management, 2 Juoyue Rd,Nantz Dist, Kaohsiung 811, Taiwan.	clhuang@ccms.nkfust.edu.tw					Bradley P. S., 1998, INFORMS Journal on Computing, V10, DOI 10.1287/ijoc.10.2.209; Bradley P. S., 1998, P 15 INT C MACH LEAR, P82; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cristianini N., 2000, INTRO SUPPORT VECTOR; Davis L., 1991, HDB GENETIC ALGORITH; DELEO JM, 2001, P INT JOINT C NEUR N, V4, P2730; Frohlich H, 2003, PROC INT C TOOLS ART, P142, DOI 10.1109/TAI.2003.1250182; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hettich S., 1998, UCI REPOSITORY MACHI; Hsu C.W., 2003, PRACTICAL GUIDE SUPP; Hsu C.W., 2002, MACH LEARN, V46, P219; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kecman V., 2001, LEARNING SOFT COMPUT; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LAVALLE SM, 2002, INT J ROBOT RES, V23, P673; Lin HT, 2003, STUDY SIGMOID KERNEL; Mao KZ, 2004, IEEE T SYST MAN CY B, V34, P60, DOI 10.1109/TSMCB.2002.805808; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SALCEDOSANZ S, 2002, P ICANN INT C ART NE, P547; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Scholkopf B., 2000, STAT LEARNING KERNEL; Vapnik V.N., 1995, NATURE STAT LEARNING; Weston J, 2001, ADV NEUR IN, V13, P668; Woods K, 1997, IEEE T MED IMAGING, V16, P329, DOI 10.1109/42.585767; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; Yu G. X., 2003, 2 IEEE COMP SOC BIOI, P235	30	223	256	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2006	31	2					231	240		10.1016/j.eswa.2005.09.024		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	044AT	WOS:000237645100003	
J	Salzberg, SL				Salzberg, SL			On comparing classifiers: Pitfalls to avoid and a recommended approach	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						classification; comparative studies; statistical methods		An important component of many data mining projects is finding a good classification algorithm, a process that requires very careful thought about experimental design. If not done very carefully comparative studies of classification and other types of algorithms can easily result in statistically invalid conclusions. This is especially true when one is using data mining techniques to analyze very large databases. which inevitably contain some statistically unlikely data. This paper describes several phenomena that can. if ignored, invalidate an experimental comparison. These phenomena and the conclusions that follow apply nor only to classification but to computational experiments in almost any aspect of data mining. The paper also discusses why comparative analysis is more important in evaluating some types of algorithms than for others. and provides some suggestions about how to avoid the pitfalls suffered by many experimental studies.	Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	Salzberg, SL (reprint author), Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.		Salzberg, Steven/F-6162-2011				AHA D. W., 1992, P 9 INT C MACH LEARN, P1; Cochran W, 1957, EXPT DESIGNS; COHEN PR, 1997, 6 INT WORKSH ART INT, P115; DENTON FT, 1985, REV ECON STAT, V67, P124, DOI 10.2307/1928442; DIETTERICH T, 1996, STAT TESTS COMP SUPE; Everitt B. S., 1977, ANAL CONTINGENCY TAB; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FEELDERS A, 1995, 5 INT WORKSH ART INT, P219; Flexer A., 1996, Cybernetics and Systems '96. Proceedings of the Thirteenth European Meeting on Cybernetics and Systems Research; Gascuel O., 1992, P 10 EUR C ART INT E, P435; Hildebrand D. K., 1986, STAT THINKING BEHAV; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JENSEN D, 1991, P 1991 KNOWL DISC DA, P148; JENSEN D, 1995, LABELING SPACE TOOL; Kibler D., 1988, P 3 EUR WORK SESS LE, P81; Kohavi R., 1995, P 14 INT JOINT C ART, P1071; L. Prechelt, 1996, NEURAL NETWORKS, V9; Marsden Peter V., 1995, SOCIOL METHODOL, P111; Murphy P. M., 1995, UCI REPOSITORY MACHI; QIAN N, 1988, J MOL BIOL, V202, P65; Sejnowski T. J., 1987, Complex Systems, V1; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wolpert D. H., 1992, Complex Systems, V6	24	222	223	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	1997	1	3					317	328		10.1023/A:1009752403260		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA829	WOS:000072406200005	
J	Huang, Z; Chen, HC; Hsu, CJ; Chen, WH; Wu, SS				Huang, Z; Chen, HC; Hsu, CJ; Chen, WH; Wu, SS			Credit rating analysis with support vector machines and neural networks: a market comparative study	DECISION SUPPORT SYSTEMS			English	Article						data mining; credit rating analysis; bond rating prediction; backpropagation neural networks; support vector machines; input variable contribution analysis; cross-market analysis	INDUSTRIAL BOND RATINGS; PREDICTION	Corporate credit rating analysis has attracted lots of research interests in the literature. Recent studies have shown that Artificial Intelligence (AI) methods achieved better performance than, traditional statistical methods. This article introduces a relatively new machine learning technique, support vector machines (SVM), to the problem in attempt to provide a model with better explanatory power. We used backpropagation neural network (BNN) as a benchmark and obtained prediction accuracy around 80% for both BNN and SVM methods for the United States and Taiwan markets. However, only slight improvement of SVM was observed. Another direction of the research is to improve the interpretability of the AI-based models. We applied recent research results in neural network model interpretation and obtained relative importance of the input fmancial variables from the neural network models. Based on these results, we conducted a market comparative analysis on the differences of determining factors in the United States and Taiwan markets. (C) 2003 Elsevier B.V All rights reserved.	Univ Arizona, Eller Coll Business & Publ Adm, Dept Management Informat Syst, Tucson, AZ 85721 USA; Natl Taiwan Univ, Dept Business Adm, Taipei, Taiwan	Huang, Z (reprint author), Univ Arizona, Eller Coll Business & Publ Adm, Dept Management Informat Syst, Rm 430,McClelland Hall,1130 E Helen St, Tucson, AZ 85721 USA.	zhuang@eller.arizona.edu; hchen@eller.afizona.edu; hsuc@email.arizona.edu; andychen@ccms.ntu.edu.tw; swu@mail.cgu.edu.tw					Bishop CM, 1995, NEURAL NETWORKS PATT; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Chaveesuk R., 1999, Journal of Engineering Valuation and Cost Analysis, V2; CHEN HC, 1994, IEEE EXPERT, V9, P21; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crammer K, 2000, P 13 ANN C COMP LEAR, P35; Cristianini N., 2000, INTRO SUPPORT VECTOR; DEAKIN EB, 1976, J ACCOUNT RES, P167; Dutta S., 1988, P IEEE INT C NEURAL, V2, P443; Ederington H., 1985, FINANCIAL REV, V20, P237; ENGELBRECHT A, 1998, P INT C SYST SIGN CO, P221; FAN A, 2000, P INT JOINT C NEUR N; FISHER L, 1959, J POLIT ECON, V67, P217, DOI 10.1086/258172; Galindo J., 2000, Computational Economics, V15, DOI 10.1023/A:1008699112516; Garavaglia S., 1991, Proceedings. The First International Conference on Artificial Intelligence on Wall Street (Cat. No.91TH0399-6), DOI 10.1109/AIAWS.1991.236588; GARSON DG, 1991, AI EXPERT        APR, P47; Gentry J., 1988, FINANCIAL REV, V23, P269, DOI 10.1111/j.1540-6288.1988.tb01267.x; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Horrigan J.O., 1966, J ACCOUNTING RES S, P44; Hsu C., 2001, COMPARISON METHODS M; JAAKKOLA TS, 1998, ADV NEURAL INFORMATI; Jackson J.D., 1988, J BEHAV EC, V17, P173, DOI 10.1016/0090-5720(88)90008-3; Joachims T., 1998, P EUR C MACH LEARN E; KAPLAN RS, 1979, J BUS, V52, P231, DOI 10.1086/296045; KIM JW, 1993, EXPERT SYST, V10, P167, DOI 10.1111/j.1468-0394.1993.tb00093.x; KUN CL, 1996, DECIS SUPPORT SYST, V18, P63; Kwon Y. S., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<23::AID-ISAF113>3.3.CO;2-W; Maher J. J., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<59::AID-ISAF116>3.0.CO;2-H; Moody J., 1995, NEURAL NETWORKS CAPI, P277; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; PINCHES GE, 1975, J FINANC, V30, P201, DOI 10.2307/2978442; PINCHES GE, 1973, J FINANC, V28, P1, DOI 10.2307/2978164; Platt J.C., 1998, ADV KERNEL METHODS S, P185; POGUE TF, 1969, J FINANC QUANT ANAL, V4, P201, DOI 10.2307/2329840; Shin KS, 2001, DECIS SUPPORT SYST, V32, P41, DOI 10.1016/S0167-9236(01)00099-9; Singleton J., 1995, NEURAL NETWORKS CAPI, P301; SINGLETON JC, 1990, P IEEE INT C NEUR NE, P163; Taha IA, 1999, IEEE T KNOWL DATA EN, V11, P448, DOI 10.1109/69.774103; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Tay FEH, 2002, NEUROCOMPUTING, V48, P847, DOI 10.1016/S0925-2312(01)00676-2; Taylor C.C., 1994, MACHINE LEARNING NEU; Tolle KM, 2000, DECIS SUPPORT SYST, V30, P139, DOI 10.1016/S0167-9236(00)00094-4; Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093; Vapnik V.N., 1995, NATURE STAT LEARNING; WEISS SM, 1991, COMPUTER SYSTEMS THA; WEST RR, 1970, J ACCOUNTING RES, V8, P118, DOI 10.2307/2674717; WIDROW B, 1994, COMMUN ACM, V37, P93, DOI 10.1145/175247.175257; WILSON RL, 1994, DECIS SUPPORT SYST, V11, P545, DOI 10.1016/0167-9236(94)90024-8; Witten I.H., 1999, DATA MINING PRACTICA; YOON Y, 1994, DECIS SUPPORT SYST, V11, P497, DOI 10.1016/0167-9236(94)90021-3; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	52	218	230	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	SEP	2004	37	4					543	558		10.1016/S0167-9236(03)00086-1		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	828HD	WOS:000221963500008	
J	Cheng, J; Greiner, R; Kelly, J; Bell, D; Liu, WR				Cheng, J; Greiner, R; Kelly, J; Bell, D; Liu, WR			Learning Bayesian networks from data: An information-theory based approach	ARTIFICIAL INTELLIGENCE			English	Article						Bayesian belief nets; learning; probabilistic model; knowledge discovery; data mining; conditional independence test; monotone DAG-faithful; information theory	PROBABILISTIC NETWORKS	This paper provides algorithms that use an information-theoretic analysis to learn Bayesian network structures from data. Based on our three-phase learning framework, we develop efficient algorithms that can effectively learn Bayesian networks, requiring only polynomial numbers of conditional independence (CI) tests in typical cases. We provide precise conditions that specify when these algorithms are guaranteed to be correct as well as empirical evidence (from real world applications and simulation tests) that demonstrates that these systems work efficiently and reliably in practice. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; Univ Ulster, Fac Informat, Coleraine BT52 1SA, Londonderry, North Ireland	Cheng, J (reprint author), Canadian Imperial Bank Commerce, Global Analyt, BCE-11,161 Bay St, Toronto, ON M5J 2S8, Canada.						ACID S, 1996, P 12 C UNC ART INT P; ACID S, 1996, P 6 INT C IPMU 96 GR; Agresti A, 1990, CATEGORICAL DATA ANA; BADSBERG J, 1992, COMPUTATION STAT, P251; Beinlich IA, 1989, P 2 EUR C ART INT ME, P247; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Cheng J., 1997, P AI STAT 97, P83; CHENG J, 2001, P 14 BIENN C CAN SOC; CHENG J, 1999, P 15 INT C UNC ART I; CHENG J, 1997, P 6 ACM INT C INF KN; CHENG J, 1998, THESIS U ULSTER UK; CHICKERING D, 1996, P 12 C UNC ART INT P; Chickering D.M., 1994, MSRTR9417 MICR CORP; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CHRISMAN L, 1996, ROADMAP RES BAYESIAN; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; COWELL RG, 2001, P 17 INT C UNC ART I; DARKEN C, COMMUNICATION; DASH D, 1999, P 15 INT C UNC ART I; Edwards D., 1995, INTRO GRAPHICAL MODE; FRIEDMAN N, 1996, P 12 INT C UNC ART I; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FRIEDMAN N, 1998, P 14 INT C UNC ART I; FUNG RM, 1990, P AAAI 90 BOST MA; GREINER R, 2001, COMPUT SURV, V33, P1; GREINER R, 1996, P 13 INT C UNC ART I, P198; Heckerman D., 1995, MSRTR9506; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Henrion M., 1988, UNCERTAINTY ARTIFICI, V2, P149; HERSKOVITS E, 1990, P 6 INT C UNC ART IN; HOJSGAARD S, 1994, USERS GUIDE BIOFROST; KRAUSE P, 1996, LEARNING PROBABILIST; Kullback S., 1951, ANN MATH STAT, V22, P76; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; MADIGAN D, 1994, SELECTING MODELS DAT, V4; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; MEEK C, 1995, P 11 INT C UNC ART I; PAGE D, 2001, ACM SIGKDD CUP 2001; Pearl J., 1988, PROBABILISTIC REASON; RAMONI M, 1997, KMITR46 OP U; RAMONI M, 1996, KMITR28 OP U; REBANE G, 1987, P 3 C UNC ART INT SE; SCHEINES R, 1994, TETRAD 2; SINGH M, 1997, P AAAI 97 PROV RI; SINGH M, 1995, INT J APPROX REASON, V12, P111, DOI 10.1016/0888-613X(94)00016-V; Spirtes P., 1991, Social Science Computer Review, V9, DOI 10.1177/089443939100900106; Spirtes P., 1993, LECT NOTES STAT; Spirtes P, 1995, P 1 INT C KNOWL DISC; SPIRTES P, 1990, P ADV COMP SOC SCI W; SPIRTES P, 1997, P AI STAT 97 FT LAUD, P481; SRINIVAS S, 1990, UNCERTAINTY ARTIFICI, V5; Suzuki J., 1996, P INT C MACH LEARN B; Thomas A., 1992, BAYESIAN STATISTICS, V4, P837; VERMA TS, 1990, P 6 INT C UNC ART IN; VERMA TS, 1992, P 8 INT C UNC ART IN; WERMUTH N, 1983, BIOMETRIKA, V70, P537, DOI 10.2307/2336490; WONG SKM, 1994, P 3 INT WORKSH ROUGH, P562	57	218	298	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	MAY	2002	137	1-2					43	90		10.1016/S0004-3702(02)00191-1		48	Computer Science, Artificial Intelligence	Computer Science	559FV	WOS:000176015900002	
J	Fawcett, T; Provost, F				Fawcett, T; Provost, F			Adaptive fraud detection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						mud detection; rule learning; profiling; constructive induction; intrusion detection; applications		One method for detecting fraud is to check for suspicious changes in user behavior. This paper describes the automatic design of user profiling methods for the purpose of fraud detection, using a series of data mining techniques. Specifically, we use a rule-learning program to uncover indicators of fraudulent behavior from a large database of customer transactions. Then the indicators are used to create a set of monitors, which profile legitimate customer behavior and indicate anomalies. Finally, the outputs of the monitors are used as features in a system that learns to combine evidence to generate high-confidence alarms. The system has been applied to the problem of detecting cellular cloning fraud based on a database of call records. Experiments indicate that this automatic approach performs better than hand-crafted methods for detecting fraud. Furthermore, this approach can adapt to the changing conditions typical of fraud detection environments.	NYNEX Sci & Technol, White Plains, NY 10604 USA	Fawcett, T (reprint author), NYNEX Sci & Technol, 400 Westchester Ave, White Plains, NY 10604 USA.	fawcett@nynexst.com; foster@nynexst.com					Aronis J. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Aronis J., 1996, P 2 INT C KNOWL DISC, P355; BUCHANAN BG, 1978, PATTERN DIRECTED INF, P297; Chatfield C., 1984, ANAL TIME SERIES INT; CLEARWATER SH, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P24, DOI 10.1109/TAI.1990.130305; DAVIS A, 1993, 13 INT C ART INT EXP, V2, P155; DEMARIA R, 1996, CELLULAR BUSINESS, P24; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P117; EZAWA K, 1995, P 1 INT C KNOWL DISC, P100; EZAWA K, 1996, IEEE EXPERT, P45; Farnum N.R., 1989, QUANTITATIVE FORECAS; FAWCETT T., 1996, P 2 INT C KNOWL DISC, P8; FRANK J, 1994, NAT COMP SEC C, V1, P22; HERZOG J, 1995, BEWARE HURRICANE CLO; Kittler J., 1986, HDB PATTERN RECOGNIT, P59; Kumar S., 1995, THESIS PURDUE U; Nilsson Nils J., 1965, LEARNING MACHINES; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost FJ, 1996, MACH LEARN, V23, P33; Quinlan J. R., 1987, P 10 INT JOINT C ART, P304; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; REDDEN M, 1996, CELLULAR BUSINESS, P84; SEGAL R, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P619; SMYTH P, 1994, PATTERN RECOGN, V27, P149, DOI 10.1016/0031-3203(94)90024-8; STEWARD S, 1997, CELLULAR BUSINESS, V23; Stolfo S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; SUNDARAM A, 1996, ACM CROSSROADS, V2; WALTERS D, 1994, MOBILE PHONE NEWS, P4; WEBB GI, 1995, J ARTIFICIAL INTELLI, V3, P383; Young P. C., 1984, RECURSIVE ESTIMATION; YUHAS BP, 1995, LEARNING STRUCTURE T; YUHAS BP, 1993, NEURAL NETW INNS, P239	33	217	222	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	1997	1	3					291	316		10.1023/A:1009700419189		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA829	WOS:000072406200004	
J	Cilibrasi, R; Vitanyi, PMB				Cilibrasi, R; Vitanyi, PMB			Clustering by compression	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article; Proceedings Paper	IEEE International Symposium on Information Theory	JUN 29-JUL 04, 2003	Yokohama, JAPAN	IEEE, IEEE Informat Theory Soc		heterogenous data analysis; hierarchical unsupervised clustering; Kolmogorov complexity; normalized compression distance; parameter-free data mining; quartet tree method; universal dissimilarity distance	INFORMATION; RECOGNITION; HYPOTHESIS; PHYLOGENY; EVOLUTION; DISTANCE; TREES	We present a new method for clustering based on compression. The method does not use subject-specific features or background knowledge, and works as follows: First, we determine a parameter-free, universal, similarity distance, the normalized compression distance or NCD, computed from the lengths of compressed data files (singly and in pairwise concatenation). Second, we apply a hierarchical clustering method. The NCD is not restricted to a specific application area, and works across application area boundaries. A theoretical precursor, the normalized information distance, co-developed by one of the authors, is provably optimal. However, the optimality comes at the price of using the noncomputable notion of Kolmogorov complexity. We propose axioms to capture the real-world setting, and show that the NCD approximates optimality. To extract a hierarchy of clusters from the distance matrix, we determine a dendrogram (ternary tree) by a new quartet method and a fast heuristic to implement it. The method is implemented and available as public software, and is robust under choice of different compressors. To substantiate our claims of universality and robustness, we report evidence of successful application in areas as diverse as genomics, virology, languages, literature, music, handwritten digits, astronomy, and combinations of objects from completely different domains, using statistical, dictionary, and block sorting compressors. In genomics, we presented new evidence for major questions in Mammalian evolution, based on whole-mitochondrial genomic analysis: the Eutherian orders and the Marsupionta hypothesis against the Theria hypothesis.	Ctr Math & Comp Sci, CWI, NL-1090 GB Amsterdam, Netherlands; Univ Amsterdam, NL-1012 WX Amsterdam, Netherlands	Cilibrasi, R (reprint author), Ctr Math & Comp Sci, CWI, POB 94079, NL-1090 GB Amsterdam, Netherlands.	Rudi.Cilibrasi@cwi.nl; Paul.Vitanyi@cwi.nl	Vitanyi, Paul/A-9037-2012	Vitanyi, Paul/0000-0002-5712-7585			BALL P, 2002, NATURE          0122; Belloni T, 2000, ASTRON ASTROPHYS, V355, P271; Benedetto D, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.048702; Bennett AF, 2003, PHYSIOL BIOCHEM ZOOL, V76, P1, DOI 10.1086/374275; Bennett CH, 1998, IEEE T INFORM THEORY, V44, P1407, DOI 10.1109/18.681318; BYRANT D, 2000, P 11 ACM SIAM S DISC, P287; Cao Y, 1998, J MOL EVOL, V47, P307, DOI 10.1007/PL00006389; Chai W, 2001, P INT C ART INT LAS; Chen X, 2004, IEEE T INFORM THEORY, V50, P1545, DOI 10.1109/TIT.2004.830793; Cilibrasi R, 2004, COMPUT MUSIC J, V28, P49, DOI 10.1162/0148926042728449; Cilibrasi RL, 2003, COMPLEARN TOOLKIT; Cooper M., 2002, P INT S MUS INF RETR, P81; Cormode G, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P197; Cover T. M., 1991, ELEMENTS INFORMATION; Dannenberg R.B., 1997, P INT COMP MUS C, P344; Duda R.O., 2001, PATTERN CLASSIFICATI; GRIMALDI M, 2002, CLASSIFYING MUSIC GE; Janke A, 2002, J MOL EVOL, V54, P71, DOI 10.1007/s00239-001-0019-8; Jiang T, 2001, SIAM J COMPUT, V30, P1942, DOI 10.1137/S0097539799361683; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Killian JK, 2001, MAMM GENOME, V12, P513, DOI 10.1007/s003350020026; Koppel M., 2002, Literary & Linguistic Computing, V17, DOI 10.1093/llc/17.4.401; KRASKOV A, 2003, HIERARCHICAL CLUSTER; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; KSIAZEK TG, 2003, NEW ENGL J MED, V349, P709; Kurtzman CP, 2001, MYCOTA, V7, P179; Kurtzman CP, 2003, FEMS YEAST RES, V4, P233, DOI 10.1016/s13567-1356(03)00175-2; LaPlace P.S., 1951, PHILOS ESSAY PROBABI; LI M, 2001, INT ENCY SOCIAL BEHA, P376; Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101; Li M, 2001, BIOINFORMATICS, V17, P149, DOI 10.1093/bioinformatics/17.2.149; Li Ming, 1997, INTRO KOLMOGOROV COM; Londei A, 2003, P 5 TRIENN ESCOM C, P200; Oliveira LS, 2002, IEEE T PATTERN ANAL, V24, P1438, DOI 10.1109/TPAMI.2002.1046154; Rokas A, 2003, NATURE, V425, P798, DOI 10.1038/nature02053; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; SALOMON D, 1997, DATA COMPRESSION; Scott P, 2001, MUSIC CLASSIFICATION; Trier OD, 1996, PATTERN RECOGN, V29, P641; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; WEHNER S, 2004, ANAL NETWORK TRAFFIC; Yang ACC, 2003, PHYSICA A, V329, P473, DOI 10.1016/S0378-4371(03)00622-8; YIANILOS PN, 1991, NORMALIZED FORMS 2 C	43	216	219	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	APR	2005	51	4					1523	1545		10.1109/TIT.2005.844059		23	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	912AZ	WOS:000228050800022	
J	Zhu, W; Wang, FY				Zhu, W; Wang, FY			Reduction and axiomization of covering generalized rough sets	INFORMATION SCIENCES			English	Article						computing with words; covering; covering lower and upper approximations; fuzzy sets; reduct; rough sets	APPROXIMATE	This paper investigates some basic properties of covering generalized rough sets, and their comparison with the corresponding ones of Pawlak's rough sets, a tool for data mining. The focus here is on the concepts and conditions for two coverings to generate the same covering lower approximation or the same covering upper approximation. The concept of reducts of coverings is introduced and the procedure to find a reduct for a covering is given. It has been proved that the reduct of a covering is the minimal covering that generates the same covering lower approximation or the same covering upper approximation, so this concept is also a technique to get rid of redundancy in data mining. Furthermore, it has been shown that covering lower and upper approximations determine each other. Finally, a set of axioms is constructed to characterize the covering lower approximation operation. (C) 2003 Elsevier Science Inc. All rights reserved.	Chinese Acad Sci, Lab Complex Syst & Intelligence Sci, Intelligent Control & Syst Engn Ctr, Beijing 100080, Peoples R China; Univ Arizona, Dept Syst & Ind Engn, Program Adv Res Complex Syst, Tucson, AZ 85721 USA	Wang, FY (reprint author), Chinese Acad Sci, Lab Complex Syst & Intelligence Sci, Intelligent Control & Syst Engn Ctr, Beijing 100080, Peoples R China.						Bonikowski Z., 1994, ROUGH SETS FUZZY SET, P243; Bonikowski Z, 1998, INFORM SCIENCES, V107, P149, DOI 10.1016/S0020-0255(97)10046-9; Bryniarski E., 1989, B POL ACAD SCI, V16, P71; Cattaneo G., 1998, ROUGH SETS KNOWLEDGE, V1, P59; Lin T. Y., 1994, Rough Sets, Fuzzy Sets and Knowledge Discovery. Proceedings of the International Workshop on Rough Sets and Knowledge Discovery (RSKD'93); Pawlak Z., 1991, ROUGH SETS THEORETIC; Pomykata J., 1987, B POLISH ACAD SCI MA, V35, P653; Skowron A., 1996, Fundamenta Informaticae, V27; Slowinski R, 2000, IEEE T KNOWL DATA EN, V12, P331, DOI 10.1109/69.842271; WANG CQ, 1995, POLYM J, V27, P173, DOI 10.1295/polymj.27.173; Wang F., 1998, INT J INTELLIGENT CO, V2, P211; Wasilewska A., 1997, ROUGH SETS DATA MINI, P411; Yao YY, 1998, INFORM SCIENCES, V109, P21, DOI 10.1016/S0020-0255(98)00012-7; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zakowski W., 1983, DEMONSTRATIO MATH, V16, P761; Zhu Feng, 2000, Chinese Journal of Computers, V23; Zhu F., 2000, Proceedings Fourth International Conference/Exhibition on High Performance Computing in the Asia-Pacific Region, DOI 10.1109/HPC.2000.843520; [祝峰 Zhu Feng], 2002, [模式识别与人工智能, Pattern recognition and artificial intelligence], V15, P6; ZHU F, 2002, THESIS U ARIZONA TUC	24	205	269	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JUN	2003	152						217	230		10.1016/S0020-0255(03)00056-2		14	Computer Science, Information Systems	Computer Science	675JU	WOS:000182691600014	
J	Liao, TW				Liao, TW			Clustering of time series data - a survey	PATTERN RECOGNITION			English	Article						time series data; clustering; distance measure; data mining	ALGORITHM; MODEL; FMRI; RECOGNITION; VALIDITY; MACHINE; INDEXES	Time series clustering has been shown effective in providing useful information in various domains. There seems to be an increased interest in time series clustering as part of the effort in temporal data mining research. To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of time series data in various application domains. The basics of time series clustering are presented, including general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time series being compared, either in the forms of raw data, extracted features, or some model parameters. The past researchs are organized into three groups depending upon whether they work directly with the raw data either in the time or frequency domain, indirectly with features extracted from the raw data, or indirectly with models built from the raw data. The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified. Moreover, the areas that time series clustering have been applied to are also summarized, including the sources of data used. It is hoped that this review will serve as the steppingstone for those interested in advancing this area of research. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Louisiana State Univ, Dept Ind & Mfg Syst Engn, Baton Rouge, LA 70803 USA	Liao, TW (reprint author), Louisiana State Univ, Dept Ind & Mfg Syst Engn, 3128 CEBA, Baton Rouge, LA 70803 USA.	ieliao@lsu.edu	Liao, Thunshun/B-2724-2009				AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Ananthanarayana VS, 2001, PATTERN RECOGN, V34, P2561, DOI 10.1016/S0031-3203(01)00097-8; Ankerst M, 1999, P ACM SIGMOD INT C M, P49, DOI 10.1145/304182.304187; Baragona R, 2001, QUADERNI STAT, V3, P1; Beran J, 1999, J COMPUT GRAPH STAT, V8, P213, DOI 10.2307/1390634; Bezdek J. C., 1987, PATTERN RECOGNITION; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Dahlhaus R, 1996, STOCH PROC APPL, V62, P139, DOI 10.1016/0304-4149(95)00090-9; Dunn J., 1974, J CYBERNETICS, V3, P32; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Fu T.-C., 2001, KDD 2001 WORKSH TEMP, P27; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Golay X, 1998, MAGNET RESON MED, V40, P249, DOI 10.1002/mrm.1910400211; Goutte C, 1999, NEUROIMAGE, V9, P298, DOI 10.1006/nimg.1998.0391; Goutte C, 2001, HUM BRAIN MAPP, V13, P165, DOI 10.1002/hbm.1031; Hall LO, 1999, IEEE T EVOLUT COMPUT, V3, P103, DOI 10.1109/4235.771164; Han J. W., 2001, DATA MINING CONCEPTS, P346; Josien K, 2002, FUZZY SET SYST, V126, P1, DOI 10.1016/S0165-0114(01)00063-X; Kakizawa Y, 1998, J AM STAT ASSOC, V93, P328, DOI 10.2307/2669629; Kalpakis K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989529; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Kaufman L., 1990, FINDING GROUPS DATA; KEOGH E, DATA MINING TIME SER; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KOSMELJ K, 1990, J CLASSIF, V7, P99, DOI 10.1007/BF01889706; Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879; Krishnapuram R, 2001, IEEE T FUZZY SYST, V9, P595, DOI 10.1109/91.940971; Krishnapuram R, 1999, IEEE T FUZZY SYST, V7, P453, DOI 10.1109/91.784208; LI C, 1999, LECT NOTES COMPUTER, V164, P245; LI C, 2001, LECT NOTES COMPUTER, V2189, P53; MacQueen J. B., P 5 BERK S MATH STAT, V1, P281; Maharaj EA, 2000, J CLASSIF, V17, P297, DOI 10.1007/s003570000023; Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856; Meng L, 2002, DYNAM CONT DIS SER B, V9, P421; MOLLERLEVET CS, 2003, P 5 INT S INT DAT AN; Ng GS, 1998, ARTIF INTELL ENG, V12, P189; Ng R, 1994, P 20 INT C VER LARG, P144; Owsley LMD, 1997, IEEE T SIGNAL PROCES, V45, P2787, DOI 10.1109/78.650105; Piccolo D, 1990, J TIME SER ANAL, V11, P153, DOI 10.1111/j.1467-9892.1990.tb00048.x; Policker S, 2000, IEEE T SYST MAN CY B, V30, P339, DOI 10.1109/3477.836381; Ramoni M, 2002, MACH LEARN, V47, P91, DOI 10.1023/A:1013635829250; Ramoni M., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Roddick JF, 2002, IEEE T KNOWL DATA EN, V14, P750, DOI 10.1109/TKDE.2002.1019212; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHAW CT, 1992, PHYSICA D, V58, P288, DOI 10.1016/0167-2789(92)90117-6; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Shumway RH, 2003, STAT PROBABIL LETT, V63, P307, DOI 10.1016/S0167-7152(03)00095-6; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; TRAN D, 2002, LECT NOTES ARTIF INT, V2275, P318; VANWIJK JJ, 1999, P IEEE S INF VIS SAN; Vlachos M., 2003, P 3 SIAM INT C DAT M; Wang LT, 2002, J MANUF SCI E-T ASME, V124, P651, DOI 10.1115/1.1475320; Wang WL, 1997, ELEC SOC S, V97, P186; WILPON JG, 1985, IEEE T ACOUST SPEECH, V33, P587, DOI 10.1109/TASSP.1985.1164581; Wismuller A, 2002, INT J COMPUT VISION, V46, P103, DOI 10.1023/A:1013550313321; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	65	201	216	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	NOV	2005	38	11					1857	1874		10.1016/j.patcog.2005.01.025		18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	967TB	WOS:000232113000006	
J	Li, M; Chen, X; Li, X; Ma, B; Vitanyi, PMB				Li, M; Chen, X; Li, X; Ma, B; Vitanyi, PMB			The similarity metric	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article; Proceedings Paper	14th Annual ACM-SIAM Symposium on Discrete Algorithms	JAN 12-14, 2003	BALTIMORE, MD	ACM, Special Interest Grp Algorithms & Computat Theory, SIAM Act Grp Discrete Math		dissimilarity distance; Kolmogorov complexity; language tree construction; normalized compression distance; normalized information distance; parameter-free data mining; phylogeny in bioinformatics; universal similarity metric	KOLMOGOROV COMPLEXITY; PHYLOGENETIC TREES; GENOME PHYLOGENY; INFORMATION; ALGORITHMS; SEQUENCES; DISTANCE; SPACE	A new class of distances appropriate for measuring similarity relations between sequences, say one type of similarity per distance, is studied. We propose a new "normalized information distance," based on the noncomputable notion of Kolmogorov complexity, and show that it is in this class and it minorizes every computable distance in the class (that is, it is universal in that it discovers all computable similarities). We demonstrate that it is a metric and call it the similarity metric. This theory forms the foundation for a new practical tool. To evidence generality and robustness, we give two distinctive applications in widely divergent areas using standard compression programs like gzip and GenCompress. First, we compare whole mitochondrial genomes and infer their evolutionary history. This results in a first completely automatic computed whole mitochondrial phylogeny tree. Secondly, we fully automatically compute the language tree of 52 different languages.	Univ Waterloo, Dept Comp Sci, Waterloo, ON N2L 3G1, Canada; Bioinformat Solut Inc, Waterloo, ON, Canada; Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA; Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Ctr Math & Comp Sci, CWI, NL-1098 SJ Amsterdam, Netherlands; Univ Amsterdam, Amsterdam, Netherlands	Li, M (reprint author), Univ Waterloo, Dept Comp Sci, Waterloo, ON N2L 3G1, Canada.	mli@wh.math.uwaterloo.ca; chxin@cs.ucsb.edu; xinli@csd.uwo.ca; bma@csd.uwo.ca; Paul.Vitanyi@cwi.nl	Chen, Xin/D-8430-2011; Ma, Bin/C-7550-2013; Vitanyi, Paul/A-9037-2012	Vitanyi, Paul/0000-0002-5712-7585			ADACHI J, COMPUT SCI MONOGR I, V28, P1; BALL P, 2002, NATURE           JAN; Benedetto D, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.048702; Bennett C., 2003, SCI AM           JUN, P76; Bennett CH, 1998, IEEE T INFORM THEORY, V44, P1407, DOI 10.1109/18.681318; Boore JL, 1998, CURR OPIN GENET DEV, V8, P668, DOI 10.1016/S0959-437X(98)80035-X; BRYANT D, 2000, P 11 ANN ACM SIAM S, P287; Cao Y, 1998, J MOL EVOL, V47, P307, DOI 10.1007/PL00006389; Chen X, 2001, IEEE ENG MED BIOL, V20, P61; Chen X., 1999, GENOME INFORMATICS, P51; Chen X, 2004, IEEE T INFORM THEORY, V50, P1545, DOI 10.1109/TIT.2004.830793; CILIBRASI R, UNPUB IEEE T INFORM; CILIBRASI R, IN PRESS COMPUTER MU; Cilibrasi R. L., COMPLEARN TOOLKIT; Cormode G, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P197; DELAHAYE JP, 2004, SCIENCE, V317, P98; FITCH WM, 1967, SCIENCE, V155, P279, DOI 10.1126/science.155.3760.279; Fitz-Gibbon ST, 1999, NUCLEIC ACIDS RES, V27, P4218, DOI 10.1093/nar/27.21.4218; Gacs P, 2001, IEEE T INFORM THEORY, V47, P2443, DOI 10.1109/18.945257; Gacs P., 1974, SOV MATH DOKL, V15, P1477; GASARCH W, 2001, COMMUNICATION   0812; GRUMBACH S, 1994, INFORM PROCESS MANAG, V30, P875, DOI 10.1016/0306-4573(94)90014-0; Hammer D, 2000, J COMPUT SYST SCI, V60, P442, DOI 10.1006/jcss.1999.1677; Hannenhalli S., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, DOI 10.1145/225058.225112; KECECIOGLU J, 1995, ALGORITHMICA, V13, P180, DOI 10.1007/BF01188586; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Kolmogorov A.N., 1965, Problems of Information Transmission, V1; Koonin EV, 1999, BIOINFORMATICS, V15, P265, DOI 10.1093/bioinformatics/15.4.265; LI M, 2001, INT ENCY SOCIAL BEHA, P376; Li M, 2001, BIOINFORMATICS, V17, P149, DOI 10.1093/bioinformatics/17.2.149; Li M, 1996, P ROY SOC A-MATH PHY, V452, P769, DOI 10.1098/rspa.1996.0039; Li Ming, 1997, INTRO KOLMOGOROV COM; Londei A, 2003, P 5 TRIENN ESCOM C, P200; Ma B, 2002, BIOINFORMATICS, V18, P440, DOI 10.1093/bioinformatics/18.3.440; MUCHNIK AA, 2001, P 16 IEEE C COMP COM, P256; MUIR H, 2003, NEW SCI; Muthukrishnan S., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335353; Nadeau JH, 1998, TRENDS GENET, V14, P495, DOI 10.1016/S0168-9525(98)01607-2; PATCH K, 2003, TECHNOLOGY RES NEWS, P36117; RAJSKI C, 1961, INFORM CONTROL, V4, P371, DOI 10.1016/S0019-9958(61)80055-7; Rokas A, 2003, NATURE, V425, P798, DOI 10.1038/nature02053; Romashchenko A, 2002, THEOR COMPUT SCI, V271, P111, DOI 10.1016/S0304-3975(01)00034-2; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; SANKOFF D, 1999, B INT STAT I, V47, P461; Snel B, 1999, NAT GENET, V21, P108, DOI 10.1038/5052; Varre JS, 1999, BIOINFORMATICS, V15, P194, DOI 10.1093/bioinformatics/15.3.194; VERESHCHAGIN NK, 1999, THEORY COMPUT SCI, V271, P131; Wang LS, 2001, P 33 ANN ACM S THEOR, P637, DOI 10.1145/380752.380861; Wooley JC, 1999, J COMPUT BIOL, V6, P459, DOI 10.1089/106652799318391; Yianilos P. N., 1991, 9108290271 NEC RES I; *UN GEN ASS, 1948, DECL HUM RIGHTS	51	200	208	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	DEC	2004	50	12					3250	3264		10.1109/TIT.2004.838101		15	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	874PT	WOS:000225363000020	
J	Knorr, EM; Ng, RT; Tucakov, V				Knorr, EM; Ng, RT; Tucakov, V			Distance-based outliers: algorithms and applications	VLDB JOURNAL			English	Article						outliers/exceptions; data mining; data mining applications; algorithms		This paper deals with finding outliers (exceptions) in large, multidimensional datasets. The identification of outliers can lead to the discovery of truly unexpected knowledge in areas such as electronic commerce, credit card fraud, and even the analysis of performance statistics of professional athletes. Existing methods that we have seen for finding outliers can only deal efficiently with two dimensions/attributes of a dataset. In this paper, we study the notion of DB (distance-based) outliers. Specifically, we show that (i) outlier detection can be done efficiently for large datasets, and for k-dimensional datasets with large Values of k (e.g., k greater than or equal to 5); and (ii), outlier detection is a meaningful and important knowledge discovery task. First, we present two simple algorithms, both having a complexity of O(k N-2), k being the dimensionality and N being the number of objects in the dataset. These algorithms readily support datasets with many more than two attributes. Second, we present an optimized cell-based algorithm that has a complexity that is linear with respect to N, but exponential with respect to k. We provide experimental results indicating that this algorithm significantly outperforms the two simple algorithms for k less than or equal to 4. Third, for datasets that are mainly disk-resident, we present another version of the cell-based algorithm that guarantees at most three passes over a dataset. Again, experimental results show that this algorithm is by far the best for k less than or equal to 4. Finally, we discuss our work on three real-life applications, including one on spatio-temporal data (e.g., a video surveillance application), in order to confirm the relevance and broad applicability of DB outliers.	Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada; Point Grey Res Inc, Vancouver, BC V6J 1Y6, Canada	Knorr, EM (reprint author), Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Arning A., 1996, P 2 INT C KNOWL DISC, P164; Barnett V., 1994, OUTLIERS STAT DATA; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Breiman L, 1984, CLASSIFICATION REGRE; Burl M. C., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), DOI 10.1109/CVPR.1994.323844; Chakrabarti S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Draper NR, 1966, APPL REGRESSION ANAL; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Eveland C, 1998, PROC CVPR IEEE, P266, DOI 10.1109/CVPR.1998.698619; FAYYAD U, 1996, P 2 INT C KNOWL DISC, P50; Freedman D., 1978, STATISTICS; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; GUTTMANN R, 1984, P SIGMOD, P47; HARITAOGLU I, 1997, REAL TIME DETECTION; Hawkins D. M., 1980, IDENTIFICATION OUTLI; Hellerstein J. M., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263688; Isard M., 1996, LECT NOTES COMPUTER, V1064, P343; Johnson RA, 1992, APPL MULTIVARIATE ST; Johnson T., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Knorr E. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; KNORR EM, P CASCON, P236; Ng R, 1994, P 20 INT C VER LARG, P144; PREPARATA F, 1998, COMPUTATIONAL GEOMET; Ruts I, 1996, COMPUT STAT DATA AN, V23, P153, DOI 10.1016/S0167-9473(96)00027-8; Samet H., 1990, DESIGN ANAL SPATIAL; Sarawagi S, 1998, LECT NOTES COMPUT SC, V1377, P168; STOLORZ P, 1995, CONCURRENT SUPERCOMP, P20; Stolorz P., 1995, P 1 INT C KNOWL DISC, P300; WHITE RA, 1992, THESIS U BRIT COLUMB; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	33	199	226	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1066-8888		VLDB J	VLDB J.	FEB	2000	8	3-4					237	253		10.1007/s007780050006		17	Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	295JV	WOS:000085963700006	
J	Hall, MA; Holmes, G				Hall, MA; Holmes, G			Benchmarking attribute selection techniques for discrete class data mining	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						attribute selection; classification; benchmarking		Data engineering is generally considered to be a central issue in the development of data mining applications. The success of many learning schemes, in their attempts to construct models of data, hinges on the reliable identification of a small set of highly predictive attributes. The inclusion of irrelevant, redundant, and noisy attributes in the model building process phase can result in poor predictive performance and increased computation. Attribute selection generally involves a combination of search and attribute utility estimation plus evaluation with respect to specific learning schemes. This leads to a large number of possible permutations and has led to a situation where very few benchmark studies have been conducted. This paper presents a benchmark comparison of several attribute selection methods for supervised classification. All the methods produce an attribute ranking, a useful devise for isolating the individual merit of an attribute. Attribute selection is achieved by cross-validating the attribute rankings with respect to a classification learner to find the best attributes. Results are reported for a selection of standard data sets and two diverse learning schemes C4.5 and naive Bayes.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Hall, MA (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.						ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; Blake C, 1998, UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; DASH M, 1997, INTELLIGENT DATA ANA, V1; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Hall M., 1998, THESIS U WAIKATO HAM; Hall M.A., 2000, P 17 INT C MACH LEAR; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I, 1994, P EUR C MACH LEARN, P171; Langley P, 1992, P 10 NAT C ART INT, P223; Liu H, 1996, P 13 INT C MACH LEAR, P319; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Sikonja M.R., 1997, P 14 INT C ICML 97, P296; Yang Y, 1997, P 14 INT C MACH LEAR, P412; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651	16	188	191	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV-DEC	2003	15	6					1437	1447		10.1109/TKDE.2003.1245283		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	737UC	WOS:000186249300007	
J	Pei, J; Han, JW; Mortazavi-Asl, B; Wang, JY; Pinto, H; Chen, QM; Dayal, U; Hsu, MC				Pei, J; Han, JW; Mortazavi-Asl, B; Wang, JY; Pinto, H; Chen, QM; Dayal, U; Hsu, MC			Mining sequential patterns by pattern-growth: The PrefixSpan approach	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining algorithm; sequential pattern; frequent pattern; transaction database; sequence database; scalability; performance analysis		Sequential pattern mining is an important data mining problem with broad applications. However, it is also a difficult problem since the mining may have to generate or examine a combinatorially explosive number of intermediate subsequences. Most of the previously developed sequential pattern mining methods, such as GSP, explore a candidate generation-and-test approach [1] to reduce the number of candidates to be examined. However, this approach may not be efficient in mining large sequence databases having numerous patterns and/or long patterns. In this paper, we propose a projection-based, sequential pattern-growth approach for efficient mining of sequential patterns. In this approach, a sequence database is recursively projected into a set of smaller projected databases, and sequential patterns are grown in each projected database by exploring only locally frequent fragments. Based on an initial study of the pattern growth-based sequential pattern mining, FreeSpan [8], we propose a more efficient method, called PSP, which offers ordered growth and reduced projected databases. To further improve the performance, a pseudoprojection technique is developed in PrefixSpan. A comprehensive performance study shows that PrefixSpan, in most cases, outperforms the a priori-based algorithm GSP, FreeSpan, and SPADE [29] ( a sequential pattern mining algorithm that adopts vertical data format), and PrefixSpan integrated with pseudoprojection is the fastest among all the tested algorithms. Furthermore, this mining methodology can be extended to mining sequential patterns with user-specified constraints. The high promise of the pattern-growth approach may lead to its further extension toward efficient mining of other kinds of frequent patterns, such as frequent substructures.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ Minnesota, Minneapolis, MN 55455 USA; Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; Packetmot Inc, San Mateo, CA 94403 USA; Hewlett Packard Labs, Palo Alto, CA 94303 USA; Commerce One Inc, San Francisco, CA 94105 USA	Pei, J (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	jpei@cse.sfu.edu; hanj@cs.uiuc.edu; mortazav@cs.sfu.ca; jianyong@cs.umn.edu; hlpinto@cs.sfu.ca; qchen@packetmotion.com; dayal@hpl.hp.com; meichun.hsu@commerceone.com					Agarwal R., 1994, P 20 INT C VER LARG, P487; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo RJ, 1999, PROC INT CONF DATA, P188, DOI 10.1109/ICDE.1999.754924; Bettini C, 1998, DATA ENG B, V21, P32; Pinto H., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J., 2000, P 6 ACM SIGKDD INT C, P355, DOI 10.1145/347090.347167; Han JW, 1999, PROC INT CONF DATA, P106; KOHAVI R, 2000, P SIGKDD EXPLORATION, V2, P86; Kuramochi M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989534; Lu H., 1998, P 1998 SIGMOD WORKSH, P12; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Masseglia F, 1998, LECT NOTES ARTIF INT, V1510, P176; NG K, 1998, P 1998 ACM SIGMOD IN, P13; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J, 2001, PROC INT CONF DATA, P433; Pei J, 2001, PROC INT CONF DATA, P215; Pei J., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Ramaswamy S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; Yan X., 2002, P 2002 IEEE INT C DA, P721; Yan XF, 2003, SIAM PROC S, P166; YAN X, 2003, P 2003 ACM SIGKDD IN; Yang J., 2002, P 2002 ACM SIGMOD IN, P406; Zaki M., 2000, MACH LEARN, V40, P31; Zaki M. J., 2002, P 8 ACM SIGKDD INT C, P71, DOI DOI 10.1145/775047.775058; Zaki M. J., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288643	31	180	200	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2004	16	11					1424	1440				17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	855ML	WOS:000223977300009	
J	Brameier, M; Banzhaf, W				Brameier, M; Banzhaf, W			A comparison of linear genetic programming and neural networks in medical data mining	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						data mining; evolutionary computation; genetic programming; neural networks		We introduce a new form of linear genetic programming (GP). Two methods of acceleration of our GP approach are discussed: 1) an efficient algorithm that eliminates intron code and 2) a demetic approach to virtually parallelize the system on a single processor. Acceleration of runtime is especially important when operating with complex data sets, because they are occuring in real-world applications. We compare GP performance on medical classification problems from a benchmark database with results obtained by neural networks. Our results show that GP performs comparable in classification and generalization.	Univ Dortmund, Fachbereich Informat, D-44221 Dortmund, Germany	Brameier, M (reprint author), Univ Dortmund, Fachbereich Informat, D-44221 Dortmund, Germany.		Banzhaf, Wolfgang/A-7992-2008	Banzhaf, Wolfgang/0000-0002-6382-3245			Andre D., 1996, ADV GENETIC PROGRAMM, P317; BANZHAF W, 1993, P 5 INT C GEN ALG, V628; BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3; Blake C, 1998, UCI REPOSITORY MACHI; BRAMEIER M, 1999, P INT C GEN EV COMP; Cramer N., 1985, P INT C GEN ALG THEI, P183; Fogel L.J., 1966, ARTIFICIAL INTELLIGE; FRIEDBERG RM, 1959, IBM J RES DEV, V3, P282; FRIEDBERG RM, 1958, IBM J RES DEV, V2, P2; GRAY HF, 1996, GENETIC PROGRAMMING; Holland J. H., 1975, ADAPTION NATURAL ART; KIMURA M, 1964, GENETICS, V49, P313; Koza J., 1989, P 11 INT JOINT C ART, P768; Koza J. R., 1992, GENETIC PROGRAMMING; NGAN PS, 1998, GENETIC PROGRAMMING; Nordin P., 1995, P 6 INT C GEN ALG, P318; Nordin P., 1994, ADV GENETIC PROGRAMM, P311; Nordin P., 1996, ADV GENETIC PROGRAMM, P111; NORDIN P, 1997, THESIS U DORTMUND; PRECHELT L, 1994, 2194 1 KARLSR; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; RIPLEY BD, 1997, ARTIFICIAL NEURAL NE; Schwefel H.P., 1995, EVOLUTION OPTIMUM SE; SOMORJAI RL, 1995, MAGNET RESON MED, V33, P257, DOI 10.1002/mrm.1910330217; Tackett W, 1994, THESIS U SO CALIFORN; TANESE R, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P434; WATSON JD, 1987, MOL BIOL GENE; Wright S, 1943, GENETICS, V28, P114; 1998, GENETIC PROGRAMMING	29	175	178	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	FEB	2001	5	1					17	26		10.1109/4235.910462		10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	409EJ	WOS:000167371300003	
J	Alcala-Fdez, J; Sanchez, L; Garcia, S; del Jesus, MJ; Ventura, S; Garrell, JM; Otero, J; Romero, C; Bacardit, J; Rivas, VM; Fernandez, JC; Herrera, F				Alcala-Fdez, J.; Sanchez, L.; Garcia, S.; del Jesus, M. J.; Ventura, S.; Garrell, J. M.; Otero, J.; Romero, C.; Bacardit, J.; Rivas, V. M.; Fernandez, J. C.; Herrera, F.			KEEL: a software tool to assess evolutionary algorithms for data mining problems	SOFT COMPUTING			English	Article						Computer-based education; Data mining; Evolutionary computation; Experimental design; Graphical programming; Java; Knowledge extraction; Machine learning	LEARNING ALGORITHMS; OPTIMIZATION; METHODOLOGY; CLASSIFIERS; REDUCTION; INDUCTION; FRAMEWORK; ACCURACY; NETWORKS	This paper introduces a software tool named KEEL which is a software tool to assess evolutionary algorithms for Data Mining problems of various kinds including as regression, classification, unsupervised learning, etc. It includes evolutionary learning algorithms based on different approaches: Pittsburgh, Michigan and IRL, as well as the integration of evolutionary learning techniques with different pre-processing techniques, allowing it to perform a complete analysis of any learning model in comparison to existing software tools. Moreover, KEEL has been designed with a double goal: research and educational.	[Alcala-Fdez, J.; Garcia, S.; Herrera, F.] Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain; [Sanchez, L.; Otero, J.] Univ Oviedo, Dept Comp Sci, Gijon 33204, Spain; [del Jesus, M. J.; Rivas, V. M.] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain; [Ventura, S.; Romero, C.; Fernandez, J. C.] Univ Cordoba, Dept Numer Anal & Comp Sci, E-14071 Cordoba, Spain; [Garrell, J. M.] Univ Ramon Llull, Dept Comp Sci, Barcelona 08022, Spain; [Bacardit, J.] Univ Nottingham, Dept Comp Sci & Informat Technol, Nottingham NG8 1BB, England	Alcala-Fdez, J (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	jalcala@decsai.ugr.es; luciano@uniovi.es; salvagl@decsai.ugr.es; mjjesus@ujaen.es; sventura@uco.es; josepmg@salle.url.edu; jotero@uniovi.es; cromero@uco.es; jqb@cs.nott.ac.uk; vrivas@ujaen.es; i82fecaj@uco.es; herrera@decsai.ugr.es	Ventura, Sebastian/A-7753-2008; Herrera, Francisco/C-6856-2008; Romero, Cristobal/H-4782-2011; Alcala Fernandez, Jesus/C-6795-2012; Del Jesus, Maria Jose/D-3932-2012	Ventura, Sebastian/0000-0003-4216-6378; Herrera, Francisco/0000-0002-7283-312X; Del Jesus, Maria Jose/0000-0002-7891-3059			Alcala R, 2006, SOFT COMPUT, V10, P717, DOI 10.1007/s00500-005-0002-1; Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI 10.1080/08839510390219309; Bernado-Mansilla E, 2005, IEEE T EVOLUT COMPUT, V9, P82, DOI 10.1109/TEVC.2004.840153; Berthold M.R., 2006, P 4 ANN IND SIM C WO; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Chuang AS, 2000, IEEE T POWER SYST, V15, P269, DOI 10.1109/59.852132; Cordon O, 1999, APPL INTELL, V10, P5, DOI 10.1023/A:1008384630089; CORDON O, 2001, GENETIC FUZZY SYSTEM, P488; Cordon O, 1999, INT J INTELL SYST, V14, P1123, DOI 10.1002/(SICI)1098-111X(199911)14:11<1123::AID-INT4>3.3.CO;2-Y; del Jesus MJ, 2004, IEEE T FUZZY SYST, V12, P296, DOI 10.1109/TFUZZ.2004.825972; DEMSAR J, EXPT MACHINE LEARNIN; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; EIBEN AE, 2003, INTRO EVOLUTIONARY C, P299; FREITAS AA, 2002, DATAMINING KNOWLEDGE, P264; Gagne C, 2006, INT J ARTIFICIAL INT, V15, P173, DOI 10.1142/S021821300600262X; GHOSH A, 2005, EVOLUTIONARY COMPUTA, P264; Goldberg D.E., 1989, GENETIC ALGORITHMS S, P372; GREFENSTETTE JJ, 1993, GENETIC ALGORITHMS M, P176; Holland J, 1975, ADAPTATION NATURAL A, P228; Keijzer M., 2001, ARTIFICIAL EVOLUTION, P231; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; KRASNOGOR N, 2000, P GEN EV COMP WORKSH, P125; Wong ML, 2000, GENET PROGR SER, V3, P1; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; Llora X., 2003, Intelligent Data Analysis, V7; Llora X., 2006, SIGEVOLUTION, V1, P10; Luke S., 2007, ECJ JAVA BASED EVOLU; Martinez-Estudillo A, 2006, NEURAL NETWORKS, V19, P477, DOI 10.1016/j.neunet.2005.11.001; MEYERM, 2006, JASSS-J ARTIF SOC S, V9, P3; Mierswa I, 2006, P 12 ACM SIGKDD INT, P1; Morik K, 2004, INTELLIGENT TECHNOLOGIES FOR INFORMATION ANALYSIS, P47; Mucientes M, 2006, SOFT COMPUT, V10, P881, DOI 10.1007/s00500-005-0014-x; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; ORTEGA M, 2000, COMPUTERS ED 21 CENT, P266; Otero J, 2006, SOFT COMPUT, V10, P825, DOI 10.1007/s00500-005-0011-0; PAL SK, 1996, GENETIC ALGORITHMS P, P336; PUNCH B, 1998, LIB GP 1 1 BETA; PYLE D, 1999, DATA PREPARATION DAT, P540; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN, P316; R Development Core Team, 2005, R LANG ENV STAT COMP; Rakotomalala R., 2005, P EGC 2005, V2, P697; Rivera AJ, 2007, SOFT COMPUT, V11, P655, DOI 10.1007/s00500-006-0128-9; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; Romero C, 2004, USER MODEL USER-ADAP, V14, P425, DOI 10.1007/s11257-004-7961-2; RUMMLER A, 2007, EVOLVICA JAVA FRAMEW; Rushing J, 2005, COMPUT GEOSCI-UK, V31, P607, DOI 10.1016/j.cageo.2004.11.009; Sonnenburg S, 2007, J MACH LEARN RES, V8, P2443; Stejic Z, 2007, SOFT COMPUT, V11, P669, DOI 10.1007/s00500-006-0129-8; Tan KC, 2001, IEEE T SYST MAN CY B, V31, P537, DOI 10.1109/3477.938259; Tan KC, 2003, IEEE T SYST MAN CY C, V33, P325, DOI 10.1109/TSMCC.2003.817359; Tan PN, 2006, INTRO DATA MINING, P769; Ventura S, 2008, SOFT COMPUT, V12, P381, DOI 10.1007/s00500-007-0172-0; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; Wang XM, 2007, SOFT COMPUT, V11, P439, DOI 10.1007/s00500-006-0108-0; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; Witten I. H., 2005, DATA MINING PRACTICA, P525; Zhang SC, 2003, APPL ARTIF INTELL, V17, P375, DOI 10.1080/08839510390219264	58	174	174	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	FEB	2009	13	3					307	318		10.1007/s00500-008-0323-y		12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	366YC	WOS:000260518500008	
J	Ishibuchi, H; Yamamoto, T				Ishibuchi, H; Yamamoto, T			Fuzzy rule selection by multi-objective genetic local search algorithms and rule evaluation measures in data mining	FUZZY SETS AND SYSTEMS			English	Article						data mining; pattern classification; fuzzy rule selection; evolutionary multi-criterion optimization; hybrid genetic algorithms	CLASSIFICATION SYSTEMS; PATTERN-CLASSIFICATION; OPTIMIZATION; COMPLEXITY	This paper shows how a small number of simple fuzzy if-then rules can be selected for pattern classification problems with many continuous attributes. Our approach consists of two phases: candidate rule generation by rule evaluation measures in data mining and rule selection by multi-objective evolutionary algorithms. In our approach, first candidate fuzzy if-then rules are generated from numerical data and prescreened using two rule evaluation measures (i.e., confidence and support) in data mining. Then a small number of fuzzy if-then rules are selected from the prescreened candidate rules using multi-objective evolutionary algorithms. In rule selection, we use three objectives: maximization of the classification accuracy, minimization of the number of selected rules, and minimization of the total rule length. Thus the task of multi-objective evolutionary algorithms is to find a number of non-dominated rule sets with respect to these three objectives. The main contribution of this paper is to propose an idea of utilizing the two rule evaluation measures as prescreening criteria of candidate rules for fuzzy rule selection. An arbitrarily specified number of candidate rules can be generated from numerical data for high-dimensional pattern classification problems. Through computer simulations, we demonstrate that such a prescreening procedure improves the efficiency of our approach to fuzzy rule selection. We also extend a multi-objective genetic algorithm (MOGA) in our former studies to a multi-objective genetic local search (MOGLS) algorithm where a local search procedure adjusts the selection (i.e., inclusion or exclusion) of each candidate rule. Furthermore, a learning algorithm of rule weights (i.e., certainty factors) is combined with our MOGLS algorithm. Such extensions to our MOGA for fuzzy rule selection are another contribution of this paper. (C) 2003 Elsevier B.V. All rights reserved.	Osaka Prefecture Univ, Dept Ind Engn, Sakai, Osaka 5998531, Japan	Ishibuchi, H (reprint author), Osaka Prefecture Univ, Dept Ind Engn, 1-1 Gakuen Cho, Sakai, Osaka 5998531, Japan.	hisaoi@ie.osakafu-u.ac.jp; yama@ie.osakafu-u.ac.jp	Ishibuchi, Hisao/B-3599-2009	Ishibuchi, Hisao/0000-0001-9186-6472			Abe S, 1997, IEEE T FUZZY SYST, V5, P358, DOI 10.1109/91.618273; Agrawal R., 1994, P 20 INT C VER LARG, P487; Castillo L, 2001, FUZZY SET SYST, V120, P309, DOI 10.1016/S0165-0114(99)00095-0; Castro JL, 2001, FUZZY SET SYST, V123, P307, DOI 10.1016/S0165-0114(01)00008-2; Cordon O, 1999, INT J APPROX REASON, V20, P21, DOI 10.1016/S0888-613X(00)88942-2; de Oliveira JV, 1999, IEEE T SYST MAN CY A, V29, P128, DOI 10.1109/3468.736369; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; Ishibuchi H, 2001, INFORM SCIENCES, V136, P109, DOI 10.1016/S0020-0255(01)00144-X; Ishibuchi H., 1996, Proceedings of 1996 IEEE International Conference on Evolutionary Computation (ICEC'96) (Cat. No.96TH8114), DOI 10.1109/ICEC.1996.542345; Ishibuchi H, 2001, IEEE T FUZZY SYST, V9, P506, DOI 10.1109/91.940964; ISHIBUCHI H, 1994, FUZZY SET SYST, V65, P237, DOI 10.1016/0165-0114(94)90022-1; Ishihara H, 2001, PROCEEDINGS OF THE 2000 INTERNATIONAL CONFERENCE ON EXCITONIC PROCESSES IN CONDENSED MATTER, P241, DOI 10.1109/ICDM.2001.989525; Ishibuchi H, 1998, IEEE T SYST MAN CY C, V28, P392, DOI 10.1109/5326.704576; Ishibuchi H, 1997, FUZZY SET SYST, V89, P135, DOI 10.1016/S0165-0114(96)00098-X; ISHIBUCHI H, 1992, FUZZY SET SYST, V52, P21, DOI 10.1016/0165-0114(92)90032-Y; Jaszkiewicz A, 2002, EUR J OPER RES, V137, P50, DOI 10.1016/S0377-2217(01)00104-7; JASZKIEWICZ A, 2001, P 1 INT C EV MULT OP, P241; Jin YC, 2000, IEEE T FUZZY SYST, V8, P212, DOI 10.1109/91.842154; KUNCHEVA LI, 2000, FUZZY CLASSIFIER DES; LEONDES CT, 1999, FUZZY THEORY SYSTEMS, V1; Nauck D, 1997, FUZZY SET SYST, V89, P277, DOI 10.1016/S0165-0114(97)00009-2; Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768; Pedrycz W, 1996, IEEE T SYST MAN CY B, V26, P627, DOI 10.1109/3477.517038; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575; Setnes M, 1998, IEEE T SYST MAN CY C, V28, P165, DOI 10.1109/5326.661100; WEISS SM, 1991, COMPUTER SYSTEMS THA; Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969; Zitzler E, 2000, EVOL COMPUT, V8, P173, DOI 10.1162/106365600568202	31	173	177	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JAN 1	2004	141	1					59	88		10.1016/S0165-0114(03)00114-3		30	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	759WL	WOS:000187774100005	
J	Guha, S; Rastogi, R; Shim, K				Guha, S; Rastogi, R; Shim, K			Rock: A robust clustering algorithm for categorical attributes	INFORMATION SYSTEMS			English	Article						data mining; knowledge discovery; clustering algorithms		Clustering, in data mining, is useful to discover distribution patterns in the underlying data. Clustering algorithms usually employ a distance metric based (e.g., euclidean) similarity measure in order to partition the database such that data points in the same partition are more similar than points in different partitions. In this paper, we study clustering algorithms for data with boolean and categorical attributes. We show that traditional clustering algorithms that use distances between points for clustering are not appropriate for boolean and categorical attributes. Instead, we propose a novel concept of links to measure the similarity/proximity between a pair of data points. We develop a robust hierarchical clustering algorithm ROCK that employs links and not distances when merging clusters. Our methods naturally extend to non-metric similarity measures that are relevant in situations where a domain expert/similarity table is the only source of knowledge. In addition to presenting detailed complexity results for ROCK, we also conduct an experimental study with real-life as well as synthetic data sets to demonstrate the effectiveness of our techniques. For data with categorical attributes, our findings indicate that ROCK not only generates better quality clusters than traditional algorithms, but it also exhibits good scalability properties. (C) 2000 Published by Elsevier Science Ltd.	Stanford Univ, Stanford, CA 94305 USA; Bell Labs, Murray Hill, NJ 07974 USA; Korea Adv Inst Sci & Technol, Taejon 305701, South Korea; Adv Informat Technol Res Ctr, Taejon 305701, South Korea	Guha, S (reprint author), Stanford Univ, Stanford, CA 94305 USA.						Agrawal R., 1995, P 21 INT C VER LARG, P490; COPPERSMITH P, 1987, P 19 ANN ACM S THEOR; Cormen T.H., 1990, INTRO ALGORITHMS; Duda R., 1973, PATTERN CLASSIFICATI; Ester M, 1996, INT C KNOWL DISC DAT, P226; ESTER M, 1995, INT C KNOWL DISC DAT, P94; HAN EH, 1997, 1997 SIGMOD WORKSH R, P9; Jain A.K., 1988, ALGORITHMS CLUSTERIN; KARYPIS G, 1997, P ACM IEEE DES AUT C; Ng R, 1994, P 20 INT C VER LARG, P144; SHIM K, 1997, ICDE, P301; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	14	172	190	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	JUL	2000	25	5					345	366		10.1016/S0306-4379(00)00022-3		22	Computer Science, Information Systems	Computer Science	343DZ	WOS:000088687600002	
S	Pasquier, N; Bastide, Y; Taouil, R; Lakhal, L		Beeri, C; Buneman, P		Pasquier, N; Bastide, Y; Taouil, R; Lakhal, L			Discovering frequent closed itemsets for association rules	DATABASE THEORY - ICDT'99	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Database Theory (ICDT 99)	JAN 10-12, 1999	JERUSALEM, ISRAEL	Hebrew Univ Jerusalem, Tel Aviv Univ, Tandem Lab Israel Compaq Co, ACM Special Inter Grp Management Data, IEEE Israel Chapter, Israel Assoc info Proc, EDBT Fdn			KNOWLEDGE	In this paper, we address the problem of finding frequent itemsets in a database. Using the closed itemset lattice framework, we show that this problem can be reduced to the problem of finding frequent closed itemsets. Based on this statement, we can construct efficient data mining algorithms by limiting the search space to the closed itemset lattice father than the subset lattice. Moreover, we show that the set of all frequent closed itemsets suffices to determine a reduced set of association rules, thus addressing another important data mining problem: limiting the number of rules produced without information loss. We propose a new algorithm, called A-Close, using a closure mechanism to find frequent closed itemsets. We realized experiments to compare our approach to the commonly used frequent itemset search approach. Those experiments showed that our approach is very valuable for dense and/or correlated data that represent an important part of existing databases.	Univ Clermont Ferrand 2, Lab Informat, LIMOS, F-63177 Clermont Ferrand, France	Pasquier, N (reprint author), Univ Clermont Ferrand 2, Lab Informat, LIMOS, Complexe Sci des Cezeaux,24 Av des Landais, F-63177 Clermont Ferrand, France.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P478; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; BIRKHOFF G, 1967, COLL PUB, V25; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Davey B.A., 1994, INTRO LATTICES ORDER; Duquenne V., 1986, MATH SCI HUM, V24, P5; GANTER B, 1991, ORDER, P283; Lin DI, 1998, P 6 INT C EXT DAT TE, P105; Luxenburger M., 1991, MATH INFORMATIQUE SC, V29, P35; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; MUELLER A, 1995, FAST SEQUENTIAL PARA; PASQUIER N, 1998, IN PRESS P BDA FRENC; Savasere A, 1995, P 21 INT C VER LARG, P432; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; TOIVONEN H, 1995, ECML 95 WORKSH STAT, P47; WILLE R, 1992, COMPUT MATH APPL, V23, P493, DOI 10.1016/0898-1221(92)90120-7; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	20	166	166	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-65452-6	LECT NOTES COMPUT SC			1999	1540						398	416				19	Computer Science, Information Systems	Computer Science	BN73Y	WOS:000082775200025	
J	Park, JS; Chen, MS; Yu, PS				Park, JS; Chen, MS; Yu, PS			Using a hash-based method with transaction trimming for mining association rules.	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; association rules; hashing; performance analysis		In this paper, we examine the issue of mining association rules among items in a large database of sales transactions. Mining association rules means that, given a database of sales transactions, to discover all associations among items such that the presence of some items in a transaction will imply the presence of other items in the same transaction. The mining of association rules can be mapped into the problem of discovering large itemsets where a large itemset is a group of items that appear in a sufficient number of transactions. The problem of discovering large itemsets can be solved by constructing a candidate set of itemsets first, and then, identifying-within this candidate set-those itemsets that meet the large itemset requirement. Generally, this is done iteratively for each large k-itemset in increasing order of k, where a large k-itemset is a large itemset with k items. To determine large itemsets from a huge number of candidate sets in early iterations is usually the dominating factor for the overall data-mining performance. To address this issue, we develop an effective algorithm for the candidate set generation. It is a hash-based algorithm and is especially effective for the generation of candidate set for large 2-itemsets. Explicitly, the number of candidate 2-itemsets generated by the proposed algorithm is, in orders of magnitude, smaller than that by previous methods-thus resolving the performance bottleneck. Note that the generation of smaller candidate sets enables us to effectively trim the transaction database size at a much earlier stage of the iterations, thereby reducing the computational cost for later iterations significantly. The advantage of the proposed algorithm also provides us the opportunity of reducing the amount of disk I/O required. Extensive simulation study is conducted to evaluate performance of the proposed algorithm.	NATL TAIWAN UNIV, DEPT ELECT ENGN, TAIPEI 10764, TAIWAN; IBM CORP, THOMAS J WATSON RES CTR, NEW YORK, NY 10598 USA	Park, JS (reprint author), SUNGSHIN WOMENS UNIV, DEPT COMP SCI, SEOUL, SOUTH KOREA.		Yu, Philip/A-2815-2012				AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 1995, ADV KDDM; AGRAWAL R, 1993, P 4 INT C FDN DAT OR; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; Agrawal R., 1994, P 20 INT C VER LARG, P478; ANWAR TM, 1992, P INT C DAT ENG TAMP, P622; COFFMAN EG, 1970, COMMUN ACM, V13, P427, DOI 10.1145/362686.362693; Han J., 1992, 18TH P INT C VER LAR, P547; Han J, 1995, P 21 INT C VER LARG, P420; Knuth D, 1973, ART COMPUTER PROGRAM, V3; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Ng R, 1994, P 20 INT C VER LARG, P144; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Quinlan J. R., 1986, MACHINE LEARNING, V1; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863	17	166	185	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP-OCT	1997	9	5					813	825				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	YE845	WOS:A1997YE84500012	
J	Lindell, Y; Pinkas, B				Lindell, Y; Pinkas, B			Privacy preserving data mining	JOURNAL OF CRYPTOLOGY			English	Article						secure two-party computation; oblivious transfer; oblivious polynomial evaluation; data mining; decision trees	INFORMATION	In this paper we address the issue of privacy preserving data mining. Specifically, we consider a scenario in which two parties owning confidential databases wish to run a data mining algorithm on the union of their databases, without revealing any unnecessary information. Our work is motivated by the need both to protect privileged information and to enable its use for research or other purposes. The above problem is a specific example of secure multi-party computation and, as such, can be solved using known generic protocols. However, data mining algorithms are typically complex and, furthermore, the input usually consists of massive data sets. The generic protocols in such a case are of no practical use and therefore more efficient protocols are required. We focus on the problem of decision tree learning with the popular ID3 algorithm. Our protocol is considerably more efficient than generic solutions and demands both very few rounds of communication and reasonable bandwidth.	Weizmann Inst Sci, Dept Comp Sci, IL-76100 Rehovot, Israel; Intertrust Technol, Star Lab, Santa Clara, CA 95054 USA	Lindell, Y (reprint author), Weizmann Inst Sci, Dept Comp Sci, IL-76100 Rehovot, Israel.	lindell@wisdom.weizmann.ac.il; bpinkas@intertrust.com					Boneh D, 1997, LECT NOTES COMPUT SC, V1294, P425; Canetti R, 2000, J CRYPTOL, V13, P143, DOI 10.1007/s001459910006; Chaum D., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/62212.62214; Chor B., 1995, Proceedings. 36th Annual Symposium on Foundations of Computer Science (Cat. No.95CB35834), DOI 10.1109/SFCS.1995.492461; EVEN S, 1985, COMMUN ACM, V28, P637, DOI 10.1145/3812.3818; Fagin R, 1996, COMMUN ACM, V39, P77, DOI 10.1145/229459.229469; Feigenbaum J., 2001, P 28 INT C AUT LANG, P927; GOLDREICH O, 1998, UNPUB SECURE MULTIPA; Goldreich Oded, 1987, P 19 ANN ACM S THEOR, P218, DOI 10.1145/28395.28420; Ben-Or M., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/62212.62213; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; Mitchell T. M, 1997, MACHINE LEARNING; Naor M, 2001, SIAM PROC S, P448; Naor M., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301312; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rabin M., 1981, TR81 AIK COMP LAB; Yao A., 1986, P 27 IEEE S FDN COMP, P162	17	151	165	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0933-2790		J CRYPTOL	J. Cryptology	SUM	2002	15	3					177	206		10.1007/s00145-001-0019-2		30	Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Mathematics, Applied	Computer Science; Engineering; Mathematics	569UC	WOS:000176619800002	
J	Mitra, S; Pal, SK; Mitra, P				Mitra, S; Pal, SK; Mitra, P			Data mining in soft computing framework: A survey	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						fuzzy logic; genetic algorithms; knowledge discovery; neural networks; neuro-fuzzy computing; rough sets; rule extraction	ROUGH SET APPROACH; KNOWLEDGE DISCOVERY; NEURAL-NETWORKS; RULE GENERATION; SELF-ORGANIZATION; FUZZY-LOGIC; DATABASES; CLASSIFICATION; SYSTEM; DESIGN	The present article provides a survey of the available literature on data mining using soft computing. A categorization has been provided based on the different soft computing tools and their hybridizations used, the data mining function implemented, and the preference criterion selected by the model. The utility on the different soft computing methodologies is highlighted. Generally fuzzy sets are suitable for handling the issues related to understandability of patterns, incomplete/noisy data, mixed media information and human interaction, and can provide approximate solutions faster. Neural networks are nonparametric, robust, and exhibit good learning and generalization capabilities in data-rich environments. Genetic algorithms provide efficient search algorithms to select a model, from mixed media data, based on some preference criterion/objective function. Rough sets are suitable for handling different types of uncertainty in data. Some challenges to data mining and the application of soft computing methodologies are indicated. An extensive bibliography is also included.	Indian Stat Inst, Machine Intelligence Unit, Calcutta 700035, W Bengal, India	Mitra, S (reprint author), Indian Stat Inst, Machine Intelligence Unit, Calcutta 700035, W Bengal, India.	sushmita@isical.ac.in; sankar@isical.ac.in; pabitra_r@isical.ac.in					Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732; Baldwin JF, 1996, PATTERN RECOGN LETT, V17, P593, DOI 10.1016/0167-8655(96)00023-2; Banerjee M, 1998, IEEE T NEURAL NETWOR, V9, P1203, DOI 10.1109/72.728363; Bengio S, 2000, IEEE T NEURAL NETWOR, V11, P550, DOI 10.1109/72.846725; Bengio Y, 2000, IEEE T NEURAL NETWOR, V11, P545; BLUM RL, 1985, DISCOVERY REPRESENTA, V19; BOSC P, 1999, P NAFIPS 99, P580; Chiang DA, 2000, FUZZY SET SYST, V112, P419, DOI 10.1016/S0165-0114(98)00003-7; CIESIELSKI V, 1996, P 2 INT C KNOWL DISC, P38; Cios K., 1998, DATA MINING METHODS; Etzioni O, 1996, COMMUN ACM, V39, P65, DOI 10.1145/240455.240473; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Fayyad U, 1996, COMMUN ACM, V39, P51, DOI 10.1145/240455.240471; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FLOCKHART IW, 1996, P 2 INT C KNOWL DISC, P299; FRIGUI H, 1999, P N AM FUZZ INF PROC, P575; Furnkranz J, 1997, APPL ARTIF INTELL, V11, P91, DOI 10.1080/088395197118262; George R., 1996, GENETIC ALGORITHMS S, P599; GRZYMALABUSSE JW, 1999, P 7 INT WORKSH ROUGH, P405; GRZYMALABUSSE JW, 1998, ROUGH SETS KNOWLEDGE, V2, P562; Hale J, 1996, DATA KNOWL ENG, V18, P167, DOI 10.1016/0169-023X(95)00033-O; Heider R, 1996, LECT NOTES ARTIF INT, V1168, P512; Hu XH, 1996, PROC INT CONF DATA, P96; Inmon WH, 1996, COMMUN ACM, V39, P49, DOI 10.1145/240455.240470; Kacprzyk J., 1998, Proceedings of the 5th International Conference on Soft Computing and Information/Intelligent Systems. Methodologies for the Conception, Design and Application of Soft Computing; Kargupta H., 2000, ADV DISTRIBUTED PARA; Kewley RH, 2000, IEEE T NEURAL NETWOR, V11, P668, DOI 10.1109/72.846738; KIEM H, 1999, P RSFDGRC 99 YAM JAP, P448; KOENIG A, 2000, IEEE T NEURAL NETWOR, V11, P615; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; Lee DH, 1997, IEEE T SYST MAN CY B, V27, P68; Lee RST, 2000, IEEE T NEURAL NETWOR, V11, P680, DOI 10.1109/72.846739; Liu B, 1999, IEEE T KNOWL DATA EN, V11, P817; LOPES C, 1999, P RSFDGRC 99 YAM JAP, P458; MAEDA A, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 5, P45, DOI 10.1109/FUZZY.1995.410035; MAJOR JA, 1992, INT J INTELL SYST, V7, P687, DOI 10.1002/int.4550070709; MAZLACK LJ, 1999, P NAFIPS 99 NEW YORK, P700; MEDASANI S, 1999, P IEEE INTL C FUZZ S, P590; MITCHELL TM, 1999, COMMUN ACM, V42; Mitra P, 2000, IEEE T BIO-MED ENG, V47, P934, DOI 10.1109/10.846688; Mitra S, 1996, IEEE T SYST MAN CY A, V26, P608, DOI 10.1109/3468.531908; MITRA S, 1995, IEEE T NEURAL NETWOR, V6, P51, DOI 10.1109/72.363450; Mitra S, 1997, IEEE T NEURAL NETWOR, V8, P1338, DOI 10.1109/72.641457; Mitra S, 2001, NEUROCOMPUTING, V36, P45, DOI 10.1016/S0925-2312(00)00335-0; Mitra S, 2000, IEEE T NEURAL NETWOR, V11, P748, DOI 10.1109/72.846746; MOLLESTAD T, 1996, LECT NOTES ARTIF INT, V1079, P448; NASRAOUI O, 1999, P N AM FUZZ INF SOC, P705; NAUCK D, 1999, P 18 INT C N AM FUZZ, P536; Noda E., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.782601; Pal S. K., 2000, SOFT COMPUTING IMAGE; Pal S.K., 1999, NEUROFUZZY PATTERN R; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; PAL SK, 2000, IN PRESS IEEE T KNOW; Pal SK, 2000, IEEE T NEURAL NETWOR, V11, P366, DOI 10.1109/72.839007; Pal S.K, 2001, SOFT COMPUTING CASE; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pedrycz W, 1998, FUZZY SET SYST, V98, P279, DOI 10.1016/S0165-0114(96)00377-6; Pedrycz W, 1996, PATTERN RECOGN LETT, V17, P625, DOI 10.1016/0167-8655(96)00027-X; PIATETSKYSHAPIR.P, 1991, KNOWLEDGE DISCOVERY; Polkowski L., 1998, ROUGH SETS KNOWLEDGE; PROVOST F, 1999, DATA MIN KNOWL DISC, V2, P131; QU WH, 1998, P IEEE INT C FUZZ SY, P1314; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RAYMER RL, 1996, P 1 ANN C GEN PROGR, P375; RUSSELL S, 1999, P NAFIPS 99 NEW YORK, P720; Ryu T., 1996, P 1 ANN GEN PROGR C, P200; Lu HJ, 1996, IEEE T KNOWL DATA EN, V8, P957; SHALVI D, 1998, P IEEE INT JOINT C N, P171; SHAN N, 1995, COMPUT INTELL, V11, P357, DOI 10.1111/j.1467-8640.1995.tb00038.x; Shin CK, 2000, IEEE T NEURAL NETWOR, V11, P637, DOI 10.1109/72.846735; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; SKOWRON A, 1995, COMPUT INTELL, V11, P371, DOI 10.1111/j.1467-8640.1995.tb00039.x; Teller A., 1995, INT J EXPERT SYST, V8, P216; Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352; TURKSEN IB, 1998, P IEEE INT C SYST MA, P2057; Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731; Wei Q, 1999, P N AM FUZZ INF PROC, P477; XU K, 1998, P IEEE SMC 98, P2326; Yager R. R., 1991, Knowledge discovery in databases; Yager RR, 1996, INT J INTELL SYST, V11, P691, DOI 10.1002/(SICI)1098-111X(199609)11:9<691::AID-INT7>3.0.CO;2-F; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255; Zadeh LA, 2001, AI MAG, V22, P73; Zhang YQ, 2000, IEEE T NEURAL NETWOR, V11, P658, DOI 10.1109/72.846737; Ziarko W., 1994, P 3 INT WORKSH ROUGH, P164; 1992, INT J INTELL SYST, V7	89	150	158	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JAN	2002	13	1					3	14		10.1109/72.977258		12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	514LE	WOS:000173440100002	
S	Han, JW; Dong, GZ; Yin, YW		Kitsuregawa, M; Maciaszek, L; Papazoglou, M; Pu, C		Han, JW; Dong, GZ; Yin, YW			Efficient mining of partial periodic patterns in time series database	15TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING, PROCEEDINGS	IEEE International Conference on Data Engineering		English	Proceedings Paper	15th International Conference on Date Engineering	MAR 23-26, 1999	SYDNEY, AUSTRALIA	IEEE Comp Soc Tech Comm Data Engn		periodicity search; partial periodicity; time-series analysis; data mining algorithms		Partial periodicity search, i.e., search for partial periodic patterns in time-series databases, is an interesting data mining problem. Previous studies on periodicity search mainly consider finding full periodic patterns, where every point in time contributes (precisely or approximately) to the periodicity. However, partial periodicity is very common in practice since it is more likely that only some of the time episodes may exhibit periodic patterns. We present several algorithms for efficient mining of partial periodic patterns, by exploring some interesting properties related to partial periodicity, such as the Apriori property and the max-subpattern hit set property, and by shared mining of multiple periods. The max-subpattern hit set property is a vital new property which allows las to derive the counts of all frequent patterns from a relatively small subset of patterns existing in the time series. We show that mining partial periodicity needs only two scans over the time series database, even for mining multiple periods. The performance study shows our proposed methods are very efficient in mining long periodic patterns.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Han, JW (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	han@cs.sfu.ca; gdong@cs.wright.edu; yiweny@cs.sfu.ca	Maciaszek, Leszek/K-2068-2013	Maciaszek, Leszek/0000-0001-6561-0545			Agrawal R., 1995, P 21 INT C VER LARG, P502; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bettini C, 1998, DATA ENG B, V21, P32; HAN J, 1998, P 1998 INT C KNOW DI; Han J, 1995, P 21 INT C VER LARG, P420; Loether H.J., 1993, DESCRIPTIVE INFERENT; LU H, 1998, P 1998 SIGMOD WORKSH; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804	12	150	165	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1084-4627	0-7695-0071-4	PROC INT CONF DATA			1999							106	115				10	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BM73S	WOS:000079630800023	
J	Delen, D; Walker, G; Kadam, A				Delen, D; Walker, G; Kadam, A			Predicting breast cancer survivability: a comparison of three data mining methods	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						breast cancer survivability; data mining; k-fold-cross-validation; SEER	ARTIFICIAL NEURAL-NETWORKS; PROGNOSIS; PROGRAM; TREES	Objective: The prediction of breast cancer survivability has been a challenging research problem for many researchers. Since the early dates of the related research, much advancement has been recorded in several related fields. For instance, thanks to innovative biomedical technologies, better explanatory prognostic factors are being measured and recorded; thanks to Low cost computer hardware and software technologies, high volume better quality data is being collected and stored automatically; and finally thanks to better analytical methods, those voluminous data is being processed effectively and efficiently. Therefore, the main objective of this manuscript is to report on a research project where we took advantage of those available technological advancements to develop prediction models for breast cancer survivability. Methods and material: We used two popular data mining algorithms (artificial neural networks and decision trees) along with a most commonly used statistical method (Logistic regression) to develop the prediction models using a Large dataset (more than 200,000 cases). We also used 10-fold cross-validation methods to measure the unbiased estimate of the three prediction models for performance comparison purposes. Results: The results indicated that the decision tree (C5) is the best predictor with 93.6% accuracy on the holdout sample (this prediction accuracy is better than any reported in the literature), artificial neural networks came out to be the second with 91.2% accuracy and the logistic regression models came out to be the worst of the three with 89.2% accuracy. Conclusion: The comparative study of multiple prediction models for breast cancer survivability using a large dataset along with a 10-fold cross-validation provided us with an insight into the relative prediction ability of different data mining methods. Using sensitivity analysis on neural network models provided us with the prioritized importance of the prognostic factors used in the study. &COPY; 2004 Elsevier B.V. All rights reserved.	Oklahoma State Univ, Dept Management Sci & Informat Syst, Tulsa, OK 74106 USA	Delen, D (reprint author), Oklahoma State Univ, Dept Management Sci & Informat Syst, 700 N Greenwood Venue, Tulsa, OK 74106 USA.	delen@okstate.edu					Abbass HA, 2002, ARTIF INTELL MED, V25, P265, DOI 10.1016/S0933-3657(02)00028-3; Abu-Hanna A, 2003, ARTIF INTELL MED, V29, P5, DOI 10.1016/S0933-3657(03)00047-2; Berman JJ, 2002, ARTIF INTELL MED, V26, P25, DOI 10.1016/S0933-3657(02)00050-7; Bostwick DG, 2001, CANCER, V91, P1643, DOI 10.1002/1097-0142(20010415)91:8+<1643::AID-CNCR1177>3.0.CO;2-I; Breiman L, 1984, CLASSIFICATION REGRE; Brenner H, 2002, EUR J CANCER, V38, P690, DOI 10.1016/S0959-8049(02)00003-5; Bundred NJ, 2001, CANCER TREAT REV, V27, P137, DOI 10.1053/ctrv.2001.0207; BURKE HB, 1995, ADV NEURAL INFORMATI, V7, P1063; Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y; CALLE J, 2004, BREAST CANC FACTS FI, P1; Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0; Cox DR, 1984, ANAL SURVIVAL DATA; D'Eredita G, 2001, EUR J CANCER, V37, P591, DOI 10.1016/S0959-8049(00)00435-4; Edwards BK, 2002, CANCER, V94, P2766, DOI 10.1002/cncr.10593; Hankey BF, 1999, CANCER EPIDEM BIOMAR, V8, P1117; Hastie T., 2001, ELEMENTS STAT LEARNI; Hornik K, 1990, NEURAL NETWORKS, V3, P359; HYAKIN S, 1998, NEURAL NETWORKS COMP; Jerez-Aragones JM, 2003, ARTIF INTELL MED, V27, P45, DOI 10.1016/S0933-3657(02)00086-6; Jimenez-Lee R, 2003, AM J SURG, V186, P404, DOI 10.1016/S0002-9610(03)00283-6; Kohavi R, 1995, 14 INT JOINT C ART I, P1137; Lavrac N, 1999, ARTIF INTELL MED, V16, P3, DOI 10.1016/S0933-3657(98)00062-1; Lundin M, 1999, ONCOLOGY-BASEL, V57, P281, DOI 10.1159/000012061; Ohno-Machado L, 2001, J BIOMED INFORM, V34, P428, DOI 10.1006/jbin.2002.1038; OMALLEY CD, 2003, SOCIOECONOMIC STATUS, P1303; Pendharkar PC, 1999, EXPERT SYST APPL, V17, P223, DOI 10.1016/S0957-4174(99)00036-6; Principe J. C., 2000, NEURAL ADAPTIVE SYST; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rampaul RS, 2001, EUR J SURG ONCOL, V27, P229, DOI 10.1053/ejso.2001.1114; Richards G, 2001, ARTIF INTELL MED, V22, P215, DOI 10.1016/S0933-3657(00)00110-X; RITTER M, 2003, TULSA WORLD     0616, pD8; ROSS E, 2003, ASS PRESS; Santos-Garcia G, 2004, ARTIF INTELL MED, V30, P61, DOI 10.1016/S0933-3657(03)00059-9; Shearer C, 2000, J DATA WAREHOUSING, V5, P13; WARREN J, 2003, WEBMD MED NEWS; *NCI SURV RES PROG, 1973, SEER CANC STAT REV S; BREAST CANC Q A FACT	38	149	155	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	JUN	2005	34	2					113	127		10.1016/j.artmed.2004.07.002		15	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	932NA	WOS:000229559200002	
J	Pan, SJ; Yang, QA				Pan, Sinno Jialin; Yang, Qiang			A Survey on Transfer Learning	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Transfer learning; survey; machine learning; data mining	TEXT CATEGORIZATION; CLASSIFICATION	A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.	[Pan, Sinno Jialin; Yang, Qiang] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China	Pan, SJ (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.	sinnopan@cse.ust.hk; qyang@cse.ust.hk			Hong Kong CERG [621307]; NEC China Lab.	The authors thank the support of Hong Kong CERG Project 621307 and a grant from NEC China Lab.	Al-Mubaid H, 2006, IEEE T KNOWL DATA EN, V18, P1156, DOI 10.1109/TKDE.2006.135; Argyriou A, 2007, ADV NEURAL INFORM PR, V19, P41; Argyriou A., 2008, P 20 ANN C NEUR INF, P25; ARGYRIOU A, 2008, P EUR C MACH LEARN K, P71; Arnold A., 2007, P 7 IEEE INT C DAT M, P77; BAKKER B., 2003, J MACH LEARN RES, V4, P83, DOI DOI 10.1162/153244304322765658; Baralis E, 2008, IEEE T KNOWL DATA EN, V20, P156, DOI 10.1109/TKDE.2007.190677; BENDAVID S, 2003, P 16 ANN C LEARN THE, P825; Ben-David S., 2007, P 20 ANN C NEUR INF, P137; Bickel S, 2007, P 24 INT C MACH LEAR, P81, DOI 10.1145/1273496.1273507; BLITZER J, 2008, P 21 ANN C NEUR INF, P129; Blitzer J, 2006, P C EMP METH NAT LAN, P120, DOI 10.3115/1610075.1610094; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Bonilla E., 2008, P 20 ANN C NEUR INF, P153; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI 10.1145/1273496.1273521; Dai W., 2008, P 21 ANN C NEUR INF; Dai W., 2008, P 25 INT C MACH LEAR, P200, DOI 10.1145/1390156.1390182; Dai W., 2007, P 13 ACM SIGKDD INT; Dai W., 2007, P 22 AAAI C ART INT, P540; Daume H, 2006, J ARTIF INTELL RES, V26, P101; Daume III H., 2007, P 45 ANN M ASS COMP, P256; Davis J., 2008, P ASS ADV ART INT AA; DREDZE M., 2007, P 45 ANN M ASS COMP, P432; EATON E, 2008, P EUR C MACH LEARN K, P317; EVGENIOU T., 2004, P 10 ACM SIGKDD INT, P109, DOI 10.1145/1014052.1014067; Fan W., 2005, P 5 IEEE INT C DAT M; Fung GPC, 2006, IEEE T KNOWL DATA EN, V18, P6; Gao J., 2008, P 14 ACM SIGKDD INT, P283, DOI 10.1145/1401890.1401928; Huang J., 2007, P 19 ANN C NEUR INF; JEBARA T., 2004, P 21 INT C MACH LEAR; Jiang J, 2007, P 45 ANN M ASS COMP, P264; Joachims T., 1999, P 16 INT C MACH LEAR, P200; JOACHIMS T, 1999, P 16 INT C MACH LEAR, P825; KUHLMANN G, 2007, P 18 EUR C MACH LEAR, P188; Kuncheva LI, 2007, IEEE T KNOWL DATA EN, V19, P500, DOI [10.1109/TKDE.2007.1016, 10.1109/TDKE.2007.1016]; Lawrence N. D., 2009, DATASET SHIFT MACHIN; Lawrence ND, 2004, P 21 INT C MACH LEAR; Lee H, 2007, P 19 ANN C NEUR INF, P801; Lee S, 2007, PROC MONOGR ENG WATE, P489, DOI 10.1145/1273496.1273558; LI B, 2009, P 21 INT JOINT C ART; LI B, 2009, P 26 INT C MACH LEAR; Liao X., 2005, P 22 INT C MACH LEAR, P505, DOI 10.1145/1102351.1102415; Ling X., 2008, P 17 INT C WORLD WID, P969, DOI 10.1145/1367497.1367628; Ling X, 2008, P 14 ACM SIGKDD INT, P488, DOI 10.1145/1401890.1401951; MAHMUD MMH, 2008, P 20 ANN C NEUR INF, P985; MIHALKOVA L, 2008, P ASS ADV ART INT AA; Mihalkova L., 2007, P 22 AAAI C ART INT, P608; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pan S., 2008, P WORKSH TRANSF LEAR; Pan S. J., 2008, P 23 AAAI C ART INT, P1383; Pan SJ, 2008, P 23 AAAI C ART INT, P677; Pan SJ, 2009, P 21 INT JOINT C ART; Pan S.J., 2007, P 22 NAT C ART INT V, P1108; Raina R., 2006, P 23 INT C MACH LEAR, P713, DOI 10.1145/1143844.1143934; Raina R., 2007, P 24 INT C MACH LEAR, P759, DOI 10.1145/1273496.1273592; RAMACHANDRAN S, 1998, P INT C MACH LEARN M, P454; RAMON J, 2007, P 18 EUR C MACH LEAR, P699; Raykar V.C., 2008, P 25 INT C MACH LEAR, P808, DOI 10.1145/1390156.1390258; Richardson AD, 2006, AGR FOREST METEOROL, V136, P1, DOI 10.1016/j.agrformet.2006.01.007; ROSENSTEIN MT, 2005, P C NEUR INF PROC SY; RUCKERT U, 2008, P EUR C MACH LEARN K, P220; Sarinnapakorn K, 2007, IEEE T KNOWL DATA EN, V19, P1638, DOI 10.1109/TKDE.2007.190663; Schwaighofer A., 2005, P 17 ANN C NEUR INF, P1209; SHI X, 2008, P EUR C MACH LEARN K, P342; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Sugiyama M, 2008, P 20 ANN C NEUR INF; Taylor M. E., 2007, P 24 INT C MACH LEAR, P879, DOI 10.1145/1273496.1273607; Thrun S., 1998, LEARNING LEARN; Vapnik V. N., 1998, STAT LEARNING THEORY; Wang C., 2008, P 25 INT C MACH LEAR, P1120, DOI 10.1145/1390156.1390297; Wang Z., 2008, P EUR C MACH LEARN K, P550; WU P, 2004, P 21 INT C MACH LEAR; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Xing D., 2007, P 11 EUR C PRINC PRA, P324; Xue G.-R., 2008, P 31 ANN INT ACM SIG, P627, DOI 10.1145/1390334.1390441; Yang LX, 2006, SER INF MANAGE SCI, V5, P626; Yang Q, 2008, IEEE INTELL SYST, V23, P8, DOI 10.1109/MIS.2008.4; Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258; YIN J, 2005, P 3 IEEE INT C PERV; Yin XX, 2006, IEEE T KNOWL DATA EN, V18, P770, DOI 10.1109/TKDE.2006.94; Zadrozny B., 2004, P 21 INT C MACH LEAR; Zhang T., 2005, P 43 ANN M ASS COMP, P1, DOI 10.3115/1219840.1219841; Zheng V. W., 2008, P 23 NAT C ART INT A, P1421; ZHENG VW, 2008, P 23 AAAI C ART INT, P1427; Zhu X, 2006, 1530 U WISC MAD; Zhu XQ, 2006, IEEE T KNOWL DATA EN, V18, P1435, DOI 10.1109/TKDE.2006.155; ZHUO H, 2008, P 10 PAC RIM INT C A	88	148	159	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	OCT	2010	22	10					1345	1359		10.1109/TKDE.2009.191		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	639UQ	WOS:000281000500001	
J	Zhao, Y; Karypis, G				Zhao, Y; Karypis, G			Empirical and theoretical comparisons of selected criterion functions for document clustering	MACHINE LEARNING			English	Article						partitional clustering; criterion function; data mining; information retrieval	OPTIMIZATION; ALGORITHM	This paper evaluates the performance of different criterion functions in the context of partitional clustering algorithms for document datasets. Our study involves a total of seven different criterion functions, three of which are introduced in this paper and four that have been proposed in the past. We present a comprehensive experimental evaluation involving 15 different datasets, as well as an analysis of the characteristics of the various criterion functions and their effect on the clusters they produce. Our experimental results show that there are a set of criterion functions that consistently outperform the rest, and that some of the newly proposed criterion functions lead to the best overall results. Our theoretical analysis shows that the relative performance of the criterion functions depends on (i) the degree to which they can correctly operate when the clusters are of different tightness, and (ii) the degree to which they can lead to reasonably balanced clusters.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Zhao, Y (reprint author), Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.	yzhao@cs.umn.edu; karypis@cs.umn.edu					Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347176; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; BOLEY D, 1998, DATA MINING KNOWLEDG, V2; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHENG CK, 1991, IEEE T COMPUT AID D, V10, P1502, DOI 10.1109/43.103500; CUTTING DR, 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; Dempster A. P., 1977, J ROYAL STAT SOC, V39; Devore J., 1997, STAT EXPLORATION ANA; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; DING C, 2001, TR2001XX U CAL LAWR; Duda R.O., 2001, PATTERN CLASSIFICATI; Ester M., 1996, P 2 INT C KNOWL DISC; Fisher D, 1996, J ARTIF INTELL RES, V4, P147; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Guha S., 1999, P 15 INT C DAT ENG; GUHA S, 1998, P 1998 ACM SIGMOD IN; Hagen L., 1991, P IEEE INT C COMP AI, P10; HAN EH, 1998, P 2 INT C AUT AG; Han J., 2001, GEOGRAPHIC DATA MINI; Hendrickson B, 2000, SIAM J SCI COMPUT, V21, P2048, DOI 10.1137/S1064827598341475; Hersh W., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval; Jackson J., 1991, USERS GUIDE PRINCIPA; Jain A. K., 1999, ACM COMPUT SURV, V31; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; KARYPIS G, 1999, TR99020 U MINN DEP C; KARYPIS G, 2000, TR00016 U MINN DEP C; King B., 1967, J AM STAT ASSOC, V69, P86; Larsen B, 1999, P 5 ACM SIGKDD INT C, DOI 10.1145/312129.312186; Lewis D. D., 1999, REUTERS 21578 TEXT C; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Meila M, 2001, MACH LEARN, V42, P9, DOI 10.1023/A:1007648401407; Ng R, 1994, P 20 INT C VER LARG, P144; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Puzicha J, 2000, PATTERN RECOGN, V33, P617, DOI 10.1016/S0031-3203(99)00076-X; Salton G., 1989, AUTOMATIC TEXT PROCE; SAVARESI S, 2001, 1 SIAM INT C DAT MIN; SAVARESI S, 2002, 2 SIAM INT C DAT MIN; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Sneath P.H.A., 1973, NUMERICAL TAXONOMY; Steinbach M, 2000, KDD WORKSH TEXT MIN; STREHL A, 2000, P HIPC; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zha H., 2001, CIKM, V3, P4; Zhao Y., 2001, 0140 TR U MINN DEP C; *TREC, 1999, TEXT RETRIEVAL C	47	147	151	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	JUN	2004	55	3					311	331		10.1023/B:MACH.0000027785.44527.d6		21	Computer Science, Artificial Intelligence	Computer Science	820LO	WOS:000221390700004	
S	Lindell, Y; Pinkas, B		Bellare, M		Lindell, Y; Pinkas, B			Privacy preserving data mining	ADVANCES IN CRYPTOLOGY-CRYPTO 2000, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	20th Annual International Cryptology Conference	AUG 20-24, 2000	SANTA BARBARA, CALIFORNIA	Int Assoc Cryptol Res, IEEE Comp Sci, Tech Comm Secur & Privacy, Univ Calif, Comp Sci Dept				In this paper we introduce the concept of privacy preserving data mining. In our model, two parties owning confidential databases wish to run a data mining algorithm on the union of their databases, without revealing any unnecessary information, This problem has many practical and important applications, such as in medical research with confidential patient records. Data mining algorithms are usually complex, especially as the size of the input is measured in megabytes, if not gigabytes. A generic secure multi-party computation solution, based on evaluation of a circuit computing the algorithm on the entire input, is therefore of no practical use. We focus on the problem of decision tree learning and use ID3, a popular and widely used algorithm for this problem. We present a solution that is considerably more efficient than generic solutions. It demands very few rounds of communication and reasonable bandwidth. In our solution, each party performs by itself a computation of the same order as computing the ID3 algorithm for its own database. The results are then combined using efficient cryptographic protocols, whose overhead is only logarithmic in the number of transactions in the databases. We feel that our result is a substantial contribution, demonstrating that secure multi-party computation can be made practical, even for complex problems and large inputs.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel; Hebrew Univ Jerusalem, Sch Comp Sci & Engn, Jerusalem, Israel	Lindell, Y (reprint author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.						BELLARE M, 1990, CRYPTO 89, P547; Ben-Or M., 1988, 20 STOC, P1; Boneh D, 1997, LECT NOTES COMPUT SC, V1294, P425; CANETTI R, 1998, IN PRESS J CRYPTOLOG; Chaum D., 1988, 20 STOC, P11; Chor B., 1995, Proceedings. 36th Annual Symposium on Foundations of Computer Science (Cat. No.95CB35834), DOI 10.1109/SFCS.1995.492461; CRAMER R, 2000, OBLIVIOUS POLYNOMIAL; EVEN S, 1985, COMMUN ACM, V28, P637, DOI 10.1145/3812.3818; Fagin R, 1996, COMMUN ACM, V39, P77, DOI 10.1145/229459.229469; FEIGENBAUM J, 2000, SECURE MULTIPARTY CO; Gilboa N., 1999, LECT NOTES COMPUTER, V1666, P116; Goldreich O., 1998, SECURE MULTIPARTY CO; GOLDREICH O, 1987, 19 ACM S THEOR COMP, P2148; KILIAN J, 1995, USES RANDOMNESS ALGO; Mitchell T. M, 1997, MACHINE LEARNING; NAOR M, 2000, EFFICIENT OBLIVIOUS; Naor M., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301312; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RABIN MO, 1981, TR815 AIK COMP LAB; Yao A., 1986, P 27 IEEE S FDN COMP, P162	21	147	154	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67907-3	LECT NOTES COMPUT SC			2000	1880						36	54				19	Computer Science, Theory & Methods	Computer Science	BS81T	WOS:000171179300003	
J	Ng, RT; Han, JW				Ng, RT; Han, JW			CLARANS: A method for clustering objects for spatial data mining	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						spatial data mining; clustering algorithms; randomized search; computational geometry		Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. To this end, this paper has three main contributions. First, we propose a new clustering method called CLARANS, whose aim is to identify spatial structures that may be present in the data. Experimental results indicate that, when compared with existing clustering methods, CLARANS is very efficient and effective. Second, we investigate how CLARANS can handle not only points objects, but also polygon objects efficiently. One of the methods considered, called the IR-approximation, is very efficient in clustering convex and nonconvex polygon objects. Third, building on top of CLARANS, we develop two spatial data mining algorithms that aim to discover relationships between spatial and nonspatial attributes. Both algorithms can discover knowledge that is difficult to find with existing spatial data mining algorithms.	Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada; Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Ng, RT (reprint author), Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.	rng@cs.ubc.ca					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; Ankerst M, 1999, P ACM SIGMOD INT C M, P49, DOI 10.1145/304182.304187; AREF WG, 1991, PROC INT CONF VERY L, P81; BORGIDA A, 1993, P 1993 ACM SIGMOD IN, P217, DOI 10.1145/170035.170073; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Brinkhoff T., 1993, P ACM SIGMOD INT C M, P237, DOI 10.1145/170035.170075; DOBKIN DP, 1985, J ALGORITHM, V6, P381, DOI 10.1016/0196-6774(85)90007-0; Ester M, 1995, P 4 INT S LARG SPAT, P67; Ester M., 1996, P 2 INT C KNOWL DISC; Gunther O., 1993, Proceedings. Ninth International Conference on Data Engineering (Cat. No.92CH3258-1), DOI 10.1109/ICDE.1993.344078; HAN JW, 1992, PROC INT CONF VERY L, P547; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Ioannidis Y.E., 1987, P ACM SIGMOD INT C M, P9, DOI 10.1145/38713.38722; IOANNIDIS YE, 1990, SIGMOD REC, V19, P312, DOI 10.1145/93597.98740; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Kaufman L., 1990, FINDING GROUPS DATA; KEIM D, 1994, P 10 C DAT ENG; KIRKPATRICK D, 1993, P 9 ACM S COMP GEOM, P133, DOI 10.1145/160985.161009; Lu W., 1993, P FAR E WORKSH GEOGR, P275; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Ng R, 1994, P 20 INT C VER LARG, P144; Piatetsky-Shapiro G., 1991, KNOWLEDGE DISCOVERY; Preparata FP, 1985, COMPUTATIONAL GEOMET; Samet H., 1990, DESIGN ANAL SPATIAL; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Spath H., 1985, CLUSTER DISSECTION A; Thompson D., 1992, FUNDAMENTALS SPATIAL; WANG W, 1997, P 23 C VER LARG DAT, P186; YU Y, 1996, THESIS U BRIT COLUMB; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	33	146	170	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP-OCT	2002	14	5					1003	1016		10.1109/TKDE.2002.1033770		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	589EH	WOS:000177745200006	
J	Han, JW; Pei, J; Yin, YW				Han, JW; Pei, J; Yin, YW			Mining frequent patterns without candidate generation	SIGMOD RECORD			English	Article; Proceedings Paper	International Conference on Management of Data	MAY 16-18, 2000	DALLAS, TEXAS	Assoc Comp Machinery, Special Interest Grp Management Data				Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist prolific patterns and/or long patterns. In this study, we propose a novel frequent pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a highly condensed, much smaller data structure, which avoids costly, repeated database scans, (2) our FP-tree-based mining adopts a pattern fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space. Our performance study shows that the FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent pattern mining methods.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Han, JW (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.						AGARWAL R, 1999, RC21538 IBM; Agarwal R., 2000, J PARALLEL DISTRIBUT; AGRAWAL R, VLDB 94, P487; AGRAWAL R, ICDE 95, P3; BAYARDO RJ, SIGMOD 98, P85; BRIN S, SIGMOD 97, P265; DONG G, KDD 99, P43; GRAHNE G, ICDE 00; HAN J, 1999, 9910 CS S FRAS U; HAN J, ICDE 99, P106; KAMBER M, KDD 97, P207; KLEMETTINE M, CIKM 94, P401; LENT B, ICDE 97, P220; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; NG R, SIGMOD 98, P13; PARK JS, SIGMOD 95, P175; SARAWAGI S, SIGMOD 98, P343; SAVASERE A, VLDB 95, P432; SILVERSTEIN C, VLDB 98, P594; SRIKANT R, KDD 97, P67	20	146	146	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0163-5808		SIGMOD RECORD	Sigmod Rec.	JUN	2000	29	2					1	12				12	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	328UA	WOS:000087867500002	
J	Perkowitz, M; Etzioni, O				Perkowitz, M; Etzioni, O			Towards adaptive Web sites: Conceptual framework and case study	ARTIFICIAL INTELLIGENCE			English	Article						adaptive Web sites; conceptual clustering; data mining		Today's Web sites are intricate but not intelligent; while Web navigation is dynamic and idiosyncratic, all too often Web sites are fossils cast in HTML. In response, this paper investigates adaptive Web sites: sites that automatically improve their organization and presentation by learning from visitor access patterns. Adaptive Web sites mine the data buried in Web server logs to produce more easily navigable Web sites. To demonstrate the feasibility of adaptive Web sites, the paper considers the problem of index page synthesis and sketches a solution that relies on novel clustering and conceptual clustering techniques. Our preliminary experiments show that high-quality candidate index pages can be generated automatically, and that our techniques outperform existing methods (including the Apriori algorithm, K-means clustering, hierarchical agglomerative clustering, and COBWEB) in this domain. (C) 2000 Published by Elsevier Science B.V. All rights reserved.	Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Perkowitz, M (reprint author), Univ Washington, Dept Comp Sci & Engn, Box 352350, Seattle, WA 98195 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 VLDB C; AGRAWAL R, 1996, FAST DISCOVERY ASS R, P307; ANANTHARAMAN T, 1990, ARTIF INTELL, V43, P99, DOI 10.1016/0004-3702(90)90073-9; ANDRE E, 1996, AIA ADAPTIVE COMMUNI; BALABANOVIC M, 1997, FAB CONTENT BASED CO; Cohen W.W., 1995, P 12 INT C MACH LEAR; CUTTING D, 1992, P 15 ANN INT SIGIR92; FERNANDEZ M, 1997, P ACM SIGMOD C MAN D; Fink J., 1996, DESIGNING WEB EMPIRI; FISHER D, 1996, J ARTIFICIAL INTELLI, V4; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; GOOD N, 1999, P AAAI 99 ORL FL; Hanson S. J., 1989, Machine Learning, V3, DOI 10.1007/BF00116838; Joachims T., 1997, P 15 INT JOINT C ART, P770; Khare R., 1997, IEEE Internet Computing, V1, DOI 10.1109/4236.612222; Kleinberg J., 1998, P 9 ACM SIAM S DISCR; Lieberman H., 1995, P 14 INT JOINT C ART, P924; LUKE S, 1997, P 1 INT C AUT AG MAR; MICHALSKI R, 1983, LEARNING OBSERVATION, P331; Mirkin B, 1999, MACH LEARN, V35, P25, DOI 10.1023/A:1007567018844; Mitchell T. M, 1997, MACHINE LEARNING; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PAZZANI M, 1996, P AAAI 96 PORTL OR; Perkowitz M., 1997, P 6 INT WWW C SANT C; PERKOWITZ M, 1997, P IJCAI 97 NAG JAP; PERKOWITZ M, 1998, P AAAI 98 MAD WI; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; Rasmussen E., 1992, INFORMATION RETRIEVA, P419; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Rist T., 1997, P 1997 INT C INT US, P79, DOI 10.1145/238218.238298; ROCCHIO JJ, 1966, THESIS HARVARD U CAM; SAVASERE A, 1995, P 21 VLDB C ZUR SWIT; SEGAL R, 1996, THESIS U WASHINGTON; Shardanand U., 1995, P C HUM FACT COMP SY; Thorpe Charles E, 1990, VISION NAVIGATION CA; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; VOORHEES EM, 1986, INFORM PROCESS MANAG, V22, P465, DOI 10.1016/0306-4573(86)90097-X; WEXELBLAT A, 1997, P C COMP ASS INF RET, P75; WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1; YAN T, 1996, P 5 INT WWW C PAR FR	42	146	159	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	APR	2000	118	1-2					245	275		10.1016/S0004-3702(99)00098-3		31	Computer Science, Artificial Intelligence	Computer Science	308WW	WOS:000086736700007	
B	Shafer, J; Agrawal, R; Mehta, M		Vijayaraman, TM; Buchmann, A; Mohan, C; Sarda, NL		Shafer, J; Agrawal, R; Mehta, M			SPRINT: A scalable parallel classifier for data mining	PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES			English	Proceedings Paper	22nd International Conference on Very Large Data Bases	SEP 03-06, 1996	MUMBAI, INDIA	Comp Soc India, VLDB Endowment India, Akshay Software Technol Ltd, Coromandel Software Ltd, Digital Equipment India Ltd, Fujitsu ICIM Ltd, Ind Dev Bank India, Informix Int Inc, Infosys Technol Ltd, Int Business Machines, Mastek Ltd, Natl Assoc Software & Serv Co, NIIT Ltd, Onward Novell Software India Ltd, Persistent Syst Pvt Ltd, Siemens Informat Syst Ltd, Tata Consultancy Serv, Tata Informat Syst Ltd, Santa Cruz Operat Inc, Unit Trust India, IBM Almaden Res Ctr, US, Indian Inst Technol, Bombay, India, Natl Ctr Soft Technol, Mumbai, India, Onward Technol, Mumbai, India, Persistent Syst Pvt Ltd, Pune, India, Tata Ynisys Ltd, Mumbai, India, Tech Univ, Darmstadt, Germany				Classification is an important data mining problem. Although classification is a well-studied problem, most of the current classification algorithms require that all or a portion of the the entire dataset remain permanently in memory. This limits their suitability for mining over large databases. We present a new decision-tree-based classification algorithm, called SPRINT that removes all of the memory restrictions, and is fast and scalable. The algorithm has also been designed to be easily parallelized, allowing many processors to work together to build a. single consistent model. This parallelization, also presented here, exhibits excellent scalability as well. The combination of these characteristics makes the proposed algorithm an ideal tool for data mining.		Shafer, J (reprint author), IBM CORP,ALMADEN RES CTR,650 HARRY RD,SAN JOSE,CA 95120, USA.							0	146	165	MORGAN KAUFMANN PUB INC	SAN MATEO	2929 CAMPUS DRIVE, SAN MATEO, CA 94403		1-55860-382-4				1996							544	555				12	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	BH34P	WOS:A1996BH34P00049	
S	Cooley, R; Mobasher, B; Srivastava, J			IEEE COMP SOC	Cooley, R; Mobasher, B; Srivastava, J			Web mining: Information and pattern discovery on the World Wide Web	NINTH IEEE INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	9th IEEE International Conference on Tools with Artificial Intelligence	NOV 03-08, 1997	NEWPORT BEACH, CA	IEEE Comp Soc, Tech Comm PAMI, Pan Amer Ctr Earth & Environm Studies				Application of data mining techniques to the World Wide Web, referred to as Web mining, has been the focus of several recent research projects and papers. However, there is no established vocabulary, leading to confusion when comparing research efforts. The term Web mining has been used in two distinct ways. The first, called Web content mining in this paper, is the process of information discovery from sources across the World Wide Web. The second, called Web usage mining, is the process of mining for user browsing and access patterns. In this paper we define Web mining and present an overview of the various research issues, techniques, and development efforts. We briefly describe WEBMINER, a system for Web usage mining, and conclude this paper by listing research issues.		Cooley, R (reprint author), UNIV MINNESOTA,DEPT COMP SCI & ENGN,MINNEAPOLIS,MN 55455, USA.							0	144	165	I E E E, COMPUTER SOC PRESS	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, LOS ALAMITOS, CA 90720	1082-3409	0-8186-8204-3	PROC INT C TOOLS ART			1997							558	567		10.1109/TAI.1997.632303		10	Computer Science, Artificial Intelligence	Computer Science	BJ93L	WOS:A1997BJ93L00075	
S	Lee, W; Stolfo, SJ; Mok, KW			IEEE; IEEE; IEEE; IEEE	Lee, W; Stolfo, SJ; Mok, KW			A data mining framework for building intrusion detection models	PROCEEDINGS OF THE 1999 IEEE SYMPOSIUM ON SECURITY AND PRIVACY	PROCEEDINGS: IEEE SYMPOSIUM ON SECURITY AND PRIVACY		English	Proceedings Paper	1999 IEEE Symposium on Security and Privacy	MAY 09-12, 1999	OAKLAND, CA	IEEE Comp Soc Tech Comm Secur & Privacy, Int Assoc Cryptol Res				There is often the need to update an installed Intrusion Detection System (IDS) due to new attack methods or upgraded computing environments. Since many current IDSs are constructed by manual encoding of expert knowledge, changes to IDSs are expensive and slow. In this paper we describe a data mining framework for adaptively building Intrusion Detection (ID) models. The central idea is to utilize auditing programs to extract an extensive set of features that describe each network connection or host session, and apply data mining programs to learn rules that accurately capture the behavior of intrusions and normal activities. These rules can then be used for misuse detection and anomaly detection. New detection models are incorporated into an existing IDS through a meta-learning (or co-operative learning) process, which produces a meta detection model that combines evidence from multiple models. We discuss the strengths of our data mining programs, namely, classification, meta-learning, association rules, and frequent episodes. We report our results of applying these programs to the extensively gathered network audit data for the 1998 DARPA Intrusion Detection Evaluation Program.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Lee, W (reprint author), Columbia Univ, Dept Comp Sci, 500 W 120th St, New York, NY 10027 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Chan P., 1993, AAAI WORKSH KNOWL DI, V227-240; Cohen W., 1995, MACHINE LEARNING; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; ILGUN K, 1995, IEEE T SOFTWARE ENG, V21, P181, DOI 10.1109/32.372146; Ko C., 1994, Proceedings. 10th Annual Computer Security Applications Conference (Cat. No.94TH8032), DOI 10.1109/CSAC.1994.367313; Kumar S., 1995, P 18 NAT INF SEC C, P194; Lane T., 1997, AI APPROACHES FRAUD, P43; LEE W, 1999, UNPUB MINING DATA FL; Lee Wenke, 1998, P 7 USENIX SEC S SAN; Lunt T, 1993, P 1993 C AUD COMP TE; Lunt T. F, 1992, REAL TIME INTRUSION; Mannila H., 1995, P 1 INT C KNOWL DISC; MANNILA H, 1996, P 2 INT C KNOWL DISC; MUKHERJEE B, 1994, IEEE NETWORK    MAY; PAXON V, 1998, P 7 USENIX SEC S SAN; Porras P A, 1997, NAT INF SYST SEC C B; STAINFORDCHEN S, COMMON INTRUSION DET; Stolfo S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; *N F R INC, 1997, NETW FLIGHT REC; *SUNS, SUNSHIELD BAS SEC MO	21	143	207	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1081-6011	0-7695-0176-1	P IEEE S SECUR PRIV			1999							120	132				13	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BN17U	WOS:000080981000014	
J	Zhu, W				Zhu, William			Topological approaches to covering rough sets	INFORMATION SCIENCES			English	Article						rough set; topology; fuzzy set; granular computing	INCOMPLETE INFORMATION-SYSTEMS; REDUCTION	Rough sets, a tool for data mining, deal with the vagueness and granularity in information systems. This paper studies covering-based rough sets from the topological view. We explore the topological properties of this type of rough sets, study the interdependency between the lower and the upper approximation operations, and establish the conditions under which two coverings generate the same lower approximation operation and the same upper approximation operation. Lastly, axiomatic systems for the lower approximation operation and the upper approximation operation are constructed. (c) 2006 Elsevier Inc. All rights reserved.	Chinese Acad Sci, Inst Automat, Beijing, Peoples R China; Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand; Jiangxi Normal Univ, Comp Informat Engn Coll, Nanchang, Peoples R China	Zhu, W (reprint author), Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.	fzhu009@ec.auckland.ac.nz					Allam AA, 2005, LECT NOTES ARTIF INT, V3641, P64; Angiulli F, 2005, IEEE T KNOWL DATA EN, V17, P203, DOI 10.1109/TKDE.2005.31; Dong GZ, 2004, IEEE T KNOWL DATA EN, V16, P922, DOI 10.1109/TKDE.2004.28; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hu F, 2005, LECT NOTES ARTIF INT, V3641, P185; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1; Kryszkiewicz M, 1999, INFORM SCIENCES, V113, P271, DOI 10.1016/S0020-0255(98)10065-8; Lashin EF, 2005, INT J APPROX REASON, V40, P35, DOI 10.1016/j.ijar.2004.11.007; Lin T. Y., 1994, Rough Sets, Fuzzy Sets and Knowledge Discovery. Proceedings of the International Workshop on Rough Sets and Knowledge Discovery (RSKD'93); LIU WJ, 2004, P 3 INT C MACH LEARN, P26; Pal SK, 2004, IEEE T KNOWL DATA EN, V16, P292, DOI 10.1109/TKDE.2003.1262181; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1991, ROUGH SETS THEORETIC; Polkowski L., 1998, ROUGH SETS KNOWLEDGE, V1; Polkowski L., 1998, ROUGH SETS KNOWLEDGE, V2; Polkowski L., 1998, ROUGH SETS CURRENT T, V1424; Pomykata J., 1987, B POLISH ACAD SCI MA, V35, P653; Skowron A., 1988, B POLISH ACAD SCI MA, V36, P477; Slowinski R, 2000, IEEE T KNOWL DATA EN, V12, P331, DOI 10.1109/69.842271; Su CT, 2005, IEEE T KNOWL DATA EN, V17, P437; Wang F., 1998, INT J INTELLIGENT CO, V2, P211; Wang FY, 2005, INFORM SCIENCES, V171, P233, DOI 10.1016/j.ins.2004.04.005; YAO Y, 1998, INFORM SCI, V101, P239; Yao YY, 1998, INFORM SCIENCES, V109, P21, DOI 10.1016/S0020-0255(98)00012-7; Yao YY, 1996, INT J APPROX REASON, V15, P291, DOI 10.1016/S0888-613X(96)00071-0; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; Zadeh L.A, 1965, FUZZY SETS INFORM CO, V8, P338, DOI DOI 10.1016/S0019-9958(65)90241-X; Zhong N, 2003, IEEE T KNOWL DATA EN, V15, P952; Zhu Feng, 2000, Chinese Journal of Computers, V23; ZHU F, 2000, P 4 INT C HIGH PERF, V2, P670, DOI 10.1109/HPC.2000.843520; ZHU F, 2002, THESIS U ARIZONA TUC; Zhu W., 2006, IEEE GRC 2006, P43; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; ZHU W, 2006, IEEE IS	38	142	168	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	MAR 15	2007	177	6					1499	1508		10.1016/j.ins.2006.06.009		10	Computer Science, Information Systems	Computer Science	134ZO	WOS:000244123600014	
J	Huang, J; Ling, CX				Huang, J; Ling, CX			Using AUC and accuracy in evaluating learning algorithms	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						evaluation of learning algorithms; ROC; AUC of ROC; accuracy	ROC CURVE; AREA	The area under the ROC ( Receiver Operating Characteristics) curve, or simply AUC, has been traditionally used in medical diagnosis since the 1970s. It has recently been proposed as an alternative single-number measure for evaluating the predictive ability of learning algorithms. However, no formal arguments were given as to why AUC should be preferred over accuracy. In this paper, we establish formal criteria for comparing two different measures for learning algorithms and we show theoretically and empirically that AUC is a better measure ( defined precisely) than accuracy. We then reevaluate well-established claims in machine learning based on accuracy using AUC and obtain interesting and surprising new results. For example, it has been well-established and accepted that Naive Bayes and decision trees are very similar in predictive accuracy. We show, however, that Naive Bayes is significantly better than decision trees in AUC. The conclusions drawn in this paper may make a significant impact on machine learning and data mining applications.	Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada	Huang, J (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	jhuang@csd.uwo.ca; cling@csd.uwo.ca					Blake C, 1998, UCI REPOSITORY MACHI; Boser B., 1992, P 5 ANN WORKSH COMP, V21, P144, DOI DOI 10.1145/130385.130401; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang CC, 2003, LIBSVM LIB SUPPORT V; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; Cristianini N., 2000, INTRO SUPPORT VECTOR; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; EGAN JP, 1975, SIGNAL DETECTION THE; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Ferri C., 2002, P 19 INT C MACH LEAR, P139; GREEN DM, 1966, SIGNAL DETECTION THE; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T., 2001, ELEMENTS STAT LEARNI; Hsu C., 2001, COMPARISON METHODS M; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P, 1992, P 10 NAT C ART INT, P223; Ling C. X., 2003, P 18 INT C ART INT I, P329; Lingjaerde O, 1998, ACTA PSYCHIAT SCAND, V98, P73, DOI 10.1111/j.1600-0447.1998.tb10045.x; LINGNER J, 2002, MOL B INT U, V22, P123; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; MEYER D, 2002, BENCKMARKING SUPPORT; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PROVOST F, 2000, 0004IS CDER STERN SC; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Scholkopf B., 2002, LEARNING KERNELS; SMYTH P, 1995, P 12 INT C MACH LEAR, P506; Spackman K.A., 1989, P 6 INT WORKSH MACH, P160; Suykens J.A.K., 1999, P INT JOINT C NEUR N; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Vapnik V. N., 1998, STAT LEARNING THEORY	36	141	150	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2005	17	3					299	310				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	888EY	WOS:000226358200001	
J	Kantarcioglu, M; Clifton, C				Kantarcioglu, M; Clifton, C			Privacy-preserving distributed mining of association rules on horizontally partitioned data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; security; privacy	LOGARITHMS	Data mining can extract important knowledge from large data collections-but sometimes these collections are split among various parties. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. This paper addresses secure mining of association rules over horizontally partitioned data. The methods incorporate cryptographic techniques to minimize the information shared, while adding little overhead to the mining task.	Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Kantarcioglu, M (reprint author), Purdue Univ, Dept Comp Sci, 250 N Univ St, W Lafayette, IN 47907 USA.	kanmurat@cs.purdue.edu; clifton@cs.purdue.edu					Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; Agrawal R., 1994, P 20 INT C VER LARG, P487; BENALOH J, 1993, ADV CRYPTOLOGY, P274; BENALOH JC, 1986, ADV CRYPTOLOGY CRYPT, P251; Cheung DW, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P31, DOI 10.1109/PDIS.1996.568665; Cheung DW, 1996, IEEE T KNOWL DATA EN, V8, P911, DOI 10.1109/69.553158; CHOR B, 1993, INFORM PROCESS LETT, V45, P205, DOI 10.1016/0020-0190(93)90120-X; Clifton C., 2002, P NAT SCI FDN WORKSH, P126; DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638; ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074; Evfimievski A., 2002, P 8 ACM SIGKDD INT C, P217; Goldreich O., 1998, SECURE MULTIPARTY CO; GOLDREICH O, 2003, ENCRYPTION SCHEMES; Huberman B.A., 1999, P ACM C EL COMM EC99, P78, DOI 10.1145/336992.337012; IOANNIDIS I, 2003, P HAW INT C SYST SCI; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; POHLIG SC, 1978, IEEE T INFORM THEORY, V24, P106, DOI 10.1109/TIT.1978.1055817; Reiter M. K., 1998, ACM T INFORM SYST, V1, P66, DOI 10.1145/290163.290168; RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI 10.1145/359340.359342; Rizvi S. J., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; Shamir A., 1979, MITLCSTM125; Vaida J., 2002, P 8 ACM SIGKDD INT C, P639; Yao A., 1986, P 27 IEEE S FDN COMP, P162	24	141	165	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP	2004	16	9					1026	1037		10.1109/TKDE.2004.45		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	839FA	WOS:000222767700001	
J	Zhou, ZH; Liu, XY				Zhou, ZH; Liu, XY			Training cost-sensitive neural networks with methods addressing the class imbalance problem	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						machine learning; data mining; neural networks; cost-sensitive learning; class imbalance learning; sampling; threshold-moving; ensemble learning		This paper studies empirically the effect of sampling and threshold-moving in training cost-sensitive neural networks. Both oversampling and undersampling are considered. These techniques modify the distribution of the training data such that the costs of the examples are conveyed explicitly by the appearances of the examples. Threshold-moving tries to move the output threshold toward inexpensive classes such that examples with higher costs become harder to be misclassified. Moreover, hard-ensemble and soft-ensemble, i.e., the combination of above techniques via hard or soft voting schemes, are also tested. Twenty-one UCI data sets with three types of cost matrices and a real-world cost-sensitive data set are used in the empirical study. The results suggest that cost-sensitive learning with multiclass tasks is more difficult than with two-class tasks, and a higher degree of class imbalance may increase the difficulty. It also reveals that almost all the techniques are effective on two-class tasks, while most are ineffective and even may cause negative effect on multiclass tasks. Overall, threshold-moving and soft-ensemble are relatively good choices in training cost-sensitive neural networks. The empirical study also suggests that some methods that have been believed to be effective in addressing the class imbalance problem may, in fact, only be effective on learning with imbalanced two-class data sets.	Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China; Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhouzh@lamda.nju.edu.cn; liuxy@lamda.nju.edu.cn					Abe N., 2004, P 10 ACM SIGKDD INT, P3, DOI 10.1145/1014052.1014056; BAUER E, 1999, MACH LEARN, V36, P102; BAY SD, 2000, UCI KDD ARCH; Blake C, 1998, UCI REPOSITORY MACHI; Bradford J. P., 1998, P 10 EUR C MACH LEAR, P131; BREFELD U, 2003, P 14 EUR C MACH LEAR, P23; Breiman L, 1984, CLASSIFICATION REGRE; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Dietterich T.G., 2002, HDB BRAIN THEORY NEU; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Drummond C., 2003, ICML 03 WORKSH LEARN; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; Elkan C, 2001, P 17 INT JOINT C ART, P973; Japkowicz N., 2002, Intelligent Data Analysis, V6; Japkowicz N., 2000, AAAI 00 WORKSH LEARN, P10; KNOLL U., 1994, P 8 EUR C MACH LEARN, P383; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Kukar M., 1998, P 13 EUR C ART INT E, P445; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Lawrence S, 1998, LECT NOTES COMPUT SC, V1524, P299; Maloof M, 2003, P ICML 03 WORKSH LEA; Margineantu D., 2000, P 17 INT C MACH LEAR, P583; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F, 2000, AAAI WORKSH LEARN IM, P1; QUINLAN JR, 1998, MINIBOOSTING DECISIO; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; Saitta L., 2000, MACHINE LEARNING TEC; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Ting K., 2000, P 17 INT C MACH LEAR, P983; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Vlachos M., 2002, P 8 ACM SIGKDD INT C, P645; Webb G. I., 1996, PRICAI'96: Topics in Artificial Intelligence. 4th Pacific Rim International Conference on Artificial Intelligence. Proceedings; Weiss G. M., 2004, SIGKDD EXPLORATIONS, V6, P7; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540; [Anonymous], 2000, P 11 EUR C MACH LEAR, P413	39	139	159	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN	2006	18	1					63	77				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	993EU	WOS:000233938200005	
J	Stumme, G; Taouil, R; Bastide, Y; Pasquier, N; Lakhal, L				Stumme, G; Taouil, R; Bastide, Y; Pasquier, N; Lakhal, L			Computing iceberg concept lattices with TITANIC	DATA & KNOWLEDGE ENGINEERING			English	Article						knowledge discovery; database analysis; formal concept analysis; closure systems; lattices; algorithms	FREQUENT CLOSED ITEMSETS; KNOWLEDGE DISCOVERY; ASSOCIATION RULES; FUNCTIONAL-DEPENDENCIES; ALGORITHM; SYSTEMS; DATABASES	We introduce the notion of iceberg concept lattices and show their use in knowledge discovery in databases. Iceberg lattices are a conceptual clustering method, which is well suited for analyzing very large databases. They also serve as a condensed representation of frequent itemsets, as starting point for computing bases of association rules, and as a visualization method for association rules. Iceberg concept lattices are based on the theory of Formal Concept Analysis, a mathematical theory with applications in data analysis, information retrieval, and knowledge discovery. We present a new algorithm called TITANIC for computing (iceberg) concept lattices. It is based on data mining techniques with a level-wise approach. In fact, TITANIC can be used for a more general problem: Computing arbitrary closure systems when the closure operator comes along with a so-called weight function. The use of weight functions for computing closure systems has not been discussed in the literature up to now. Applications providing such a weight function include association rule mining, functional dependencies in databases, conceptual clustering, and ontology engineering. The algorithm is experimentally evaluated and compared with Ganter's Next-Closure algorithm. The evaluation shows an important gain in efficiency, especially for weakly correlated data. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Karlsruhe, Inst Angew Informat & Formale Beschreibungsverfah, D-76128 Karlsruhe, Germany; Inst Natl Rech Informat & Automat Lorraine, LORIA, F-54506 Vandoeuvre Les Nancy, France; Univ Clermont Ferrand, Lab Informat, LIMOS, F-63177 Aubiere, France; Univ Nice, UNSA, CNRS, UPRESA 6070, F-06903 Sophia Antipolis, France; Univ Mediterranee, LIM, CNRS, FRE 2246, F-13288 Marseille 9, France	Stumme, G (reprint author), Univ Karlsruhe, Inst Angew Informat & Formale Beschreibungsverfah, Kaiserstr 12, D-76128 Karlsruhe, Germany.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P478; ARNAULD A, 1668, LOGIQUE ART PENSER C; Bastide I, 2000, LECT NOTES ARTIF INT, V1861, P972; BASTIDE Y, 2000, SIGKDD EXPLORATIONS, V2, P71; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Becker K, 2000, LECT NOTES ARTIF INT, V1937, P352; Carpineto C., 1993, P 10 INT C MACH LEAR, P33; Cole R, 2000, LECT NOTES ARTIF INT, V1867, P438; DICKY H, 1996, OOPSLA, P251; GANTER B, 1991, ORDER, P283; Ganter B., 1999, FORMAL CONCEPT ANAL; Godin R, 1998, THEOR PRACT OBJ SYST, V4, P117; GODIN R, 1994, THEOR COMPUT SCI, V133, P387, DOI 10.1016/0304-3975(94)90195-3; GRUBER T, 1997, INT J HUMAN COMPUTER, V46, P293; Han J., 2000, ACM SIGMOD WORKSH RE, P21; Hereth J, 2000, LECT NOTES ARTIF INT, V1867, P421; Huhtala Y, 1999, COMPUT J, V42, P100, DOI 10.1093/comjnl/42.2.100; KIVINEN J, 1995, THEOR COMPUT SCI, V149, P129, DOI 10.1016/0304-3975(95)00028-U; KRONE M, 1994, PROC INT CONF SOFTW, P49, DOI 10.1109/ICSE.1994.296765; LINDIG C, 1997, CONCEPTS; Lopes S, 2000, LECT NOTES COMPUT SC, V1777, P350; Luxenburger M., 1991, MATH INFORMATIQUE SC, V29, P35; Mackensen K, 1999, QUAL QUANT, V33, P135, DOI 10.1023/A:1004305723553; MADCHE A, 2000, LECT NOTES ARTIF INT, V1937, P189; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4; MINEAU GW, 1995, IEEE T KNOWL DATA EN, V7, P824, DOI 10.1109/69.469834; MISSIKOFF M, 1989, LECT NOTES COMPUT SC, V367, P64; Nourine L, 1999, INFORM PROCESS LETT, V71, P199, DOI 10.1016/S0020-0190(99)00108-8; PASQUIER N, 1998, 14 JOURN BAS DONN AV; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; Scheich P., 1993, INFORMATION CLASSIFI, P72; SCHMITT I, 1998, P 3 IFCIS INT C COOP, P122; Snelling G., 1998, P ACM SIGSOFT S FDN, P99, DOI 10.1145/288195.288273; STRAHRINGER S, 1993, INFORMATION CLASSIFI, P85; Stumme G., 2001, LECT NOTES ARTIF INT, V2174, P335; Stumme G, 1998, LECT NOTES ARTIF INT, V1510, P450; Stumme G., 2000, P 7 INT WORKSH KNOWL; Stumme G., 2001, P 17 INT JOINT C ART, P225; STUMME G, 2000, BEGRIFFLICHE WISSENS; STUMME G, 2001, P GI FACHGR MASCH LE, V763; VOGT F, 1995, LECT NOTES COMPUTER, V894, P226; WAIYAMAI K, 1997, LNCS, V1331, P299; Wille R., 1982, ORDERED SETS, P445; WILLE R, 1984, INT CLASSIF, V11, P77; WILLE R, 1992, COMPUT MATH APPL, V23, P493, DOI 10.1016/0898-1221(92)90120-7; WROBEL S, 2000, HDB KNSTLICHEN INTEL, V3, P517; YAHIA A, 1996, LNCS, V1157, P422	50	138	142	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	AUG	2002	42	2					189	222		10.1016/S0169-023X(02)00057-5		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	561GM	WOS:000176131900002	
J	Ishibuchi, H; Yamamoto, T				Ishibuchi, H; Yamamoto, T			Rule weight specification in fuzzy rule-based classification systems	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						data mining; fuzzy systems; pattern classification; rule generation; rule selection	PATTERN-CLASSIFICATION	This paper shows how the rule weight of each fuzzy rule can be specified in fuzzy rule-based classification systems. First, we propose two heuristic methods for I rule weight specification. Next, the proposed methods are compared with existing ones through computer simulations on artificial numerical examples and real-world pattern classification problems. Simulation results show that the proposed methods outperform the existing ones in the case of multiclass pattern classification problems with many classes.	Osaka Prefecture Univ, Dept Ind Engn, Osaka 5998531, Japan	Ishibuchi, H (reprint author), Osaka Prefecture Univ, Dept Ind Engn, Osaka 5998531, Japan.	hisaoi@cs.osakafu-u.ac.jp	Ishibuchi, Hisao/B-3599-2009	Ishibuchi, Hisao/0000-0001-9186-6472			Abe S, 1997, IEEE T FUZZY SYST, V5, P358, DOI 10.1109/91.618273; Agrawal R., 1994, P 20 INT C VER LARG, P487; Castillo L, 2001, FUZZY SET SYST, V120, P309, DOI 10.1016/S0165-0114(99)00095-0; Cordon O, 1999, INT J APPROX REASON, V20, P21, DOI 10.1016/S0888-613X(00)88942-2; Hong TP, 2001, INT J UNCERTAIN FUZZ, V9, P587, DOI 10.1142/S0218488501001071; Ishibuchi H, 2001, IEEE T FUZZY SYST, V9, P506, DOI 10.1109/91.940964; Ishibuchi H, 1999, FUZZY SET SYST, V103, P223, DOI 10.1016/S0165-0114(98)00223-1; Ishihara H, 2001, PROCEEDINGS OF THE 2000 INTERNATIONAL CONFERENCE ON EXCITONIC PROCESSES IN CONDENSED MATTER, P241, DOI 10.1109/ICDM.2001.989525; ISHIBUCHI H, 1992, FUZZY SET SYST, V52, P21, DOI 10.1016/0165-0114(92)90032-Y; Klawonn F., 1997, P 7 INT FUZZ SYST AS, V1, P193; Nauck D, 1997, FUZZY SET SYST, V89, P277, DOI 10.1016/S0165-0114(97)00009-2; Nauck D. D., 1998, P 7 IEEE INT C FUZZ, P1235; NURNBERGER A, 1999, P 6 INT C NEUR INF P, P154; Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575; van den Berg J, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P991	15	136	140	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	AUG	2005	13	4					428	435		10.1109/TFUZZ.2004.841738		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	954XB	WOS:000231187600002	
J	Ishibuchi, H; Nojima, Y				Ishibuchi, Hisao; Nojima, Yusuke			Analysis of interpretability-accuracy tradeoff of fuzzy systems by multiobjective fuzzy genetics-based machine learning	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article; Proceedings Paper	1st International Workshop on Genetic Fuzzy Systems	MAR 17-19, 2005	Granada, SPAIN			classification; fuzzy systems; fuzzy data mining; multiobjective optimization; genetic algorithms; genetics-based machine learning	PATTERN-CLASSIFICATION PROBLEMS; KNOWLEDGE EXTRACTION; ALGORITHMS; RULES; PERFORMANCE; ATTRIBUTES; COMPLEXITY	This paper examines the interpretability-accuracy tradeoff in fuzzy rule-based classifiers using a multiobjective fuzzy genetics-based machine learning (GBML) algorithm. Our GBML algorithm is a hybrid version of Michigan and Pittsburgh approaches, which is implemented in the framework of evolutionary multiobjective optimization (EMO). Each fuzzy rule is represented by its antecedent fuzzy sets as an integer string of fixed length. Each fuzzy rule-based classifier, which is a set of fuzzy rules, is represented as a concatenated integer string of variable length. Our GBML algorithm simultaneously maximizes the accuracy of rule sets and minimizes their complexity. The accuracy is measured by the number of correctly classified training patterns while the complexity is measured by the number of fuzzy rules and/or the total number of antecedent conditions of fuzzy rules. We examine the in terpretability-accuracy tradeoff for training patterns through computational experiments on some benchmark data sets. A clear tradeoff structure is visualized for each data set. We also examine the interpretabitity-accuracy tradeoff for test patterns. Due to the overfitting to training patterns, a clear tradeoff structure is not always obtained in computational experiments for test patterns. (C) 2006 Elsevier Inc. All rights reserved.	Osaka Prefecture Univ, Grad Sch Engn, Dept Comp Sci & Intelligent Syst, Osaka 5998531, Japan	Ishibuchi, H (reprint author), Osaka Prefecture Univ, Grad Sch Engn, Dept Comp Sci & Intelligent Syst, 1-1 Gakuen Cho, Osaka 5998531, Japan.	hisaoi@cs.osakafu-u.ac.jp	Ishibuchi, Hisao/B-3599-2009; Nojima, Yusuke/F-4832-2010	Ishibuchi, Hisao/0000-0001-9186-6472; 			Casillas J, 2003, ACCURACY IMPROVEMENT; Casillas J., 2003, INTERPRETABILITY ISS; Coello C., 2002, EVOLUTIONARY ALGORIT; Coello C. A. C., 1999, Knowledge and Information Systems, V1; Cordon O, 1999, INT J APPROX REASON, V20, P21, DOI 10.1016/S0888-613X(00)88942-2; Cordon O., 2001, GENETIC FUZZY SYSTEM; Deb K., 2001, MULTIOBJECTIVE OPTIM; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; Elomaa T, 1999, MACH LEARN, V36, P201, DOI 10.1023/A:1007674919412; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; Ishibuchi H, 1999, IEEE T IND ELECTRON, V46, P157; Ishibuchi H, 2001, INFORM SCIENCES, V136, P109, DOI 10.1016/S0020-0255(01)00144-X; Ishibuchi H, 2004, FUZZY SET SYST, V141, P59, DOI 10.1016/S0165-0114(03)00114-3; Ishibuchi H, 2005, IEEE T SYST MAN CY B, V35, P359, DOI 10.1109/TSMCB.2004.842257; Ishibuchi H, 2001, IEEE T FUZZY SYST, V9, P506, DOI 10.1109/91.940964; ISHIBUCHI H, 1994, FUZZY SET SYST, V65, P237, DOI 10.1016/0165-0114(94)90022-1; Ishibuchi H, 1999, FUZZY SET SYST, V103, P223, DOI 10.1016/S0165-0114(98)00223-1; Ishibuchi H, 1999, IEEE T SYST MAN CY B, V29, P601, DOI 10.1109/3477.790443; Ishibuchi H, 2005, IEEE T FUZZY SYST, V13, P428, DOI 10.1109/TFUZZ.2004.841738; ISHIBUCHI H, 2005, P GEN EV COMP C GECC, P787, DOI 10.1145/1068009.1068142; Ishibuchi H, 1997, FUZZY SET SYST, V89, P135, DOI 10.1016/S0165-0114(96)00098-X; ISHIBUCHI H, 2004, ADV APPRAOCHES LINGU; JIMENEZ F, 2001, P INT C EV MULT CRIT, P653; JIN Y, 2004, P 2004 IEEE C EV COM, P1; Jin YC, 1999, IEEE T SYST MAN CY B, V29, P829, DOI 10.1109/3477.809036; Jin YC, 2000, IEEE T FUZZY SYST, V8, P212, DOI 10.1109/91.842154; OLIVEIRA LS, 2005, P 3 INT C EV MULT OP, P592; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575; Van Veldhuizen DA, 2000, EVOL COMPUT, V8, P125; Wang HL, 2005, IEEE T SYST MAN CY C, V35, P143, DOI 10.1109/TSMCC.2004.841910; Wang HL, 2005, FUZZY SET SYST, V149, P149, DOI 10.1016/j.fss.2004.07.013	33	133	133	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X		INT J APPROX REASON	Int. J. Approx. Reasoning	JAN	2007	44	1					4	31		10.1016/j.ijar.2006.01.004		28	Computer Science, Artificial Intelligence	Computer Science	130NY	WOS:000243807500002	
J	Garcia, S; Fernandez, A; Luengo, J; Herrera, F				Garcia, Salvador; Fernandez, Alberto; Luengo, Julian; Herrera, Francisco			Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis of power	INFORMATION SCIENCES			English	Article						Statistical analysis; Computational intelligence; Data mining; Nonparametric statistics; Multiple comparisons procedures; Genetics-based machine learning; Fuzzy classification systems	LEARNING CLASSIFIER SYSTEM; EVOLUTIONARY ALGORITHMS; STATISTICAL COMPARISONS; NEURAL-NETWORKS; BONFERRONI TEST; SIGN TEST; DATA SETS; PERFORMANCE; SELECTION; RANKINGS	Experimental analysis of the performance of a proposed method is a crucial and necessary task in an investigation. In this paper, we focus on the use of nonparametric statistical inference for analyzing the results obtained in an experiment design in the field of computational intelligence. We present a case study which involves a set of techniques in classification tasks and we study a set of nonparametric procedures useful to analyze the behavior of a method with respect to a set of algorithms, such as the framework in which a new proposal is developed. Particularly, we discuss some basic and advanced nonparametric approaches which improve the results offered by the Friedman test in some circumstances. A set of post hoc procedures for multiple comparisons is presented together with the computation of adjusted p-values. We also perform an experimental analysis for comparing their power, with the objective of detecting the advantages and disadvantages of the statistical tests described. We found that some aspects such as the number of algorithms, number of data sets and differences in performance offered by the control method are very influential in the statistical tests studied. Our final goal is to offer a complete guideline for the use of nonparametric statistical procedures for performing multiple comparisons in experimental studies. (C) 2009 Elsevier Inc. All rights reserved.	[Garcia, Salvador] Univ Jaen, Dept Comp Sci, Jaen, Spain; [Fernandez, Alberto; Luengo, Julian; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Garcia, S (reprint author), Univ Jaen, Dept Comp Sci, Jaen, Spain.	sglopez@ujaen.es; alberto@decsai.ugr.es; julianlm@decsai.ugr.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X	Spanish Ministry of Science and Innovation (MICINN) [TIN-200806681-006-01]; Spanish Ministry of Education and Science	This work was supported in part by the Spanish Ministry of Science and Innovation (MICINN) under Project TIN-200806681-006-01. J. Luengo holds a FPU scholarship from Spanish Ministry of Education and Science. The authors are very grateful to the anonymous reviewers for their valuable suggestions and comments to improve the quality of this paper.	Abramowitz M., 1974, HDB MATH FUNCTIONS F; ASUNCION A., 2007, UCI MACHINE LEARNING; Bacardit J, 2007, LECT NOTES ARTIF INT, V4399, P59, DOI 10.1007/978-3-540-71231-2_5; Bacardit J, 2007, LECT NOTES ARTIF INT, V4399, P291, DOI 10.1007/978-3-540-71231-2_20; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Carvalho DR, 2004, INFORM SCIENCES, V163, P13, DOI 10.1016/j.ins.2003.03.013; Chen YX, 2003, IEEE T FUZZY SYST, V11, P716, DOI 10.1109/TFUZZ.2003.819843; Conover WJ, 1999, PRACTICAL NONPARAMET; Daniel W.W., 1990, APPL NONPARAMETRIC S; Alcala-Fdez J, 2009, SOFT COMPUT, V13, P307, DOI 10.1007/s00500-008-0323-y; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DOKSUM K, 1967, ANN MATH STAT, V38, P878, DOI 10.1214/aoms/1177698881; DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330; Engelbrecht A., 2007, COMPUTATIONAL INTELL; Eshelman L., 1991, FDN GENETIC ALGORITH, P265; FINNER H, 1993, J AM STAT ASSOC, V88, P920, DOI 10.2307/2290782; Friedman M., 1937, J AM STAT ASSOC, V32, P674; Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Garcia S, 2009, SOFT COMPUT, V13, P959, DOI 10.1007/s00500-008-0392-y; Garcia S, 2005, J HEURISTICS, V15, P617, DOI 10.1007/s10732-008-9080-4; Garcia S, 2009, INT J PATTERN RECOGN, V23, P1527, DOI 10.1142/S0218001409007727; Garcia S, 2008, J MACH LEARN RES, V9, P2677; Han J., 2005, DATA MINING CONCEPTS; HOCHBERG Y, 1988, BIOMETRIKA, V75, P800, DOI 10.1093/biomet/75.4.800; HODGES JL, 1962, ANN MATH STAT, V33, P482, DOI 10.1214/aoms/1177704575; HOLLAND BS, 1987, BIOMETRICS, V43, P417, DOI 10.2307/2531823; HOLM S, 1979, SCAND J STAT, V6, P65; HOMMEL G, 1988, BIOMETRIKA, V75, P383, DOI 10.1093/biomet/75.2.383; IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904; Ishibuchi H, 2005, IEEE T SYST MAN CY B, V35, P359, DOI 10.1109/TSMCB.2004.842257; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.2307/2280779; Lei Z, 2008, INFORM SCIENCES, V178, P1836, DOI 10.1016/j.ins.2007.11.019; Li JJ, 2008, J STAT PLAN INFER, V138, P1521, DOI 10.1016/j.jspi.2007.04.032; Martinez-Estudillo FJ, 2008, NEUROCOMPUTING, V72, P548, DOI 10.1016/j.neucom.2007.11.019; Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452; Partalas I, 2008, INFORM SCIENCES, V178, P3867, DOI 10.1016/j.ins.2008.05.025; QUADE D, 1979, J AM STAT ASSOC, V74, P680, DOI 10.2307/2286991; RHYNE AL, 1965, TECHNOMETRICS, V7, P293, DOI 10.2307/1266590; Rivas VM, 2004, INFORM SCIENCES, V165, P207, DOI 10.1016/j.ins.2003.09.025; ROM DM, 1990, BIOMETRIKA, V77, P663, DOI 10.1093/biomet/77.3.663; Sheskin D., 2006, HDB PARAMETRIC NONPA; Shilane D, 2008, INFORM SCIENCES, V178, P2870, DOI 10.1016/j.ins.2008.03.007; STEEL RGD, 1959, J AM STAT ASSOC, V54, P767, DOI 10.2307/2282500; Tan P-N, 2006, INTRO DATA MINING; Tsai CJ, 2008, INFORM SCIENCES, V178, P714, DOI 10.1016/j.ins.2007.09.004; Tsumoto S, 2009, INFORM SCIENCES, V179, P1615, DOI 10.1016/j.ins.2008.11.023; Ulas A, 2009, INFORM SCIENCES, V179, P1298, DOI 10.1016/j.ins.2008.12.024; Westfall P.H., 2004, RESAMPLING BASED MUL; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; Wolpert D.H., 2001, P 6 ONL WORLD C SOFT; WRIGHT SP, 1992, BIOMETRICS, V48, P1005, DOI 10.2307/2532694; Yang Y, 2009, MACH LEARN, V74, P39, DOI 10.1007/s10994-008-5083-5; Zar J.H., 1999, BIOSTATISTICAL ANAL	54	131	131	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	MAY 15	2010	180	10			SI		2044	2064		10.1016/j.ins.2009.12.010		21	Computer Science, Information Systems	Computer Science	583VN	WOS:000276708100021	
J	Rauber, A; Merkl, D; Dittenbach, M				Rauber, A; Merkl, D; Dittenbach, M			The growing hierarchical self-organizing map: Exploratory analysis of high-dimensional data	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						data mining; exploratory data analysis; hierarchical clustering; pattern recognition; self-organizing map (SOM)	TEXT RETRIEVAL	The self-organizing map (SOM) is a very popular unsupervised neural-network model for the analysis of high-dimensional input data as in data mining applications. However, at least two limitations have to be noted, which are related to the static architecture of this model as well as to the limited capabilities for the representation of hierarchical relations of the data. With our novel growing hierarchical SOM (GHSOM) presented in this paper, we address both limitations. The GHSOM is an artificial neural-network model with hierarchical architecture composed of independent growing SOMs. The motivation was to provide a model that adapts its architecture during its unsupervised training process according to the particular requirements of the input data. Furthermore, by providing a global orientation of the independently growing maps in the individual layers of the hierarchy, navigation across branches is facilitated. The benefits of this novel neural network are a problem-dependent architecture and the intuitive representation of hierarchical relations in the data. This is especially appealing in explorative data mining applications, allowing the inherent structure of the data to unfold in a highly intuitive fashion.	Vienna Univ Technol, Dept Software Technol & Interact Syst, A-1040 Vienna, Austria	Rauber, A (reprint author), Vienna Univ Technol, Dept Software Technol & Interact Syst, A-1040 Vienna, Austria.						Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732; BAUER HU, 1997, IEEE T NEURAL NETWOR, V8, P226; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Blackmore J., 1993, P IEEE INT C NEUR NE, V1, P450; Dittenbach M., 2001, P 3 WORKSH SELF ORG, P140; Dittenbach M., 2000, P INT JOINT C NEUR N, P15; Fritzke B, 1995, NEURAL PROCESS LETT, V2, P1; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kangas J A, 1990, IEEE Trans Neural Netw, V1, P93, DOI 10.1109/72.80208; Kaski S., 1998, NEURAL COMPUTING SUR, V1, P1; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; Kohonen T., 1989, SELF ORG ASS MEMORY; Kohonen Teuvo, 1995, SELF ORG MAPS; KOIKKALAINEN P, 1995, P ICANN 95 INT C ART, V2, P63; Koikkalainen Pasi, 1990, P INT JOINT C NEUR N, VII, P279; Lin X., 1991, P 14 ANN INT ACM SIG, P262, DOI 10.1145/122860.122887; Merkl D, 1998, NEUROCOMPUTING, V21, P61, DOI 10.1016/S0925-2312(98)00032-0; MERKL D, 1999, P 6 INT C NEUR INF P; MERKL D, 2000, SOFT COMPUTING INFOR, P102; Merkl D., 1997, P WORKSH SELF ORG MA, P106; Miikkulainen R., 1990, Connection Science, V2; RAUBER A, 1999, P INT JOINT C NEUR N; Rauber A., 1999, LECT NOTES COMPUTER, V1677, P302; Roussinov DG, 2001, INFORM PROCESS MANAG, V37, P789, DOI 10.1016/S0306-4573(00)00062-5; Salton G., 1989, AUTOMATIC TEXT PROCE; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Santini S, 1996, IEEE T NEURAL NETWOR, V7, P1415, DOI 10.1109/72.548169; TURTLE HR, 1992, COMPUT J, V35, P279, DOI 10.1093/comjnl/35.3.279; ULTSCH A, 1992, STUDIES CLASSIFICATI, P307	30	128	142	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	NOV	2002	13	6					1331	1341		10.1109/TNN.2002.804221		11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	618JX	WOS:000179415900007	
J	van der Aalst, WMP; Reijers, HA; Weijters, AJMM; van Dongen, BF; de Medeiros, AKA; Song, M; Verbeek, HMW				van der Aalst, W. M. P.; Reijers, H. A.; Weijters, A. J. M. M.; van Dongen, B. F.; de Medeiros, A. K. Alves; Song, M.; Verbeek, H. M. W.			Business process mining: An industrial application	INFORMATION SYSTEMS			English	Article						process mining; social network analysis; workflow management; business process management; business process analysis; data mining; Petri nets	WORKFLOW; MODELS; MANAGEMENT; SYSTEMS; LOGS	Contemporary information systems (e.g., WfM, ERP, CRM, SCM, and B2B systems) record business events in so-called event logs. Business process mining takes these logs to discover process, control, data, organizational, and social structures. Although many researchers are developing new and more powerful process mining techniques and software vendors are incorporating these in their software, few of the more advanced process mining techniques have been tested on real-life processes. This paper describes the application of process mining in one of the provincial offices of the Dutch National Public Works Department, responsible for the construction and maintenance of the road and water infrastructure. Using a variety of process mining techniques, we analyzed the processing of invoices sent by the various subcontractors and suppliers from three different perspectives: (1) the process perspective, (2) the organizational perspective, and (3) the case perspective. For this purpose, we used some of the tools developed in the context of the ProM framework. The goal of this paper is to demonstrate the applicability of process mining in general and our algorithms and tools in particular. (c) 2006 Elsevier B.V. All rights reserved.	Eindhoven Univ Technol, Dept Technol Management, NL-5600 MB Eindhoven, Netherlands; Pohang Univ Sci & Technol, Dept Ind Engn, Pohang 790784, South Korea	van der Aalst, WMP (reprint author), Eindhoven Univ Technol, Dept Technol Management, POB 513, NL-5600 MB Eindhoven, Netherlands.	w.m.p.v.d.aalst@tm.tue.nl	Song, Minseok/E-9070-2010; weijters, ton/D-1779-2010; van Dongen, Boudewijn/C-2133-2011; van der Aalst, Wil/G-1248-2011	van der Aalst, Wil/0000-0002-0955-6940			Agrawal R., 1998, 6 INT C EXT DAT TECH, P469; ARKIN A, 2005, SERVICES BUSINESS PR; ATHENA P, 2002, FLOWER USER MANUAL; Begole J. B., 2002, P 2002 ACM C COMP SU, P334; BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; FARNHAM S, 2004, P CSCW04 WORKSH SOC; FARNHAM S, 2004, P 37 ANN HAW INT C S; Fisher D., 2004, P C HUM FACT COMP SY, P551, DOI 10.1145/985692.985762; Grigori D, 2004, COMPUT IND, V53, P321, DOI 10.1016/j.compind.2003.10.007; Grigori D., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Hammer M., 1993, REENGINEERING CORPOR; Herbst J, 2000, LECT NOTES ARTIF INT, V1810, P183; Hoffman T., 2004, COMPUTER WORLD, V38, P14; Jablonski S., 1996, WORKFLOW MANAGEMENT; KAVANTZAS N, 2004, WEB SERVICES CHOREOG; KELLER G, 1998, SAP R3 PROCESS ORIEN; Lawrence Peter, 1997, WORKFLOW HDB 1997; Leymann F., 1999, PRODUCTION WORKFLOW; Moreno Jacob L., 1934, WHO SHALL SURVIVE NE; Nardi BA, 2002, COMMUN ACM, V45, P89, DOI 10.1145/505248.505251; Nemati H., 2003, ORG DATA MINING LEVE; Ogata H., 2001, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V10, DOI 10.1023/A:1011216431296; Van Der Aalst W. M. P., 2005, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V14, DOI 10.1007/s10606-005-9005-9; Reijers HA, 2005, INT J INFORM MANAGE, V25, P458, DOI 10.1016/j.ijinfomgt.2005.06.008; Reisig W., 1998, LECT NOTES COMPUTER, V1491; Rinderle S, 2004, DATA KNOWL ENG, V50, P9, DOI 10.1016/j.datak.2004.01.002; Rosemann M., 2000, P 33 HAW INT C SYST, P1; Sayal M., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; Scott J., 1992, SOCIAL NETWORK ANAL; TIBCO, 2005, TIBCO STAFFW PROC MO; van der Aalst W. M. P., 2002, WORKFLOW MANAGEMENT; van Dongen B.F., 2005, P CAISE 05 WORKSH EM, P309; van der Aalst W, 2004, IEEE T KNOWL DATA EN, V16, P1128, DOI 10.1109/TKDE.2004.47; VANDERAALST WMP, 2004, PROCESS MIN SPECIAL, V53; van der Aalst WMP, 2003, DATA KNOWL ENG, V47, P237, DOI 10.1016/S0169-023X(03)00066-1; van der Aalst WMP, 2002, LECT NOTES COMPUT SC, V2480, P45; van der Aalst WMP, 2004, LECT NOTES COMPUT SC, V3080, P244; van Dongen BF, 2005, LECT NOTES COMPUT SC, V3536, P444; Wasserman S, 1994, SOCIAL NETWORK ANAL; Weijters A. J. M. M., 2002, P ECAI WORKSH KNOWL, P78; Weijters AJMM, 2003, INTEGR COMPUT-AID E, V10, P151; *IDS SCHEER, 2002, ARIS PROC PERF MAN M	43	127	127	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	JUL	2007	32	5					713	732		10.1016/j.is.2006.05.003		20	Computer Science, Information Systems	Computer Science	169NF	WOS:000246598200005	
J	Kaski, S; Honkela, T; Lagus, K; Kohonen, T				Kaski, S; Honkela, T; Lagus, K; Kohonen, T			WEBSOM - Self-organizing maps of document collections	NEUROCOMPUTING			English	Article						data mining; information retrieval; self-organizig map; SOM; WEBSOM	INFORMATION-RETRIEVAL	With the WEBSOM method a textual document collection may be organized onto a graphical map display that provides an overview of the collection and facilitates interactive browsing. Interesting documents can be located on the map using a content-directed search. Each document is encoded as a histogram of word categories which are formed by the self-organizing map (SOM) algorithm based on the similarities in the contexts of the words. The encoded documents an organized on another self-organizing map, a document map, on which nearby locations contain similar documents. Special consideration is given to the computation of very large document maps which is possible with general-purpose computers if the dimensionality of the word category histograms is first reduced with a random mapping method and if computationally efficient algorithms are used in computing the SOMs. (C) 1998 Elsevier Science B.V. All rights reserved.	Helsinki Univ Technol, Neural Networks Res Ctr, FIN-02015 Helsinki, Finland	Kaski, S (reprint author), Helsinki Univ Technol, Neural Networks Res Ctr, POB 2200, FIN-02015 Helsinki, Finland.						Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; Chen HC, 1996, J VIS COMMUN IMAGE R, V7, P88, DOI 10.1006/jvci.1996.0008; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; FINCH S, 1992, ARTIFICIAL NEURAL NE, V2, P1365; GALLANT SI, 1992, ACM SIGIR FORUM, V26, P34, DOI 10.1145/146565.146569; HONKELA T, 1996, P INT C NEUR NETW IC, P56; Honkela T., 1997, P WSOM 97 WORKSH SEL, P310; HONKELA T, 1995, P ICANN 95 INT C ART, V2, P3; Honkela T., 1998, Classification, Data Analysis, and Data Highways. Proceedings of the 21st Annual Conference of the Gesellschaft fur Klassifikation e.V; HONKELA TK, 1996, A32 HELS U TECHN LAB; Hyotyniemi H., 1996, P FINN ART INT C GEN, P64; Kaski S, 1997, NEURAL PROCESS LETT, V5, P139; Kaski S., 1997, ACTA POLYTECHNICA SC, V82; Kaski S., 1998, P IJCNN 98 INT JOINT, V1, P413; KASKI S, 1996, P WCNN 96 WORLD C NE, P814; KOHONEN T, 1996, A33 HELS U TECHN LAB; Kohonen T., 1997, SELF ORG MAPS; Kohonen T., 1996, LECT NOTES COMPUTER, V1112, P269; KOHONEN T, 1997, P ICNN 97 INT C NEUR, pPL1; LAGUS K, 1996, P WWW5 5 INT WORLD W, P71; LAGUS K, 1996, P 2 INT C KNOWL DISC, P238; LAGUS K, 1996, P STEP 96 FINN ART I, P73; LAGUS K, 1997, P WSOM 97 WORKSH SEL, P368; Lesteven S., 1996, VISTAS ASTRON, V40, P395, DOI 10.1016/S0083-6656(96)90140-3; Lin X., 1991, P 14 ANN INT ACM SIG, P262, DOI 10.1145/122860.122887; Lin X, 1997, J AM SOC INFORM SCI, V48, P40, DOI 10.1002/(SICI)1097-4571(199701)48:1<40::AID-ASI6>3.0.CO;2-1; Lin X., 1992, Proceedings. Visualization '92 (Cat. No.92CH3201-1), DOI 10.1109/VISUAL.1992.235198; MERKL D, 1997, P WSOM 97 WORKSH SEL, P316; MERKL D, 1994, THESIS U WIEN; MERKL D, 1994, P ICNN 94 INT C NEUR, P3905; MERKL D, 1995, P ICNN 95 IEEE INT C, V2, P1086, DOI 10.1109/ICNN.1995.487573; Merkl D., 1995, P ICANN 95 INT C ART, VII, P239; MERKL D, 1993, P IJCNN 93 NAG INT J, V3, P2468, DOI 10.1109/IJCNN.1993.714224; Miikkulainen R., 1993, SUBSYMBOLIC NATURAL; Poincot P, 1998, ASTRON ASTROPHYS SUP, V130, P183, DOI 10.1051/aas:1998220; RITTER H, 1990, P IJCNN 90 WASH DC I, V1, P23; RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171; SALTON G, 1983, INTRO MODERN INFORMA; SCHOLTES J, 1993, THESIS U AMSTERDAM A; Zavrel J, 1996, ARTIF INTELL REV, V10, P477, DOI 10.1007/BF00130695	40	126	127	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	OCT	1998	21	1-3					101	117		10.1016/S0925-2312(98)00039-3		17	Computer Science, Artificial Intelligence	Computer Science	145TL	WOS:000077387400009	
J	Shaw, MJ; Subramaniam, C; Tan, GW; Welge, ME				Shaw, MJ; Subramaniam, C; Tan, GW; Welge, ME			Knowledge management and data mining for marketing	DECISION SUPPORT SYSTEMS			English	Article						data mining; knowledge management; marketing decision support; customer relationship management	DECISION-SUPPORT; DATABASES; DISCOVERY	Due to the proliferation of information systems and technology, businesses increasingly have the capability to accumulate huge amounts of customer data in large databases. However, much of the useful marketing insights into customer characteristics and their purchase patterns are largely hidden and untapped. Current emphasis on customer relationship management makes the marketing function an ideal application area to greatly benefit from the use of data mining tools for decision support. A systematic methodology that uses data mining and knowledge management techniques is proposed to manage the marketing knowledge and support marketing decisions. This methodology can be the basis for enhancing customer relationship management. (C) 2001 Elsevier Science B.V. All rights reserved.	Univ Illinois, Beckman Inst, Urbana, IL 61801 USA; Univ Illinois, NCSA, Urbana, IL 61801 USA; Univ Illinois, Dept Business Adm, Urbana, IL 61801 USA	Shaw, MJ (reprint author), Univ Illinois, Beckman Inst, Room 2051,405 N Mathews Ave, Urbana, IL 61801 USA.		Wang, Charles/B-5565-2011				AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AMIDON DM, 1998, J KNOWLEDGE MANAGEME, V2, P23, DOI 10.1108/13673279810800753; Berry M. R. J., 1997, DATA MINING TECHNIQU; Bigus J. P., 1996, DATA MINING NEURAL N; Blattberg R., 1991, SLOAN MANAGEMENT FAL, P5; CHAN KCC, 1991, KNOWLEDGE DISCOVERY, pCH6; EICK SG, 1993, VISUALIZATION 93, PROCEEDINGS, P204; FAYYAD UM, 1996, ADV KNOWLEDGE DISCOV, pCH1; FRAWLEY WJ, 1992, AI MAG, V13, P57; GRAEN M, 1999, COMMUNICATION; HAN J, 1992, P 18 VLDB C; HOLSAPPLE CW, 1993, DECIS SUPPORT SYST, V10, P85, DOI 10.1016/0167-9236(93)90032-X; HOLSHEIMER M, 1996, ADV KNOWLEDGE DISCOV, pCH18; HOLTZ H, 1992, DATABASED MARKETING; HSU CN, 1996, ADV KNOWLEDGE DISCOV, pCH17; Inmon W.H., 1996, BUILDING DATA WAREHO; Keim DA, 1996, IEEE T KNOWL DATA EN, V8, P923, DOI 10.1109/69.553159; KELLY S, 1996, DATA WAREHOUSING ROU; Lee G., 1999, J MANAGE INFORM SYST, P63; Lin FR, 1997, ANN OPER RES, V75, P105, DOI 10.1023/A:1018999110972; MTHEUS CJ, 1996, ADV KNOWLEDGE DISCOV, pCH20; Peppers D, 1999, HARVARD BUS REV, V77, P151; PEPPERS D, 1997, ENTERPRISE 1 1 TOOLS; PIATETSKYSHAPIRO G, 1992, INT J INTELL SYST, V7, P675, DOI 10.1002/int.4550070708; RUMIZEN MC, 1998, J KNOWLEDGE MANAGEME, V2, P77, DOI 10.1108/EUM0000000004609; SHAW MJ, 1993, DECIS SUPPORT SYST, V10, P79, DOI 10.1016/0167-9236(93)90031-W; Spangler W. E., 1999, Journal of Management Information Systems, V16; ZIARKO W, 1991, KNOWLEDGE DISCOVERY, pCH11	28	124	133	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	MAY	2001	31	1			SI		127	137		10.1016/S0167-9236(00)00123-8		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	417LL	WOS:000167836400009	
J	Silverstein, C; Brin, S; Motwani, R				Silverstein, C; Brin, S; Motwani, R			Beyond market baskets: Generalizing association rules to dependence rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; market basket; association rules; dependence rules; closure properties; text mining		One of the more well-studied problems in data mining is the search for association rules in market basket data. Association rules are intended to identify patterns of the type: "A customer purchasing item A often also purchases item B." Motivated partly by the goal of generalizing beyond market basket data and partly by the goal of ironing out some problems in the definition of association rules, we develop the notion of dependence rules that identify statistical dependence in both the presence and absence of items in itemsets. We propose measuring significance of dependence via the chi-squared test for independence from classical statistics. This leads to a measure that is upward-closed in the itemset lattice, enabling us to reduce the mining problem to the search for a border between dependent and independent itemsets in the lattice. We develop pruning strategies based on the closure property and thereby devise an efficient algorithm for discovering dependence rules. We demonstrate our algorithm's effectiveness by testing it on census data, text data (wherein we seek term dependence), and synthetic data.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Silverstein, C (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	csilvers@cs.stanford.edu; brin@cs.stanford.edu; motwani@cs.stanford.edu					Agrawal R., 1996, P 2 INT C KNOWL DISC; AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 1996, P ADV KNOWL DISC DAT, P307; Agresti A., 1992, STAT SCI, V7, P131, DOI DOI 10.1214/SS/1177011454; DELAPLACE PS, 1878, OEUVRES COMPLETES LA; DEMOIAVRE A, 1933, MISCELLANEA ANAL S; DIETZFELBINGER M, 1988, P 29 IEEE S FDN COMP, P524, DOI 10.1109/SFCS.1988.21968; EWALD R, 1994, 3 INT C INF KNOWL MA; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FREDMAN ML, 1984, J ACM, V31, P538, DOI 10.1145/828.1884; FUKUDA T, 1996, P 15 ACM S PRINC DAT; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; GUNOPULOS D, 1997, INPRESS P 6 INT C DA; Han J, 1995, P 21 INT C VER LARG, P420; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Lancaster H. O, 1969, CHISQUARED DISTRIBUT; MANNILA H, 1994, P AAAI WORKSH KNOWL, P144; Moore D. S., 1986, GOODNESS FIT TECHNIQ, P63; MOSTELLER F, 1964, INFERENCE DISPUTED A; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897; Piatetsky G., 1991, KNOWLEDGE DISCOVERY; Savasere A, 1995, P 21 INT C VER LARG, P432; Srikant R., 1995, P 21 INT C VER LARG, P407; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134	27	124	127	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	1998	2	1					39	68		10.1023/A:1009713703947		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZZ733	WOS:000074761700003	
J	Zhang, T; Ramakrishnan, R; Livny, M				Zhang, T; Ramakrishnan, R; Livny, M			BIRCH: A new data clustering algorithm and its applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						very large databases; data clustering; incremental algorithm; data classification and compression	MODELS	Data clustering is an important technique for exploratory data analysis, and has been studied for several years. It has been shown to be useful in many practical domains such as data classification and image processing. Recently, there has been a growing emphasis on exploratory analysis of very large datasets to discover useful patterns and/or correlations among attributes. This is called data mining, and data clustering is regarded as a particular branch. However existing data clustering methods do not adequately address the problem of processing large datasets with a limited amount of resources (e.g., memory and cpu cycles). So as the dataset size increases, they do not scale up well in terms of memory requirement, running time, and result quality. In this paper, an efficient and scalable data clustering method is proposed, based on a new in-memory data structure called CF-tree, which serves as an in-memory summary of the data distribution. We have implemented it in a system called BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and studied its performance extensively in terms of memory requirements, running time, clustering quality, stability and scalability; we also compare it with other available methods. Finally, BIRCH is applied to solve two real-life problems: one is building an iterative and interactive pixel classification tool, and the other is generating the initial codebook for image compression.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	Zhang, T (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.	zhang@cs.wisc.edu; raghu@cs.wisc.edu; miron@cs.wisc.edu					BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; CHEESEMAN P, 1988, P 5 INT C MACH LEARN; CHENG M, 1995, P IS T SPIE C VIS DA; DUBES R, 1980, ADV COMPUTERS, V19; Duda R., 1973, PATTERN CLASSIFICATI; ESTER M, 1995, P 4 INT S LARG SPAT; FEIGENBAUM EA, 1984, COGNITIVE SCI, V8, P305, DOI 10.1207/s15516709cog0804_1; FISHER D, 1987, MACHINE LEARNING, V2; FISHER DH, 1995, CS9501 VAND U DEP CO; GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5; Gersho A., 1992, VECTOR QUANTIZATION; Guttman A., 1984, P ACM SIGMOD INT C M, P47; Hartigan J. A., 1979, APPL STAT, V28; HUANG C, 1992, IEEE T IMAGE PROCESS, V1; Kaufman L., 1990, WILEY SERIES PROBABI; Kou W., 1995, DIGITAL IMAGE COMPRE; KUCHARIK CJ, 1996, UNPUB J GEOPHYSICAL; KUCHARIK CJ, 1996, P 22 C AGR FOR MET A; LEBOWITZ M, 1987, EXPT INCREMENTAL CON; Lee RCT, 1981, ADV INFORMATION SYST, V8, P169; Linde Y., 1980, IEEE T COMMUNICATION, V28; MURTAGH F, 1983, COMPUTER J; NG RT, 1994, P VLDB; Olson C.F., 1993, PARALLEL ALGORITHMS; Rabbani M., 1991, DIGITAL IMAGE COMPRE; Xu X., 1995, P 1 INT C KNOWL DISC; ZHANG T, 1996, THESIS U WISCONSIN M; ZHANG T, 1995, BIRCH EFFICIENT DATA	28	124	130	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	2					141	182		10.1023/A:1009783824328		42	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA828	WOS:000072406100002	
J	Menzies, T; Greenwald, J; Frank, A				Menzies, Tim; Greenwald, Jeremy; Frank, Art			Data mining static code attributes to learn defect predictors	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						data mining detect prediction; McCabe; Halstead; artifical intelligence; empirical; naive Bayes	SELECTION	The value of using static code attributes to learn defect predictors has been widely debated. Prior work has explored issues like the merits of "McCabes versus Halstead versus lines of code counts" for generating defect predictors. We show here that such debates are irrelevant since how the attributes are used to build predictors is much more important than which particular attributes are used. Also, contrary to prior pessimism, we show that such defect predictors are demonstrably useful and, on the data studied here, yield predictors with a mean probability of detection of 71 percent and mean false alarms rates of 25 percent. These predictors would be useful for prioritizing a resource-bound exploration of code that has yet to be inspected.	W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA; Portland State Univ, Dept Comp Sci, Portland, OR 97207 USA	Menzies, T (reprint author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.	tim@menzies.us; jegreen@cecs.pdx.edu; arf@cs.pdx.edu					ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; BASILI V, 2002, P 24 INT C SOFTW ENG; Blake C, 1998, UCI REPOSITORY MACHI; BOUCKAERT R, 2003, P INT C MACH LEARN I; CHAPMAN M, 2002, P NASA SOFTW ASS S; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; FAGAN M, 1986, IEEE T SOFTWARE  JUL, P744; FAGAN ME, 1976, IBM SYSTEMS J, V15; FENTON N, 2000, IEEE T SOFTWARE ENG, P797; FENTON NE, 1995, SOFTWARE METRICS RIG; Fenton N.E., 1997, SOFTWARE METRICS RIG; Fisher D, 1992, P 9 INT C MACH LEARN; Goldberg D.E., 1989, GENETIC ALGORITHMS S; HALL G, 2000, J SYST SOFTWARE, P111; Hall M., 1998, THESIS U WAIKATO HAM; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Halstead M., 1977, ELEMENTS SOFTWARE SC; HEEGER D, 1998, SIGNAL DETECTION THE; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Khoshgoftaar T. M., 2001, Proceedings 12th International Symposium on Software Reliability Engineering, DOI 10.1109/ISSRE.2001.989459; KHOSHGOFTAAR TM, 2001, RECENT ADV RELIABILI, P247; Khoshgoftaar TM, 2003, EMPIR SOFTW ENG, V8, P255, DOI 10.1023/A:1024424811345; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kononenko I, 1994, P EUR C MACH LEARN, P171; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; MENZIES T, 2003, P 2004 IEEE C HIGH A; MENZIES T, 2002, P 27 NASA SEL WORKSH; Menzies T, 2003, IEEE INTELL SYST, V18, P18, DOI 10.1109/MIS.2003.1200723; MENZIES T, 2004, P INT WORKSH MIN SOF; MENZIES T, 2003, P IEEE SOFTW METR S; MENZIES T, 2002, P IEEE AUT SOFTW ENG; Menzies T., P WORKSH PRED SOFTW; NAGAPPAN N, 2005, P INT C SOFTW ENG; Nagappan N, 2005, PROC INT CONF SOFTW, P580, DOI 10.1145/1062455.1062558; Nikora A. P., 2003, P 9 INT SOFTW METR S; PORTER AA, 1990, IEEE SOFTWARE    MAR, P46; Quinlan R., 1992, C4 5 PROGRAMS MACHIN; Rakitin S.R., 2001, SOFTWARE VERIFICATIO; Rumellart D.E., 1986, NATURE, P533; SHEPPERD M, 1994, J SYST SOFTWARE, V26, P197, DOI 10.1016/0164-1212(94)90011-6; Shull F., 2002, Proceedings Eighth IEEE Symposium on Software Metrics, DOI 10.1109/METRIC.2002.1011343; Shull F, 2000, COMPUTER, V33, P73, DOI 10.1109/2.869376; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Tang W, 2004, PROC INT C TOOLS ART, P373; TIAN J, 1995, IEEE T SOFTWARE ENG, V21, P641, DOI 10.1109/32.403788; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Witten I. H., 2005, DATA MINING	47	123	130	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	JAN	2007	33	1					2	13		10.1109/TSE.2007.256941		12	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	109ML	WOS:000242312200001	
J	Warmuth, MK; Liao, J; Ratsch, G; Mathieson, M; Putta, S; Lemmen, C				Warmuth, MK; Liao, J; Ratsch, G; Mathieson, M; Putta, S; Lemmen, C			Active learning with support vector machines in the drug discovery process	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article; Proceedings Paper	6th International Conference on Chemical Structures	JUN, 2002	NOORDWIJKERHOUT, NETHERLANDS	Amer Chem Soc, Div Chem Informat, Chem Struct Assoc Trust, Soc German Chemists, Chem Informat Comp Div, Chem Soc Japan, Div Chem Informat & Comp Sci, Swiss Chem Soc, Royal Netherlands Chem Soc, Royal Soc Chem, Chem Informat Grp			LIBRARY	We investigate the following data mining problem from computer-aided drug design: From a large collection of compounds, find those that bind to a target molecule in as few iterations of biochemical testing as possible. In each iteration a comparatively small batch of compounds is screened for binding activity toward this target. We employed the so-called "active learning paradigm" from Machine Learning for selecting the successive batches. Our main selection strategy is based on the maximum margin hyperplane-generated by "Support Vector Machines". This hyperplane separates the current set of active from the inactive compounds and has the largest possible distance from any labeled compound. We perform a thorough comparative study of various other selection strategies on data sets provided by DuPont Pharmaceuticals and show that the strategies based on the maximum margin hyperplane clearly outperform the simpler ones.	Univ Calif Santa Cruz, Dept Comp Sci, Santa Cruz, CA 95064 USA; Australian Natl Univ, RSISE, Canberra, ACT 0200, Australia; Rational Discovery LLC, Palo Alto, CA 94301 USA; BioSolveIT GMBH, D-53757 St Augustin, Germany	Warmuth, MK (reprint author), Univ Calif Santa Cruz, Dept Comp Sci, Santa Cruz, CA 95064 USA.						Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; Atlas L., 1990, ADV NEURAL INFORMATI, V2, P566; Bachrach R, 1999, LECT NOTES ARTIF INT, V1572, P34; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; BURBIDGE R, 2001, COMPUT CHEM, V26, P4; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CAMPBELL C, 2000, P ICML2000 STANF CA, P8; COHN DA, 1995, ADV NEURAL INFORM PR, V7, P705; Eksterowicz JE, 2002, J MOL GRAPH MODEL, V20, P469, DOI 10.1016/S1093-3263(01)00148-6; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; LEMMEN C, 2000, P 13 EUR S QSAR RAT; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; MYERS PL, 1997, TODAYS CHEM WORK, V6, P46; Putta S, 2002, J CHEM INF COMP SCI, V42, P1230, DOI 10.1021/ci0255026; RATSCH G, 2002, MACH LEARN, V48, P193; Saunders J, 1997, GENET ENG NEWS, V17, P35; Scholkopf B., 2002, LEARNING KERNELS; Sollich P., 1995, ADV NEURAL INFORMATI, V7, P287; TONG S, 2000, P 7 INT C MACH LEARN; Vapnik V.N., 1995, NATURE STAT LEARNING; Warmuth MK, 2002, ADV NEUR IN, V14, P1449; WESTON J, 2002, UNPUB BIOINF	22	122	127	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	MAR-APR	2003	43	2					667	673		10.1021/ci025620t		7	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	661KF	WOS:000181889200043	
J	Zhou, ZH; Li, M				Zhou, ZH; Li, M			Tri-training: Exploiting unlabeled data using three classifiers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; machine learning; learning from unlabeled data; semi-supervised learning; co-training; tri-training; Web page classification	EM	In many practical data mining applications, such as Web page classification, unlabeled training examples are readily available, but labeled ones are fairly expensive to obtain. Therefore, semi-supervised learning algorithms such as co-training have attracted much attention. In this paper, a new co-training style semi-supervised learning algorithm, named tri-training, is proposed. This algorithm generates three classifiers from the original labeled example set. These classifiers are then refined using unlabeled examples in the tri-training process. In detail, in each round of tri-training, an unlabeled example is labeled for a classifier if the other two classifiers agree on the labeling, under certain conditions. Since tri-training neither requires the instance space to be described with sufficient and redundant views nor does it put any constraints on the supervised learning algorithm, its applicability is broader than that of previous co-training style algorithms. Experiments on UCl data sets and application to the Web page classification task indicate that tri-training can effectively exploit unlabeled data to enhance the learning performance.	Nanjing Univ, Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhouzh@lamda.nju.edu.cn; lim@lamda.nju.edu.cn					Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116829; Bennett K. P., 2002, P 8 ACM SIGKDD INT C, P289; Blake C, 1998, UCI REPOSITORY MACHI; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Blum A., 2001, P 18 INT C MACH LEAR, P19; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Collins M., 1999, P JOINT SIGDAT C EMP, P100; d'Alche-Buc F, 2002, ADV NEUR IN, V14, P553; Dasgupta S, 2002, ADV NEUR IN, V14, P375; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DIETTERICH T, 2000, LECT NOTES COMPUTER, V1867, P1; Efron B., 1993, INTRO BOOTSTRAP; Goldman S., 2000, P 17 INT C MACH LEAR, P327; HWA R, 2003, ICML 03 WORKSH CONT; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Miller DJ, 1997, ADV NEUR IN, V9, P571; Muhlenbach F, 2004, J INTELL INF SYST, V22, P89, DOI 10.1023/A:1025832930864; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354805; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pierce D, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; QUINLAN JR, 1998, MINIBOOSTING DECISIO; Riloff E., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Sarkar BK, 2001, B MATER SCI, V24, P95, DOI 10.1007/BF02710081; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; Steedman M., 2003, P 11 C EUR CHAPT ASS, P331; Witten IH, 2000, DATA MINING PRACTICA; Yarowsky D., 1995, P 33 ANN M ASS COMP, P189, DOI 10.3115/981658.981684	29	120	173	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2005	17	11					1529	1541				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	964OV	WOS:000231891300007	
J	Zimmermann, T; Weissgerber, P; Diehl, S; Zeller, A				Zimmermann, T; Weissgerber, P; Diehl, S; Zeller, A			Mining version histories to guide software changes	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article; Proceedings Paper	Workshop on Mining Software Repositories held in conjunction with the 27th International Conference on Software Engineering (ICSE)	MAY   17, 2005	St Louis, MO			programming environments/construction tools; distribution; maintenance; enhancement; configuration management; clustering; classification; association rules; data mining		We apply data mining to version histories in order to guide programmers along related changes: "Programmers who changed these functions also changed...." Given a set of existing changes, the mined association rules 1) suggest and predict likely further changes, 2) show up item coupling that is undetectable by program analysis, and 3) can prevent errors due to incomplete changes. After an initial change, our ROSE prototype can correctly predict further locations to be changed; the best predictive power is obtained for changes to existing software. In our evaluation based on the history of eight popular open source projects, ROSE's topmost three suggestions contained a correct location with a likelihood of more than 70 percent.	Univ Saarland, Dept Comp Sci, D-66041 Saarbrucken, Germany; Catholic Univ Eichstatt, Dept Comp Sci, D-85072 Eichstatt, Germany	Zimmermann, T (reprint author), Univ Saarland, Dept Comp Sci, Postfach 15 11 50, D-66041 Saarbrucken, Germany.	zimmerth@cs.uni-sb.de; peter.weissgerber@ku-eichstaett.de; diehl@acm.org; zeller@acm.org					Agrawal R., 1994, P 20 INT C VER LARG, P487; ATKINS DL, 1998, P C SYST CONF MAN SC; Ball T., 1997, P ICSE WORKSH PROC M; Berliner B., 1990, Proceedings of the Winter 1990 USENIX Conference; Bieman JM, 2003, PROG COMPREHEN, P44; BURCH M, 2005, P ACM S SOFTW VIS SO; Chen I., 2001, BUSINESS PROCESS MAN, V7, P374, DOI DOI 10.1108/14637150110406768; Cubranic D, 2003, PROC INT CONF SOFTW, P408, DOI 10.1109/ICSE.2003.1201219; FOGEL K, 2002, CVS2CLPL CVS LOG MES; Gall H., 1997, Proceedings International Conference on Software Maintenance (Cat. No.97CB36119), DOI 10.1109/ICSM.1997.624242; Gall H, 1998, PROC IEEE INT CONF S, P190, DOI 10.1109/ICSM.1998.738508; Gall H., 2003, Proceedings. Sixth International Workshop on Principles of Software Evolution; GORG C, 2005, P 13 INT WORKSH PROG; Graves T. L, 2000, IEEE T SOFTWARE ENG, V26; HASSAN AE, 2003, P INT WORKSH PRINC S; HASSAN AE, 2004, P INT C SOFTW MAINT; Michail A., 2000, Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium, DOI 10.1109/ICSE.2000.870408; Michail A., 1999, P 14 INT C AUT SOFTW, P24; Mockus A, 2000, PROC IEEE INT CONF S, P120, DOI 10.1109/ICSM.2000.883028; Mockus A, 2003, PROC INT CONF SOFTW, P274, DOI 10.1109/ICSE.2003.1201207; RIJSBERGEN CJV, 1979, INFORMATION RETRIEVA; SAYYADSHIRABAD J, 2001, P INT C SOFTW METH, P22; SAYYADSHIRABAD J, 2004, P INT WORKSH MIN SOF, P53; SAYYADSHIRABAD J, 2003, P INT C SOFTW MAINT; Sliwerski J., 2005, P INT WORKSH MIN SOF; SRIKANT R, 1997, P 3 INT C KDD DAT MI; Srikant R., 1995, P 21 INT C VER LARG, P407; Xing Z., 2004, P 16 INT C SOFTW ENG; Ying ATT, 2004, IEEE T SOFTWARE ENG, V30, P574, DOI 10.1109/TSE.2004.52; Zimmermann T., 2004, P 1 INT WORKSH MIN S, P2; ZIMMERMANN T, 2004, THESIS U PASSAU GERM; Zimmermann T., 2003, Proceedings. Sixth International Workshop on Principles of Software Evolution; 2003, P 25 INT C SOFTW ENG; 2001, P INT C SOFTW MAINT; 2003, P INT WORKSH PRINC S; 2004, P INT WORKSH MIN SOF	36	120	124	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	JUN	2005	31	6					429	445		10.1109/TSE.2005.72		17	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	940AX	WOS:000230117200002	
J	Patcha, A; Park, JM				Patcha, Animesh; Park, Jung-Min			An overview of anomaly detection techniques: Existing solutions and latest technological trends	COMPUTER NETWORKS			English	Article						survey; anomaly detection; machine learning; statistical anomaly detection; data mining	INTRUSION-DETECTION; MODELS; NETWORKS	As advances in networking technology help to connect the distant corners of the globe and as the Internet continues to expand its influence as a medium for communications and commerce, the threat from spammers, attackers and criminal enterprises has also grown accordingly. It is the prevalence of such threats that has made intrusion detection systems-the cyberspace's equivalent to the burglar alarm join ranks with firewalls as one of the fundamental technologies for network security. However, today's commercially available intrusion detection systems are predominantly signature-based intrusion detection systems that are designed to detect known attacks by utilizing the signatures of those attacks. Such systems require frequent rule-base updates and signature updates, and are not capable of detecting unknown attacks. In contrast, anomaly detection systems, a subset of intrusion detection systems, model the normal system/network behavior which enables them to be extremely effective in finding and foiling both known as well as unknown or "zero day" attacks. While anomaly detection systems are attractive conceptually, a host of technological problems need to be overcome before they can be widely adopted. These problems include: high false alarm rate, failure to scale to gigabit speeds, etc. In this paper, we provide a comprehensive survey of anomaly detection systems and hybrid intrusion detection systems of the recent past and present. We also discuss recent technological trends in anomaly detection and identify open problems and challenges in this area. (c) 2007 Elsevier B.V. All rights reserved.	Virginia Polytech Inst & State Univ, Bradley Dept Elect & Comp Engn, Blacksburg, VA 24061 USA	Patcha, A (reprint author), Virginia Polytech Inst & State Univ, Bradley Dept Elect & Comp Engn, Blacksburg, VA 24061 USA.	apatcha@vt.edu; jungmin@vt.edu	WANG, HUAN/A-1155-2009; Pagna Disso, Jules Ferdinand/A-6712-2009	Pagna Disso, Jules Ferdinand/0000-0001-8388-0418			Aggarwal C C, 2001, P 2001 ACM SIGMOD IN, P37, DOI 10.1145/375663.375668; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; ANDERSON D, 1995, SRICSL9507 COMP SCI; ANDERSON D, 1909, SRICSL9506 COMP SCI; Anderson D., 1994, SRICSL950; ANDERSON JP, 1980, 9817 J P AND CO FORT; Axelsson S., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/357830.357849; AXELSSON S, 1998, 9817 DEP COMP ENG CH; Axelsson S., 2000, 9915 CHALM U; Barbara D, 2001, SIGMOD RECORD, V30, P15; Barnett V., 1994, OUTLIERS STAT DATA; BOUZIDA Y, 2004, P 3 C SEC ARCH RES S; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breuning M.M., 2000, P ACM SIGMOD INT C M, P93, DOI DOI 10.1145/342009.335388; Bridges S.M., 2000, P NAT INF SYST SEC C; Calvo RA, 1998, P 9 AUSTR C NEUR NET; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Crosbie M., 1995, AAAI S GEN PROGR, P1; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; DENNING DE, 1985, 83F830100 COMP SCI L; Dickerson JE, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P301, DOI 10.1109/NAFIPS.2000.877441; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; Ertoz L., 2004, NEXT GENERATION DATA; Eskin E., 2001, Proceedings DARPA Information Survivability Conference and Exposition II. DISCEX'01, DOI 10.1109/DISCEX.2001.932213; Estevez-Tapiador JM, 2004, COMPUT COMMUN, V27, P1569, DOI 10.1016/j.comcom.2004.07.002; Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675; Gaffney JE, 2001, P IEEE S SECUR PRIV, P50, DOI 10.1109/SECPRI.2001.924287; GHOSH AK, 1999, P 1 USENIX WORKSH IN; Ghosh A. K., 1999, Proceedings of the Eighth USENIX Security Symposium (Security'99); GHOSH AK, 2000, P 3 INT S REC ADV IN, P93; GOMEZ J, 2001, IEEE WORKSH INF ASS; GROSSMAN RL, 1997, DATA MINING CHALLENG; Hautamaki V, 2004, INT C PATT RECOG, P430, DOI 10.1109/ICPR.2004.1334558; Heckerman D., 1995, MSRTR9506 MICR RES; HIPP J, 2000, P ACM SIGKDD INT C K, P58; Hofmeyr S. A., 1998, Journal of Computer Security, V6; HOSMER HH, 1993, P 1992 1993 WORKSH N; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; KEENEY M, 2005, INSIDER THREAT STUDY, P1; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Kruegel C, 2002, P IEEE S SECUR PRIV, P285, DOI 10.1109/SECPRI.2002.1004378; Kruegel Christopher, 2003, P 19 ANN COMP SEC AP; Krugel C, 2002, P 17 ACM S APPL COMP, P201; KUMAR S, 1994, CSDTR94013 COAST PRO; Lee W, 1998, PROCEEDINGS OF THE SEVENTH USENIX SECURITY SYMPOSIUM, P79; LEE W, 2000, P 3 INT WORKSH REC A, P49; LEE W, 2001, P 2001 DARPA INF SUR, P85; Lee W, 2001, P IEEE S SECUR PRIV, P130; Lee W, 1999, P IEEE S SECUR PRIV, P120; Lee WK, 2000, ARTIF INTELL REV, V14, P533, DOI 10.1023/A:1006624031083; LI W, 2004, USING GENETIC ALGORI, P1; Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X; ling Shyu M., 2003, P IEEE FDN NEW DIR D, P172; Lippmann R, 2000, COMPUT NETW, V34, P579, DOI 10.1016/S1389-1286(00)00139-0; Liu A, 2005, Proceedings from the Sixth Annual IEEE Systems, Man and Cybernetics Information Assurance Workshop, P340, DOI 10.1109/IAW.2005.1495972; Lunt T. F, 1992, REAL TIME INTRUSION; MAHALANOBIS PRASANTA CHANDRA, 1930, JOUR AND PROC ASIATIC SOC BENGAL, V26, P541; Mahoney M. V., 2002, P 8 ACM SIGKDD INT C, P376; MAHONEY MV, 2002, CS20028 COMP SCI DEP; MAHONEY MV, 2001, CS20014 DEP COMP SCI; MAXION RA, 1990, IEEE T RELIAB, V39, P433, DOI 10.1109/24.58721; McHugh J., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382923; Millard E, 2005, TOP TECH NEWS; NEWMAN D, 2002, NETWORK WORLD; PARK JS, 2006, P 25 IEEE INT PERF C, P463; Patcha A., 2005, Proceedings. 14th International Conference on Computer Communications and Networks (IEEE Cat. No. 05EX1184), DOI 10.1109/ICCCN.2005.1523864; Phillips J, 2006, ATHENS NEWS ATHENS; PILLAI MM, 2004, P SAICSIT, P221; Porras P., 1997, P 20 NAT INF SYST SE, P353; Portnoy L., 2001, P ACM WORKSH DAT MIN; PTACEK TH, 1998, INSERTION EVASION DE; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Ramadas M., 2003, P 6 INT S REC ADV IN, P36; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Roesch M, 1999, P 13 USENIX C SYST A, P229; Sarasamma ST, 2005, IEEE T SYST MAN CY B, V35, P302, DOI 10.1109/TSMCB.2005.843274; SEQUEIRA K, 2000, P 8 ACM SIGKDD INT C, P386; SHANKAR U, 2003, P IEEE S RES SEC PRI; Smaha S.E., 1988, P IEEE 4 AER COMP SE, P37, DOI 10.1109/ACSAC.1988.113412; STAFF C, 2005, HACKERS COMPANIES EN, V2006; Staniford S., 2002, Journal of Computer Security, V10; Stolfo S. J., 2000, P DARPA INF SURV C E, P130; STOLFO WLS, 2001, P 2 DARPA INT SURV C, P85; Sung A. H., 2003, Proceedings 2003 Symposium on Applications and the Internet, DOI 10.1109/SAINT.2003.1183050; TAN KMC, 2002, P 5 INT S REC ADV IN, P54; Tan KMC, 2003, IEEE J SEL AREA COMM, V21, P96, DOI 10.1109/JSAC.2002.806130; Tombini E., 2004, P 20 ANN COMP SEC AP; Valdes A, 2000, LECT NOTES COMPUT SC, V1907, P80; WANG W, 2004, P INT S NEUR NETW DA, P657; Wang W, 2006, FIRST INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY, PROCEEDINGS, P270; Warrender C, 1999, P IEEE S SECUR PRIV, P133, DOI 10.1109/SECPRI.1999.766910; WILLIAMS M, 2000, CNN COM; Ye N, 2004, IEEE T RELIAB, V53, P116, DOI 10.1109/TR.2004.823851; Ye N, 2000, P IEEE SYST MAN CYB; Ye N, 2002, IEEE T COMPUT, V51, P810, DOI 10.1109/TC.2002.1017701; Yeung DY, 2003, PATTERN RECOGN, V36, P229, DOI 10.1016/S0031-3203(02)00026-2; ZHANG J, 2006, P 1 INT C AV REL SEC, P262; *C S I FBO INV, 2005, P 10 ANN COMP CRIM S, P1; *WIKIPEDIA, 2006, MAH DIST, V2006	99	118	135	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1389-1286		COMPUT NETW	Comput. Netw.	AUG 22	2007	51	12					3448	3470		10.1016/j.comnet.2007.02.001		23	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	191OD	WOS:000248139800009	
J	Cook, DJ; Holder, LB				Cook, DJ; Holder, LB			Graph-based data mining	IEEE INTELLIGENT SYSTEMS & THEIR APPLICATIONS			English	Article							MACHINE DISCOVERY; DOMAIN KNOWLEDGE		Univ Texas, Dept Comp Sci & Engn, Arlington, TX 76019 USA; Univ Texas, Learning & Planning Lab, Arlington, TX 76019 USA	Cook, DJ (reprint author), Univ Texas, Dept Comp Sci & Engn, Box 19015, Arlington, TX 76019 USA.						Cameron-Jones R.M, 1994, SIGART B, V5, P33; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CONKLIN D, 1995, MACH LEARN, V21, P125, DOI 10.1007/BF00993382; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Cook DJ, 1996, IEEE EXPERT, V11, P59, DOI 10.1109/64.539018; CRAVEN MW, 1993, IEEE EXPERT, V9, P2; Djoko S, 1997, IEEE T KNOWL DATA EN, V9, P575, DOI 10.1109/69.617051; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Galal G., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rissanen J, 1989, STOCHASTIC COMPLEXIT; THOMPSON K, 1991, CONCEPT FORMATION KN; VALDESPEREZ RE, 1994, ARTIF INTELL, V65, P247, DOI 10.1016/0004-3702(94)90018-3	14	116	130	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1094-7167		IEEE INTELL SYST APP	IEEE Intell. Syst. Appl.	MAR-APR	2000	15	2					32	+		10.1109/5254.850825		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	303DF	WOS:000086405000012	
J	Ganesan, P; Garcia-Molina, H; Widom, J				Ganesan, P; Garcia-Molina, H; Widom, J			Exploiting hierarchical domain structure to compute similarity	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						algorithms; similarity measures; hierarchy; collaborative filtering; data mining	INFORMATION-RETRIEVAL	The notion of similarity between objects finds use in many contexts, for example, in search engines, collaborative filtering, and clustering. Objects being compared often are modeled as sets, with their similarity traditionally determined based on set intersection. Intersection-based measures do not accurately capture similarity in certain domains, such as when the data is sparse or when there are known relationships between items within sets. We propose new measures that exploit a hierarchical domain structure in order to produce more intuitive similarity scores. We extend our similarity measures to provide appropriate results in the presence of multisets (also handled unsatisfactorily by traditional measures), for example, to correctly compute the similarity between customers who buy several instances of the same product (say milk), or who buy several products in the same category (say dairy products). We also provide an experimental comparison of our measures against traditional similarity measures, and report on a user study that evaluated how well our measures match human intuition.	Stanford Univ, Stanford, CA 94305 USA	Ganesan, P (reprint author), Stanford Univ, 353 Serra Mall,432, Stanford, CA 94305 USA.						Bollacker K. D., 1998, Proceedings of the Second International Conference on Autonomous Agents, DOI 10.1145/280765.280786; BREESE JS, 1998, P 14 ANN C UNC ART I; Chakrabarti K, 2000, P 26 INT C VER LARG, P111; Das G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; FELDMAN R, 1995, P KDD 95; GANESAN P, 2002, EXPLOITING HIERARCHI; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; GOOD N, 1999, P AAAI IAAI; Han J, 1995, P 21 INT C VER LARG, P420; Ioannidis YE, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P174; JEH G, 2001, SIMRANK MEASURE STRU; JOSHI A, 2000, ACM SIGMOD WORKSH RE, P63; KIM YW, 1990, J DOC, V46, P113, DOI 10.1108/eb026857; LEE JH, 1993, J DOC, V49, P188, DOI 10.1108/eb026913; LUSTIG G, 1967, FID IFIP JOINT C ROM; MCGILL MJ, 1983, INTRO MODERN INFORMA; Melnik S, 2002, P ICDE 2002; Miller G.A., 1990, J LEXICOGRAPHY, V3, P234; Nasraoui O., 1999, P 8 INT FUZZ SYST AS; RADA R, 1989, IEEE T SYST MAN CYB, V19, P17, DOI 10.1109/21.24528; RESNICK P, 1994, P COMP SUPP COLL WOR; Resnik P., 1995, P 14 INT JOINT C ART, P448; RICHARDSON R, 1995, P 17 BCS IRSG C INF; RODRIGUEZ MD, 1997, P 2 INT C REC ADV NA; RUBNER Y, 1998, STANCSTN9886; SALTON G, 1968, AUTOMATIC INFORAMTIO; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SANKOFF D, 1983, MACROMOLECULES THEOR; Sarwar B., 2001, P 10 INT WWW C; Sarwar B., 2000, P ACM WEBKDD 2000 WO; SARWAR B, 1998, P ACM C COMP SUPP CO; SCOTT S, 1998, P US WORDN NAT LANG; SHASHA D, 1997, PATTERN MATCHING ALG; Shivakumar N, 1995, P 2 INT C THEOR PRAC; SIBSON R, 1972, J ROY STAT SOC B, V34, P311; Sneath P.H.A., 1973, NUMERICAL TAXONOMY; SOERGEL D, 1967, INFORM STORAGE RET, V3, P129, DOI 10.1016/0020-0271(67)90006-X; Srikant R., 1995, P 21 INT C VER LARG, P407; Strehl A, 2000, P AAAI WORKSH AI WEB; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; *OPD, OP DIR PROJ	42	115	130	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	1046-8188		ACM T INFORM SYST	ACM Trans. Inf. Syst.	JAN	2003	21	1					64	93		10.1145/635484.635487		30	Computer Science, Information Systems	Computer Science	648HZ	WOS:000181146300003	
J	Lu, HJ; Setiono, R; Liu, H				Lu, HJ; Setiono, R; Liu, H			Effective data mining using neural networks	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; neural networks; rule extraction; network pruning; classification		Classification is one of the data mining problems receiving great attention recently in the database community. This paper presents an approach to discover symbolic classification rules using neural networks. Neural networks have not been thought suited for data mining because how the classifications were made is not explicitly stated as symbolic rules that are suitable for verification or interpretation by humans. With the proposed approach, concise symbolic rules with high accuracy can be extracted from a neural network. The network is first trained to achieve the required accuracy rate. Redundant connections of the network are then removed by a network pruning algorithm. The activation values of the hidden units in the network are analyzed, and classification rules are generated using the result of this analysis. The effectiveness of the proposed approach is clearly demonstrated by the experimental results on a set of standard data mining test problems.		Lu, HJ (reprint author), NATL UNIV SINGAPORE,DEPT INFORMAT SYST & COMP SCI,LOWER KENT RIDGE RD,SINGAPORE 119260,SINGAPORE.						Agrawal R., 1993, IEEE T KNOWLEDGE DAT, V5; DENNIS JE, 1983, NUMERICAL METHODS UN; LIU H, 1995, P IEEE INT C SYSTEMS; Lu H., 1995, P 21 INT C VER LARG, P478; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1994, COMPUTATIONAL LEARNI, V1, P445; SETIONO R, 1997, NEURAL COMPUT, V9, P301; Setiono R., 1995, Connection Science, V7, DOI 10.1080/09540099550039327; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; Taylor C.C., 1994, MACHINE LEARNING NEU	10	114	144	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	DEC	1996	8	6					957	961				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	WC057	WOS:A1996WC05700010	
J	Huang, CL; Chen, MC; Wang, CJ				Huang, Cheng-Lung; Chen, Mu-Chen; Wang, Chieh-Jen			Credit scoring with a data mining approach based on support vector machines	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						credit scoring; support vector machine; genetic programming; neural networks; decision tree; data mining; classification	FEATURE SUBSET-SELECTION; NEURAL-NETWORKS; MODELS; CLASSIFICATION; ALGORITHMS; FUZZY	The credit card industry has been growing rapidly recently, and thus huge numbers of consumers' credit data are collected by the credit department of the bank. The credit scoring manager often evaluates the consumer's credit with intuitive experience. However, with the support of the credit classification model, the manager can accurately evaluate the applicant's credit score. Support Vector Machine (SVM) classification is currently an active research area and successfully solves classification problems in many domains. This study used three strategies to construct the hybrid SVM-based credit scoring models to evaluate the applicant's credit score from the applicant's input features. Two credit datasets in UCI database are selected as the experimental data to demonstrate the accuracy of the SVM classifier. Compared with neural networks, genetic programming, and decision tree classifiers, the SVM classifier achieved an identical classificatory accuracy with relatively few input features. Additionally, combining genetic algorithms with SVM classifier, the proposed hybrid GA-SVM strategy can simultaneously perform feature selection task and model parameters optimization. Experimental results show that SVM is a promising addition to the existing data mining methods. (c) 2006 Elsevier Ltd. All rights reserved.	Natl Kaohsiung First Univ Sci & Technol, Dept Informat Management, Kaohsiung 811, Taiwan; Natl Chiao Tung Univ, Inst Traff & Transportat, Taipei 10012, Taiwan; Huafan Univ, Dept Informat Management, Shihtin Hsiang 223, Taipei Hsien, Taiwan	Huang, CL (reprint author), Natl Kaohsiung First Univ Sci & Technol, Dept Informat Management, 2 Juoyue Rd,Nantz Dist, Kaohsiung 811, Taiwan.	clhuang@ccms.nkfust.edu.tw					Baesens B, 2003, J OPER RES SOC, V54, P627, DOI 10.1057/palgrave.jors.2601545; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chen MC, 2003, EXPERT SYST APPL, V24, P433, DOI 10.1016/S0957-4174(02)00191-4; Chen SY, 2004, J INF SCI, V30, P550, DOI 10.1177/0165551504047928; Chen Y. W., 2005, COMBINING SVMS VARIO; Cristianini N., 2000, INTRO SUPPORT VECTOR; Davis R.H., 1992, IMA J MATH APPL BUSI, V4, P43, DOI 10.1093/imaman/4.1.43; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; Frohlich H, 2003, PROC INT C TOOLS ART, P142, DOI 10.1109/TAI.2003.1250182; Garson GD, 1991, AI EXPERT, V6, P47; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Henley W E., 1995, THESIS OPEN U MILTON; Henley WE, 1996, STATISTICIAN, V45, P77, DOI 10.2307/2348414; Hoffmann F, 2002, INT J INTELL SYST, V17, P1067, DOI 10.1002/int.10052; HOLLAND JH, 1975, ADAPTATION NATURAL A; Hsieh NC, 2005, EXPERT SYST APPL, V28, P655, DOI 10.1016/j.eswa.204.12.022; Hsu C.W., 2003, PRACTICAL GUIDE SUPP; Hsu C.W., 2002, MACH LEARN, V46, P219; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; J Brill, 1998, BUSINESS CREDIT, V100, P16; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kecman V., 2001, LEARNING SOFT COMPUT; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koza J. R., 1992, GENETIC PROGRAMMING; Lee TS, 2002, EXPERT SYST APPL, V23, P245, DOI 10.1016/S0957-4174(02)00044-1; Lee TS, 2005, EXPERT SYST APPL, V28, P743, DOI 10.1016/j.eswa.2004.12.031; Liu H., 1998, FEATURE SELECTION KN; Malhotra R, 2002, EUR J OPER RES, V136, P190, DOI 10.1016/S0377-2217(01)00052-2; Mao KZ, 2004, IEEE T SYST MAN CY B, V34, P60, DOI 10.1109/TSMCB.2002.805808; Murphy P. M., 2001, UCI REPOSITORY MACHI; Ong CS, 2005, EXPERT SYST APPL, V29, P41, DOI 10.1016/j.eswa.2005.01.003; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Reichert A. K., 1983, J BUS ECON STAT, V1, P101, DOI 10.2307/1391851; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Scholkopf B., 2000, STAT LEARNING KERNEL; Somol P, 2005, INT J INTELL SYST, V20, P985, DOI 10.1002/int.20103; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Thomas LC, 2000, INT J FORECASTING, V16, P149, DOI 10.1016/S0169-2070(00)00034-0; Vapnik V.N., 1995, NATURE STAT LEARNING; West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5; Weston J, 2001, ADV NEUR IN, V13, P668; Yu G. X., 2003, 2 IEEE COMP SOC BIOI, P235; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	47	113	121	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	NOV	2007	33	4					847	856		10.1016/j.eswa.2006.07.007		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	165OQ	WOS:000246315200005	
J	Olaru, C; Wehenkel, L				Olaru, C; Wehenkel, L			A complete fuzzy decision tree technique	FUZZY SETS AND SYSTEMS			English	Article						learning; approximate reasoning; fuzzy decision tree; data mining; soft split; pruning; global optimization; regression tree; neural network	SECURITY ASSESSMENT; NEURAL-NETWORKS; LEARNING-METHOD; CLASSIFICATION; CLASSIFIERS; ALGORITHMS; INDUCTION; ENTROPY; ID3	In this paper, a new method of fuzzy decision trees called soft decision trees (SDT) is presented. This method combines tree growing and pruning, to determine the structure of the soft decision tree, with refitting and backfitting, to improve its generalization capabilities. The method is explained and motivated and its behavior is first analyzed empirically on 3 large databases in terms of classification error rate, model complexity and CPU time. A comparative study on 11 standard UCI Repository databases then shows that the soft decision trees produced by this method are significantly more accurate than standard decision trees. Moreover, a global model variance study shows a much lower variance for soft decision trees than for standard trees as a direct cause of the improved accuracy. (C) 2003 Elsevier B.V. All rights reserved.	Univ Liege, Inst Montefiore, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium	Olaru, C (reprint author), Univ Liege, Inst Montefiore, Dept Elect Engn & Comp Sci, B28, B-4000 Liege, Belgium.						Apolloni B, 1998, NEURAL NETWORKS, V11, P885, DOI 10.1016/S0893-6080(98)00030-6; ARAYA R, 1992, P STAT, P119; BALDWIN JF, 1998, P IPMU98, V1, P524; Boyen X., 1995, P 2 IFAC S CONTR POW, P151; BOYEN X, 1995, THESIS U LIEGE; BOYEN X, 1995, UNFAIRNESS CONVEX DI; Boyen X, 1999, FUZZY SET SYST, V102, P3, DOI 10.1016/S0165-0114(98)00198-5; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; CARTER C, 1987, IEEE EXPERT      FAL, P71; CHANG RLP, 1977, IEEE T SYST MAN CYB, V7, P28, DOI 10.1109/TSMC.1977.4309586; Chi ZR, 1996, IEEE T FUZZY SYST, V4, P24; CIOS KJ, 1992, IEEE T NEURAL NETWOR, V3, P280, DOI 10.1109/72.125869; Cios KJ, 1997, NEUROCOMPUTING, V14, P383, DOI 10.1016/S0925-2312(96)00039-2; CIOS KJ, 1992, P IEEE INT C FUZZ SY, P469; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 1995, MACHINE LEARNING BIA; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; FRIEDMAN J. H., 1996, LOCAL LEARNING BASED; GEURTS P, 2000, P 11 EUR C MACH LEAR, P162; Geurts P, 2001, ENG INTELL SYST ELEC, V9, P195; HALL LO, 1997, P INT FUZZ SYST ASS, V2, P418; HAYASHI I, 1998, GEN FUZZY DECISION T; HEINZ AP, 1995, ICNN 95, V1, P394; HEINZ AP, 1994, EUFIT 94, P1347; Ichihashi H, 1996, FUZZY SET SYST, V81, P157, DOI 10.1016/0165-0114(95)00247-2; ITTNER A, 1997, P INT FUZZ SYST ASS, V2, P394; Jang J.S.R, 1994, P 3 IEEE INT C FUZZ, V1, P480; Janikow CZ, 1998, IEEE T SYST MAN CY B, V28, P1, DOI 10.1109/3477.658573; Jeng BC, 1997, DECIS SUPPORT SYST, V21, P61, DOI 10.1016/S0167-9236(97)00019-5; JORDAN MI, 1994, P 7 ANN ACM C COMP L; MARSALA C, 1998, THESIS U PARIS 6; MARSALA C, 1997, P INT FUZZ SYST ASS, V2, P369; OLARU C, 1998, FUZZY DECISION TREE; PRESS WH, 1994, NUMERICAL REECIPES C; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RAMDANI M, 1994, THESIS U PARIS 6 PAR; SETHI IK, 1995, IEEE T SYST MAN CYB, V25, P1243, DOI 10.1109/21.398685; SETHI IK, 1990, P IEEE, V78, P1605, DOI 10.1109/5.58346; Shah Hamzei G. H., 1999, Engineering Applications of Artificial Intelligence, V12, DOI 10.1016/S0952-1976(98)00045-1; SHIBATA T, 1995, P 6 IFSA WORLD C SAO, V1, P613; Suarez A, 1999, IEEE T PATTERN ANAL, V21, P1297, DOI 10.1109/34.817409; WANG QR, 1987, IEEE T PATTERN ANAL, V9, P91; TANI T, 1992, P IEEE INT C FUZZ SY, P923; Torgo L., 1999, THESIS U PORTO; Tsang ECC, 2000, IEEE T FUZZY SYST, V8, P601, DOI 10.1109/91.873583; TSUCHIYA T, 1996, J IND ERGONOMICS, V18, P135; TURNEY P, 1995, MACH LEARN, V20, P23, DOI 10.1007/BF00993473; UMANO M, 1994, P 3 IEEE INT C FUZZ, V3, P2113; Utgoff P. E., 1989, Connection Science, V1, DOI 10.1080/09540098908915648; Wang XZ, 2000, FUZZY SET SYST, V112, P117, DOI 10.1016/S0165-0114(97)00386-2; Weber R., 1992, P 2 INT C FUZZ LOG N, P265; WEHENKEL L, 1997, P 7 IFSA WORLD C PRA, V2, P381; WEHENKEL L, 1993, INT J ELEC POWER, V15, P13, DOI 10.1016/0142-0615(93)90014-E; Wehenkel L., 1998, AUTOMATIC LEARNING T; WEHENKEL L, 1992, P IPMU 92 C PALM MAL; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z; ZEIDLER J, 1996, P 6 INT C INF PROC M, P395	60	113	122	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	SEP 1	2003	138	2					221	254		10.1016/S0165-0114(03)00089-7		34	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	711GM	WOS:000184731300001	
J	Mobasher, B; Dai, H; Luo, T; Nakagawa, M				Mobasher, B; Dai, H; Luo, T; Nakagawa, M			Discovery and evaluation of aggregate usage profiles for web personalization	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						Web usage mining; clustering; personalization; collaborative filtering; data mining		Web usage mining, possibly used in conjunction with standard approaches to personalization such as collaborative filtering, can help address some of the shortcomings of these techniques, including reliance on subjective user ratings, lack of scalability, and poor performance in the face of high-dimensional and sparse data. However, the discovery of patterns from usage data by itself is not sufficient for performing the personalization tasks. The critical step is the effective derivation of good quality and useful (i.e., actionable) "aggregate usage profiles" from these patterns. In this paper we present and experimentally evaluate two techniques, based on clustering of user transactions and clustering of pageviews, in order to discover overlapping aggregate profiles that can be effectively used by recommender systems for real-time Web personalization. We evaluate these techniques both in terms of the quality of the individual profiles generated, as well as in the context of providing recommendations as an integrated part of a personalization engine. In particular, our results indicate that using the generated aggregate profiles, we can achieve effective personalization at early stages of users' visits to a site, based only on anonymous clickstream data and without the benefit of explicit input by these users or deeper knowledge about them.	Depaul Univ, Sch Comp Sci Telecommun & Informat Syst, Ctr Web Intelligence, Chicago, IL 60604 USA	Mobasher, B (reprint author), Depaul Univ, Sch Comp Sci Telecommun & Informat Syst, Ctr Web Intelligence, Chicago, IL 60604 USA.						AGARWAL R, 1999, P HIGH PERF DAT MIN; Agrawal R., 1994, P 20 INT C VER LARG; AGRAWAL R, 1995, P INT C DAT ENG ICDE; BANERJEE A, 2001, P WEB MIN WORKSH 1 S; BRIN S, 1997, P ACM SIGMOD INT C M; BUCHNER A, 1999, SIGMOD REC, V4, P27; Charniak E., 1996, STAT LANGUAGE LEARNI; COOLEY R, 1999, P WORKSH WEB US AN U; COOLEY R, 1999, J KNOWLEDGE INFORMAT, V1, P1; HAN EH, 1998, IEEE B TECHNICAL COM, V21, P1; HAN EH, 1999, J ARTIFICIAL INTELLI, V13, P365; HAN EH, 1997, P SIGMOD 97 WORKSH R; Herlocker J. L., 1999, P 1999 C RES DEV INF; KARYPIS G, 2000, 00016 U MINN DEP COM; KONSTAN J, 1997, COMMUN ACM, V40, P3; LEWIS D, 1994, P 17 ANN ACM SIGIR C, V3, P12; MOBASHER B, 1999, IEEE KNOWL DAT ENG W; MOBASHER B, 2000, COMMUN ACM, V43, P8; MOBASHER B, 1999, P 9 WORKSH INF TECHN; Nasraoui O., 1999, P 8 INT FUZZ SYST AS; OCONNER M, 1999, P ACM SIGIR WORKSH R; Perkowitz M., 1998, P 15 NAT C ART INT M; SARWAR BM, 2000, P 2 ACM E COMM C EC; Schechter S., 1998, P 7 INT WORLD WID WE; SHAHABI C, 1997, P WORKSH RES ISS DAT; SHARDANAND U, 1995, P ACM CHI C CHI95; SPILIOPOULOU M, 1999, LNCS, V1590; SPILIOPOULOU M, 1999, P WORKSH WEB US AN U; Srivastava J, 2000, SIGKDD EXPLOR NEWSL, V1, P2; YAN TW, 1996, P 5 INT WORLD WID WE; YU PS, 1999, P INT C DAT SYST ADV; ZAIANE O, 1998, ADV DIGITAL LIB, P19	32	113	119	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2002	6	1					61	82		10.1023/A:1013232803866		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	503VK	WOS:000172822000004	
J	Zaki, MJ; Hsiao, CJ				Zaki, MJ; Hsiao, CJ			Efficient algorithms for mining closed itemsets and their lattice structure	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						closed itemsets; frequent itemsets; closed itemset lattice; association rules; data mining		The set of frequent closed itemsets uniquely determines the exact frequency of all itemsets, yet it can be orders of magnitude smaller than the set of all frequent itemsets. In this paper, we present CHARM, an efficient algorithm for mining all frequent closed itemsets. It enumerates closed sets using a dual itemset-tidset search tree, using an efficient hybrid search that skips many levels. It also uses a technique called diffsets to reduce the memory footprint of intermediate computations. Finally, it uses a fast hash-based approach to remove any "nonclosed" sets found during computation. We also present CHARM-L, an algorithm that outputs the closed itemset lattice, which is very useful for rule generation and visualization. An extensive experimental evaluation on a number of real and synthetic databases shows that CHARM is a state-of-the-art algorithm that outperforms previous methods. Further, CHARM-L explicitly generates the frequent closed itemset lattice.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Zaki, MJ (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.	zaki@cs.rpi.edu; hsiao@cs.rpi.edu					AGRAWAL R, 2000, P 7 INT C KNOWL DISC; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; BASTIDE Y, 2000, SIGKDD EXPLORATIONS, V2; BAYARDO R, 1998, P ACM SIGMOD C MAN D; Brin S., 1997, P ACM SIGMOD C MAN D; BURDICK D, 2001, P P INT C DAT ENG AP; CRISTOFOR D., 2000, J UNIVERS COMPUT SCI, V6, P60; DUNKEL B, 1999, P 15 IEEE INT C DAT; Ganter B., 1999, FORMAL CONCEPT ANAL; GOUDA K, 2001, P 1 IEEE INT C DAT M; Han J., 2001, DATA MINING CONCEPTS; Han J., 2000, P ACM SIGMOD C MAN D; LIN DI, 1998, P 6 INT C EXT DAT TE; Nourine L, 1999, INFORM PROCESS LETT, V71, P199, DOI 10.1016/S0020-0190(99)00108-8; Park J.S., 1995, P ACM SIGMOD INT C M; PASQUIER N, 1999, P 7 INT C DAT THEOR; PEI J, 2000, P SIGMOD INT WORKSH; SAVASERE A, 1995, P 21 VER LARG DAT BA; SHENOY P, 2000, P ACM SIGMOD INT C M; WANG J, 2003, P ACM SIGKDD INT C K; ZAKI M, 1999, 9910 RENSS POL I COM; Zaki M. J, 1998, P 3 ACM SIGMOD WORKS; Zaki M.J., 2003, P 9 ACM SIGKDD INT C; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291; ZAKI MJ, 2000, P 6 ACM SIGKDD INT C; ZAKI MJ, 2003, 034 POL I COMP SCI D	26	112	121	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2005	17	4					462	478		10.1109/TKDE.2005.60		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	897IB	WOS:000226996100002	
J	Van Renesse, R; Birman, KP; Vogels, W				Van Renesse, R; Birman, KP; Vogels, W			Astrolabe: A robust and scalable technology for distributed system monitoring, management, and data mining	ACM TRANSACTIONS ON COMPUTER SYSTEMS			English	Article						algorithms; design; management; performance; reliability; security	AREA	Scalable management and self-organizational capabilities are emerging as central requirements for a generation of large-scale, highly dynamic, distributed applications. We have developed an entirely new distributed information management system called Astrolabe. Astrolabe collects large-scale system state, permitting rapid updates and providing on-the-fly attribute aggregation. This latter capability permits an application to locate a resource, and also offers a scalable way to track system state as it evolves over time. The combination of features makes it possible to solve a wide variety of management and self-configuration problems. This paper describes the design of the system with a focus upon its scalability. After describing the Astrolabe service, we present examples of the use of Astrolabe for locating resources, publish-subscribe, and distributed synchronization in large systems. Astrolabe is implemented using a peer-to-peer protocol, and uses a restricted form of mobile code based on the SQL query language for aggregation. This protocol gives rise to a novel consistency model. Astrolabe addresses several security considerations using a built-in PKI. The scalability of the system is evaluated using both simulation and experiments; these confirm that Astrolabe could scale to thousands and perhaps millions of nodes, with information propagation delays in the tens of seconds.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Van Renesse, R (reprint author), Cornell Univ, Dept Comp Sci, Upson Hall, Ithaca, NY 14853 USA.						ADJIEWINOTO W, 1999, P 17 ACM S OP SYST P; Aguilera M, 1999, P 18 ACM S PRINC DIS; Anderson CJ, 2001, J ENG TECHNOL MANAGE, V18, P131, DOI 10.1016/S0923-4748(01)00032-7; BALAZINSKA M, 2002, LNCS, V2414, P195; Birman K., 1987, P 11 ACM S OP SYST P, P123, DOI 10.1145/41457.37515; Birman KP, 1999, ACM T COMPUT SYST, V17, P41, DOI 10.1145/312203.312207; BIRRELL AD, 1982, COMMUN ACM, V25, P260, DOI 10.1145/358468.358487; BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692; Bonnet P., 2001, P 2 INT C MOB DAT MA; Carzaniga A, 2001, ACM T COMPUT SYST, V19, P332, DOI 10.1145/380749.380767; Demers A, 1987, P 6 ANN ACM S PRINC, P1, DOI 10.1145/41840.41841; GOLDING RA, 1994, PROCEEDINGS OF THE WINTER 1994 USENIX CONFERENCE, P47; Golding R. A., 1992, Computing Systems, V5; Gribble SD, 2001, COMPUT NETW, V35, P473, DOI 10.1016/S1389-1286(00)00179-1; Heidemann J., 2001, P 18 ACM S OP SYST P, V35, P146, DOI 10.1145/502034.502049; LAMPSON BW, 1986, P 5 ACM S PRINC DIST; MINSKY Y, 2002, THESIS CORNELL U ITH; MOCKAPETRIS P, 1984, P IFIP 6 5 INT S COM; Oki B., 1993, P 14 ACM S OP SYST P, P58, DOI 10.1145/168619.168624; Petersen K., 1997, P 16 ACM S OP SYST P, P288, DOI 10.1145/268998.266711; RADICATI S, 1994, X500 DIRECTORY SERVI; Reese G, 2000, DATABASE PROGRAMMING; ROWSTRON A, 2001, P MIDDL 2001 HEID GE; SANDERS RE, 1998, ODBC 3 5 DEV GUIDE; Snoeren A. C., 2001, P 18 ACM S OP SYST P, P160; STALLINGS W, 1993, SNMP SNMPV2 CMIP; STOICA I, 1995, P 95 S COMM ARCH PRO; Tennenhouse DL, 1997, IEEE COMMUN MAG, V35, P80, DOI 10.1109/35.568214; VANRENESSE R, 1998, P IFIP INT C DISTR S, P55; VANRENESSE R, 2002, P 21 S REL DISTR SYS; van Steen M, 1998, IEEE COMMUN MAG, V36, P104, DOI 10.1109/35.649334; WHITE B, 2002, USENIX OSDI 02 BOST; ZHAO B., 2001, UCBCSD011141	33	112	113	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0734-2071		ACM T COMPUT SYST	ACM Trans. Comput. Syst.	MAY	2003	21	2					164	206		10.1145/762483.762485		43	Computer Science, Theory & Methods	Computer Science	665MV	WOS:000182125600002	
J	Delgado, M; Marin, N; Sanchez, D; Vila, MA				Delgado, M; Marin, N; Sanchez, D; Vila, MA			Fuzzy association rules: General model and applications	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						association rules; data mining; fuzzy transactions; quantified sentences	RELATIONAL DATABASES	The theory of fuzzy sets has been recognized as a suitable tool to model several kinds of patterns that can hold in data. In this paper, we are concerned with the development of a general model to discover association rules among items in a (crisp) set of fuzzy transactions. This general model can be particularized in several ways; each particular instance corresponds to a certain kind of pattern and/or repository of data. We describe some applications of this scheme, paying special attention to the discovery of fuzzy association rules in relational databases.	Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Delgado, M (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	daniel@decsai.ugr.es	Vila Miranda, Amparo/B-1840-2012; Delgado Calvo-Flores, Miguel/B-1842-2012				Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P478; AU WH, 1998, P IEEE INT C FUZZ SY, V2, P1314; AU WH, 1997, P 6 INT C INF KNOWL, P209; AU WH, 1999, P FUZZ IEEE 99, V3, P22; BENYAHIA S, 2000, P 8 INT C INF PROC M, P952; BERZAL F, 2001, LECT NOTES COMPUTER, V2189, P95; Berzal F, 2001, DATA KNOWL ENG, V37, P47, DOI 10.1016/S0169-023X(00)00055-0; BERZAL F, 2000, CCIA000116 U GRAN DE; BERZAL F, 2002, 4 INT S IDA 01 INT D; BLANCO I, 2003, UNPUB DATA MINING KN; BOSC P, 1997, P ANN M NAFIPS, P57; Bouchon-Meunier B, 1999, HDB FUZZ SET SER, P15; Brin S., 1997, SIGMOD Record, V26; CHEN G, 2000, STUDIES FUZZINESS SO; CUBERO JC, 1995, FUZZY LOGIC SOFT COM; CUBERO JC, 1994, INT J INTELL SYST, V9, P441, DOI 10.1002/int.4550090504; CUBERO JC, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P162, DOI 10.1109/FUZZY.1994.343699; DELGADO M, 2000, MATH SOFT COMPUT, V7, P149; Delgado M., 2002, FUZZY SETS SYSTEMS, V126, P41; DELGADO M, 2000, IPMU 2000 MADR SPAIN; Delgado M, 2000, INT J APPROX REASON, V23, P23, DOI 10.1016/S0888-613X(99)00031-6; DELGADO M, 2002, IN PRESS STUDIES FUZ, V83, P286; DELGADO M, 1999, EUFIT 99 AACH GERM; DELUCA A, 1979, ADV FUZZY SET THEORY, V20, P321; Dubois D., 1992, INTRO FUZZY LOGIC AP, P45; Fu A. W. C., 1998, P INT S INT DAT ENG, P263; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HIDBER C, 1999, P ACM SIGMOD INT C M, P145, DOI 10.1145/304182.304195; Hipp J., 2000, SIGKDD EXPLORATIONS, V2, P58; Hong T. P., 1999, INTELL DATA ANAL, V3, P363, DOI 10.1016/S1088-467X(99)00028-1; KACPRZYK J, 1988, FUZZY SETS PSYCHOL, P233; Kuok C. M., 1998, SIGMOD REC, P41, DOI DOI 10.1145/273244.273257; LEE JH, 1997, IFSA 97 PRAG CZECH R; LEE JWT, 2000, FUZZ IEEE 2000, P399; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; MARTINBAUTISTA MJ, 2000, THESIS U GRANADA GRA; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; Park J., 1995, SIGMOD REC, V24, P175; Pedrycz W, 1998, FUZZY SET SYST, V98, P279, DOI 10.1016/S0165-0114(96)00377-6; SANCHEZ D, 1999, THESIS U GRANADA GRA; Shortliffe E. H., 1975, Mathematical Biosciences, V23, DOI 10.1016/0025-5564(75)90047-4; SHUYUE J, 2000, P IEEE INT C SYST MA, P1906; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Srikant R., 1995, P 21 INT C VER LARG, P407; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; VAZIRGIANNIS M, 1998, P RES DEV KNOWL DISC, P414; Wijsen J, 1998, DATA MIN KNOWL DISC, V2, P263, DOI 10.1023/A:1009755120593; WYGRALAK M, 1996, VAGUELY DEFINED OBJE; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; YEN SJ, 1996, J INTELL INF SYST, V7, P235, DOI 10.1007/BF00125369; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; Zhang W., 1999, P IEEE ICTAI, P99; ZHANG Z, 1997, KDD TECHNIQUES APPL, P241	55	112	113	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	APR	2003	11	2					214	225		10.1109/TFUZZ.2003.809896		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	664ZN	WOS:000182095300006	
J	Hu, QH; Xie, ZX; Yu, DR				Hu, Qinghua; Xie, Zongxia; Yu, Daren			Hybrid attribute reduction based on a novel fuzzy-rough model and information granulation	PATTERN RECOGNITION			English	Article						numerical feature; categorical feature; feature selection; attribute reduction; fuzzy set; rough set; inclusion degree	FEATURE-SELECTION; INCLUSION DEGREE; SETS; APPROXIMATION; ALGORITHM; DISCRETIZATION; CLASSIFICATION; CATEGORIZATION; DIMENSIONALITY; SIMILARITY	Feature subset selection has become an important challenge in areas of pattern recognition, machine learning and data mining. As different semantics are hidden in numerical and categorical features, there are two strategies for selecting hybrid attributes: discretizing numerical variables or numericalize categorical features. In this paper, we introduce a simple and efficient hybrid attribute reduction algorithm based on a generalized fuzzy-rough model. A theoretic framework of fuzzy-rough model based on fuzzy relations is presented, which underlies a foundation for algorithm construction. We derive several attribute significance measures based on the proposed fuzzy-rough model and construct a forward greedy algorithm for hybrid attribute reduction. The experiments show that the technique of variable precision fuzzy inclusion in computing decision positive region can get the optimal classification performance. Number of the selected features is the least but accuracy is the best. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Harbin Inst Technol, Harbin 150001, Peoples R China	Hu, QH (reprint author), Harbin Inst Technol, Harbin 150001, Peoples R China.	huqinghua@hcms.hit.edu.cn	Hu, Qinghua/B-8857-2008				Bargiela A, 2003, IEEE T SYST MAN CY B, V33, P96, DOI 10.1109/TSMCB.2003.808190; Berthold MR, 2004, INT J INTELL SYST, V19, P607, DOI 10.1002/int.20013; Beynon MJ, 2006, INT J INTELL SYST, V21, P173, DOI 10.1002/int.20126; Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P1632, DOI 10.1016/j.patrec.2005.01.006; Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044; Bortolan G, 2002, IEEE T FUZZY SYST, V10, P743, DOI 10.1109/TFUZZ.2002,805891; Chen Y. H., 2006, P 2006 IEEE INT C GR; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107; Guillaume S, 2004, IEEE T FUZZY SYST, V12, P324, DOI 10.1109/TFUZZ.2004.825979; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hu QH, 2005, LECT NOTES ARTIF INT, V3613, P494; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; Hu QH, 2004, INT J UNCERTAIN FUZZ, V12, P575, DOI 10.1142/S0218488504003089; Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086; Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; JENSON R, P IEEE INT C FUZZ SY, P29; Kira K, 1992, P 10 NAT C ART INT, P129; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Lee CK, 2006, INFORM PROCESS MANAG, V42, P155, DOI 10.1016/j.ipm.2004.08.006; Lee HS, 2001, FUZZY SET SYST, V123, P129, DOI 10.1016/S0165-0114(00)00062-2; Lin T. Y., 1999, COMPUTING WORDS INFO, P183; LIN TY, 2000, J APPL INTELLIGENCE, V13, P113; Lin TY, 1988, P 1988 ACM 16 ANN CO, P725, DOI 10.1145/322609.323183; LIN TY, 2004, P IEEE C FUZZ SYST, P1141; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; Ma ZM, 1999, INFORM PROCESS LETT, V72, P25, DOI 10.1016/S0020-0190(99)00124-6; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Modrzejewski M., 1993, P EUR C MACH LEARN, P213; Muni DP, 2006, IEEE T SYST MAN CY B, V36, P106, DOI 10.1109/TSMCB.2005.854499; Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9; Oh SK, 2002, ADV ENG INFORM, V16, P247, DOI 10.1016/S1474-0346(03)00016-8; Pavlenko T, 2003, J STAT PLAN INFER, V115, P565, DOI 10.1016/S0378-3758(02)00166-0; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pedrycz W, 1999, IEEE T SYST MAN CY B, V29, P745, DOI 10.1109/3477.809029; Pedrycz W, 2002, PATTERN RECOGN, V35, P825, DOI 10.1016/S0031-3203(01)00102-9; Bargiela A, 2005, SOFT COMPUT, V9, P155, DOI 10.1007/s00500-003-0339-2; Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654; Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016; Skowron A, 2001, INT J INTELL SYST, V16, P57, DOI 10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y; Slezak D, 2002, FUND INFORM, V53, P365; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Tang WY, 2005, LECT NOTES ARTIF INT, V3518, P683; Wang GY, 2005, FUND INFORM, V68, P289; Wu WZ, 2004, INFORM SCIENCES, V159, P233, DOI 10.1016/j.ins.2003.08.005; Xu ZB, 2002, INFORM SCIENCES, V141, P227, DOI 10.1016/S0020-0255(02)00174-3; Yao Y.Y., 2004, LNCS T ROUGH SETS, P232; Yao YY, 2001, INT J INTELL SYST, V16, P87, DOI 10.1002/1098-111X(200101)16:1<87::AID-INT7>3.0.CO;2-S; Yeung DS, 2005, IEEE T FUZZY SYST, V13, P343, DOI 10.1109/TFUZZ.2004.841734; Yu L., 2003, P 20 INT C MACH LEAR, P856; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; Zadeh L.A, 1965, FUZZY SETS INFORM CO, V8, P338, DOI DOI 10.1016/S0019-9958(65)90241-X; Zhang YQ, 2005, IEEE T FUZZY SYST, V13, P48, DOI 10.1109/TFUZZ.2004.839657	57	111	123	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	DEC	2007	40	12					3509	3521		10.1016/j.patcog.2007.03.017		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	213PA	WOS:000249678400015	
J	Romero, C; Ventura, S				Romero, C.; Ventura, S.			Educational data mining: A survey from 1995 to 2005	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; educational systems; web mining; web-based educational systems	KNOWLEDGE	Currently there is an increasing interest in data mining and educational systems, making educational data mining as a new growing research community. This paper surveys the application of data mining to traditional educational systems, particular web-based courses, well-known learning content management systems, and adaptive and intelligent web-based educational systems. Each of these systems has different data source and objectives for knowledge discovering. After preprocessing the available data in each case, data mining techniques can be applied: statistics and visualization; clustering, classification and outlier detection; association rule mining and pattern mining; and text mining. The success of the plentiful work needs much more specialized work in order for educational data mining to become a mature area. (c) 2006 Elsevier Ltd. All rights reserved.	Univ Cordoba, Dept Comp Sci, Cordoba, Spain	Romero, C (reprint author), Univ Cordoba, Dept Comp Sci, Cordoba, Spain.	cromero@uco.es	Ventura, Sebastian/A-7753-2008; Romero, Cristobal/H-4782-2011	Ventura, Sebastian/0000-0003-4216-6378; 			Agrawal R., 1995, 11 INT C DAT ENG, P3; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Arroyo I, 2004, LECT NOTES COMPUT SC, V3220, P782; Arruabarrena R., 2002, Adaptive Hypermedia and Adaptive Web-Based Systems. Second International Conference, AH 2002. Proceedings (Lecture Notes in Computer Science Vol.2347); AVOURIS N, 2005, WORKSH US AN LEARN S; Baker RS, 2004, LECT NOTES COMPUT SC, V3220, P531; BARI M, 2005, INT C HUM SYST LEARN, P321; Beck JE, 2000, LECT NOTES COMPUT SC, V1839, P584; BECKER K, 2000, P 14 SPIES ANN INT S, P412; Becker K, 2005, 6 INT C E COMM WEB T, P267; Brusilovsky Peter, 2003, INT J ARTIFICIAL INT, V13, P156; CASTRO F, 2005, 1 S NAC TECN INF COM, P153; Chen GD, 2000, J EDUC COMPUT RES, V23, P305; CHEN J, 2004, ICWL 2004, P35; DAMEZ M, 2005, INT C HUM SYST LEARN, P287; Dringus LP, 2005, COMPUT EDUC, V45, P141, DOI 10.1016/j.compedu.2004.05.003; FARZAN R, 2004, 3 INT C AD HYP AD WE; FENG M, 2005, P AAAI 05 WORKSH ED; FREYBERGER J, 2004, WORKSH AN STUD TUT I; Grob H., 2004, P 26 INT C INF TECHN, P233; Grobelnik M., 2002, P ICML 2002 WORKSH D, P34; Ha S., 2000, IEEE INT C MAN INN T, P715; Hamalainen W., 2004, WORLD C OP LEARN DIS; HAMMOUDA K, 2005, DATA MINING E LEARNI; Hanna M., 2004, COMPUTERS ED J, V42, P267; HEINER C, 2004, P ITS2004 WORKSH AN, P1; HERAUD J, 2004, INT C INT TUT SYST W, P57; Hwang WY, 2004, COMPUT EDUC, V42, P267, DOI 10.1016/j.compedu.2003.08.004; IKSAL S, 2005, USAGE ANAL DRIVEN MO; Ingram A. L., 1999, Journal of Educational Technology Systems, V28, DOI 10.2190/R3AE-UCRY-NJVR-LY6F; Johnson S. D., 2000, Journal of Interactive Learning Research, V11; Klosgen W., 2002, HDB DATA MINING KNOW; KOUTRI M, 2004, SURVEY WEB USAGE MIN; LI J, 2004, INT C E COMM WEB TEC, P305; Lu J., 2004, INT C INF TECHN APPL, P374; LUAN J, 2002, WORKSH ASS I RES INT, P1; Ma Y, 2000, KDD 00 P 6 ACM SIGKD, P457; MARKHAM S, 2003, P EXPL ED TECHN C; MAZZA R, 2005, WORKSH US AN LEARN S; Merceron A., 2003, P 11 INT C ART INT E, P201; Merceron A., 2004, J INTERACTIVE LEARNI, V15, P319; MERCERON A, 2005, INTERACTIVE MULTIMED, V7, P267; MINAEIBIDGOLI B, 2004, INT C MACH LEARN APP; Minaei-Bidgoli B, 2003, LECT NOTES COMPUT SC, V2724, P2252; MONK D, 2005, ELECT J E LEARNING, V3, P41; Mor E., 2004, P 13 INT WORLD WID W, P264, DOI 10.1145/1013367.1013427; MOSTOW J, 2004, P ITS2004 WORKSH AN; Mostow J., 2005, P WORKSH ED DAT MIN, P15; MUEHLENBROCK M, 2005, AUTOMATIC ACTION ANA; Nilakant Karthik, 2005, P ART INT ED AIED, P896; PAHL C, 2003, P C E LEARN MONTR CA; Paulsen M. F., 2003, ONLINE ED LEARNING M; Peled A, 1999, J EDUC COMPUT RES, V21, P413; RAHKILA M, 1999, ASEE IEEE FRONT ED C, P16; Romero C, 2003, LECT NOTES ARTIF INT, V2702, P25; Romero C, 2006, DATA MINING E LEARNI; Romero C, 2004, USER MODEL USER-ADAP, V14, P425, DOI 10.1007/s11257-004-7961-2; SANJEEV P, 1995, KDD, P246; SHEARD J, 2003, J ED INFORM TECHNOLO, V8, P245; Shen R., 2003, J DISTANCE ED TECHNO, V1, P46; SHEN R, 2002, P 1 INT C ADV WEB BA, P19; Silva D., 2002, IEEE INT C ADV LEARN, P40; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12; Talavera L., 2004, WORKSH ART INT CSCL, P17; Tane J., 2004, P 13 INT WORLD WID W, P1, DOI 10.1145/1013367.1013369; Tang C., 2000, P 1 INT C WEB INF SY, V2, P204; Tang T., 2005, INT J E LEARNING, V4, P105; Tang TY, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P967; Tsakalidis A., 2005, P WEB BAS ED GRIND S, P461; TSANTIS L, 2001, J SPECIAL ED TECHNOL, V16; Ueno M., 2004, INT C COMP ADV TECHN, P248; UENO M, 2004, ICALT; Urbancic T, 2002, AI COMMUN, V15, P199; WANG F, 2002, C ED MULT HYP TEL DE, P2005; WANG W, 2004, ASEE IEEE FRONT ED C, P17; YU P, 2001, P ICCEE OSL BERG NOR; ZAIANE O, 1988, ADV DIGITAL LIB, P19; Zaiane OR, 2002, INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION, VOLS I AND II, PROCEEDINGS, P55; Zaiane O.R., 2001, P C ADV TECHN ED BAN, P60; ZARZO M, 2003, INT C NETW U E LEARN; Zorrilla M. E., 2005, WEB MIN WORKSH CAT	81	111	112	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2007	33	1					135	146		10.1016/j.eswa.2006.04.005		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	134UV	WOS:000244110600013	
J	Wen, JR; Nie, JY; Zhang, HJ				Wen, JR; Nie, JY; Zhang, HJ			Query clustering using user logs	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						algorithms; experimentation; performance; query clustering; web data mining; user log; search engine		Query clustering is a process used to discover frequently asked questions or most popular topics on a search engine. This process is crucial for search engines based on question-answering. Because of the short lengths of queries, approaches based on keywords are not suitable for query clustering. This paper describes a new query clustering method that makes use of user logs which allow us to identify the documents the users have selected for a query. The similarity between two queries may be deduced from the common documents the users selected for them. Our experiments show that a combination of both keywords and user logs is better than using either method alone.	Microsoft Res, Beijing Sigma Ctr 49, Beijing, Peoples R China; Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Wen, JR (reprint author), Microsoft Res, Beijing Sigma Ctr 49, Asia 5F,Zhichun Rd, Beijing, Peoples R China.						Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347176; de Lima E. F., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312669; Dubes R.C., 1988, ALGORITHMS CLUSTERIN; Ester M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Fitzpatrick L, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P306, DOI 10.1145/258525.258597; Garfield E., 1979, CITATION INDEXING; Gusfield D., 1997, ALGORITHMS STRINGS T; KESSLER MM, 1963, AM DOC, V14, P10, DOI 10.1002/asi.5090140103; Kleinberg J. M, 1998, P 9 ANN ACM SIAM S D, P668; KULYUKIN VA, 1998, P AAAI 98, V98, P532; Lewis David D., 1990, P 13 ANN INT ACM SIG, P385, DOI 10.1145/96749.98244; Lu Z., 2000, P 23 ANN INT ACM SIG, P248, DOI 10.1145/345508.345591; MILLER G, 1990, INT J LEXICOGR, V3, P4; Ng R, 1994, P 20 INT C VER LARG, P144; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; SALTON G, 1983, INTRO MODERN INFORMA; SRIHARI R, 1999, P TREC 8, P75; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; Voorhees E. M., 1995, P 18 ANN INT ACM SIG, P172, DOI 10.1145/215206.215357; Xu J., 1996, P 19 ANN INT ACM SIG, P4, DOI 10.1145/243199.243202	21	111	114	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	1046-8188		ACM T INFORM SYST	ACM Trans. Inf. Syst.	JAN	2002	20	1					59	81		10.1145/503104.503108		23	Computer Science, Information Systems	Computer Science	517AE	WOS:000173588300004	
J	Agrawal, R; Srikant, R				Agrawal, R; Srikant, R			Privacy-preserving data mining	SIGMOD RECORD			English	Article; Proceedings Paper	International Conference on Management of Data	MAY 16-18, 2000	DALLAS, TEXAS	Assoc Comp Machinery, Special Interest Grp Management Data			SECURITY	A fruitful direction for future data mining research will be the development of techniques that incorporate privacy concerns. Specifically, we address the following question. Since the primary task in data mining is the development of models about aggregated data, can we develop accurate models without access to precise information in individual data records? We consider the concrete case of building a decision-tree classifier from training data in which the values of individual records have been perturbed. The resulting data records look very different from the original records and the distribution of data values is also very different from the original distribution. While it is not possible to accurately estimate original values in individual data records, we propose a novel reconstruction procedure to accurately estimate the distribution of original data values. By using these reconstructed distributions, we are able to build classifiers whose accuracy is comparable to the accuracy of classifiers built with the original data.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Agrawal, R (reprint author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.						ACKERMAN MS, 1999, ACM C HUM FACT COMP; ADAM NR, 1989, COMPUT SURV, V21, P515; AGRAWAL R, 1999, 5 INT C KNOWL DISC D; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; Barbara D., 1997, SIGMOD Record, V26; BARBARA D, 1997, DATA ENG B, V20, P3; Beck L. L., 1980, ACM Transactions on Database Systems, V5, DOI 10.1145/320613.320617; Benassi P, 1999, COMMUN ACM, V42, P56, DOI 10.1145/293411.293461; Breiman L, 1984, CLASSIFICATION REGRE; CHIN FY, 1982, IEEE T SOFTWARE ENG, V8, P113; Clifton C., 1996, ACM SIGMOD WORKSH RE, P15; Conway R, 1976, P ACM ANN C, P85, DOI 10.1145/800191.805537; COX LH, 1980, J AM STAT ASSOC, V75, P377, DOI 10.2307/2287463; Cramer H, 1946, MATH METHODS STAT; CRANOR L, 1999, COMM ACM, V42; CRANOR LF, 1999, 9943 TR AT T LAB RES; Denning D. E., 1980, ACM Transactions on Database Systems, V5, DOI 10.1145/320613.320616; Denning D. E., 1979, ACM Transactions on Database Systems, V4, DOI 10.1145/320064.320069; Denning D.E., 1982, CRYPTOGRAPHY DATA SE; DINARDO CT, 1978, COMPUTERS SECURITY; Dobkin D., 1979, ACM Transactions on Database Systems, V4, DOI 10.1145/320064.320068; Engl H W, 1996, REGULARIZATION INVER; Estivill-Castro V., 1999, LECT NOTES COMPUTER, V1676, P389; Faloutsos C, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P36; FELLEGI IP, 1972, J AM STAT ASSOC, V67, P7, DOI 10.2307/2284695; Fisz M, 1963, PROBABILITY THEORY M; GOLDBERG I, 1997, IEEE COMPCON FEBR; HAGEL J, 1999, NET WORTH; HINE C, 1998, INFORMATION SOC, V42, P56; LAU T, 1999, COMMUN ACM, V42, P89; LEFONS E, 1983, 9 INT C VER LARG DAT, P260; LIEW CK, 1985, ACM T DATABASE SYST, V10, P395, DOI 10.1145/3979.4017; LOTSPIECH JB, 1999, Patent No. 5913030; Mehta M., 1996, P 5 INT C EXT DAT TE; Oppliger R, 1997, COMMUN ACM, V40, P92, DOI 10.1145/253769.253802; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; REISS SP, 1984, ACM T DATABASE SYST, V9, P20, DOI 10.1145/348.349; Rubin AD, 1998, COMPUTER, V31, P34, DOI 10.1109/2.708448; Shafer J., 1996, P 22 INT C VER LARG; Shoshani A., 1982, Proceedings of Very Large Data Bases. Eighth International Conference on Very Large Data Bases; Stachour P. D., 1990, IEEE Transactions on Knowledge and Data Engineering, V2, DOI 10.1109/69.54719; Taylor C.C., 1994, MACHINE LEARNING NEU; THEARLING K, 1998, DS               MAR; TRAUB JF, 1984, ACM T DATABASE SYST, V9, P672, DOI 10.1145/1994.383392; WARNER SL, 1965, J AM STAT ASSOC, V60, P63, DOI 10.2307/2283137; WESTIN A, 1998, E COMMERCE PRIVACY N; WESTIN A, 1998, PRIVACY CONCERNS CON; WESTIN AF, 1999, FREEBIES PRIVACY NET; YU CT, 1977, P ACM SIGMOD INT C M, P181; *EU, 1998, EU DIR PRIV PROT OCT; *OFF INF PRIV COMM, 1998, DAT MIN STAK CLAIM Y; *WORLD WID WEB CON, PLATF PRIV PREF P3P; 1999, ECONOMIST        MAY; 1997, TIME             AUG	54	111	111	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0163-5808		SIGMOD RECORD	Sigmod Rec.	JUN	2000	29	2					439	450				12	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	328UA	WOS:000087867500039	
J	Cheung, DW; Ng, VT; Fu, AW; Fu, YJ				Cheung, DW; Ng, VT; Fu, AW; Fu, YJ			Efficient mining of association rules in distributed databases	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; knowledge discovery; distributed data mining; association rule; distributed database; distributed algorithm; partitioned database		Many sequential algorithms have been proposed for mining of association rules. However, very little work has been done in mining association rules in distributed databases. A direct application of sequential algorithms to distributed databases is not effective, because it requires a large amount of communication overhead. In this study, an efficient algorithm, DMA, is proposed. It generates a small number of candidate sets and requires only O(n) messages for support count exchange for each candidate set, where n is the number of sites in a distributed database. The algorithm has been implemented on an experimental test bed and its performance is studied. The results show that DMA has superior performance when comparing with the direct application of a popular sequential algorithm in distributed databases.	HONG KONG POLYTECH UNIV,DEPT COMP,HONG KONG,HONG KONG; CHINESE UNIV HONG KONG,DEPT COMP SCI & ENGN,HONG KONG,HONG KONG; SIMON FRASER UNIV,SCH COMP SCI,BURNABY,BC V5A 1S6,CANADA	Cheung, DW (reprint author), UNIV HONG KONG,DEPT COMP SCI,HONG KONG,HONG KONG.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AGRAWAL R, 1996, RJ1004 IBM; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; AGRAWAL R, 1993, P 4 INT C FDN DAT OR; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; CHEUNG DW, 1996, P IEEE INT C DAT ENG; CHEUNG DW, 1994, P 1994 INT S METH IN, P164; Fayyad U.M., 1995, ADV KNOWLEDGE DISCOV; Frawley W. J., 1991, Knowledge discovery in databases; Geist A., 1994, PVM PARALLEL VIRTUAL; Han J, 1995, P 21 INT C VER LARG, P420; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Ng R, 1994, P 20 INT C VER LARG, P144; PARK J, 1995, P INT C INF KNOWL MA; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Savasere A, 1995, P 21 INT C VER LARG, P432; SILBERSCHATZ A, 1995, NSF WORKSH FUT DAT S; Srikant R., 1995, P 21 INT C VER LARG, P407; Ullman J. D., 1989, PRINCIPLES DATABASE, V1	22	110	127	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	DEC	1996	8	6					911	922		10.1109/69.553158		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	WC057	WOS:A1996WC05700005	
J	Ying, ATT; Murphy, GC; Ng, R; Chu-Carroll, MC				Ying, ATT; Murphy, GC; Ng, R; Chu-Carroll, MC			Predicting source code changes by mining change history	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						enhancement; maintainability; clustering; classification; association rules; data mining	SYSTEMS	Software developers are often faced with modification tasks that involve source which is spread across a code base. Some dependencies between source code, such as those between source code written in different languages, are difficult to determine using existing static and dynamic analyses. To augment existing analyses and to help developers identify relevant source code during a modification task, we have developed an approach that applies data mining techniques to determine change patterns-sets of files that were changed together frequently in the past-from the change history of the code base. Our hypothesis is that the change patterns can be used to recommend potentially relevant source code to a developer performing a modification task. We show that this approach can reveal valuable dependencies by applying the approach to the Eclipse and Mozilla open source projects and by evaluating the predictability and interestingness of the recommendations produced for actual modification tasks on these systems.	IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA; Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada	Ying, ATT (reprint author), IBM TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.	aying@us.ibm.coom; murphy@cs.ubc.ca; rng@cs.ubc.ca; markcc@us.ibm.com					Agrawal H., 1990, P ACM SIGPLAN 90 C P, P246, DOI DOI 10.1145/93542.93576; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Arnold R., 1996, SOFTWARE CHANGE IMPA; Baker B. S, 1992, COMPUTING SCI STAT, V24, P49; Baxter ID, 1998, PROC IEEE INT CONF S, P368, DOI 10.1109/ICSM.1998.738528; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Cheung W., 2003, Proceedings International Database Engineering and Applications Symposium; CUBRANIC D, P INT C SOFTW ENG, P408; Fischer M, 2003, PROC IEEE INT CONF S, P23, DOI 10.1109/ICSM.2003.1235403; Fischer M, 2003, P 10 WORK C REV ENG, P90; GALLAGHER KB, 1991, IEEE T SOFTWARE ENG, V17, P751, DOI 10.1109/32.83912; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Krinke J., 2001, Proceedings Eighth Working Conference on Reverse Engineering, DOI 10.1109/WCRE.2001.957835; LEBLANG DB, 1994, CM CHALLENGE CONFIGU; MAGNUSSON B, 1996, P 6 INT WORKSH SOFTW, P31; Mayrand J., 1996, Proceedings. International Conference on Software Maintenance (Cat. No.96CB36002), DOI 10.1109/ICSM.1996.565012; Michail A., 2000, Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium, DOI 10.1109/ICSE.2000.870408; Michail A., 1999, P 14 INT C AUT SOFTW, P24; Mockus A, 2001, IEEE SOFTWARE, V18, P30, DOI 10.1109/52.914737; Mockus A, 2002, ACM T SOFTW ENG METH, V11, P1; PARK JS, 1997, T KNOWLEDGE DATA ENG, P813; PARNAS DL, 1972, COMMUN ACM, V15, P1053, DOI 10.1145/361598.361623; Sartipi K., 2000, Proceedings of the Fourth European Conference on Software Maintenance and Reengineering, DOI 10.1109/CSMR.2000.827321; SHIRABAD JS, 2000, P C CTR ADV STUD COL; Tjortjis C, 2003, PROG COMPREHEN, P125; WEISER M, 1984, IEEE T SOFTWARE ENG, V10, P352; Zimmermann T, 2004, PROC INT CONF SOFTW, P563, DOI 10.1109/ICSE.2004.1317478; ZIMMERMANN T, 2003, P INT WORKSH PRINC S	29	109	113	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	SEP	2004	30	9					574	586		10.1109/TSE.2004.52		13	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	845HM	WOS:000223233000002	
J	Cho, YH; Kim, JK; Kim, SH				Cho, YH; Kim, JK; Kim, SH			A personalized recommender system based on web usage mining and decision tree induction	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						product recommendation; personalization; web usage mining; decision tree induction; Internet shopping mall		A personalized product recommendation is an enabling mechanism to overcome information overload occurred when shopping in an Internet marketplace. Collaborative filtering has been known to be one of the most successful recommendation methods, but its application to e-commerce has exposed well-known limitations such as sparsity and scalability, which would lead to poor recommendations. This paper suggests a personalized recommendation methodology by which we are able to get further effectiveness and quality of recommendations when applied to an Internet shopping mall. The suggested methodology is based on a variety of data mining techniques such as web usage mining, decision tree induction, association rule mining and the product taxonomy. For the evaluation of the methodology, we implement a recommender system using intelligent agent and data warehousing technologies. (C) 2002 Elsevier Science Ltd. All rights reserved.	Korea Adv Inst Sci & Technol, Grad Sch Management, Seoul 130012, South Korea; Kyung Hee Univ, Sch Business Adm, Seoul 130701, South Korea	Cho, YH (reprint author), Korea Adv Inst Sci & Technol, Grad Sch Management, 207-43 Cheongryangri Dong, Seoul 130012, South Korea.		Kim, Soung Hie/C-1863-2011				Agrawal R., 1993, INT P ACM SIGMOD INT, P207; Agrawal R., 1994, P INT C VER LARG DAT, P407; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Basu C., 1998, P 1998 WORKSH REC SY, P11; BEIMAN L, 1984, CLASSIFICATION REGRE; Berry J.A., 2000, MASTERING DATA MININ; Berry J.A.M., 1997, DATA MINING TECHNIQU; Berson Alex, 2000, BUILDING DATA MINING; Changchien SW, 2001, EXPERT SYST APPL, V20, P325, DOI 10.1016/S0957-4174(01)00017-3; CLAYPOOL M, 1999, ACM SIGIR 99 WORKSH; Cooley R., 1999, J KNOWLEDGE INFORMAT, P1; Han J., 2001, DATA MINING CONCEPTS; HAN J, 1995, P INT C LARG DAT BAS; Hill W, 1995, P ACM CHI 95 C HUM F, P194, DOI 10.1145/223904.223929; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Kim E, 2000, INT C EL COMM 2000, P274; Kim JW, 2001, INT J ELECTRON COMM, V5, P45; Konstan J., 2000, P 2 ACM C EL COMM, P158, DOI DOI 10.1145/352871.352887; Lawrence RD, 2001, DATA MIN KNOWL DISC, V5, P11, DOI 10.1023/A:1009835726774; Lee DT, 2001, IEEE COMMUN LETT, V5, P1; Loh WY, 1997, STAT SINICA, V7, P815; Menasce D., 1999, P 1 ACM C EL COMM, P119, DOI 10.1145/336992.337024; Mobasher B, 2000, P INT C E COMM WEB T, P165; Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169; Mulvenna MD, 2000, COMMUN ACM, V43, P123; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Srikant R., 1995, P INT C VER LARG DAT; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P1; VANDERMEER D, 2000, P ACM E COMM 2000 C, P185, DOI 10.1145/352871.352892; Yuan ST, 2001, EXPERT SYST APPL, V20, P187, DOI 10.1016/S0957-4174(00)00058-0	34	108	113	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	OCT	2002	23	3					329	342		10.1016/S0957-4174(02)00052-0		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	598FC	WOS:000178264000015	
B	Garofalakis, MN; Rastogi, R; Shim, K		Atkinson, M; Orlowska, ME; Valduriez, P; Zdonik, S; Brodie, M		Garofalakis, MN; Rastogi, R; Shim, K			SPIRIT: Sequential pattern mining with regular expression constraints	PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES			English	Proceedings Paper	25th International Conference on Very Large Data Bases	SEP 07-10, 1999	EDINBURGH, SCOTLAND	ORACLE, Sun Microsyst, IBM, Microsoft SQL Server, Scottish Widows				Discovering sequential patterns is an important problem in data mining with a host of application domains including medicine, telecommunications, and the World Wide Web. Conventional mining systems provide users with only a very restricted mechanism (based on minimum support) for specifying patterns of interest. In this paper, we propose the use of Regular Expressions (REs) as a flexible constraint specification tool that enables user-controlled focus to be incorporated into the pattern mining process. We develop a family of novel algorithms (termed SPIRIT - Sequential Pattern mining with Regular expression consTraints) for mining frequent sequential patterns that also satisfy user-specified RE constraints. The main distinguishing factor among the proposed schemes is the degree to which the RE constraints are enforced to prune the search space of patterns during computation. Our solutions provide valuable insights into the tradeoffs that arise when constraints that do not subscribe to nice properties (like anti-monotonicity) are integrated into the mining process. A quantitative exploration of these tradeoffs is conducted through an extensive experimental study on synthetic and real-life data sets.	Bell Labs, Murray Hill, NJ 07974 USA	Garofalakis, MN (reprint author), Bell Labs, 600 Mt Ave, Murray Hill, NJ 07974 USA.						AGRAWAL R, 1995, P 11 INT C DAT ENG M; Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R., 1995, P 21 INT C VER LARG; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; GAROFALAKIS MN, 1999, BL011237099022303TM; Lewis H. R., 1981, ELEMENTS THEORY COMP; Mannila H., 1995, P 1 INT C KNOWL DISC; MANNILA H, 1996, P 2 INT C KNOWL DISC; NG RT, 1998, P 1998 ACM SIGMOD IN; SRIKANT R, 1997, P 3 INT C KNOWL DISC; Srikant R., 1996, P 5 INT C EXT DAT TE; WANG JTL, 1994, P 1994 ACM SIGMOD IN	12	108	121	MORGAN KAUFMANN PUB INC	SAN FRANCISCO	340 PINE STR, 6TH FLR, SAN FRANCISCO, CA 94104-3205 USA		1-55860-615-7				1999							223	234				10	Computer Science, Information Systems	Computer Science	BQ81V	WOS:000089669900022	
J	Pedrycz, W				Pedrycz, W			Conditional fuzzy C-Means	PATTERN RECOGNITION LETTERS			English	Article						fuzzy clustering; Fuzzy C-Means; conditional variable; data mining; radial basis functions		A Fuzzy C-Means-based clustering method guided by an auxiliary (conditional) variable is introduced. The method reveals a structure within a family of patterns by considering their vicinity in a feature space along with the similarity of the values assumed by a certain conditional variable. The usefulness of the algorithm is exemplified in the problems of data mining.		Pedrycz, W (reprint author), UNIV MANITOBA,DEPT ELECT & COMP ENGN,WINNIPEG,MB R3T 5V6,CANADA.						Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873; Chambers J. M., 1983, GRAPHICAL METHODS DA; DAVE R, 1992, PATTERN RECOGN, V12, P657; HATHAWAY RJ, 1994, PATTERN RECOGN, V27, P429, DOI 10.1016/0031-3203(94)90119-8; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; RUSPINI EH, 1970, INFORM SCIENCES, V2, P319, DOI 10.1016/S0020-0255(70)80056-1; ZADEH LA, 1977, CLASSIFICATION CLUST, P251	8	108	115	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAY 15	1996	17	6					625	631		10.1016/0167-8655(96)00027-X		7	Computer Science, Artificial Intelligence	Computer Science	UR048	WOS:A1996UR04800009	
J	Peng, Y; Kou, G; Shi, Y; Chen, ZX				Peng, Yi; Kou, Gang; Shi, Yong; Chen, Zhengxin			A DESCRIPTIVE FRAMEWORK FOR THE FIELD OF DATA MINING AND KNOWLEDGE DISCOVERY	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING			English	Article						Grounded theory; knowledge discovery; descriptive framework; document clustering	DATABASES	Despite the rapid development, the field of data mining and knowledge discovery (DMKD) is still vaguely defined and lack of integrated descriptions. This situation causes difficulties in teaching, learning, research, and application. This paper surveys a large collection of DMKD literature to provide a comprehensive picture of current DMKD research and classify these research activities into high-level categories using grounded theory approach; it also evaluates the longitudinal changes of DMKD research activities during the last decade.	[Peng, Yi; Kou, Gang] Univ Elect Sci & Technol China, Sch Management & Econ, Chengdu 610054, Peoples R China; [Shi, Yong] CAS Res Ctr Fictitious Econ & Data Sci, Beijing 100080, Peoples R China; [Shi, Yong; Chen, Zhengxin] Univ Nebraska, Coll Informat Sci & Technol, Omaha, NE 68182 USA	Kou, G (reprint author), Univ Elect Sci & Technol China, Sch Management & Econ, Chengdu 610054, Peoples R China.	pengyi@uestc.edu.cn; kougang@yahoo.com; yshi@gscas.ac.cn; zchen@mail.unomaha.edu					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; ANCONA DG, 1990, ACAD MANAGE J, V33, P334, DOI 10.2307/256328; Bacon C. J., 2001, Data Base for Advances in Information Systems, V32; Bar-Or A, 2005, IEEE T KNOWL DATA EN, V17, P1138, DOI 10.1109/TKDE.2005.129; Baskerville R., 1999, ACCOUNTING MANAGEMEN, V9, P1, DOI 10.1016/S0959-8022(98)00017-4; Beck C T, 1996, Issues Compr Pediatr Nurs, V19, P1, DOI 10.3109/01460869609026851; Chen ZX, 2006, INT J INF TECH DECIS, V5, P703, DOI 10.1142/S0219622006002271; Cheng SW, 2006, INT J INF TECH DECIS, V5, P585, DOI 10.1142/S021962200600226X; CONRAD JG, 2005, P ICAIL 2005, P177, DOI 10.1145/1165485.1165513; Denzin N., 1978, RES ACT; Dick B., 2005, GROUNDED THEORY THUM; DNUGGETS K, 2005, POLLS DATA MINING TX; Dzeroski S., 2003, ACM SIGKDD EXPLORATI, V5, P1, DOI 10.1145/959242.959245; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; FAYYAD U, 1998, ADV KNOWLEDGE DISCOV; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FRIEDMAN J, 1997, P 29 S INT COMP SCI; GEIST I, 2002, P ACM S APPL COMP, P508; Getoor L., 2003, ACM SIGKDD EXPLORATI, V5, P84, DOI 10.1145/959242.959253; Glaser B.G., 1967, DISCOVERY GROUNDED T; Han J, 2006, DATA MINING CONCEPTS; Han J., 2000, DATA MINING CONCEPTS; HO TB, 2005, ADV KNOWLEDGE DISCOV, V3518; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JICK TD, 1979, ADMIN SCI QUART, V24, P602, DOI 10.2307/2392366; KDNUGGETS, 2007, M C DAT MIN KNOWL DI; Kleinberg J, 1998, DATA MIN KNOWL DISC, V2, P311, DOI 10.1023/A:1009726428407; KOGAN J, 2003, TUT ACM 14 C INF KNO; Kosala R., 2000, ACM SIGKDD EXPLORATI, V2, P1, DOI DOI 10.1145/360402.360406; Lin W., 2002, P 1 AUSTR DAT MIN WO, P83; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Macskassy S. A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Mannila H, 1999, LECT NOTES ARTIF INT, V1634, P14; MARTIN PY, 1986, J APPL BEHAV SCI, V22, P141, DOI 10.1177/002188638602200207; Nolan R. L., 1980, MIS Q, V4, P1, DOI 10.2307/249333; ORLIKOWSKI WJ, 1993, MIS QUART, V17, P309, DOI 10.2307/249774; PECHENIZKIY M, 2004, P ICDM 04 FDN DAT MI, P139; PENG Y, 2006, P 3 IEEE SSSM 2006 I; PENG Y, 2006, P WORKSH 6 IEEE INT; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Sarker S., 2001, Data Base for Advances in Information Systems, V32; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Schuster A, 2004, DATA MIN KNOWL DISC, V8, P171, DOI 10.1023/B:DAMI.0000015870.80026.6a; SHI Y, 2005, INT J INFORM TECH DE, V4; Shi Y., 2002, INT J INFORMATION TE, V1, P131, DOI 10.1142/S0219622002000038; SI L, 2005, P 9 PAC AS C, P622; SIMOFF SJ, 2002, SIGKDD EXPLOR NEWSLE, V4, P118; Strauss A., 1990, BASICS QUALITATIVE R; Thurston WE, 2005, HEALTH POLICY, V73, P237, DOI 10.1016/j.healthpol.2004.11.013; Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258; YAO YY, 2004, P ICDM 04 WORKSH FDN, P215; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6; ZHAO Y, 2003, FUNCTIONAL GENOMICS; Zhao Y., 2001, 0140 U MINN DEP COMP; *MICR CORP, 2005, MICR SQL SERV; *UCI, 2006, MACH LEARN REP; *UCI, 2006, KDD ARCH	60	107	107	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-6220		INT J INF TECH DECIS	Int. J. Inf. Technol. Decis. Mak.	DEC	2008	7	4					639	682				44	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	389NO	WOS:000262100300005	
J	Lingras, P; West, C				Lingras, P; West, C			Interval set clustering of web users with rough K-means	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						clustering; interval sets; K-means algorithm; rough sets; unsupervised learning; web mining	CLASSIFICATION	Data collection and analysis in web mining faces certain unique challenges. Due to a variety of reasons inherent in web browsing and web logging, the likelihood of bad or incomplete data is higher than conventional applications. The analytical techniques in web mining need to accommodate such data. Fuzzy and rough sets provide the ability to deal with incomplete and approximate information. Fuzzy set theory has been shown to be useful in three important aspects of web and data mining, namely clustering, association, and sequential analysis. There is increasing interest in research on clustering based on rough set theory. Clustering is an important part of web mining that involves finding natural groupings of web resources or web users. Researchers have pointed out some important differences between clustering in conventional applications and clustering in web mining. For example, the clusters and associations in web mining do not necessarily have crisp boundaries. As a result, researchers have studied the possibility of using fuzzy sets in web mining clustering applications. Recent attempts have used genetic algorithms based on rough set theory for clustering. However, the genetic algorithms based clustering may not be able to handle the large amount of data typical in a web mining application. This paper proposes a variation of the K-means clustering algorithm based on properties of rough sets. The proposed algorithm represents clusters as interval or rough sets. The paper also describes the design of an experiment including data collection and the clustering process. The experiment is used to create interval set representations of clusters of web visitors.	St Marys Univ, Halifax, NS B3H 3C3, Canada	Lingras, P (reprint author), St Marys Univ, Halifax, NS B3H 3C3, Canada.	Pawan.Lingras@StMarys.CA					DOPRADO HA, 2002, LECT NOTES ARTIFICIA, V2475; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Hathaway R. J., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.236552; HIRANO S, 2000, J INF SCI, V124, P125; JOACHIMS T, 1995, AAAI SPRING S INF GA; Joshi A., 1998, P WORKSH DAT MIN KNO; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; KRISHNAPURAM R, 1995, IEEE T FUZZY SYST, V3, P29, DOI 10.1109/91.366564; Lingras P, 2002, P 2002 IEEE INT C FU; LINGRAS P, 2002, UNPUB INTELLIGENCE R; Lingras P, 2001, J INTELL INF SYST, V16, P215, DOI 10.1023/A:1011219918340; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; PAWLAK Z, 1984, INT J MAN MACH STUD, V20, P469, DOI 10.1016/S0020-7373(84)80022-X; Pawlak Z, 1982, INT J INFORMATION CO, P145; Pawlak Z., 1992, ROUGH SETS THEORETIC; Perkowitz M., 1999, P 16 INT JOINT C ART; PERKOWITZ M, 1997, P 15 INT JOINT C ART; Peters JF, 2002, SOFT COMPUTING DISTR, P57; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Skowron A, 1999, LECT NOTES ARTIF INT, V1711, P357; Voges KE, 2002, HEURISTICS OPTIMIZAT, P208; VOGES KE, 2002, HEURISTICS OPTIMIZAT, P217; YAO YY, 1994, P 3 INT WORKSH ROUGH, P630	23	107	131	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	JUL	2004	23	1					5	16		10.1023/B:JIIS.0000029668.88665.1a		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	825GU	WOS:000221745000001	
J	Verykios, VS; Bertino, E; Fovin, IN; Provenza, LP; Saygin, Y; Theodoridis, Y				Verykios, VS; Bertino, E; Fovin, IN; Provenza, LP; Saygin, Y; Theodoridis, Y			State-of-the-art in privacy preserving data mining	SIGMOD RECORD			English	Article								We provide here an overview of the new and rapidly emerging research area of privacy preserving data mining. We also propose a classification hierarchy that sets the basis for analyzing the work which has been performed in this context. A detailed review of the work accomplished in this area is also given, along with the coordinates of each work to the classification hierarchy. A brief evaluation is performed, and some initial conclusions are made.	Acad & Res Comp Technol Inst, Athens, Greece; Univ Milan, Dipartimento Sci Informaz, I-20122 Milan, Italy; SABANCI Univ, Fac Engn & Nat Sci, Istanbul, Turkey	Verykios, VS (reprint author), Acad & Res Comp Technol Inst, Athens, Greece.						ADAM NR, 1989, COMPUT SURV, V21, P515; Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; Atallah M, 1999, P 1999 IEEE KNOWL DA, P45; Chang L., 1998, P NEW SEC PAR, P82, DOI 10.1145/310889.310921; CHANG L, 2000, DATA APPL SECURITY, P161; Chcung D.W., 1996, P 1996 INT C PAR DIS; Clifton C, 2002, SIGKDD EXPLORATIONS, V4; Clifton C., 1996, P ACM SIGMOD WORKSH, P15; Dasseni E, 2001, P 4 INF HID WORKSH P, P369; DU W, 2001, 200151 CERIAS PURD U; DU W, 2002, P IEEE ICDM WORKSH P; EVFIMIEVSKI A, 2002, P 8 ACM SIGKDDD INT; IOANNIDIS I, 2002, P INT C PAR PROC; Kantarcioglou Murat, 2002, P ACM SIGMOD WORKSH, P24; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; MOSKOWITZ I, 2000, P 5 JOINT C INF SCI; O'Leary DE, 1991, P 1 INT C KNOWL DISC, P107; Rizvi S., 2002, P 28 INT C VER LARG; Saygin Y, 2001, SIGMOD RECORD, V30, P45; Saygin Y, 2002, PR GR LAK SYMP VLSI, P151, DOI 10.1109/RIDE.2002.995109; STANLEY RM, 2002, P IEEE ICDM WORKSH P, P43; Vaidya J., 2002, 8 ACM SIGKDD INT C K, P639, DOI [10.1145/775047.775142, DOI 10.1145/775047.775142]; Verykios Vassilios S., 2003, IEEE T KNOWLEDGE DAT	24	107	115	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0163-5808		SIGMOD REC	Sigmod Rec.	MAR	2004	33	1					50	57				8	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	803OX	WOS:000220241500009	
J	Boros, E; Hammer, PL; Ibaraki, T; Kogan, A; Mayoraz, E; Muchnik, I				Boros, E; Hammer, PL; Ibaraki, T; Kogan, A; Mayoraz, E; Muchnik, I			An implementation of logical analysis of data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; knowledge discovery; machine learning; classification; Boolean functions; patterns; decision support	CLASSIFICATION	The paper describes a new, logic-based methodology for analyzing observations. The key features of the Logical Analysis of Data (LAD) are the discovery of minimal sets of features necessary for explaining all observations and the detection of hidden patterns in the data capable of distinguishing observations describing "positive" outcome events from "negative" outcome events. Combinations of such patterns are used for developing general classification procedures. An implementation of this methodology is described in the paper along with the results of numerical experiments demonstrating the classification performance of LAD in comparison with the reported results of other procedures. In the final section, we describe three pilot studies on applications of LAD to oil exploration, psychometric testing, and the analysis of developments in the Chinese transitional economy. These pilot studies demonstrate not only the classification power of LAD, but also its flexibility and capability to provide solutions to various case-dependent problems.	Rutgers State Univ, Ctr Operat Res, Piscataway, NJ 08854 USA; Rutgers State Univ, Fac Management, Newark, NJ 07102 USA; Kyoto Univ, Grad Sch Engn, Dept Appl Math & Phys, Kyoto 606, Japan; Inst Dalle Molle Intelligence Artificielle Percep, CH-1920 Martigny, Switzerland	Boros, E (reprint author), Rutgers State Univ, Ctr Operat Res, 640 Bartholomew Rd, Piscataway, NJ 08854 USA.						ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Bores E, 1998, INFORM COMPUT, V140, P254; Boros E, 1999, ARTIF INTELL, V107, P219, DOI 10.1016/S0004-3702(98)00110-6; BOROS E, 1996, P ALG THEOR SWAT 96, P440; CARTER C, 1987, IEEE EXPERT      FAL, P71; CHARNES A, 1978, EUR J OPER RES, V2, P429, DOI 10.1016/0377-2217(78)90138-8; Crama Y., 1988, Annals of Operations Research, V16, DOI 10.1007/BF02283750; Hammer AB, 1999, ANN OPER RES, V87, P165, DOI 10.1023/A:1018920600320; HAMMER AB, 1995, THESIS BRANDEIS U WA; Hammer AB, 1999, ANN OPER RES, V87, P153, DOI 10.1023/A:1018968516250; HERMAN GT, 1992, IEEE T PATTERN ANAL, V14, P782, DOI 10.1109/34.142914; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; MAYORAZ E, 1995, 195 RTR RUTG U; MUCHNIK I, 1995, 295 RTR RUTG U; Murphy P., 1994, UCI REPOSITORY MACHI; Murthy S, 1994, J ARTIFICIAL INTELLI, V2, P1; P Hammer, 1986, P INT C MULT DEC MAK; SENJU S, 1968, MANAGE SCI, V15, pB196; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1)	20	107	108	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR-APR	2000	12	2					292	306				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	315KL	WOS:000087112900010	
J	Zhang, ML; Zhou, ZH				Zhang, Min-Ling; Zhou, Zhi-Hua			Multilabel neural networks with applications to functional genomics and text categorization	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						machine learning; data mining; multilabel learning; neural networks; backpropagation; functional genomics; text categorization	CLASSIFICATION	In multilabel learning, each instance in the training set is associated with a set of labels and the task is to output a label set whose size is unknown a priori for each unseen instance. In this paper, this problem is addressed in the way that a neural network algorithm named BP-MLL, i.e., Backpropagation for Multilabel Learning, is proposed. It is derived from the popular Backpropogation algorithm through employing a novel error function capturing the characteristics of multilabel learning, i.e., the labels belonging to an instance should be ranked higher than those not belonging to that instance. Applications to two real-world multilabel learning problems, i.e., functional genomics and text categorization, show that the performance of BP-MLL is superior to that of some well-established multilabel learning algorithms.	Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhang, ML (reprint author), Nanjing Univ, Natl Lab Novel Software Technol, Mailbox 419,Hankou Rd 22, Nanjing 210093, Peoples R China.	zhangml@lamda.nju.edu.cn; zhouzh@lamda.nju.edu.cn					Bishop CM, 1995, NEURAL NETWORKS PATT; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Clare A., 2003, THESIS U WALES ABERY; Clare A., 2001, LECT NOTES COMPUTER, P42; Comite F., 2003, LECT NOTES COMPUTER, V2734, P35; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Gao S., 2003, P 26 ANN INT ACM SIG, P174; Gao S., 2004, P 21 INT C MACH LEAR, P329; Haykin S., 1999, NEURAL NETWORKS COMP; JIN R, 2003, ADV NEURAL INFORM PR, V15, P897; Joachims T, 2002, J INTELL INF SYST, V18, P103, DOI 10.1023/A:1013652626023; Kazawa H., 2005, ADV NEURAL INFORM PR, V17, P649; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; McCallum A., 1999, P WORK NOT AM ASS AR; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Minsky M., 1969, PERCEPTRONS; Pavlidis P., 2001, P 5 INT C COMP MOL B, P242; Quinlan JR, 1993, PROGRAMS MACHINE LEA; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; SALTON G, 1991, SCIENCE, V253, P974, DOI 10.1126/science.253.5023.974; Salton G., 1989, AUTOMATIC TEXT PROCE; Schapire R. E., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279960; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Ueda N., 2003, ADV NEURAL INFORMATI, V15, P721; Widrow B., 1960, IRE Wescon Convention Record, V4; Yang Y, 1997, P 14 INT C MACH LEAR, P412; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651	34	106	122	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	OCT	2006	18	10					1338	1351				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	074LV	WOS:000239814600004	
J	Omiecinski, ER				Omiecinski, ER			Alternative interest measures for mining associations in databases	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; associations; interest measures; databases; performance		Data mining is defined as the process of discovering significant and potentially useful patterns in large volumes of data. Discovering associations between items in a large database is one such data mining activity. In finding associations, support is used as an indicator as to whether an association is interesting. In this paper, we discuss three alternative interest measures for associations: any-confidence, all-confidence, and bond, We prove that the important downward closure property applies to both all-confidence and bond. We show that downward closure does not hold for any-confidence. We also prove that, if associations have a minimum all confidence or minimum bond, then those associations will have a given lower bound on their minimum support and the rules produced from those associations will have a given lower bound on their minimum confidence as well. However, associations that have that minimum support (and likewise their rules that have minimum confidence) may not satisfy the minimum all-confidence or minimum bond constraint. We describe the algorithms that efficiently find all associations with a minimum all-confidence or minimum bond and present some experimental results.	Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Omiecinski, ER (reprint author), Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.						AGGARWAL C, 1998, P INT C DAT ENG FEB; Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal RC, 2000, P 6 ACM SIGKDD INT C, P108; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; BRIN S, 1998, P ACM SIGMOD C, P255; COOLEY R, 1999, P WEBKDD WORKSH; HAN EH, 1997, P ACM SIGMOD INT C M, P277, DOI 10.1145/253260.253330; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J, 1995, P 21 INT C VER LARG, P420; HIDBER C, 1999, P ACM SIGMOD INT C M, P145, DOI 10.1145/304182.304195; HOUTSMA M, 1995, P INT C DAT ENG MAR; LAKSHMANAN LVS, 1999, P 1999 ACM SIGMOD IN, P157, DOI 10.1145/304182.304196; Ma Y., 1999, P 5 ACM SIGKDD INT C, P337, DOI 10.1145/312129.312274; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Morimoto Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; PARK JS, 1995, P ACM SIGMOD C MAN D, P229; PEI J, 2000, P 2000 ACM KNOWL DIS; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Ramaswamy S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; SALTON G, 1983, INTRO MODERN INFORMA; SAVASERE A, 1998, P IEEE DAT ENG C FEB; Savasere A, 1995, P 21 INT C VER LARG, P432; Srikant R., 1995, P 21 INT C VER LARG, P407; Zaki M. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347101	28	106	114	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN-FEB	2003	15	1					57	69		10.1109/TKDE.2003.1161582		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	632NW	WOS:000180230300005	
J	Huang, ZX; Ng, MK				Huang, ZX; Ng, MK			A fuzzy k-modes algorithm for clustering categorical data	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						categorical data; clustering; data mining; fuzzy partitioning; k -means algorithm	CONVERGENCE THEOREM; C-MEANS; OPTIMALITY	This correspondence describes extensions to the fuzzy k-means algorithm for clustering categorical data. By using a simple matching dissimilarity measure for categorical objects and modes instead of means for clusters, a new approach is developed, which allows the use of the k-means paradigm to efficiently cluster large categorical data sets. A fuzzy k-modes algorithm is presented and the effectiveness of the algorithm is demonstrated with experimental results.	Management Informat Principles Ltd, Melbourne, Vic, Australia; Univ Hong Kong, Dept Math, Hong Kong, Hong Kong	Huang, ZX (reprint author), Management Informat Principles Ltd, Melbourne, Vic, Australia.		Ng, Michael/B-7189-2009; HKBU, Mathematics/B-5086-2009				Anderberg M.R., 1973, CLUSTER ANAL APPL; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; HATHAWAY RJ, 1986, PATTERN RECOGN, V19, P477, DOI 10.1016/0031-3203(86)90047-6; HUANG Z, 1998, DATA MINING KNOWLEDG, V2; ISMAIL MA, 1986, PATTERN RECOGN, V19, P481, DOI 10.1016/0031-3203(86)90048-8; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kaufman L., 1990, FINDING GROUPS DATA; Kohonen T, 1980, CONTENT ADDRESSABLE; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; MICHALSKI RS, 1983, IEEE T PATTERN ANAL, V5, P396; Ng R, 1994, P 20 INT C VER LARG, P144; RALAMBONDRAINY H, 1995, PATTERN RECOGN LETT, V16, P1147, DOI 10.1016/0167-8655(95)00075-R; Ruspini E. R., 1969, INFORM CONTR, V15, P22; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; Woodbury M. A., 1974, Journal of Cybernetics, V4	18	106	125	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	AUG	1999	7	4					446	452				7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	228ZR	WOS:000082167900006	
J	HU, XH; CERCONE, N				HU, XH; CERCONE, N			LEARNING IN RELATIONAL DATABASES - A ROUGH SET APPROACH	COMPUTATIONAL INTELLIGENCE			English	Article						KNOWLEDGE DISCOVERY IN DATABASES; MACHINE LEARNING; ROUGH SET; ATTRIBUTE-ORIENTED INDUCTION		Knowledge discovery in databases, or data mining, is an important direction in the development of data and knowledge-based systems. Because of the huge amount of data stored in large numbers of existing databases, and because the amount of data generated in electronic forms is growing rapidly, it is necessary to develop efficient methods to extract knowledge from databases. An attribute-oriented rough set approach has been developed for knowledge discovery in databases. The method integrates machine-learning paradigm, especially learning-from-examples techniques, with rough set techniques. An attribute-oriented concept tree ascension technique is first applied in generalization, which substantially reduces the computational complexity of database learning processes. Then the cause-effect relationship among the attributes in the database is analyzed using rough set techniques, and the unimportant or irrelevant attributes are eliminated. Thus concise and strong rules with little or no redundant information can be learned efficiently. Our study shows that attribute-oriented induction combined with rough set theory provide an efficient and effective mechanism for knowledge discovery in database systems.		HU, XH (reprint author), UNIV REGINA,DEPT COMP SCI,REGINA,SK S4S 0A2,CANADA.						Cai Y., 1991, Knowledge discovery in databases; DIETTERICH TG, 1983, MACHINE LEARNING ART, V1, P43; Frawley W. J., 1991, Knowledge discovery in databases; Grzymala-Busse J. W., 1988, Journal of Intelligent and Robotic Systems: Theory and Applications, V1, DOI 10.1007/BF00437317; HAN J, 1992, 18TH P VLDB C VANC, P340; Kaufman K. A., 1991, Knowledge discovery in databases; MANAGO M, 1987, P IJCAI87 MIL, P348; MICKALSKI RS, 1983, MACHINE LEARING ARTI, V1, P41; PAWLAK Z, 1990, ICS1192 WARS U TECHN; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; SILBERSCHATZ A, 1991, COMMUN ACM, V34, P94; ZIARKO W, 1990, KNOWLEDGE DISCOVERY, P213; ZYTKOW J, 1990, KNOWLEDGE DISCOVERY, P31	13	105	284	BLACKWELL PUBLISHERS	CAMBRIDGE	238 MAIN STREET, CAMBRIDGE, MA 02142	0824-7935		COMPUT INTELL	Comput. Intell.	MAY	1995	11	2					323	338		10.1111/j.1467-8640.1995.tb00035.x		16	Computer Science, Artificial Intelligence	Computer Science	TD200	WOS:A1995TD20000008	
J	Yang, Q; Wu, XD				Yang, Qiang; Wu, Xindong			10 Challenging problems in data mining research	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING			English	Article; Proceedings Paper	278th Xiangshan Sciences Forum on Frontier Studies on Data Technology and Knowledge Economy	MAY 22-24, 2006	Beijing, PEOPLES R CHINA	Comm Xiangshan Sci, Western Union Financial Serv		data mining; machine learning; knowledge discovery		In October 2005, we took an initiative to identify 10 challenging problems in data mining research, by consulting some of the most active researchers in data mining and machine learning for their opinions on what are considered important and worthy topics for future research in data mining. We hope their insights will inspire new research efforts, and give young researchers (including PhD students) a high-level guideline as to where the hot problems are located in data mining. Due to the limited amount of time, we were only able to send out our survey requests to the organizers of the IEEE ICDM and ACM KDD conferences, and we received an overwhelming response. We are very grateful for the contributions provided by these researchers despite their busy schedules. This short article serves to summarize the 10 most challenging problems of the 14 responses we have received from this survey. The order of the listing does not reflect their level of importance.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA	Yang, Q (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.	xwu@cs.uvm.edu						0	104	122	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-6220		INT J INF TECH DECIS	Int. J. Inf. Technol. Decis. Mak.	DEC	2006	5	4					597	604		10.1142/S0219622006002258		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	123TK	WOS:000243318400003	
J	Verykios, VS; Elmagarmid, AK; Bertino, E; Saygin, Y; Dasseni, E				Verykios, VS; Elmagarmid, AK; Bertino, E; Saygin, Y; Dasseni, E			Association rule hiding	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						privacy preserving data mining; association rule mining; sensitive rule hiding		Large repositories of data contain sensitive information that must be protected against unauthorized access. The protection of the confidentiality of this information has been a long-term goal for the database security research community and for the government statistical agencies. Recent advances in data mining and machine learning algorithms have increased the disclosure risks that one may encounter when releasing data to outside parties. A key problem, and still not sufficiently investigated, is the need to balance the confidentiality of the disclosed data with the legitimate needs of the data users. Every disclosure limitation method affects, in some way, and modifies true data values and relationships. In this paper, we investigate confidentiality issues of a broad category of rules, the association rules. In particular, we present three strategies and five algorithms for hiding a group of association rules, which is characterized as sensitive. One rule is characterized as sensitive if its disclosure risk is above a certain privacy threshold. Sometimes, sensitive rules should not be disclosed to the public since, among other things, they may be used for inferring sensitive data or they may provide business competitors with an advantage. We also perform an evaluation study of the hiding algorithms in order to analyze their time complexity and the impact that they have in the original database.	Comp Technol Inst, Data & Knowledge Engn Grp, Patras 26221, Greece; Hewlett Packard Corp, Off Strategy & Technol, Palo Alto, CA USA; Univ Milan, Dept Comp Sci, I-20135 Milan, Italy; Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Istanbul, Turkey; TXT E Solut SpA, I-20126 Milan, Italy	Verykios, VS (reprint author), Comp Technol Inst, Data & Knowledge Engn Grp, 3 Kolokotroni St, Patras 26221, Greece.	verykios@cti.gr; ahmed_elmagarmid@hp.com; bertino@dsi.unimi.it; ysaygin@sabanciuniv.edu; elena.dasseni@txtgroup.it					ADAM NR, 1989, COMPUT SURV, V21, P515; AGRAWAL D, 2001, P ACM PODS C; Agrawal R., 2000, P ACM SIGMOD C; ATALLAH M, 1999, P KNOWL DAT EXCH WOR; CLIFTON C, 1996, P 1996 ACM WORKSH DA; CLIFTON C, 1999, P 13 IFIP WG11 3 C D; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; JOHNSTEN T, 1999, P 13 IFIP WG11 3 C D; Marks DG, 1996, IEEE T KNOWL DATA EN, V8, P46, DOI 10.1109/69.485628; O'Leary DE, 1991, P 1 INT C KNOWL DISC, P107; THURAISINGHAM B, 1995, IEEE T KNOWL DATA EN, V7, P274, DOI 10.1109/69.382297	11	103	113	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2004	16	4					434	447		10.1109/TKDE.2004.1269668		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	803VJ	WOS:000220258300005	
J	Cios, KJ; Moore, GW				Cios, KJ; Moore, GW			Uniqueness of medical data mining	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						medical data mining; unique features of medical data mining and knowledge discovery; ethical; security and legal aspects of medical data mining	KNOWLEDGE DISCOVERY APPROACH; CARDIAC SPECT DIAGNOSIS; RISK	This article addresses the special features of data mining with medical data. Researchers in other fields may not be aware of the particular constraints and difficulties of the privacy-sensitive, heterogeneous, but voluminous data of medicine. Ethical and legal aspects of medical data mining are discussed, including data ownership, fear of lawsuits, expected benefits, and special administrative issues. The mathematical understanding of estimation and hypothesis formation in medical data may be fundamentally different than those from other data collection activities. Medicine is primarily directed at patient-care activity, and only secondarily as a research resource; almost the only justification for collecting medical data is to benefit the individual patient. Finally, medical data have a special status based upon their applicability to all people; their urgency (including life-or-death); and a moral obligation to be used for beneficial purposes. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Colorado, Dept Comp Sci & Engn, Denver, CO 80217 USA; Univ Colorado, Boulder, CO 80309 USA; Univ Colorado, Hlth Sci Ctr, Denver, CO USA; 4CData LLC, Golden, CO USA; Baltimore Vet Affairs Med Ctr, Baltimore, MD USA; Univ Maryland, Sch Med, Baltimore, MD 21201 USA; Johns Hopkins Univ, Sch Med, Baltimore, MD USA	Cios, KJ (reprint author), Univ Colorado, Dept Comp Sci & Engn, Campus Box 109,1200 Larimer St, Denver, CO 80217 USA.						Apps E., 2000, PC AI, V14; Banerjee S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839454; BAUER CJ, 1998, WASHINGTON POST 0315; BERMAN JJ, 2002, TISSUE MICROARRAY DA; Berman J J, 1996, Proc AMIA Annu Fall Symp, P328; BRAY T, 2000, EXTENSIBLE MARKUP LA; BREWKA G, 1997, CSLI LECT NOTES, P179; BUCHNER AG, 2000, P 1 INT C WEB INF SY, P127; CEUSTERS W, 2000, MED DATA MINING KNOW, P32; Changeux J.-P., 1995, CONVERSATIONS MIND M; Cheng J., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839455; Cios K., 1998, DATA MINING METHODS; CIOS KJ, 2000, MED DATA MINING KNOW, P1; Cios KJ, 2000, IEEE ENG MED BIOL, V19, P17, DOI 10.1109/51.853478; CIOS KJ, 2001, IN PRESS KNOWLEDGE D; Department of Health and Human Services, 2000, FED REG, V65, P82461; Fayyad U., 1996, P 2 INT C KNOWL DISC; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Friedman C, 1998, METHOD INFORM MED, V37, P334; GOEBEL M., 1999, SIGKDD EXPLORATIONS, V1, P20; GOLDNER MG, 1971, J AMER MED ASSOC, V218, P1400, DOI 10.1001/jama.218.9.1400; Kurgan LA, 2001, ARTIF INTELL MED, V23, P149, DOI 10.1016/S0933-3657(01)00082-3; Lai HC, 2000, NEW ENGL J MED, V342, P851, DOI 10.1056/NEJM200003233421204; Manning C., 2000, FDN STAT NATURAL LAN; MANSOUR EG, 1989, NEW ENGL J MED, V320, P485, DOI 10.1056/NEJM198902233200803; McHugh J., 1997, SIGMOD Record, V26; MOORE GW, 1980, METAMEDICINE, V1, P277, DOI 10.1007/BF00882620; MOORE GW, 1986, AM J MED, V80, P182, DOI 10.1016/0002-9343(86)90007-0; Moore GW, 1996, ARCH PATHOL LAB MED, V120, P782; MOORE GW, 2000, MED DATA MINING KNOW, P61; NAGAO M, 1992, ENCY ARTIFICIAL INTE, V2, P898; PAWLAK Z, 1984, INT J MAN MACH STUD, V20, P469, DOI 10.1016/S0020-7373(84)80022-X; PAZZANI MJ, 2000, IEEE INTELLIGENT MAR, P10; REINSCHMIDT J, 1999, INTELLIGENT MINER DA; RENNHACKKAMP M, 1998, DBMS             AUG; Sacha JP, 2000, IEEE ENG MED BIOL, V19, P78, DOI 10.1109/51.853485; SAUL JM, 2000, MED DATA MINING KNOW, P17; Schneier B., 1996, APPL CRYPTOGRAPHY PR; Schoning H, 2001, PROC INT CONF DATA, P149, DOI 10.1109/ICDE.2001.914823; Sweeney L., 2001, THESIS MIT; TANG Z, 2001, BUILDING DATA MINING; The Veterans Administration Co-operative Urological Research Group, 1967, SURG GYNECOL OBSTET, V124, P1011; United States Office for Human Research Protections (OHRP), 1991, FED REG, V56, P28003; Yaginuma Y, 2000, FUJITSU SCI TECH J, V36, P201; Zadeh L.A., 1979, ADV FUZZY SET THEORY, P3; ZAIANE OR, 1998, P CASCON 98 M MINDS, P83; *US DEP HHS, 2002, NAT I HLTH STAT SHAR; *US NAT LIB MED, 2002, UN MED LANG SYST; 2001, XML ACCESS 2001 EXPL; 2001, INFORMIX OBJECT TRAN; 2000, SQL SERVER MAGAZINE; 1991, FED REG, V56, P58758; 2000, US NATL CANC CONFIDE; 2001, ORACLE DATA MINING S; 2001, NATIXE XML DBMS	55	103	104	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	SEP-OCT	2002	26	1-2					1	24		10.1016/S0933-3657(02)00049-0		24	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	597BJ	WOS:000178201900001	
J	Lin, WY; Alvarez, SA; Ruiz, C				Lin, WY; Alvarez, SA; Ruiz, C			Efficient adaptive-support association rule mining for recommender systems	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; efficient association rule mining; e-commerce; recommender systems; adaptive computation		Collaborative recommender systems allow personalization for e-commerce by exploiting similarities and dissimilarities among customers' preferences. We investigate the use of association rule mining as an underlying technology for collaborative recommender systems. Association rules have been used with success in other domains. However, most currently existing association rule mining algorithms were designed with market basket analysis in mind. Such algorithms are inefficient for collaborative recommendation because they mine many rules that are not relevant to a given user. Also, it is necessary to specify the minimum support of the mined rules in advance, often leading to either too many or too few rules; this negatively impacts the performance of the overall system. We describe a collaborative recommendation technique based on a new algorithm specifically designed to mine association rules for this purpose. Our algorithm does not require the minimum support to be specified in advance. Rather, a target range is given for the number of rules, and the algorithm adjusts the minimum support for each user in order to obtain a ruleset whose size is in the desired range. Rules are mined for a specific target user, reducing the time required for the mining process. We employ associations between users as well as associations between items in making recommendations. Experimental evaluation of a system based on our algorithm reveals performance that is significantly better than that of traditional correlation-based approaches.	Microsoft Corp, Mt View, CA 94043 USA; Boston Coll, Dept Comp Sci, Chestnut Hill, MA 02467 USA; Worcester Polytech Inst, Dept Comp Sci, Worcester, MA 01609 USA	Lin, WY (reprint author), Microsoft Corp, SVC-3 2955,1065 La Ave, Mt View, CA 94043 USA.						Agarwal R., 1994, P 20 INT C VER LARG, P487; Agarwal R. C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347114; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Billsus D, 1998, P 15 INT C MACH LEAR; Breese J, 1998, P 14 C UNC ART INT M; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; COOLEY R, 1999, P WORKSH WEB US AN U; COOLEY R, 1997, 97021 TR U MINN DEP; FU X, 2000, P 2000 INT C INT US, P106, DOI 10.1145/325737.325796; HAJEK P, 1977, INT J MAN MACH STUD, V9, P415, DOI 10.1016/S0020-7373(77)80011-4; HAJEK P, 1966, COMPUTING, V1, P293, DOI 10.1007/BF02345483; Liu B, 1998, P 4 INT C KNOWL DISC, P80; McJones P., 1997, EACHMOVIE COLLABORAT; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Sarwar B, 2001, THESIS U MINNESOTA; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Srikant R., 1993, P ACM SIGMOD C MAN D, P207, DOI DOI 10.1145/170035.170072; SRIKANT R, 1996, P 1996 ACM SIGMOD C; Srivastava J., 1997, P 9 IEEE INT C TOOLS; Webb G. I., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347112	21	103	120	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2002	6	1					83	105		10.1023/A:1013284820704		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	503VK	WOS:000172822000005	
J	Han, JW; Fu, WJ				Han, JW; Fu, WJ			Mining multiple-level association rules in large databases	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; knowledge discovery in databases; association rules; multiple-level association rules; algorithms performance	RELATIONAL DATABASES	A top-down progressive deepening method is developed for efficient mining of multiple-level association rules from large transaction databases based on the Apriori principle. A group of variant algorithms is proposed based on the ways of sharing intermediate results, with the relative performance tested and analyzed. The enforcement of different interestingness measurements to find more interesting rules, and the relaxation of rule conditions for finding "level-crossing" association rules, are also investigated in the paper. Our study shows that efficient algorithms can be developed from large databases for the discovery of interesting and strong multiple-level association rules.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; Simon Fraser Univ, Intelligent Database Syst Res Lab, Burnaby, BC V5A 1S6, Canada; Univ Missouri, Dept Comp Sci, Rolla, MO 65409 USA	Han, JW (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	han@cs.sfu.ca; yongjian@umr.edu					Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; CHAUDHURI S., 1997, ACM SIGMOD RECORD, V26, P65, DOI 10.1145/248603.248616; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Cheung DW, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P31, DOI 10.1109/PDIS.1996.568665; Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094; Fu Y., 1995, P 1 INT WORKSH INT K, P39; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; HAN J, 1997, MINING MULTIPLE LEVE; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; KKOPERSKI K, 1995, P 4 INT S LARG SPAT, P47; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Meo R, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P122; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Savasere A, 1995, P 21 INT C VER LARG, P432; Simoudis E., 1996, P 2 INT C KNOWL DISC; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Srikant R., 1995, P 21 INT C VER LARG, P407; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413	24	103	114	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP-OCT	1999	11	5					798	805				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	258EY	WOS:000083826200007	
J	Friedman, JH; Fisher, NI				Friedman, JH; Fisher, NI			Bump hunting in high-dimensional data	STATISTICS AND COMPUTING			English	Article						Data Mining; noisy function optimization; classification; association; rule induction		Many data analytic questions can be formulated as (noisy) optimization problems. They explicitly or implicitly involve finding simultaneous combinations of values for a set of ("input") variables that imply unusually large (or small) values of another designated ("output") variable. Specifically, one seeks a set of subregions of the input variable space within which the value of the output variable is considerably larger (or smaller) than its average value over the entire input domain. In addition it is usually desired that these regions be describable in an interpretable form involving simple statements ("rules") concerning the input values. This paper presents a procedure directed towards this goal based on the notion of "patient" rule induction. This patient strategy is contrasted with the greedy ones used by most rule induction methods, and semi-greedy ones used by some partitioning tree techniques such as CART. Applications involving scientific and commercial data bases are presented.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Univ, Stanford Linear Accelerator Ctr, Stanford, CA 94305 USA; CSIRO, N Ryde, NSW 2113, Australia							BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839; Bishop CM, 1995, NEURAL NETWORKS PATT; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; DONOHO DL, 1992, ANN STAT, V20, P1803, DOI 10.1214/aos/1176348890; Efron B., 1993, INTRO BOOTSTRAP; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GREEN PJ, 1981, INTERPRETING MULTIVA; GRIFFIN WL, 1999, IN PRESS J PETROLOGY; HALL P, 1989, ANN STAT, V17, P573, DOI 10.1214/aos/1176347126; Lorentz G.G., 1986, APPROXIMATION FUNCTI; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan JR, 1994, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Ripley B., 1996, PATTERN RECOGNITION; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; TIBSHIRANI R, 1995, MODEL SEARCH INFEREN; Vapnik V.N., 1995, NATURE STAT LEARNING; Wahba G, 1990, SPLINE MODELS OBSERV	21	103	105	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0960-3174		STAT COMPUT	Stat. Comput.	APR	1999	9	2					123	143		10.1023/A:1008894516817		21	Computer Science, Theory & Methods; Statistics & Probability	Computer Science; Mathematics	208VB	WOS:000081011600004	
J	Pal, SK; Talwar, V; Mitra, P				Pal, SK; Talwar, V; Mitra, P			Web mining in soft computing framework: Relevance, state of the art and future directions	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						artificial neural networks (ANNs); data mining; fuzzy logic (FL); genetic algorithms (GAs); information retrieval (IR); knowledge discovery; pattern recognition; rough sets (RSs); search engines	WORLD-WIDE-WEB; INFORMATION-RETRIEVAL; NEURAL NETWORKS; FUZZY; CLASSIFICATION; DISCOVERY; INTERNET; TEXT	This paper summarizes the different characteristics of web data, the basic components of web mining and its different types, and their current states of the art. The reason for considering web mining, a separate field from data mining, is explained. The limitations of some of the existing web mining methods and tools are enunciated, and the significance of soft computing (comprising fuzzy logic (FL), artificial neural networks (ANNs), genetic algorithms (GAs), and rough sets (RSs) highlighted. A survey of the existing literature on "soft web mining" is provided along with the commercially available systems. The prospective areas of web mining where the application of soft computing needs immediate attention are outlined with justification. Scope for future research in developing "soft web mining" systems is explained. An extensive bibliography is also provided.	Indian Stat Inst, Machine INtelligence Unit, Calcutta 700035, W Bengal, India; Netaji Subhas Inst Technol, Dept Comp Sci, New Delhi 110045, India	Pal, SK (reprint author), Indian Stat Inst, Machine INtelligence Unit, Calcutta 700035, W Bengal, India.						BAEZA- YATES R., 1999, MODERN INFORMATION R; Banerjee M, 1998, IEEE T NEURAL NETWOR, V9, P1203, DOI 10.1109/72.728363; Bikel DM, 1999, MACH LEARN, V34, P211, DOI 10.1023/A:1007558221122; BOUGHANEM M, 1998, P 7 INT C TEXT RETR, P355; Boughanem M., 2000, SOFT COMPUTING INFOR, V50, P102; Broder A. Z., 1997, P 6 INT WORLD WID WE, P391; BROWN CM, 1994, P 2 INT WORLD WID WE, P763; Chakrabarti S., 2000, ACM SIGKDD EXPLORATI, V1, P1, DOI 10.1145/846183.846187; CHAKRABARTI S, 1999, 8 WORLD WID WEB C TO; Chen HC, 2000, STUD FUZZ SOFT COMP, V50, P122; COHEN WW, 1995, P 16 INT C MACH LEAR, P515; Cooley R, 1997, PROC INT C TOOLS ART, P558, DOI 10.1109/TAI.1997.632303; Craven M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; CRAVEN M, 1998, FUTURE GENERATION CO, V13, P211; CRESTANI F, 2000, SOFT COMPUTING INFOR, V50; Crimmins F, 1999, IEEE INTELL SYST APP, V14, P55, DOI 10.1109/5254.784085; CUTTING DR, 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; DRUMMOND C, 1995, TR9512 U OTT; ETZIONI O, 1997, P 6 WWW C SANT CARL; Etzioni O, 1996, COMMUN ACM, V39, P65, DOI 10.1145/240455.240473; ETZIONI O, 1996, TR960103 U WASH DEP; ETZIONI O, 1995, P 15 INT JOINT C ART, P930; Etzioni O, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1322; ETZIONI O, 1998, P 21 ANN INT ACM SIG, P46; ETZIONI O, 1997, P 15 INT JOINT C ART, P16; Freitag D., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); FREITAG D, 1999, P AAAI 99 WORKSH MAC; FREITAG D, 1997, SELF ORG MAPS; Freitag D., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; FUKUDA H, 2000, P 6 BRAZ S NEUR NETW, P131; Furnkranz J., 1999, P 3 S INT DAT AN IDA, P487; GEDEON T, 2000, SOFT COMPUTING INFOR, V50, P48; Ghani R., 2000, P 6 INT C KNOWL DISC, P29; GIBSON D, 1998, UK C HYP; GORDON MD, 1988, COMMUN ACM, V31, P208; GYENESEI A., 2000, 336 TUCS; HAMMOND K, 1995, AAAI SPRING S INF GA; Hipp J., 2000, ACM SIGKDD EXPLORATI, P58, DOI 10.1145/360402.360421; Joshi A., 1998, P WORKSH DAT MIN KNO; Kargupta H, 1999, ADV DISTRIBUTED PARA; Kargupta H., 1996, Proceedings of 1996 IEEE International Conference on Evolutionary Computation (ICEC'96) (Cat. No.96TH8114), DOI 10.1109/ICEC.1996.542674; KAWASAKI S, P 6 INT C KNOWL DISC; Kim S, 2000, P IEEE INT ASIC C&E, P13; Kobayashi M, 2000, ACM COMPUT SURV, V32, P144, DOI 10.1145/358923.358934; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; Konopnicki D, 1995, P 21 INT C VER LARG, P54; Kosla R., 2000, SIG KDD EXPLORATIONS, V2, P1; KRAFT DH, 1994, P IEEE S EV COMP; KRISHNAPURAM R, 1999, P IEEE INT C FUZZ SY; Kushmerick N, 1999, IEEE INTELL SYST APP, V14, P20, DOI 10.1109/5254.757626; KWOK C, 1996, P 14 NAT C AI; LEE CH, 2001, P INT C INF TECHN CO, P604; LEVY AY, 1995, AAAI SPRING S INF GA; Levy AY, 2000, ARTIF INTELL, V118, P1, DOI 10.1016/S0004-3702(00)00013-8; Lim JH, 2000, STUD FUZZ SOFT COMP, V50, P77; LIN WY, COLLABORATIVE RECOMM; Loh S., 2000, ACM SIGKDD EXPLORATI, V2, P29, DOI 10.1145/360402.360414; Loia V., 2001, LNCS, V2198, P292; MAHESWARI VU, 2001, P 1 AS PAC C WEB INT; MAREEK YS, 1996, P 5 INT WWW C; Martelli M, 1999, P C EV COMP CEC99, P13; Merkl D, 2000, STUD FUZZ SOFT COMP, V50, P102; MITCHELL T, 1997, P INT JOINT C AIIJCA, P770; MITRA S, 1995, IEEE T NEURAL NETWOR, V6, P51, DOI 10.1109/72.363450; Mitra S., 2001, IEEE T NEURAL NETWOR, V13, P3; MLADENIC D, P TEXT MIN WORKSH 10; MOBASHER B, 1997, TR96050 U MINN DEP C; MOBASHER B, 2000, P KDD 2000 WORKSH WE; MOBASHER B, 1997, TR97063 MINN U; Muslea I, 2001, AUTON AGENT MULTI-AG, V4, P93, DOI 10.1023/A:1010022931168; NAUCK D, 1999, P 18 INT C N AM FUZZ, P536; Negoita C. V., 1973, Kybernetes, V2, DOI 10.1108/eb005334; Page L., 1998, P 7 INT WORLD WID WE, P107; Pal S. K., 2000, SOFT COMPUTING IMAGE; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; PAL SK, 2002, IN PRESS IEEE T KNOW; Pal S.K, 2001, SOFT COMPUTING CASE; Pal S.R., 1999, NEURO FUZZY PATTERN; PASI G, 2000, SOFT COMPUTING INFOR, V50, P21; PAZZANI J, 1998, P 15 INT C MACH LEAR, P46; Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54; Pitkow J., 1997, P 6 INT WORLD WID WE, P451; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; SHAVLIK J, 2001, INT J USER MODELING; Singh L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Skowron A., 1998, ROUGH SETS KNOWLEDGE; Soderland S, 1999, MACH LEARN, V34, P233, DOI 10.1023/A:1007562322031; SPERTUS E, 1997, P 6 WWW C; Straccia U, 2000, STUD FUZZ SOFT COMP, V50, P332; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; WAN C, 2001, LNCS, V2198, P389; Wong SKM, 2000, STUD FUZZ SOFT COMP, V50, P317; Wulfekuhler MR, 1997, COMPUT NETWORKS ISDN, V29, P1147, DOI 10.1016/S0169-7552(97)00010-X; Yager RR, 2000, STUD FUZZ SOFT COMP, V50, P3; YANAI K, 2001, LNCS, V2198, P324; YANG JJ, 1992, TRLIS0451592001 U PI; ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255; Zadeh LA, 2001, AI MAG, V22, P73; 1999, IEEE COMPUTER, V32	99	102	109	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	SEP	2002	13	5					1163	1177		10.1109/TNN.2002.1031947		15	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	593LL	WOS:000177992800013	
J	Tan, PN; Kumar, V; Srivastava, J				Tan, PN; Kumar, V; Srivastava, J			Selecting the right objective measure for association analysis	INFORMATION SYSTEMS			English	Article; Proceedings Paper	8th International Conference on Knowledge Discovery and Data Mining (KDD 2002)	JUL 23-26, 2002	EDMONTON, CANADA	ACM, SIGKDD			STATISTICS; ATTRIBUTES	Objective measures such as support, confidence, interest factor, correlation, and entropy are often used to evaluate the interestingness of association patterns. However, in many situations, these measures may provide conflicting information about the interestingness of a pattern. Data mining practitioners also tend to apply an objective measure without realizing that there may be better alternatives available for their application. In this paper, we describe several key properties one should examine in order to select the right measure for a given application. A comparative study of these properties is made using twenty-one measures that were originally developed in diverse fields such as statistics, social science, machine learning, and data mining. We show that depending on its properties, each measure is useful for some application, but not for others. We also demonstrate two scenarios in which many existing measures become consistent with each other, namely, when support-based pruning and a technique known as table standardization are applied. Finally, we present an algorithm for selecting a small set of patterns such that domain experts can find a measure that best fits their requirements by ranking this small set of patterns. (C) 2003 Elsevier Ltd. All rights reserved.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Tan, PN (reprint author), Univ Minnesota, Dept Comp Sci, 200 Union St SE, Minneapolis, MN 55455 USA.	ptan@cs.umn.edu; kumar@cs.umn.edu; srivasta@cs.umn.edu					Aggarwal C. C., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275490; AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agresti A, 1990, CATEGORICAL DATA ANA; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Breiman L, 1984, CLASSIFICATION REGRE; Brijs T, 1999, P 5 INT C KNOWL DISC, P254, DOI 10.1145/312129.312241; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Clifton C, 1999, LECT NOTES ARTIF INT, V1704, P174; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cover T. M., 1991, ELEMENTS INFORMATION; DuMouchel W., 2001, P 7 ACM SIGKDD INT C, P67, DOI 10.1145/502512.502526; GAVRILOV M, 2000, P 6 INT C KNOWL DISC; GEORGE A, 1981, SERIES COMPUTATIONAL; GOODMAN LA, 1954, J AM STAT ASSOC, V49, P732, DOI 10.2307/2281536; Hand D. J., 2001, PRINCIPLES DATA MINI; Hilderman R., 2001, KNOWLEDGE DISCOVERY; Hilderman R. J., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference; Kamber M., 1996, P 2 INT C KNOWL DISC, P263; KLOSGEN W, 1992, INT J INTELL SYST, V7, P649, DOI 10.1002/int.4550070707; KONENKO I, 1995, P 1 INT C KNOWL DISC, P1034; MOSTELLE.F, 1968, J AM STAT ASSOC, V63, P1, DOI 10.2307/2283825; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Sahar S., 1999, SPIE C DAT MIN KNOWL, P63; Shortliffe E. H., 1975, Mathematical Biosciences, V23, DOI 10.1016/0025-5564(75)90047-4; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; Smyth P., 1991, Knowledge discovery in databases; Tan P., 2000, KDD 2000 WORKSH POST; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019; Yule GU, 1912, J R STAT SOC, V75, P579, DOI 10.2307/2340126; ZHAO Y, 2001, TR0140 U MINN DEP CO	34	101	102	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	JUN	2004	29	4					293	313		10.1016/S0306-4379(03)00072-3		21	Computer Science, Information Systems	Computer Science	802KI	WOS:000220162000003	
J	Geng, LQ; Hamilton, HJ				Geng, Liqiang; Hamilton, Howard J.			Interestingness measures for data mining: A survey	ACM COMPUTING SURVEYS			English	Article						algorithms; measurement; knowledge discovery; classification rules; interestingness measures; interest measures; summaries; association rules	KNOWLEDGE DISCOVERY; ALGORITHMS; TREES	Interestingness measures play an important role in data mining, regardless of the kind of patterns being mined. These measures are intended for selecting and ranking patterns according to their potential interest to the user. Good measures also allow the time and space costs of the mining process to be reduced. This survey reviews the interestingness measures for rules and summaries, classifies them from several perspectives, compares their properties, identifies their roles in the data mining process, gives strategies for selecting appropriate measures for applications, and identifies opportunities for future research in this area.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Geng, LQ (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.	gengl@cs.uregina.ca; hamilton@cs.uregina.ca					Agrawal R., 1994, P 20 INT C VER LARG, P487; Barber B, 2003, DATA MIN KNOWL DISC, V7, P153, DOI 10.1023/A:1022419032620; Bastide Y., 2000, P 1 INT C COMP LOG, P972; Bay S., 1999, P 5 ACM SIGKDD INT C, P302, DOI 10.1145/312129.312263; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Breiman L, 1984, CLASSIFICATION REGRE; Cai C. H., 1998, Proceedings. IDEAS'98. International Database Engineering and Applications Symposium (Cat. No.98EX156), DOI 10.1109/IDEAS.1998.694360; Carter CL, 1997, LECT NOTES ARTIF INT, V1263, P14; Carvalho D. R., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Chan R, 2003, P 3 IEEE INT C DAT M, P19; Ling C. X., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1184049; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Dong G., 1998, P 2 PAC AS C KNOWL D, P72; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FORSYTH RS, 1994, J EXP THEOR ARTIF IN, V6, P289, DOI 10.1080/09528139408953790; Freitas AA, 1998, LECT NOTES ARTIF INT, V1510, P1; Furnkranz J, 2005, MACH LEARN, V58, P39, DOI 10.1007/s10994-005-5011-x; GRAY B, 1998, P PAC AS C KNOWL DIS, P132; HAMILTON HJ, 2006, J APPL LOGIC, V4, P192, DOI 10.1016/j.jal.2005.06.005; Hilderman R., 2001, KNOWLEDGE DISCOVERY; Hilderman R. J., 1998, P 2 PAC AS C KNOWL D, P72; Hoaglin DC, 1985, EXPLORING DATA TABLE; Jaroszewicz S, 2001, P EUR C PRINC DAT MI, P253; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, P249; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Lavrac N., 1999, P 9 INT WORKSH IND L, P174; LENCA P, 2004, LUSSITR200401EN GETE; Li GC, 2004, SIAM PROC S, P166; Liu B., 1997, P 3 INT C KNOWL DISC, P31; Liu B, 1999, IEEE T KNOWL DATA EN, V11, P817; Lu S., 2001, INTELL DATA ANAL, V5, P211; McGarry K, 2005, KNOWL ENG REV, V20, P39, DOI 10.1017/S0269888905000408; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; OHSAKI M, 2004, P 8 EUR C PRINC DAT, P362; Padmanabhan B., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347103; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Piatetsky-Shapiro G., 1994, P AAAI 94 WORKSH KNO, P25; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; SAHAR S, 1999, P 25 INT C VER LARG, P42; SARAWAGI S, 1998, P INT C EXT DAT TECH, P168; Shen Y., 2002, P 2002 IEEE INT C DA, P426; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; Tan P., 2002, P 8 ACM SIGKDD INT C, P32, DOI DOI 10.1145/775047.775053; TAN P, 2000, 00036 U MINN DEP COM; VAILLANT B, 2004, P DISC SCI 2004, P290; Vitanyi PMB, 2000, IEEE T INFORM THEORY, V46, P446, DOI 10.1109/18.825807; WANG K, 2002, P EDBT, P70; WEBB GI, 2002, P 2002 PAC RIM KNOWL, P117; Yao H, 2004, SIAM PROC S, P482; YAO H, 2006, DATA KNOWL ENG, V59, P3; Yao Y. Y., 1999, P PAC AS C KNOWL DIS, P479; Yao YY, 2006, STUD COMPUT INTELL, V9, P41; Zbidi N, 2006, MACH LEARN, V62, P175, DOI 10.1007/s10994-005-5066-8; ZHANG H., 2004, P 10 INT C KNOWL DIS, P374, DOI 10.1145/1014052.1014094; Zhong N, 2003, IEEE T KNOWL DATA EN, V15, P952	58	100	104	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0360-0300		ACM COMPUT SURV	ACM Comput. Surv.		2006	38	3							9	10.1145/1132960.1132963		32	Computer Science, Theory & Methods	Computer Science	095JN	WOS:000241304100003	
J	Cano, JR; Herrera, F; Lozano, M				Cano, JR; Herrera, F; Lozano, M			Using evolutionary algorithms as instance selection for data reduction in KDD: An experimental study	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						data mining (DM); data reduction; evolutionary algorithms (EAs); instance selection; knowledge discovery	NEAREST NEIGHBOR RULE; LEARNING ALGORITHMS; CLASSIFIER	Evolutionary algorithms are adaptive, methods based on natural evolution that may be used for search and optimization. As data reduction in knowledge discovery in databases (KDDs) can be viewed as a search problem, it could be solved using evolutionary algorithms (EAs). In this paper, we have carried out an empirical study of the performance of four representative EA models in which we have taken into account two different instance selection perspectives, the prototype selection and the training set selection for data reduction in KDD. This paper includes a comparison between these algorithms and other nonevolutionary instance selection algorithms. The results show that the evolutionary instance selection algorithms consistently outperform the nonevolutionary ones, the main advantages being: better instance reduction rates, higher classification accuracy, and models that are easier to interpret.	Univ Huelva, Dept Elect Engn Comp Syst & Automat, Escuela Super La Rabida, Huelva 21819, Spain; Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Cano, JR (reprint author), Univ Huelva, Dept Elect Engn Comp Syst & Automat, Escuela Super La Rabida, Huelva 21819, Spain.		Herrera, Francisco/C-6856-2008; Lozano Marquez, Manuel/B-1848-2012	Herrera, Francisco/0000-0002-7283-312X; 			Adriaans P, 1996, DATA MINING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Back T., 1997, HDB EVOLUTIONARY COM; Baluja S., 1994, CMUCS94163; BRIGHTON H, 2001, INSTANCE SELECTION C, P77; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BROADLEY CE, 1993, P 10 INT MACH LEARN, P17; CHAPMAN P, 1999, CRISP DM PROCESS MOD; Devijver PA, 1982, PATTERN RECOGNITION; ESHELMAN L. J., 1991, FDN GENETIC ALGORITH, V1, P265; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; FRANK E, 1999, P 16 INT C MACH LEAR, P115; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Goldberg D.E., 1989, GENETIC ALGORITHMS S; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOLLAND JH, 1975, ADAPTATION NATURAL A; Kibbler D., 1987, P 4 INT WORKSH MACH, P24; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Liu H., 1998, FEATURE SELECTION KN; Liu H, 1995, PROC INT C TOOLS ART, P388; LIU H, 2001, INSTANCE SELECTION C, P3; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Reeves C. R., 2001, INSTANCE SELECTION C, P339; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; SHANAHAN JG, 2000, SOFT COMPUTING KNOWL; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; WHITLEY D, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P116; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson D.R., 1997, P 14 INT C MACH LEAR, P403; Witten IH, 2000, DATA MINING PRACTICA; Zhang J., 1992, P 9 INT MACH LEARN C, P470	36	99	102	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	DEC	2003	7	6					561	575		10.1109/TEVC.2003.819265		15	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	759KC	WOS:000187736000005	
S	Aggarwal, CC; Hinneburg, A; Keim, DA		VanDenBussche, J; Vianu, V		Aggarwal, CC; Hinneburg, A; Keim, DA			On the surprising behavior of distance metrics in high dimensional space	DATABASE THEORY - ICDT 2001, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Database Theory (ICDT 2001)	JAN 04-06, 2001	LONDON, ENGLAND	Univ London, Sen House Birckbeck Coll, European Union, European Res Consort Informat & Math, ACMSIGACT, SIGMOD				In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a efficiency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used L-k norm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric (L-1 norm) is consistently more preferable than the Euclidean distance metric (L-2 norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the L-k norm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; Univ Halle, Inst Comp Sci, D-06120 Halle Saale, Germany	Aggarwal, CC (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.						BENNETT KP, 1999, ACM SIGKDD C P; BERCHTOLD S, 1997, ACM PODS C P; BERCHTOLD S, 1998, ICDE C P; BERCHTOLD S, 1998, ACM SIGMOD C P JUN; Beyer K., 1999, ICDT C P; GUTTMAN A, 1984, ACM SIGMOD C P; HINNEBURG A, 2000, VLDB C P; KATAYAMA N, 1997, ACM SIGMOD C P; Lin K.-I., 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; SHAFT U, 1388 U WISC DEP COMP; WEBER R, 1998, VLDB C P	11	99	99	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-41456-8	LECT NOTES COMPUT SC			2001	1973						420	434				15	Computer Science, Theory & Methods	Computer Science	BS88B	WOS:000171312300027	
J	Skowron, A; Stepaniuk, J				Skowron, A; Stepaniuk, J			Information granules: Towards foundations of granular computing	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							FUZZY-LOGIC	We introduce basic notions related to granular computing, namely the information granule syntax and semantics as well as the inclusion and closeness (similarity) relations of granules. Different information sources (units, agents) are equipped with two kinds of operations on information granules: operations transforming tuples of information granules definable by a given agent into information granules definable by this agent and approximation operations for computing by agents approximations of information granules delivered by other agents. More complex granules are constructed by means of these operations and approximation operations from some input information granules. The construction of information granules is described by expressions called terms. We discuss a problem of synthesis of robust terms, i.e., descriptions of information granules, satisfying a given specification. This is an important problem for granular computing and its applications for spatial reasoning or knowledge discovery and data mining. (C) 2001 John Wiley & Sons, Inc.	Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland; Bialystok Univ Technol, Inst Comp Sci, PL-15351 Bialystok, Poland	Skowron, A (reprint author), Warsaw Univ, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.						Agotnes T, 1999, LECT NOTES ARTIF INT, V1704, P193; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; BOHLEN MH, 1999, LECT NOTES COMPUTER, V1678; Cattaneo G., 1998, ROUGH SETS KNOWLEDGE, V1, P59; Escrig M.T., 1998, QUALITATIVE SPATIAL; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Huhns M. N., 1998, READINGS AGENTS; Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; Lin T.Y., 1998, ROUGH SETS KNOWLEDGE, P107; NGUYEN HS, 1999, LECT NOTES COMPUTER, V1609, P310; Pawlak Z., 1991, ROUGH SETS THEORETIC; PETERS JF, 1999, LECT NOTES ARTIF INT, V1609, P556; POLKOWSKI J, 1999, COMPUTING WORDS INFO; POLKOWSKI L, 1998, INFORMATION SCI, V104, P129; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Polkowski L., 1998, P 1998 IEEE INT C FU, P111; RENZ J, 1998, P 13 EUR C ART INT B, P562; SKOWRON A, 1998, P 7 INT C INF PROC M, P1354; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A, 1999, LECT NOTES ARTIF INT, V1711, P357; Skowron A, 1999, LECT NOTES ARTIF INT, V1704, P542; Stepaniuk J., 1998, ROUGH SETS KNOWLEDGE, P109; STEPANIUK J, 2000, IN PRESS ROUGH SETS; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; Zadeh L. A., 1999, COMPUTING WORDS INFO, V1; Zadeh L.A., 1999, COMPUTING WORDS INFO, V2	27	99	108	JOHN WILEY & SONS INC	NEW YORK	605 THIRD AVE, NEW YORK, NY 10158-0012 USA	0884-8173		INT J INTELL SYST	Int. J. Intell. Syst.	JAN	2001	16	1					57	85		10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y		29	Computer Science, Artificial Intelligence	Computer Science	385AH	WOS:000165979100006	
J	Dhillon, IS; Guan, YQ; Kulis, B				Dhillon, Inderjit S.; Guan, Yuqiang; Kulis, Brian			Weighted graph cuts without eigenvectors: A multilevel approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; data mining; segmentation; kernel k-means; spectral clustering; graph partitioning		A variety of clustering algorithms have recently been proposed to handle data that is not linearly separable; spectral clustering and kernel k-means are two of the main methods. In this paper, we discuss an equivalence between the objective functions used in these seemingly different methods-in particular, a general weighted kernel k- means objective is mathematically equivalent to a weighted graph clustering objective. We exploit this equivalence to develop a fast high-quality multilevel algorithm that directly optimizes various weighted graph clustering objectives, such as the popular ratio cut, normalized cut, and ratio association criteria. This eliminates the need for any eigenvector computation for graph clustering problems, which can be prohibitive for very large graphs. Previous multilevel graph partitioning methods such as Metis have suffered from the restriction of equal-sized clusters; our multilevel algorithm removes this restriction by using kernel k- means to optimize weighted graph cuts. Experimental results show that our multilevel algorithm outperforms a state-of-the-art spectral clustering algorithm in terms of speed, memory usage, and quality. We demonstrate that our algorithm is applicable to large-scale clustering tasks such as image segmentation, social network analysis, and gene network analysis.	Univ Texas, Dept Comp Sci, Austin, TX 78712 USA; Microsoft Corp, Redmond, WA 98052 USA	Dhillon, IS (reprint author), Univ Texas, Dept Comp Sci, 1 Univ Stn C0500, Austin, TX 78712 USA.	inderjit@cs.utexas.edu; yuqiang.guan@microsoft.com; kulis@cs.utexas.edu					Bach F., 2004, P 17 ADV NEUR INF PR; CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898; Chen CY, 2004, SPINE, V29, P17, DOI 10.1097/01.BRS.0000096675.01484.87; Cristianini N., 2000, INTRO SUPPORT VECTOR; CRISTIANINI N, 2001, P 14 ADV NEUR INF PR; DAVIS T, 1996, U FLORIDA SPARSE MAT, V96; Dhillon I., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; Dhillon I., 2005, P 11 ACM SIGKDD INT, P629, DOI 10.1145/1081870.1081948; DHILLONI, 2004, TR0425 U TEX; DHILLONIS, 2002, P 2002 IEEE INT C DA, P131; DONATH WE, 1973, IBM J RES DEV, V17, P422; GIROLAMI M, 2002, IEEE T NEURAL NETWOR, V13, P669; Golub G. H., 1989, MATRIX COMPUTATION; HALL KM, 1970, MANAGE SCI, V17, P219, DOI 10.1287/mnsc.17.3.219; Hendrickson B., 1993, SAND931301; Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997; Kernighan B. W., 1970, Bell System Technical Journal, V49; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V2, P281; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; NG A, 2001, P 14 ADV NEUR INF PR; Overbeek R, 1999, P NATL ACAD SCI USA, V96, P2896, DOI 10.1073/pnas.96.6.2896; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; ROTH V, 2003, IEEE T PATTERN ANAL, V25; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; STRONG M, 2003, GENOME BIOL, V4; Strong M, 2003, NUCLEIC ACIDS RES, V31, P7099, DOI 10.1093/nar/gkg924; Yu S., 2003, P INT C COMP VIS; ZASS R, 2005, P 10 IEEE C COMP VIS; ZHA H, 2001, P NEURAL INFORM PROC	30	98	108	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					1944	1957		10.1109/TPAMI.2007.1115		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	208UE	WOS:000249343900006	
J	Zhao, Y; Karypis, G				Zhao, Y; Karypis, G			Hierarchical clustering algorithms for document datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						hierarchical clustering; criterion function; constrained agglomerative clustering; data mining		Fast and high-quality document clustering algorithms play an important role in providing intuitive navigation and browsing mechanisms by organizing large amounts of information into a small number of meaningful clusters. In particular, clustering algorithms that build meaningful hierarchies out of large document collections are ideal tools for their interactive visualization and exploration as they provide data-views that are consistent, predictable, and at different levels of granularity. This paper focuses on document clustering algorithms that build such hierarchical solutions and (i) presents a comprehensive study of partitional and agglomerative algorithms that use different criterion functions and merging schemes, and (ii) presents a new class of clustering algorithms called constrained agglomerative algorithms, which combine features from both partitional and agglomerative approaches that allows them to reduce the early-stage errors made by agglomerative methods and hence improve the quality of clustering solutions. The experimental evaluation shows that, contrary to the common belief, partitional algorithms always lead to better solutions than agglomerative algorithms; making them ideal for clustering large document collections due to not only their relatively low computational requirements, but also higher clustering quality. Furthermore, the constrained agglomerative methods consistently lead to better solutions than agglomerative methods alone and for many cases they outperform partitional methods, as well.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; Digital Technol Ctr, Minneapolis, MN 55455 USA; Army HPC Res Ctr, Minneapolis, MN 55455 USA	Zhao, Y (reprint author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	yzhao@cs.umn.edu; karypis@cs.umn.edu					Aggarwal C., 1999, P 5 ACM SIGKDD INT C, P352, DOI 10.1145/312129.312279; Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347176; Boley D, 1999, DECIS SUPPORT SYST, V27, P329, DOI 10.1016/S0167-9236(99)00055-X; Boley D, 1998, DATA MIN KNOWL DISC, V2, P325, DOI 10.1023/A:1009740529316; BOLEY D, 1999, AI REV, V11, P365; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHENG CK, 1991, IEEE T COMPUT AID D, V10, P1502, DOI 10.1109/43.103500; CUTTING DR, 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; Devore J., 1997, STAT EXPLORATION ANA; Dhillon I. S., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183895; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; DING C, 2001, LBNL47937 U CAL; Duda R.O., 2001, PATTERN CLASSIFICATI; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Hagen L., 1991, P IEEE INT C COMP AI, P10; Han E.-H., 1998, P 2 INT C AUT AG, P408, DOI 10.1145/280765.280872; Han E.-H., 1998, B TECHNICAL COMMITTE, V21, P15; Jain A.K., 1988, ALGORITHMS CLUSTERIN; KARYPIS G, 1999, IEEE COMPUT, V32, P68, DOI DOI 10.1109/2.781637; Karypis G., 2002, 02017 U MINN DEP COM; King B., 1967, J AM STAT ASSOC, V69, P86; Kohavi R., 1995, P 1 INT C KNOWL DISC, P192; Larsen B, 1999, P 5 ACM SIGKDD INT C, DOI 10.1145/312129.312186; LEOUSKI A, 1996, IR76 U MASS DEP COMP; Lewis D. D., 1999, REUTERS 21578 TEXT C; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Moore J., 1997, 7 WORKSH INF TECHN S; Ng R, 1994, P 20 INT C VER LARG, P144; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Puzicha J, 2000, PATTERN RECOGN, V33, P617, DOI 10.1016/S0031-3203(99)00076-X; Salton G., 1989, AUTOMATIC TEXT PROCE; SAVARESI S, 2001, 1 SIAM INT C DAT MIN; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Sneath P.H.A., 1973, NUMERICAL TAXONOMY; Steinbach M, 2000, KDD WORKSH TEXT MIN; Strehl A., 2000, P 17 INT C HIGH PERF, P525; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zha H., 2001, CIKM 01, P25; ZHANG B, 1999, HPL1999119; Zhao Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6; 1999, TEXT RETRIEVAL C	46	98	105	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	2005	10	2					141	168		10.1007/s10618-005-0361-3		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	924HV	WOS:000228970700003	
J	Srikant, R; Agrawal, R				Srikant, R; Agrawal, R			Mining generalized association rules	FUTURE GENERATION COMPUTER SYSTEMS			English	Article; Proceedings Paper	21st International Conference on Very Large Databases	SEP, 1995	ZURICH, SWITZERLAND			association rules; taxonomy; hierarchy; data mining		We introduce the problem of mining generalized association rules. Given a large database of transactions, where each transaction consists of a set of items, and a taxonomy (is-a hierarchy) on the items, we find associations between items at any level of the taxonomy. For example, given a taxonomy that says that jackets is-a outerwear is-a clothes, we may infer a rule that ''people who buy outerwear tend to buy shoes''. This rule may hold even if rules that ''people who buy jackets tend to buy shoes'', and ''people who buy clothes tend to buy shoes'' do not hold. An obvious solution to the problem is to add all ancestors of each item in a transaction to the transaction, and then run any of the algorithms for mining association rules on these ''extended transactions''. However, this ''Basic'' algorithm is not very fast; we present two algorithms, Cumulate and EstMerge, which run 2 to 5 times faster than Basic (and more than 100 times faster on one real-life dataset). Finally, we present a new interest-measure for rules which uses the information in the taxonomy. Given a user-specified ''minimum-interest-level'', this measure prunes a large number of redundant rules; 40-60% of all the rules were pruned on two real-life datasets.		Srikant, R (reprint author), IBM CORP,ALMADEN RES CTR,650 HARRY RD,SAN JOSE,CA 95120, USA.						Agrawal R., 1994, P 20 INT C VER LARG; AGRAWAL R, 1996, IEEE T KNOWLEDGE DAT, V8; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Alon N., 1992, PROBABILISTIC METHOD; HAGERUP T, 1989, INFORM PROCESS LETT, V33, P305; HAN EH, 1997, P ACM SIGMOD C MANAG; HOUTSMA M, 1995, INT C DAT ENG; NEARHOS JP, 1996, P 22 INT C VER LARG; PARK JS, 1995, P ACM SIGMOD C MAN D; PARK JS, 1995, P 41 INT FC INF KNOW; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; SAVASERE A, 1995, P VLDB C ZUR SWITZ; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134	14	98	101	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-739X		FUTURE GENER COMP SY	Futur. Gener. Comp. Syst.	NOV	1997	13	2-3					161	180		10.1016/S0167-739X(97)00019-8		20	Computer Science, Theory & Methods	Computer Science	YJ828	WOS:A1997YJ82800006	
J	Dehaspe, L; Toivonen, H				Dehaspe, L; Toivonen, H			Discovery of frequent DATALOG patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						frequent patterns; inductive logic programming; DATALOG queries; association rules; episodes; sequential patterns	KNOWLEDGE DISCOVERY; DECLARATIVE BIAS; CARCINOGENICITY; MUTAGENICITY; SEARCH; ILP	Discovery of frequent patterns has been studied in a variety of data mining settings. In its simplest form, known from association rule mining, the task is to discover all frequent itemsets, i.e., all combinations of items that are found in a sufficient number of examples. The fundamental task of association rule and frequent set discovery has been extended in various directions, allowing more useful patterns to be discovered with special purpose algorithms. We present WARMR, a general purpose inductive logic programming algorithm that addresses frequent query discovery: a very general DATALOG formulation of the frequent pattern discovery problem. The motivation for this novel approach is twofold. First, exploratory data mining isi well supported: WARMR offers the flexibility required to experiment with standard and in particular novel settings not supported by special purpose algorithms. Also, application prototypes based on WARMR can be used as benchmarks in the comparison and evaluation of new special purpose algorithms. Second, the unified representation gives insight to the blurred picture of the frequent pattern discovery domain. Within the DATALOG formulation a number of dimensions appear that relink diverged settings. We demonstrate the frequent query approach and its use on two applications, one in alarm analysis, and one in a chemical toxicology domain.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium; Univ Helsinki, Rolf Nevanlinna Inst, FIN-00014 Helsinki, Finland; Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland	Dehaspe, L (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Heverlee, Belgium.	luc.dehaspe@cs.kuleuven.ac.be; hannu.toivonen@rni.helsinki.fi	Toivonen, Hannu/A-3657-2012	Toivonen, Hannu/0000-0003-1339-8022			ADE H, 1995, MACH LEARN, V20, P119, DOI 10.1007/BF00993477; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; ASHBY J, 1991, MUTAT RES, V257, P229, DOI 10.1016/0165-1110(91)90003-E; Bettini C., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237680; Blockeel H, 1998, P 15 INT C MACH LEAR, P55; BLOCKEEL H, 1996, P 6 INT WORKSH IND L, V1314, P199; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; BRISTOL D, 1996, ENV HLTH PERSPECTI S, V3, P1001; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DEHASPE L, 1998, THESIS KU LEUVEN; DEHASPE L, 1996, LECT NOTES ARTIF INT, V1079, P613; Dehaspe L, 1997, LECT NOTES ARTIF INT, V1297, P125; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; DERAEDT L, 1998, IN PRESS LECT NOTES; DERAEDT L, 1996, P 3 INT WORKSH MULT, P29; DERAEDT L, 1995, LECT NOTES ARTIF INT, V997, P80; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Djoko Surnjani, 1995, P 1 INT C KNOWL DISC, P75; Dousson C., 1993, P INT JOINT C ART IN, P166; DZEROSKI S, 1998, P 15 INT C MACH LEAR; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P118; Fayyad U., 1996, P 2 INT C KNOWL DISC, P351; GOODMAN RM, 1991, INTEGRATED NETWORK M, V2, P541; Han J, 1995, P 21 INT C VER LARG, P420; Hatonen K, 1996, PROC INT CONF DATA, P115, DOI 10.1109/ICDE.1996.492095; Holsheimer M, 1995, P 1 INT C KNOWL DISC, P150; KIETZ JU, 1994, P 11 INT C MACH LEAR; Kietz J.-U., 1992, INDUCTIVE LOGIC PROG, P335; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; King RD, 1996, ENVIRON HEALTH PERSP, V104, P1031, DOI 10.2307/3433027; KLEMETTINEN M, 1998, J NETWORK SYSTEMS MA; Klosgen W., 1996, ADV KNOWLEDGE DISCOV; Kramer S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Langley P, 1996, ELEMENTS MACHINE LEA; LINDNER G, 1995, P MLNET FAM WORKSH S; Lu H., 1995, P 21 INT C VER LARG, P478; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MORRIS RA, 1995, 2 INT WORKSH TEMP RE; MUGGLETON S, 1995, NEW GEN COMPUTING, V13; Muggleton S., 1996, P 6 INT WORKSH IND L, P225; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; NEDELLEC C, 1996, FR ART INT, V32, P82; Oates T, 1996, P 13 INT C MACH LEAR, P346; Plotkin G.D., 1970, MACH INTELL, V5, P153; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sasisekharan R, 1996, IEEE EXPERT, V11, P37, DOI 10.1109/64.482956; Savasere A, 1995, P 21 INT C VER LARG, P432; Shen W., 1996, ADV KNOWLEDGE DISCOV, P375; Srikant R., 1996, Advances in Database Technology - EDBT '96. 5th International Conference on Extending Database Technology. Proceedings; Srikant R., 1995, P 21 INT C VER LARG, P407; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; SRINISAVAN A, 1997, P 15 INT JOINT C ART; Srinivasan A., 1997, LECT NOTES ARTIF INT, V1297, P273; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; Ullman J. D., 1988, PRINCIPLES DATABASE, VI; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; WANG K, 1997, P 3 INT C KNOWL DISC, P271; WANG X, 1997, P 3 INT C KNOWL DISC, P89; WEBER I, 1997, LECT NOTES ARTIF INT, V1297, P288; WEBER I, 1998, P FACHGR MASCH LERN; Wrobel S, 1997, LECT NOTES ARTIF INT, V1263, P78	67	97	108	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	1999	3	1					7	36		10.1023/A:1009863704807		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	192WR	WOS:000080103100002	
J	Huang, JZX; Ng, MK; Rong, HQ; Li, ZC				Huang, JZX; Ng, MK; Rong, HQ; Li, ZC			Automated variable weighting in k-means type clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; data mining; mining methods and algorithms; feature evaluation and selection	ALGORITHM; VALIDATION; SELECTION	This paper proposes a k-means type clustering algorithm that can automatically calculate variable weights. A new step is introduced to the k-means clustering process to iteratively update variable weights based on the current partition of data and a formula for weight calculation is proposed. The convergency theorem of the new clustering process is given. The variable weights produced by the algorithm measure the importance of variables in clustering and can be used in variable selection in data mining applications where large and complex real data are often involved. Experimental results on both synthetic and real data have shown that the new algorithm outperformed the standard k-means type algorithms in recovering clusters in data.	Univ Hong Kong, E Business Technol Inst, Hong Kong, Hong Kong, Peoples R China; Univ Hong Kong, Dept Math, Hong Kong, Hong Kong, Peoples R China; Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Henan Polytech Univ, Dept Comp Sci & Technol, Jiaozuo City 454003, Henan Province, Peoples R China	Huang, JZX (reprint author), Univ Hong Kong, E Business Technol Inst, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.	jhuang@eti.hku.hk; mng@maths.hku.hk; hqrong@cs.hku.hk; lizc@hpu.edu.cn	Ng, Michael/B-7189-2009; HKBU, Mathematics/B-5086-2009				Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Anderberg M.R., 1973, CLUSTER ANAL APPL; Bezdek JC, 1980, IEEE T PATTERN ANAL, V1, P1; DESOETE G, 1986, QUAL QUANT, V20, P169; DESOETE G, 1988, J CLASSIF, V5, P101; DESARBO WS, 1984, PSYCHOMETRIKA, V49, P57, DOI 10.1007/BF02294206; Fishman G. S, 1996, MONTE CARLO CONCEPTS; FOWLKES EB, 1988, J CLASSIF, V5, P205, DOI 10.1007/BF01897164; FRIEDMAN JH, 2002, J ROYAL STAT SOC B; GNANADESIKAN R, 1995, J CLASSIF, V12, P113, DOI 10.1007/BF01202271; GREEN PE, 1990, J CLASSIF, V7, P271, DOI 10.1007/BF01908720; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Huang ZX, 1999, IEEE T FUZZY SYST, V7, P446; Jain A.K., 1988, ALGORITHMS CLUSTERIN; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V2, P281; Makarenkov V, 2001, J CLASSIF, V18, P245; Makarenkov V, 1999, J CLASSIF, V16, P3, DOI 10.1007/s003579900040; MILLIGAN GW, 1989, J CLASSIF, V6, P53, DOI 10.1007/BF01908588; MILLIGAN GW, 1980, PATTERN RECOGN, V12, P41, DOI 10.1016/0031-3203(80)90001-1; Modha DS, 2003, MACH LEARN, V52, P217, DOI 10.1023/A:1024016609528; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81	21	96	115	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					657	668		10.1109/TPAMI.2005.95		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	905LI	WOS:000227569300001	
J	Lessmann, S; Baesens, B; Mues, C; Pietsch, S				Lessmann, Stefan; Baesens, Bart; Mues, Christophe; Pietsch, Swantje			Benchmarking classification models for software defect prediction: A proposed framework and novel findings	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						complexity measures; data mining; formal methods; statistical methods; software defect prediction	STATIC CODE ATTRIBUTES; VECTOR MACHINE CLASSIFIERS; QUANTITATIVE-ANALYSIS; QUALITY; ANALOGY; TREES; RELIABILITY; ALGORITHMS; COMPONENTS; NETWORKS	Software defect prediction strives to improve software quality and testing efficiency by constructing predictive classification models from code attributes to enable a timely identification of fault-prone modules. Several classification models have been evaluated for this task. However, due to inconsistent findings regarding the superiority of one classifier over another and the usefulness of metric-based classification in general, more research is needed to improve convergence across studies and further advance confidence in experimental results. We consider three potential sources for bias: comparing classifiers over one or a small number of proprietary data sets, relying on accuracy indicators that are conceptually inappropriate for software defect prediction and cross-study comparisons, and, finally, limited use of statistical testing procedures to secure empirical findings. To remedy these problems, a framework for comparative software defect prediction experiments is proposed and applied in a large-scale empirical comparison of 22 classifiers over 10 public domain data sets from the NASA Metrics Data repository. Overall, an appealing degree of predictive accuracy is observed, which supports the view that metric-based classification is useful. However, our results indicate that the importance of the particular classification algorithm may be less than previously assumed since no significant performance differences could be detected among the top 17 classifiers.	[Lessmann, Stefan; Pietsch, Swantje] Univ Hamburg, Inst Informat Syst, D-20146 Hamburg, Germany; [Baesens, Bart] Katholieke Univ Leuven, Dept Appl Econ Sci, B-3000 Louvain, Belgium; [Mues, Christophe] Univ Southampton, Sch Management, Southampton SO17 1BJ, Hants, England	Lessmann, S (reprint author), Univ Hamburg, Inst Informat Syst, Von Melle Pk 5, D-20146 Hamburg, Germany.	lessmann@econ.uni-hamburg.de; Bart.Baesens@econ.kuleuven.ac.be; c.mues@soton.ac.uk; mailing@swantje-pietsch.de	Lessmann, Stefan/J-2931-2013				Andersson C, 2007, IEEE T SOFTWARE ENG, V33, P273, DOI 10.1109/TSE.2007.1005; Andersson C, 2007, EMPIR SOFTW ENG, V12, P161, DOI 10.1007/s10664-006-9018-0; Baesens B, 2003, J OPER RES SOC, V54, P627, DOI 10.1057/palgrave.jors.2601545; Basili V. R., 1996, IEEE T SOFTWARE ENG, V22, P751; Bishop CM, 1995, NEURAL NETWORKS PATT; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Briand LC, 2002, IEEE T SOFTWARE ENG, V28, P706, DOI 10.1109/TSE.2002.1019484; BRIAND LC, 1993, IEEE T SOFTWARE ENG, V19, P1028, DOI 10.1109/32.256851; CHAPMAN M, 2004, NASA 4 5 FACILITY; Cleary JG, 1995, P 12 INT C MACH LEAR; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dougherty J, 1995, P 12 INT C MACH LEAR; Duda R.O., 2001, PATTERN CLASSIFICATI; El Emam K, 2001, J SYST SOFTWARE, V56, P63, DOI 10.1016/S0164-1212(00)00086-8; El Emam K, 2001, J SYST SOFTWARE, V55, P301, DOI 10.1016/S0164-1212(00)00079-0; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fayyad U, 1996, AI MAG, V17, P37; Fenton NE, 1999, IEEE T SOFTWARE ENG, V25, P675, DOI 10.1109/32.815326; Fenton NE, 2000, IEEE T SOFTWARE ENG, V26, P797, DOI 10.1109/32.879815; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Freund Y., 1999, P 16 INT C MACH LEAR; Ganesan K, 2000, INT J SOFTW ENG KNOW, V10, P139, DOI 10.1142/S0218194000000092; Guo L., 2004, P 15 INT S SOFTW REL; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Halstead M., 1977, ELEMENTS SOFTWARE SC; Hastie T., 2002, ELEMENTS STAT LEARNI; Khoshgoftaar T. M., 1999, INT J RELIABILITY QU, V6, P303, DOI 10.1142/S0218539399000292; Khoshgoftaar TM, 2003, EMPIR SOFTW ENG, V8, P325, DOI 10.1023/A:1025316301168; Khoshgoftaar T. M., 1995, Annals of Software Engineering, V1, DOI 10.1007/BF02249049; Khoshgoftaar TM, 1997, IEEE T NEURAL NETWOR, V8, P902, DOI 10.1109/72.595888; Khoshgoftaar TM, 2006, SOFTWARE QUAL J, V14, P85, DOI 10.1007/s11219-006-7597-z; Khoshgoftaar TM, 2000, IEEE T RELIAB, V49, P4, DOI 10.1109/24.855532; Khoshgoftaar TM, 2004, EMPIR SOFTW ENG, V9, P229, DOI 10.1023/B:EMSE.0000027781.18360.9b; Koru A. G., 2005, P WORKSH PRED MOD SO; Landwehr N, 2005, MACH LEARN, V59, P161, DOI 10.1007/s10994-005-0466-3; Lanubile F, 1997, J SYST SOFTWARE, V38, P225, DOI 10.1016/S0164-1212(96)00153-7; Li JZ, 2007, EMPIR SOFTW ENG, V12, P65, DOI 10.1007/s10664-006-7552-4; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P2, DOI 10.1109/TSE.2007.256941; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P637, DOI 10.1109/TSE.2007.70721; Menzies T., P WORKSH PRED SOFTW; Mierswa I., 2006, P 12 ACM SIGKDD INT; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; MUNSON JC, 1992, IEEE T SOFTWARE ENG, V18, P423, DOI 10.1109/32.135775; Myrtveit I, 2005, IEEE T SOFTWARE ENG, V31, P380, DOI 10.1109/TSE.2005.58; Myrtveit I, 1999, IEEE T SOFTWARE ENG, V25, P510, DOI 10.1109/32.799947; OHLSSON MC, 2002, P 8 INT SOFTW METR S; Ohlsson N, 1996, IEEE T SOFTWARE ENG, V22, P886, DOI 10.1109/32.553637; Ohlsson N., 1997, Empirical Software Engineering, V2, DOI 10.1023/A:1009757419320; PORTER AA, 1990, J SYST SOFTWARE, V12, P209, DOI 10.1016/0164-1212(90)90041-J; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; ROBERT JB, 1981, PSYCHOMETRIKA, V46, P241; Sayyad Shirabad J., 2005, PROMISE REPOSITORY S; SCHNEIDEWIND NF, 1992, IEEE T SOFTWARE ENG, V18, P410, DOI 10.1109/32.135774; SELBY RW, 1988, IEEE T SOFTWARE ENG, V14, P1743, DOI 10.1109/32.9061; Shepperd M, 2001, IEEE T SOFTWARE ENG, V27, P1014, DOI 10.1109/32.965341; Shepperd M, 1997, IEEE T SOFTWARE ENG, V23, P736, DOI 10.1109/32.637387; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tipping ME, 2000, ADV NEUR IN, V12, P652; Vandecruys O, 2008, J SYST SOFTWARE, V81, P823, DOI 10.1016/j.jss.2007.07.034; van Gestel T, 2004, MACH LEARN, V54, P5, DOI 10.1023/B:MACH.0000008082.80494.e0; Zar J.H., 1999, BIOSTATISTICAL ANAL; Zhang HY, 2007, IEEE T SOFTWARE ENG, V33, P635, DOI 10.1109/TSE.2007.70706; Zhong S, 2004, IEEE INTELL SYST, V19, P20, DOI 10.1109/MIS.2004.1274907	67	94	98	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	JUL-AUG	2008	34	4					485	496		10.1109/TSE.2008.35		12	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	330JI	WOS:000257936500005	
J	Rousseeuw, PJ; Van Driessen, K				Rousseeuw, PJ; Van Driessen, K			Computing LTS regression for large data sets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						breakdown value; linear model; outlier detection; regression; robust estimation	MULTIPLE LINEAR-REGRESSION; HIGH BREAKDOWN-POINT; SQUARES REGRESSION; ALGORITHM; ESTIMATOR; STABILITY	Data mining aims to extract previously unknown patterns or substructures from large databases. In statistics, this is what methods of robust estimation and outlier detection were constructed for, see e.g. Rousseeuw and Leroy (1987). Here we will focus on least trimmed squares (LTS) regression, which is based on the subset of h cases (out of n) whose least squares fit possesses the smallest sum of squared residuals. The coverage h may be set between n/2 and n. The computation time of existing LTS algorithms grows too much with the size of the data set, precluding their use for data mining. In this paper we develop a new algorithm called FAST-LTS. The basic ideas are an inequality involving order statistics and sums of squared residuals, and techniques which we call 'selective iteration' and nested extensions'. We also use an intercept adjustment technique to improve the precision. For small data sets FAST-LTS typically finds the exact LTS, whereas for larger data sets it gives more accurate results than existing algorithms for LTS and is faster by orders of magnitude. This allows us to apply FAST-LTS to large databases.	Univ Antwerp, Dept Math & Comp Sci, B-2020 Antwerp, Belgium; Univ Antwerp, Fac Appl Econ, B-2000 Antwerp, Belgium	Rousseeuw, PJ (reprint author), Univ Antwerp, Dept Math & Comp Sci, Middelheimlaan 1, B-2020 Antwerp, Belgium.	peter.rousseeuw@ua.ac.be; katrien.vandriessen@ua.ac.be					Agullo J, 1997, INST MATH S, V31, P133; AGULLO J, 1997, THESIS U ALICANTE SP; CHORK CJ, 1990, J GEOCHEM EXPLOR, V37, P191; COAKLEY CW, 1993, J AM STAT ASSOC, V88, P872, DOI 10.2307/2290776; HAWKINS DM, 1994, COMPUT STAT DATA AN, V17, P185, DOI 10.1016/0167-9473(92)00070-8; Hawkins DM, 1999, COMPUT STAT DATA AN, V30, P1, DOI 10.1016/S0167-9473(98)00082-6; HOSSJER O, 1994, J AM STAT ASSOC, V89, P149, DOI 10.2307/2291211; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Kaufman L., 1990, FINDING GROUPS DATA; KAUFMAN L, 1986, PATTERN RECOGN, V2, P425; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Mili L, 1996, IEEE T POWER SYST, V11, P1118, DOI 10.1109/59.496203; MILI L, 1991, IEEE T POWER SYST, V6, P511, DOI 10.1109/59.76693; Ng R, 1994, P 20 INT C VER LARG, P144; ODEWAHN S, 1998, DATA DIGITIZED PALOM; Rousseeuw P., 1985, MATH STAT APPL, V8, P283; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566; Rousseeuw PJ, 1997, INST MATH S, V31, P201; ROUSSEEUW PJ, 1990, J AM STAT ASSOC, V85, P633, DOI 10.2307/2289995; ROUSSEEUW PJ, 1997, HANDB STAT, V15, P101, DOI 10.1016/S0169-7161(97)15007-6; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SIMPSON DG, 1992, J AM STAT ASSOC, V87, P439, DOI 10.2307/2290275; STEELE JM, 1986, DISCRETE APPL MATH, V14, P93, DOI 10.1016/0166-218X(86)90009-0; STROMBERG AJ, 1993, SIAM J SCI COMPUT, V14, P1289, DOI 10.1137/0914076; Wang CM, 1997, TECHNOMETRICS, V39, P25, DOI 10.2307/1270769; WOODRUFF DL, 1994, J AM STAT ASSOC, V89, P888, DOI 10.2307/2290913; YOHAI VJ, 1987, ANN STAT, V15, P642, DOI 10.1214/aos/1176350366; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328	29	94	99	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2006	12	1					29	45		10.1007/s10618-005-0024-4		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	013ZU	WOS:000235449300002	
J	Hristovski, D; Peterlin, B; Mitchell, JA; Humphrey, SM				Hristovski, D; Peterlin, B; Mitchell, JA; Humphrey, SM			Using literature-based discovery to identify disease candidate genes	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						medical informatics; knowledge discovery; data mining; MEDLINE; discovery support; genes; diseases	FISH-OIL; GENERATING HYPOTHESES; RESOURCES; RAYNAUDS	We present BITOLA, an interactive titerature-based biomedical discovery support system. The goal of this system is to discover new, potentially meaningful relations between a given starting concept of interest and other concepts, by mining the bibliographic database MEDLINE(R). To make the system more suitable for disease candidate gene discovery and to decrease the number of candidate relations, we integrate background knowledge about the chromosomal location of the starting disease as well as the chromosomal location of the candidate genes from resources such as LocusLink and Human Genome Organization (HUGO). BITOLA can also be used as an alternative way of searching the MEDLINE database. The system is available at http://www.mf.uni-lj.si/bitola/. (C) 2004 Elsevier Ireland Ltd. All rights reserved.	Univ Ljubljana, Fac Med, Inst Biomed Informat, Ljubljana 1104, Slovenia; Natl Lib Med, Lister Hill Natl Ctr Biomed Commun, Bethesda, MD USA; Univ Ljubljana, Med Ctr, Div Med Genet, Ljubljana 1104, Slovenia; Univ Missouri, Sch Med, Dept Hlth Management & Informat, Columbia, MO 65211 USA	Hristovski, D (reprint author), Univ Ljubljana, Fac Med, Inst Biomed Informat, Vrazov Trg 2-2, Ljubljana 1104, Slovenia.	dimitar.hristovski@mf.uni-lj.si	Hristovski, Dimitar/A-6288-2009				Agrawal R., 1996, ADV KNOWLEDGE DISCOV; Bodenreider Olivier, 2002, Proc AMIA Symp, P61; Freudenberg J, 2002, BIOINFORMATICS, V18, pS110; Gordon MD, 1996, J AM SOC INFORM SCI, V47, P116, DOI 10.1002/(SICI)1097-4571(199602)47:2<116::AID-ASI3>3.0.CO;2-1; HRISTOVSKI D, 2001, MEDINFO, V10, P1344; HUMPHREY SM, 2000, P 11 ASIST SIG CR CL, P103; Humphrey SM, 1999, J AM SOC INFORM SCI, V50, P661, DOI 10.1002/(SICI)1097-4571(1999)50:8<661::AID-ASI4>3.0.CO;2-R; HUMPHREYS BL, 1998, J AM MED INFORM ASSN, V1, P1; Jenssen TK, 2001, NAT GENET, V28, P21, DOI 10.1038/ng0501-21; Kilicoglu H., 2003, P AM MED INF ASS ANN, P554; Mitchell JA, 2003, METHOD INFORM MED, V42, P557; MITCHELL JA, 2003, J AMIN S, P460; Perez-Iratxeta C, 2002, NAT GENET, V31, P316, DOI 10.1038/ng895; Pruitt KD, 2001, NUCLEIC ACIDS RES, V29, P137, DOI 10.1093/nar/29.1.137; Sekimizu T, 1998, GENOME INFORM SER WO, V9, P62; Srinivasan P, 2004, J AM SOC INF SCI TEC, V55, P396, DOI 10.1002/asi.10389; Stapley B J, 2000, Pac Symp Biocomput, P529; Stephens M, 2001, Pac Symp Biocomput, P483; SWANSON DR, 1986, PERSPECT BIOL MED, V30, P7; Turner FS, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-11-r75; van Driel MA, 2003, EUR J HUM GENET, V11, P57, DOI 10.1038/sj.ejhg.5200918; Wain HM, 2002, GENOMICS, V79, P464, DOI 10.1006/geno.2002.6748; Weeber M, 2001, J AM SOC INF SCI TEC, V52, P548, DOI 10.1002/asi.1104.abs; Weeber M, 2003, J AM MED INFORM ASSN, V10, P252, DOI 10.1197/jamia.M1158	24	94	99	ELSEVIER SCI IRELAND LTD	CLARE	CUSTOMER RELATIONS MANAGER, BAY 15, SHANNON INDUSTRIAL ESTATE CO, CLARE, IRELAND	1386-5056		INT J MED INFORM	Int. J. Med. Inform.	MAR	2005	74	2-4					289	298		10.1016/j.ijmedinf.2004.04.024		10	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	903DW	WOS:000227406700024	
J	Keogh, E; Kasetty, S				Keogh, E; Kasetty, S			On the need for time series data mining benchmarks: A survey and empirical demonstration	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th International Conference on Knowledge Discovery and Data Mining (KDD 2002)	JUL 23-26, 2002	EDMONTON, CANADA	ACM, SIGKDD		time series; data mining; experimental evaluation	SIMILARITY SEARCH; SEQUENCES; WAVELETS; QUERIES; DATABASES	In the last decade there has been an explosion of interest in mining time series data. Literally hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we make the following claim. Much of this work has very little utility because the contribution made ( speed in the case of indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an amount of "improvement" that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details. To illustrate our point, we have undertaken the most exhaustive set of time series experiments ever attempted, re-implementing the contribution of more than two dozen papers, and testing them on 50 real world, highly diverse datasets. Our empirical results strongly support our assertion, and suggest the need for a set of time series benchmarks and more careful empirical evaluation in the data mining community.	Univ Calif Riverside, Riverside, CA 92521 USA	Keogh, E (reprint author), Univ Calif Riverside, Riverside, CA 92521 USA.	eamonn@cs.ucr.edu; skasetty@cs.ucr.edu					Agrawal R., 1995, P 21 INT C VER LARG, P490; Andre-Jonsson H, 1997, LECT NOTES ARTIF INT, V1263, P211; Bailey D. H., 1991, SUPERCOMPUTING REV, P54; BAY S, 1999, UCI REPOSITORY KDD D; Berndt D. J., 1996, ADV KNOWLEDGE DISCOV, P229; Bozkaya T., 1997, Proceedings of the Sixth International Conference on Information and Knowledge Management. CIKM'97, DOI 10.1145/266714.266880; Caraca-Valente J. P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347192; Chan KP, 1999, PROC INT CONF DATA, P126; Chu K. K. W., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, DOI 10.1145/303976.304000; Chu W.W., 2001, P 16 ACM S APPL COMP, P248, DOI 10.1145/372202.372334; Cohen W. W., 1993, P 13 INT JOINT C ART, P988; Das G, 1997, LECT NOTES ARTIF INT, V1263, P88; DAS G, P 4 INT C KNOWL DISC, P16; David BL., 1993, P 4 INT C FDN DAT OR, P69; Debregeas A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; FALOUTSOS C, 1997, P INT C COMPR COMPL; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; Ferhatosmanoglu H, 2001, PROC INT CONF DATA, P503, DOI 10.1109/ICDE.2001.914864; GAVRILOV M, 2000, KDD 00, P487; Ge X., 2000, P 6 ACM SIGKDD INT C, P81, DOI 10.1145/347090.347109; Geurts P., 2001, P 5 EUR C PRINC DAT, P115; Goldin D. Q., 1995, Principles and Practice of Constraint Programming - CP '95. First International Conference, CP'95. Proceedings; Guralnik V, 1999, P 5 ACM SIGKDD INT C, P33, DOI 10.1145/312129.312190; Huang YW, 1999, P 5 INT C KNOWL DISC, P282, DOI 10.1145/312129.318357; Huhtala Y, 1999, PROC SPIE, V3695, P150, DOI 10.1117/12.339977; Indyk P., 2000, P 26 INT C VER LARG, P363; Kahveci T, 2001, PROC INT CONF DATA, P273, DOI 10.1109/ICDE.2001.914838; Kahveci T, 2002, PROC INT CONF DATA, P266, DOI 10.1109/ICDE.2002.994720; Kalpakis K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989529; KAWAGOE K, 2002, P 9 INT S TEMP REPR; Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; Keogh E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Kibler D., 1988, P 3 EUR WORK SESS LE, P81; KIM E, 2000, P DAT WAR KNOWL DISC, P347; Kim SW, 2001, PROC INT CONF DATA, P607; Korn F., 1997, P ACM SIGMOD INT C M, P289, DOI DOI 10.1145/253260.253332; Lam SK, 1998, DATA KNOWL ENG, V28, P321, DOI 10.1016/S0169-023X(98)00023-8; Lavrenko V., 2000, P 6 ACM SIGKDD INT C, P37; Lee S.-L., 2000, P ICDE, P599; LI C., 1998, P 7 INT C INF KNOWL, P267, DOI 10.1145/288627.288666; LOH WK, 2000, P ACM INT C INF KNOW, P480, DOI 10.1145/354756.354856; Park S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839384; PARK S, 2001, COMMUNICATION; PARK S, 1999, P 3 IEEE KNOWL DAT E; POLLY WPM, 2001, P 2001 ACM CIKM INT, P271; Popivanov I, 2002, PROC INT CONF DATA, P212, DOI 10.1109/ICDE.2002.994711; PRATT KB, 2002, INT J IMAGE GRAPHICS, V2, P86; PRECHELT L, 1995, P 4 INT C ART NEUR N, P223; QU Y, 1998, P ACM CIKM, P251, DOI 10.1145/288627.288664; RAFIEI D, 1998, P 5 INT C FDN DAT OR; Rafiei D, 1999, PROC INT CONF DATA, P410, DOI 10.1109/ICDE.1999.754957; Shahabi C., 2000, Proceedings. 12th International Conference on Scientific and Statistica Database Management, DOI 10.1109/SSDM.2000.869778; Shatkay H, 1996, PROC INT CONF DATA, P536, DOI 10.1109/ICDE.1996.492204; SIMON JL, 1994, AM STAT, V48, P1; Struzik ZR, 1999, LECT NOTES ARTIF INT, V1704, P12; WALKER J, 2001, HOTBITS GENUINE RAND; WANG C, 2000, P 9 ACM CIKM INT C I, P314, DOI 10.1145/354756.354834; WANG C, 2000, P 12 INT C SCI STAT, P69; WANG C, 2000, P 82 ANN M TOR ONT E, P37; Wu L., 2000, P 26 INT C VER LARG, P297; Wu Y. L., 2000, P 9 ACM CIKM INT C I, P488, DOI 10.1145/354756.354857; Yi BK, 1998, PROC INT CONF DATA, P201; Yi B.K., 2000, P 26 INT C VER LARG, P385; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680	65	94	108	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2003	7	4					349	371		10.1023/A:1024988512476		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	704UM	WOS:000184358900002	
J	Boulicaut, JF; Bykowski, A; Rigotti, C				Boulicaut, JF; Bykowski, A; Rigotti, C			Free-sets: A condensed representation of Boolean data for the approximation of frequency queries	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						condensed representations; frequent pattern discovery; association rules		Given a large collection of transactions containing items, a basic common data mining problem is to extract the so-called frequent itemsets (i.e., sets of items appearing in at least a given number of transactions). In this paper, we propose a structure called free-sets, from which we can approximate any itemset support (i.e., the number of transactions containing the itemset) and we formalize this notion in the framework of epsilon-adequate representations (H. Mannila and H. Toivonen, 1996. In Proc. of the Second International Conference on Knowledge Discovery and Data Mining (KDD'96), pp. 189-194). We show that frequent free-sets can be efficiently extracted using pruning strategies developed for frequent itemset discovery, and that they can be used to approximate the support of any frequent itemset. Experiments on real dense data sets show a significant reduction of the size of the output when compared with standard frequent itemset extraction. Furthermore, the experiments show that the extraction of frequent free-sets is still possible when the extraction of frequent itemsets becomes intractable, and that the supports of the frequent free-sets can be used to approximate very closely the supports of the frequent itemsets. Finally, we consider the effect of this approximation on association rules ( a popular kind of patterns that can be derived from frequent itemsets) and show that the corresponding errors remain very low in practice.	Inst Natl Sci Appl, Lab Ingn Syst Informat, F-69621 Villeurbanne, France	Boulicaut, JF (reprint author), Inst Natl Sci Appl, Lab Ingn Syst Informat, Batiment 501, F-69621 Villeurbanne, France.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo R. J.  Jr., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; BOULICAUT JF, IN PRESS P 4 EUR C P; Boulicaut JF, 2000, LECT NOTES ARTIF INT, V1805, P62; BYKOWSKI A, 2000, P 2000 INT WORKSH WE, P27; Fujiwara S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839449; Mannila H., 1996, P 2 INT C KNOWL DISC, P189; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; PAVLOV D, 2000, 200007 U CAL DEP INF; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases	15	94	95	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN	2003	7	1					5	22		10.1023/A:1021571501451		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	623LU	WOS:000179705200001	
J	Lavrac, N				Lavrac, N			Selected techniques for data mining in medicine	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						data mining; machine learning; medical applications	DIAGNOSIS; KNOWLEDGE; DISCOVERY; INDUCTION	Widespread use of medical information systems and explosive growth of medical databases require traditional manual data analysis to be coupled with methods for efficient computer-assisted analysis. This paper presents selected data mining techniques that can be applied in medicine, and in particular some machine learning techniques including the mechanisms that make them better suited for the analysis of medical databases (derivation of symbolic rules, use of background knowledge, sensitivity and specificity of induced descriptions). The importance of the interpretability of results of data analysis is discussed and illustrated on selected medical applications. (C) 1999 Elsevier Science B.V. All rights reserved.	Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia	Lavrac, N (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia.	nada.lavrac@ijs.si					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BRATKO I, 1986, CISM COURSES LECT, V382, P163; BRATKO I, 1987, AI METHODS STAT; CESTNIK B, 1987, PROGR MACHINE LEARNI; Cestnik B., 1990, P EUR C ART INT, P147; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Dzeroski S, 1996, Technol Health Care, V4, P203; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; FIX E, 1957, 4 US AIR FORC SCH AV; Frawley WJ, 1991, KNOWLEDGE DISCOVERY; French S., 1986, DECISION THEORY; GROSELJ C, 1997, P WORKSH COMP AID DA, P68; HOLTE R, 1989, P 10 INT JOINT C ART; Kira K., 1992, P 9 INT C MACH LEARN, P249; KIRA K, 1992, P AAAI 1992 SAN JOS; KONENKO I, 1994, P EUR C MACH LEARN B, P171; KONONENKO I, 1995, P ISSEK WORKSH MATH, P199; KONONENKO I, 1995, P WORKSH COMP AID DA; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; Kononenko I, 1991, P 6 EUR WORK SESS LE, p206~219; Kukar M, 1996, ARTIF INTELL MED, V8, P431, DOI 10.1016/S0933-3657(96)00351-X; KUKAR M, 1998, ARTIF INTELL MED; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Lavrac N, 1997, INTELLIGENT DATA ANA; LAVRAC N, 1991, P 5 EUR WORK SESS LE, P265; Lavrac N., 1994, INDUCTIVE LOGIC PROG; LAVRAC N, 1993, APPL ARTIF INTELL, V7, P273, DOI 10.1080/08839519308949989; LESMO L, 1982, APPROXIMATE REASONIN; LUCAS PJF, 1995, KNOWL ENG REV, V10, P153; Mizoguchi F, 1997, KLUWER INT SER ENG C, V414, P227; MOZETIC I, UIUCDCSF85949 U ILL; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muggleton S., 1991, New Generation Computing, V8; NIBLETT T, 1986, RES DEV EXPERT SYSTE, V3, P24; NUNEZ M, 1990, CURRENT TRENDS KNOWL; Pearl J., 1988, PROBABILISTIC REASON; Pilih IA, 1997, KLUWER INT SER ENG C, V414, P131; PIRNAT V, 1989, P 2 EUR C ART INT ME, P24; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Richeldi M., 1995, P 8 EUR C MACH LEARN, P335; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1; SHANKLE WR, 1997, NTELLIGENT DATA ANAL, P149; SHANNON CE, 1948, AT&T TECH J, V27, P379; Taylor C.C., 1994, MACHINE LEARNING NEU; WETTSCHERECK D, 1994, THESIS OREGON STATE; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445; Zelic I, 1997, J Med Syst, V21, P429, DOI 10.1023/A:1022880431298; ZUPAN B, 1997, P 6 C ART INT MED BE, P86	57	93	94	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	MAY	1999	16	1					3	23		10.1016/S0933-3657(98)00062-1		21	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	184DR	WOS:000079595400002	
S	Chen, MS; Park, JS; Yu, PS			IEEE, COMP SOC	Chen, MS; Park, JS; Yu, PS			Data mining for path traversal patterns in a web environment	PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS	INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS - PROCEEDINGS		English	Proceedings Paper	16th International Conference on Distributed Computing Systems	MAY 27-30, 1996	HONG KONG, HONG KONG	IEEE, Comp Soc, Tech Comm Distributed Proc					IBM CORP,THOMAS J WATSON RES CTR,YORKTOWN HTS,NY 10598			Yu, Philip/A-2815-2012					0	93	145	I E E E, COMPUTER SOC PRESS	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, LOS ALAMITOS, CA 90720	1063-6927	0-8186-7398-2	INT CON DISTR COMP S			1996							385	392				8	Computer Science, Theory & Methods	Computer Science	BF78X	WOS:A1996BF78X00044	
J	Hu, QH; Yu, DR; Liu, JF; Wu, CX				Hu, Qinghua; Yu, Daren; Liu, Jinfu; Wu, Congxin			Neighborhood rough set based heterogeneous feature subset selection	INFORMATION SCIENCES			English	Article						categorical feature; numerical feature; heterogeneous feature; feature selection; neighborhood; rough sets	FUZZY-LOGIC; REDUCTION; CLASSIFICATION; APPROXIMATION; CLASSIFIERS; GRANULATION; ALGORITHM; SYSTEMS	Feature subset selection is viewed as an important preprocessing step for pattern recognition, machine learning and data mining. Most of researches are focused on dealing with homogeneous feature selection, namely, numerical or categorical features. In this paper, we introduce a neighborhood rough set model to deal with the problem of heterogeneous feature subset selection. As the classical rough set model can just be used to evaluate categorical features, we generalize this model with neighborhood relations and introduce a neighborhood rough set model. The proposed model will degrade to the classical one if we specify the size of neighborhood zero. The neighborhood model is used to reduce numerical and categorical features by assigning different thresholds for different kinds of attributes. In this model the sizes of the neighborhood lower and upper approximations of decisions reflect the discriminating capability of feature subsets. The size of lower approximation is computed as the dependency between decision and condition attributes. We use the neighborhood dependency to evaluate the significance of a subset of heterogeneous features and construct forward feature subset selection algorithms. The proposed algorithms are compared with some classical techniques. Experimental results show that the neighborhood model based method is more flexible to deal with heterogeneous data. (C) 2008 Elsevier Inc. All rights reserved.	[Hu, Qinghua; Yu, Daren; Liu, Jinfu; Wu, Congxin] Harbin Inst Technol, Harbin 150001, Peoples R China	Hu, QH (reprint author), Harbin Inst Technol, Harbin 150001, Peoples R China.	huqinghua@hcms.hit.edu.cn					Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044; Chen DG, 2007, INFORM SCIENCES, V177, P3500, DOI 10.1016/j.ins.2007.02.041; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; FAYYAD U, 1996, P 13 INT C MACH LEAR, P157; Hall M. A., 1999, THESIS U WAIKATO; Hall M. A., 2000, P 17 INT C MACH LEAR, P359; Hu QH, 2006, LECT NOTES ARTIF INT, V4099, P423; Hu QH, 2008, KNOWL-BASED SYST, V21, P294, DOI 10.1016/j.knoys.2007.07.001; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086; Hu QH, 2008, EXPERT SYST APPL, V34, P866, DOI 10.1016/j.eswa.2006.10.043; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; Jensen R, 2007, IEEE T FUZZY SYST, V15, P73, DOI 10.1109/TFUZZ.2006.889761; Jin W., 2006, P 10 PAC AS C ADV KN, P577; Li Y, 2006, IEEE T KNOWL DATA EN, V18, P415; Lin T.Y., 2001, GRANULAR COMPUTING E, P125; Lin TY, 1989, P 4 INT S METH INT S, P75; LIN TY, 2003, 2003 IEEE INT C SYST; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Muni DP, 2006, IEEE T SYST MAN CY B, V36, P106, DOI 10.1109/TSMCB.2005.854499; Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9; Newman D.J., 1998, UCI REPOSITORY MACHI; Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006; Pawlak Z., 1991, ROUGH SETS THEORETIC; Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016; Shin HJ, 2005, PATTERN RECOGN LETT, V26, P707, DOI 10.1016/j.patrec.2004.09.023; Skowron A., 1996, Fundamenta Informaticae, V27; Slezak D, 1996, P IPMU 96 GRAN SPAIN, V3, P1159; Slowinski R, 2000, IEEE T KNOWL DATA EN, V12, P331, DOI 10.1109/69.842271; STEFANOWSKI J, 1998, ROUGH SETS KNOWLEDGE, P501; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Tang WY, 2007, PATTERN RECOGN LETT, V28, P563, DOI 10.1016/j.patrec.2006.10.008; Wang H, 2006, IEEE T PATTERN ANAL, V28, P942; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Yeung DS, 2005, IEEE T FUZZY SYST, V13, P343, DOI 10.1109/TFUZZ.2004.841734; Yu Da-ren, 2004, Proceedings of the CSEE, V24; Yu L, 2004, J MACH LEARN RES, V5, P1205; Yu L., 2003, P 9 ACM SIGKDD INT C, P685; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; Zhu W, 2007, INFORM SCIENCES, V177, P4997, DOI 10.1016/j.ins.2007.05.037; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; Zhu ZX, 2007, IEEE T SYST MAN CY B, V37, P70, DOI 10.1109/TSMCB.2006.883267; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	47	92	110	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	SEP 15	2008	178	18					3577	3594		10.1016/j.ins.2008.05.024		18	Computer Science, Information Systems	Computer Science	336FN	WOS:000258349800007	
J	Zhu, W; Wang, FY				Zhu, William; Wang, Fei-Yue			On three types of covering-based rough sets	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						rough sets; approximation; covering; data mining; reduct; fuzzy sets; granular computing; computing with words	FUZZY-SETS; ALGORITHM; PROTEIN	Rough set theory is a useful tool for data mining. It is based on equivalence relations and has been extended to covering-based generalized rough set. This paper studies three kinds of covering generalized rough sets for dealing with the vagueness and granularity in information systems. First, we examine the properties of approximation operations generated by a covering in comparison with those of the Pawlak's rough sets. Then, we propose concepts and conditions for two coverings to generate an identical lower approximation operation and an identical upper approximation operation. After the discussion on the interdependency of covering lower and upper approximation operations, we address the axiomization issue of covering lower and upper approximation operations. In addition, we study the relationships between the covering lower approximation and the interior operator and also the relationships between the covering upper approximation and the closure operator. Finally, this paper explores the relationships among these three types of covering rough sets.	Chinese Acad Sci, Inst Automat, Beijing 100080, Peoples R China; Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand; Univ Arizona, Dept Syst & Ind Engn, Tucson, AZ 85721 USA	Zhu, W (reprint author), Chinese Acad Sci, Inst Automat, Beijing 100080, Peoples R China.	fzhu009@ec.auckland.ac.nz; feiyue@sie.arizona.edu					Bartol W, 2004, INFORM SCIENCES, V166, P193, DOI 10.1016/j.ins.2003.12.002; Blake C., 1998, GRANULAR COMPUTING I; BONIKOWSKI Z, 1994, P INT WORKSH ROUGH S, P243; Bonikowski Z, 1998, INFORM SCIENCES, V107, P149, DOI 10.1016/S0020-0255(97)10046-9; Bryniarski E., 1989, B POL ACAD SCI, V16, P71; Cattaneo G., 1998, ROUGH SETS KNOWLEDGE, V1, P59; Chen Y.-H., 2006, P 2006 IEEE INT C GR, P281; DENG T, 2006, P 3 INT C FUZZ SYST, P266; Deng TQ, 2007, INFORM SCIENCES, V177, P2308, DOI 10.1016/j.ins.2006.11.013; Dick S, 2007, INFORM SCIENCES, V177, P408, DOI 10.1016/j.ins.2006.03.020; FENG T, 2006, P 1 INT C ROUGH SETS, P208; [李进金 Li Jinjin], 2004, [模式识别与人工智能, Pattern recognition and artificial intelligence], V17, P7; LI TJ, 2006, P 5 INT C ROUGH SETS, P174; LI W, 2006, P 5 INT C ROUGH SETS, P776; Lin TY, 1998, INFORM SCIENCES, V104, P1, DOI 10.1016/S0020-0255(97)00071-6; Lin T.Y., 1994, P INT WORKSH ROUGH S, P256; LIN TY, 2003, P 9 INT C ROUGH SETS, P16; Mordeson JN, 2001, FUZZY SET SYST, V121, P315, DOI 10.1016/S0165-0114(00)00023-3; ORLOWSKA E, 1986, THEOR COMPUT SCI, V43, P81, DOI 10.1016/0304-3975(86)90167-2; Pal SK, 2004, IEEE T KNOWL DATA EN, V16, P292, DOI 10.1109/TKDE.2003.1262181; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pawlak Z, 2007, INFORM SCIENCES, V177, P41, DOI 10.1016/j.ins.2006.06.007; Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003; Pedrycz W, 2003, INFORM SCIENCES, V153, P199, DOI 10.1016/S0020-0255(03)00075-6; Polkowski L., 1998, ROUGH SETS KNOWLEDGE, V1; POLKOWSKI L, 1998, P 1 INT C ROUGH SETS; POLKOWSKI L, 1998, ROUGH SETS KNOWLDEGE, V2; POMYKALA J, 1993, CT930N U ILLC U AMST; Pomykata J., 1987, B POLISH ACAD SCI MA, V35, P653; Pomykata J., 1988, B POLISH ACAD SCI MA, V36, P495; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A, 2003, LECT NOTES ARTIF INT, V2639, P25; Slowinski R, 2000, IEEE T KNOWL DATA EN, V12, P331, DOI 10.1109/69.842271; Su CT, 2005, IEEE T KNOWL DATA EN, V17, P437; Tsang ECC, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4200; Wang F., 1998, INT J INTELLIGENT CO, V2, P211; Wang FY, 2005, INFORM SCIENCES, V171, P233, DOI 10.1016/j.ins.2004.04.005; Wang H, 2004, SHOCK, V21, P2; Wille R., 1982, ORDERED SETS, P445; [徐忠印 Xu Zhongyin], 2005, [河南师范大学学报. 自然科学版, Journal of Henan Normal University.Natural Science], V33, P130; [徐忠印 XU Zhongyin], 2006, [模糊系统与数学, Fuzzy Systems and Mathematics], V20, P141; YAO Y, 2007, INFORM SCI, V176, P3431; Yao Y. Y., 1999, P WORLD MULT SYST CY, P573; Yao YY, 1998, INFORM SCIENCES, V109, P21, DOI 10.1016/S0020-0255(98)00012-7; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Yao YY, 2004, LECT NOTES COMPUT SC, V3100, P232; Yao YY, 1998, INFORM SCIENCES, V109, P227, DOI 10.1016/S0020-0255(98)10023-3; Yao Y.Y., 2000, P 5 JOINT C INF SCI, VI, P186; YAO YY, 1998, P 1 INT C ROUGH SETS, P298; Yeung DS, 2005, IEEE T FUZZY SYST, V13, P343, DOI 10.1109/TFUZZ.2004.841734; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; Zadeh LA, 2005, INFORM SCIENCES, V172, P1, DOI 10.1016/j.ins.2005.01.017; ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zakowski W., 1983, DEMONSTRATIO MATH, V16, P761; ZHANG B, 1992, THEORY ALLICATION PR; ZHANG L, 2003, P INT C ROUGH SETS F, P11; ZHONG N, 2001, J JAPAN SOC FUZZY TH, V13, P581; Zhong N, 2003, IEEE T KNOWL DATA EN, V15, P952; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; Zhu Feng, 2000, Chinese Journal of Computers, V23; ZHU F, 2000, P 4 INT C HIGH PERF, V2, P670, DOI 10.1109/HPC.2000.843520; ZHU F, 2002, THESIS U ARIZONA TUC; Zhu W., 2006, P 6 INT C HYBR INT S, P43; Zhu W., 2006, P 2006 IEEE WIC ACM, P494; ZHU W, 2006, P 3 INT C FUZZ SYST, P276; Zhu W., 2006, P DM WORKSH 06 ICDM, P407; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; ZHU W, 2006, P 1 INT C ROUGH SETS, P216; Zhu W., 2006, P 3 IEEE INT C INT S, P444; ZHU W, 2006, P IEEE INT SEC INF C, P566; Zhu W, 2007, INFORM SCIENCES, V177, P1499, DOI 10.1016/j.ins.2006.06.009; Zhu XP, 2002, BIOMED ENVIRON SCI, V15, P1	77	92	119	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	AUG	2007	19	8					1131	1144		10.1109/TKDE.2007.1044		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	192SM	WOS:000248223300010	
J	Imielinski, T; Virmani, A				Imielinski, T; Virmani, A			MSQL: A query language for database mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						database mining; query language; MSQL; SQL; association rules		The tremendous number of rules generated in the mining process makes it necessary for any good data mining system to provide for powerful query primitives to post-process the generated rulebase, as well as for performing selective, query based generation. In this paper, we present the design and compilation of MSQL, the rule query language developed as part of the Discovery Board system.	Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08903 USA	Imielinski, T (reprint author), Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08903 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; HAN J, 1996, SIGMOD 96 WORKSH KDD; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Meo R, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P122; NG R, 1998, P ACM SIGMOD C MAN D; SARAWAGI S, 1998, P ACM SIGMOD C MAN D; SHEN W, 1996, ADV KNOWLEDGE DISCOV; TSUR D, 1997, P ACM SIGMOD C MAN D; VIRMANI A, 1998, THESIS RUTGERS U	9	92	95	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1999	3	4					373	408		10.1023/A:1009816913055		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	261MB	WOS:000084012000002	
J	Chan, PK; Fan, W; Prodromidis, AL; Stolfo, SJ				Chan, PK; Fan, W; Prodromidis, AL; Stolfo, SJ			Distributed data mining in credit card fraud detection	IEEE INTELLIGENT SYSTEMS & THEIR APPLICATIONS			English	Article									Florida Tech, Comp Sci, Melbourne, FL 32901 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; iPrivacy, New York, NY 10022 USA	Chan, PK (reprint author), Florida Tech, Comp Sci, Melbourne, FL 32901 USA.						Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chan P. K., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); Fan W., 1999, P 16 INT C MACH LEAR, P97; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Lee W., 1999, P 5 ACM SIGKDD INT C, P114, DOI 10.1145/312129.312212; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; PRODROMIDIS A, 1998, P 1 NAT C NEW INF TE, P151; Prodromidis A. L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; RAS Z, 1998, ROUGH SETS KNOWLEDGE, P98; SCHAPIRE RE, 1998, P 11 C COMP LEARN TH; Stolfo S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	12	92	100	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1094-7167		IEEE INTELL SYST APP	IEEE Intell. Syst. Appl.	NOV-DEC	1999	14	6					67	74		10.1109/5254.809570		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	264BJ	WOS:000084159600016	
J	Zhang, TH; Tao, DC; Li, XL; Yang, J				Zhang, Tianhao; Tao, Dacheng; Li, Xuelong; Yang, Jie			Patch Alignment for Dimensionality Reduction	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Dimensionality reduction; spectral analysis; patch alignment; discriminative locality alignment	FACE-RECOGNITION; DISCRIMINANT-ANALYSIS; PRESERVING PROJECTIONS; EIGENMAPS; EXTENSIONS; RETRIEVAL; FRAMEWORK; IMAGE	Spectral analysis-based dimensionality reduction algorithms are important and have been popularly applied in data mining and computer vision applications. To date many algorithms have been developed, e. g., principal component analysis, locally linear embedding, Laplacian eigenmaps, and local tangent space alignment. All of these algorithms have been designed intuitively and pragmatically, i.e., on the basis of the experience and knowledge of experts for their own purposes. Therefore, it will be more informative to provide a systematic framework for understanding the common properties and intrinsic difference in different algorithms. In this paper, we propose such a framework, named "patch alignment," which consists of two stages: part optimization and whole alignment. The framework reveals that 1) algorithms are intrinsically different in the patch optimization stage and 2) all algorithms share an almost identical whole alignment stage. As an application of this framework, we develop a new dimensionality reduction algorithm, termed Discriminative Locality Alignment (DLA), by imposing discriminative information in the part optimization stage. DLA can 1) attack the distribution nonlinearity of measurements; 2) preserve the discriminative ability; and 3) avoid the small-sample-size problem. Thorough empirical studies demonstrate the effectiveness of DLA compared with representative dimensionality reduction algorithms.	[Zhang, Tianhao; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China; [Tao, Dacheng] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Li, Xuelong] Univ London, Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HX, England	Zhang, TH (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.	z.tianhao@gmail.com; dctao@ntu.edu.sg; xuelong@dcs.bbk.ac.uk; jieyang@sjtu.edu.cn			National Science Foundation of China [60675023]; Chinese National 863 High Technology Plan [2007AA01Z164]; Nanyang Technological University [M58020010]	The authors thank the handling Associate Editor Prof. Sameer Singh and four anonymous reviewers for their constructive comments on this paper. The first author thanks Mr. Deli Zhao (CUHK) for beneficial discussions and selfless help. The work was supported by the National Science Foundation of China (No. 60675023), Chinese National 863 High Technology Plan (No. 2007AA01Z164), and the Nanyang Technological University SUG grant under Project M58020010.	Aslandogan YA, 1999, IEEE T KNOWL DATA EN, V11, P56, DOI 10.1109/69.755615; BELHUMEUR P, 1997, IEEE T PATTERN ANAL, V7, P711; Belkin M, 2002, ADV NEUR IN, V14, P585; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bengio Y, 2004, ADV NEUR IN, V16, P177; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Bishop CM, 1998, NEUROCOMPUTING, V21, P203, DOI 10.1016/S0925-2312(98)00043-5; Cai D, 2008, IEEE T KNOWL DATA EN, V20, P1, DOI 10.1109/TKDE.2007.190669; Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198; CAI D, 2005, 2636 U ILL DEP COMP; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Duda R. O., 2000, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Gao B, 2005, IEEE T KNOWL DATA EN, V17, P1263; Graham D.B., 1998, FACE RECOGNITION THE, V163, P446; He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692; He X., 2005, P 10 IEEE INT C COMP, P1208; He XF, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230816; He XF, 2004, ADV NEUR IN, V16, P153; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131; Koren Y, 2004, IEEE T VIS COMPUT GR, V10, P459, DOI 10.1109/TVCG.2004.17; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rosenberg S., 1997, LAPLACIAN RIEMANNIAN; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul L., 2006, SEMISUPERVISED LEARN; Saul L. K., 2003, J MACHINE LEARNING R, V4, P119; Shakhnarovich G., 2004, HDB FACE RECOGNITION; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2007, IEEE T KNOWL DATA EN, V19, P568, DOI 10.1109/TKDE.2007.1003; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tipping M., 1999, J ROYAL STAT SOC B, V61, P611; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Xu D, 2007, IEEE T SYST MAN CY B, V37, P1226, DOI 10.1109/TSMCB.2006.888925; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; Zhang TH, 2007, NEUROCOMPUTING, V70, P1547, DOI 10.1016/j.neucom.2006.11.007; Zhang Z., 2005, SIAM J SCI COMPUT, V26, P313, DOI DOI 10.1016/J.PATCOG.2009.01.010; ZHOU S, 2003, CARTR993	40	91	101	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP	2009	21	9					1299	1313		10.1109/TKDE.2008.212		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	471MO	WOS:000268062400005	
J	Bay, SD; Pazzani, MJ				Bay, SD; Pazzani, MJ			Detecting group differences: Mining contrast sets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; contrast sets; change detection; association rules	KNOWLEDGE DISCOVERY	A fundamental task in data analysis is understanding the differences between several contrasting groups. These groups can represent different classes of objects, such as male or female students, or the same group over time, e.g. freshman students in 1993 through 1998. We present the problem of mining contrast sets: conjunctions of attributes and values that differ meaningfully in their distribution across groups. We provide a search algorithm for mining contrast sets with pruning rules that drastically reduce the computational complexity. Once the contrast sets are found, we post-process the results to present a subset that are surprising to the user given what we have already shown. We explicitly control the probability of Type I error (false positives) and guarantee a maximum error rate for the entire analysis by using Bonferroni corrections.	Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA	Bay, SD (reprint author), Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA.						Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1995, P 21 INT C VER LARG; Agresti A, 1990, CATEGORICAL DATA ANA; Bay S., 1999, P 5 ACM SIGKDD INT C, P302, DOI 10.1145/312129.312263; BAY SD, 1999, UCI KDD ARCH; BAYARDO R, 1998, P ACM SIGMOD C MAN D; BAYARDO RJ, 1999, P 15 INT C DAT ENG; Bazaraa M. S., 1979, NONLINEAR PROGRAMMIN; Bishop Y.M.M., 1975, DISCRETE MULTIVARIAT; BLAKE C, 1998, UCI REPOSITORY MACH; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; CHAKRABARTI S, 1998, P 24 INT C VER LARG; COHEN J, 1990, AM PSYCHOL, V45, P1304, DOI 10.1037//0003-066X.45.12.1304; Darity WA, 1998, SOUTHERN ECON J, V64, P805, DOI 10.2307/1061206; DAVIES J, 1996, P 18 ANN C COGN SCI, P750; Dong G., 1999, P 5 ACM SIGKDD INT C; Everitt BS, 1992, ANAL CONTINGENCY TAB; GANTI V, 1999, P 18 ACM SIGMOD SIGA; Glenn ND, 1977, COHORT ANAL; Hoschka P., 1991, Knowledge discovery in databases; Keogh E., 1998, P 4 INT C KNOWL DISC; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; KLOSGEN W, 1993, EXPLORA USER DOCUMEN; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, P249; Knoke D., 1980, LOG LINEAR MODELS; LEWONTIN RC, 1965, BIOMETRICS, V21, P19, DOI 10.2307/2528349; LIN D, 1998, P 6 EUR C EXT DAT TH; Lincoff G, 1981, AUDUBON SOC FIELD GU; Liu B., 1997, P 3 INT C KNOWL DISC, P31; Liu B., 1999, P 5 ACM SIGKDD INT C; Liu B, 1999, IEEE T KNOWL DATA EN, V11, P817; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; MEGIDDO N, 1998, P 4 INT C KNOWL DISC; Menard S., 1991, LONGITUDINAL RES; MICHELL TM, 1977, P 5 INT JOINT C ART; NG R, 1998, P ACM SIGMOD C MAN D; PADMANABHAN B, 1998, P 4 INT C KNOWL DISC; RIDDLE P, 1994, APPL ARTIF INTELL, V8, P125, DOI 10.1080/08839519408945435; Ruggles S, 1997, DEMOGRAPHY, V34, P455, DOI 10.2307/3038300; Ruggles S., 1997, INTEGRATED PUBLIC US; RUGGLES S, 1995, HIST METHOD, V28, P40; RYMON R, 1992, 3 INT C PRINC KNOWL; SHAFFER JP, 1995, ANNU REV PSYCHOL, V46, P561, DOI 10.1146/annurev.psych.46.1.561; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; SRIKANT R, 1997, P 3 INT C KNOWL DISC; Srikant R, 1996, P ACM SIGMOD C MAN D; Tamhane AC, 1987, MULTIPLE COMPARISON; Zaki M.J., 1997, P 3 INT C KNOWL DISC	51	91	96	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2001	5	3					213	246		10.1023/A:1011429418057		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	443EK	WOS:000169327200005	
J	Freitas, AA				Freitas, AA			On rule interestingness measures	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	18th SGES International Conference on Knowledge-Based Systems and Applied Artificial Intelligence (ES98)	DEC 14-16, 1998	CAMBRIDGE, ENGLAND	Specialist Grp Expert Syst		data mining; rule interestingness; rule surprisingness		This paper discusses several factors influencing the evaluation of the degree of interestingness of rules discovered by a data mining algorithm. This article aims at: (1) drawing attention to several factors related to rule interestingness that have been somewhat neglected in the literature; (2) showing some ways of modifying rule interestingness measures to take these factors into account; (3) introducing a new criterion to measure attribute surprisingness, as a factor influencing the interestingness of discovered rules. (C) 1999 Elsevier Science B.V. All rights reserved.	Fed Ctr Technol Educ, CEFET, PR, DAINF, BR-80230901 Curitiba, Parana, Brazil	Freitas, AA (reprint author), Fed Ctr Technol Educ, CEFET, PR, DAINF, Av Sete Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.		Freitas, Alex/H-1249-2011				Breiman L, 1984, CLASSIFICATION REGRE; Danyluk A. P., 1993, P 10 INT C MACH LEAR, P81; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Gebhardt F., 1991, Knowledge Acquisition, V3, DOI 10.1016/S1042-8143(05)80025-1; Glymour C, 1997, DATA MIN KNOWL DISC, V1, P11, DOI 10.1023/A:1009773905005; HOLTE RC, P INT JOINT C AI IJC, P813; Kamber M., 1996, P 2 INT C KNOWL DISC, P263; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Liu B., 1997, P 3 INT C KNOWL DISC, P31; Major J. A., 1995, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V4, DOI 10.1007/BF00962821; MAJOR JA, 1993, P AAAI 93 WORKSH KNO, P28; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; QUINLAN JR, 1991, MACH LEARN, V6, P93, DOI 10.1007/BF00153762; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; ROBERTS H, 1995, P INT DAT AN C IDA 9; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; Taylor C.C., 1994, MACHINE LEARNING NEU; Ting K., 1994, P 10 CAN C ART INT, P91; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2	23	91	94	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	OCT	1999	12	5-6					309	315		10.1016/S0950-7051(99)00019-2		7	Computer Science, Artificial Intelligence	Computer Science	237GB	WOS:000082646200014	
J	Keim, DA; Kriegel, HP				Keim, DA; Kriegel, HP			Visualization techniques for mining large databases: A comparison	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; explorative data analysis; visualizing large databases; visualizing multidimensional; multivariate data	SPACE	Visual data mining techniques have proven to be of high value in exploratory data analysis, and they also have a high potential for mining large databases. In this article, we describe and evaluate a new visualization-based approach to mining large databases. The basic idea of our visual data mining techniques is to represent as many data items as possible on the screen at the same time by mapping each data value to a pixel of the screen and arranging the pixels adequately. The major goal of this article is to evaluate our visual data mining techniques and to compare them to other well-known visualization techniques for multidimensional data. the parallel coordinate and stick figure visualization techniques. For the evaluation of visual data mining techniques, in the first place the perception of properties of the data counts, and only in the second place the CPU time and the number of secondary storage accesses are important. In addition to testing the visualization techniques using real data, we developed a testing environment for database visualizations similar to the benchmark approach used for comparing the performance of database systems. The testing environment allows the generation of test data sets with predefined data characteristics which are important for comparing the perceptual abilities of visual data mining techniques.		Keim, DA (reprint author), UNIV MUNICH,INST COMP SCI,OETTINGENSTR 67,D-80538 MUNICH,GERMANY.						Agrawal R., 1994, P 20 INT C VER LARG, P487; Ahlberg C., 1994, P CHI 94, P313, DOI 10.1145/191666.191775; Ahlberg C, 1992, P ACM CHI 92, P619, DOI 10.1145/142750.143054; AHLBERG C, 1995, P ACM CHI C DEM PROG; Alpern B., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), DOI 10.1109/VISUAL.1991.175790; ANDREWS DF, 1972, BIOMETRICS, V28, P125, DOI 10.2307/2528964; Anupam V., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), DOI 10.1109/INFVIS.1995.528690; ANWAR TM, 1992, P INT C DAT ENG TAMP, P622; ASIMOV D, 1985, SIAM J SCI STAT COMP, V6, P128, DOI 10.1137/0906011; Becker R. A., 1988, NEW S LANGUAGE; BECKER RA, 1995, IEEE T VISUALIZATION, V1, P1628; BEDDOW J, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P238, DOI 10.1109/VISUAL.1990.146387; BERGERON RD, 1994, PERCEPTUAL ISSUES VI, P922; BESHERS C, 1990, COMPUTER GRAPHICS, V24, P37; Buja A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), DOI 10.1109/VISUAL.1991.175794; CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077; Cleveland W. S., 1993, VISUALIZING DATA; Consens M.P., 1993, P ACM SIGMOD INT C M, P511, DOI 10.1145/170035.171537; Dunn G., 1982, INTRO MATH TAXONOMY; Frawley W. J., 1991, Knowledge discovery in databases; FREI HP, 1991, P GI GMD WORKSH DARM, V289, P11; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; FURNAS GW, 1994, J COMPUTATIONAL GRAP, V3, P323, DOI 10.2307/1390897; Gaasterland T., 1992, J INTELL INF SYST, V1, P123, DOI 10.1007/BF00962280; GRINSTEIN G, 1989, P GRAPHICS INTERFACE; GRINSTEIN G, 1991, VISUALIZATION KNOWLE; HAN J, 1993, IEEE T KNOWL DATA EN, V5, P209; HERMAN GT, 1992, COMPUTER GRAPHICS AP, P72; Hilbert D, 1891, MATH ANN, V38, P459, DOI DOI 10.1007/BF01199431; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402; Inselberg Alfred, 1985, VISUAL COMPUT, V1, P69, DOI DOI 10.1007/BF01898350; Keim D. A., 1994, Proceedings. The 10th International Conference Data Engineering (Cat. No.94CH3383-7), DOI 10.1109/ICDE.1994.283045; KEIM DA, 1995, P C VIS DAT SYST VDB, P203; KEIM DA, 1995, P ACM SIGMOD INT C M, P482, DOI 10.1145/223784.223895; KEIM DA, 1995, P WORKSH DAT ISS DAT; KEIM DA, 1994, COMPUTER GRAPHIC SEP, P40; KEIM DA, 1994, THESIS U MUNICH AACH; Keim D. A., 1995, Proceedings. Visualization '95 (Cat. No.95CB35835), DOI 10.1109/VISUAL.1995.485140; Knuth D, 1973, ART COMPUTER PROGRAM, V3; LEBLANC J, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P230, DOI 10.1109/VISUAL.1990.146386; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; Morton G., 1966, COMPUTER ORIENTED GE; Motro A., 1990, IEEE Transactions on Knowledge and Data Engineering, V2, DOI 10.1109/69.54722; Ng R, 1994, P 20 INT C VER LARG, P144; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Peano G, 1890, MATH ANN, V36, P157, DOI 10.1007/BF01199438; Pickett R. M., 1988, Proceedings of the 1988 IEEE International Conference on Systems, Man, and Cybernetics (IEEE Cat. No.88CH2556-9); PICKETT RM, 1970, PICTURE PROCESSING P; Robertson G., 1991, P ACM C HUM FACT COM, P189, DOI 10.1145/108844.108883; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768; SWAYNE DF, 1992, USERS MANUAL XGOBI D; TUFTE ER, 1990, ENVISIONING INFORMAT; Tufte E.R., 1983, VISUAL DISPLAY QUANT; van Wijk J. J., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), DOI 10.1109/VISUAL.1993.398859; Vasudevan V., 1994, Proceedings. The 10th International Conference Data Engineering (Cat. No.94CH3383-7), DOI 10.1109/ICDE.1994.283044; VELLEMAN PF, 1992, DATA DESK 4 2 DATA D; Ward M. O., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), DOI 10.1109/VISUAL.1994.346302	59	91	93	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	DEC	1996	8	6					923	938		10.1109/69.553159		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	WC057	WOS:A1996WC05700006	
J	Banerjee, A; Dhillon, IS; Ghosh, J; Sra, S				Banerjee, A; Dhillon, IS; Ghosh, J; Sra, S			Clustering on the unit hypersphere using von Mises-Fisher distributions	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						clustering; directional distributions; mixtures; von Mises-Fisher; expectation maximization; maximum likelihood; high dimensional data	FITTING MIXTURES; EM; MODELS	Several large scale data mining applications, such as text categorization and gene expression analysis, involve high-dimensional data that is also inherently directional in nature. Often such data is L(2) normalized so that it lies on the surface of a unit hypersphere. Popular models such as (mixtures of) multi-variate Gaussians are inadequate for characterizing such data. This paper proposes a generative mixture-model approach to clustering directional data based on the von Mises-Fisher (vMF) distribution, which arises naturally for data distributed on the unit hypersphere. In particular, we derive and analyze two variants of the Expectation Maximization (EM) framework for estimating the mean and concentration parameters of this mixture. Numerical estimation of the concentration parameters is non-trivial in high dimensions since it involves functional inversion of ratios of Bessel functions. We also formulate two clustering algorithms corresponding to the variants of EM that we derive. Our approach provides a theoretical basis for the use of cosine similarity that has been widely employed by the information retrieval community, and obtains the spherical kmeans algorithm (kmeans with cosine similarity) as a special case of both variants. Empirical results on clustering of high-dimensional text and gene-expression data based on a mixture of vMF distributions show that the ability to estimate the concentration parameter for each vMF component, which is not present in existing approaches, yields superior results, especially for difficult clustering tasks in high-dimensional spaces.	Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA; Univ Texas, Dept Comp Sci, Austin, TX 78712 USA	Banerjee, A (reprint author), Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA.	ABANERJE@ECE.UTEXAS.EDU; INDERJIT@CS.UTEXAS.EDU; GHOSH@ECE.UTEXAS.EDU; SUVRIT@CS.UTEXAS.EDU					Abramowitz M, 1974, HDB MATH FUNCTIONS; Amari SI, 1995, NEURAL NETWORKS, V8, P1379, DOI 10.1016/0893-6080(95)00003-8; Banerjee A, 2004, SIAM PROC S, P234; Banerjee A, 2004, IEEE T NEURAL NETWOR, V15, P702, DOI 10.1109/TNN.2004.824416; Banerjee A., 2004, P 10 INT C KNOWL DIS, P515, DOI 10.1145/1014052.1014112; Banerjee A, 2002, IEEE IJCNN, P1590, DOI 10.1109/IJCNN.2002.1007755; Bilmes J.A., 1997, ICSITR97021 U BERK; BLUM A, 2003, P 16 ANN C LEARN THE; BRADLEY PS, 2000, CONSTRAINED KMEANS C; Coleman D, 1999, COMPUT STAT DATA AN, V31, P1, DOI 10.1016/S0167-9473(99)00009-2; COLLINS M, 1997, EM ALGORITHM FULFILL; Cover T. M., 1991, ELEMENTS INFORM THEO; Dasgupta S, 1999, IEEE S FDN COMPUTER; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DHILLON I., 2001, DATA MINING SCI ENG; DHILLON IS, 2002, P 2002 IEEE INT C DA; DHILLON IS, 2002, 200249 U TEX DEP COM; DHILLON IS, 2003, TR0306 U TEX AUST AU; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; DOM BE, 2001, 10219 IBM; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FISHER N. I., 1996, STAT ANAL CIRCULAR D; Ghosh J, 2003, HUM FAC ER, P247; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; INDYK P, 1999, 40 S FDN COMP SCI; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kannan R, 2000, ANN IEEE SYMP FOUND, P367; KEARNS M, 1997, 13 ANN C UNC ART INT; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; Mardia K. V., 1975, STAT DISTRIBUTIONS S, V3, P365; Mardia K. V., 2000, DIRECTIONAL STAT; McLachlan G., 2000, FINITE MIXTURE MODEL; McLachlan G. J., 1982, HDB STATISTICS, V2, P199, DOI 10.1016/S0169-7161(82)02012-4; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; MEILA M, 2003, COLT; Mooney JA, 2003, COMPUT STAT DATA AN, V41, P505; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Peel D, 2001, J AM STAT ASSOC, V96, P56, DOI 10.1198/016214501750332974; PIATER JH, 2001, THESIS U MASSACHUSSE; Rao C. R., 1973, LINEAR STAT INFERENC; Rasmussen E., 1992, INFORMATION RETRIEVA, P419; Salton G., 1983, INTRO MODERN RETRIEV; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SARWAR BM, 2001, WORLD WIDE WEB, V10, P285; Scholkopf B, 2001, LEARNING KERNELS; SEGAL E, 2003, P 8 PAC S BIOC; Sharan R., 2000, Proceedings. Eighth International Conference on Intelligent Systems for Molecular Biology; Shimizu K, 2002, COMMUN STAT-THEOR M, V31, P513, DOI 10.1081/STA-120003131; Sinkkonen J, 2002, NEURAL COMPUT, V14, P217, DOI 10.1162/089976602753284509; Smyth P, 1997, ADV NEUR IN, V9, P648; Steinbach M., 2000, KDD WORKSH TEXT MINI; Strehl A., 2000, P AAAI WORKSH AI WEB, P58; Wallace CS, 2000, STAT COMPUT, V10, P73, DOI 10.1023/A:1008992619036; Watson G.N., 1995, TREATISE THEORY BESS; WOOD ATA, 1994, COMMUN STAT SIMULAT, V23, P157, DOI 10.1080/03610919408813161; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6; Zhong S, 2003, J MACHINE LEARNING R, V4, P1001, DOI 10.1162/jmlr.2003.4.6.1001; ZHONG S, 2003, WORKSH CLUSTERING HI	60	89	89	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	SEP	2005	6						1345	1382				38	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HN	WOS:000236330100004	
J	Zaki, MJ				Zaki, MJ			Efficiently mining frequent trees in a forest: Algorithms and applications	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						frequent tree mining; rooted; ordered; labeled trees; subtree enumeration; pattern matching; RNA structure; phylogenetic trees; data mining	DATABASE; PATTERNS; GRAPHS	Mining frequent trees is very useful in domains like bioinformatics, Web mining, mining semistructured data, etc. We formulate the problem of mining (embedded)subtrees in a forest of rooted, labeled, and ordered trees. We present TREEMINER, a novel algorithm to discover all frequent subtrees in a forest, using a new data structure called scope-list. We contrast TREEMINER with a pattern matching tree mining algorithm (PATTERNMATCHER), and we also compare it with TREEMINERD, which counts only distinct occurrences of a pattern. We conduct detailed experiments to test the performance and scalability of these methods. We also use tree mining to analyze RNA structure and phylogenetics data sets from bioinformatics domain.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Zaki, MJ (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.	zaki@cs.rpi.edu					ABITEBOUL S, 2001, P ACM S DISCR ALG JA; ABITEBOUL S, 1997, P ACM INT C PRINC DA; Agrawal R., 1995, P 11 INT C DAT ENG; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; ASAI T, 2002, P 2 SIAM INT C DAT M; ASAI T, 2003, P 6 INT C DISC SCI O; Brown JW, 1999, NUCLEIC ACIDS RES, V27, P314, DOI 10.1093/nar/27.1.314; CHEN Z, 2001, P 17 INT C DAT ENG; CHI Y, 2003, P 3 IEEE INT C DAT M; Chi Y., 2004, P 16 INT C SCI STAT; COLE R, 1999, P 10 S DISCR ALG; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; DEHASPE L, 1998, P 4 INT C KNOWL DISC; FERNANDEZ MF, 1998, P IEEE INT C DAT ENG; Gan HH, 2003, NUCLEIC ACIDS RES, V31, P2926, DOI 10.1093/nar/gkg365; Gan HH, 2004, BIOINFORMATICS, V20, P1285, DOI 10.1093/bioinformatics/bth084; HUANG J, 2003, P IEEE INT C DAT MIN; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; KRAMER S, 2001, P INT C KNOWL DISC D; Kuramochi M, 2004, IEEE T KNOWL DATA EN, V16, P1038, DOI 10.1109/TKDE.2004.33; Li Q., 2001, P 27 INT C VER LARG; KILPELAINEN P, 1995, SIAM J COMPUT, V24, P340; Morell V, 1996, SCIENCE, V273, P568, DOI 10.1126/science.273.5275.568; Mount D. M., 2001, BIOINFORMATICS SEQUE; NIJSSEN S, 2004, P ACM SIGKDD INT C K; Nijssen S., 2003, P 1 INT WORKSH MIN G; Page R.D.M., 1998, MOL EVOLUTION PHYLOG; RUCKERT U, 2004, SPEC TRACK DAT MIN P; Shamir R, 1999, J ALGORITHM, V33, P267, DOI 10.1006/jagm.1999.1044; SHAPIRO BA, 1990, COMPUT APPL BIOSCI, V6, P309; SHASHA D, 2004, P INT C DAT ENG; TERMIER A, 2002, P IEEE INT C DAT MIN; WANG C, 2004, P PAC AS C KNOWL DIS; WANG K, 1998, P ACM SIGIR C INF RE; XIAO Y, 2003, P INT C DAT MIN; YAN X, 2002, P IEEE INT C DAT MIN; YAN X, 2003, ACM SIGKDD INT C KNO; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A; Zaki M.J., 2003, P 9 ACM SIGKDD INT C; ZAKI MJ, 2001, 017 RENSS POL I COMP; ZAKI MJ, 2002, P 8 ACM SIGKDD INT C; ZHANG C, 2001, P ACM INT C MAN DAT	42	89	102	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	AUG	2005	17	8					1021	1035		10.1109/TKDE.2005.125		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	935UP	WOS:000229809200002	
J	Zhou, C; Xiao, WM; Tirpak, TM; Nelson, PC				Zhou, C; Xiao, WM; Tirpak, TM; Nelson, PC			Evolving accurate and compact classification rules with gene expression programming	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						classification rule; data mining; gene expression programming (GEP); genetic algorithms (GAs) .	INDUCTION	Classification is one of the fundamental tasks of data mining. Most rule induction and decision tree algorithms perform local, greedy search to generate classification rules that are often more complex than necessary. Evolutionary algorithms for pattern classification have recently received increased attention because they can perform global searches. In this paper, we propose a new approach for discovering classification rules by using gene expression programming (GEP), a new technique of genetic programming (GP) with linear representation. The antecedent of discovered rules may involve many different combinations of attributes. To guide the search process, we suggest a fitness function considering both the rule consistency gain and completeness. A multiclass classification problem is formulated as multiple two-class problems by using the one-against-all learning method. The covering strategy is applied to learn multiple rules if applicable for each class. Compact rule sets are subsequently evolved using a two-phase pruning method based on the minimum description length (MDL) principle and the integration theory. Our approach is also noise tolerant and able to deal with both numeric and nominal attributes. Experiments with several benchmark data sets have shown up to 20% improvement in validation accuracy, compared with C4.5 algorithms. Furthermore, the proposed GEP approach is more efficient and tends to generate shorter solutions compared with canonical tree-based GP classifiers.	Motorola Inc, Ctr Adv Technol, Schaumburg, IL 60196 USA; Univ Illinois, Artificial Intelligence Lab, Dept Comp Sci, Chicago, IL 60607 USA	Zhou, C (reprint author), Motorola Inc, Ctr Adv Technol, Schaumburg, IL 60196 USA.	A19387@motorola.com; AWX003@motorola.com; T.Tirpak@motorola.com; nelson@cs.uic.edu					AUGIER S, 1995, P 1 INT C KNOWL DISC, P21; Banzhaf W, 1994, LECT NOTES COMPUT SC, V866, P322; Blake C, 1998, UCI REPOSITORY MACHI; Bojarczuk CC, 1999, P GEN EV COMP C ORL, P953; BOJARCZUK CC, 2001, P INT DAT AN MED PHA; Bot MCJ, 2000, LECT NOTES COMPUT SC, V1802, P247; BRAZDIL PB, 1990, CURRENT TRENDS KNOWL; Breiman L, 1984, CLASSIFICATION REGRE; Bruha I., 1997, MACHINE LEARNING STA, P107; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; DAVENPORT GF, 1999, P GEN EV COMP C GECC, V2, P990; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; EGGERMONT J, 1999, ADV INTELLIGENT DATA; Ferreira C, 2002, PROCEEDINGS OF THE 6TH JOINT CONFERENCE ON INFORMATION SCIENCES, P614; Ferreira C., 2001, Complex Systems, V13; FLOCKHART IW, 1996, P 2 INT C KNOWL DISC, P299; Freitas A., 2001, ADV EVOLUTIONARY COM; FREITAS AA, 1997, P 2 ANN C GEN PROGR, P96; Furnkranz J., 2001, P 18 INT C MACH LEAR, P146; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Hekanaho J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; HERRERA F, 1995, FUZZY LOGIC SOFT COM, P11; Holland J.H, 1978, PATTERN DIRECTED INF; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V8, P485; JANIKOW CZ, 1993, MACH LEARN, V13, P189, DOI 10.1023/A:1022669929488; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; Koza J. R., 1992, GENETIC PROGRAMMING; KOZA JR, 1991, PARALLEL PROBLEM SOL; LANZI PL, 2000, LECT NOTES ARTIFICIA, V1813; Wong ML, 2000, GENET PROGR SER, V3, P1; LOVEARD T, 2001, P C EV COMP, V2, P1070, DOI 10.1109/CEC.2001.934310; LUKE S, 2000, 2000 GEN EV COMP C L, P228; MARMELSTEIN RE, 1998, P 3 ANN C GEN PROGR, P223; MARMELSTEIN RE, 1998, GEN PROGR 1998 C, P22; MARMELSTEIN RE, 1999, INT ICSC C COMP INT; MICHALSKI RS, 2001, LECT NOTES ARTIF INT, V2049, P22; Mitchell T. M, 1997, MACHINE LEARNING; Montana DJ, 1995, EVOL COMPUT, V3, P199, DOI 10.1162/evco.1995.3.2.199; NIKOLAEV NI, 1998, INTELL DATA ANAL, V2, P31, DOI 10.1016/S1088-467X(98)00005-5; NODA E, 1999, 1999 C EV COMP CEC 9; PATERSON MR, 1996, GEN PROGR 1996 C, P141; PEI M, 1997, 1 PAC AS C KNOWL DIS; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rosca J., 1996, P 1 ANN C GEN PROGR, P381; Ryan C., 1998, LECT NOTES COMPUTER, V1391, P83; Corcoran A. L., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), DOI 10.1109/ICEC.1994.350030; Smith S. F., 1983, P 8 INT JOINT C ART, P422; TACKETT WA, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P303; Tan KC, 2002, P C EV COMP CEC 02, V2, P1302, DOI 10.1109/CEC.2002.1004431; THRUN SB, 1991, CSCMU91197 COMP SCI; Venturini G., 1993, P EUR C MACH LEARN V, P280; Zhang BT, 1995, EVOL COMPUT, V3, P17, DOI 10.1162/evco.1995.3.1.17; ZHOU C, 2002, INT C ART INT IC AI	57	89	105	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	DEC	2003	7	6					519	531		10.1109/TEVC.2003.819261		13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	759KC	WOS:000187736000002	
J	Berendt, B; Spiliopoulou, M				Berendt, B; Spiliopoulou, M			Analysis of navigation behaviour in web sites integrating multiple information systems	VLDB JOURNAL			English	Article						Web usage mining; data mining; Web query interfaces; Web databases; query capabilities; conceptual hierarchies		The analysis of web usage has mostly focused on sites composed of conventional static pages. However, huge amounts of information available in the web come from databases or other data collections and are presented to the users in the form of dynamically generated pages. The query interfaces of such sites allow the specification of many search criteria. Their generated results support navigation to pages of results combining cross-linked data from many sources. For the analysis of visitor navigation behaviour in such web sites, we propose the web usage miner (WUM), which discovers navigation patterns subject to advanced statistical and structural constraints. Since our objective is the discovery of interesting navigation patterns, we do not focus on accesses to individual pages. Instead, Eve construct conceptual hierarchies that reflect the query capabilities used in the production of these pages. Our experiments with a real web site that integrates data from multiple databases, the German SchulWeb, demonstrate the appropriateness of WUM in discovering navigation patterns and show how those discoveries can help in assessing and improving the quality of the site.	Humboldt Univ, Fac Philosophy 4, Inst Petag & Informat, D-10117 Berlin, Germany; Humboldt Univ, Fac Econ, Inst Informat Syst, D-10178 Berlin, Germany	Spiliopoulou, M (reprint author), Humboldt Univ, Fac Philosophy 4, Inst Petag & Informat, D-10117 Berlin, Germany.						AGRAWAL R, 1995, P INT C DAT ENG TAIP; Agrawal R., 1993, SIGMOD, P207; Benjafield J. G., 1994, THINKING CRITICALLY; Berry M. R. J., 1997, DATA MINING TECHNIQU; Berthon P, 1996, J ADVERTISING RES, V36, P43; BUCHNER AG, 1999, WEBKDD 99; Buchner A.G., 1998, ACM SIGMOD RECORD, V27, P54, DOI 10.1145/306101.306124; CHAKRABARTI S, 1997, VLDB 97, P446; Chen MS, 1996, INT CON DISTR COMP S, P385; COOLEY R, 1999, J KNOWLEDGE INFORMAT, V1; COOLEY R, 1999, MS99; Eighmey J, 1997, J ADVERTISING RES, V37, P59; FLEMING J, 1999, WEB NAVIGATION DESIG; Goldman R., 1997, VLDB, P436; JOACHIM T, 1997, P IJCAI 97; MARTIN D, 1999, MS99; MASAND B, 1999, KDD 99 WORKSH WEB US; Perkowitz M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; PIROLLI P, 1996, CHI 96; ROSENFELD L, 1998, INFORMATION ARCH WOR; SPILIOPOULOU M, 1999, INT J COMP SYS SCI E, V14, P113; SPILIOPOULOU M, 1999, P WORKSH MACH LEARN; Spiliopoulou M, 1999, LECT NOTES COMPUT SC, V1590, P184; Srikant R., 1996, EDBT; SULLIVAN T, 1997, P WEB C 97; TAUSCHER L, 1997, P INT C CHI 97 ATL G; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; WANG K, 1997, KDD 97, P271; WANG K, 1997, INTELLIGENT INFORMAT, V9, P8; WEXELBLAT A, 1996, P AAAI SPRING S ACQ; ZAIANE O, 1998, ADV DIGITAL LIB, P19; Zamir O., 1997, KDD 97, P287	32	89	92	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1066-8888		VLDB J	VLDB J.	APR	2000	9	1					56	75		10.1007/s007780050083		20	Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	321CE	WOS:000087436700005	
J	Inokuchi, A; Washio, T; Motoda, H				Inokuchi, A; Washio, T; Motoda, H			Complete mining of frequent patterns from graphs: Mining graph data	MACHINE LEARNING			English	Article						data mining; graph data; Apriori algorithm; adjacency matrix; Web browsing analysis; chemical carcinogenesis analysis	NETWORKS	Basket Analysis, which is a standard method for data mining, derives frequent itemsets from database. However, its mining ability is limited to transaction data consisting of items. In reality, there are many applications where data are described in a more structural way, e. g. chemical compounds and Web browsing history. There are a few approaches that can discover characteristic patterns from graph-structured data in the field of machine learning. However, almost all of them are not suitable for such applications that require a complete search for all frequent subgraph patterns in the data. In this paper, we propose a novel principle and its algorithm that derive the characteristic patterns which frequently appear in graph-structured data. Our algorithm can derive all frequent induced subgraphs from both directed and undirected graph structured data having loops (including self-loops) with labeled or unlabeled nodes and links. Its performance is evaluated through the applications to Web browsing pattern analysis and chemical carcinogenesis analysis.	Osaka Univ, Inst Sci & Ind Res, Osaka 5670047, Japan	Inokuchi, A (reprint author), IBM Japan Ltd, Tokyo Res Lab, Tokyo 102, Japan.	washio@sanken.osaka-u.ac.jp; motoda@sanken.osaka-u.ac.jp	Inokuchi, Akihiro/F-2283-2010				AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Biggs N., 1974, ALGEBRAIC GRAPH THEO; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; De Raedt L., 2001, P 17 INT JOINT C ART, V2, P853; DEBNATH AK, 1991, J MED CHEM, V34, P786, DOI 10.1021/jm00106a046; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Fortin S., 1996, 9620 U ALB; Garey M. R., 1979, COMPUTERS INTRACTABI; GEIBEL P, 1996, P 13 INT C MACH LEAR, P166; Hogg T, 1996, ARTIF INTELL, V81, P1, DOI 10.1016/0004-3702(95)00044-5; INOKUCHI A, 1999, P 3 PAC AS C KNOWL D, P420; INOKUCHI A, 2000, INT WORKSH KDD CHALL; KANN V, 1995, LECT NOTES COMPUT SC, V969, P227; LIQUIERE M, 1998, P 15 INT C MACH LEAR, P305; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; McKay B. D., 1990, TRCS9002 AUSTR NAT U; Nijssen S, 2001, P 17 INT JOINT C ART, V2, P891; READ RC, 1977, J GRAPH THEOR, V1, P339, DOI DOI 10.1002/JGT.3190010410; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; SRINIVASAN A, 1997, P 15 INT JOINT C ART, P4; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; Walsh T., 2001, P 17 INT JOINT C ART, P266; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A	27	88	98	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAR	2003	50	3					321	354		10.1023/A:1021726221443		34	Computer Science, Artificial Intelligence	Computer Science	627QJ	WOS:000179944600006	
B	Yin, XX; Han, JW		Barbara, D; Kamath, C		Yin, XX; Han, JW			CPAR: Classification based on Predictive Association Rules	PROCEEDINGS OF THE THIRD SIAM INTERNATIONAL CONFERENCE ON DATA MINING	SIAM PROCEEDINGS SERIES		English	Proceedings Paper	3rd SIAM International Conference on Data Mining	MAY 01-03, 2003	SAN FRANCISCO, CA					Recent studies in data mining have proposed a new classification approach, called associative classification, which, according to several reports, such as [7, 6], achieves higher classification accuracy than traditional classification approaches such as C4.5. However, the approach also suffers from two major deficiencies: (1) it generates a very large number of association rules, which leads to high processing overhead; and (2) its confidence-based rule evaluation measure may lead to overfitting. In comparison with associative classification, traditional rule-based classifiers, such as C4.5, FOIL and RIPPER, are substantially faster but their accuracy, in most cases, may not be as high. In this paper, we propose a new classification approach, CPAR (Classification based on Predictive Association Rules), which combines the advantages of both associative classification and traditional rule-based classification. Instead of generating a large number of candidate rules as in associative classification, CPAR adopts a greedy algorithm to generate rules directly from training data. Moreover, CPAR generates and tests more rules than traditional rule-based classifiers to avoid missing important rules. To avoid overfitting, CPAR uses expected accuracy to evaluate each rule and uses the best k rules in prediction.	Univ Illinois, Urbana, IL 61801 USA	Yin, XX (reprint author), Univ Illinois, Urbana, IL 61801 USA.						Agrawal R., 1994, VLDB, P487; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cohen W. W., 1995, INT C MACH LEARN, P115; GEHRKE J, 1998, VLDB 98 NEW YORK NY, P416; Han J, 2000, SIGMOD 00, P1, DOI DOI 10.1145/342009.335372; Li Wenmin, 2001, ICDM, P369; LIU B, 1998, KDD 98 NEW YORK NY A; Quinlan J. R., 1993, P EUR C MACH LEARN, P3; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN	9	86	95	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA		0-89871-545-8	SIAM PROC S			2003							331	335				5	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	BX26M	WOS:000184780800040	
B	Das, G; Gunopulos, D; Mannila, H		Komorowski, J; Zytkow, J		Das, G; Gunopulos, D; Mannila, H			Finding similar time series	PRINCIPLES OF DATA MINING AND KNOWLEDGE DISCOVERY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	1st European Symposium on Principles of Data Mining and Knowledge Discovery (PKDD 97)	JUN 24-27, 1997	TRONDHEIM, NORWAY					Similarity of objects is one of the crucial concepts in several applications, including data mining. For complex objects, similarity is nontrivial to define. In this paper we present an intuitive model for measuring the similarity between two time series. The model takes into account outliers, different scaling functions, and variable sampling rates. Using methods from computational geometry, we show that this notion of similarity can be computed in polynomial time. Using statistical approximation techniques, the algorithms can be speeded up considerably. We give preliminary experimental results that show the naturalness of the notion.	Univ Memphis, Memphis, TN 38152 USA; Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland; IBM Corp, San Jose, CA 95120 USA	Das, G (reprint author), Univ Memphis, Memphis, TN 38152 USA.	dasg@next1.msci.memphis.edu; gunopulo@almaden.ibm.com; Heikki.Mannila@cs.helsinki.fi					AGRAWAL R, 1993, P 4 INT C FDN DAT OR; Agrawal R., 1995, P 21 INT C VER LARG, P490; Aho A. V., 1990, HDB THEORETICAL COMP, VA, P255; Berndt D. J., 1996, ADV KNOWLEDGE DISCOV, P229; BOLLOBAS B, 1997, ACM COMPUTATIONAL GE; FALOUTSOS C, 1994, SIGMOD 94 MAY; GOLDIN D, 1995, INT C PRINC PRACT CO, P137; HOAGLIN DC, 1982, UNDERSTANDING ROBUST; Jagadish H. V., 1995, Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1995, DOI 10.1145/212433.212444; Sankoff D., 1983, TIME WARPS STRING ED; SHATKAY H, 1996, ICDE 96; WHITE DA, 1996, VCL96101 U CAL VIS C; Yazdani N., 1996, Proceedings. Eighth International Conference on Scientific and Statistical Database Management (Cat. No.96TB100051), DOI 10.1109/SSDM.1996.505915	13	86	90	SPRINGER-VERLAG BERLIN	BERLIN 33	HEIDELBERGER PLATZ 3, W-1000 BERLIN 33, GERMANY		3-540-63223-9	LECT NOTES ARTIF INT			1997	1263						88	100				13	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BK96X	WOS:000073947600010	
J	Zielstorff, RD				Zielstorff, RD			Online practice guidelines: Issues, obstacles, and future prospects	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Proceedings Paper	Nursing Informatics 97 Working Conference on Informatics and Patient and Clinical Guidelines - the State of our Knowledge and a Vision	OCT 02-04, 1997	STOCKHOLM, SWEDEN	Int Med Informat Assoc			PREVENTIVE CARE GUIDELINES; CLINICAL-PRACTICE; DECISION-SUPPORT; RECOMMENDATIONS; IMPLEMENTATION; PHYSICIANS; MANAGEMENT; PERFORMANCE; INFORMATION; OUTCOMES	The "guidelines movement" was formed to reduce variability in practice, control costs, and improve patient care outcomes. Yet the overall impact on practice and outcomes has been disappointing. Evidence demonstrates that the most effective method of stimulating awareness of and compliance with best practices is computer-generated reminders provided at the point of care. This paper reviews five steps along the path from the development of a guideline to its integration into practice and the subsequent evaluation of its impact on practice and outcomes. Issues arising at each step and obstacles to moving from one step to the next are described. Last, developments that could help overcome the obstacles are highlighted. These include 1) more rapid knowledge acquisition using data mining, 2) better accommodation to imprecise knowledge in clinical algorithms using fuzzy logic, 3) development of a shareable model for guideline representation and execution, and 4) more widespread availability of clinically robust information systems that support decision-making at the point of care.	Partners HealthCare Syst, Boston, MA USA	Zielstorff, RD (reprint author), Partners Informat Syst, Clin Informat Syst Res & Dev, 850 Boylston St,Suite 202, Brookline, MA 02167 USA.	rzielsto@warren.med.harvard.edu					Appleton JV, 1997, PUBLIC HEALTH, V111, P107, DOI 10.1016/S0033-3506(97)90011-1; BARAHONA P, 1995, COMPUT METH PROG BIO, V48, P27, DOI 10.1016/0169-2607(95)01656-E; BARNAS GP, 1996, P AMIA ANN FALL S, P827; Berger JT, 1996, ARCH INTERN MED, V156, P2051, DOI 10.1001/archinte.156.18.2051; Bisognano M A, 1995, Qual Lett Healthc Lead, V7, P16; BONICHON F, 1996, ANT TREATMENT 6 INT, P131; Bosl G J, 1996, Oncology (Williston Park), V10, P247; Canadian medical association, 1994, GUID CAN CLIN PRACT; CHASSIN MR, 1990, J OCCUP ENVIRON MED, V32, P1199, DOI 10.1097/00043764-199012000-00015; Chueh H, 1997, ACAD MED, V72, P512, DOI 10.1097/00001888-199706000-00016; CIMINO JJ, 1995, P 19 ANN S COMP APPL, P941; Cook DJ, 1997, ANN INTERN MED, V127, P210; DAVIS DA, 1995, JAMA-J AM MED ASSOC, V274, P700, DOI 10.1001/jama.274.9.700; Dean-Baar S L, 1993, J Nurs Care Qual, V8, P33; DEIBEL SRA, 1997, INTRO INTERMED COMMO; EAST T, 1992, INT J CLIN MONIT COM, V8, P263; Elson R B, 1995, Arch Fam Med, V4, P698, DOI 10.1001/archfami.4.8.698; Elson RB, 1997, J AM MED INFORM ASSN, V4, P266; ERIKSEN LR, 1997, P 6 INT C NURS INF N, P383; Field MJ, 1992, GUIDELINES CLIN PRAC; FLETCHER RH, 1990, ANN INTERN MED, V113, P645; Fridsma D B, 1996, Proc AMIA Annu Fall Symp, P597; GOTZSCHE PC, 1995, ST HEAL T, V16, P17; GRECO PJ, 1993, NEW ENGL J MED, V329, P1271, DOI 10.1056/NEJM199310213291714; Grilli R, 1996, THERAPIE, V51, P265; Harpole LH, 1997, J AM MED INFORM ASSN, V4, P511; Hogan WR, 1997, J AM MED INFORM ASSN, V4, P342; HULSE M, 1997, P AMIA ANN FALL S, P951; Jacox A, 1993, Nurs Econ, V11, P170; Jenders R A, 1994, Proc Annu Symp Comput Appl Med Care, P802; JOHNSTON ME, 1994, ANN INTERN MED, V120, P135; Kuperman G J, 1997, Proc AMIA Annu Fall Symp, P243; Lam S H, 1993, Proc Annu Symp Comput Appl Med Care, P253; Leape L L, 1990, QRB Qual Rev Bull, V16, P42; Liem E B, 1995, Proc Annu Symp Comput Appl Med Care, P223; Litzelman DK, 1996, J GEN INTERN MED, V11, P497, DOI 10.1007/BF02599049; Liu J C, 1997, Proc AMIA Annu Fall Symp, P283; Lobach D F, 1995, Proc Annu Symp Comput Appl Med Care, P581; Lobach D F, 1994, Proc Annu Symp Comput Appl Med Care, P787; LOMAS J, 1989, NEW ENGL J MED, V321, P1306, DOI 10.1056/NEJM198911093211906; LUMSDON K, 1995, HOSP HEALTH NETWORK, V69, P38; LUMSDON K, 1995, HOSP HEALTH NETWORK, V69, P40; LUMSDON K, 1995, HOSP HEALTH NETWORK, V69, P34; Magyary D, 1993, J Pediatr Nurs, V8, P253; Marek K, 1995, MANUAL DEV GUIDELINE; Margolis A, 1995, Proc Annu Symp Comput Appl Med Care, P228; McDonald CJ, 1996, ANN INTERN MED, V124, P170; McKenna H P, 1995, Br J Nurs, V4, P1257; Mosser G, 1996, Med Interface, V9, P136; Murphy R N, 1996, Adv Wound Care, V9, P31; Naditch M P, 1995, J Healthc Resour Manag, V13, P24; NASH DB, 1990, ARCH PATHOL LAB MED, V114, P1122; Nilasena D S, 1994, Proc Annu Symp Comput Appl Med Care, P831; Nilasena D S, 1995, Proc Annu Symp Comput Appl Med Care, P640; Overhage JM, 1996, ARCH INTERN MED, V156, P1551, DOI 10.1001/archinte.156.14.1551; Parboosingh EJ, 1996, CAN MED ASSOC J, V154, P1847; Petrucci K, 1991, Proc Annu Symp Comput Appl Med Care, P43; Prather J C, 1997, Proc AMIA Annu Fall Symp, P101; Pryor David B., 1995, International Journal of Bio-Medical Computing, V39, P105, DOI 10.1016/0020-7101(94)01087-H; RAFUSE J, 1994, CAN MED ASSOC J, V150, P1479; Rischer JB, 1996, JOINT COMM J QUAL IM, V22, P683; ROBBINS JA, 1993, SOUTHERN MED J, V86, P289; SAFRAN C, 1995, MEDINFO 2, P1076; Schmidt K L, 1996, AACN Clin Issues, V7, P425, DOI 10.1097/00044067-199608000-00011; SCHRIGER DL, 1995, MEDINFO 2, P1018; Scott L, 1995, Mod Healthc, V25, P30; Shiffman R N, 1994, Proc Annu Symp Comput Appl Med Care, P797; SHIFFMAN RN, 1994, MED DECIS MAKING, V14, P245, DOI 10.1177/0272989X9401400306; Shortliffe E H, 1996, Proc AMIA Annu Fall Symp, P125; SITTIG DF, 1989, COMPUT BIOMED RES, V22, P474, DOI 10.1016/0010-4809(89)90040-2; Stetler C B, 1976, Nurs Outlook, V24, P559; Sylvestri M F, 1996, Med Interface, V9, P100; Tape T G, 1992, Proc Annu Symp Comput Appl Med Care, P806; TIERNEY WM, 1995, J AM MED INFORM ASSN, V2, P316; Wallace C J, 1995, Proc Annu Symp Comput Appl Med Care, P810; Wallace K G, 1997, J Nurs Staff Dev, V13, P24; Weingarten S, 1997, JAMA-J AM MED ASSOC, V277, P1977, DOI 10.1001/jama.277.24.1977; Willson D, 1995, Proc Annu Symp Comput Appl Med Care, P646; Willson D, 1996, Holist Nurs Pract, V11, P84; YAMAMOTO LG, 1989, AM J EMERG MED, V7, P91, DOI 10.1016/0735-6757(89)90092-2; Zielstorff R D, 1996, Proc AMIA Annu Fall Symp, P562; *AG HLTH CAR POL R, 1993, AHCPR PUBL	82	85	85	HANLEY & BELFUS INC	PHILADELPHIA	210 S 13TH ST, PHILADELPHIA, PA 19107 USA	1067-5027		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY-JUN	1998	5	3					227	236				10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	ZM958	WOS:000073593500002	
J	Zhu, W				Zhu, William			Relationship between generalized rough sets based on binary relation and covering	INFORMATION SCIENCES			English	Article						Rough set; Fuzzy set; Granular computing; Data mining; Reduction; Covering; Approximation	ALGEBRAIC STRUCTURES; FUZZY-SETS; REDUCTION	Rough set theory is a powerful tool for dealing with uncertainty, granularity, and incompleteness of knowledge in information systems. This paper systematically studies a type of generalized rough sets based on covering and the relationship between this type of covering-based rough sets and the generalized rough sets based on binary relation. Firstly, we present basic concepts and properties of this kind of rough sets. Then we investigate the relationships between this type of generalized rough sets and other five types of covering-based rough sets. The major contribution in this paper is that we establish the equivalency between this type of covering-based rough sets and a type of binary relation based rough sets. Through existing results in binary relation based rough sets, we present axiomatic systems for this type of covering-based lower and upper approximation operations. In addition, we explore the relationships among several important concepts such as minimal description, reduction, representative covering, exact covering, and unary covering in covering-based rough sets. Investigation of this type of covering-based will benefit to our understanding of other types of rough sets based on covering and binary relation. (c) 2008 Elsevier Inc. All rights reserved.	[Zhu, William] Univ Elect Sci & Technol China, Sch Engn & Comp Sci, Chengdu 610054, Peoples R China; [Zhu, William] Chinese Acad Sci, Key Lab Complex Syst & Intelligence Sci, Inst Automat, Beijing, Peoples R China	Zhu, W (reprint author), Univ Elect Sci & Technol China, Sch Engn & Comp Sci, Chengdu 610054, Peoples R China.	williamfengzhu@uestc.edu.cn			National Science Foundation of China [60873077/17020107]; Key Laboratory of Complex Systems and Intelligence Science; Institute of Automation, Chinese Academy of Sciences [20070105]	This work is in part supported by National Science Foundation of China under Grant No. 60873077/17020107 and the Public Fund from the Key Laboratory of Complex Systems and Intelligence Science, Institute of Automation, Chinese Academy of Sciences under Grant No. 20070105.	Bartol W, 2004, INFORM SCIENCES, V166, P193, DOI 10.1016/j.ins.2003.12.002; Blake C., 1998, GRANULAR COMPUTING I; Bonikowski Z, 1998, INFORM SCIENCES, V107, P149, DOI 10.1016/S0020-0255(97)10046-9; BRYNIARSKI E, 1989, B POL ACAD SCI, V36, P71; Cattaneo G, 2004, LECT NOTES COMPUT SC, V3135, P208; Dai JH, 2008, INFORM SCIENCES, V178, P1986, DOI 10.1016/j.ins.2007.11.011; Deng TQ, 2007, INFORM SCIENCES, V177, P2308, DOI 10.1016/j.ins.2006.11.013; Deng TQ, 2006, LECT NOTES COMPUT SC, V4223, P266; Feng T, 2006, LECT NOTES ARTIF INT, V4062, P208; LI J, 2004, ARTIF INTELL, V17, P7; Li WB, 2006, LECT NOTES ARTIF INT, V4259, P776; Lin TY, 2003, LECT NOTES ARTIF INT, V2639, P16; Lin T. Y., 1994, Rough Sets, Fuzzy Sets and Knowledge Discovery. Proceedings of the International Workshop on Rough Sets and Knowledge Discovery (RSKD'93); Liu GL, 2006, FUND INFORM, V69, P331; Liu GL, 2008, INFORM SCIENCES, V178, P4105, DOI 10.1016/j.ins.2008.06.021; Liu GL, 2008, INFORM SCIENCES, V178, P1651, DOI 10.1016/j.ins.2007.11.010; Mordeson JN, 2001, FUZZY SET SYST, V121, P315, DOI 10.1016/S0165-0114(00)00023-3; Pal SK, 2005, PATTERN RECOGN LETT, V26, P2509, DOI 10.1016/j.patrec.2005.05.007; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pawlak Z, 2007, INFORM SCIENCES, V177, P41, DOI 10.1016/j.ins.2006.06.007; Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003; Polkowski L., 1998, ROUGH SETS CURRENT T, V1424; Pomykata J., 1987, B POLISH ACAD SCI MA, V35, P653; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A, 2003, LECT NOTES ARTIF INT, V2639, P25; Slowinski R, 2000, IEEE T KNOWL DATA EN, V12, P331, DOI 10.1109/69.842271; Tsang ECC, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4200; Wang FY, 2005, INFORM SCIENCES, V171, P233, DOI 10.1016/j.ins.2004.04.005; Wang M, 2004, SHOCK, V21, P20; [徐忠印 Xu Zhongyin], 2005, [河南师范大学学报. 自然科学版, Journal of Henan Normal University.Natural Science], V33, P130; YAO J, 2006, IEEE GRC 2006, P683; Yao JT, 2002, LECT NOTES ARTIF INT, V2475, P331; YAO Y, 2007, INFORM SCI, V176, P3431; Yao Y., 1998, LECT NOTES ARTIF INT, V1424, P298; Yao Y. Y., 1999, P WORLD MULT SYST CY, P573; Yao YY, 1998, INFORM SCIENCES, V109, P21, DOI 10.1016/S0020-0255(98)00012-7; Yao YY, 2004, LECT NOTES COMPUT SC, V3100, P232; Yao Y.Y., 2000, P 5 JOINT C INF SCI, VI, P186; Yeung DS, 2005, IEEE T FUZZY SYST, V13, P343, DOI 10.1109/TFUZZ.2004.841734; Zadeh LA, 2005, INFORM SCIENCES, V172, P1, DOI 10.1016/j.ins.2005.01.017; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zakowski W., 1983, DEMONSTRATIO MATH, V16, P761; ZHONG N, 2001, J JAPAN SOC FUZZY TH, V13, P581; Zhong N, 2003, IEEE T KNOWL DATA EN, V15, P952; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; Zhu Feng, 2000, Chinese Journal of Computers, V23; Zhu N, 2007, EAS PUBLICATIONS, V24, P289; Zhu W, 2007, IEEE T KNOWL DATA EN, V19, P1131, DOI 10.1109/TKDE.2007.1044; Zhu W., 2006, WORKSH P GRC BI 06 I, P494; Zhu W, 2006, LECT NOTES COMPUT SC, V3975, P566; Zhu W., 2006, IEEE GRC 2006, P43; Zhu W., 2006, IEEE IS 2006, P444; Zhu W., 2006, HIS 06 AUT TECHN PAR, P43; Zhu W, 2006, LECT NOTES COMPUT SC, V4223, P276; Zhu W, 2007, INFORM SCIENCES, V177, P4997, DOI 10.1016/j.ins.2007.05.037; ZHU W, 2007, ICNC 07, V5, P283; Zhu W., 2006, P DM WORKSH 06 ICDM, P407; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; Zhu W, 2007, INFORM SCIENCES, V177, P1499, DOI 10.1016/j.ins.2006.06.009	61	84	105	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JAN 16	2009	179	3					210	225		10.1016/j.ins.2008.09.015		16	Computer Science, Information Systems	Computer Science	412FE	WOS:000263708600002	
J	Au, WH; Chan, KCC; Yao, X				Au, WH; Chan, KCC; Yao, X			A novel evolutionary data mining algorithm with applications to churn prediction	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						churn prediction; customer retention; data mining; evolutionary computation; genetic algorithms	CLASSIFIER SYSTEMS	Classification is an important topic in data mining research. Given a set of data records; each of which belongs to one of a number of predefined classes, the classification problem is concerned with the discovery of classification rules that can allow records with unknown class membership to be correctly classified. Many algorithms have been developed to mine large data sets for classification models and they have been shown to be very effective. However, when it comes to determining the likelihood of each classification made, many of them are not designed with, such purpose in mind. For this, they are not readily applicable to such problem as churn prediction. For such an application, the goal is not only to predict whether or not a subscriber would switch from one carrier to another, it is. also important that the likelihood of the subscriber's doing so be predicted. The reason for this is that a carrier can then choose to provide special personalized offer and services to those subscribers who are predicted with higher likelihood to churn. Given its importance, we propose a new data mining algorithm, called data mining by evolutionary learning (DMEL), to handle classification problems of which the accuracy of each predictions made has to be estimated. In performing its tasks, DMEL searches through the possible rule space using an evolutionary approach that has the following characteristics: 1) the evolutionary process begins with the generation of an initial set of first-order rules (i.e., rules with one conjunct/condition) using a probabilistic induction technique and based on these rules, rules of higher order (two or more conjuncts) are obtained iteratively; 2) when identifying interesting rules, an objective interestingness measure is used; 3) the fitness of a chromosome is defined in terms of the probability that the attribute values of a record can be correctly determined using the rules it encodes; and 4) the likelihood of predictions (or classifications) made are estimated so that subscribers can be ranked according to their likelihood to churn. Experiments with different data sets showed that DMEL is able to effectively discover interesting classification rules. In particular; it is able to predict churn accurately under different churn rates when applied to real telecom subscriber data.	Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China; Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England	Au, WH (reprint author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.	eswhau@comp.polyu.edu.hk; cskcchan@comp.polyu.edu.hk; x.yao@cs.bham.ac.uk					Agresti A, 1990, CATEGORICAL DATA ANA; Au WH, 2003, IEEE T FUZZY SYST, V11, P238, DOI 10.1109/TFUZZ.2003.809901; Bishop CM, 1995, NEURAL NETWORKS PATT; CARLIN B.P., 2000, BAYES EMPIRICAL BAYE; Chan K. C. C., 1991, Knowledge discovery in databases; Chan K. C. C., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00129.x; CHAN KCC, 2001, DATA MINING COMPUTAT, P95; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P1; Choenni A., 2000, P 26 INT C VER LARG, P33; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FIDELIS MV, 2000, P 2000 C EV COMP, V1, P805, DOI 10.1109/CEC.2000.870381; Fogel D. B., 1995, EVOLUTIONARY COMPUTA; Forsyth R. S., 1990, PC BEAGLE USERS GUID; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Gehrke J., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Gehrke J., 1999, P ACM SIGMOD INT C M, P169, DOI 10.1145/304182.304197; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Greene DP, 1994, EVOL COMPUT, V2, P67, DOI 10.1162/evco.1994.2.1.67; HILL RR, 1999, P 1999 WINT SIM C, P543; Holland J. H., 1986, MACHINE LEARNING ART; Ishibuchi H, 1999, IEEE T IND ELECTRON, V46, P1057, DOI 10.1109/41.807986; JANIKOW CZ, 1993, MACH LEARN, V13, P189, DOI 10.1023/A:1022669929488; Julstrom B.A., 1994, P ACM S APPL COMP PH, P222, DOI 10.1145/326619.326728; Kohavi R., 1996, P 2 INT C KNOWL DISC; Kwedlo W, 1998, LECT NOTES ARTIF INT, V1510, P370; LIGHT RJ, 1971, J AM STAT ASSOC, V66, P534, DOI 10.2307/2283520; LOCKWOOD J, 1997, WIRELESS WEEK   0825; MCAULAY AD, 1994, IEEE T SYST MAN CYB, V24, P152, DOI 10.1109/21.259696; Mehta M., 1996, P 5 INT C EXT DAT TE, P18; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Mozer MC, 2000, IEEE T NEURAL NETWOR, V11, P690, DOI 10.1109/72.846740; NOORDEWIER MO, 1991, ADV NEURAL INFORMATI, V3; Quinlan J. R., 1987, Proceedings of the Fourth International Workshop on Machine Learning; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rastogi R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1); Smith S. F., 1983, P 8 INT JOINT C ART, P422; Yang C. H., 1993, P 1993 ACM C COMP SC, P378, DOI 10.1145/170791.170875	41	84	90	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	DEC	2003	7	6					532	545		10.1109/TEVC.2003.819264		14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	759KC	WOS:000187736000003	
J	Bolshakova, N; Azuaje, F				Bolshakova, N; Azuaje, F			Cluster validation techniques for genome expression data	SIGNAL PROCESSING			English	Article						genome expression; clustering; cluster validation; genomic data mining	GENE-EXPRESSION; MOLECULAR CLASSIFICATION; MICROARRAY; CANCER; DISCOVERY; VALIDITY	Several clustering algorithms have been suggested to analyse genome expression data, but fewer solutions have been implemented to guide the design of clustering-based experiments and assess the quality of their outcomes. A cluster validity framework provides insights into the problem of predicting the correct the number of clusters. This paper presents several validation techniques for gene expression data analysis. Normalisation and validity aggregation strategies are proposed to improve the prediction about the number of relevant clusters. The results obtained indicate that this systematic evaluation approach may significantly support genome expression analyses for knowledge discovery applications. (C) 2002 Elsevier Science B.V. All rights reserved.	Trinity Coll Dublin, Dept Comp Sci, Dublin, Ireland; Univ Ulster, Sch Comp & Math, Jordanstown BT37 0QB, Antrim, North Ireland	Bolshakova, N (reprint author), Trinity Coll Dublin, Dept Comp Sci, Dublin, Ireland.						Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Azuaje F, 2002, BIOINFORMATICS, V18, P319, DOI 10.1093/bioinformatics/18.2.319; Azuaje F, 2001, IEEE T BIO-MED ENG, V48, P332, DOI 10.1109/10.914796; AZUAJE F, 2002, IN PRESS UNDERSTANDI; Berns A, 2000, NATURE, V403, P491, DOI 10.1038/35000684; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Bittner M, 2000, NATURE, V406, P536, DOI 10.1038/35020115; BOLSHAKOVA N, 2003, UNPUB 4 ANN IEEE EMB; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Dunn J. C., 1974, Journal of Cybernetics, V4; DUNNE K, 2002, UNPUB J MACHINE LEAR; EVERETT BS, 1993, CLUSTER ANAL; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GOODMAN LA, 1954, J AM STAT ASSOC, V49, P732, DOI 10.2307/2281536; Granzow M., 2001, ACM SIGBIO NEWSLETTE, V21, P16, DOI 10.1145/381371.381384; Gunter S., 2001, P 3 IAPR TC15 WORKSH, P229; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; HUBERT L, 1976, BRIT J MATH STAT PSY, V29, P190; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309	25	84	93	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684		SIGNAL PROCESS	Signal Process.	APR	2003	83	4					825	833		10.1016/S0165-1684(02)00475-9		9	Engineering, Electrical & Electronic	Engineering	653BP	WOS:000181415600011	
J	Martens, D; De Backer, M; Haesen, R; Vanthienen, J; Snoeck, M; Baesens, B				Martens, David; De Backer, Manu; Haesen, Raf; Vanthienen, Jan; Snoeck, Monique; Baesens, Bart			Classification with ant colony optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						ant colony optimization (ACO); classification; comprehensibility; MAX-MIN ant system; rule list	NETWORKS; SYSTEM	Ant colony optimization (ACO) can be applied to the data mining field to extract rule-based classifiers. The aim of this paper is twofold. On the one hand, we provide an overview of previous ant-based approaches to the classification task and compare them with state-of-the-art classification techniques, such as C4.5, RIPPER, and support vector machines in a benchmark study. On the other hand, a new ant-based classification technique is proposed, named AntMiner+. The key differences between the proposed AntMiner+ and previous AntMiner versions are the usage of the better performing MAX-MIN ant system, a clearly defined and augmented environment for the ants to walk through, with the inclusion of the class variable to handle multiclass problems, and the ability-to include interval rules in the rule list. Furthermore, the commonly encountered problem in ACO of setting system parameters is dealt with in an automated, dynamic manner. Our benchmarking experiments show an AntMiner+ accuracy that is superior to that obtained by the other AntMiner versions, and competitive or better than the results achieved by the compared classification techniques.	Katholieke Univ Leuven, Dept Decis Sci, B-3000 Louvain, Belgium; Univ Southampton, Sch Management, Southampton SO17 1BJ, Hants, England	Martens, D (reprint author), Katholieke Univ Leuven, Dept Decis Sci, B-3000 Louvain, Belgium.	David.Martens@econ.kuleuven.be	Martens, David/A-8158-2013				Abraham A, 2003, IEEE C EVOL COMPUTAT, P1384; Baesens B, 2003, J OPER RES SOC, V54, P627, DOI 10.1057/palgrave.jors.2601545; Baesens B, 2003, MANAGE SCI, V49, P312, DOI 10.1287/mnsc.49.3.312.12739; Blum C, 2005, COMPUT OPER RES, V32, P1565, DOI 10.1016/j.cor.2003.11.018; Bonabeau E., 1999, SWARM INTELLIGENCE N; Bullnheimer B., 1990, CENTRAL EUROPEAN J O, V7, P25; Bullnheimer B., 1999, METAHEURISTICS ADV T, P285; Christofides N., 1975, GRAPH THEORY ALGORIT; Colorni A., 1994, JORBEL BELGIAN J OPE, V34, P39; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Di Caro G, 1998, J ARTIF INTELL RES, V9, P317; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; Dorigo M, 2004, ANT COLONY OPTIMIZATION, P1, DOI 10.1007/b99492; Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585892; DORIGO M, 1991, 91016; Dorigo Marco, 1999, NEW IDEAS OPTIMIZATI, P11; Duda R. O., 2000, PATTERN CLASSIFICATI; Gambardella L.M., 1995, P 12 INT C MACH LEAR, P252; Hand D. J., 1981, DISCRIMINATION CLASS; HAND DJ, 2002, LECT NOTES ARTIF INT, V2447, P1; Handl J, 2006, ARTIF LIFE, V12, P35, DOI 10.1162/106454606775186400; HETTICH S, 1996, INF COMPUT SCI; Liu B, 2003, P IEEE WIC INT C INT, P83; Liu B., 2002, P 6 AUSTR JAP JOINT, P180; Montemanni R, 2005, J COMB OPTIM, V10, P327, DOI 10.1007/s10878-005-4922-6; Mues C, 2004, EXPERT SYST APPL, V27, P257, DOI 10.1016/j.eswa.2004.02.001; Parpinelli R.S., 2001, P GEN EV COMP C, P791; Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452; Pazzani MJ, 2001, METHOD INFORM MED, V40, P380; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; SOCHA K, 2002, P 3 INT WORKSH ANT A, V2463, P1; Stutzle T, 2000, FUTURE GENER COMP SY, V16, P889, DOI 10.1016/S0167-739X(00)00043-1; STUTZLE T, 1996, 9612 AIDA; Tan P.N, 2005, INTRO DATA MINING; Thomas LC, 2002, CREDIT SCORING ITS A; van Gestel T, 2004, MACH LEARN, V54, P5, DOI 10.1023/B:MACH.0000008082.80494.e0; Vapnik V.N., 1995, NATURE STAT LEARNING; Wade A, 2004, APPL OPTIMIZAT, V86, P699; Witten IH, 2000, DATA MINING PRACTICA	41	83	86	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	OCT	2007	11	5					651	665		10.1109/TEVC.2006.890229		15	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	217PI	WOS:000249959400007	
J	Grahne, G; Zhu, JF				Grahne, G; Zhu, JF			Fast algorithms for frequent itemset mining using FP-trees	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; association rules	DISCOVERY; PATTERNS	Efficient algorithms for mining frequent itemsets are crucial for mining association rules as well as for many other data mining tasks. Methods for mining frequent itemsets have been implemented using a prefix-tree structure, known as an FP-tree, for storing compressed information about frequent itemsets. Numerous experimental results have demonstrated that these algorithms perform extremely well. In this paper, we present a novel FP-array technique that greatly reduces the need to traverse FP-trees, thus obtaining significantly improved performance for FP-tree-based algorithms. Our technique works especially well for sparse data sets. Furthermore, we present new algorithms for mining all, maximal, and closed frequent itemsets. Our algorithms use the FP-tree data structure in combination with the FP-array technique efficiently and incorporate various optimization techniques. We also present experimental results comparing our methods with existing algorithms. The results show that our methods are the fastest for many cases. Even though the algorithms consume much memory when the data sets are sparse, they are still the fastest ones when the minimum support is low. Moreover, they are always among the fastest algorithms and consume less memory than other methods when the data sets are dense.	Concordia Univ, Dept Comp Sci, Montreal, PQ H3G 1M8, Canada	Grahne, G (reprint author), Concordia Univ, Dept Comp Sci, 1455 De Maisonneuve Blvd W, Montreal, PQ H3G 1M8, Canada.	grahne@cs.concordia.ca; j_zhu@cs.concordia.ca					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; BORGELT C, 2003, CEUR WORKSH P NOV, V80; Burdick D, 2001, PROC INT CONF DATA, P443, DOI 10.1109/ICDE.2001.914857; GOETHALS B, 2003, CEUR WORKSH P NOV, V80; Gouda K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989514; Gouda K., 2003, P 9 ACM SIGKDD INT C, P326; GRAHNE G, 2004, P IEEE INT C DAT MIN, P91; GRAHNE G, 2003, P SIAM WORKSH HIGH P; Han H S, 2000, Korean J Ophthalmol, V14, P1; Han J., 2002, P 2002 IEEE INT C DA, P211; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Kamber M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Knuth D. E., 1973, SORTING SEARCHING; LIU G, 2003, P IEEE ICDM WORKSH F, V80; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; ORLANDO S, 2003, P IEEE ICDM WORKSH F, V80; Park JS, 1997, IEEE T KNOWL DATA EN, V9, P813; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J., 2000, P ACM SIGMOD WORKSH, P21; PIETRACAPRINA A, 2003, P IEEE ICDM WORKSH F, V80; Savasere A, 1995, P 21 INT C VER LARG, P432; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Wang J., 2003, P 9 ACM SIGKDD INT C, P236; Xin D., 2003, P 29 INT C VER LARG, P476, DOI 10.1016/B978-012722442-8/50049-5; Zaki MJ, 2002, SIAM PROC S, P457; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291; Zou Q., 2002, P IEEE INT C DAT MIN	32	83	92	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	OCT	2005	17	10					1347	1362		10.1109/TKDE.2005.166		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	956BT	WOS:000231274600004	
J	Hong, TP; Kuo, CS; Chi, SC				Hong, TP; Kuo, CS; Chi, SC			Trade-off between computation time and number of rules for fuzzy mining from quantitative data	INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS			English	Article						data mining; fuzzy set; association rule; transaction; quantitative value	MEMBERSHIP FUNCTIONS; INDUCTION; ATTRIBUTES; SYSTEMS	Data mining is the process of extracting desirable knowledge or interesting patterns from existing databases for specific purposes. Most conventional data-mining algorithms identify the relationships among transactions using binary values. Transactions with quantitative values are however commonly seen in real-world applications. We proposed a fuzzy mining algorithm by which each attribute used only the linguistic term with the maximum cardinality in the mining process. The number of items was thus the same as that of the original attributes, making the processing time reduced. The fuzzy association rules derived in this way are not complete. This paper thus modifies it and proposes a new fuzzy data-mining algorithm for extracting interesting knowledge from transactions stored as quantitative values. The proposed algorithm can derive a more complete set of rules but with more computation time than the method proposed. Trade-off thus exists between the computation time and the completeness of rules. Choosing an appropriate learning method thus depends on the requirement of the application domains.	I Shou Univ, Dept Informat Management, Kaohsiung 84008, Taiwan; Natl Chengchi Univ, Dept Management Informat Syst, Taipei 11623, Taiwan; Huafan Univ, Dept Ind Management, Taipei 233, Taiwan; Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan	Hong, TP (reprint author), I Shou Univ, Dept Informat Management, Kaohsiung 84008, Taiwan.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R., 1994, INT C VER LARG DAT B, P487; AGRAWAL R, 1997, 3 INT C KNOWL DISC D; Agrawal R., 1993, 1993 ACM SIGMOD C WA; BLISHUN AF, 1987, FUZZY SET SYST, V22, P57, DOI 10.1016/0165-0114(87)90006-6; CHANG RLP, 1977, IEEE T SYST MAN CYB, V7, P28, DOI 10.1109/TSMC.1977.4309586; CLAIR C, 1998, 7 INT C INF KNOWL MA, P259; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; DECAMPOS LM, 1993, FUZZY SET SYST, V59, P247, DOI 10.1016/0165-0114(93)90470-3; DELGADO M, 1993, FUZZY SET SYST, V55, P121, DOI 10.1016/0165-0114(93)90125-2; Frawley WJ, 1991, AAAI WORKSH KNOWL DI, P1; GONZALEZ A, 1995, INT J INTELL SYST, V10, P57; GRAHAM, 1988, EXPERT SYSTEMS KNOWL, P117; Hong T. P., 1999, INTELL DATA ANAL, V3, P363, DOI 10.1016/S1088-467X(99)00028-1; Hong TP, 1996, FUZZY SET SYST, V84, P33, DOI 10.1016/0165-0114(95)00305-3; Hong TP, 1997, IEEE T KNOWL DATA EN, V9, P336; Hong TP, 1999, FUZZY SET SYST, V103, P389; Hong TP, 2000, FUZZY SET SYST, V112, P127, DOI 10.1016/S0165-0114(98)00179-1; Hou RH, 1997, J AUTOM REASONING, V18, P5, DOI 10.1023/A:1005726727996; KANDEL, 1992, FUZZY EXPERT SYSTEMS, P8; Mamdani E.H., 1974, IEEE P, P1585; Mannila H., 1997, INT C DAT THEOR; QUINLAN JR, 1987, 4 INT MACH LEARN WOR, P31; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RIVES J, 1990, 1 INT S UNC MOD AN, P457; Srikant R., 1996, 1996 ACM SIGMOD INT, P1; Wang CH, 1999, FUZZY SET SYST, V103, P91; WANG H, 1996, 5 IEEE INT C FUZZ SY, P13; Weber R., 1992, 2 INT C FUZZ LOG NEU, P265; Zimmermann HJ, 1991, FUZZY SET THEORY ITS	30	83	84	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 912805, SINGAPORE	0218-4885		INT J UNCERTAIN FUZZ	Int. J. Uncertainty Fuzziness Knowl.-Based Syst.	OCT	2001	9	5					587	604		10.1142/S0218488501001071		18	Computer Science, Artificial Intelligence	Computer Science	486TM	WOS:000171833100004	
J	Grabmeier, J; Rudolph, A				Grabmeier, J; Rudolph, A			Techniques of cluster algorithms in data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; cluster algorithm; Condorcet's criterion; demographic clustering		An overview of cluster analysis techniques from a data mining point of view is given. This is done by a strict separation of the questions of various similarity and distance measures and related optimization criteria for clusterings from the methods to create and modify clusterings themselves. In addition to this general setting and overview, the second focus is used on discussions of the essential ingredients of the demographic cluster algorithm of IBM's Intelligent Miner, based Condorcet's criterion.	Univ Appl Sci, D-94469 Deggendorf, Germany; Univ Bundeswehr Munchen, D-85579 Neubiberg, Germany	Grabmeier, J (reprint author), Univ Appl Sci, Edlmaierstr 6 & 8, D-94469 Deggendorf, Germany.						BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BALL GH, 1967, RADCTR67310 STANF RE; BALL GH, 1965, P AFIPS FALL JOINT C, V1, P533; BALL GH, 1965, ISODATA NOVEL TECHNI; Bigus J. P., 1996, DATA MINING NEURAL N; Bishop CM, 1995, NEURAL NETWORKS PATT; Bock H. H., 1974, AUTOMATISCHE KLASSIF; BRAVERMAN EM, 1996, AUTOMAT REM CONTR, V27, P1748; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FORTIER JJ, 1996, P MULT AN 66, P493; Graham R. L., 1989, CONCRETE MATH FDN CO; HARTUNG HJ, 1984, MULTIVARIATE STAT; Hoppner F., 1999, FUZZY CLUSTER ANAL; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jobson J. D., 1992, APPL MULTIVARIATE DA, V1; Jobson J. D., 1992, APPL MULTIVARIATE DA, V2; JOHNSON NL, 1990, CONTINUOUS UNIVARIAT, V1; Kaufman L., 1990, FINDING GROUPS DATA; Kohonen T., 1997, SELF ORG MAPS; KRISHNAIAH PR, P MULT AN 66; LU SY, 1978, IEEE T SYST MAN CYB, V8, P381, DOI 10.1109/TSMC.1978.4309979; MCLACHLAN GJ, MIXTURE MODELS; MESSATFA H, 1997, FUTURE GEN COMPUTER, V13, P149; MICHAUD P, 1985, F052 IBM CTR SCI; MICHAUD P, 1995, MAP010 IBM ECAM; MICHAUD P, 1987, APPL STOCH MODEL BUS, V3, P173, DOI 10.1002/asm.3150030305; MICHAUD P, 1982, F051 IBM CTR SCI; MICHAUD P, 1987, F084 IBM CTR SCI; Michaud P, 1997, FUTURE GENER COMP SY, V13, P135, DOI 10.1016/S0167-739X(97)00017-4; Rao C. R., 1973, LINEAR STAT INFERENC; RENYI A, 1962, WAHRSCHEINLICHKEITST; Ripley B., 1996, PATTERN RECOGNITION; Robins H., 1951, ANN MATH STAT, V22, P400; RUDOLPH A, 1999, DATA MINING ACTION S; Seber G.A.F., 1984, MULTIVARIATE OBSERVA; SPAETH H, 1984, CLUSTER ANAL ALGORIT; STEINHAUSEN D, 1977, CLUSTERANALYSE; TSYPKIN YZ, 1967, ENG CYBERNETICS USSR, V5, P70	38	82	100	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2002	6	4					303	360		10.1023/A:1016308404627		58	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	574AB	WOS:000176865200001	
J	Lingras, PJ; Yao, YY				Lingras, PJ; Yao, YY			Data mining using extensions of the rough set model	JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE			English	Article								This article examines basic issues of data mining using the theory of rough sets, which is a recent proposal for generalizing classical set theory. The Pawlak rough set model is based on the concept of an equivalence relation. Recent research has shown that a generalized rough set model need not be based on equivalence relation axioms. The Pawlak rough set model has been used for deriving deterministic as well as probabilistic rules from a complete database. This article demonstrates that a generalized rough set model can be used for generating rules from incomplete databases. These rules are based on plausibility functions proposed by Shafer. The article also discusses the importance of rule extraction from incomplete databases in data mining.	Algoma Univ Coll, Dept Comp Sci, Sault St Marie, ON P6A 2G4, Canada; Lakehead Univ, Dept Comp Sci, Thunder Bay, ON P7B 5E1, Canada	Lingras, PJ (reprint author), Algoma Univ Coll, Dept Comp Sci, Sault St Marie, ON P6A 2G4, Canada.		Yao, Yiyu/B-2926-2008				DEOGUN JS, 1994, SOFT COMP P 3 INT WO, P302; GRZYMALABUSSE JW, 1991, LECT NOTES ARTIF INT, V542, P368; Kryszkiewicz M., 1996, P 6 INT C INF PROC M, P1165; Lin T. Y., 1994, Rough Sets, Fuzzy Sets and Knowledge Discovery. Proceedings of the International Workshop on Rough Sets and Knowledge Discovery (RSKD'93); Lingras P., 1996, Proceedings of the Ninth Florida Artificial Intelligence Research Symposium, FLAIRS-96; LINGRAS PJ, 1995, P 23 COMP SCI C CSC; Lingras P., 1993, Proceedings ICCI '93. Fifth International Conference on Computing and Information (Cat. No.93TH0563-7), DOI 10.1109/ICCI.1993.315361; ORLOWSKA E, 1993, ROUGH SETS FUZZY SET, P143; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1992, FUZZY LOGIC MANAGEME, P105; Shafer G, 1976, MATH THEORY EVIDENCE; Skowron A., 1994, ADV DEMPSTER SHAFER, P193; WONG SKM, 1986, P 6 INT WORKSH EXP S, V1, P713; WONG SKM, 1987, FUZZY SET SYST, V21, P357, DOI 10.1016/0165-0114(87)90135-7; YAO YY, 1994, SOFT COMP P 3 INT WO, P44; ZYTKOW JM, 1993, J INTELL INF SYST, V2, P39, DOI 10.1007/BF01066546	16	82	108	JOHN WILEY & SONS INC	NEW YORK	605 THIRD AVE, NEW YORK, NY 10158-0012 USA	0002-8231		J AM SOC INFORM SCI	J. Am. Soc. Inf. Sci.	APR 15	1998	49	5					415	422		10.1002/(SICI)1097-4571(19980415)49:5<415::AID-ASI4>3.3.CO;2-Q		8	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	ZB682	WOS:000072497000004	
J	Liu, K; Kargupta, H; Ryan, J				Liu, K; Kargupta, H; Ryan, J			Random projection-based multiplicative data perturbation for privacy preserving distributed data mining	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						random projection; multiplicative data perturbation; privacy preserving data mining		This paper explores the possibility of using multiplicative random projection matrices for privacy preserving distributed data mining. It specifically considers the problem of computing statistical aggregates like the inner product matrix, correlation coefficient matrix, and Euclidean distance matrix from distributed privacy sensitive data possibly owned by multiple parties. This class of problems is directly related to many other data-mining problems such as clustering, principal component analysis, and classification. This paper makes primary contributions on two different grounds. First, it explores Independent Component Analysis as a possible tool for breaching privacy in deterministic multiplicative perturbation-based models such as random orthogonal transformation and random rotation. Then, it proposes an approximate random projection-based technique to improve the level of privacy protection while still preserving certain statistical characteristics of the data. The paper presents extensive theoretical analysis and experimental results. Experiments demonstrate that the proposed technique is effective and can be successfully used for different types of privacy-preserving data mining applications.	Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA	Liu, K (reprint author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.	kunliu1@cs.umbc.edu; hillol@cs.umbc.edu; jryan4@cs.umbc.edu					ADAM NR, 1989, COMPUT SURV, V21, P515; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; AGRAWAL S, 2005, P 21 INT C DAT ENG I, P193; Arriaga Rosa I., 1999, P 40 ANN S FDN COMP, P616; Atallah M, 1999, P 1999 IEEE KNOWL DA, P45; Atallah M. J., 2001, P 7 INT WORKSH ALG D, P165; Cao XR, 1996, IEEE T SIGNAL PROCES, V44, P562; CHAWLA S, 2005, P 2 THEOR CRYPT C TC; Clifton C., 2003, ACM SIGKDD EXPLORATI, V4; Common P., 1994, SIGNAL PROCESS, V36, P287; DALENIUS T, 1982, J STAT PLAN INFER, V6, P73, DOI 10.1016/0378-3758(82)90058-1; DEMMEL JW, 1990, CS90113 U TENN COMP; DU W, 2004, P 2004 SIAM INT C DA; Du W. L., 2002, P IEEE ICDM WORKSH P, P1; EATON ML, 1973, ANN STAT, V1, P710, DOI 10.1214/aos/1176342465; ERIKSSON J, 2003, P 4 INT S IND COMP A; EVFIMEVSKI A, 2003, P ACM SIGMOD PODS C; EVFIMIEVSKI A. V., 2002, P 8 ACM SIGKDD INT C; Fienberg S.E., 2003, DATA SWAPPING VARIAT; GIANNELLA C, 2004, P 4 IEEE INT C DAT M; GOLDREICH O, 2004, FDN CRYPTOGRAPHY, V2, pCH7; Gupta A., 1999, MATRIX VARIATE DISTR; HARDLE W, 2003, APPL MULTIVARIATE ST, P57; Hecht-Nielsen R., 1994, COMPUT INTELL, P43; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Johnson W., 1984, CONT MATH, V26, P189; KARGUPTA H, 2003, P IEEE INT C DAT MIN; Kaski S., 1998, P IJCNN 98 INT JOINT, V1, P413; Kim J.J., 2003, 200301 US BUR CENS S; LEFONS E, 1983, P 9 INT C VER LARG D, P260; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; LIEW CK, 1985, ACM T DATABASE SYST, V10, P395, DOI 10.1145/3979.4017; LIU K, 2004, DISTRIBUTED DATA MIN; MENG D, 2004, P 4 IEEE INT C DAT M; MERUGU S, 2003, P 3 IEEE INT C DAT M; Oliveira S.R.M., 2003, P 18 BRAZ S DAT MAN, P304; PARK BH, 2003, SER HUMAN FACTORS ER, P341; Pinkas B., 2002, SIGKDD EXPLORATIONS, V4, P12; Saygin Y, 2001, SIGMOD RECORD, V30, P45; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Verykios Vassilios S., 2003, IEEE T KNOWLEDGE DAT; VERYKIOS VS, 2004, ACM SIGMOD RECORD, V3, P50; VIDYA JS, 2002, P 8 ACM SIGKDD INT C; WARNER SL, 1965, J AM STAT ASSOC, V60, P63, DOI 10.2307/2283137; WEISSTEIN EW, 2004, ORTHOGONAL TRANSFORM; Yao A., 1986, P 27 IEEE S FDN COMP, P162	46	81	83	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN	2006	18	1					92	106				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	993EU	WOS:000233938200007	
J	Wei, CP; Chiu, IT				Wei, CP; Chiu, IT			Turning telecommunications call details to churn prediction: a data mining approach	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; telecommunications data mining; churn prediction; churn management; classification analysis; decision tree induction; multi-classifier class-combiner approach	FRAUD	As deregulation, stew technologies, and new competitors open up the mobile telecommunications industry, churn prediction and management has become of great concern to mobile service providers: A mobile service provider wishing to retain its subscribers needs to be able to predict which of them may be at-risk of changing services and will make those subscribers the focus of customer retention efforts. In response to the limitations of existing churn-prediction systems and the unavailability of customer demographics in the mobile telecommunications provider investigated, we propose, design, and experimentally evaluate a churn-prediction technique that predicts churning from subscriber contractual information and call pattern changes extracted from call details. This proposed technique is capable of identifying potential churners at the contract level for a specific prediction time-period. In addition, the proposed technique incorporates the multi-classifier class-combiner approach to address the challenge of a highly skewed class distribution between churners and non-churners. The empirical evaluation results suggest that the proposed call-behavior-based churn-prediction technique exhibits satisfactory predictive effectiveness when more recent call details are employed for the churn prediction model construction. Furthermore, the proposed technique is able to demonstrate satisfactory or reasonable predictive power within the one-month interval between model construction and churn prediction. Using a previous demographics-based churn-prediction system as a reference, the lift factors attained by our proposed technique appear largely satisfactory. (C) 2002 Elsevier Science Ltd. All rights reserved.	Natl Sun Yat Sen Univ, Dept Informat Management, Kaohsiung, Taiwan; Chunghwa Telecom Co Ltd, So Taiwan Business Grp, Kaohsiung, Taiwan	Wei, CP (reprint author), Natl Sun Yat Sen Univ, Dept Informat Management, Kaohsiung, Taiwan.	cwei@mis.nsysu.edu.tw					Berry M. R. J., 1997, DATA MINING TECHNIQU; BERSON A, 2000, BUILDING DATA MINING, pCH12; Breiman L, 1984, CLASSIFICATION REGRE; Cabena P., 1998, DISCOVERING DATA MIN; Chan PK, 1999, IEEE INTELL SYST APP, V14, P67, DOI 10.1109/5254.809570; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cox KC, 1997, DATA MIN KNOWL DISC, V1, P225, DOI 10.1023/A:1009740009307; EIBEN AE, 1998, FUZZY SETS ROUGH SET; Ezawa KJ, 1996, IEEE EXPERT, V11, P45, DOI 10.1109/64.539016; Frawley W. J., 1991, Knowledge discovery in databases; GERPOTT TJ, 2001, TELECOMMUNICATIONS P, V25, P885; KAPPERT CB, 1997, P 30 HAW INT C SYST, V5, P465, DOI 10.1109/HICSS.1997.663206; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; MICHALSKI RS, 1986, P AAAI AUG, V2, P1041; P Burge, 1997, P AI APPR FRAUD DET, P9; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; Shaw MJ, 2001, DECIS SUPPORT SYST, V31, P127, DOI 10.1016/S0167-9236(00)00123-8; Taniguchi M, 1998, INT CONF ACOUST SPEE, P1241, DOI 10.1109/ICASSP.1998.675496; WEI C, 2000, J COMPUTERS, V12, P60; Yang Y, 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953; *SPSS INC, 1999, WORK TEL CHURN TEL I	25	81	86	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2002	23	2					103	112		10.1016/S0957-4174(02)00030-1		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	585WG	WOS:000177547100003	
J	Nemati, HR; Steiger, DM; Iyer, LS; Herschel, RT				Nemati, HR; Steiger, DM; Iyer, LS; Herschel, RT			Knowledge warehouse: an architectural integration of knowledge management, decision support, artificial intelligence and data warehousing	DECISION SUPPORT SYSTEMS			English	Article						knowledge warehouse; data warehouse; knowledge management; decision support systems; data mining; intelligent analysis; model analysis	SENSITIVITY ANALYSIS; MODELING LANGUAGE; DSS IMPLEMENTATION; SYSTEMS; ENVIRONMENT; FRAMEWORK; OUTPUT; USERS; LA	Decision support systems (DSS) are becoming increasingly more critical to the daily operation of organizations. Data warehousing, an integral part of this, provides an infrastructure that enables businesses to extract, cleanse, and store vast amounts of data. The basic purpose of a data warehouse is to empower the knowledge workers with information that allows them to make decisions based on a solid foundation of fact, However, only a fraction of the needed information exists on computers; the vast majority of a firm's intellectual assets exist as knowledge in the minds of its employees. What is needed is a new generation of knowledge-enabled systems that provides the infrastructure needed to capture, cleanse, store, organize, leverage, and disseminate not only data and information but also the knowledge of the firm. The purpose of this paper is to propose, as an extension to the data warehouse model, a knowledge warehouse (KW) architecture that will not only facilitate the capturing and coding of knowledge but also enhance the retrieval and sharing of knowledge across the organization. The knowledge warehouse proposed here suggests a different direction for DSS in the next decade, This new direction is based on an expanded purpose of DSS. That is, the purpose of DSS in knowledge improvement. This expanded purpose of DSS also suggests that the effectiveness of a DSS will, in the future, be measured based on how well it promotes and enhances knowledge, how well it improves the mental model(s) and understanding of the decision maker(s) and thereby how well it improves his/her decision making. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ N Carolina, Bryan Sch Business & Econ, Greensboro, NC 27412 USA; Univ Maine, Maine Business Sch, Orono, ME 04469 USA; St Josephs Univ, Erivan K Haub Sch Business, Philadelphia, PA 19131 USA	Nemati, HR (reprint author), Univ N Carolina, Bryan Sch Business & Econ, 440 Bryan Bldg, Greensboro, NC 27412 USA.		Wang, Charles/B-5565-2011				Ahn T., 1985, Journal of Management Information Systems, V2; ALAVI M, 1992, MIS QUART, V16, P95, DOI 10.2307/249703; ALTER S, 1994, DECISION SUPPORT EXE, P58; ALTER S, 1994, DECISION SUPPORT EXE, P2; Amidon Debra M., 1997, CREATING KNOWLEDGE B; BARKI H, 1994, MIS QUART, V18, P59, DOI 10.2307/249610; BARRON AR, 1984, SELF ORG METHODS MOD, P86; Berson A., 1997, DATA WAREHOUSE DATA; BRUNSWIK E, 1952, CONCEPTUAL FDN PSYCH; CALIFF ME, 1997, RELATIONAL LEARNING; CHOO CW, 1998, KNOWING ORG ORG USE; DAVENPORT TH, 1998, WORKING KNOWLEDGE; Devlin B., 1997, DATA WAREHOUSE ARCHI; Dhaliwal JS, 1996, INFORM SYST RES, V7, P342, DOI 10.1287/isre.7.3.342; DOLK DR, 1984, IEEE T SOFTWARE ENG, V10, P619; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FOURER R, 1983, ACM T MATH SOFTWARE, V9, P143, DOI 10.1145/357456.357457; GASKIN JE, 1997, CORPORATE POLITICS I; Gray P., 1998, DECISION SUPPORT DAT; GREENBERG HJ, 1993, COMPUTER ASSISTED AN; GREENBERG HJ, 1994, EUR J OPER RES, V72, P300, DOI 10.1016/0377-2217(94)90311-5; GREENE RR, 1993, J GERONTOL SOC WORK, V19, P223; HAMMOND KF, 1988, P WORKSH CAS BAS REA, P17; HARRIS K, 1998, KA038437 GARTN GROUP; Hogue JT, 1983, MIS QUART, V7, P15, DOI 10.2307/248910; HOMER BR, 1996, MIS Q, V20, P55; INMAN WH, 1996, BUILDING DATA WAREHO; JANG DH, 1997, RIAO 97 C P COMP ASS, P101; JOHNSON L, 1985, INT J SYSTEMS RES IN, V1, P23; Jones C. V., 1990, ORSA Journal on Computing, V2; Joshi K, 1998, INFORM MANAGE, V34, P349, DOI 10.1016/S0378-7206(98)00069-X; JOSHI K, 1991, MIS Q, V15, P228; JOSHI K, 1989, MIS QUART, V13, P343, DOI 10.2307/249010; Kallman E. A., 1996, ETHICAL DECISION MAK; Kennington J.L., 1980, ALGORITHMS NETWORK P; KIDD AL, 1987, KNOWLEDGE ACQUISITIO; Kim C. N., 1999, J MANAGEMENT INFORMA, V16, P189; KIMBROUGH SO, 1993, INTERFACES, V23, P17, DOI 10.1287/inte.23.3.17; KIMBROUGH SO, 1990, INTERFACES, V20, P5, DOI 10.1287/inte.20.6.5; Kohler W., 1969, TASK GESTALT PSYCHOL; KOLODNER JL, 1987, P WORKSH CAS BAS REA, P21; KOSY DW, 1984, P NAT C ART INT AUG, P176; Kupiec J., 1995, SIGIR Forum; Lederer A. L., 1992, Journal of Management Information Systems, V9; LIANG TP, 1988, MIS Q            DEC, P667; MEREDITH JR, 1981, J OPERATIONAL MA OCT, P11; Newell A, 1972, HUMAN PROBLEM SOLVIN; NEWMAN M, 1996, MIS Q, V20, P1; Nonaka I., 1995, KNOWLEDGE CREATING C; PALVIA SC, 1995, INFORM MANAGE, V29, P43, DOI 10.1016/0378-7206(95)00006-I; PARSAYE D, 1990, AI EXPERT        MAR, P38; Perkins D. N., 1986, KNOWLEDGE DESIGN; PIELA PC, 1991, COMPUT CHEM ENG, V15, P53, DOI 10.1016/0098-1354(91)87006-U; Riloff E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1044; SALTELLI A, 1990, RELIAB ENG SYST SAFE, V28, P229, DOI 10.1016/0951-8320(90)90065-U; SALTELLI A, 1992, COMPUT STAT DATA AN, V13, P73, DOI 10.1016/0167-9473(92)90155-9; Sharda R, 1996, INFORM SYST RES, V7, P328, DOI 10.1287/isre.7.3.328; SODERLAND S, 1994, J ARTIFICIAL INTELLI, V2, P131; Sprague R. H., 1982, BUILDING EFFECTIVE D; Sprague R.H., 1996, DECISION SUPPORT MAN; SPRAGUE RH, 1989, DECISION SUPPORT SYS; STEIGER D, 1993, ANN OPER RES, V43, P195, DOI 10.1007/BF02025017; Steiger D. M., 1998, Journal of Management Information Systems, V15; Steiger D., 1993, ORSA Journal on Computing, V5; STEPHANOPOULOS G, 1990, COMPUT CHEM ENG, V14, P813, DOI 10.1016/0098-1354(90)87040-V; STEPHANOPOULOS G, 1990, COMPUT CHEM ENG, V14, P847, DOI 10.1016/0098-1354(90)87041-M; TAIT P, 1988, MIS QUART, V12, P91, DOI 10.2307/248809; Turban E., 2000, DECISION SUPPORT SYS; TURNEY P, 1997, EXTRACTION KEYPHRASE; TUTTLE B, 1992, J MANAGEMENT INFORMA, V9, P127; Wagner HM, 1995, OPER RES, V43, P948, DOI 10.1287/opre.43.6.948; WAH L, 1999, MANAGEMENT REV   APR, P16	72	81	83	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	JUN	2002	33	2					143	161		10.1016/S0167-9236(01)00141-5		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	552YN	WOS:000175648000004	
J	DeRaedt, L; Dehaspe, L				DeRaedt, L; Dehaspe, L			Clausal discovery	MACHINE LEARNING			English	Article						inductive logic programming; knowledge discovery in databases; data mining; learning; induction; semantics for induction; logic of induction; parallel learning		The clausal discovery engine CLAUDIEN is presented. CLAUDIEN is an inductive logic programming engine that fits in the descriptive data mining paradigm. CLAUDIEN addresses characteristic induction from interpretations, a task which is related to existing formalisations of induction in logic. In characteristic induction from interpretations, the regularities are represented by clausal theories, and the data using Herbrand interpretations. Because CLAUDIEN uses clausal logic to represent hypotheses, the regularities induced typically involve multiple relations or predicates. CLAUDIEN also employs a novel declarative bias mechanism to define the set of clauses that may appear in a hypothesis.		DeRaedt, L (reprint author), KATHOLIEKE UNIV LEUVEN, DEPT COMP SCI, CELESTIJNENLAAN 200A, B-3001 HEVERLEE, BELGIUM.						ADE H, 1995, MACH LEARN, V20, P119, DOI 10.1007/BF00993477; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; BERGADANO F, 1993, INDUCTIVE LOGIC PROG; BERGADANO F, 1993, 13TH P INT JOINT C A, P1044; BRATKO I, 1993, 3 INT WORKSH IND LOG, P279; BRATKO I, 1986, PROLOG PROGRAMMING A; CAMERONJONES RM, 1993, P 13 INT JOINT C ART, P1050; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clocksin WF, 1981, PROGRAMMING PROLOG; COHEN WW, 1994, ARTIF INTELL, V68, P303, DOI 10.1016/0004-3702(94)90070-1; DEHASPE L, 1996, LECT NOTES ARTIF INT, V1079, P613; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DERAEDT L, 1993, 13TH P INT JOINT C A, P1037; DERAEDT L, 1993, P 13 INT JOINT C ART, P1058; DERAEDT L, 1996, P 3 INT WORKSH MULT, P29; DERAEDT L, 1995, LECT NOTES ARTIFICIA, V997; Dolsak B., 1992, INDUCTIVE LOGIC PROG, P453; DZEROSKI S, 1994, P 5 INT C DEV APPL C; DZEROSKI S, 1995, ADV KNOWLEDGE DISCOV, P118; EMDE W, 1983, P IJCAI 83, P455; Fayyad U.M., 1995, ADV KNOWLEDGE DISCOV; FENSEL D, 1995, P 5 INT WORKSH IND L; FLACH P, 1992, INDUCTIVE LOGIC PROG; Flach P, 1993, LECT NOTES ARTIF INT, P83; FLACH PA, 1994, GMD STUDIEN, V237; FLACH PA, 1995, THESIS TILBURG U; Genesereth M., 1987, LOGICAL FDN ARTIFICI; HELFT N, 1989, 1ST P INT C PRINC KN, P149; KANTOLA M, 1992, INT J INTELL SYST, V7, P561; Kietz J.-U., 1992, INDUCTIVE LOGIC PROG, P335; Klosgen W., 1996, ADV KNOWLEDGE DISCOV; Lavrac N., 1994, INDUCTIVE LOGIC PROG; LLOYD JW, 1987, F LOGIC PROGRAMMING; Macdonald I., 1979, SYMMETRIC FUNCTIONS; MANNILA H, 1995, P MLNET FAM WORKSH S, P1; Manthey R., 1988, 9th International Conference on Automated Deduction Proceedings; MICHALSKI RS, 1983, MACHINE LEARNING, V1; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MORIK K, 1996, P 3 INT WORKSH MULT, P17; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; MUGGLETON S, 1990, 1ST P C ALG LEARN TH, P368; MUGGLETON S, 1995, NEW GENERATION COMPU, V13; Dzeroski S., 1993, Journal of Computing and Information Technology - CIT, V1; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Plotkin G.D., 1970, MACH INTELL, V5, P153; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; ROUVEIROL C, 1994, MACH LEARN, V14, P19; Savnik I., 1993, P AAAI 93 WORKSH KNO, P174; SCHLIMMER JC, 1991, 1991 P AAAI WORKSH K, P64; SHEN WM, 1992, INT J INTELLIGENT SY, V7; SRINIVASAN A, 1995, IN PRESS ARTIFICIAL; SRINIVASAN A, 1995, P 5 INT WORKSH IND L; SRINIVASAN A, 1992, P 2 INT WORKSH IND L; STERLING L., 1986, ART PROLOG; VANDERLAAG PRJ, 1994, LECT NOTES ARTIF INT, V784, P307; WROBEL S, 1995, 1995 WORKSH GI SPEC	56	81	81	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	FEB-MAR	1997	26	2-3					99	146		10.1023/A:1007361123060		48	Computer Science, Artificial Intelligence	Computer Science	WP300	WOS:A1997WP30000002	
J	Wang, YF				Wang, YF			Mining stock price using fuzzy rough set system	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						rough set; fuzzy rough set; data mining; matching degree; truth value	RELATIONAL DATABASES; LINGUISTIC QUANTIFIERS; GENETIC ALGORITHMS; NEURAL NETWORKS; DISCOVERY; IMPLEMENTATION; KNOWLEDGE; MODELS; LOGIC	In this study of mining stock price data, we attempt to predict the stronger rules of stock prices. To address this problem, we proposed an effective method, a fuzzy rough set system to predict a stock price at any given time. Our system has two agents: one is a visual display agent that helps stock dealers monitor the current price of a stock and the other is a mining agent that helps stock dealers make decisions about-when to buy or sell stocks. To demonstrate that our system is effective, we used it to. predict the stronger rules of stock price and achieved at least 93% accuracy after 180 trials. (C) 2002 Elsevier Science Ltd. All rights reserved.	Chang Gung Inst Technol, Dept Informat Management, Tao Yuan, Taiwan	Wang, YF (reprint author), Chang Gung Inst Technol, Dept Informat Management, Tao Yuan, Taiwan.						BABA N, 1992, P IJCNN 92 BALT MAR; Bansal K, 1998, DATA MIN KNOWL DISC, V2, P97, DOI 10.1023/A:1009769804855; BOSC P, 1988, FUZZY SET SYST, V28, P333, DOI 10.1016/0165-0114(88)90039-5; BOSC P, 1995, IEEE T FUZZY SYST, V3, P1, DOI 10.1109/91.366566; BUCKLES BP, 1983, IEEE T SYST MAN CYB, V13, P72; Cai Y., 1991, Knowledge discovery in databases; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Chiang DA, 2000, FUZZY SET SYST, V112, P419, DOI 10.1016/S0165-0114(98)00003-7; Chiang DA, 1998, IEEE T SYST MAN CY C, V28, P476; Cubero JC, 1999, INFORM SCIENCES, V121, P233, DOI 10.1016/S0020-0255(99)00104-8; DEMAREST M, 1994, DBMA MAGAZINE, V7, P44; Dhar V, 2000, DATA MIN KNOWL DISC, V4, P251, DOI 10.1023/A:1009848126475; DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Giudici P, 2001, DATA MIN KNOWL DISC, V5, P163, DOI 10.1023/A:1011452614423; Glymour C, 1997, DATA MIN KNOWL DISC, V1, P11, DOI 10.1023/A:1009773905005; GRZYMALABUSSE J, 1995, COMMUN ACM, V38, P89; HAEFKE C, 2000, NEURAL NETWORKS FINA, P378; Hernandez MA, 1998, DATA MIN KNOWL DISC, V2, P9, DOI 10.1023/A:1009761603038; KACPRZYK J, 1989, INFORM SYST, V14, P443, DOI 10.1016/0306-4379(89)90012-4; KACPRZYK J, 1986, IEEE T SYST MAN CYB, V16, P474, DOI 10.1109/TSMC.1986.4308982; KACPRZYK J, 1992, FUZZY LOGIC MANAGEME, P465; Kendall S.M., 1990, TIME SERIES; Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0; Kuo RJ, 2001, FUZZY SET SYST, V118, P21, DOI 10.1016/S0165-0114(98)00399-6; Lee KH, 1999, EXPERT SYST APPL, V16, P357, DOI 10.1016/S0957-4174(99)00011-1; Lin T. Y., 1997, ROUGH SETS DATA MINI; Liu J, 1996, Biomed Environ Sci, V9, P1; Mahfoud S, 1996, APPL ARTIF INTELL, V10, P543, DOI 10.1080/088395196118425; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; MEDINA JM, 1994, INFORM SCIENCES, V76, P87, DOI 10.1016/0020-0255(94)90069-8; MEDINA JM, 1995, FUZZY SET SYST, V75, P273, DOI 10.1016/0165-0114(94)00380-P; MROZEK A, 1998, ROUGH SETS KNOWLEDGE, V2, P214; Pawlak Z, 1982, INT J INFORMATION CO, P145; Pawlak Z., 1991, ROUGH SETS THEORETIC; PIATESKYSHAPIRO G, 1989, P IJCAI 89 WORKSH KN, P264; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; RAJU KVSVN, 1988, ACM T DATABASE SYST, V13, P129, DOI 10.1145/42338.42344; TAHANI V, 1977, INFORM PROCESS MANAG, V13, P289, DOI 10.1016/0306-4573(77)90018-8; Westerdijk M, 2001, DATA MIN KNOWL DISC, V5, P337, DOI 10.1023/A:1011405212443; Widom J., 1995, Proceedings of the 1995 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/221270.221319; YAGER RR, 1984, INT J MAN MACH STUD, V21, P389, DOI 10.1016/S0020-7373(84)80066-8; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; YAGER RR, 1991, KNOWLEDGE DISCOVERY; Yager RR, 2001, IEEE T SYST MAN CY B, V31, P19, DOI 10.1109/3477.907562; Yager RR, 1996, INT J INTELL SYST, V11, P691, DOI 10.1002/(SICI)1098-111X(199609)11:9<691::AID-INT7>3.0.CO;2-F; Zadeh L. A., 1978, FUZZY SETS SYSTEMS, V1, P1, DOI DOI 10.1016/0165-0114(78)90029-5; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; Zadeh LA, 1999, COMPUT MATH APPL, V37, P35, DOI 10.1016/S0898-1221(99)00140-6; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Ziarko W., 1994, ROUGH SETS FUZZY SET; ZIARKO W, 1999, COMMUN ACM, V42, P55	52	80	90	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JAN	2003	24	1					13	23		10.1016/S0957-4174(02)00079-9		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	627KM	WOS:000179932400002	
J	Espinosa, J; Vandewalle, J				Espinosa, J; Vandewalle, J			Constructing fuzzy models with linguistic integrity from numerical data-AFRELI algorithm	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						data mining; function approximation; fuzzy modeling; knowledge extraction	OPTIMIZATION	This paper presents an algorithm to extract rules relating input/output data and including prior knowledge. The rules are created in the environment of fuzzy systems. The fuzzy sets describing the system are constructed within a framework of linguistic integrity to guarantee its interpretability in the linguistic context. Two algorithms are presented in this paper. The main algorithm is the autonomous fuzzy rule extractor with linguistic integrity (AFRELI). This algorithm is complemented with the use of the FuZion algorithm created to merge consecutive membership functions, while guaranteeing the distinguish ability between fuzzy sets. Comparisons with other proposed methods show a good tradeoff between accuracy and interpretability.	Katholieke Univ Leuven, ESAT, SISTA, B-3001 Heverlee, Belgium	Espinosa, J (reprint author), Katholieke Univ Leuven, ESAT, SISTA, B-3001 Heverlee, Belgium.						BEZDEK JC, 1976, IEEE T SYST MAN CYB, V6, P387; BIERMANN G, 1977, FACTORIZATION METHOD; BROADBENT D, 1975, MAGIC NUMBER 7 15 YE, P3; de Oliveira JV, 1999, IEEE T SYST MAN CY A, V29, P128, DOI 10.1109/3468.736369; ESPINOSA J, 1997, P IEEE SING INT S CO, P437; Espinosa J., 1998, Proceedings of the 5th International Conference on Soft Computing and Information/Intelligent Systems. Methodologies for the Conception, Design and Application of Soft Computing; ESPINOSA J, 1998, P INT WORKSH ADV BLA, P197; JANG JR, 1994, P IEEE INT C FUZZ SY; JANG JSR, 1992, THESIS U CALIFORNIA; Jang J.S.R., 1997, NEUROFUZZY SOFT COMP; LORI N, 1995, INTELLIGENT ENG SYST, V5, P311; Nozaki K, 1997, FUZZY SET SYST, V86, P251, DOI 10.1016/0165-0114(95)00413-0; PEDRYCZ W, 1994, FUZZY SET SYST, V64, P21, DOI 10.1016/0165-0114(94)90003-5; Pedrycz W, 1996, IEEE T SYST MAN CY B, V26, P627, DOI 10.1109/3477.517038; Setnes M, 1998, IEEE T SYST MAN CY B, V28, P376, DOI 10.1109/3477.678632; Setnes M, 1998, IEEE T SYST MAN CY C, V28, P165, DOI 10.1109/5326.661100; Sugeno M., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390281; TAN S, 1995, P 6 INT FUZZ SYST AS, P189; Wang L. X., 1994, ADAPTIVE FUZZY SYSTE; Yager R., 1994, ESSENTIALS FUZZY MOD; Yen J, 1999, IEEE T SYST MAN CY B, V29, P13, DOI 10.1109/3477.740162; *MATHW, 1998, FUZZ LOG TOOLB US GU	22	80	80	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	OCT	2000	8	5					591	600				10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	363DU	WOS:000089820400010	
S	Mukkamala, S; Janoski, G; Sung, A			IEEE; IEEE	Mukkamala, S; Janoski, G; Sung, A			Intrusion detection using neural networks and support vector machines	PROCEEDING OF THE 2002 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-3	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN 02)	MAY 12-17, 2002	HONOLULU, HI	IEEE, IEEE Neural Networks Soc, Int Neural Network Soc				Information security is an issue of serious global concern. The complexity, accessibility, and openness of the Internet have served to increase the security risk of information systems tremendously. This paper concerns intrusion detection. We describe approaches to intrusion detection using neural networks and support vector machines. The key ideas are to discover useful patterns or features that describe user behavior on a system, and use the set of relevant features to build classifiers that can recognize anomalies and known intrusions, hopefully in real time. Using a set of benchmark data from a KDD (Knowledge Discovery and Data Mining) competition designed by DARPA, we demonstrate that efficient and accurate classifiers can be built to detect intrusions. We compare the performance of neural networks based, and support vector machine based, systems for intrusion detection.	New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA	Mukkamala, S (reprint author), New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA.						Beale M., 2000, NEURAL NETWORK TOOLB; Cannady J., 1998, NAT INF SYST SEC C; CRAMER M, 1995, P TECHN INF SEC C TI, P1; Debar H, 1992, P IEEE COMP SOC S RE; Debar H., 1992, P INT JOINT C NEUR N, P78; Denning D., 1987, IEEE T SOFTWARE ENG, V13; GHOSH A, 1999, LEARNING PROGRAM BEH; Joachims T., 2000, SVMLIGHT IS IMPLEMEN; Joachims T., 2000, P INT C MACH LEARN; Joachims Thorsten, 1998, LS8 U DORTM; KUMAR S, 1994, CSDTR94013 PURD U; LUO J, 2000, INT J INTELL SYST, P15; RYAN J, 1998, ADV NEURAL INFORMATI, V10; SUNG AH, 1998, EXPERT SYSTEMS APPL, P15; VLADIMIR VN, 1995, NATRE STAT LEARNING	15	79	105	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	0-7803-7278-6	IEEE IJCNN			2002							1702	1707		10.1109/IJCNN.2002.1007774		2	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BU92F	WOS:000177402800303	
J	Cohen, E; Datar, M; Fujiwara, S; Gionis, A; Indyk, P; Motwani, R; Ullman, JD; Yang, C				Cohen, E; Datar, M; Fujiwara, S; Gionis, A; Indyk, P; Motwani, R; Ullman, JD; Yang, C			Finding interesting associations without support pruning	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article; Proceedings Paper	16th International Conference on Data Engineering (ICDE 2000)	FEB 29-MAR 03, 2000	SAN DIEGO, CALIFORNIA			data mining; association rules; similarity metric; min hashing; locality sensitive hashing		Association-rule mining has heretofore relied on the condition of high support to do its work efficiently. In particular, the well-known a priori algorithm is only effective when the only rules of interest are relationships that occur very frequently. However, there are a number of applications, such as data mining, identification of similar web documents, clustering, and collaborative filtering, where the rules of interest have comparatively few instances in the data. In these cases, we must look for highly correlated items, or possibly even causal relationships between infrequent items. We develop a family of algorithms for solving this problem, employing a combination of random sampling and hashing techniques. We provide analysis of the algorithms developed and conduct experiments on real and synthetic data to obtain a comparative performance analysis.	AT&T Labs Res, Florham Park, NJ 07932 USA; Hitachi Ltd, Cupertino, CA 95014 USA; Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Cohen, E (reprint author), AT&T Labs Res, 180 Pk Ave,Rm A105, Florham Park, NJ 07932 USA.		Gionis, Aristides/G-2225-2013	Gionis, Aristides/0000-0002-5211-112X			Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Broder A. Z., 1998, Proceedings. Compression and Complexity of SEQUENCES 1997 (Cat. No.97TB100171), DOI 10.1109/SEQUEN.1997.666900; Cohen E, 1997, J COMPUT SYST SCI, V55, P441, DOI 10.1006/jcss.1997.1534; Duda R., 1973, PATTERN CLASSIFICATI; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; GOLDBERG D, 1991, COMMUN ACM, V55, P1; HELLERSTEIN JM, 1997, P ACM SIGMOD INT C M; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Motwani R., 1995, RANDOMIZED ALGORITHM; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; SHIVAKUMAR N, 1996, P 3 INT C THEOR PRAC; SILVERSTEIN C, 1998, DATA MIN KNOWL DISC, V2, P69; Silverstein C., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; VARIAN HR, 1997, COMM ACM, V40	16	79	88	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN-FEB	2001	13	1					64	78		10.1109/69.908981		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	400RU	WOS:000166886100007	
J	Michalski, RS				Michalski, RS			Learnable Evolution ModeL: Evolutionary processes guided by machine learning	MACHINE LEARNING			English	Article; Proceedings Paper	4th International Workshop on Multistrategy Learning	1998	DESENZANO GARDA, ITALY			multistrategy learning; genetic algorithms; evolution model; evolutionary computation	GENETIC ALGORITHM	A new class of evolutionary computation processes is presented, called Learnable Evolution Model or LEM. In contrast to Darwinian-type evolution that relies on mutation, recombination, and selection operators, LEM employs machine learning to generate new populations. Specifically, in Machine Learning mode, a learning system seeks reasons why certain individuals in a population (or a collection of past populations) are superior to others in performing a designated class of tasks. These reasons, expressed as inductive hypotheses, are used to generate new populations. A remarkable property of LEM is that it is capable of quantum leaps ("insight jumps") of the fitness function, unlike Darwinian-type evolution that typically proceeds through numerous slight improvements. In our early experimental studies, LEM significantly outperformed evolutionary computation methods used in the experiments, sometimes achieving speed-ups of two or more orders of magnitude in terms of the number of evolutionary steps. LEM has a potential for a wide range of applications, in particular, in such domains as complex optimization or search problems, engineering design, drug design, evolvable hardware, software engineering, economics, data mining, and automatic programming.	George Mason Univ, Machine Learning & Inference Lab, Fairfax, VA 22030 USA; Polish Acad Sci, Inst Comp Sci, PL-00901 Warsaw, Poland	Michalski, RS (reprint author), George Mason Univ, Machine Learning & Inference Lab, Fairfax, VA 22030 USA.	michalski@gmu.edu					ACKLEY D, 1992, ARTIFICIAL, V2; AUGIER S, 1995, P 1 INT C KNOWL DISC, P21; Baeck T, 1997, HDB EVOLUTIONARY COM; Baldwin J. M., 1896, AM NAT, V30, p[441, 536], DOI DOI 10.1086/276408; Banzhaf W., 1998, GENETIC PROGRAMMING; BLOEDORN E, 1998, IEEE INTELLIGENT SYS; CERVONE G, IN PRESS REPORTS MAC; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Cohen W.W., 1995, P 12 INT C MACH LEAR; COLETTI M, 1999, REPORTS MACHINE LEAR; Darwin C, 1859, ORIGIN SPECIES MEANS; DEGARIS H, IN PRESS APPL MATH C; DEGARIS H, 1996, LECT NOTES COMPUTER, V1062, P76; Dejong K. A., 1975, THESIS U MICHIGAN; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DEJONG KA, IN PRESS EVOLUTIONAR; DIETTERICH TG, 1997, AI MAGAZINE, V18; ESPOSITO F, 1998, P 4 INT WORKSH MULT; FORSBURG S, 1976, AQPLUS ADAPTIVE RAND; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Grefenstette J. J., 1991, P 4 INT C GEN ALG SA, P303; Hekanaho J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; HEKANAHO J, 1998, 168 TUCS TECHNICAL R; Hinton G. E., 1987, Complex Systems, V1; HOLLAND JH, 1975, ADAPTATION NATURAL A; JANIKOW CZ, 1993, MACH LEARN, V13, P189, DOI 10.1023/A:1022669929488; KAUFMAN K, 1999, 11 INT S ISMIS 99 SP; Koza J. R., 1994, GENETIC PROGRAMMING; Lavrac N., 1994, INDUCTIVE LOGIC PROG; MALOOF M, 1999, P INT INF SYST USTR, V8; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Michalski R. S., 1994, MACHINE LEARNING MUL, V4; MICHALSKI RS, 1998, P 4 INT WORKSH MULT; MICHALSKI RS, 1999, REPORTS MACHINE LEAR; MICHALSKI RS, 1986, REPORTS INTELLIGENT, V8620; MICHALSKI RS, IN PRESS REPORTS MAC; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; MICHALSKI RS, 1969, 5TH P INT S INF PROC, V3, P125; MICHALSKI RS, 1973, P 3 INT JOINT C ART, P162; MICHALSKI RS, 1988, MACHINE LEARNING DAT; MICHALSKI RS, 1978, REPORTS DEP COMPUTER, V897; MICHALSKI RS, 1971, P 3 ANN HOUST C COMP; Mitchell M., 1996, INTRO GENETIC ALGORI; MITCHELL TM, 1997, AI MAGAZINE, V18; RAVISE C, 1996, P 13 INT C MACH LEAR, P400; SEBAG M, 1997, LNCS, V1213, P247; Sebag M, 1994, LECT NOTES COMPUT SC, V866, P209; Sebag M., 1997, P 7 INT C GEN ALG, P291; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; VAFAIE H, P 1 INT WORKSH MULT; VAFAIE H, 1992, P 4 INT C TOOLS ART; WNEK J, 1995, REPORTS MACHINE LEAR; YAO L, 1994, IEEE T SIGNAL PROCES, V42, P927; ZHANG Q, 1997, REPORTS MACHINE LEAR	56	79	85	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	JAN	2000	38	1-2					9	40		10.1023/A:1007677805582		32	Computer Science, Artificial Intelligence	Computer Science	283CP	WOS:000085258800002	
S	Savasere, A; Omiecinski, E; Navathe, S			IEEE COMP SOC	Savasere, A; Omiecinski, E; Navathe, S			Mining for strong negative associations in a large database of customer transactions	14TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING, PROCEEDINGS	PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON DATA ENGINEERING (SERIES)		English	Proceedings Paper	IEEE Computer-Society 14th International Conference on Data Engineering (ICDE 98)	FEB 23-27, 1998	ORLANDO, FL	IEEE Comp Soc, Tech Comm Data Engn				Mining for association rules is considered an important data mining problem. Many different variations of this problem have been described in the literature. In this paper we introduce the problem of mining for negative associations. A naive approach to finding negative associations leads to a very large number of rules with low interest measures. We address this problem by combining previously discovered positive associations with domain knowledge to constrain the search space such that fewer but more interesting negative rules are mined. We describe an algorithm that efficiently finds all such negative associations and present the experimental results.	Tandem Comp Inc, Data Min Grp, Austin, TX 78728 USA	Savasere, A (reprint author), Tandem Comp Inc, Data Min Grp, 14231 Tandem Blvd, Austin, TX 78728 USA.							0	79	109	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6382	0-8186-8289-2	PROC INT CONF DATA			1998							494	502		10.1109/ICDE.1998.655812		9	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BK59S	WOS:000072696100058	
J	Chen, GQ; Wei, Q				Chen, GQ; Wei, Q			Fuzzy association rules and the extended mining algorithms	INFORMATION SCIENCES			English	Article						data mining; fuzzy association rule; fuzzy taxonomic structure; linguistic hedge		This paper focuses on the notion of fuzzy association rules that are of the form X double right arrow Y, where either X or Y is a collection of fuzzy sets. The work stems from two observations. First, in generalized association rule mining, the taxonomies concerned may not be crisp but fuzzy (e.g., "Tomato" could be regarded as both "Fruit" and "Vegetable", each at a different degree). Second, managers often refer to decision rules in terms of linguistic expressions that may or may not be the nodes of the taxonomies (e.g., "VERY 'Expensive cloth' " double right arrow "Tropical fruit"). The paper deals with the fuzziness based upon fuzzy taxonomies that reflect partial belongings among itemsets, as well as upon the extended settings for the degree of support and the degree of confidence. Apriori algorithms are extended accordingly to discover association rules across the higher-level taxonomic nodes which are fuzzy sets in general. As a result, the discovered rules are fuzzy rules. Furthermore, linguistic hedges are also incorporated in mining fuzzy rules to express more meaningful knowledge. Moreover, the extended algorithms are tested with the synthetic data, revealing similar computational complexities to that of the classical algorithm. Finally, the extended algorithms are applied to a real data set with an explanation of the semantics of discovered fuzzy rules. (C) 2002 Elsevier Science Inc. All rights reserved.	Tsing Hua Univ, Dept Management Sci & Engn, Sch Econ & Management, Beijing 100084, Peoples R China	Chen, GQ (reprint author), Tsing Hua Univ, Dept Management Sci & Engn, Sch Econ & Management, Beijing 100084, Peoples R China.						Agrawal R., 1994, RJ9839 IBM; Agrawal R., 1993, P 1993 ACM SIGMOD C; Agrawal R., 1996, ADV KNOWLEDGE DISCOV; AU WH, 1999, 1999 IEEE INT FUZZ S; FUKUDA T, 1996, SIGMOD 96 MONTR CAN; GYENESEI A., 2000, 336 TUCS; HAN J, 1995, P 21 INT C VER LARG; HONG TP, 1999, 1999 3 INT C KNOWL B; Houtsma M, 1995, DATA KNOWL ENG, V17, P245, DOI 10.1016/0169-023X(95)00024-M; ISHIBUCHI H, 2001, FUZZY ASS RULES HAND, P118; Kerre E.E., 1993, INTRO BASIC PRINCIPL; KLEMETTINEN M, 1994, P 3 INT C INF KNOWL; LIU D, 2000, IFIP WCC2000 AUG BEI; Mannila H., 1994, AAAI WORKSH KNOWL DI, P181; Minieka E., 1978, OPTIMIZATION ALGORIT; SAVASERE E, 1995, P VLDB C ZUR SWITZ S; Srikant R., 1995, P 21 VLDB C ZUR SWIT; Srikant R., 1996, SIGMOD 96 MONTR CAN; WEI Q, 2000, FQAS2000 WARS POL; WEI Q, 1999, NAFIPS 99 NEW YORK; [Anonymous], 1998, FUZZY LOGIC DATA MOD	21	78	86	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	NOV	2002	147	1-4					201	228		10.1016/S0020-0255(02)00264-5		28	Computer Science, Information Systems	Computer Science	620JQ	WOS:000179530600009	
J	Bose, I; Mahapatra, RK				Bose, I; Mahapatra, RK			Business data mining - a machine learning perspective	INFORMATION & MANAGEMENT			English	Article						business applications; data mining; machine learning	WORLD-WIDE-WEB; NEURAL NETWORKS; KNOWLEDGE DISCOVERY; AI-SYSTEM; DATABASES; ALGORITHMS; PREDICTION; SUPPORT; SALES; RULES	The objective of this paper is to inform the information systems (IS) manager and business analyst about the role of machine learning techniques in business data mining. Data mining is a fast growing application area in business. Machine learning techniques are used for data analysis and pattern discovery and thus can play a key role in the development of data mining applications. Understanding the strengths and weaknesses of these techniques in the context of business is useful in selecting an appropriate method for a specific application. The paper, therefore, provides an overview of machine learning techniques and discusses their strengths and weaknesses in the context of mining business data, A survey of data mining applications in business is provided to investigate the use of learning techniques. Rule induction (RI) was found to be most popular, followed by neural networks (NNs) and case-based reasoning (CBR). Most applications were found in financial areas, where prediction of the future was a dominant task category. (C) 2001 Elsevier Science B.V. All rights reserved.	Univ Texas, Coll Business Adm, Dept Informat Syst & Management Sci, Arlington, TX 76019 USA; Univ Florida, Warrington Coll Business Adm, Dept Decis & Informat Sci, Gainesville, FL 32611 USA	Mahapatra, RK (reprint author), Univ Texas, Coll Business Adm, Dept Informat Syst & Management Sci, POB 19437, Arlington, TX 76019 USA.	bosei@ufl.edu; mahapatra@uta.edu					ALLEN BP, 1994, COMMUN ACM, V37, P40, DOI 10.1145/175247.175250; Anand SS, 1998, KNOWL-BASED SYST, V10, P449, DOI 10.1016/S0950-7051(98)00035-5; Anand T., 1995, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V4, DOI 10.1007/BF00962820; ANAND T, 1993, IEEE EXPERT, P19; Apte C, 1997, FUTURE GENER COMP SY, V13, P197, DOI 10.1016/S0167-739X(97)00021-6; BARR DS, 1994, AI EXPERT, P16; BECKER BG, 1997, IEEE COMPUTER GR JUL, P75; Bergadano F., 1996, INDUCTIVE LOGIC PROG; Berson A., 1997, DATA WAREHOUSING DAT; Bhargava HK, 1999, INFORMS J COMPUT, V11, P239, DOI 10.1287/ijoc.11.3.239; Bhattacharyya S, 1999, INFORMS J COMPUT, V11, P248, DOI 10.1287/ijoc.11.3.248; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Buta P., 1994, AI Expert, V9; CARTER C, 1987, IEEE EXPERT      FAL, P71; CHAKRABARTI S, 1999, IEEE COMPUT, P60; Chen MS, 1996, INT CON DISTR COMP S, P385; Cooley R, 1997, PROC INT C TOOLS ART, P558, DOI 10.1109/TAI.1997.632303; CRAVEN M, 1998, P 10 EUR C MACH LEAR, P250; Craven MW, 1997, FUTURE GENER COMP SY, V13, P211, DOI 10.1016/S0167-739X(97)00022-8; Daengdej J, 1999, KNOWL-BASED SYST, V12, P239, DOI 10.1016/S0950-7051(99)00015-5; Dale S. L., 1997, Proceedings. Eighth International Workshop on Database and Expert Systems Applications (Cat. No. 97TB100181), DOI 10.1109/DEXA.1997.617267; Etzioni O, 1996, COMMUN ACM, V39, P65, DOI 10.1145/240455.240473; Fayyad U, 1996, AI MAG, V17, P37; Furnkranz J, 1997, APPL ARTIF INTELL, V11, P91, DOI 10.1080/088395197118262; GERSHON N, 1997, IEEE COMPUT GRAPH, P66; GOLDBERG DE, 1994, COMMUN ACM, V37, P113, DOI 10.1145/175247.175259; JOHN GH, 1996, P IEEE IAFE C COMP I, P52; Kim SH, 1997, EXPERT SYST APPL, V13, P85, DOI 10.1016/S0957-4174(97)00010-9; Kokkinaki A. I., 1997, Proceedings. 1997 IEEE Knowledge and Data Engineering Exchange Workshop (Cat. No.97TB100208), DOI 10.1109/KDEX.1997.629848; Kolodner J. L., 1993, CASE BASED REASONING; Koonce DA, 1997, COMPUT IND ENG, V33, P27, DOI 10.1016/S0360-8352(97)00033-8; KRIEGSMAN M, 1993, IEEE EXPERT, V8, P18, DOI 10.1109/64.248349; LANGLEY P, 1995, COMMUN ACM, V38, P55; Lee A, 1998, INFORM MANAGE, V34, P1, DOI 10.1016/S0378-7206(98)00041-X; Lee G., 1999, J MANAGE INFORM SYST, P63; Lee HY, 1996, IEEE EXPERT, V11, P69; MAJOR JA, 1992, INT J INTELL SYST, V7, P687, DOI 10.1002/int.4550070709; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Matheus C., 1996, ADV KNOWLEDGE DISCOV, P495; MESSIER WF, 1988, MANAGE SCI, V34, P1403, DOI 10.1287/mnsc.34.12.1403; Packard N. H., 1990, Complex Systems, V4; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RAUCH J, 1997, NEURAL NETW WORLD, V4, P427; ROHRER RM, 1997, IEEE COMPUT GRAPH, P52; RUMELHART DE, 1994, COMMUN ACM, V37, P87, DOI 10.1145/175247.175256; Sasisekharan R, 1996, IEEE EXPERT, V11, P37, DOI 10.1109/64.482956; SCARFE RT, 1995, IEE C DIGEST; SCHMITZ JD, 1990, INTERFACES, V20, P29, DOI 10.1287/inte.20.6.29; SELFRIDGE PG, 1996, P SIGMOD 96, P24, DOI 10.1145/233269.233315; Senator TE, 1995, AI MAG, V16, P21; SETIONO R, 1998, INFORMATION MANAGEME, V34, P33; SHAW M, 1990, IEEE EXPERT, P47; SHORTLAND R, 1995, IEE REVIEW, V41, P213, DOI 10.1049/ir:19950504; SIMOUDIS E, 1992, IEEE EXPERT, P7; SPANGLER W, 1999, J MANAGEMENT INFORMA, V16, P47; SPARTUS E, 1997, COMPUTER NETWORKS IS, V29, P1205; Tsaih R, 1998, DECIS SUPPORT SYST, V23, P161, DOI 10.1016/S0167-9236(98)00028-1; UCKUN S, 1993, IEEE EXPERT, P15; Viveros M. S., 1997, PADD97 Proceedings of the First International Conference on the Practical Application of Knowledge Discovery and Data Mining; Vollrath I, 1998, IEEE INTERNET COMPUT, V2, P47, DOI 10.1109/4236.707690; WILSON RL, 1994, DECIS SUPPORT SYST, V11, P545, DOI 10.1016/0167-9236(94)90024-8; Wu KL, 1998, IBM SYST J, V37, P89; YUANHUI Z, 1997, P IEEE INT C SYST MA, V5, P4338	63	78	84	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-7206		INFORM MANAGE-AMSTER	Inf. Manage.	DEC 20	2001	39	3					211	225		10.1016/S0378-7206(01)00091-X		15	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	489ML	WOS:000171995100004	
J	Saygin, Y; Verykios, VS; Clifton, C				Saygin, Y; Verykios, VS; Clifton, C			Using unknowns to prevent discovery of association rules	SIGMOD RECORD			English	Article								Data mining technology has given us new capabilities to identify correlations in large data sets. This introduces risks when the data is to be made public, but the correlations are private. We introduce a method for selectively removing individual values from a database to prevent the discovery of a set of rules, while preserving the data for other applications. The efficacy and complexity of this method are discussed. We also present an experiment showing an example of this methodology.	Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA							Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; AGRAWAL R, 2000, P SIGMOD C, P45; Atallah M, 1999, P 1999 IEEE KNOWL DA, P45; CHANG L, 1999, P WORKSH NEW SEC PAR, P82; CLIFTON C, 2000, J COMPUTER SECURITY, V8; ELENA D, 2001, IN PRESS P INF HID W; Hinke TH, 1997, COMPUT SECUR, V16, P687, DOI 10.1016/S0167-4048(97)87607-9; VERYKLOS VS, 2000, UNPUB IEEE T KNOWLED	8	78	84	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0163-5808		SIGMOD RECORD	Sigmod Rec.	DEC	2001	30	4					45	54				10	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	499JA	WOS:000172567000005	
J	Kautz, H; Selman, B; Shah, M				Kautz, H; Selman, B; Shah, M			The hidden web	AI MAGAZINE			English	Article								The difficulty of finding information on the World Wide Web by browsing hypertext documents has led to the development and deployment of various search engines and indexing techniques. However, many information-gathering tasks are better handled by finding a referral to a human expert rather than by simply interacting with online information sources. A personal referral allows a user to judge the quality of the information he or she is receiving as well as to potentially obtain information that is deliberately not made public. The process of finding an expert who is both reliable and likely to respond to the user can be viewed as a search through the network of social relationships between individuals as opposed to a search through the network of hypertext documents. The goal of the REFERRAL WEB Project is to create models of social networks by data mining the web and develop tools that use the models to assist in locating experts and related information search and evaluation tasks.	AT&T LABS, ARTIFICIAL INTELLIGENCE RES DEPT, MURRAY HILL, NJ USA	Kautz, H (reprint author), AT&T LABS, ARTIFICIAL INTELLIGENCE PRINCIPLES RES DEPT, MURRAY HILL, NJ 07974 USA.						Galegher Jolene, 1990, INTELLECTUAL TEAMWOR; GRANOVETTER M, 1973, AM J SOCIOL, V6, P1360; Grossman J. W., 1995, C NUMERANTIUM, V108, P129; HEDETNIEMI ST, 1988, NETWORKS, V19, P319; HILL W, 1996, P ACM 1996 CSCW C NO, P106, DOI 10.1145/240080.240229; KAUTZ H, 1996, P 13 NAT C ART INT A; KRACKHARDT D, 1993, HARVARD BUS REV, V71, P4; MALONE TW, 1987, COMMUN ACM, V30, P390, DOI 10.1145/22899.22903; MILGRAM S, 1967, PSYCHOL TODAY, V1, P61; RESNICK P, 1996, COMMUNICATIONS ACM, V30; SALTON R, 1989, AUTOMATIC TEXT PROCE; SCHWARTZ MF, 1993, COMMUN ACM, V36, P78, DOI 10.1145/163381.163402; SUNDHEIM B, 1995, P 6 MESS UND C SAN F; WASSERMAN S, 1994, ADV SOCIAL NETWORK A	14	78	83	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496	0738-4602		AI MAG	AI Mag.	SUM	1997	18	2					27	36				10	Computer Science, Artificial Intelligence	Computer Science	XK443	WOS:A1997XK44300004	
J	Rokach, L; Maimon, O				Rokach, L; Maimon, O			Top-down induction of decision trees classifiers - A survey	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						classification; decision trees; pruning methods; splitting criteria	CLASSIFICATION TREES; DESIGN; ALGORITHM; SELECTION; CONSTRUCTION; ACCURACY; DATASETS; RULES	Decision trees are considered to be one of the most popular approaches for representing classifiers. Researchers from various disciplines such as statistics, machine learning, pattern recognition, and data mining considered the issue of growing a decision tree from available data. This paper presents an updated survey of current methods for constructing decision tree classifiers in a top-down manner. The paper suggests a unified algorithmic framework for presenting these algorithms and describes the various splitting criteria and pruning methodologies.	Tel Aviv Univ, Dept Ind Engn, IL-69978 Ramat Aviv, Israel	Rokach, L (reprint author), Tel Aviv Univ, Dept Ind Engn, IL-69978 Ramat Aviv, Israel.	liorr@eng.tau.ac.il	Rokach, Lior/F-8247-2010				ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Almuallim H, 1996, ARTIF INTELL, V83, P347, DOI 10.1016/0004-3702(95)00060-7; Alsabti K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; ATTNEAVE F, 1959, APPL INFORMATION THE; BAKER E, 1976, P 3 INT JOINT C PATT, P45; BENBASSAT M, 1978, IEEE T COMPUT, V27, P170; BENNETT P, 1994, OPTIMIZATION METH SO, V3, P29; BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1007/BF00993345; Breiman L, 1984, CLASSIFICATION REGRE; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; CATLETT J, 1991, THESIS U SYDNEY SYDN; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008640732416; CRAWFORD SL, 1989, INT J MAN MACH STUD, V31, P197, DOI 10.1016/0020-7373(89)90027-8; Duda R., 1973, PATTERN CLASSIFICATI; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Fayyad U., 1992, P 10 NAT C ART INT S, P104; FIFIELD DJ, 1992, THESIS U CANBERRA AU; Freitas A. A, 1998, MINING VERY LARGE DA; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; Gehrke J, 2000, DATA MIN KNOWL DISC, V4, P127, DOI 10.1023/A:1009839829793; Gehrke J., 1999, P ACM SIGMOD INT C M, P169, DOI 10.1145/304182.304197; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; GILLO MW, 1972, BEHAV SCI, V17, P251; Grumbach S, 1996, J COMPUT SYST SCI, V52, P570, DOI 10.1006/jcss.1996.0042; Hancock T, 1996, INFORM COMPUT, V126, P114; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; JOHN GH, 1996, LEARNING DATA ARTIFI, P375; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Kearns M., 1998, P 15 INT C MACH LEAR, P269; Kohavi R., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Kohavi R., 2002, HDB DATA MINING KNOW, P267; Langley P., 1994, P 1994 AAAI WORKSH C, P113; Last M, 2002, INT J PATTERN RECOGN, V16, P145, DOI 10.1142/S0218001402001599; LI XB, 1986, PATTERN RECOGN, V19, P229, DOI 10.1016/0031-3203(86)90013-0; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; LIN WC, 1983, PATTERN RECOGN, V16, P1, DOI 10.1016/0031-3203(83)90002-X; LOH SL, 1999, STAT COMPUT, V9, P309; Loh WY, 1997, STAT SINICA, V7, P815; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; LUBINSKY D, 1993, P AL STAT, P435; Martin JK, 1997, MACH LEARN, V28, P257, DOI 10.1023/A:1007367629006; Mehta M., 1996, P 5 INT C EXT DAT TE, P18; Mehta RL, 1995, P 1 INT C KNOWL DISC, P216; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; MORGAN MW, 1973, THAID SEQUENTIAL SEA; Muller W., 1994, Annals of Operations Research, V52, DOI 10.1007/BF02032305; Murthy S, 1994, J ARTIFICIAL INTELLI, V2, P1; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Naumov G. E., 1991, Soviet Physics - Doklady, V36; NIBLETT T, 1986, EXPERT SYSTEMS; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1988, MACH INTELL, V11, P305; Rastogi R, 2000, DATA MIN KNOWL DISC, V4, P315, DOI 10.1023/A:1009887311454; Rissanen J, 1989, STOCHASTIC COMPLEXIT; ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; SCLIMMER JC, 1993, P INT C MACH LEARN S, P284; SETHI IK, 1994, PATTERN RECOGN, V27, P939, DOI 10.1016/0031-3203(94)90159-7; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; Shih YS, 2001, STAT PROBABIL LETT, V54, P341, DOI 10.1016/S0167-7152(00)00188-7; Sklansky J., 1981, PATTERN CLASSIFIERS; SONQUIST A, 1971, SEARCING STRUCTURE; TAYLOR PC, 1993, STAT COMPUT, V3, P147, DOI 10.1007/BF00141771; Utgoff P. E., 1989, Connection Science, V1, DOI 10.1080/09540098908915648; UTGOFF PE, 963 U MASS DEP COMP; UTGOFF PE, 1997, MACH LEARN, V29; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; WALLACE CS, 1993, MACH LEARN, V11, P7, DOI 10.1023/A:1022646101185; Zantema H., 2000, International Journal of Foundations of Computer Science, V11, DOI 10.1142/S0129054100000193	78	77	80	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	NOV	2005	35	4					476	487		10.1109/TSMCC.2004.843247		12	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	978BH	WOS:000232846700003	
J	Kacprzyk, J; Zadrozny, S				Kacprzyk, J; Zadrozny, S			Linguistic database summaries and their protoforms: towards natural language based knowledge discovery tools	INFORMATION SCIENCES			English	Article						fuzzy logic; computing with words and perceptions; protoform; data mining; linguistic summarization	FUZZY ASSOCIATION RULES; QUANTIFIERS; LOGIC	We consider linguistic data(base) summaries in the sense of Yager [Information Sciences 28 (1982) 69-86], exemplified by "most employees are young and well paid" (with some degree of truth added), for a personnel database, as an intuitive, human consistent and natural language based knowledge discovery tool. We present first an extension of the classic Yager's approach to involve more sophisticated criteria of goodness, search methods, etc. We advocate the use of the concept of a protoform (prototypical form), that is recently vividly advocated by Zadch [A prototype-centered approach to adding deduction capabilities to search engines-the concept of a protoform. BISC Seminar, University of California, Berkeley, 2002], as a general form of a linguistic data summary. We present an extension of our interactive approach, based on fuzzy logic and fuzzy database queries, which makes it possible to implement such linguistic data summaries. We show how fuzzy queries are related to linguistic summaries, and show that one can introduce a hierarchy of protoforms, or abstract summaries in the sense of latest Zadeh's. [A prototype-centered approach to adding deduction capabilities to search engines-the concept of a protoform. BISC Seminar, University of California, Berkeley, 2002] ideas meant mainly for increasing deduction capabilities of search engines. For illustration we show an implementation for a sales database in a computer retailer, employing some type of a protoform of a linguistic summary. (c) 2005 Published by Elsevier Inc.	Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; Warsaw Sch Informat Technol, PL-01447 Warsaw, Poland	Kacprzyk, J (reprint author), Polish Acad Sci, Syst Res Inst, Ul Newelska 6, PL-01447 Warsaw, Poland.	kacprzyk@ibspan.waw.pl; zadrozny@ibspan.waw.pl	Zadrozny, Slawomir/A-4278-2008				ANWAR TM, P INT C DAT ENG TAMP, P622; Bordogna G, 2000, INT J INTELL SYST, V15, P995, DOI 10.1002/1098-111X(200011)15:11<995::AID-INT2>3.0.CO;2-J; Bosc P., 2002, P 9 INT C IPMU 2002, P1553; BOSC P, P 3 IEEE INT C FUZZ, P325; CHEN G, 2001, P FUZZ IEEE 2001 VAN, P1440; CHEN G, 2000, RECENT ISSUES FUZZY, P45; Chen GQ, 2002, INFORM SCIENCES, V147, P201, DOI 10.1016/S0020-0255(02)00264-5; DUBOIS D, 1992, INFORM SCIENCES, V61, P103, DOI 10.1016/0020-0255(92)90035-7; George R, 1996, INFORM SCIENCES, V92, P313, DOI 10.1016/0020-0255(96)00049-7; George R., 1996, GENETIC ALGORITHMS S, P599; Hu YC, 2002, COMPUT IND ENG, V43, P735, DOI 10.1016/S0360-8352(02)00136-5; Kacprzyk J, 2003, IEEE INT CONF FUZZY, P702; Kacprzyk J., 1995, FUZZINESS DATABASE M, P415; Kacprzyk J, 2000, KYBERNETIKA, V36, P605; Kacprzyk J., 2000, International Journal of Applied Mathematics and Computer Science, V10; Kacprzyk J., 1999, P IFSA 99 TAIP TAIW, V1, P29; KACPRZYK J, 1986, IEEE T SYST MAN CYB, V16, P474, DOI 10.1109/TSMC.1986.4308982; Kacprzyk J., 1989, INFORMATION SYSTEMS, V6, P443; Kacprzyk J, 2000, ST CLASS DAT ANAL, P153; Kacprzyk J., 2002, SOFT COMPUTING SYSTE, P417; Kacprzyk J, 2000, QUO VADIS COMPUTATIO, P144; KACPRZYK J, 2001, COMPUT INTELL, P235; Kacprzyk J., 1999, COMPUTING WORDS INFO, P382; Kacprzyk J, 2000, KYBERNETIKA, V36, P657; KACPRZYK J, 2001, KNOWLEDGE DISCOVERY, P129; Kacprzyk J, 2001, ADV SOFT COMP, P475; Kacprzyk J, 2001, FLSI SOFT COMP SER, V5, P325; KACPRZYK J, 1995, P FUZZ IEEE IFES 95, V2, P61; KACPRZYK J, 2000, KNOWLEDGE MANAGEMENT, P211; KACPRZYK J, 2001, DATA MINING COMPUTAT, P115; Kacprzyk J., 1998, METHODOLOGIES CONCEP, P668; KACPRZYK J, 1994, P 3 IEEE C FUZZ SYST, V1, P167; KACPRZYK J, 2000, RECENT RES ISSUES MA, P67; Kacprzyk J, 2001, INT J GEN SYST, V30, P133, DOI 10.1080/03081070108960702; Kacprzyk J, 2001, INFORM SCIENCES, V134, P71, DOI 10.1016/S0020-0255(01)00093-7; LEE JH, 1997, P IFSA 1997 PRAG JUN, P399; LIU ZH, 1998, ACTA POLYM SIN, V1, P1; PONS O, 2000, KNOWLEDGE MANAGEMENT; Raschia G, 2002, FUZZY SET SYST, V129, P137, DOI 10.1016/S0165-0114(01)00197-X; Rasmussen D., 1997, FUZZY INFORMATION EN, P253; RASMUSSEN D, 1997, INTELLIGENT DATA ANA, V1; RASMUSSEN D, 1996, P IPMU 96 GRAN SPAIN, P275; Rasmussen D, 1999, FUZZY SET SYST, V106, P131, DOI 10.1016/S0165-0114(97)00268-6; Yager R.R., 1995, P WORKSH FUZZ DAT SY, P79; Yager R.R., 1997, ORDERED WEIGHTED AVE; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; YAGER RR, 1999, P IFSA 99 C TAIP, V1, P44; Yager R. R., 1991, Knowledge discovery in databases; Yager RR, 1996, INT J INTELL SYST, V11, P691, DOI 10.1002/(SICI)1098-111X(199609)11:9<691::AID-INT7>3.0.CO;2-F; YAGER RR, 1982, INFORM SCIENCES, V28, P69, DOI 10.1016/0020-0255(82)90033-0; Zadeh L., 1992, FUZZY LOGIC MANAGEME; Zadeh L. A., 1999, COMPUTING WORDS INFO, V1; ZADEH LA, 2002, BISC SEM 2002 U CAL; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; ZADEH LA, 1985, IEEE T SYST MAN CYB, V15, P754; Zadrozny S., 1995, P 3 EUR C INT TECHN, V2, P733; ZADROZNY S, 1999, P IFSA 99 WORLD C TA, V1, P39	57	77	77	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JUN 23	2005	173	4			SI		281	304		10.1016/j.ins.2005.03.002		24	Computer Science, Information Systems	Computer Science	938DW	WOS:000229981100002	
J	Bernado-Mansilla, E; Garrell-Guiu, JM				Bernado-Mansilla, E; Garrell-Guiu, JM			Accuracy-based Learning Classifier Systems: Models, analysis and applications to classification tasks	EVOLUTIONARY COMPUTATION			English	Article						learning classifier systems; accuracy-based fitness; knowledge representation; learning complexity; generalization; data mining	ALGORITHMS	Recently, Learning Classifier Systems (LCS) and particularly XCS have arisen as promising methods for classification tasks and data ruining. This paper investigates two models of accuracy-based learning classifier systems oil different types of classification problems. Departing from XCS, we analyze the evolution of a complete action map as a knowledge representation. We propose an alternative, UCS, which evolves a best action map more efficiently. We also investigate how the fitness pressure guides the search towards accurate classifiers. While XCS bases fitness oil a reinforcement learning scheme, UCS defines fitness from a supervised learning scheme. We find significant differences in how the fitness pressure leads towards accuracy, and suggest the use of a supervised approach specially for multi-class problems and problems with unbalanced classes. We also investigate the complexity factors which arise ill each type of accuracy-based LCS. We provide a model on the learning complexity of LCS which is based oil the representative examples given to the system. The results and observations are also extended to a set of real world classification problems, where accuracy-based LCS are shown to perform competitively with respect to other learning algorithms. The work presents an extended analysis of accuracy-based LCS, gives insight into the Understanding of the LCS dynamics, and suggests open issues for further improvement of LCS on classification tasks.	Ramon Llull Univ, Barcelona 08022, Spain	Bernado-Mansilla, E (reprint author), Lucent Technol, Comp Sci, Bell Labs, 600-700 Mt Ave, Murray Hill, NJ 07974 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bernado E, 2002, LECT NOTES ARTIF INT, V2321, P115; BERNADOMANSILLA E, 2001, LECT NOTES COMPUTER, V1993, P696; BERNADOMANSILLA E, 2002, THESIS R LULL U BARC; Blake C, 1998, UCI REPOSITORY MACHI; BONELLI P, 1990, 7 INT C MACH LEARN, P153; Bull L., 2002, Parallel Problem Solving from Nature - PPSN VII. 7th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2439); Butz M., 2001, LECT NOTES ARTIF INT, V1996, P253; Butz M., 2001, P GEN EV COMP C GECC, P935; Butz M.V., 2001, P GEN EV COMP C GECC, P927; CLIFF D, 1995, ADAPT BEHAV, V32, P101; Conover WJ., 1971, PRACTICAL NONPARAMET, P206; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; HARTLEY A, 1999, P GEN EV COMP C 1999, P266; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOLMES JH, 1997, P 7 INT C GEN ALG IC, P426; Horn J, 1994, EVOL COMPUT, V2, P37, DOI 10.1162/evco.1994.2.1.37; John G. H., 1995, 11 C UNC ART INT, P338; Kovacs T., 1999, P GEN EV COMP C GECC, P329; KOVACS T, 2002, THESIS U BIRMINGHAM; Kovacs T., 1997, SOFT COMPUTING ENG D, P59; Kovacs T., 2000, LECT NOTES ARTIF INT, V1813/2000, P143, DOI 10.1007/3-540-45027-0_7; Kovacs T., 2000, FDN GENETIC ALGORITH, V6, P165; Kovacs Tim, 2000, LECT NOTES ARTIF INT, V1996, P80; Lanzi P. L, 1997, P 7 INT C GEN ALG IC, P418; Platt J, 1998, ADV KERNEL METHODS S; Quinlan R.J., 1993, C4 5 PROGRAMS MACHIN; SAXON S, 2000, LECT NOTES ARTIF INT, V1813, P223, DOI 10.1007/3-540-45027-0_12; Sutton R. S., 1998, REINFORCEMENT LEARNI; Wilson S., 2001, LECT NOTES ARTIF INT, V1996, P158; Wilson S. W., 1998, Genetic Programming 1998. Proceedings of the Third Annual Conference; Wilson S. W., 1987, Machine Learning, V2, DOI 10.1007/BF00058679; Wilson SW, 2002, LECT NOTES ARTIF INT, V2321, P197; WILSON SW, 1999, FESTSCHRIFT HONOR JH, P111; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; Witten IH, 2000, DATA MINING PRACTICA	38	77	78	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1063-6560		EVOL COMPUT	Evol. Comput.	FAL	2003	11	3					209	238		10.1162/106365603322365289		30	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	717PV	WOS:000185099300002	
J	Kohonen, T; Somervuo, P				Kohonen, T; Somervuo, P			How to make large self-organizing maps for nonvectorial data	NEURAL NETWORKS			English	Article						batch map; clustering; data mining; database organization; generalized median; protein sequence; self-organizing map; visualization	PROTEIN SEQUENCES; TOOL	The self-organizing map (SOM) represents an open set of input samples by a topologically organized, finite set of models. In this paper, a new version of the SOM is used for the clustering, organization, and visualization of a large database of symbol sequences (viz. protein sequences). This method combines two principles: the batch computing version of the SOM, and computation of the generalized median of symbol strings. (C) 2002 Elsevier Science Ltd. All rights reserved.	Helsinki Univ Technol, Neural Networks Res Ctr, FIN-02015 Espoo, Finland	Kohonen, T (reprint author), Helsinki Univ Technol, Neural Networks Res Ctr, POB 5400, FIN-02015 Espoo, Finland.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Andrade MA, 1997, BIOL CYBERN, V76, P441, DOI 10.1007/s004220050357; Bairoch A, 1999, NUCLEIC ACIDS RES, V27, P49, DOI 10.1093/nar/27.1.49; Cheng YZ, 1997, NEURAL COMPUT, V9, P1667, DOI 10.1162/neco.1997.9.8.1667; Cottrell M., 1997, P WSOM 97 WORKSH SEL, P246; FERRAN EA, 1991, BIOL CYBERN, V65, P451, DOI 10.1007/BF00204658; FERRAN EA, 1994, PROTEIN SCI, V3, P507; Hanke J, 1996, COMPUT APPL BIOSCI, V12, P447; Hofmann K, 1999, NUCLEIC ACIDS RES, V27, P215, DOI 10.1093/nar/27.1.215; Kaski S., 1996, P ICANN 96, P809; Kiviluoto K., 1996, P IEEE INT C NEUR NE, V1, P294, DOI 10.1109/ICNN.1996.548907; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1985, PATTERN RECOGN LETT, V3, P309, DOI 10.1016/0167-8655(85)90061-3; Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105; Kohonen T., 1996, A42 HELS U TECHN LAB; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T, 2001, SELF ORG MAPS; KRAAIJVELD MA, 1995, IEEE T NEURAL NETWOR, V6, P548, DOI 10.1109/72.377962; Kraaijveld M. A., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems, DOI 10.1109/ICPR.1992.201718; Kruskal JB, 1978, MULTIDIMENSIONAL SCA; PEARSON W, 1999, FASTA PROGRAM PACKAG; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; SMITH T, 1981, ADV APPL MATH, V2, P483; SOMERVUO P, 2000, P 3 INT C DISC SCI, P76; Ultsch A., 1989, 329 U DORTM; VILLMANN T, 1994, P IEEE INT C NEUR NE, P645; ZREHEN S, 1993, P INT C ART NEUR NET, P609	27	77	85	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	OCT-NOV	2002	15	8-9					945	952		10.1016/S0893-6080(02)00069-2		8	Computer Science, Artificial Intelligence	Computer Science	606VY	WOS:000178756400002	
J	Duch, W; Adamczak, R; Grabczewski, K				Duch, W; Adamczak, R; Grabczewski, K			A new methodology of extraction, optimization and application of crisp and fuzzy logical rules	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						backpropagation; data mining; decision trees; feature selection; fuzzy systems; logical rule-based systems; neural networks	ARTIFICIAL NEURAL NETWORKS; SYSTEMS	A new methodology of extraction, optimization, and application of sets of logical rules is described. Neural networks are used for initial rule extraction, local, or global minimization procedures for optimization, and Gaussian uncertainties of measurements are assumed during application of logical rules, Algorithms for extraction of logical rules from data with real-valued features require determination of linguistic variables or membership functions, Context-dependent membership functions for crisp and fuzzy linguistic variables are introduced and methods of their determination described, Several neural and machine learning methods of logical rule extraction generating initial rules are described, based on constrained multilayer perceptron, networks with localized transfer functions or on separability criteria for determination of linguistic variables. A tradeoff between accuracy/simplicity is explored at the rule extraction stage and between rejection/error level at the optimization stage: Gaussian uncertainties of measurements are assumed during application of crisp logical rules, leading to "soft trapezoidal" membership functions and allowing to optimize the linguistic variables using gradient procedures. Numerous applications of this methodology to benchmark and real-life problems are reported and very simple crisp logical rules for many datasets provided.	Nicholas Copernicus Univ, Dept Comp Methods, PL-87100 Torun, Poland	Duch, W (reprint author), Nicholas Copernicus Univ, Dept Comp Methods, Grudziadzka 5, PL-87100 Torun, Poland.		Duch, Wlodzislaw/A-2002-2011				ALEXANDER JA, 1995, ADV NEURAL INFORMATI, V7; ANDREWS R, 1996, RULES NETWORKS P RUL; Andrews R., 1994, P 5 AUSTR C NEUR NET, P9; Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; ANDREWS R, 1997, INT C NEUR INF PROC, V2, P847; Bennett K.P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; BISHOP CM, 1995, NEURLA NETWORKS PATT; BREIMAN L, 1998, NEURAL NETWORKS MACH; BROWNE C, 1998, ROUGH SETS KNOWLEDGE, V2, P345; Butcher JN, 1996, ANNU REV PSYCHOL, V47, P87, DOI 10.1146/annurev.psych.47.1.87; Cestnik G., 1987, PROGR MACHINE LEARNI, P31; Craven M. W., 1994, P 11 INT C MACH LEAR, P37; CRAVEN MW, 1996, ADV NEURAL INFORMATI, V8; DUCH W, 1997, 3 C NEUR NETW KUL PO, P65; DUCH W, 1998, INTELLIGENT INFORMAT, V7, P85; DUCH W, 1997, P EUR S ART NEUR NET, P109; DUCH W, 1997, P 3 C NEUR NETW KUL, P99; DUCH W, IN PRESS INT J ADV C; DUCH W, 1999, COMPUTATIONAL INTELL, V23; DUCH W, 1997, INT C NEUR INF PROC, V2, P831; DUCH W, 1996, P C AI LODZ POL, P163; DUCH W, 1994, NEURAL NETWORK WORLD, V4, P645; DUCH W, 1998, NEURAL PROCESS LETT, V7, P1; DUCH W, 1999, IN PRESS P INT JOINT; DUCH W, 1999, P 4 C NEUR NETW THEI, P65; DUCH W, 1995, COMPUT PHYS COMMUN, V87, P341, DOI 10.1016/0010-4655(95)00023-9; DUCH W, 1997, INT C ART NEUR NETW, P2384; Duch W., 1997, Applied Mathematics and Computer Science, V7; DUCH W, 1999, INT C NEUR INF PROC, V2, P616, DOI 10.1109/ICONIP.1999.845665; DUCH W, 1996, P 2 C NEUR NETW APPL, V1, P131; DUCH W, 1996, P 1 ONL WORKSH SOFT, P25; Fu L, 1994, NEURAL NETWORKS COMP; FU LM, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P590; FU LM, 1994, IEEE T SYST MAN CYB, V24, P1114; FU LM, 1993, IEEE T SYST MAN CYB, V23, P173, DOI 10.1109/21.214775; Gallant S. I., 1993, NEURAL NETWORK LEARN; GECZY P, 1997, ICONIP 97, V2, P835; Grabczewski K., 1999, P 4 C NEUR NETW THEI, P203; GRZYMALABUSSE JW, 1998, INTELL INFORM SYST, V7, P371; HALGAMUGE SK, 1994, FUZZY SET SYST, V65, P1, DOI 10.1016/0165-0114(94)90242-9; HAYASHI Y, 1991, ADV NEURAL INFORMATI, V3; HAYASHI Y, 1990, P 8 INT C CYB SYST N, P54; HAYWARD R, 1996, RULENEG EXTRACTING R; Healy MJ, 1997, IEEE T NEURAL NETWOR, V8, P461, DOI 10.1109/72.572088; ISHIBUCCHI H, 1996, P 4 INT C SOFT COMP, V2, P822; ISHIKAWA M, 1996, P 1996 IEEE ICNN WAS, P1139; JAGIELSKA I, 1996, P 4 INT C SOFT COMP, V2, P565; JANG JSR, 1993, IEEE T NEURAL NETWOR, V4, P156, DOI 10.1109/72.182710; Jankowski N., 1997, P 7 INT C ART NEUR N, P385; KANAL L, 1988, SEARCH ARTIFICIAL IN; Kasabov N., 1998, PROF 4 INT C NEUR NE, P403; Kasabov N.K., 1996, FDN NEURAL NETWORKS; KASABOV NK, 1996, P IIZUKA 96, P74; Kosko B., 1992, NEURAL NETWORKS FUZZ; LOZOWSKI A, 1996, P INT C NEUR NETW VO, P94; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MAHONEY JJ, 1993, ADV NEURAL INFORM PR, V5, P107; MCMILLAN C, 1992, ADV NEURAL PROCESSIN, V4; MERTZ CJ, UCI REPOSITORY MACHI; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Mitchell T. M, 1997, MACHINE LEARNING; Mitra S, 1997, IEEE T NEURAL NETWOR, V8, P1338, DOI 10.1109/72.641457; Nauck D., 1996, FUZZY MODELLING PARA, P203; NAUCK D, 1997, FDN NEUROFUZZY SYST; NAUCK D, 1996, P BIENN C N AM FUZZ; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pop E., 1994, RULENEG EXTRACTING R; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Saito K., 1988, P IEEE INT C NEURAL, V1, P255; Schalkoff R, 1992, PATTERN RECOGNITION; Schiffmann W., 1993, P EUR S ART NEUR NET, P97; SESITO S, 1994, AUTOMATED KNOWLEDGE; SETHI IK, 1994, PATTERN RECOGNITION, V4; Setiono R, 1995, P 14 INT JOINT C ART, P480; SHANG N, 1996, INT C NEUR INF PROC, V1, P133; Ster B., 1996, P INT C ENG APPL NEU, P427; TAN AH, 1994, PROCEEDINGS OF THE 1993 CONNECTIONIST MODELS SUMMER SCHOOL, P192; TAN M, 1988, P 5 INT C MACH LEARN, P121; Taylor C.C., 1994, MACHINE LEARNING NEU; TEGHEM J, 1992, INTELLIGENT DECISION, V11, P267; THRUN S, 1995, ADV NEURAL INFORMATI, V7; Thrun S. B., 1991, CMUCS91197; Tickle A. B., 1994, DEDEC DECISION DETEC; Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1007/BF00993103; TRESP V, 1992, ADV NEURAL INFORMATI, V4; ULTSCH A, 1993, INFORMATION CLASSIFI, P301; WEISS S, 1990, COMPUTER SYSTEMS LEA; WEISS SM, 1990, READING MACHINE LEAR; ZURADA J M, 1992, INTRO ARTIFICIAL NEU; ZURADA JM, 1996, P 4 INT C SOFT COMP, V2, P618	94	77	79	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAR	2001	12	2					277	306		10.1109/72.914524		30	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	418JG	WOS:000167886700008	
J	Aronson, AR				Aronson, AR			Effective mapping of biomedical text to the UMLS metathesaurus: The MetaMap Program	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Proceedings Paper	Annual Symposium of the American-Medical-Informatics-Association (AMIA 2001)	NOV 03-07, 2001	WASHINGTON, D.C.	Amer Med Informat Assoc			MEDLINE; DOCUMENTS	The UMLS(R) Metathesaurus(R), the largest thesaurus in the biomedical domain, provides a representation of biomedical knowledge consisting of concepts classified by semantic type and both hierarchical and non-hierarchical relationships among the concepts. This knowledge has proved useful for many applications including decision support systems, management of patient records, information retrieval (IR) and data mining. Gaining effective access to the knowledge is critical to the success of these applications. This paper describes MetaMap, a program developed at the National Library of Medicine (NLM) to map biomedical text to the Metathesaurus or, equivalently, to discover Metathesaurus concepts referred to in text. MetaMap uses a knowledge intensive approach based on symbolic, natural language processing (NLP) and computational linguistic techniques. Besides being applied for both IR and data mining applications, MetaMap is one of the foundations of NLM's Indexing Initiative System which is being applied to both semiautomatic and fully automatic indexing of the biomedical literature at the library.	Natl Lib Med, Bethesda, MD 20894 USA	Aronson, AR (reprint author), Natl Lib Med, Bethesda, MD 20894 USA.						Aronson A. R., 1994, P RIAO 94, P197; Aronson A R, 1997, Proc AMIA Annu Fall Symp, P485; Aronson A R, 2000, Proc AMIA Symp, P17; Aronson A R, 1996, Proc AMIA Annu Fall Symp, P373; CALLAN J, 1992, P INT C DAT EXP SYST, P347; Cutting D., 1992, P 3 C APPL NAT LANG; Elkin P. L., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1); EVANS DA, 1991, P RIAO 91, V91, P624; HERSH WR, 1994, J AM MED INFORM ASSN, V1, P51; Hersh W, 1995, Proc Annu Symp Comput Appl Med Care, P858; Humphrey SM, 1999, J AM SOC INFORM SCI, V50, P661, DOI 10.1002/(SICI)1097-4571(1999)50:8<661::AID-ASI4>3.0.CO;2-R; HUMPHREY SM, 2000, IN PRESS P 11 ASIST; McCray A T, 1994, Proc Annu Symp Comput Appl Med Care, P235; Miller R A, 1992, Proc Annu Symp Comput Appl Med Care, P86; Nadkarni P, 2001, J AM MED INFORM ASSN, V8, P80; Pratt W, 2000, Proc AMIA Symp, P655; Rindflesch T C, 1993, Proc Annu Symp Comput Appl Med Care, P611; Rindflesch T C, 2000, Pac Symp Biocomput, P517; Rindflesch T C, 2000, Proc AMIA Symp, P704; Rindflesch T C, 1994, Proc Annu Symp Comput Appl Med Care, P240; Rindflesch T C, 1999, Proc AMIA Symp, P127; Salton G, 1971, SMART RETRIEVAL SYST; Sneiderman C A, 1998, Proc AMIA Symp, P428; Sneiderman C A, 1996, Proc AMIA Annu Fall Symp, P239; Srinivasan P, 1996, J AM MED INFORM ASSN, V3, P157; Srinivasan P, 1996, INFORM PROCESS MANAG, V32, P431, DOI 10.1016/0306-4573(95)00076-3; Tuttle MS, 1998, METHOD INFORM MED, V37, P373; Weeber M, 2000, Proc AMIA Symp, P903; Wilbur W J, 1999, Proc AMIA Symp, P176; Wright LW, 1999, J AM SOC INFORM SCI, V50, P514, DOI 10.1002/(SICI)1097-4571(1999)50:6<514::AID-ASI6>3.3.CO;2-H; *NLM, 2000, UMLS KNOWL SOURC	31	77	77	HANLEY & BELFUS INC	PHILADELPHIA	210 S 13TH ST, PHILADELPHIA, PA 19107 USA	1067-5027		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.		2001				S			17	21				5	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	494CZ	WOS:000172263400005	
J	Lee, WK; Stolfo, SJ; Mok, KW				Lee, WK; Stolfo, SJ; Mok, KW			Adaptive intrusion detection: A data mining approach	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						association rules; audit data; classification; feature construction; frequent episodes; intrusion detection	UNIX	Tn this paper we describe a data mining framework for constructing intrusion detection models. The first key idea is to mine system audit data for consistent: and useful patterns of program and user behavior The other is to use the set of relevant system features presented in the patterns to compute inductively learned classifiers that can recognize anomalies and known intrusions. In order for the classifiers to be effective intrusion detection models, we need to have sufficient audit data for training and also select a set of predictive system features. We propose to use the association rules and frequent episodes computed from audit data as the basis for guiding the audit data gathering and feature selection processes. We modify these two basic algorithms to use axis attribute(s) and reference attribute(s) as forms of item constraints to compute only the relevant patterns. In addition, we use an iterative level-wise approximate mining procedure to uncover the low frequency but important patterns. We use meta-learning as a mechanism to make intrusion detection models more effective and adaptive. We report our extensive experiments in using our framework on real-world audit data.	N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; Morgan Stanley Dean Witter & Co, New York, NY 10019 USA	Lee, WK (reprint author), N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1995, P 11 INT C DAT ENG T; Agrawal R., 1994, P 20 VLDB C SANT CHI; Bellovin S. M., 1989, Computer Communication Review, V19; Chan P., 1993, AAAI WORKSH KNOWL DI, V227-240; COHEN WW, 1995, MACH LEARNING; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675; GRAMPP FT, 1984, AT&T TECH J, V63, P1649; HAN J, 1995, P 21 VLDB C ZUR SWIT; Heady R., 1990, ARCHITECTURE NETWORK; ILGUN K, 1995, IEEE T SOFTWARE ENG, V21, P181, DOI 10.1109/32.372146; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Kumar S., 1995, P 18 NAT INF SEC C, P194; Lane TM, 1997, MAIN GROUP CHEM, V2, P43, DOI 10.1080/13583149712331338869; LEE W, 1999, P ACM SIGKDD INT C K; Lee W., 1998, P 4 INT C KNOWL DISC; Lee Wenke, 1998, P 7 USENIX SEC S SAN; LENT B, 1997, P 13 INT C DAT ENG B; Lunt T, 1993, P 1993 C AUD COMP TE; Lunt T. F, 1992, REAL TIME INTRUSION; Mannila H., 1995, P 1 INT C KNOWL DISC; MANNILA H, 1996, P 2 INT C KNOWL DISC; MCCLURE S, 1998, INFOWORLD       0504; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Stolfo S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Utgoff PE, 1997, MACH LEARN, V29, P5, DOI 10.1023/A:1007413323501	27	77	88	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	DEC	2000	14	6					533	567		10.1023/A:1006624031083		35	Computer Science, Artificial Intelligence	Computer Science	417GX	WOS:000167828000005	
J	Bui, T; Lee, J				Bui, T; Lee, J			An agent-based framework for building decision support systems	DECISION SUPPORT SYSTEMS			English	Article						decision support systems; system analysis and design; software agents; organizational computing		This paper proposes a framework for building decision support systems using software agent technology to support organizations characterized by physically distributed, enterprise-wide, heterogeneous information systems. Intelligent agents have offered tremendous potential in supporting well-defined tasks such as information filtering, data mining and data conversion. However, the use of intelligent agents to support decisions has not been explored and merits serious consideration. This paper proposes a taxonomy of agent characteristics that can be used to help identify agents to support different types of decision tasks. We advocate a goal-directed, behavior-based architecture for building cooperative decision support using agents. We look at the development of agent-based DSS as being a process of putting together a coordinated workflow of collaborating agents that is able to support a problem-solving process. The methodology is illustrated by a selection of intelligent agents to support Crisis Action Procedures in a large organization. (C) 1999 Elsevier Science B.V. All rights reserved.	Univ Hawaii Manoa, Honolulu, HI 96822 USA	Bui, T (reprint author), Univ Hawaii Manoa, E303,2404 Maile Way, Honolulu, HI 96822 USA.						BHARGAVA HK, 1997, DECISION SUPPORT DEM; BIRD SD, 1993, INT J MAN MACH STUD, V39, P689, DOI 10.1006/imms.1993.1079; BOEHM BW, 1976, IEEE T COMPUT, V25, P1226; Boehm B. W., 1988, IEEE COMPUT, V<IT>21</IT>, P61; Bond A., 1988, READINGS DISTRIBUTED; Bussler C., 1994, Proceedings Fourth International Workshop on Research Issues in Data Engineering. Active Database Systems (Cat. No.94TH0618-9), DOI 10.1109/RIDE.1994.282853; CARROLL JM, 1995, ENVISIONING WORK TEC; CHAIBDRAA B, 1992, SIGART B, V3; DURFEE EH, 1987, IEEE T COMPUT, V36, P1275; EDMISTON MR, 1998, DECISION SUPPORT REC; ETZIONI O, 1996, IEEE EXPERT INTE AUG; GASSER L, 1988, P 1 SCAND C ART INT; GUHA RV, 1994, COMMUN ACM, V37, P127; JEUSFELD M, 1997, DECISION SUPPORT SYS, V19; KALAOKA R, 1996, FRONTIERS ELECT COMM; KAUTZ H, 1992, COMMUNICATIONS ACM, V37; MALONE TW, 1994, ACM COMPUT SURV, V26, P87, DOI 10.1145/174666.174668; NORMAN TJ, 1994, P 1994 WORKSH AG THE; OLeary DE, 1996, IEEE EXPERT, V11, P8, DOI 10.1109/64.491309; ORTONY A, 1988, COGNITIVE EMOTIONS; Poggi A., 1996, Proceedings of the Twenty-Ninth Hawaii International Conference on System Sciences, DOI 10.1109/HICSS.1996.495473; ROSENSCHEIN JS, 1987, P 6 PHOEN C COMP COM; Sprague R. H., 1982, BUILDING EFFECTIVE D; Winograd Terry, 1986, UNDERSTANDING COMPUT; WOELK D, 1993, 2 INT C PAR DISTR IN, P133; WOELK D, 1996, DEV INFOSLEUTH AGENT; ZENG D, 1995, CMURITR9514; *IBM, 1997, IBM AG BUILD ENV DEV	28	77	95	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	APR	1999	25	3					225	237		10.1016/S0167-9236(99)00008-1		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	189FR	WOS:000079894300005	
J	MANNILA, H; RAIHA, KJ				MANNILA, H; RAIHA, KJ			ALGORITHMS FOR INFERRING FUNCTIONAL-DEPENDENCIES FROM RELATIONS	DATA & KNOWLEDGE ENGINEERING			English	Article						FUNCTIONAL DEPENDENCIES; MACHINE DISCOVERY; DATA MINING; ALGORITHMS	ARMSTRONG RELATIONS; DESIGN	The dependency inference problem is to find a cover of the set of functional dependencies that hold in a given relation. The problem has applications in relational database design, in query optimization, and in artificial intelligence. The problem is exponential in the number of attributes. We develop two algorithms with better best case behavior than the simple one. One algorithm reduces the problem to computing the transversal of a hypergraph. The other is based on repeatedly sorting the relation with respect to a set of attributes.	UNIV TAMPERE,DEPT COMP SCI,SF-33101 TAMPERE,FINLAND	MANNILA, H (reprint author), UNIV HELSINKI,DEPT COMP SCI,POB 26,SF-90014 HELSINKI,FINLAND.						ALMUALLIM H, 1991, 9 NAT C ART INT, P547; Armstrong W. W., 1974, INFORMATION PROCESSI, P580; BEERI C, 1984, J ACM, V31, P30, DOI 10.1145/2422.322414; Berge C., 1989, HYPERGRAPHS COMBINAT; BITTON D, 1989, 5TH P INT C DAT ENG; BORGIDA A, 1986, KNOWLEDGE BASE MANAG, P259; BORGIDA A, 1985, 11 INT C VER LARG DA, P72; BOUZEGHOUB M, 1985, 11TH P INT VLDB C ST, P82; CASANOVA MA, 1984, IBM J RES DEV, V28, P82; CASANOVA MA, 1984, J COMPUT SYST SCI, V28, P29, DOI 10.1016/0022-0000(84)90075-8; DECHTER R, 1990, J COMPUT SYST SCI, V41, P2, DOI 10.1016/0022-0000(90)90031-F; DELGRANDE JP, 1987, 6TH P ACM SIGACT SIG, P109; DEMETROVICS J, 1981, ACTA CYBERN, V5, P295; Demetrovics J., 1988, Acta Cybernetica, V8; Demetrovics J., 1988, Acta Cybernetica, V8; EITER T, 1991, CDTR9116 TU TECHN RE; FAGIN R, 1982, RJ3440 IBM RES REP; JOHNSON DS, 1988, INFORM PROCESS LETT, V27, P119, DOI 10.1016/0020-0190(88)90065-8; KANTOLA M, 1991, UNPUB DESIGN EXAMPLE; KIVINEN J, 1992, LECT NOTES COMPUT SC, V646, P86; Maier D., 1983, THEORY RELATIONAL DA; MANNILA H, 1986, J COMPUT SYST SCI, V33, P126, DOI 10.1016/0022-0000(86)90015-2; MANNILA H, 1992, DISCRETE APPL MATH, V40, P237, DOI 10.1016/0166-218X(92)90031-5; MANNILA H, 1987, 13TH P INT C VER LAR, P155; MANNILA H, 1987, C198748 U HELS DEP C; Mannila H., 1992, DESIGN RELATIONAL DA; Michalski R. S., 1986, MACHINE LEARNING, V2; Michalski R. S., 1983, MACHINE LEARNING; RUSSELL SJ, 1989, USE KNOWLEDGE ANALOG; SCHLIMMER JC, 1991, 1991 P AAAI WORKSH K, P64; SIEGEL M, 1986, BUCS86013 BOST U COM; SILVA AM, 1981, ADV DATA BASE THEORY, P115; THI VD, 1986, ACTA CYBERNET, V7, P361; Tsukiyama S., 1977, SIAM Journal on Computing, V6, DOI 10.1137/0206036; ULLMAN JD, 1989, PRINCIPLES DATABASE, V2	35	77	80	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	FEB	1994	12	1					83	99		10.1016/0169-023X(94)90023-X		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	PT690	WOS:A1994PT69000004	
J	Kriegel, HP; Kroger, P; Zimek, A				Kriegel, Hans-Peter; Kroeger, Peer; Zimek, Arthur			Clustering High-Dimensional Data: A Survey on Subspace Clustering, Pattern-Based Clustering, and Correlation Clustering	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Survey; clustering; high-dimensional data		As a prolific research area in data mining, subspace clustering and related problems induced a vast quantity of proposed solutions. However, many publications compare a new proposition-if at all-with one or two competitors, or even with a so-called "naive" ad hoc solution, but fail to clarify the exact problem definition. As a consequence, even if two solutions are thoroughly compared experimentally, it will often remain unclear whether both solutions tackle the same problem or, if they do, whether they agree in certain tacit assumptions and how such assumptions may influence the outcome of an algorithm. In this survey, we try to clarify: (i) the different problem definitions related to subspace clustering in general; (ii) the specific difficulties encountered in this field of research; (iii) the varying assumptions, heuristics, and intuitions forming the basis of different approaches; and (iv) how several prominent solutions tackle different problems.	[Kriegel, Hans-Peter; Kroeger, Peer; Zimek, Arthur] Univ Munich, Inst Informat, D-80538 Munich, Germany	Kriegel, HP (reprint author), Univ Munich, Inst Informat, Oettingenstr 67, D-80538 Munich, Germany.	kriegel@dbs.ifi.lmu.de; kroegerp@dbs.ifi.lmu.de; zimek@dbs.ifi.lmu.de					ACHTERT E, 2006, P 18 INT C SCI STAT; Achtert E., 2007, P 7 SIAM INT C DAT M; Achtert E, 2007, P 19 INT C SCI STAT; Achtert E, 2007, P 12 INT C DAT SYST; Achtert E, 2006, P 12 ACM INT C KNOWL; Achtert E, 2008, P 8 SIAM INT C DAT M; Achtert Elke, 2008, P 20 INT C SCI STAT; Aggarwal C., 1999, P ACM INT C MAN DAT; Aggarwal CC, 2001, P 8 INT C DAT THEOR; Aggarwal CC, 2000, P ACM INT C MAN DAT; Agrawal R, 1994, P ACM INT C MAN DAT; Agrawal R, 1998, P ACM INT C MAN DAT; Ankerst M, 1999, P ACM INT C MAN DAT; Assent I., 2007, ACM SIGKDD EXPLORATI, V9, P5, DOI 10.1145/1345448.1345451; ASSENT I, 2007, P 7 INT C DAT MIN IC; Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95; BARBARA D, 2000, P 6 ACM INT C KNOWL; Bellman R., 1961, ADAPTIVE CONTROL PRO; BELUSSI A, 1995, P 21 INT C VER LARG; BENDOR A, 2002, P 6 ANN INT C COMP M; BERCHTOLD S, 2000, P 16 INT C DAT ENG I; BERCHTOLD S, 1998, P ACM INT C MAN DAT; BERCHTOLD S, 1998, P 14 INT C DAT ENG I; BERCHTOLD S, 1996, P 22 INT C VER LARG; Beyer K, 1999, P 7 INT C DAT THEOR; Bishop C. M., 2006, PATTERN RECOGNITION; BOHM C, 2000, P 16 INT C DAT ENG I; BOHM C, 2004, P 4 INT C DAT MIN IC; BOHM C, 2000, P 7 INT C EXT DAT TE; Bohm Ch., 2004, P ACM INT C MAN DAT; Bouveyron C, 2007, COMPUT STAT DATA AN, V52, P502, DOI 10.1016/j.csda.2007.02.009; CALIFANO A, 2000, P 8 INT C INT SYST M; Chakrabarti K, 2000, P 26 INT C VER LARG; Cheng C. H., 1999, P 5 ACM SIGKDD INT C, P84, DOI 10.1145/312129.312199; CHENG H, 2008, P 34 INT C VER LARG; Cheng Y, 2000, P 8 INT C INT SYST M; Cho H., 2004, P 4 SIAM INT C DAT M; DESOUSA PM, 2002, P KDD WORKSH FRACT S; DHILLON IS, 2001, P 7 ACM INT C KNOWL; Domeniconi C, 2004, P 4 SIAM INT C DAT M; Duda R.O., 2001, PATTERN CLASSIFICATI; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Ester M, 1996, P 2 ACM INT C KNOWL; FALOUTSOS C, 1994, P ACM INT C MAN DAT; Faloutsos C, 2007, DATA MIN KNOWL DISC, V15, P3, DOI 10.1007/s10618-006-0057-3; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Friedman JH, 2004, J R STAT SOC B, V66, P825; Ganter B., 1999, FORMAL CONCEPT ANAL; Garey M.R., 1979, COMPUTER INTRACTABIL; GEORGII E, 2005, BIOINFORMATICS, V21, P1; Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797; GIONIS A, 2005, P 11 ACM INT C KNOWL; Han J., 2001, DATA MINING CONCEPTS; Han J, 2006, DATA MINING CONCEPTS; Hand D. J., 2001, PRINCIPLES DATA MINI; Haralick R, 2005, P 4 INT C MACH LEARN; Harpaz R, 2007, P IEEE S COMP INT DA; HARPAZ R, 2007, THESIS CITY U NEW YO; HARPAZ R, 2007, INT J INF TECHNOL IN, V2, P2; HARTIGAN JA, 1972, J AM STAT ASSOC, V67, P123, DOI 10.2307/2284710; Hastie T., 2001, ELEMENTS STAT LEARNI; Hinneburg A., 2000, P 26 INT C VER LARG; Hough PVC, 1962, US patent, Patent No. [3,069,654, 3069654]; Huang JZX, 2005, IEEE T PATTERN ANAL, V27, P657, DOI 10.1109/TPAMI.2005.95; Ihmels J, 2004, BIOINFORMATICS, V20, P1993, DOI 10.1093/bioinformatics/bth166; Jain A. K., 1999, ACM COMPUT SURV; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; Jing L, 2007, IEEE T KNOWL DATA EN, V19, P1026, DOI 10.1109/TKDE.2007.1048; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kailing K, 2004, P 4 SIAM INT C DAT M; KATAYAMA N, 1997, P ACM INT C MAN DAT; KETTENRING JR, 2008, STAT ANAL DATA MININ, V1, P52, DOI 10.1002/sam.10001; Korn F, 2001, IEEE T KNOWL DATA EN, V13, P96, DOI 10.1109/69.908983; Kriegel H.-P., 2005, P 5 INT C DAT MIN IC; Kriegel H.-P., 2008, P 20 INT C SCI STAT; KRIEGEL HP, 2007, 7 INT C DAT MIN ICDM; Li J, 2007, P 11 PAC AS C KNOWL; LIN K, 1995, VLDB J, V3, P517; Liu B, 2000, P 9 INT C INF KNOWL; LIU G, 2007, P 23 INT C DAT ENG I; LIU J, 2003, P 3 INT C DAT MIN IC; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; Mirkin B, 1996, MATH CLASSIFICATION; Mitchell TM, 1997, MACH LEARN; Moise G, 2008, P 14 ACM INT C KNOWL; MOISE G, 2006, P 6 INT C DAT MIN IC; Moise G, 2008, KNOWL INF SYST, V14, P273, DOI 10.1007/s10115-007-0090-6; MURALI TM, 2003, P 8 PAC S BIOC PSB; Nagesh H, 2001, P 1 SIAM INT C DAT M; PAGEL BU, 2000, P 16 INT C DAT ENG I; Parsons L, 2004, ACM SIGKDD EXPLORATI, V6, P90, DOI 10.1145/1007730.1007731; PEI J, 2003, P 3 INT C DAT MIN IC; PFALTZ J, 2007, P 19 INT C SCI STAT; Prelic A, 2006, BIOINFORMATICS, V22, P1122, DOI 10.1093/bioinformatics/btl060; Procopiuc CM, 2002, P ACM INT C MAN DAT; RUCKERT U, 2004, P 4 IEEE INT C DAT M, P507; Segal E, 2001, Bioinformatics, V17 Suppl 1, pS243; Sequeira K., 2005, International Journal of Business Intelligence and Data Mining, V1, DOI 10.1504/IJBIDM.2005.008360; Sheng Q., 2003, BIOINFORMATICS S2, V19, pii196; SIM K, 2006, P 6 INT C DAT MIN IC; Slagle J., 1975, IEEE T SYST MAN CYB, V5, P121; Tan P-N, 2006, INTRO DATA MINING; Tanay Amos, 2002, Bioinformatics, V18 Suppl 1, pS136; Tanay A., 2006, HDB COMPUTATIONAL MO; TUNG AKH, 2005, P ACM INT C MAN DAT; Van Mechelen I, 2004, STAT METHODS MED RES, V13, P363, DOI 10.1191/0962280204sm373ra; WANG H, 2002, P ACM INT C MAN DAT; Webb G. I., 2001, P 7 ACM SIGKDD INT C, P383, DOI 10.1145/502512.502569; Weber R., 1998, P 24 INT C VER LARG; Witten IH, 2005, DATA MINING PRACTICA; Woo KG, 2004, INFORM SOFTWARE TECH, V46, P255, DOI 10.1016/j.infsof.2003.07.003; YANG J, 2002, P 18 INT C DAT ENG I; Yip KY, 2004, IEEE T KNOWL DATA EN, V16, P1387, DOI 10.1109/TKDE.2004.74; Yip K.Y., 2005, P 21 INT C DAT ENG I; YIU ML, 2003, P 3 INT C DAT MIN IC; Yiu ML, 2005, IEEE T KNOWL DATA EN, V17, P176	116	76	80	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1556-4681		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	MAR	2009	3	1								10.1145/1497577.1497578		58	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	V20VN	WOS:000208167600001	
S	Koperski, K; Han, JW		Egenhofer, MJ; Herring, JR		Koperski, K; Han, JW			Discovery of spatial association rules in geographic information databases	ADVANCES IN SPATIAL DATABASES	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th International Symposium on Large Spatial Databases (SSD 95)	AUG 06-09, 1995	PORTLAND, ME	ACM SIGMOD, Environm Syst Res Inst Inc, Lockheed Martin, Management & Data Syst, Natl Ctr Geog Informat & Anal, Oracle Corp				Spatial data mining, i.e., discovery of interesting, implicit knowledge in spatial databases, is an important task for understanding and use of spatial data- and knowledge-bases. In this paper, an efficient method for mining strong spatial association rules in geographic information databases is proposed and studied. A spatial association rule is a rule indicating certain association relationship among a set of spatial and possibly some nonspatial predicates. A strong rule indicates that the patterns in the rule have relatively frequent occurrences in the database and strong implication relationships. Several optimization techniques are explored, including a two-step spatial computation technique (approximate computation on large sets, and refined computations on small promising patterns), shared processing in the derivation of large predicates at multiple concept levels, etc. Our analysis shows that interesting association rules can be discovered efficiently in large spatial databases.		Koperski, K (reprint author), SIMON FRASER UNIV,SCH COMP SCI,BURNABY,BC V5A 1S6,CANADA.						Agrawal R., 1993, 1993 ACM SIGMOD INT, P207; AGRAWAL R, 1994, 1994 P INT C VLDB SA, P487; AREF WG, 1991, 17TH P INT C VLDB BA, P81; BRINKHOFF T, 1993, 1993 P ACM SIGMOD C, P237; BRINKHOFF T, 1994, 1994 P ACM SIGMOD C, P197; EGENHOFER MJ, 1994, IEEE T KNOWL DATA EN, V6, P86, DOI 10.1109/69.273029; Egenhofer M. J., 1991, Advances in Spatial Databases. 2nd Symposium, SSD '91 Proceedings; FAYYAD U, 1993 P KNOWL DISC DA, P14; Fayyad U.M., 1995, ADV KNOWLEDGE DISCOV; Fotheringham S., 1994, SPATIAL ANAL GIS; Guttman A., 1984, P ACM SIGMOD INT C M, P47; HAN J, 1995, 1995 P VLDB ZUR; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; LU W, 1993, JUN P FAR E WORKSH G, P275; NG R, 1994, 1994 P INT C VLDB SA, P144; PIATESKYSHAPIRO G, 1994 P WORKSH KNOWL, P25; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Preparata FP, 1985, COMPUTATIONAL GEOMET; Samet H., 1990, DESIGN ANAL SPATIAL	19	76	85	SPRINGER-VERLAG BERLIN	BERLIN 33	HEIDELBERGER PLATZ 3, W-1000 BERLIN 33, GERMANY	0302-9743	3-540-60159-7	LECT NOTES COMPUT SC			1995	951						47	66				20	Computer Science, Information Systems	Computer Science	BE73J	WOS:A1995BE73J00004	
J	Lafon, S; Keller, Y; Coifman, RR				Lafon, Stephane; Keller, Yosi; Coifman, Ronald R.			Data fusion and multicue data matching by diffusion maps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern matching; graph theory; graph algorithms; Markov processes; machine learning; data mining; image databases	DIMENSIONALITY REDUCTION; GEOMETRIC DIFFUSIONS; STRUCTURE DEFINITION; HARMONIC-ANALYSIS; TOOL; EIGENMAPS	Data fusion and multicue data matching are fundamental tasks of high-dimensional data analysis. In this paper, we apply the recently introduced diffusion framework to address these tasks. Our contribution is three-fold: First, we present the Laplace-Beltrami approach for computing density invariant embeddings which are essential for integrating different sources of data. Second, we describe a refinement of the Nystrom extension algorithm called "geometric harmonics." We also explain how to use this tool for data assimilation. Finally, we introduce a multicue data matching scheme based on nonlinear spectral graphs alignment. The effectiveness of the presented schemes is validated by applying it to the problems of lipreading and image sequence alignment.	Google Inc, Mountain View, CA 94043 USA; Yale Univ, Dept Appl Math, New Haven, CT 06511 USA	Lafon, S (reprint author), Google Inc, 1600 Amphitheater Pkwy, Mountain View, CA 94043 USA.	stephane.lafon@gmail.com; yosi.keller@yale.edu; coifman-ronald@yale.edu					AHARON M, IN PRESS INT J COMPU; Bai X, 2004, INT C PATT RECOG, P398; BELKIN M, 2005, P 18 ANN C LEARN THE, P486; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M., 2001, ADV NEURAL INFORM PR, P585; Belkin M., 2004, TR200406 U CHIC; Bengio Y, 2003, 1238 U MONTR; BREGLER C, 1998, COMPUTER VISION MAN; BREGLER C, 1993, P IEEE INT C AC SPEE; CHRISTOPH B, 1997, P 24 ANN C COMP GRAP, P353; Chung F, 1997, SPECTRAL GRAPH THEOR; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7432, DOI 10.1073/pnas.0500896102; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P31, DOI 10.1016/j.acha.2005.07.005; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Cosatto E, 2000, IEEE T MULTIMEDIA, V2, P152, DOI 10.1109/6046.865480; DETTMER N, 1997, COMPUTATIONAL IMAGIN, P345; Diaconis P., 1991, ANN APPL PROBAB, V1, P36, DOI 10.1214/aoap/1177005980; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Fitzgibbon A. W., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937584; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Gori M, 2005, IEEE T PATTERN ANAL, V27, P1100, DOI 10.1109/TPAMI.2005.138; Groenen P., 1997, MODERN MULTIDIMENSIO; Ham J, 2005, P 10 INT WORKSH ART, P120; Keselman Y, 2003, PROC CVPR IEEE, P850; Kondor R, 2002, P 19 INT C MACH LEAR, P315; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; LAFON S, 2005, DEMO MASK ALIGNMENT; Luettin J, 1997, COMPUT VIS IMAGE UND, V65, P163, DOI 10.1006/cviu.1996.0570; LUETTIN J, 1996, NATO ASI SERIES F, V150, P383; Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900; Meila M., 2001, P INT WORKSH ART INT; Nadler B, 2006, APPL COMPUT HARMON A, V21, P113, DOI 10.1016/j.acha.2005.07.004; Nefian AV, 2002, EURASIP J APPL SIG P, V2002, P1274, DOI 10.1155/S1110865702206083; Press W. H., 1988, NUMERICAL RECIPES C; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; TIAN YL, 2000, P 4 AS C COMP VIS AC; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790354; Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604; Yu S. X., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Zhang Z.Y., 2002, CSE02019 PENN STAT U	42	75	77	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1784	1797		10.1109/TPAMI.2006.223		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	083GC	WOS:000240443400006	
J	Wu, G; Chang, EY				Wu, G; Chang, EY			KBA: Kernel boundary alignment considering imbalanced data distribution	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						imbalanced-data training; support vector machines; supervised classification		An imbalanced training data set can pose serious problems for many real-world data mining tasks that employ SVMs to conduct supervised learning. In this paper, we propose a kernel-boundary-alignment algorithm, which considers THE training data imbalance as prior information to augment SVMs to improve class-prediction accuracy. Using a simple example, we first show that SVMs can suffer from high incidences of false negatives when the training instances of the target class are heavily outnumbered by the training instances of a nontarget class. The remedy we propose is to adjust the class boundary by modifying the kernel matrix, according to the imbalanced data distribution. Through theoretical analysis backed by empirical study, we show that our kernel-boundary-alignment algorithm works effectively on several data sets.	Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA	Wu, G (reprint author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.	gwu@engineering.ucsb.edu; echang@ece.ucsb.edu					Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; C BURGES C J, 1999, ADV KERNEL METHODS S; Cardinal BJ, 1997, ADAPT PHYS ACT Q, V14, P65; Chan P., 1998, P WORKSH NOT KDD 98, P1; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Cristianini N., 2001, P NEUR INF PROC SYST, P367; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Drummond C., 2000, P 17 INT C MACH LEAR, P239; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Fukunaga K., 1990, INTRO STAT PATTERN R; Hastie T., 2001, ELEMENTS STAT LEARNI; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kandola J, 2003, P 9 INT WORKSH ART I; KARAKOULAS G, 1999, ADV NEURAL INFORMATI; Kubat M., 1997, P 14 INT C MACH LEAR, P179; KUHN HW, 1961, P 2 BERK S MATH STAT; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Nugroho AS, 2002, IEICE T INF SYST, VE85D, P1165; Scholkopf B., 2002, LEARNING KERNELS SUP; Tong S., 2001, P ACM INT C MULT, P107, DOI DOI 10.1145/560141.500159; Vapnik V.N., 1995, NATURE STAT LEARNING; Veropoulos K, 1999, P INT JOINT C ART IN, P55; Weiss G. M., 2004, SIGKDD EXPLORATIONS, V6, P7; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Wu G., 2003, P 20 INT C MACH LEAR, P816; WU G, 2003, P ACM INT C MULT NOV; Wu X., 2004, P 10 ACM SIGKDD INT; WU X, 2003, P 20 INT C MACH LEAR	30	75	85	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUN	2005	17	6					786	795		10.1109/TKDE.2005.95		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	917IC	WOS:000228453300006	
J	Cai, D; He, XF; Han, JW				Cai, Deng; He, Xiaofei; Han, Jiawei			SRDA: An efficient algorithm for large-scale discriminant analysis	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						linear discriminant analysis; spectral regression; dimensionality reduction.	SPARSE LINEAR-EQUATIONS; LEAST-SQUARES; LSQR	Linear Discriminant Analysis (LDA) has been a popular method for extracting features that preserves class separability. The projection functions of LDA are commonly obtained by maximizing the between-class covariance and simultaneously minimizing the within-class covariance. It has been widely used in many fields of information processing, such as machine learning, data mining, information retrieval, and pattern recognition. However, the computation of LDA involves dense matrices eigendecomposition, which can be computationally expensive in both time and memory. Specifically, LDA has O(mnt + t(3) )time complexity and requires O(mn + mt + nt) memory, where m is the number of samples, n is the number of features, and t = min(m,n). When both m and n are large, it is infeasible to apply LDA. In this paper, we propose a novel algorithm for discriminant analysis, called Spectral Regression Discriminant Analysis (SRDA). By using spectral graph analysis, SRDA casts discriminant analysis into a regression framework that facilitates both efficient computation and the use of regularization techniques. Specifically, SRDA only needs to solve a set of regularized least squares problems, and there is no eigenvector computation involved, which is a huge save of both time and memory. Our theoretical analysis shows that SRDA can be computed with O(ms) time and O(ms) memory, where s(<= n) n is the average number of nonzero features in each sample. Extensive experimental results on four real-world data sets demonstrate the effectiveness and efficiency of our algorithm.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Yahoo, Burbank, CA 91504 USA	He, XF (reprint author), Univ Illinois, Dept Comp Sci, Siebel Ctr, 201 N Goodwin Ave, Urbana, IL 61801 USA.	dengcai2@cs.uiuc.edu; hex@yahoo-inc.com; hanj@cs.uiuc.edu					Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cai D., 2007, P 11 INT C COMP VIS; CAI D, 2007, P ACM C MULT; Cai D., 2007, P INT C DAT MIN ICDM; CAI D, 2007, P 16 ACM INT C INF K; Chung Fan R.K., 1997, CBMS REG C SER MATH, V92; Duda R. O., 2000, PATTERN CLASSIFICATI; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; FUKUNAGA JH, 1990, INTRO STAT PATTERN R; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; Golub G.H., 1996, MATRIX COMPUTATIONS; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Hastie T., 2001, ELEMENTS STAT LEARNI; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; Lang K., 1995, P 12 INT C MACH LEAR, P331; PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P195, DOI 10.1145/355993.356000; PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989; PENROSE R., 1955, P CAMBRIDGE PHILOS S, V51, P406; STEWARD O, 1998, NEURON, V21, P1; Stewart G.W., 2001, MATRIX ALGORITHMS, VII; SWETS D, 1996, IEEE T PATTERN ANAL, V8, P831; Torkkola K., 2001, P IEEE INT C DAT MIN; XIONG H., 2004, P 10 ACM SIGKDD INT, P364, DOI 10.1145/1014052.1014093; Ye J., 2007, P 24 INT C MACH LEAR; Ye J.P., 2006, P 12 ACM SIGKDD INT, P454, DOI 10.1145/1150402.1150453; Ye JP, 2005, J MACH LEARN RES, V6, P483	27	74	77	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN	2008	20	1					1	12		10.1109/TKDE.2007.190669		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	232FI	WOS:000251003300001	
J	Facca, FM; Lanzi, PL				Facca, FM; Lanzi, PL			Mining interesting knowledge from weblogs: a survey	DATA & KNOWLEDGE ENGINEERING			English	Article						machine learning; Web Mining	WORLD-WIDE-WEB; RECOMMENDER SYSTEMS; PERSONALIZATION; DISCOVERY; FRAMEWORK; EFFICIENT; SESSIONS	Web Usage Mining is that area of Web Mining which deals with the extraction of interesting knowledge from logging information produced by Web servers. In this paper we present a survey of the recent developments in this area that is receiving increasing attention from the Data Mining community. (c) 2004 Elsevier B.V. All rights reserved.	Politecn Milan, Dipartimento Elettron & Informaz, Artificial Intelligence & Robot Lab, I-20133 Milan, Italy	Lanzi, PL (reprint author), Politecn Milan, Dipartimento Elettron & Informaz, Artificial Intelligence & Robot Lab, I-20133 Milan, Italy.	facca@elet.polimi.it; lanzi@elet.polimi.it					ADOMAVICIUS G, 2001, WORKSH INT TECHN WEB; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; ANDERSEN J, 2000, INT WORKSH DAT WAR O; ANDERSON CR, 2002, P 8 ACM SIGKDD INT C; Anderson CR, 2002, THESIS U WASHINGTON; ANSARI S, 2001, P 2001 IEEE INT C DA; ANSARI S, 2000, WEBKDD 2000 WEB MIN; BANERJEE A, 2001, P WEB MIN WORKSH 1 S; BERENDT B, 2002, P 4 WEBKDD 2002 WORK; Berendt B, 2002, DATA MIN KNOWL DISC, V6, P37, DOI 10.1023/A:1013280719795; Bonchi F, 2001, DATA KNOWL ENG, V39, P165, DOI 10.1016/S0169-023X(01)00038-6; BORGES J, 2000, THESIS U COLLEGE LON; BOUNSAYTHIP C, 2001, TTEI200118 VTT; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; CATLEDGE LD, 1995, COMPUT NETWORKS ISDN, V27, P1065, DOI 10.1016/0169-7552(95)00043-7; CHANG CY, 2002, P 11 INT C INF KNOWL, P632; CHANG WL, 2000, WEBKDD 2000 WEB MIN; Chen M., 2002, P 25 ANN INT ACM SIG, P65; Chi E. H., 2001, P ACM CHI 2001 C HUM, P490, DOI 10.1145/365024.365325; Cooley R, 2003, ACM T INTERNET TECHN, V3, P93, DOI 10.1145/767193.767194; Cooley R., 1999, Knowledge and Information Systems, V1; COOLEY R, 2000, WEB USAGE DISCOVERY; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; Dai H., 2002, P 2 SEM WEB MIN WORK; DIEBOLD B, 2001, AUSTR S INF VIS, P159; Eirinaki M., 2003, P 9 ACM SIGKDD INT C, P99; Eirinaki M., 2003, ACM T INTERNET TECHN, V3, P1, DOI DOI 10.1145/643477.643478; Etzioni O, 1996, COMMUN ACM, V39, P65, DOI 10.1145/240455.240473; EVFIMIEVSKI A. V., 2002, P 8 ACM SIGKDD INT C; FENSTERMACHER KD, 2002, 4 IEEE INT WORKSH AD, P205; Fu Y, 2001, P 10 INT C INF KNOWL, P583; Han J., 2001, DATA MINING CONCEPTS; HAN J, 2000, P 6 ACM SIGKDD INT C; HAY B, 2001, INTELLIGENT TECHNIQU, P1; HEER J, 2002, P WORKSH WEB AN 2 SI; HOLLAND JH, 1992, ADAPTATION NATURAL A; Huang JZ, 2002, LECT NOTES ARTIF INT, V2356, P48; Huang X., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; JESPERSEN SE, 2002, P 4 INT C DAT WAR KN, P73; Joshi KP, 2003, DISTRIB PARALLEL DAT, V13, P161, DOI 10.1023/A:1021515408295; KAMDAR T, 2001, THESIS U MARYLAND BA; Kim HR, 2003, P 8 INT C INT US INT, P101; Kosala R., 2000, ACM SIGKDD EXPLORATI, V2, P1, DOI DOI 10.1145/360402.360406; Kristol D.M., 2001, ACM T INTERNET TECHN, V1, P151, DOI 10.1145/502152.502153; LAN B, 2000, P 9 ACM INT C INF KN, P504, DOI 10.1145/354756.354859; LI T, 2001, THESIS S FRASER U; Lin WY, 2002, DATA MIN KNOWL DISC, V6, P83, DOI 10.1023/A:1013284820704; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; MENASALVAS E, 2002, P FUZZ IEEE FUZZ SET; MEO R, 2004, IN PRESS WEBKDD2004; Mobasher B, 2002, DATA MIN KNOWL DISC, V6, P61, DOI 10.1023/A:1013232803866; Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169; MOBASHER B, 2001, WEB INFORMATION DATA, P9; MORTAZAVIASL B, 2001, THESIS S FRASER U; Nanopoulos A, 2002, LECT NOTES ARTIF INT, V2356, P68; Nanopoulos A, 2003, IEEE T KNOWL DATA EN, V15, P1155, DOI 10.1109/TKDE.2003.1232270; NANOPOULOS A, 2002, 4 ACM CIKM INT WORKS; NASRAOUI O, 2002, P WORLD C COMP INT W, P711; NIU ESN, 2002, P 4 INT WORKSH WEB S, P53; OYANAGI S, 2001, WEBKDD 2001 MIN WEB; Paik H.-Y., 2002, WWW J, V5, P325, DOI 10.1023/A:1021072310244; Pal SK, 2002, IEEE T NEURAL NETWOR, V13, P1163, DOI 10.1109/TNN.2002.1031947; Pei J., 2000, P PAC AS C KNOWL DIS, P396; PEI J, IN PRESS IEEE T KNOW; Punin JR, 2002, LECT NOTES ARTIF INT, V2356, P88; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; SHAHABI C, 2002, E COMMERCE INTELLIGE, V105; Shahabi C, 2002, LECT NOTES ARTIF INT, V2356, P113; SPILOPOULOU M, 2001, DATA MINING MEASURIN, P85; Srikant R, 2001, WORLD WIDE WEB, P430; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12; STUMME G, 2002, NAT SCI FDN WORKSH N; Tan PN, 2002, DATA MIN KNOWL DISC, V6, P9, DOI 10.1023/A:1013228602957; TAN PN, 2000, WEBKDD 2000 WEB MIN; Toolan F, 2002, WISE 2002: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS ENGINEERING (WORKSHOPS), P232; VANDERMEER D, 2000, P ACM E COMM 2000 C, P185, DOI 10.1145/352871.352892; WONG SSC, 2001, WORKSH SOFT COMP CAS; Wu Y, 2002, WORLD WIDE WEB, V5, P67, DOI 10.1023/A:1015750423727; Xie Y., 2001, P 1 INT C KNOWL CAPT, P202; Yang Q, 2003, IEEE T KNOWL DATA EN, V15, P1050; YPMA A, 2002, P 14 BELG DUTCH C AI; ZAIANE OR, 2001, P C ADV TECHN ED, P450; Zhu JH, 2002, LECT NOTES COMPUT SC, V2311, P60; [Anonymous], 1995, OFFICIAL J EUROPEAN, VL 281, P0031; *EUR COMM INF SOC, 1998, CONS DISC KNOWL IND; *IBM, 2003, SURFA AN; *PIL SOFTW, 2002, WEB SIT AN GOING TRA; CONFIGURATION FILE W; W3C EXTENDED LOG FIL	89	74	82	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	JUN	2005	53	3					225	241		10.1016/j.datak.2004.08.001		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	907ZZ	WOS:000227758100001	
J	Coussement, K; Van den Poel, D				Coussement, Kristof; Van den Poel, Dirk			Churn prediction in subscription services: An application of support vector machines while comparing two parameter-selection techniques	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; Churn prediction; subscription services; support vector machines; parameter-selection technique	SWITCHING BEHAVIOR; CUSTOMER RETENTION; MODELS; CATEGORIZATION; SEGMENTATION; RECOGNITION; ATTRITION	CRM gains increasing importance due to intensive competition and saturated markets. With the purpose of retaining customers, academics as well as practitioners find it crucial to build a churn prediction model that is as accurate as possible. This study applies support vector machines in a newspaper subscription context in order to construct a churn model with a higher predictive performance. Moreover, a comparison is made between two parameter-selection techniques, needed to implement support vector machines. Both techniques are based on grid search and cross-validation. Afterwards, the predictive performance of both kinds of support vector machine models is benchmarked to logistic regression and random forests. Our study shows that support vector machines show good generalization performance when applied to noisy marketing data. Nevertheless, the parameter optimization procedure plays an important role in the predictive performance. We show that only when the optimal parameter-selection procedure is applied, support vector machines outperform traditional logistic regression, whereas random forests outperform both kinds of support vector machines. As a substantive contribution, an overview of the most important churn drivers is given. Unlike ample research, monetary value and frequency do not play an important role in explaining churn in this subscription-services application. Even though most important churn predictors belong to the category of variables describing the subscription, the influence of several client/company-interaction variables cannot be neglected. (c) 2006 Elsevier Ltd. All rights reserved.	Univ Ghent, Fac Econ & Business Adm, Dept Marketing, B-9000 Ghent, Belgium	Coussement, K (reprint author), Univ Ghent, Fac Econ & Business Adm, Dept Marketing, Tweekerkenstr 2, B-9000 Ghent, Belgium.	Kristof.Coussement@UGent.be; Dirk.VandenPoel@UGent.be					Acir N, 2006, EXPERT SYST APPL, V31, P150, DOI 10.1016/j.eswa.2005.09.013; Allison PD, 1999, LOGISTIC REGRESSION; Athanassopoulos AD, 2000, J BUS RES, V47, P191, DOI 10.1016/S0148-2963(98)00060-5; Bauer C. L., 1988, J DIRECT MARKETING, V2, P16, DOI 10.1002/dir.4000020305; Bicego M, 2005, LECT NOTES COMPUT SC, V3781, P15; Bratko A, 2006, INFORM PROCESS MANAG, V42, P679, DOI 10.1016/j.ipm.2005.06.003; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buckinx W, 2005, EUR J OPER RES, V164, P252, DOI 10.1016/j.ejor.2003.12.010; BUCKLIN RE, 1992, J MARKETING RES, V29, P201, DOI 10.2307/3172570; BUREZ J, IN PRESS EXPERT SYST; BURGES CJC, 1997, ADV NEURAL INFORM PR; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chang C., 2004, LIBSVM LIB SUPPORT V; CHEN KY, 2007, EXPERT SYSTEMS APPL, V321, P254; Chen XJ, 2005, J COMPUT THEOR NANOS, V2, P534, DOI 10.1166/jctn.2005.008; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cui DP, 2005, MARKET SCI, V24, P595, DOI 10.1287/mksc.1050.0123; Dekimpe MG, 1997, EUR J OPER RES, V98, P37, DOI 10.1016/0377-2217(95)00337-1; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Duda R.O., 2001, PATTERN CLASSIFICATI; EGAN JP, 1975, SIGNAL DETECTION THE; Glotsos D, 2005, INT J NEURAL SYST, V15, P1, DOI 10.1142/S0129065705000013; Guadagni PM, 1983, MARKET SCI, V2, P203, DOI 10.1287/mksc.2.3.203; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T., 2001, ELEMENTS STAT LEARNI; He JY, 2005, LECT NOTES COMPUT SC, V3759, P203; Hsu C., 2004, PRACTICAL GUIDE SUPP; Hung SY, 2006, EXPERT SYST APPL, V31, P515, DOI 10.1016/j.eswa.2005.09.080; Jones MA, 2000, J RETAILING, V76, P259, DOI 10.1016/S0022-4359(00)00024-5; Keaveney SM, 2001, J ACAD MARKET SCI, V29, P374, DOI 10.1177/03079450094225; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Kim S, 2005, LECT NOTES COMPUT SC, V3611, P636; Kim SK, 2005, LECT NOTES COMPUT SC, V3689, P328; Lariviere B, 2005, EXPERT SYST APPL, V29, P472, DOI 10.1016/j.eswa.2005.04.043; Li ST, 2006, EXPERT SYST APPL, V30, P772, DOI 10.1016/j.eswa.2005.07.041; Lin HT, 2003, STUDY SIGMOID KERNEL; Luo T, 2004, IEEE T SYST MAN CY B, V34, P1753, DOI 10.1109/TSMCB.2004.830340; NESLIN S, 2004, DEFECTION DETECTION; Pai PF, 2005, INT J ADV MANUF TECH, V27, P205, DOI 10.1007/s00170-004-2139-y; Reinartz WJ, 2003, J MARKETING, V67, P77, DOI 10.1509/jmkg.67.1.77.18589; Rossi PE, 1996, MARKET SCI, V15, P321, DOI 10.1287/mksc.15.4.321; Rust RT, 1996, EUR J OPER RES, V91, P427, DOI 10.1016/0377-2217(95)00316-9; SWETS JA, 1979, INVEST RADIOL, V14, P109, DOI 10.1097/00004424-197903000-00002; Swets JA, 1982, EVALUATION DIAGNOSTI; Tax SS, 1998, J MARKETING, V62, P60, DOI 10.2307/1252161; Thomas JS, 2001, J MARKETING RES, V38, P262, DOI 10.1509/jmkr.38.2.262.18848; Van den Poel D, 2004, EUR J OPER RES, V157, P196, DOI 10.1016/S0377-2217(03)00069-9; Vapnik V. N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; WEISS GM, 2001, MLTR43 RUTG U DEP CO; YAMAGUCHI K, 1992, J AM STAT ASSOC, V87, P284, DOI 10.2307/2290258; Zhao Y, 2005, LECT NOTES ARTIF INT, V3584, P300; ZHONG W, IN PRESS EXPERT SYST	54	73	77	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JAN	2008	34	1					313	327		10.1016/j.eswa.2006.09.038		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	222KP	WOS:000250295300031	
J	Li, ZM; Lu, S; Myagmar, S; Zhou, YY				Li, ZM; Lu, S; Myagmar, S; Zhou, YY			CP-Miner: Finding copy-paste and related bugs in large-scale software code	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						software analysis; code reuse; code duplication; debugging aids; data mining	PROGRAMS	Recent studies have shown that large software suites contain significant amounts of replicated code. It is assumed that some of this replication is due to copy-and-paste activity and that a significant proportion of bugs in operating systems are due to copy-paste errors. Existing static code analyzers are either not scalable to large software suites or do not perform robustly where replicated code is modified with insertions and deletions. Furthermore, the existing tools do not detect copy-paste related bugs. In this paper, we propose a tool, CIF-Miner, that uses data mining techniques to efficiently identify copy-pasted code in large software suites and detects copy-paste bugs. Specifically, it takes less than 20 minutes for CP-Miner to identify 190,000 copy-pasted segments in Linux and 150,000 in FreeBSD. Moreover, CP-Miner has detected many new bugs in popular operating systems, 49 in Linux and 31 in FreeBSD, most of which have since been confirmed by the corresponding developers and have been rectified in the following releases. In addition, we have found some interesting characteristics of copy-paste in operating system code. Specifically, we analyze the distribution of copy-pasted code by size (number lines of code), granularity (basic blocks and functions), and modification within copy-pasted code. We also analyze copy-paste across different modules and various software versions.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Li, ZM (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	zli4@uiuc.edu; shanlu@uiuc.edu; myagmar@uiuc.edu; yyzhou@uiuc.edu					Agrawal R., 1995, P 11 INT C DAT ENG; Aho A. V., 1986, COMPILERS PRINCIPLES; AIKEN A., 2003, P 2003 ACM SIGMOD IN, P76; Aiken A., 2005, MOSS SYSTEM DETECTIN; Baker B. S, 1992, COMPUTING SCI STAT, V24, P49; Baker B. S., 1995, Proceedings. Second Working Conference on Reverse Engineering (Cat. No.95TB8101), DOI 10.1109/WCRE.1995.514697; Baxter ID, 1998, PROC IEEE INT CONF S, P368, DOI 10.1109/ICSM.1998.738528; Choi J.-D., 2002, P ACM SIGPLAN C PROG, P258; Chou A., 2001, P 18 ACM S OP SYST P, P73; CHOU A, 2000, P 9 INT C ARCH SUPP, P59, DOI 10.1145/378993.379002; CHURCH KW, 1993, J COMPUTATIONAL GRAP; CONDIT J, 2003, P ACM SIGPLAN 2003 C, P232; Ducasse S., 1999, Proceedings IEEE International Conference on Software Maintenance - 1999 (ICSM'99). `Software Maintenance for Business Change' (Cat. No.99CB36360), DOI 10.1109/ICSM.1999.792593; Engler D., 2001, P 18 ACM S OP SYST P, P57; Engler D., 2003, P 19 ACM S OP SYST P, P237; GRIER S, 1981, P 12 SIGCSE TECHN S, P15, DOI 10.1145/800037.800954; HALLEM S, 2002, P ACM SIGPLAN 2002 C, P69; HANGAL S, 2002, P INT C SOFTW ENG MA; HASTINGS R, 1992, P WINT USENIX C DEC, P158; JANKOWITZ HT, 1988, COMPUT J, V31, P1, DOI 10.1093/comjnl/31.1.1; Johnson J. H., 1994, Proceedings. International Conference on Software Maintenance (Cat. No.94CH3485-0), DOI 10.1109/ICSM.1994.336783; JOHNSON JH, 1993, P C CTR ADV STUD COL; JOHNSON RE, 1993, P INT S OBJ TECHN AD, P264; Kamiya T, 2002, IEEE T SOFTWARE ENG, V28, P654, DOI 10.1109/TSE.2002.1019480; KAPSER C, 2003, EVOLUTION LARGE SCAL; KOMONDOOR R, 2001, P 8 INT S STAT AN; KONTOGIANNIS K, 1995, 3 WORKSH AI SOFTW EN; Krinke J., 2001, P 8 WORK C REV ENG; Li Z., 2004, P 3 USENIX C FIL STO, P173; Li Z., 2004, Proceedings of the Sixth Symposium on Operating Systems Design and Implementation (OSDI'04); MANBER U, 1994, PROCEEDINGS OF THE WINTER 1994 USENIX CONFERENCE, P1; Mayrand J., 1996, Proceedings. International Conference on Software Maintenance (Cat. No.96CB36002), DOI 10.1109/ICSM.1996.565012; MUSUVATHI M, 2002, P S OP SYST DES IMPL; Nethercote N., 2003, P 3 WORKSH RUNT VER; Prechelt L, 2002, J UNIVERS COMPUT SCI, V8, P1016; Savage S, 1997, ACM T COMPUT SYST, V15, P391, DOI 10.1145/265924.265927; STERN U, 1995, P IFIP WG 10 5 ADV R, P21; Yan X, 2003, P SIAM INT C DAT MIN; 2005, LINUX KERNEL MAILING	39	73	80	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	MAR	2006	32	3					176	192		10.1109/TSE.2006.28		17	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	033LC	WOS:000236848300003	
J	Sousa, T; Silva, A; Neves, A				Sousa, T; Silva, A; Neves, A			Particle Swarm based Data Mining Algorithms for classification tasks	PARALLEL COMPUTING			English	Article						Data Mining; Particle Swarm Optimisation; Swarm intelligence		Particle Swarm Optimisers are inherently distributed algorithms where the solution for a problem emerges from the interactions between many simple individual agents called particles. This article proposes the use of the Particle Swarm Optimiser as a new tool for Data Mining. In the first phase of our research, three different Particle Swarm Data Mining Algorithms were implemented and tested against a Genetic Algorithm and a Tree Induction Algorithm (J48). From the obtained results, Particle Swarm Optimisers proved to be a suitable candidate for classification tasks. The second phase was dedicated to improving one of the Particle Swarm optimiser variants in terms of attribute type support and temporal complexity. The data sources here used for experimental testing are commonly used and considered as a de facto standard for rule discovery algorithms reliability ranking. The results obtained in these domains seem to indicate that Particle Swarm Data Mining Algorithms are competitive, not only with other evolutionary techniques, but also with industry standard algorithms such as the J48 algorithm, and can be successfully applied to more demanding problem domains. (C) 2004 Elsevier B.V. All rights reserved.	Escola Super Tecnol, Inst Politecn Castelo Branco, P-6000 Castelo Branco, Portugal; Univ Coimbra, Ctr Informat & Sistemas, P-3030 Coimbra, Portugal	Sousa, T (reprint author), Escola Super Tecnol, Inst Politecn Castelo Branco, Ave Empresario, P-6000 Castelo Branco, Portugal.	tsousa@est.ipcb.pt; arlindo@est.ipcb.pt; dorian@est.ipcb.pt					BLACKWELL T, 2002, P C EV COMP; Clerc Maurice, 2002, IEEE T EVOLUTIONARY, V6; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Freitas A., 2001, ADV EVOLUTIONARY COM; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Kennedy J., 1995, P IEEE INT C NEUR NE; Kennedy JF, 2001, SWARM INTELLIGENCE; LOPES HS, 1997, EVOLUTIONARY APPROAC; Parpinelli R., 2002, ANT COLONY ALGORITHM; SHI Y, 1999, P 1999 C EV COMP PID; Silva A., 2002, P MENDEL 2002 8 INT; Witten I.H., 1999, DATA MINING PRACTICA	12	73	82	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8191		PARALLEL COMPUT	Parallel Comput.	MAY-JUN	2004	30	5-6					767	783		10.1016/j.parco.2003.12.015		17	Computer Science, Theory & Methods	Computer Science	830EF	WOS:000222103700013	
J	Hwang, H; Jung, T; Suh, E				Hwang, H; Jung, T; Suh, E			An LTV model and customer segmentation based on customer value: a case study on the wireless telecommunication industry	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						lifetime value; customer segmentation; customer value; data mining; customer churn		Since the early 1980s, the concept of relationship management in marketing area has gained its importance. Acquiring and retaining the most profitable customers are serious concerns of a company to perform more targeted marketing campaigns. For effective customer relationship management, it. is important to gather information on customer value. Many researches have been performed to calculate customer value based on Customer lifetime value (LTV). It, however, has some limitations. It is difficult to consider the defection of customers. Prediction models have focused mainly on expected future cash flow derived from customers' past profit contribution. In this paper we suggest an LTV model considering past profit contribution, potential benefit, and defection probability of a customer. We also cover a framework for analyzing customer value and segmenting customers based on their value. Customer value is classified into three categories: current value, potential value, and customer loyalty. Customers are segmented according to three types of customer value. A case study on calculating customer value and segmenting customers of a wireless communication company will be illustrated. (C) 2003 Elsevier Ltd. All rights reserved.	Pohang Univ Sci & Technol, Dept Ind Engn, POSMIS Lab, Pohang 790784, Kyungbuk, South Korea	Hwang, H (reprint author), Pohang Univ Sci & Technol, Dept Ind Engn, POSMIS Lab, San 31, Pohang 790784, Kyungbuk, South Korea.	ieman@postech.ac.kr; white978@postech.ac.kr; ehsuh@postech.ac.kr					Bayon T., 2002, EUROPEAN MANAGEMENT, V20, P213, DOI 10.1016/S0263-2373(02)00037-3; BERGER PD, 1998, J INTERACT MARK, V12, P17, DOI 10.1002/(SICI)1520-6653(199824)12:1<17::AID-DIR3>3.0.CO;2-K; Bitran GR, 1996, MANAGE SCI, V42, P1364, DOI 10.1287/mnsc.42.9.1364; Blattberg RC, 1996, HARVARD BUS REV, V74, P136; Carraway Robert L., 2000, J INTERACTIVE MARKET, V14, P43, DOI 10.1002/(SICI)1520-6653(200021)14:2<43::AID-DIR4>3.0.CO;2-H; Colombo R, 1999, J INTERACT MARK, V13, P2, DOI 10.1002/(SICI)1520-6653(199922)13:3<2::AID-DIR1>3.0.CO;2-H; COURTHEOUX R, 1995, CUSTOMER RETENTION M; Dwyer F. Robert, 1997, J DIRECT MARKETING, V11, P6, DOI 10.1002/(SICI)1522-7138(199723)11:4<6::AID-DIR3>3.0.CO;2-T; Gupta S, 2003, J INTERACT MARK, V17, P9, DOI 10.1002/dir.10045; Hansotia B, 2002, J INTERACT MARK, V16, P35, DOI 10.1002/dir.10035; Hawkes VA, 2000, HEART MATTER CHALLEN; HOEKSTRA JC, 1999, J MARKET FOCUSED MAN, V3, P257, DOI 10.1023/A:1009842805871; Jackson D., 1994, J TARGETING MEASUREM, V3, P9; Jain D., 2002, J INTERACT MARK, V16, P34, DOI DOI 10.1002/DIR.10032; Kim BD, 1999, J INTERACT MARK, V13, P2, DOI 10.1002/(SICI)1520-6653(199923)13:4<2::AID-DIR1>3.0.CO;2-D; KIM J, 2000, E CRM E BUSINESS; Kim J, 2003, J INTERACT MARK, V17, P5, DOI 10.1002/dir.10051; Knox S., 1998, EUROPEAN MANAGEMENT, V16, P729, DOI 10.1016/S0263-2373(98)00049-8; Pearson S., 1996, BUILDING BRANDS DIRE; ROBERTS ML, 1989, DIRECT MARKETING MAN; Verhoef PC, 2001, DECIS SUPPORT SYST, V32, P189, DOI 10.1016/S0167-9236(01)00110-5	21	73	77	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2004	26	2					181	188		10.1016/S0957-4174(03)00133-7		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	763WW	WOS:000188124300006	
J	Kolda, TG; O'Leary, DP				Kolda, TG; O'Leary, DP			A semidiscrete matrix decomposition for latent semantic indexing in information retrieval	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						algorithms; data mining; latent semantic indexing; semidiscrete decomposition; singular-value decomposition; text retrieval		The vast amount of textual information available today is useless unless it can be effectively and efficiently searched. The goal in information retrieval is to find documents that are relevant to a given user query. We can represent a document collection by a matrix whose (i, j) entry is nonzero only if the ith term appears in the jth document; thus each document corresponds to a column vector. The query is also represented as a column vector whose ith term is nonzero only if the ith term appears in the query. We score each document for relevancy by taking its inner product with the query. The highest-scoring documents are considered the most relevant. Unfortunately, this method does not necessarily retrieve all relevant documents because it is based on literal term matching. Latent semantic indexing (LSI) replaces the document matrix with an approximation generated by the truncated singular-value decomposition (SVD). This method has been shown to overcome many difficulties associated with literal term matching. In this article we propose replacing the SVD with the semidiscrete decomposition (SDD). We will describe the SDD approximation, show how to compute it, and compare the SDD-based LSI method to the SVD-bascd LSI method. We will show that SDD-based LSI does as well as SVD-based LSI in terms of document retrieval while requiring only one-twentieth the storage and one-half the time to compute each query. We will also show how to update the SDD approximation when documents are added or deleted from the document collection.	Oak Ridge Natl Lab, Math Sci Sect, Oak Ridge, TN 37831 USA; Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA; Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA	Kolda, TG (reprint author), Oak Ridge Natl Lab, Math Sci Sect, POB 2008,Bldg 6012, Oak Ridge, TN 37831 USA.		Kolda, Tamara/B-1628-2009	Kolda, Tamara/0000-0003-4176-2493			BERRY M, 1993, SVDPACK VERSION 1 0; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; BERRY MW, 1996, NUMERICAL LINEAR ALG, V1, P1; BROGLIO J, 1995, NIST SPECIAL PUBLICA; Cohen E, 1997, PROCEEDINGS OF THE EIGHTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P682; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DUMAIS ST, 1991, BEHAV RES METH INSTR, V23, P229, DOI 10.3758/BF03203370; DUMAIS ST, 1995, NIST SPECIAL PUBLICA, P219; Frakes W., 1992, INFORMATION RETRIEVA, P131; Golub G.H., 1989, MATRIX COMPUTATIONS; Harman D., 1992, INFORMATION RETRIEVA, P363; HARMAN D, 1995, NIST SPECIAL PUBLICA; KOLDA TG, 1997, THESIS U MARYLAND; KOLDA TG, CSTR3717 U MAR DEP C; KOLDA TG, CSTR3806 DEP COMP SC; KOLDA TG, 1997, IN PRESS IMA VOLUMES; OBRIEN G, UTCS94258 DEP COMP S; OBrien G.W., 1994, THESIS U TENNESSEE K; OLEARY DP, 1983, IEEE T COMMUN, V31, P441, DOI 10.1109/TCOM.1983.1095823; PAIGE CC, 1974, SIAM J NUMER ANAL, V11, P197, DOI 10.1137/0711019; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Wilkinson JH, 1965, ALGEBRAIC EIGENVALUE; Witten Ian H., 1994, MANAGING GIGABYTES C	23	73	76	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	1046-8188		ACM T INFORM SYST	ACM Trans. Inf. Syst.	OCT	1998	16	4					322	346		10.1145/291128.291131		25	Computer Science, Information Systems	Computer Science	164YQ	WOS:000078491500002	
J	Tan, SB				Tan, SB			Neighbor-weighted K-nearest neighbor for unbalanced text corpus	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						text classification; K-nearest neighbor (KNN); information retrieval; data mining		Text categorization or classification is the automated assigning of text documents to pre-defined classes based on their contents. Many of classification algorithms usually assume that the training examples are evenly distributed among different classes. However, unbalanced data sets often appear in many practical applications. In order to deal with uneven text sets, we propose the neighbor-weighted K-nearest neighbor algorithm, i.e. NWKNN. The experimental results indicate that our algorithm NWKNN achieves significant classification performance improvement on imbalanced corpora. (c) 2005 Elsevier Ltd. All rights reserved.	Chinese Acad Sci, Inst Comp Technol, Software Dept, Beijing 100080, Peoples R China; Chinese Acad Sci, Grad Sch, Beijing, Peoples R China	Tan, SB (reprint author), Chinese Acad Sci, Inst Comp Technol, Software Dept, POB 2704, Beijing 100080, Peoples R China.	tansongbo@software.ict.ac.cn	Tan, Songbo/A-7450-2012				CHAI KMA, BAYESIAN ONLINE CLAS; Han E.-H., 2000, CENTROID BASED DOCUM; JAPKOWICZ N, 2000, P LEARN IMB DAT SETS; Joachims T., 1998, 10 EUR C MACH LEARN, P137; Lewis D. D., 1996, P 19 ANN INT ACM SIG, P298, DOI 10.1145/243199.243277; Lewis D.D., 1998, 10 EUR C MACH LEARN, P4; LEWIS DD, 1994, P 3 ANN S DOC AN INF; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Singhal A, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P25, DOI 10.1145/258525.258530; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; YANG Y, 1999, 22 ANN INT ACM SIGIR; Yang Y., 1999, INFORMATION RETRIEVA, V1, P76; ZHANG J, KNN APPROACH UNBALAN; *TDT2, 1998, NIST TOP DET TRACK C	14	72	83	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2005	28	4					667	671		10.1016/j.eswa.2004.12.023		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	913BD	WOS:000228124200007	
J	Eschrich, S; Ke, JW; Hall, LO; Goldgof, DB				Eschrich, S; Ke, JW; Hall, LO; Goldgof, DB			Fast accurate fuzzy clustering through data reduction	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						aggregation; fuzzy clustering; image segmentation; quantization; speed-up	VECTOR QUANTIZATION; ALGORITHM; EM	Clustering is a useful approach in image segmentation, data mining, and other pattern recognition problems for which unlabeled data exist. Fuzzy clustering using fuzzy c-means or variants of it can provide a data partition that is both better and more meaningful than hard clustering approaches. The clustering process can be quite slow when there are many objects or patterns to be clustered. This paper discusses an algorithm brFCM, which is able to reduce the number of distinct patterns which must be clustered without adversely affecting partition quality. The reduction is done by aggregating similar examples and then using a weighted exemplar in the clustering process. The reduction in the amount of clustering data allows a partition of the data to be produced faster. The algorithm is applied to the problem of segmenting 32 magnetic resonance images into different tissue types and the problem of segmenting 172 infrared images into trees, grass and target. Average speed-ups of as much as 59-290 times a traditional implementation of fuzzy c-means were obtained using brFCM, while producing partitions that are equivalent to those produced by fuzzy c-means.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	Eschrich, S (reprint author), Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.		Eschrich, Steven/K-6848-2013				ALSBERG BK, 1995, J COMPUT CHEM, V16, P414, DOI 10.1002/jcc.540160404; Baek S, 1998, ELECTRON LETT, V34, P151, DOI 10.1049/el:19980217; BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; Bezdek JC, 1991, FUZZY MODELS PATTERN; Bezdek J C, 1997, Stat Methods Med Res, V6, P191, DOI 10.1191/096228097677057357; CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248; Cheng SC, 2001, PATTERN RECOGN LETT, V22, P845, DOI 10.1016/S0167-8655(01)00025-3; Cheng TW, 1998, FUZZY SET SYST, V93, P49, DOI 10.1016/S0165-0114(96)00232-1; Clark MC, 1998, IEEE T MED IMAGING, V17, P187, DOI 10.1109/42.700731; Cormen T. H., 1998, INTRO ALGORITHMS; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Eschrich S., 2001, Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569), DOI 10.1109/NAFIPS.2001.944766; Estivill-Castro V, 2001, ALGORITHMICA, V30, P216, DOI 10.1007/s00453-001-0010-1; Fletcher-Heath LM, 2001, ARTIF INTELL MED, V21, P43, DOI 10.1016/S0933-3657(00)00073-7; HALL LO, 1992, IEEE T NEURAL NETWOR, V3, P672, DOI 10.1109/72.159057; HALL LO, 2000, ISL0004 U S FLOR DEP; Han JK, 1999, ELECTRON LETT, V35, P1305, DOI 10.1049/el:19990920; JAIN A, 1988, ALGORITHMS THAT CLUS; KE J, 1999, THESIS U S FLORIDA T; KOLEN JF, 2002, IEEE T FUZZY SYST, V2, P263; KRISHNAPURAM R, 1999, P IEEE INT FUZZ SYST, V3; Laws K.I., 1979, P IM UND WORKSH, P47; LI C, 1993, IEEE T MED IMAGING, V12, P672; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pal NR, 2002, IEEE T SYST MAN CY B, V32, P598, DOI 10.1109/TSMCB.2002.1033179; PELLEG D, 1999, C KNOWL DISC DAT SAN; Ribarsky W, 1999, IEEE COMPUT GRAPH, V19, P32, DOI 10.1109/38.788796; SHANKAR BU, 1994, P 3 INT C FUZZ LOG N, P331; SOMERVUO P, 2000, P 3 INT C DISC SCI, P76; Wu CH, 2000, IMAGE VISION COMPUT, V18, P1033, DOI 10.1016/S0262-8856(00)00044-5; Xu XW, 1999, DATA MIN KNOWL DISC, V3, P263, DOI 10.1023/A:1009884809343; YAO W, 2000, P INT C PATT REC, V2, P307, DOI 10.1109/ICPR.2000.906074; ZHANG M, 2000, INT J PATTERN RECOGN, V14, P43	33	72	82	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	APR	2003	11	2					262	270		10.1109/TFUZZ.2003.809902		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	664ZN	WOS:000182095300010	
J	Freitas, AA				Freitas, AA			Understanding the crucial role of attribute interaction in data mining	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						attribute interaction; classification; constructive induction; data mining; evolutionary algorithms; inductive logic programming; rule induction; rule interestingness; Simpson's paradox; small disjuncts	KNOWLEDGE DISCOVERY; DATABASES	This is a review paper, whose goal is to significantly improve our understanding of the crucial role of attribute interaction in data mining. The main contributions of this paper are as follows. Firstly, we show that the concept of attribute interaction has a crucial role across different kinds of problem in data mining, such as attribute construction, coping with small disjuncts, induction of first-order logic rules, detection of Simpson's paradox, and finding several types of interesting rules. Hence, a better understanding of attribute interaction can lead to a better understanding of the relationship between these kinds of problems, which are usually studied separately from each other. Secondly, we draw attention to the fact that most rule induction algorithms are based on a greedy search which does not cope well with the problem of attribute interaction, and point out some alternative kinds of rule discovery methods which tend to cope better with this problem. Thirdly, we discussed several algorithms and methods for discovering interesting knowledge that, implicitly or explicitly, are based on the concept of attribute interaction.	Pontificia Univ Catolica Parana, Postgrad Program Comp Sci, BR-80215901 Curitiba, Parana, Brazil	Freitas, AA (reprint author), Pontificia Univ Catolica Parana, Postgrad Program Comp Sci, Rua Imaculada Conceicao 1155, BR-80215901 Curitiba, Parana, Brazil.		Freitas, Alex/H-1249-2011				ANGLANO C, 1997, P 7 INT C GEN ALG, P434; Araujo DLA, 1999, P 1999 IEEE SYST MAN, V3, P940; Banzhaf W., 1998, GENETIC PROGRAMMING; BHANDARI I, 1993, P 1993 WORKSH KNOWL, P61; BHANDARI I, 1994, P AAAI 94 WORKSH KNO, P61; BRAZDIL P, 1994, MACHINE LEARNING NEU, pCH10; CARVALHO DR, 2000, LECT NOTES ARTIF INT, P345; Danyluk A. P., 1993, P 10 INT C MACH LEAR, P81; Dhar V, 2000, DATA MIN KNOWL DISC, V4, P251, DOI 10.1023/A:1009848126475; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; DZEROSKI S, 1993, IEEE T KNOWL DATA EN, V5, P939, DOI 10.1109/69.250076; Fabris C., 1999, RES DEV INTELLIGENT, P148; FABRIS CC, 2000, UNPUB INCORPORATING; Frawley W. J., 1991, Knowledge discovery in databases; Freitas A. A, 1998, MINING VERY LARGE DA; Freitas A.A., 2000, P GEN EV COMP C GECC, P1061; FREITAS AA, 2000, P 2000 GEN EV COMP C, P69; Freitas AA, 1998, LECT NOTES ARTIF INT, V1510, P1; GARDNER H, 1994, MINDS NEW SCI HIST C; Goil S, 1997, DATA MIN KNOWL DISC, V1, P391, DOI 10.1023/A:1009777418785; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Holte RC, 1989, P 11 INT JOINT C ART, P813; HU YJ, 1998, GENETIC PROGRAMMING, P146; Kuscu I., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.781928; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Liu B., 1999, P 5 ACM SIGKDD INT C, P125, DOI 10.1145/312129.312216; Liu H, 1998, FEATURE EXTRACTION C; Michalewicz Z, 1996, GENETIC ALGORITHMS D; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; MICHIE D, 1994, MACHINE LEARNING NEU, P213; NAZAR K, 1999, KNOWLEDGE DISCOVERY, P3; Neri F., 1995, P 6 INT C GEN ALG, p[436, Morgan]; NEWSON G, 1991, MATH GAZ, V75, P290, DOI 10.2307/3619486; PAZZANI MJ, 2000, IEEE INTELLIGENT MAR, P10; PIATETSKYSHAPIRO G, 1991, AI MAG, V11, P68; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RENDELL L, 1990, MACH LEARN, V5, P267, DOI 10.1007/BF00117106; Rendell L., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00298.x; RENDELL L, 1993, P 13 INT JOINT C ART, P952; SAMUEL AL, 1959, IBM J RES DEV, V3, P211; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SIMPSON EH, 1951, J ROY STAT SOC B, V13, P238; Srinivasan A, 1999, DATA MIN KNOWL DISC, V3, P37, DOI 10.1023/A:1009815821645; Taha IA, 1999, IEEE T KNOWL DATA EN, V11, P448, DOI 10.1109/69.774103; Ting K., 1994, P 10 CAN C ART INT, P91; Vaughn ML, 1996, NEURAL COMPUT APPL, V4, P72, DOI 10.1007/BF01413743; WAGNER CH, 1982, AM STAT, V36, P46, DOI 10.2307/2684093; WEISS G M, 1995, P 12 INT C MACH LEAR, P558; WEISS GM, 1998, P 15 INT C MACH LEAR, P574; Weiss G. M., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); ZYTKOW J, 1999, P 1999 C EV COMP CEC, P1307	53	72	76	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	NOV	2001	16	3					177	199		10.1023/A:1011996210207		23	Computer Science, Artificial Intelligence	Computer Science	475AM	WOS:000171139500001	
J	Andrienko, G; Andrienko, N; Jankowski, P; Keim, D; Kraak, MJ; Maceachren, A; Wrobel, S				Andrienko, G.; Andrienko, N.; Jankowski, P.; Keim, D.; Kraak, M.-J.; Maceachren, A.; Wrobel, S.			Geovisual analytics for spatial decision support: Setting the research agenda	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article						geovisual analytics; spatial decision support; research agenda	SYSTEMS	This article summarizes the results of the workshop on Visualization, Analytics & Spatial Decision Support, which took place at the GIScience conference in September 2006. The discussions at the workshop and analysis of the state of the art have revealed a need in concerted cross-disciplinary efforts to achieve substantial progress in supporting space-related decision making. The size and complexity of real-life problems together with their ill-defined nature call for a true synergy between the power of computational techniques and the human capabilities to analyze, envision, reason, and deliberate. Existing methods and tools are yet far from enabling this synergy. Appropriate methods can only appear as a result of a focused research based on the achievements in the fields of geovisualization and information visualization, human-computer interaction, geographic information science, operations research, data mining and machine learning, decision science, cognitive science, and other disciplines. The name `Geovisual Analytics for Spatial Decision Support' suggested for this new research direction emphasizes the importance of visualization and interactive visual interfaces and the link with the emerging research discipline of Visual Analytics. This article, as well as the whole special issue, is meant to attract the attention of scientists with relevant expertise and interests to the major challenges requiring multidisciplinary efforts and to promote the establishment of a dedicated research community where an appropriate range of competences is combined with an appropriate breadth of thinking.	Schloss Birlinghoven, Fraunhofer Inst Intelligent Anal & Informat Syst, D-53754 St Augustin, Germany; San Diego State Univ, Dept Geog, San Diego, CA 92182 USA; Univ Konstanz, Inst Comp Sci, D-78464 Constance, Germany; Int Inst Geoinformat Sci & Earth Observat, Dept Geoinformat Proc, NL-7514 AE Enschede, Netherlands; Penn State Univ, Dept Geog, University Pk, PA 16802 USA	Andrienko, G (reprint author), Schloss Birlinghoven, Fraunhofer Inst Intelligent Anal & Informat Syst, D-53754 St Augustin, Germany.	natalia.andrienko@iais.fraunhofer.de	MacEachren, Alan/E-9444-2011; Kraak, Menno-Jan/A-2809-2012; Wright, Dawn/A-4518-2011	Kraak, Menno-Jan/0000-0002-8605-0484; Wright, Dawn/0000-0002-2997-7611			Andrienko Gennady, 2005, EXPLORING GEOVISUALI, P103; ANSELIN L, 1989, WHAT SPECIAL SPATIAL; ANSELIN L, 2000, J GEOGRAPHICAL SYSTE, V2, P201, DOI 10.1007/PL00011455; Carr DB, 2005, ANN ASSOC AM GEOGR, V95, P32, DOI 10.1111/j.1467-8306.2005.00449.x; CHEN C, 2005, IEEE COMPUTER GRAPHI; Convertino G., 2005, Proceedings. Third International Conference on Coordinated and Multiple Views in Exploratory Visualization (CMV 2005); Dix A., 2003, HUMAN COMPUTER INTER; Dykes J., 2005, EXPLORING GEOVISUALI; Figueira J, 2005, INT SER OPER RES MAN, V78, P1, DOI 10.1007/b100605; Gahegan M., 2006, T GIS, V10, P727, DOI 10.1111/j.1467-9671.2006.01025.x; GOODCHILD MF, 2003, GIS DEV ASIAN MONTHL, V7, P8; Han J, 2006, DATA MINING CONCEPTS; Hand D. J., 2001, PRINCIPLES DATA MINI; HEER J, 2007, P CHI 2007; Hutchins Edwin, 1995, COGNITION WILD; Jacko J. A., 2002, HUMAN COMPUTER INTER; Kirschner Paul A., 2003, VISUALIZING ARGUMENT; LARKIN JH, 1987, COGNITIVE SCI, V11, P65, DOI 10.1016/S0364-0213(87)80026-5; Maceachren AM, 2004, INT J GEOGR INF SCI, V18, P1, DOI 10.1080/13658810310001596094; Malczewski J, 2006, INT J GEOGR INF SCI, V20, P703, DOI 10.1080/13658810600661508; Malczewski J., 1999, GIS MULTICRITERIA DE; Nevo D, 2005, DECIS SUPPORT SYST, V39, P549, DOI 10.1016/j.dss.2004.03.002; PALMER JD, 1994, COMPUTER, V27, P67, DOI 10.1109/2.291289; RAMAKRISHNAN R., 2003, DATABASE MANAGEMENT; Saaty TL, 2005, INT SER OPER RES MAN, V78, P345, DOI 10.1007/0-387-23081-5_9; Shneiderman B., 2004, DESIGNING USER INTER; Simon H.A., 1960, NEW SCI MANAGEMENT D; Thomas J J, 2005, ILLUMINATING PATH RE; Tufte E. R., 1997, VISUAL EXPLANATIONS; Zhu H, 2006, INT J PROD RES, V44, P181, DOI 10.1080/00207540500247495	30	71	71	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	SEP	2007	21	8					839	857		10.1080/13658810701349011		19	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	201UG	WOS:000248857500001	
J	Glymour, C; Madigan, D; Pregibon, D; Smyth, P				Glymour, C; Madigan, D; Pregibon, D; Smyth, P			Statistical themes and lessons for data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						statistics; uncertainty; modeling; bias; variance	MODEL UNCERTAINTY	Data mining is on the interface of Computer Science and Statistics, utilizing advances in both disciplines to make progress in extracting information from large databases. It is an emerging field that has attracted much attention in a very short period of time. This article highlights some statistical themes and lessons that are directly relevant to data mining and attempts to identify opportunities where close cooperation between the statistical and computational communities might reasonably provide synergy for further progress in data analysis.	Carnegie Mellon Univ, Dept Cognit Psychol, Pittsburgh, PA 15213 USA; Univ Washington, Dept Stat, Seattle, WA 98195 USA; AT&T Bell Labs, Stat Res, Murray Hill, NJ 07974 USA; Univ Calif Irvine, Irvine, CA 92717 USA	Glymour, C (reprint author), Carnegie Mellon Univ, Dept Cognit Psychol, Pittsburgh, PA 15213 USA.	cg09@andrew.cmu.edu; madigan@stat.washington.edu; daryl@research.att.com; smyth@ics.uci.edu					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BERGER JO, 1987, J AM STAT ASSOC, V82, P112, DOI 10.2307/2289131; BREIMAN L, 1996, IN PRESS MACHINE LEA; CHASNOFF IJ, 1989, JAMA-J AM MED ASSOC, V261, P1741, DOI 10.1001/jama.261.12.1741; CHATFIELD C, 1995, J ROY STAT SOC A STA, V158, P419, DOI 10.2307/2983440; DALAL SR, 1989, J AM STAT ASSOC, V84, P945, DOI 10.2307/2290069; DIGGLE P, 1994, APPL STAT-J ROY ST C, V43, P49, DOI 10.2307/2986113; DRAPER D, 1995, J ROY STAT SOC B MET, V57, P45; DRAPER D, 1993, COMBINGING INFORMATI; Efron B., 1993, INTRO BOOSTRAP; Fisher R. A., 1958, STAT METHODS RES WOR; FREEDMAN DA, 1983, AM STAT, V37, P152, DOI 10.2307/2685877; GEIGER D, 1996, P 12 ANN C UNC ART I; Gilks W., 1996, MARKOV CHAIN MONTE C; HAND DJ, 1994, J ROY STAT SOC A STA, V157, P317, DOI 10.2307/2983526; Hastie T.J., 1990, GEN ADDITIVE MODELS; HOERL RW, 1993, AM STAT, V47, P280, DOI 10.2307/2685288; Huber P.J., 1981, ROBUST STAT; JEFFREYS H, 1980, BAYESIAN ANAL ECONOM, P451; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; KIIVERI H, 1982, SOCIOL METHODOL, P209; KOOPERBERG C, 1996, IN PRESS J AM STAT A; Lauritzen SL, 1996, GRAPHICAL MODELS; Leamer E.E., 1978, SPECIFICATION SEARCH; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; Madigan D., 1994, J AM STAT ASSOC, V89, P1335; MATHESON JE, 1976, MANAGE SCI, V22, P1087, DOI 10.1287/mnsc.22.10.1087; McCullagh P, 1989, GEN LINEAR MODELS; MICHELANGELI PA, 1995, J ATMOS SCI, V52, P1237, DOI 10.1175/1520-0469(1995)052<1237:WRRAQS>2.0.CO;2; MILLER RG, 1981, SIMULTANEOUS STAT IN; Neyman J, 1933, PHILOS T R SOC LOND, V231, P289, DOI 10.1098/rsta.1933.0009; PEARL J, 1990, R155 UCLA COMP SCI D; PEARL J, 1991, P 2 INT C; Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.1093/biomet/82.4.669; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SCHEINES R, 1995, CMUPHIL66 DE PHIL; Scheines Richard, 1994, TETRAD 2 USERS MANUA; Schervish M. J., 1995, THEORY STAT; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SELVIN HC, 1966, AM STAT, V20, P20, DOI 10.2307/2681493; SIMPSON EH, 1951, J ROY STAT SOC B, V13, P238; SMITH AFM, 1993, J ROY STAT SOC B MET, V55, P3; Spirtes P., 1993, SPRINGER LECT NOTES; Spirtes P, 1995, P 11 C UNC ART INT U, P499; Spirtes P, 1995, P 1 INT C KNOWL DISC, P294; SPIRTES P, 1997, IN PRESS P C AI STAT; Stigler Stephen M., 1986, HIST STAT MEASUREMEN; WEN SW, 1995, JAMA-J AM MED ASSOC, V274, P1687, DOI 10.1001/jama.274.21.1687; Wright S., 1921, J AGR RES, V20, P557; *EN MOD FOR, 1982, 6 EMF STANF U EN MOD	51	71	77	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					11	28		10.1023/A:1009773905005		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900002	
J	Lin, J; Keogh, E; Wei, L; Lonardi, S				Lin, Jessica; Keogh, Eamonn; Wei, Li; Lonardi, Stefano			Experiencing SAX: a novel symbolic representation of time series	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						time series; data mining; symbolic representation; discretize		Many high level representations of time series have been proposed for data mining, including Fourier transforms, wavelets, eigenwaves, piecewise polynomial models, etc. Many researchers have also considered symbolic representations of time series, noting that such representations would potentiality allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities. While many symbolic representations of time series have been introduced over the past decades, they all suffer from two fatal flaws. First, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Second, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. In this work we formulate a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. In particular, we will demonstrate the utility of our representation on various data mining tasks of clustering, classification, query by content, anomaly detection, motif discovery, and visualization.	George Mason Univ, Informat & Software Engn Dept, Fairfax, VA 22030 USA; Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA	Lin, J (reprint author), George Mason Univ, Informat & Software Engn Dept, Fairfax, VA 22030 USA.	jessica@ise.gmu.edu					Agrawal R., 1995, P 21 INT C VER LARG, P502; ANDREJONSSON H, 1997, 1 EUR S TRONDH NORW, P211; ANDROULAKIS IP, 2005, P 15 EUR S COMP AID; Apostolico A., 2002, P 6 INT C RES COMP M, P22, DOI 10.1145/565196.565200; Bagnall A, 2004, P ACM KDD 04 SEATTL, P49, DOI 10.1145/1014052.1014061; BAKALOV P, 2005, P ACM INT S ADV GEOG; BASTOGNE T., 2002, P 4 EUR CONTR C BRUS; BERNDT D, 1994, 12 INT C ART INT SEA, P229; CAHN K, 1999, P INT DAT ENG SYDN M, P126; CELLY B, 2004, P 17 INT C COMP AN S; Cheng MF, 2005, BMC INFECT DIS, V5, DOI 10.1186/1471-2334-5-22; Chiu B., 2003, P 9 ACM SIGKDD INT C, P493; DASGUPTA D, 1999, P 8 INT C INT DENV C; Daw CS, 2003, REV SCI INSTRUM, V74, P915, DOI 10.1063/1.1531823; Ding C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183897; DUCHENE F, 2005, P C FRAN APPR AUT NI; DUCHENE F, 2004, 10702 I INF MATH APP; Durbin R., 1998, BIOL SEQUENCE ANAL P; FALOUTSOS C, 1994, FAST SUBSEQUENCE MAT, V23, P419; FERREIRA PG, 2006, P 9 INT C DISC SCI B; Gavrilov M., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347189; Geurts P., 2001, P 5 EUR C PRINC DAT, P115; Gionis A, 2003, P 7 INT C RES COMP M, P123, DOI 10.1145/640075.640091; Hellerstein J. M., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263688; Huang YW, 1999, P 5 INT C KNOWL DISC, P282, DOI 10.1145/312129.318357; HUGUENEY B, 2006, P 10 EUR C PRINC PRA, P545; Kalpakis K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989529; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; Keogh E., 2001, J KNOWL INF SYST, V3, P263; Keogh E., 2002, P 8 ACM SIGKDD INT C, P550; Keogh E., 2005, P 5 IEEE INT C DAT M, P226; Kumar N, 2005, SIAM PROC S, P531; LARSEN RJ, 1986, INTRO MATH STAT APPL; LIN J, 2003, 8 ACM SIGMOD SAN DIE; Lin J., 2005, Information Visualization, V4, DOI 10.1057/palgrave.ivs.9500089; Lin J., 2002, 8 ACM SIGKDD INT C K, P53; LIN J, 2006, P 10 EUR C PRINC PRA, P284; Lin J., 2004, P 10 ACM SIGKDD INT, P460, DOI 10.1145/1014052.1014104; Lkhagva B., 2006, P 22 INT C DAT ENG W, P115; LONARDIS S, 2001, GLOBAL DETECTORS UNU; MCGOVERN A, 2006, P ICML WORKSH OP PRO; Morchen F., 2005, P 11 ACM SIGKDD INT, P660, DOI 10.1145/1081870.1081953; MURAKAMI K, 2004, P JSME C ROB MECH NA; OHSAKI M, 2006, 14 EUR C MACH LEARN; POUGET F, 2006, P 18 ANN 1 C BALT MD; RATANAMAHATANA CA, 2005, P ADV KNOWL DISC DAT, P771; Reinert G, 2000, J COMPUT BIOL, V7, P1, DOI 10.1089/10665270050081360; RODDICK JF, 2001, POST WORKSH P INT WO, P147; Shahabi C., 2000, Proceedings. 12th International Conference on Scientific and Statistica Database Management, DOI 10.1109/SSDM.2000.869778; SILVENT A, 2003, P INT DAT AN MED PHA; SILVENT A, 2004, MULT LEV TEMP ABSTR; STADEN R, 1989, COMPUT APPL BIOSCI, V5, P293; TANAKA Y, 2004, P 18 ANN C JAP SOC A; TANAKA Y, 2003, P 3 INT C MACH LEARN, P252; TOMPA M., 2001, P 5 INT C COMP MOL B, P67; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; WEI L, 2006, P 2006 IEEE INT C DA; Yi B.K., 2000, P 26 INT C VER LARG, P385; [Anonymous], 2001, P ACM SIGMOD C MAN D, P151, DOI 10.1145/375663.375680; *NIST EMATECH, 2003, E HDB STAT METH	62	70	76	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2007	15	2					107	144		10.1007/s10618-007-0064-z		38	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	202IC	WOS:000248894200001	
J	Qian, YH; Liang, JY; Pedrycz, W; Dang, CY				Qian, Yuhua; Liang, Jiye; Pedrycz, Witold; Dang, Chuangyin			Positive approximation: An accelerator for attribute reduction in rough set theory	ARTIFICIAL INTELLIGENCE			English	Article						Rough set theory; Attribute reduction; Decision table; Positive approximation; Granular computing	ORDERED INFORMATION-SYSTEMS; FEATURE-SELECTION; KNOWLEDGE REDUCTION; DECISION TABLES; GRANULATION; DIMENSIONALITY; DISCRETIZATION; UNCERTAINTY; ENTROPY; MODEL	Feature selection is a challenging problem in areas such as pattern recognition, machine learning and data mining. Considering a consistency measure introduced in rough set theory, the problem of feature selection, also called attribute reduction, aims to retain the discriminatory power of original features. Many heuristic attribute reduction algorithms have been proposed however, quite often, these methods are computationally time-consuming. To overcome this shortcoming, we introduce a theoretic framework based on rough set theory, called positive approximation, which can be used to accelerate a heuristic process of attribute reduction. Based on the proposed accelerator, a general attribute reduction algorithm is designed. Through the use of the accelerator, several representative heuristic attribute reduction algorithms in rough set theory have been enhanced. Note that each of the modified algorithms can choose the same attribute reduct as its original version, and hence possesses the same classification accuracy. Experiments show that these modified algorithms outperform their original counterparts. It is worth noting that the performance of the modified algorithms becomes more visible when dealing with larger data sets. (C) 2010 Elsevier B.V. All rights reserved.	[Qian, Yuhua; Liang, Jiye] Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan 030006, Shanxi, Peoples R China; [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada; [Qian, Yuhua; Dang, Chuangyin] City Univ Hong Kong, Dept Mfg Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China	Liang, JY (reprint author), Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan 030006, Shanxi, Peoples R China.	jinchengqyh@sxu.edu.cn; ljy@sxu.edu.cn; pedrycz@ee.ualberta.ca; mecdang@cityu.edu.hk	Liang, Jiye/G-6810-2011; Dang, Chuangyin/F-5964-2012		National Natural Science Foundation of China [60773133, 60903110, 70971080]; National Key Basic Research and Development Program of China (973) [2007CB311002]; Government of Hong Kong SAR [GRF: CityU 113308]; National High Technology Research and Development Program of China [2007AA01Z165]; Natural Science Foundation of Shanxi Province, China [2008011038, 2009021017-1]	This work was supported by the National Natural Science Foundation of China (Nos. 60773133, 60903110, 70971080), National Key Basic Research and Development Program of China (973) (No. 2007CB311002), GRF: CityU 113308 of the Government of Hong Kong SAR, the National High Technology Research and Development Program of China (No. 2007AA01Z165), and the Natural Science Foundation of Shanxi Province, China (Nos. 2008011038, 2009021017-1).	Bazan J., 1998, ROUGH SETS KNOWLEDGE, V1, P321; Bazan J.G., 2000, ROUGH SET METHODS AP, P49; Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P1632, DOI 10.1016/j.patrec.2005.01.006; Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; Duntsch I, 1998, ARTIF INTELL, V106, P109, DOI 10.1016/S0004-3702(98)00091-5; Gediga G, 2001, ARTIF INTELL, V132, P219, DOI 10.1016/S0004-3702(01)00147-3; Grzymala-Busse J. W., 1992, INTELLIGENT DECISION, P3; Grzymala-Busse J. W., 1991, MANAGING UNCERTAINTY, P66; Guan JW, 1998, ARTIF INTELL, V105, P77, DOI 10.1016/S0004-3702(98)00090-3; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086; Hu X H, 1995, INT J COMPUTATIONAL, V11, P323; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; Jensen R., 2008, COMPUTATIONAL INTELL; Kira K, 1992, P 10 NAT C ART INT, P129; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kryszkiewicz M, 2001, INT J INTELL SYST, V16, P105, DOI 10.1002/1098-111X(200101)16:1<105::AID-INT8>3.0.CO;2-S; Lasek P., 2008, T ROUGH SETS, V9, P76; Lee CK, 2006, INFORM PROCESS MANAG, V42, P155, DOI 10.1016/j.ipm.2004.08.006; Li DY, 2004, INT J UNCERTAIN FUZZ, V12, P651, DOI 10.1142/S0218488504003132; Liang JY, 2002, INT J GEN SYST, V31, P331, DOI 10.1080/0308107021000013635; Liang JY, 2005, LECT NOTES ARTIF INT, V3641, P701; Liang JY, 2002, INT J UNCERTAIN FUZZ, V10, P95, DOI 10.1142/S021848850200134X; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; [米据生 Mi Jusheng], 2003, [模糊系统与数学, Fuzzy Systems and Mathematics], V17, P54; Modrzejewski M., 1993, P EUR C MACH LEARN, P213; Nguyen HS, 2006, LECT NOTES COMPUT SC, V4100, P334; Pavlenko T, 2003, J STAT PLAN INFER, V115, P565, DOI 10.1016/S0378-3758(02)00166-0; Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pawlak Z, 2007, INFORM SCIENCES, V177, P41, DOI 10.1016/j.ins.2006.06.007; Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003; Pedrycz W, 2002, PATTERN RECOGN, V35, P825, DOI 10.1016/S0031-3203(01)00102-9; POLKOWSKI L, 1992, INTELLIGENT DECISION, V11, P305; Qian YH, 2008, FUZZY SET SYST, V159, P2353, DOI 10.1016/j.fss.2007.12.016; Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121; Qian YH, 2010, IEEE T SYST MAN CY A, V40, P420, DOI 10.1109/TSMCA.2009.2035436; Qian YH, 2009, INFORM SCIENCES, V179, P2809, DOI 10.1016/j.ins.2009.04.007; Qian YH, 2008, COMPUT MATH APPL, V55, P1754, DOI 10.1016/j.camwa.2007.08.031; Qian YH, 2008, INFORM SCIENCES, V178, P181, DOI 10.1016/j.ins.2007.08.010; Qian YH, 2008, COMPUT MATH APPL, V56, P1994, DOI 10.1016/j.camwa.2008.04.021; QUINLAN JR, 1986, MACH LEARN, V1, P106; Shao MW, 2005, INT J INTELL SYST, V20, P13, DOI 10.1002/int.20051; Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016; SKOWRON A, 1995, COMPUT INTELL, V11, P371, DOI 10.1111/j.1467-8640.1995.tb00039.x; Slezak D., 2000, IPMU 00, V1, P248; Slezak D, 2002, FUND INFORM, V53, P365; SLEZAK D, 1995, APPROXIMATE REDUCTS; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Wang Guo-Yin, 2002, Chinese Journal of Computers, V25; Wang GY, 2005, FUND INFORM, V68, P289; Wu S.X., 2004, J SYSTEM SCI INFORM, V2, P557; Wu WZ, 2005, INFORM SCIENCES, V174, P143, DOI 10.1016/j.ins.2004.09.002; Xu Zhang-Yan, 2006, Chinese Journal of Computers, V29; Yao YY, 2001, INT J INTELL SYST, V16, P87, DOI 10.1002/1098-111X(200101)16:1<87::AID-INT7>3.0.CO;2-S; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	60	69	86	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	JUN	2010	174	9-10					597	618		10.1016/j.artint.2010.04.018		22	Computer Science, Artificial Intelligence	Computer Science	603OZ	WOS:000278219200004	
J	Nguyen, TTT; Armitage, G				Nguyen, Thuy T. T.; Armitage, Grenville			A Survey of Techniques for Internet Traffic Classification using Machine Learning	IEEE COMMUNICATIONS SURVEYS AND TUTORIALS			English	Article						Traffic classification; Internet Protocol; Machine Learning; Real Time; Payload inspection; Flow clustering; Statistical traffic properties	SELECTION	The research community has begun looking for IP traffic classification techniques that do not rely on 'well known' TCP or UDP port numbers, or interpreting the contents of packet payloads. New work is emerging on the use of statistical traffic characteristics to assist in the identification and classification process. This survey paper looks at emerging research into the application of Machine Learning (ML) techniques to IP traffic classification - an inter-disciplinary blend of IP networking and data mining techniques. We provide context and motivation for the application of ML techniques to IP traffic classification, and review 18 significant works that cover the dominant period from 2004 to early 2007. These works are categorized and reviewed according to their choice of ML strategies and primary contributions to the literature. We also discuss a number of key requirements for the employment of ML-based traffic classifiers in operational IP networks, and qualitatively critique the extent to which the reviewed works meet these requirements. Open issues and challenges in the field are also discussed.	[Nguyen, Thuy T. T.; Armitage, Grenville] Swinburne Univ Technol, Ctr Adv Internet Architectures, Melbourne, Vic, Australia	Nguyen, TTT (reprint author), Swinburne Univ Technol, Ctr Adv Internet Architectures, Melbourne, Vic, Australia.	tnguyen@swin.edu.au; garmitage@swin.edu.au					Armitage G., 2000, QUALITY SERVICE IP N; Auld T, 2007, IEEE T NEURAL NETWOR, V18, P223, DOI 10.1109/TNN.2006.883010; Baker F., 2004, 3924 RFC; BERNAILLE L, 2006, ACM SPECIAL INTEREST, V36; Blake S., 1998, 2475 RFC IETF; BONFIGLIO D, 2007, SIGCOMM 07, P37; Braden R., 1994, 1633 RFC IETF; BURGSTAHLER L, 2003, RIPQOS 03, P121; BUT J, 2006, P 5 ANN WORKSH NETW; Carmichael O, 2004, IEEE T PATTERN ANAL, V26, P1537, DOI 10.1109/TPAMI.2004.128; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Claffy K., 1994, THESIS U CALIFORNIA; Crotti M, 2007, COMPUT COMMUN REV, V37, P5; DEMPSTER A, 1997, J ROYAL STAT SOC, V30; DEWES C, 2003, ACM SIGCOMM INT MEAS; Duda R.O., 2001, PATTERN CLASSIFICATI; ERMAN J, 2007, OFFLINE REALTIME NET; Erman J, 2007, PERF E R SI, V35, P369; Erman J., 2007, WWW 07, P883; Erman J., 2006, MINENET 06, P281; Erman J., 2006, P 49 IEEE GLOB TEL C; ERMAN J, 2007, MINENET 07, P35; FISHER HD, 1991, CONCEPT FORMATION KN; Frank J., 1994, P NAT 17 COMP SEC C; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Haffner P., 2005, MINENET 05, P197; Halkidi M, 2002, SIGMOD RECORD, V31, P19; Halkidi M, 2002, SIGMOD RECORD, V31, P40; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; KARAGIANNIS T, 2004, P 47 ANN IEEE GLOB T; KARAGIANNIS T, 2005, P SPEC INT GROUP DAT; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LANG T, 2004, P ACM SIGCHI INT C A; LANG T, 2003, P AUSTR TEL NETW APP; Ma J., 2006, IMC 06, P313; MADHUKAR A, 2006, 14 IEEE INT S MOD AN; McGregor A., 2004, P PASS ACT MEAS WORK; Moore A., 2005, ACM INT C MEAS MOD C; MOORE A, 2005, P PASS ACT MEAS WORK; Netmate, NETMATE; Nguyen T., 2006, P IEEE 31 C LOC COMP; NGUYEN T, 2006, P AUSTR TEL NETW APP, P293; Park J., 2006, IEEE INT C MULT EXP; Park J., 2006, P 2006 INT C INT INF; PAXSON V, 1994, IEEE ACM T NETWORK, V2, P316, DOI 10.1109/90.330413; Paxson V, 1999, COMPUT NETW, V31, P2435, DOI 10.1016/S1389-1286(99)00112-7; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; REICH Y, 1991, CONCEPT FORMATION KN; Roughan M., 2004, P ACM SIGCOMM INT ME; Schulzrinne H., 1996, 1889 RFC IETF, V1889; Sen S., 2004, WWW2004; SHI Z, 1992, PRINCIPLES MACHINE L; SILVER B, 1990, P 3 INT C IND ENG AP; SIMON H, 1983, MACHINE LEARNING ART; SNORT, DE FACT STAND INTR D; STEWART L, 2005, IEEE INT REG 10 C TE; University of Twente, TRAFF MEAS DAT REP; WILLIAMS N, 060410C CTR ADV INT; WILLIAMS N, 2006, SIGCOMM COMPUT COMMU, V36, P5; Winston P. H., 1984, ARTIFICIAL INTELLIGE; Witten IH, 2005, DATA MINING PRACTICA; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; Zander S., 2005, IEEE 30 C LOC COMP N; *BRO INTR DET SYST, BRO OV; *NLANR, TRAFF MEAS DAT REP; *UB INC, SOLV PERF PROBL INT	66	69	80	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1553-877X		IEEE COMMUN SURV TUT	IEEE Commun. Surv. Tutor.		2008	10	4					56	76		10.1109/SURV.2008.080406		21	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	V17YG	WOS:000207971900005	
J	Keerthi, SS; DeCoste, D				Keerthi, SS; DeCoste, D			A modified finite newton method for fast solution of large scale linear SVMs	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						linear SVMs; classification; conjugate gradient	LEAST-SQUARES; CLASSIFICATION	This paper develops a fast method for solving linear SVMs with L-2 loss function that is suited for large scale data mining tasks such as text classification. This is done by modifying the finite Newton method of Mangasarian in several ways. Experiments indicate that the method is much faster than decomposition methods such as SVMlight, SMO and BSVM (e.g., 4-100 fold), especially when the number of examples is large. The paper also suggests ways of extending the method to other loss functions such as the modified Huber's loss function and the L-1 loss function, and also for solving ordinal regression.	Yahoo Res Labs, Pasadena, CA 91105 USA	Keerthi, SS (reprint author), Yahoo Res Labs, 210 S Delacey Ave, Pasadena, CA 91105 USA.	SATHIYA.KEERTHI@OVERTURE.COM; DENNIS.DECOSTE@OVERTURE.COM					Bertsekas D.P., 1999, NONLINEAR PROGRAMMIN; BJORCK A, 1996, NUMERICAL METHODS LE; Blake C, 1998, UCI REPOSITORY MACHI; Chakrabarti S, 2003, VLDB J, V12, P170, DOI 10.1007/s00778-003-0098-9; CHU W, 2005, NEW APPROACHES SUPPO; DeCoste D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347165; Frommer A, 1999, SIAM J SCI COMPUT, V20, P1831, DOI 10.1137/S1064827596313310; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI 10.1145/502512.502527; Hsu CW, 2002, MACH LEARN, V46, P291, DOI 10.1023/A:1012427100071; Joachims T., 1999, ADV KERNEL METHODS S; Kao WC, 2004, NEURAL COMPUT, V16, P1689, DOI 10.1162/089976604774201640; Komarek P., 2004, THESIS CARNEGIE MELL; Mangasarian OL, 2002, OPTIM METHOD SOFTW, V17, P913, DOI 10.1080/1055678021000028375; McCallum A, 1996, BOW TOOLKIT STAT LAN; PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989; Platt J, 1999, ADV KERNEL METHODS S; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; ZHANG J, 2003, 20 INT C MACH LEARN, P472; Zhang T, 2004, ANN STAT, V32, P56	19	69	73	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	MAR	2005	6						341	361				21	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HG	WOS:000236329400004	
J	Liu, DR; Shih, YY				Liu, DR; Shih, YY			Integrating AHP and data mining for product recommendation based on customer lifetime value	INFORMATION & MANAGEMENT			English	Article						recommendation; marketing analytic hierarchy process (AHP); customer lifetime value; collaborative filtering; clustering; association rule mining	KNOWLEDGE; SUPPORT; WEB	Product recommendation is a business activity that is critical in attracting customers. Accordingly, improving the quality of a recommendation to fulfill customers' needs is important in fiercely competitive environments. Although various recommender systems have been proposed, few have addressed the lifetime value of a customer to a firm. Generally, customer lifetime value (CLV) is evaluated in terms of recency, frequency, monetary (RFM) variables. However, the relative importance among them varies with the characteristics of the product and industry. We developed a novel product recommendation methodology that combined group decision-making and data mining techniques. The analytic hierarchy process (AHP) was applied to determine the relative weights of RFM variables in evaluating customer lifetime value or loyalty. Clustering techniques were then employed to group customers according to the weighted RFM value. Finally, an association rule mining approach was implemented to provide product recommendations to each customer group. The experimental results demonstrated that the approach outperformed one with equally weighted RFM and a typical collaborative filtering (CF) method. (C) 2004 Elsevier B.V. All rights reserved.	Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan; MingHsin Univ Sci & Technol, Dept Informat Management, Hsinchu, Taiwan	Liu, DR (reprint author), Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan.	dliu@iim.nctu.edu.tw					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P INT C VER LARG DAT, P407; BERGER PD, 1998, J INTERACT MARK, V12, P17, DOI 10.1002/(SICI)1520-6653(199824)12:1<17::AID-DIR3>3.0.CO;2-K; Bose I, 2001, INFORM MANAGE-AMSTER, V39, P211, DOI 10.1016/S0378-7206(01)00091-X; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Bult JR, 1995, MARKET SCI, V14, P378, DOI 10.1287/mksc.14.4.378; Changchien SW, 2001, EXPERT SYST APPL, V20, P325, DOI 10.1016/S0957-4174(01)00017-3; Chen H C, 2001, P ACM C INF KNOWL MA, P231; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Goodman J., 1992, DIRECT MARKETING, V55, P26; Ha SH, 1998, EXPERT SYST APPL, V15, P1; Hill W, 1995, P ACM CHI 95 C HUM F, P194, DOI 10.1145/223904.223929; Hughes A. M., 1994, STRATEGIC DATABASE M; Hui SC, 2000, INFORM MANAGE-AMSTER, V38, P1, DOI 10.1016/S0378-7206(00)00051-3; IRVIN S, 1994, CREDIT WORLD, V82, P37; Kahan R., 1998, J CONSUMER MARKETING, V15, P491, DOI 10.1108/07363769810235965; Konstan J., 2000, P 2 ACM C EL COMM, P158, DOI DOI 10.1145/352871.352887; Lang K., 1995, P 12 INT C MACH LEAR, P331; Liang TP, 2002, INFORM MANAGE-AMSTER, V39, P431, DOI 10.1016/S0378-7206(01)00129-X; Lin QY, 2003, INFORM MANAGE-AMSTER, V40, P431, DOI 10.1016/S0378-7206(02)00062-9; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; Liu C, 2000, INFORM MANAGE, V38, P23, DOI 10.1016/S0378-7206(00)00049-5; MacQueen J.B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Miglautsch J. R., 2000, J DATABASE MARKETING, V8, P67, DOI 10.1057/palgrave.jdm.3240019; PEPPERS D, 1997, ONE ONE FUTURE BUILD; PUNJ G, 1983, J MARKETING RES, V20, P134, DOI 10.2307/3151680; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Rucker J, 1997, COMMUN ACM, V40, P73, DOI 10.1145/245108.245125; Saaty T.L., 1994, FUNDAMENTALS DECISIO; SALTON G, 1983, INTRO MODERN INFORMA; Schafer J.B., 2001, J DATA MINING KNOWLE, V5, P115; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Shaw MJ, 2001, DECIS SUPPORT SYST, V31, P127, DOI 10.1016/S0167-9236(00)00123-8; Srikant R., 1995, P 21 INT C VER LARG, P407; Stone B., 1995, SUCCESSFUL DIRECT MA; Stone RW, 2001, INFORM MANAGE, V38, P437, DOI 10.1016/S0378-7206(00)00080-X; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; Wells JD, 1999, INFORM MANAGE, V35, P53, DOI 10.1016/S0378-7206(98)00076-7	38	69	79	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-7206		INFORM MANAGE-AMSTER	Inf. Manage.	MAR	2005	42	3					387	400		10.1016/j.im.2004.01.008		14	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	877YE	WOS:000225611200001	
J	Kleinberg, J; Papadimitriou, C; Raghavan, P				Kleinberg, J; Papadimitriou, C; Raghavan, P			A microeconomic view of data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						market segmentation; optimization; clustering		We present a rigorous framework, based on optimization, for evaluating data mining operations such as associations and clustering, in terms of their utility in decision-making. This framework leads quickly to some interesting computational problems related to sensitivity analysis, segmentation and the theory of games.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA; IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Kleinberg, J (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Aumann Robert J, 1992, HDB GAME THEORY, V1; Avriel M., 1976, NONLINEAR PROGRAMMIN; Berry M. R. J., 1997, DATA MINING TECHNIQU; BRIN S, 1997, P ACM SIGMOD INT C M; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Dantzig G., 1963, LINEAR PROGRAMMING E; Derman C., 1970, FINITE STATE MARKOV; Gunopulos D., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263684; KLEINBERG J, 1998, P ACM S THEOR COMP; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; MASAND BM, 1996, P INT C KNOWL DISC D; Papadimitriou C.H., 1997, COMBINATORIAL OPTIMI; Piatetsky-Shapiro G., 1994, P AAAI 94 WORKSH KNO, P25; Silberschatz A., 1996, IEEE T KNOWLEDGE DAT, V8; SMYTH P, 1991, P INT C KNOWL DISC D, P159; Srikant R., 1995, P INT C VER LARG DAT; TOIVONEN H, 1996, P INT C VER LARG DAT	20	69	72	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1998	2	4					311	324		10.1023/A:1009726428407		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	182WA	WOS:000079520100001	
J	Guha, S; Rastogi, R; Shim, K				Guha, S; Rastogi, R; Shim, K			Cure: An efficient clustering algorithm for large databases	INFORMATION SYSTEMS			English	Article						data mining; knowledge discovery; clustering algorithms		Clustering, in data mining, is useful for discovering groups and identifying interesting distributions in the underlying data. Traditional clustering algorithms either favor clusters with spherical shapes and similar sizes, or are very fragile in the presence of outliers. We propose a new clustering algorithm called CURE that is more robust to outliers, and identifies clusters having non-spherical shapes and wide variances in size. CURE achieves this by representing each cluster by a certain fixed number of points that are generated by selecting well scattered points from the cluster and then shrinking them toward the center of the cluster by a specified fraction. Having more than one representative point per cluster allows CURE to adjust well to the geometry of non-spherical shapes and the shrinking helps to dampen the effects of outliers. To handle large databases, CURE employs a combination of random sampling and partitioning. A random sample drawn from the data set is first partitioned and each partition is partially clustered. The partial clusters are then clustered in a second pass to yield the desired clusters. Our experimental results confirm that the quality of clusters produced by CURE is much better than those found by existing algorithms. Furthermore, they demonstrate that random sampling and partitioning enable CURE to not only outperform existing algorithms but also to scale well for large databases without sacrificing clustering quality. (C) 2001 Published by Elsevier Science Ltd.	Stanford Univ, Stanford, CA 94305 USA; Bell Labs, Murray Hill, NJ 07974 USA; Korea Adv Inst Sci & Technol, Taejon 305701, South Korea; Adv Informat Technol Res Ctr, Taejon 305701, South Korea	Guha, S (reprint author), Stanford Univ, Stanford, CA 94305 USA.						BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Cormen T.H., 1990, INTRO ALGORITHMS; COXETER HSM, 1964, S PURE MATH, V7, P53; Ester M, 1996, INT C KNOWL DISC DAT, P226; ESTER M, 1995, INT C KNOWL DISC DAT, P94; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; HAN EH, 1997, 1997 SIGMOD WORKSH R, P9; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Motwani R., 1995, RANDOMIZED ALGORITHM; Ng R, 1994, P 20 INT C VER LARG, P144; Olson C.F., 1993, PARALLEL ALGORITHMS; Samet H., 1989, DESIGN ANAL SPATIAL; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	16	68	84	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	MAR	2001	26	1					35	58		10.1016/S0306-4379(01)00008-4		24	Computer Science, Information Systems	Computer Science	414WW	WOS:000167690000003	
J	Hui, SC; Jha, G				Hui, SC; Jha, G			Data mining for customer service support	INFORMATION & MANAGEMENT			English	Article						data mining; knowledge discovery in databases; customer service support; decision support; machine fault diagnosis	SYSTEM	In traditional customer service support of a manufacturing environment, a customer service database usually stores two types of service information: (1) unstructured customer service reports record machine problems and its remedial actions and (2) structured data on sales, employees, and customers for day-to-day management operations. This paper investigates how to apply data mining techniques to extract knowledge from the database to support two kinds of customer service activities: decision support and machine fault diagnosis. A data mining process, based on the data mining tool DBMiner, was investigated to provide structured management data for decision support. In addition, a data mining technique that integrates neural network, case-based reasoning, and rule-based reasoning is proposed; it would search the unstructured customer service records for machine fault diagnosis. The proposed technique has been implemented to support intelligent fault diagnosis over the World Wide Web. (C) 2000 Elsevier Science B.V. All rights reserved.	Nanyang Technol Univ, Sch Appl Sci, Singapore 639798, Singapore	Hui, SC (reprint author), Nanyang Technol Univ, Sch Appl Sci, Nanyang Ave, Singapore 639798, Singapore.	asschui@ntuvax.ntu.ac.sg					AAMODT A, 1994, AI COMMUN, V7, P39; Lent B., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Ahonen H, 1998, P IEEE INT FORUM RES, P2, DOI 10.1109/ADL.1998.670374; BALAKRISHNAN K, 1998, J INTELLIGENT SYSTEM, V8; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Breiman L, 1984, CLASSIFICATION REGRE; CHAUDHURI S., 1997, ACM SIGMOD RECORD, V26, P65, DOI 10.1145/248603.248616; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; EUSTACE R, 1995, P 8 INT C IND ENG AP, P67; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Fellbaum C., 1998, WORDNET ELECT LEXICA; HAN J, 1997, P CASCON 97 M MINDS; Han J, 1998, SIGMOD REC, V27, P97; HUGGETS KD, 1999, TOOLS SIFTWARE DATA; JHA G, 1999, THESIS NANYANG TECHN; Kohonen T., 1997, SPRINGER SERIES INFO, V30; LAGUS K, 1999, IN PRESS WEBSOM TEXT; Law YFD, 1997, EXPERT SYST APPL, V13, P265; LEES B, 1997, P 5 GERM WORKSH CAS, P139; Liu ZQ, 1997, IEEE T FUZZY SYST, V5, P209; PAPAGNI M, 1997, P 5 GERM WORKSH CAS, P181; Patterson D. W. R., 1997, New Review of Applied Expert Systems, V3; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Watson I.D, 1997, APPL CASE BASED REAS; *INF CORP, 1999, CBR CONT NAV	27	68	73	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-7206		INFORM MANAGE-AMSTER	Inf. Manage.	OCT	2000	38	1					1	13		10.1016/S0378-7206(00)00051-3		13	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	351XU	WOS:000089185800001	
J	Hung, SY; Yen, DC; Wang, HY				Hung, SY; Yen, DC; Wang, HY			Applying data mining to telecom chum management	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						chum management; wireless telecommunication; data mining; decision tree; neural network	ARTIFICIAL NEURAL-NETWORKS; PREDICTION	Taiwan deregulated its wireless telecommunication services in 1997. Fierce competition followed, and chum management becomes a major focus of mobile operators to retain subscribers via satisfying their needs under resource constraints. One of the challenges is chumer prediction. Through empirical evaluation, this study compares various data mining techniques that can assign a 'propensity-to-chum' score periodically to each subscriber of a mobile operator. The results indicate that both decision tree and neural network techniques can deliver accurate chum prediction models by using customer demographics, billing information, contract/service status, call detail records, and service change log. (c) 2005 Elsevier Ltd. All rights reserved.	Miami Univ, Dept DSC & MIS, Oxford, OH 45056 USA; Natl Chung Cheng Univ, Dept Informat Management, Chiayi 62117, Taiwan	Yen, DC (reprint author), Miami Univ, Dept DSC & MIS, 309 Upham, Oxford, OH 45056 USA.	syhung@mis.ccu.edu.tw; yendc@muoho.edu; HsiuYu.Wang@msa.hinet.net					Berson Alex, 2000, BUILDING DATA MINING; Bortiz J. E., 1995, EXPERT SYSTEMS APPL, V9, P503; CYBENCO H, 1998, MATH CONTROL CIGNAL, V2, P303; FLETCHER D, 1993, INFORM MANAGE, V24, P159, DOI 10.1016/0378-7206(93)90064-Z; KENTRIAS S, 2001, CUSTOMER RELATIONSHI; LANGLEY P, 1995, COMMUN ACM, V38, P55; Lariviere B, 2004, EXPERT SYST APPL, V27, P277, DOI 10.1016/j.eswa.2004.02.002; Lau HCW, 2003, KNOWL-BASED SYST, V16, P69, DOI 10.1016/S0950-7051(02)00052-7; Lejeune MAPM, 2001, INTERNET RES, V11, P375, DOI 10.1108/10662240110410183; Mattersion R., 2001, TELECOM CHURN MANAGE; SALCHENBERGER LM, 1992, DECISION SCI, V23, P899, DOI 10.1111/j.1540-5915.1992.tb00425.x; Su CT, 2002, J COMPUT INFORM SYST, V42, P61; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; THEALING K, 1999, DIRECT MARKETING MAG; Wei CP, 2002, EXPERT SYST APPL, V23, P103, DOI 10.1016/S0957-4174(02)00030-1; Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7; Zhang GQ, 1999, EUR J OPER RES, V116, P16, DOI 10.1016/S0377-2217(98)00051-4; *SAS I, 2000, BEST PRIC CHURN PRED	18	67	74	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	OCT	2006	31	3					515	524		10.1016/j.eswa.2005.09.080		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	059RP	WOS:000238750200007	
J	Lam, M				Lam, M			Neural network techniques for financial performance prediction: integrating fundamental and technical analysis	DECISION SUPPORT SYSTEMS			English	Article						neural networks; financial performance; forecasting; technical analysis; fundamental analysis; postprocessing techniques; data mining; rule extraction	NONLINEAR PREDICTABILITY; ECONOMIC VARIABLES	This research project investigates the ability of neural networks, specifically, the backpropagation algorithm, to integrate fundamental and technical analysis for financial performance prediction. The predictor attributes include 16 financial statement variables and 11 macroeconomic variables. The rate of return on common shareholders' equity is used as the to-be-predicted variable. Financial data of 364 S&P companies are extracted from the CompuStat database, and macroeconomic variables are extracted from the Citibase database for the study period of 1985-1995. Used as predictors in Experiments 1, 2, and 3 are the 1 year's, the 2 years', and the 3 years' financial data, respectively. Experiment 4 has 3 years' financial data and macroeconomic data as predictors. Moreover, in order to compensate for data noise and parameter misspecification as well as to reveal prediction logic and procedure, we apply a rule extraction technique to convert the connection weights from trained neural networks to symbolic classification rules. The performance of neural networks is compared with the average return from the top one-third returns in the market (maximum benchmark) that approximates the return from perfect information as well as with the overall market average return (minimum benchmark) that approximates the return from highly diversified portfolios. Paired t tests are carried out to calculate the statistical significance of mean differences. Experimental results indicate that neural networks using I year's or multiple years' financial data consistently and significantly outperform the minimum benchmark, but not the maximum benchmark. As for neural networks with both financial and macroeconomic predictors, they do not outperform the minimum or maximum benchmark in this study. The experimental results also show that the average return of 0.25398 from extracted rules is the only compatible result to the maximum benchmark of 0.2786. Consequentially, we demonstrate rule extraction as a postprocessing technique for improving prediction accuracy and for explaining the prediction logic to financial decision makers. (C) 2003 Elsevier B.V. All rights reserved.	Calif State Univ Sacramento, Coll Business Adm, Sacramento, CA 95819 USA	Lam, M (reprint author), Calif State Univ Sacramento, Coll Business Adm, 6000 J St, Sacramento, CA 95819 USA.	lamsm@csus.edu					Andrews R., 1994, P 5 AUSTR C NEUR NET, P9; Cheng W., 1997, REV BUSINESS     SUM, P4; Dixit A., 1994, INVESTMENT UNDER UNC; Dropsy V., 1996, J APPL BUSINESS RES, V12, P120; Dutta S., 1988, P IEEE INT C NEURAL, V2, P443; ELTON EJ, 1995, MODERN PORTFOLIO THE; FISHER KL, 1984, SUPER STOCKS; Frankel JA, 1995, FINANCIAL MARKETS MO; FREEMAN JD, 1992, FINANCIAL ANAL J, V48, P26, DOI 10.2469/faj.v48.n6.26; FU LM, 1991, P 9 NAT C ART INT, P500; GALLANT SI, 1988, COMMUN ACM, V31, P152, DOI 10.1145/42372.42377; Gupta A, 1999, IEEE T KNOWL DATA EN, V11, P985, DOI 10.1109/69.824621; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; JENSEN MC, 1969, J BUS, V42, P167, DOI 10.1086/295182; Kiang M. Y., 1993, J MANAGE INFORM SYST, V9, P59; KRYZANOWSKI L, 1993, FINANCIAL ANAL J JUL, P21; Leigh W, 2002, DECIS SUPPORT SYST, V32, P361, DOI 10.1016/S0167-9236(01)00121-X; Lin F. C., 1993, AI EXPERT        FEB, P36; Meyers T.A., 1989, TECHNICAL ANAL COURS; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; ONEIL WJ, 1995, HOW MAKE MONEY STOCK; OU JA, 1990, J ACCOUNTING RES, V28, P144, DOI 10.2307/2491220; Pring M. J., 1980, TECHNICAL ANAL EXPLA; Qi M, 1999, J BUS ECON STAT, V17, P419, DOI 10.2307/1392399; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Racine J, 2001, J BUS ECON STAT, V19, P380, DOI 10.1198/073500101681019927; Reinganum M.R., 1988, FINANCIAL ANAL J MAR, P16; RITCHIE J, 1989, FUNDAMENTAL ANAL BAC; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Saito K., 1988, P IEEE INT C NEURAL, V1, P255; SESITO S, 1994, AUTOMATED KNOWLEDGE; Lu HJ, 1996, IEEE T KNOWL DATA EN, V8, P957; Shah J.R., 2000, AM BUSINESS REV, V18, P80; SHARPE WF, 1966, J BUS, V39, P119, DOI 10.1086/294846; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Tang Z., 1990, P 1 WORKSH NEUR NETW, P95; Thomsett MC, 1999, MASTERING TECHNICAL; THRUN SB, 1994, IAITR935; TOWELL GG, 1992, ADV NEURAL INFORMATI, V4; TREYNOR JL, 1965, HARVARD BUS REV, V43, P63; Trippi R., 1992, J PORTFOLIO MANA FAL, P27; TSO L, 1965, TECHNIQUES UNCOVERIN; Walczak S, 2001, J MANAGE INFORM SYST, V17, P203; Walczak S, 1999, INFORM SOFTWARE TECH, V41, P107, DOI 10.1016/S0950-5849(98)00116-5; White H, 1988, P IEEE INT C NEUR NE, P451, DOI DOI 10.1109/ICNN.1988.23959; WHITE H, 1981, J AM STAT ASSOC, V76, P419, DOI 10.2307/2287845	46	67	69	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	SEP	2004	37	4					567	581		10.1016/S0167-9236(03)00088-5		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	828HD	WOS:000221963500010	
J	Hagenbuchner, M; Sperduti, A; Tsoi, AC				Hagenbuchner, M; Sperduti, A; Tsoi, AC			A self-organizing map for adaptive processing of structured data	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						clustering; data mining which involves novel types of data/knowledge; data reduction techniques; discovering similarities; innovative algorithms; processing labeled graphs; recurrent neural networks; recursive neural networks; self organizing maps (SOMs); vector quantization (VQ)	RECURSIVE NEURAL NETWORKS; TREE AUTOMATA; CLASSIFICATION	Recent developments in the area of neural networks produced models capable of dealing with structured data. Here, we propose the first fully unsupervised model, namely,an extension of traditional self-organizing maps (SOMs)., for the processing of labeled directed acyclic graphs,(DAGs). The extension is obtained by using the unfolding procedure Adopted in recurrent, and recursive,neural:networks, with the replicated neurons in the unfolded network comprising of a full SOM. This approach enables the discovery of similarities among objects including vectors consisting of numerical data. The capabilities of the model are analyzed in detail by utilizing a relatively large data set, taken from an artificial benchmark problem involving visual Patterns encoded as labeled DAGs. The experimental. results demonstrate clearly that the proposed model, is capable of exploiting both information conveyed in the labels Attached to each node of the input DAGs And information encoded in the DAG topology.	Univ Wollongong, Fac Informat, Wollongong, NSW 2522, Australia; Univ Padua, Dipartimento Matemat Pura & Applicata, I-35122 Padua, Italy; Univ Wollongong, Off Pro Vice Chancellor, Wollongong, NSW 2500, Australia	Hagenbuchner, M (reprint author), Univ Wollongong, Fac Informat, Wollongong, NSW 2522, Australia.						BIANUCCI AM, 2000, APPL INTELL, V12, P115; Carrasco RC, 2001, IEEE T KNOWL DATA EN, V13, P148, DOI 10.1109/69.917555; CHAPPELL GJ, 1993, NEURAL NETWORKS, V6, P441, DOI 10.1016/0893-6080(93)90011-K; Cormen T.H., 1990, INTRO ALGORITHMS; COSTA F, IN PRESS APPL INTELL; DILIGENTI M, 1998, P INT C ADV PATT REC, P425; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; ELMAN JL, 1988, 8801 CRL; FRANCESCONI E, 1997, GRAPHICS RECOGNITION, V1389, P104; FRASCONI P, P EUR C ART INT, P301; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; FRASCONI P, 1997, P INT JOINT C ART IN, P1066; GOLLER C, 1997, THESIS TU MUNICH MUN; GOLLER C, 1996, P IEEE INT C NEUR NE, P347; GOLLER C, 1999, P INT JOINT C NEUR N, P425; Gori M, 1999, IEEE T NEURAL NETWOR, V10, P1305, DOI 10.1109/72.809076; Hagenbuchner M, 2001, ADVANCES IN SELF-ORGANISING MAPS, P21; Hammer B, 1999, MATH CONTROL SIGNAL, V12, P62, DOI 10.1007/PL00009845; Hammer B, 2001, IEEE T KNOWL DATA EN, V13, P196, DOI 10.1109/69.917560; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kohonen T., 1995, SELF ORG MAPS, V30; KOHONEN T, 1990, SELF ORG ASSOCIATIV; Micheli A, 2001, J CHEM INF COMP SCI, V41, P202, DOI 10.1021/ci0000399; MICHELI A, 2001, P INT JOINT C NEUR N, V4, P2732; SCHMITT T, 1998, RELATING CHEM STRUCT; Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108; SPERDUTI A, 1996, LECT NOTES COMPUTER, V1121, P90; Sperduti A, 2000, KNOWLEDGE-BASED NEUROCOMPUTING, P117; Sperduti A, 1997, NEURAL NETWORKS, V10, P395; Van Hulle M., 2000, FAITHFUL REPRESENTAT; Varsta M., 1997, P 7 INT C ART NEUR N, P421; Villmann T, 1997, IEEE T NEURAL NETWOR, V8, P256, DOI 10.1109/72.557663; VOEGTLIN T, 2000, P IJCNN 2000, V6, P20	33	67	68	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2003	14	3					491	505		10.1109/TNN.2003.810735		15	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	680LU	WOS:000182980300003	
J	Yeung, DY; Ding, YX				Yeung, DY; Ding, YX			Host-based intrusion detection using dynamic and static behavioral models	PATTERN RECOGNITION			English	Article						anomaly detection; computer security; data mining; hidden Markov model; intrusion detection; maximum likelihood; minimum cross entropy; profiling; shell command; system call	MINIMUM CROSS-ENTROPY; AXIOMATIC DERIVATION; NOVELTY DETECTION; MAXIMUM-ENTROPY; PRINCIPLE	Intrusion detection has emerged as an important approach to network security. In this paper, we adopt an anomaly detection approach by detecting possible intrusions based on program or user profiles built from normal usage data. In particular, program profiles based on Unix system calls and user profiles based on Unix shell commands are modeled using two different types of behavioral models for data mining. The dynamic modeling approach is based on hidden Markov models (HMM) and the principle of maximum likelihood, while the static modeling approach is based on event occurrence frequency distributions and the principle of minimum cross entropy. The novelty detection approach is adopted to estimate the model parameters using normal training data only, as opposed to the classification approach which has to use both normal and intrusion data for training. To determine whether or not a certain behavior is similar enough to the normal model and hence should be classified as normal, we use a scheme that can be justified from the perspective of hypothesis testing. Our experimental results show that the dynamic modeling approach is better than the static modeling approach for the system call datasets, while the dynamic modeling approach is worse for the shell command datasets. Moreover, the static modeling approach is similar in performance to instance-based learning reported previously by others for the same shell command database but with much higher computational and storage requirements than our method. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Yeung, DY (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.	dyyeung@cs.ust.hk					BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BISHOP CM, 1994, IEE P-VIS IMAGE SIGN, V141, P217, DOI 10.1049/ip-vis:19941330; Cohen P., 1995, EMPIRICAL METHODS AR; DAUNICHT WJ, 1991, SCIENCE, V253, P1289, DOI 10.1126/science.1891718; Debar H, 1999, COMPUT NETW, V31, P805, DOI 10.1016/S1389-1286(98)00017-6; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; Duda R.O., 2001, PATTERN CLASSIFICATI; Endler D., 1998, Proceedings 14th Annual Computer Security Applications Conference (Cat. No.98EX217), DOI 10.1109/CSAC.1998.738647; Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675; GUNETTI D, 1999, P 3 INT S INT DAT AN, P383; HELMER G. G., 1998, P IEEE INF TECHN C S, P121; JAPKOWICZ J, 1995, P 14 INT JOINT C ART, V1, P518; JOHNSON RW, 1983, IEEE T INFORM THEORY, V29, P942, DOI 10.1109/TIT.1983.1056747; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lane T., 1998, P 5 ACM C COMP COMM, P150, DOI 10.1145/288090.288122; Lane T., 1999, P IJCAI 99 WORKSH LE, P35; Lane T, 1999, ACM T INFORM SYST, V2, P295, DOI 10.1145/322510.322526; Lee W, 1998, PROCEEDINGS OF THE SEVENTH USENIX SECURITY SYMPOSIUM, P79; Lee W, 1999, P IEEE S SECUR PRIV, P120; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ryan J, 1998, ADV NEUR IN, V10, P943; Schonlau M, 2000, INFORM PROCESS LETT, V76, P33, DOI 10.1016/S0020-0190(00)00122-8; SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144; Warrender C, 1999, P IEEE S SECUR PRIV, P133, DOI 10.1109/SECPRI.1999.766910	25	67	76	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JAN	2003	36	1					229	243		10.1016/S0031-3203(02)00026-2		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	612XP	WOS:000179101000020	
J	Li, TR; Ruan, D; Geert, W; Song, J; Xu, Y				Li, Tianrui; Ruan, Da; Geert, Wets; Song, Jing; Xu, Yang			A rough sets based characteristic relation approach for dynamic attribute generalization in data mining	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	International Conference on Intelligent Systems and Knowledge Engineering	APR 06-07, 2006	Shanghai, PEOPLES R CHINA	China Flanders Project, Natl Nat Sci Fdn China, K C Wong Educ Fdn, Shanghai White Yulan Fdn Sci Technol Commiss, Shanghai Int Culture Assoc		rough sets; knowledge discovery; data mining; incomplete information systems	INCOMPLETE INFORMATION; FEATURE-SELECTION; RULES; MODEL	Any attribute set in an information system may be evolving in time when new information arrives. Approximations of a concept by rough set theory need updating for data mining or other related tasks. For incremental updating approximations of a concept, methods using the tolerance relation and similarity relation have been previously studied in literature. The characteristic relation-based rough sets approach provides more informative results than the tolerance-and-similarity relation based approach. In this paper, an attribute generalization and its relation to feature selection and feature extraction are firstly discussed. Then, a new approach for incrementally updating approximations of a concept is presented under the characteristic relation-based rough sets. Finally, the approach of direct computation of rough set approximations and the proposed approach of dynamic maintenance of rough set approximations are employed for performance comparison. An extensive experimental evaluation on a large soybean database from MLC shows that the proposed approach effectively handles a dynamic attribute generalization in data mining. (C) 2007 Elsevier B.V. All rights reserved.	SW Jiaotong Univ, Dept Math, Chengdu 610031, Peoples R China; CEN SCK, Belgian Nucl Res Ctr, B-2400 Mol, Belgium; Univ Ghent, Dept Appl Math & Comp Sci, B-9000 Ghent, Belgium; Univ Hasselt, Dept Appl Econ Sci, B-3590 Diepenbeek, Belgium	Li, TR (reprint author), SW Jiaotong Univ, Dept Math, Chengdu 610031, Peoples R China.	trli@swjtu.edu.cn; druan@sckcen.be; geert.wets@uhasselt.be; jesen811206@126.com; xuyang@home.swjtu.edu.cn	Li, Tianrui/A-4889-2012				Chan C. C., 1998, INFORM SCI, V107, P177; Chang Li-Yun, 1999, Journal of Software, V10; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Depren O, 2005, EXPERT SYST APPL, V29, P713, DOI 10.1016/j.eswa.2005.05.002; Dy JG, 2004, J MACH LEARN RES, V5, P845; Fakih SJ, 2006, IEEE T INF TECHNOL B, V10, P220, DOI 10.1109/TITB.205.855538; GRZYMALABUSSE JW, 2004, INT C INF PROC MAN U, P923; Grzymala-Busse J.W., 2005, T ROUGH SETS, VIV, P58; Hall M.A, 1999, THESIS WAIKATO U NZ; Hong TP, 2002, EXPERT SYST APPL, V22, P285, DOI 10.1016/S0957-4174(02)00016-7; KITTLER J, 1986, HDB PATTERN RECOGNIT, P203; Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1; Kusiak A, 2001, IEEE T ELECTRON PA M, V24, P44, DOI 10.1109/6104.924792; Kusiak A, 2000, IEEE T ELECTRON PA M, V23, P345, DOI 10.1109/6104.895081; LI T, 2003, INT C MACH LEARN CYB, P1678; LI T, 2004, INT C N AM FUZZ INF, P446; Li Tianrui, 2000, Journal of Southwest Jiaotong University (English Edition), V8; Lingras PJ, 1998, J AM SOC INFORM SCI, V49, P415, DOI 10.1002/(SICI)1097-4571(19980415)49:5<415::AID-ASI4>3.3.CO;2-Q; LIU Q, 1999, J COMPUTER RES DEV, V36, P800; PAWLAK Z, 1995, COMMUN ACM, V38, P89; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pearson R. K., 2006, SIGKDD EXPLORATIONS, V8, P83; Peters JF, 2003, PATTERN RECOGN LETT, V24, P911, DOI 10.1016/S0167-8655(02)00203-9; Polkowski L., 2000, ROUGH SET METHODS AP; Radzikowska A.M., 2002, FUZZY SETS SYSTEMS, V126, P137, DOI 10.1016/S0165-0114(01)00032-X; SHANG C, 2005, INT J COMPUTATIONAL, V1, P68; Stefanowski J, 2001, COMPUT INTELL, V17, P545, DOI 10.1111/0824-7935.00162; Stefanowski J, 1999, LECT NOTES ARTIF INT, V1711, P73; Tsumoto S, 2004, INFORM SCIENCES, V162, P65, DOI 10.1016/j.ins.2004.03.002; Yao JT, 2005, LECT NOTES ARTIF INT, V3641, P204; Zheng Z, 2004, FUND INFORM, V59, P299	31	66	76	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	JUN	2007	20	5					485	494		10.1016/j.knosys.2007.01.002		10	Computer Science, Artificial Intelligence	Computer Science	186EP	WOS:000247762200006	
J	Cheng, JL; Sweredoski, MJ; Baldi, P				Cheng, JL; Sweredoski, MJ; Baldi, P			Accurate prediction of protein disordered regions by mining protein structure data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						protein structure prediction; disordered regions; recursive neural networks	SECONDARY STRUCTURE	Intrinsically disordered regions in proteins are relatively frequent and important for our understanding of molecular recognition and assembly, and protein structure and function. From an algorithmic standpoint, flagging large disordered regions is also important for ab initio protein structure prediction methods. Here we first extract a curated, non-redundant, data set of protein disordered regions from the Protein Data Bank and compute relevant statistics on the length and location of these regions. We then develop an ab initio predictor of disordered regions called DISpro which uses evolutionary information in the form of profiles, predicted secondary structure and relative solvent accessibility, and ensembles of 1D-recursive neural networks. DISpro is trained and cross validated using the curated data set. The experimental results show that DISpro achieves an accuracy of 92.8% with a false positive rate of 5%. DISpro is a member of the SCRATCH suite of protein data mining tools available through http://www.igb.uci.edu/servers/psss.html.	Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA	Cheng, JL (reprint author), Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA.	pfbaldi@ics.uci.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Bengio Y, 1996, IEEE T NEURAL NETWOR, V7, P1231, DOI 10.1109/72.536317; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Dunker AK, 2002, BIOCHEMISTRY-US, V41, P6573, DOI 10.1021/bi012159+; Frasconi P, 2002, P IEEE WORKSH NEUR N, P25, DOI 10.1109/NNSP.2002.1030014; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; LI X, 1999, GENOME INFORM, V42, P389; Linding R, 2003, STRUCTURE, V11, P1453, DOI 10.1016/j.str.2003.10.002; Mika S, 2003, NUCLEIC ACIDS RES, V31, P3789, DOI 10.1093/nar/gkg620; POLLASTRI G, 2001, PROTEINS, V47, P142; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; PRZYBYLSKI D, 2002, PROTEIN-STRUCT FUNCT, V46, P195; Ward JJ, 2004, J MOL BIOL, V337, P635, DOI 10.1016/j.jmb.2004.02.002; WOOTTON JC, 1994, COMPUT CHEM, V18, P269, DOI 10.1016/0097-8485(94)85023-2; Wright PE, 1999, J MOL BIOL, V293, P321, DOI 10.1006/jmbi.1999.3110	17	66	73	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2005	11	3					213	222		10.1007/s10618-005-0001-y		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	990GZ	WOS:000233732500001	
J	Li, LH; Tang, H; Wu, ZB; Gong, JL; Gruidl, M; Zou, J; Tockman, M; Clark, RA				Li, LH; Tang, H; Wu, ZB; Gong, JL; Gruidl, M; Zou, J; Tockman, M; Clark, RA			Data mining techniques for cancer detection using serum proteomic profiling	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						proteomics; cancer; detection; data mining; statistical testing; genetic algorithm; support vector machine	PROTEIN EXPRESSION PROFILES; MASS-SPECTROMETRY; OVARIAN-CANCER; PROSTATE-CANCER; BIOMARKER DISCOVERY; BREAST-CANCER; IDENTIFICATION; MARKERS; CLASSIFICATION; PATTERN	Objective: Pathological changes in an organ or tissue may be reflected in proteomic patterns in serum. It is possible that unique serum proteomic patterns could be used to discriminate cancer samples from non-cancer ones. Due to the complexity of proteomic profiling, a higher order analysis such as data mining is needed to uncover the differences in complex proteomic patterns. The objectives of this paper are (1) to briefly review the application of data mining techniques in proteomics for cancer detection/diagnosis; (2) to explore a novel analytic method with different feature selection methods; (3) to compare the results obtained on different datasets and that reported by Petricoin et al. in terms of detection performance and selected proteomic patterns. Methods and material: Three serum SELDI MS data sets were used in this research to identify serum proteomic patterns that distinguish the serum of ovarian cancer cases from non-cancer controls. A support vector machine-based method is applied in this study, in which statistical testing and genetic algorithm-based methods are used for feature selection respectively. Leave-one-out cross validation with receiver operating characteristic (ROC) curve is used for evaluation and comparison of cancer detection performance. Results and conclusions: The results showed that (1) data mining techniques can be successfully applied to ovarian cancer detection with a reasonably high performance; (2) the classification using features selected by the genetic algorithm consistently outperformed those selected by statistical testing in terms of accuracy and robustness; (3) the discriminatory features (proteomic patterns) can be very different from one selection method to another. In other words, the pattern selection and its classification efficiency are highly classifier dependent. Therefore, when using data mining techniques, the discrimination of cancer from normal does not depend solely upon the identity and origination of cancer-related proteins. (C) 2004 Elsevier B.V. All rights reserved.	Univ S Florida, Coll Med, Dept Radiol, H Lee Moffitt Canc Ctr & Res Inst, Tampa, FL 33612 USA; Univ S Florida, Dept Interdiciplinary Oncol, H Lee Moffitt Canc Ctr & Res Inst, Tampa, FL 33612 USA	Li, LH (reprint author), Univ S Florida, Coll Med, Dept Radiol, H Lee Moffitt Canc Ctr & Res Inst, 12901 Bruce B Downs Blvd,MDC 17, Tampa, FL 33612 USA.	lilh@moffitt.usf.edu					Adam BL, 2002, CANCER RES, V62, P3609; Adam BL, 2001, PROTEOMICS, V1, P1264, DOI 10.1002/1615-9861(200110)1:10<1264::AID-PROT1264>3.0.CO;2-R; Alaiya AA, 2000, ELECTROPHORESIS, V21, P1210, DOI 10.1002/(SICI)1522-2683(20000401)21:6<1210::AID-ELPS1210>3.3.CO;2-J; Alaiya AA, 2002, INT J CANCER, V98, P895, DOI 10.1002/ijc.10288; Bakhtiar R, 2001, MOL PHARMACOL, V60, P405; Bakhtiar R, 2000, MUTAGENESIS, V15, P415, DOI 10.1093/mutage/15.5.415; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Banks RE, 2000, LANCET, V356, P1749, DOI 10.1016/S0140-6736(00)03214-1; Bergman AC, 2000, ELECTROPHORESIS, V21, P679, DOI 10.1002/(SICI)1522-2683(20000201)21:3<679::AID-ELPS679>3.3.CO;2-1; Cazares LH, 2002, CLIN CANCER RES, V8, P2541; Celis JE, 2000, FEBS LETT, V480, P2, DOI 10.1016/S0014-5793(00)01771-3; Chambers G, 2000, J PATHOL, V192, P280, DOI 10.1002/1096-9896(200011)192:3<280::AID-PATH748>3.0.CO;2-L; Cristianini N., 2000, INTRO SUPPORT VECTOR; Hlavaty JJ, 2001, CLIN CHEM, V47, P1924; HONG T, 2003, THESIS U S FLORIDA; Jones MB, 2002, PROTEOMICS, V2, P76, DOI 10.1002/1615-9861(200201)2:1<76::AID-PROT76>3.3.CO;2-F; Li JN, 2002, CLIN CHEM, V48, P1296; Liu H., 1998, FEATURE SELECTION KN; McDonald WH, 2002, DIS MARKERS, V18, P99; PAWELETZ CP, UROLOGY S4A, V57, P160; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Poon TCW, 2001, CLIN CHIM ACTA, V313, P231, DOI 10.1016/S0009-8981(01)00677-5; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; Qu YS, 2002, CLIN CHEM, V48, P1835; Sauter ER, 2002, BRIT J CANCER, V86, P1440, DOI 10.1038/sj/bjc/6600285; SCHMID HR, 1995, ELECTROPHORESIS, V16, P1961, DOI 10.1002/elps.11501601322; SKATES SJ, 1995, CANCER, V76, P2004, DOI 10.1002/1097-0142(19951115)76:10+<2004::AID-CNCR2820761317>3.0.CO;2-G; Srinivas PR, 2001, CLIN CHEM, V47, P1901; Valerio A, 2001, RAPID COMMUN MASS SP, V15, P2420, DOI 10.1002/rcm.528; Vapnik V. N., 1998, STAT LEARNING THEORY; WATKINS B, 2001, AM LAB           JUN, P32; WOOLAS RP, 1993, J NATL CANCER I, V85, P1748, DOI 10.1093/jnci/85.21.1748; Wulfkuhle JD, 2001, PROTEOMICS, V1, P1205, DOI 10.1002/1615-9861(200110)1:10<1205::AID-PROT1205>3.3.CO;2-O; Wulfkuhle JD, 2003, NAT REV CANCER, V3, P267, DOI 10.1038/nrc.1043; Yang J., 1998, FEATURE EXTRACTION C; YATES JR, TRENDS GENET, V16, P5	37	66	75	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	OCT	2004	32	2					71	83		10.1016/j.artmed.2004.03.006		13	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	857SN	WOS:000224138700001	
S	Ankerst, M; Kastenmuller, G; Kriegel, HP; Seidl, T		Guting, RH; Papadias, D; Lochovsky, F		Ankerst, M; Kastenmuller, G; Kriegel, HP; Seidl, T			3D shape histograms for similarity search and classification in spatial databases	ADVANCES IN SPATIAL DATABASES	Lecture Notes in Computer Science		English	Article; Proceedings Paper	6th International Symposium on Spatial Databases (SSD 99)	JUL 20-23, 1999	HONG KONG, PEOPLES R CHINA	Environm Syst Res Inst, Oracle Corp, IEEE HK Chapter, Sino Software Res Inst, Dept Comp Sci, HKUST, ACM SIGMOD, US Natl Ctr Geog Informat & Anal		3D shape similarity search; quadratic form distance functions; spatial data mining; nearest neighbor classification	PROTEIN	Classification is one of the basic tasks of data mining in modem database applications including molecular biology, astronomy, mechanical engineering, medical imaging or meteorology. The underlying models have to consider spatial properties such as shape or extension as well as thematic attributes. We introduce 3D shape histograms as an intuitive and powerful similarity model for 3D objects. Particular flexibility is provided by using quadratic form distance functions in order to account for errors of measurement, sampling, and numerical rounding that all may result in small displacements and rotations of shapes. For query processing, a general filter-refinement architecture is employed that efficiently supports similarity search based on quadratic forms. An experimental evaluation in the context of molecular biology demonstrates both, the high classification accuracy of more than 90% and the good performance of the approach.	Univ Munich, Inst Comp Sci, D-80538 Munich, Germany	Ankerst, M (reprint author), Univ Munich, Inst Comp Sci, Oettingenstr 67, D-80538 Munich, Germany.	ankerst@dbs.informatik.uni-muenchen.de; kastenmu@dbs.informatik.uni-muenchen.de; kriegel@dbs.informatik.uni-muenchen.de; seidl@dbs.informatik.uni-muenchen.de					Ankerst M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ankerst M, 1998, IEEE T KNOWL DATA EN, V10, P996, DOI 10.1109/69.738362; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; BERCHTOLD S, 1997, P ACM SIGMOD INT C M, P564, DOI 10.1145/253260.253407; BERCHTOLD S, 1997, SERIES INFORMATIK AK, P152; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Berchtold S., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263671; Berchtold S., 1997, VLDB Journal, V6, DOI 10.1007/s007780050049; BERCHTOLD S, 1997, THESIS U MUNICH AACH; BERCHTOLD S, 1997, P ACM SIGMOD INT C M, P1, DOI 10.1145/253260.253263; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, DOI 10.1007/BF00962238; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; GARY JE, 1993, INFORM SYST, V18, P525, DOI 10.1016/0306-4379(93)90005-L; Guttman A., 1984, P ACM SIGMOD INT C M, P47; HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417; Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83; HOLM L, 1994, NUCLEIC ACIDS RES, V22, P3600; Holm L, 1998, NUCLEIC ACIDS RES, V26, P316, DOI 10.1093/nar/26.1.316; JAGADISH HV, 1991, P ACM SIGMOD INT C M, P208, DOI 10.1145/115790.115821; KASTENMULLER G, 1998, THESIS U MUNICH; Korn F, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P215; Kriegel H.-P., 1998, GeoInformatica, V2, DOI 10.1023/A:1009760031965; Kriegel HP, 1997, LECT NOTES COMPUT SC, V1262, P11; Kriegel H.-P., 1998, P ACM SIGMOD INT C M, P154, DOI 10.1145/276304.276319; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LAMDAN Y., 1988, P IEEE INT C COMP VI, P238; Mitchell T. M, 1997, MACHINE LEARNING; Orengo CA, 1997, STRUCTURE, V5, P1093, DOI 10.1016/S0969-2126(97)00260-8; Samet H., 1990, DESIGN ANAL SPATIAL; Seidl T, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P506; Seidl T, 1995, LECT NOTES COMPUT SC, V951, P240; SEIDL T, 1997, THESIS U MUNICH; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; Taubin G, 1991, SPIE C GEOM METH COM, V1570, P175; Taylor C.C., 1994, MACHINE LEARNING NEU; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases	38	66	68	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-66247-2	LECT NOTES COMPUT SC			1999	1651						207	226				20	Computer Science, Information Systems	Computer Science	BQ22W	WOS:000087625200014	
J	Wu, WZ				Wu, Wei-Zhi			Attribute reduction based on evidence theory in incomplete decision systems	INFORMATION SCIENCES			English	Article						attribute reduction; belief functions; incomplete information systems; information systems; reducts; rough sets	ROUGH SET APPROACH; DEMPSTER-SHAFER THEORY; INFORMATION-SYSTEMS; KNOWLEDGE REDUCTION; INCONSISTENT SYSTEMS; RULES; MODEL; ACQUISITION; CONSISTENT; VALUES	Attribute reduction is a basic issue in knowledge representation and data mining. This paper deals with attribute reduction in incomplete information systems and incomplete decision systems based on Dempster-Shafer theory of evidence. The concepts of plausibility reduct and belief reduct in incomplete information systems as well as relative plausibility reduct and relative belief reduct in incomplete decision systems are introduced. It is shown that in an incomplete information system an attribute set is a belief reduct if and only if it is a classical reduct and a plausibility consistent set must be a classical consistent set. In a consistent incomplete decision system, the concepts of relative reduct, relative plausibility reduct, and relative belief reduct are all equivalent. In an inconsistent incomplete decision system, an attribute set is a relative plausibility reduct if and only if it is a relative reduct, a plausibility consistent set must be a belief consistent set, and a belief consistent set is not a plausibility consistent set in general. (C) 2007 Elsevier Inc. All rights reserved.	Zhejiang Ocean Univ, Sch Math Phys & Informat Sci, Zhoushan 316004, Zhejiang, Peoples R China	Wu, WZ (reprint author), Zhejiang Ocean Univ, Sch Math Phys & Informat Sci, Zhoushan 316004, Zhejiang, Peoples R China.	wuwz@zjou.edu.cn					Bazan J., 1998, ROUGH SETS KNOWLEDGE, V1, P321; Beynon M, 2001, EUR J OPER RES, V134, P592, DOI 10.1016/S0377-2217(00)00280-0; Chen DG, 2007, INFORM SCIENCES, V177, P3500, DOI 10.1016/j.ins.2007.02.041; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; DEMRI S. P, 2002, INCOMPLETE INFORM ST; Deng TQ, 2007, INFORM SCIENCES, V177, P2308, DOI 10.1016/j.ins.2006.11.013; Greco S, 1999, LECT NOTES ARTIF INT, V1711, P146; Greco S, 2002, INT J INTELL SYST, V17, P153, DOI 10.1002/int.10014; Grzymala-Busse J. W., 1998, LECT NOTES ARTIF INT, V1424, P37; Grzymala-Busse JW, 2006, LECT NOTES ARTIF INT, V4062, P58; Guan YY, 2006, INFORM SCIENCES, V176, P2507, DOI 10.1016/j.ins.2005.12.007; Hong TP, 2002, EXPERT SYST APPL, V22, P285, DOI 10.1016/S0957-4174(02)00016-7; Hong TP, 2007, EXPERT SYST APPL, V32, P223, DOI 10.1016/j.eswa.2005.11.009; HONG TP, 2000, INTELL DATA ANAL, V4, P289; Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; INUIGUCHI M, 2006, FUZZINESS KNOWLEDGE, V14, P461; Jensen R, 2007, IEEE T FUZZY SYST, V15, P73, DOI 10.1109/TFUZZ.2006.889761; KATZBERG LD, 1994, ROUGH SETS FUZZY SET, P167; Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; KORVIN A, 1998, J INTELL FUZZY SYST, V6, P237; Kryszkiewicz M, 2001, INT J INTELL SYST, V16, P105, DOI 10.1002/1098-111X(200101)16:1<105::AID-INT8>3.0.CO;2-S; Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1; Kryszkiewicz M, 1999, INFORM SCIENCES, V113, P271, DOI 10.1016/S0020-0255(98)10065-8; Leung Y, 2006, EUR J OPER RES, V168, P164, DOI 10.1016/j.ejor.2004.03.032; Leung Y, 2003, INFORM SCIENCES, V153, P85, DOI 10.1016/S0020-0255(03)00061-6; Li DY, 2004, INT J UNCERTAIN FUZZ, V12, P651, DOI 10.1142/S0218488504003132; Liang JY, 2002, INT J UNCERTAIN FUZZ, V10, P95, DOI 10.1142/S021848850200134X; Lin T.Y., 1998, ROUGH SETS KNOWLEDGE, P122; Lingras PJ, 1998, J AM SOC INFORM SCI, V49, P415, DOI 10.1002/(SICI)1097-4571(19980415)49:5<415::AID-ASI4>3.3.CO;2-Q; LIPSKI W, 1981, J ACM, V28, P41, DOI 10.1145/322234.322239; Liu M, 2006, COMPUT MATH APPL, V51, P1571, DOI 10.1016/j.camwa.2005.10.017; MARCZEWSKI E., 1958, B ACAD POLON SCI SER, V6, P731; Mi JS, 2004, INFORM SCIENCES, V159, P255, DOI 10.1016/j.ins.2003.07.004; Nguyen HS, 1999, LECT NOTES ARTIF INT, V1711, P137; Orlowska E., 1998, INCOMPLETE INFORM RO; ORLOWSKA E, 1984, THEOR COMPUT SCI, V29, P27, DOI 10.1016/0304-3975(84)90010-0; ORLOWSKA E, 1986, THEOR COMPUT SCI, V43, P81, DOI 10.1016/0304-3975(86)90167-2; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006; Pawlak Z., 1991, ROUGHT SETS THEORETI; Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003; POLKOWSKI L, 2000, ROUGHT SET METHODS A; Quafafou M, 2000, INFORM SCIENCES, V124, P301, DOI 10.1016/S0020-0255(99)00075-4; Shafer G, 1976, MATH THEORY EVIDENCE; Shao MW, 2005, INT J INTELL SYST, V20, P13, DOI 10.1002/int.20051; Skowron A., 1994, ADV DEMPSTER SHAFER, P193; Skowron A., 1990, Fundamenta Informaticae, V13; Skowron A., 1989, B POLISH ACAD SCI TE, V37, P87; Skowron A., 1992, INTELLIGENT DECISION, P331; Slezak D., 1998, P IPMU 98 PAR FRANC, V2, P1362; Slezak D, 1996, P IPMU 96 GRAN SPAIN, V3, P1159; Slowinski R., 1994, Rough Sets, Fuzzy Sets and Knowledge Discovery. Proceedings of the International Workshop on Rough Sets and Knowledge Discovery (RSKD'93); SLOWINSKI R, 1989, MATH COMPUT MODEL, V12, P1347; Starzyk J. A., 2000, Knowledge and Information Systems, V2, DOI 10.1007/s101150050007; Stefanowski J, 2001, COMPUT INTELL, V17, P545, DOI 10.1111/0824-7935.00162; Stefanowski J., 1998, ROUGH SETS KNOWLEDGE, V1, P500; Terlecki P, 2007, INFORM SCIENCES, V177, P74, DOI 10.1016/j.ins.2006.04.002; Wang G, 2003, INT J INTELL SYST, V18, P679, DOI 10.1002/int.10109; Wang XZ, 2007, INFORM SCIENCES, V177, P4493, DOI 10.1016/j.ins.2007.04.010; Wu WZ, 2005, INFORM SCIENCES, V174, P143, DOI 10.1016/j.ins.2004.09.002; Wu WZ, 2002, INT J GEN SYST, V31, P405, DOI 10.1080/0308107021000013626; Wu WZ, 2003, EXPERT SYST, V20, P280, DOI 10.1111/1468-0394.00252; Wu WZ, 2006, LECT NOTES ARTIF INT, V4062, P254; Yao YY, 1998, ROUGH SETS KNOWLEDGE, P286; YAO YY, 1992, INT J MAN MACH STUD, V37, P793, DOI 10.1016/0020-7373(92)90069-W; Yao YY, 1998, INFORM SCIENCES, V104, P81, DOI 10.1016/S0020-0255(97)00076-5; Zhang M, 2003, EXPERT SYST, V20, P298, DOI 10.1111/1468-0394.00254; Zhang WX, 2003, INT J INTELL SYST, V18, P989, DOI 10.1002/int.10128; Zhang WX, 2004, COMPUT MATH APPL, V48, P691, DOI 10.1016/j.camwa.2004.06.028; Zhao Y, 2007, INFORM SCIENCES, V177, P4959, DOI 10.1016/j.ins.2007.06.031; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	73	65	81	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	MAR 1	2008	178	5					1355	1371		10.1016/j.ins.2007.10.006		17	Computer Science, Information Systems	Computer Science	260TB	WOS:000253032200008	
J	Mitra, S; Banka, H				Mitra, Sushmita; Banka, Haider			Multi-objective evolutionary biclustering of gene expression data	PATTERN RECOGNITION			English	Article						multi-objective optimization; microarray; genetic algorithms; knowledge discovery; clustering		Biclustering or simultaneous clustering of both genes and conditions have generated considerable interest over the past few decades, particularly related to the analysis of high-dimensional gene expression data in information retrieval, knowledge discovery, and data mining. The objective is to find sub-matrices, i.e., maximal subgroups of genes and subgroups of conditions where the genes exhibit highly correlated activities over a range of conditions. Since these two objectives are mutually conflicting, they become suitable candidates for multi-objective modeling. In this study, a novel multi-objective evolutionary biclustering framework is introduced by incorporating local search strategies. A new quantitative measure to evaluate the goodness of the biclusters is developed. The experimental results on benchmark datasets demonstrate better performance as compared to existing algorithms available in literature. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, W Bengal, India	Banka, H (reprint author), Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, W Bengal, India.	sushmita@isical.ac.in; hbanka_r@isical.ac.in					Altman RB, 2001, CURR OPIN STRUC BIOL, V11, P340, DOI 10.1016/S0959-440X(00)00212-8; BANERJEE M, 2006, IN PRESS IEEE T SY C; Bleuler S., 2004, Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753), DOI 10.1109/CEC.2004.1330853; Bryan K, 2005, COMP MED SY, P383, DOI 10.1109/CBMS.2005.37; Cheng Y., 2000, P 8 INT C INT SYST M, P93; Cho H., 2004, P 4 SIAM INT C DAT M; Deb K., 2001, MULTIOBJECTIVE OPTIM; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; Getz G, 2003, BIOINFORMATICS, V19, P1079, DOI 10.1093/bioinformatics/btf876; Goldberg D.E., 1989, GENETIC ALGORITHMS S; HARTIGAN JA, 1972, J AM STAT ASSOC, V67, P123, DOI 10.2307/2284710; KUNG SY, 2005, P 2005 IEEE COMP SYS; Lazzeroni L, 2002, STAT SINICA, V12, P61; LIU J, 2004, P 2004 COMP SYST BIO, P1; Liu Jinze, 2004, Proc IEEE Comput Syst Bioinform Conf, P436; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; Mitra S., 2003, DATA MINING MULTIMED; Peeters R, 2003, DISCRETE APPL MATH, V131, P651, DOI 10.1016/S0166-218X(03)00333-0; Segal E., 2001, BIOINFORMATICS S1, V17, pS243; Tan KL, 2004, P 4 IEEE S BIOINF BI, P283; Tanay Amos, 2002, Bioinformatics, V18 Suppl 1, pS136; Tavazoie S, 1999, NAT GENET, V22, P281; TEWFIK AH, 2005, P ICASSP 2005, pV773; Tou J.T., 1974, PATTERN RECOGNITION; Turner H, 2005, COMPUT STAT DATA AN, V48, P235, DOI 10.1016/j.csda.2004.02.003; Yang J, 2003, AM FISH S S, V38, P1; Zhang Y., 2005, P INT C INF TECHN CO, P1, DOI 10.1145/1330107.1330146; *IEEE, 2002, IEEE COMPUT, V35	28	65	69	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	DEC	2006	39	12					2464	2477		10.1016/j.patcog.2006.03.003		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	095OX	WOS:000241318400018	
J	Law, MHC; Jain, AK				Law, MHC; Jain, AK			Incremental nonlinear dimensionality reduction by manifold learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						incremental learning; dimensionality reduction; ISOMAP; manifold learning; unsupervised learning	PRINCIPAL COMPONENT ANALYSIS; NEURAL NETWORKS; CURVES; IMAGES	Understanding the structure of multidimensional patterns, especially in unsupervised cases, is of fundamental importance in data mining, pattern recognition, and machine learning. Several algorithms have been proposed to analyze the structure of high-dimensional data based on the notion of manifold learning. These algorithms have been used to extract the intrinsic characteristics of different types of high-dimensional data by performing nonlinear dimensionality reduction. Most of these algorithms operate in a '' batch '' modeand cannot be efficiently applied when data are collected sequentially. In this paper, we describe an incremental version of ISOMAP, one of the key manifold learning algorithms. Our experiments on synthetic data as well as real world images demonstrate that our modified algorithm can maintain an accurate low-dimensional representation of the data in an efficient manner.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Law, MHC (reprint author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48824 USA.	lawhiu@cse.msu.edu; jain@cse.msu.edu					BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y., 2004, ADV NEURAL INFORM PR, V16; Bernstein M., 2000, GRAPH APPROXIMATIONS; BEYGELZIMER A, 2005, COVER TREES NEAREST; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Brand M., 2003, ADV NEURAL INFORMATI, V15, P961; BRUN A, 2003, P 9 INT C AID SYST T, V2809; Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189; Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212; Chang Y, 2004, PROC CVPR IEEE, P520; Costa J., 2004, P IEEE INT C AC SPEE, V3, P988; Cox T.F., 2001, MULTIDIMENSIONAL SCA; DE SILVA V., 2003, ADV NEURAL INFORM PR, V15, P705; DeMers D., 1993, ADV NEURAL INFORMATI, P580; Demetrescu C, 2004, J ACM, V51, P968, DOI 10.1145/1039488.1039492; Donoho D.L., 2002, 200227 STANF U DEP S; DUDA RO, 2001, PATTERN CLASSIFICAT; Elgamal EA, 2004, CHILD NERV SYST, V20, P489, DOI 10.1007/s00381-003-0891-1; ELGAMMAL A, 2004, P CVPR, V2, P681, DOI 10.1109/CVPR.2004.1315230; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Golub G.H., 1996, MATRIX COMPUTATIONS; Hadid A., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1044625; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Jenkins O., 2004, P 21 INT C MACH LEAR; Kegl B., 2003, ADV NEURAL INFORM PR, V15; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kohonen T, 2001, SELF ORG MAPS; Law MHC, 2004, SIAM PROC S, P33; Levina E., 2005, ADV NEURAL INFORM PR, V17; Li S.Z., 2001, P IEEE ICCV WORKSH R; Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; MARTINEZ A, 1998, 24 U AL BIRM COMP VI; Narvaez P, 2000, IEEE ACM T NETWORK, V8, P734, DOI 10.1109/90.893870; Narvaez P, 2001, IEEE ACM T NETWORK, V9, P706, DOI 10.1109/90.974525; NISKANEN M, 2003, P 6 INT C QUAL CONTR, P178; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25; Roweis S, 2002, ADV NEUR IN, V14, P889; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Simard P., 2003, P INT C DOC AN REC, P958; SJOSTROM E, 1996, THESIS; Smola AJ, 2001, J MACH LEARN RES, V1, P179, DOI 10.1162/15324430152748227; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889678; VERBEEK JJ, 2002, P INT C ART NEUR NET, P914; Weinberger K.Q., 2004, P IEEE C COMP VIS PA, P988, DOI 10.1109/CVPR.2004.1315272; Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034; YANG MH, 2002, P IEEE INT C IM PROC, P117; Zha H.Z., 2003, P 20 INT C MACH LEAR; Zhang J., 2004, P 6 INT C AUT FAC GE	53	65	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					377	391		10.1109/TPAMI.2006.56		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	001FB	WOS:000234517900004	
J	Glick, M; Jenkins, JL; Nettles, JH; Hitchings, H; Davies, JW				Glick, M; Jenkins, JL; Nettles, JH; Hitchings, H; Davies, JW			Enrichment of high-throughput screening data with increasing levels of noise using support vector machines, recursive partitioning, and Laplacian-modified naive Bayesian classifiers	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	4th Indo-US Workshop on Mathematical Chemistry	JAN 08-12, 2005	Pune, INDIA				STOCHASTIC RESONANCE; CHEMICAL-STRUCTURES; DRUG DISCOVERY; DESCRIPTORS; DIVERSE; CLASSIFICATION; FINGERPRINTS; SELECTION; DOCKING; MODELS	High-throughput screening (HTS) plays a pivotal role in lead discovery for the pharmaceutical industry. In tandem, cheminformatics approaches are employed to increase the probability of the identification of novel biologically active compounds by mining the HTS data. HTS data is notoriously noisy, and therefore, the selection of the optimal data mining method is important for the success of such an analysis. Here, we describe a retrospective analysis of four HTS data sets using three mining approaches: Laplacian-modified naive Bayes, recursive partitioning, and support vector machine (SVM) classifiers with increasing stochastic noise in the form of false positives and false negatives. All three of the data mining methods at hand tolerated increasing levels of false positives even when the ratio of misclassified compounds to true active compounds was 5: 1 in the training set. False negatives in the ratio of 1: 1 were tolerated as well. SVM outperformed the other two methods in capturing active compounds and scaffolds in the top 1%. A Murcko scaffold analysis could explain the differences in enrichments among the four data sets. This study demonstrates that data mining methods can add a true value to the screen even when the data is contaminated with a high level of stochastic noise.	Novartis Inst Biomed Res Inc, Lead Discovery Ctr, Cambridge, MA 02139 USA; Equbits LLC, Palo Alto, CA 94306 USA	Glick, M (reprint author), Novartis Inst Biomed Res Inc, Lead Discovery Ctr, 250 Massachusetts Ave, Cambridge, MA 02139 USA.	meir.glick@novartis.com					Bemis GW, 1996, J MED CHEM, V39, P2887, DOI 10.1021/jm9602928; Blower P, 2002, J CHEM INF COMP SCI, V42, P393, DOI 10.1021/ci0101049; Breiman L, 1984, CLASSIFICATION REGRE; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Brown RD, 1996, J CHEM INF COMP SCI, V36, P572, DOI 10.1021/ci9501047; Diller DJ, 2004, J MED CHEM, V47, P6373, DOI 10.1021/jm049902r; Dixon SL, 2001, J MED CHEM, V44, P3795, DOI 10.1021/jm010137f; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Godden JW, 2003, QSAR COMB SCI, V22, P487, DOI 10.1002/qsar.200310001; Hastie T., 2005, ELEMENTS STAT LEARNI; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; Karnachi PS, 2004, J BIOMOL SCREEN, V9, P678, DOI 10.1177/1087057104269570; Kelley BP, 2004, CHEM BIOL, V11, P1495, DOI 10.1016/j.chembiol.2004.08.026; Klon AE, 2004, J MED CHEM, V47, P4356, DOI 10.1021/jm049970d; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Matter H, 1999, J CHEM INF COMP SCI, V39, P1211, DOI 10.1021/ci980185h; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Schuffenhauer A, 2000, J CHEM INF COMP SCI, V40, P295, DOI 10.1021/ci990263g; Schuffenhauer A, 2004, COMB CHEM HIGH T SCR, V7, P771, DOI 10.2174/1386207043328238; Shi LM, 2001, J CHEM INF COMP SCI, V41, P186, DOI 10.1021/ci000066d; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; Valler MJ, 2000, DRUG DISCOV TODAY, V5, P286, DOI 10.1016/S1359-6446(00)01517-8; Vapnik V. N., 1998, STAT LEARNING THEORY; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; WIESENFELD K, 1995, NATURE, V373, P33, DOI 10.1038/373033a0; Russell DF, 1999, NATURE, V402, P291; Witten I.H., 1999, DATA MINING PRACTICA; Wu X, 2003, J BIOMOL SCREEN, V8, P381, DOI 10.1177/1087057103256466; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195	32	65	66	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	JAN-FEB	2006	46	1					193	200		10.1021/ci050374h		8	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	008DU	WOS:000235021200024	
J	Figueiredo, V; Rodrigues, F; Vale, Z; Gouveia, JB				Figueiredo, V; Rodrigues, F; Vale, Z; Gouveia, JB			An electric energy consumer characterization framework based on data mining techniques	IEEE TRANSACTIONS ON POWER SYSTEMS			English	Article						classification; clustering; consumer classes; data mining; decision trees; load profiles; neural networks		This paper presents an electricity consumer characterization framework based on a knowledge discovery in databases (KDD) procedure, supported by data mining (DM) techniques, applied on the different stages of the process. The core of this framework is a data mining model based on a combination of unsupervised and supervised learning techniques. Two main modules compose this framework: the load profiling module and the classification module. The load profiling module creates a set of consumer classes using a clustering operation and the representative load profiles for each class. The classification module uses this knowledge to build a classification model able to assign different consumers to the existing classes. The quality of this framework is illustrated with a case study concerning a real database of LV consumers from the Portuguese distribution company.	Polytech Inst, Dept Elect Engn, ISEP IPP, Oporto, Portugal; Polytech Inst, Dept Comp Engn, ISEP IPP, Oporto, Portugal; Univ Aveiro, Dept Engn & Ind Management, P-3800 Aveiro, Portugal	Figueiredo, V (reprint author), Polytech Inst, Dept Elect Engn, ISEP IPP, Oporto, Portugal.	veraf@dee.isep.ipp.pt; fr@dei.isep.ipp.pt; zav@dee.isep.ipp.pt; bgou-veia@egi.ua.pt	Vale, Zita/A-5824-2012				Chen CS, 1997, IEEE T POWER SYST, V12, P1746, DOI 10.1109/59.627886; Chicco G, 2003, IEEE T POWER SYST, V18, P381, DOI 10.1109/TPWRS.2002.807085; ERNOULT M, 1982, REV GEN ELECT; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FIGUEIREDO V, 2003, P ISAP; HIRST E, 2001, RETAIL LOAD PARTICIP; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kohonen T., 1989, SELF ORG ASSOCIATIVE; Pitt BD, 1999, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON POWER INDUSTRY COMPUTER APPLICATIONS, P131, DOI 10.1109/PICA.1999.779395; Quinlan R, 1993, BOOK C4 5 PROGRAMS M; RODRIGUES F, 2003, LECT NOTES ARTIF INT, P73; Witthen I., 2000, DATA MINING PRACTICA	12	65	70	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0885-8950		IEEE T POWER SYST	IEEE Trans. Power Syst.	MAY	2005	20	2					596	602		10.1109/TPWRS.2005.846234		7	Engineering, Electrical & Electronic	Engineering	921QF	WOS:000228778800009	
S	Han, H; Wang, WY; Mao, BH		Huang, DS; Zhang, XP; Huang, GB		Han, H; Wang, WY; Mao, BH			Borderline-SMOTE: A new over-sampling method in imbalanced data sets learning	ADVANCES IN INTELLIGENT COMPUTING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Conference on Intelligent Computing	AUG 23-26, 2005	Hefei, PEOPLES R CHINA	Inst Intelligent Machines, Univ Sci Technol, IEEE Computat Intelligence Soc, Hong Kong Computat Intelligence Chapter				In recent years, mining with imbalanced data sets receives more and more attentions in both theoretical and practical aspects. This paper introduces the importance of imbalanced data sets and their broad application domains in data mining, and then summarizes the evaluation metrics and the existing methods to evaluate and solve the imbalance problem. Synthetic minority over-sampling technique (SMOTE) is one of the over-sampling methods addressing this problem. Based on SMOTE method, this paper presents two new minority over-sampling methods, borderline-SMOTE1 and borderline-SMOTE2, in which only the minority examples near the borderline are over-sampled. For the minority class, experiments show that our approaches achieve better TP rate and F-value than SMOTE and random over-sampling methods.	Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China; Cent Univ Finance & Econ, Dept Stat, Beijing 100081, Peoples R China	Han, H (reprint author), Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China.	hanh01@mails.tsinghua.edu.cn; wwy-dau@mail.tsinghua.edu.cn; maobinghuan@yahoo.com					Blake C, 1998, UCI REPOSITORY MACHI; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Chawla Nitesh V., 2003, 7 EUR C PRINC PRACT, P107; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Chawla NV, 2004, SIGKDD EXPLORATIONS, V6, P1; DIETTERICH T, 2000, P ICML 2000 WORKSH C; Estabrooks A, 2004, COMPUT INTELL, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x; Ezawa K J, 1996, P 13 INT C MACH LEAR, P139; FAWCETT T., 1996, P 2 INT C KNOWL DISC, P8; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GU G, 2003, WORKSH LEARN IMB DAT, V2; Guo H, 2004, SIGKDD EXPLORATIONS, V6, P30; GUSTAVO EAP, 2004, SIGKDD EXPLORATIONS, V6, P20; HUANG KZ, 2004, P IEEE COMP SOC C CO; Jo T., 2004, SIGKDD EXPLORATIONS, V6, P40, DOI DOI 10.1145/1007730.1007737; JOSHI M, 2001, 1 IEEE INT C DAT MIN; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, ICML, P179; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; Manevitz LM, 2001, J MACHINE LEARNING R, V2, P139; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; VANDUERSEN A, 1997, P DSL 97 1 ACM SIGPL, P109; Weiss G. M., 2004, SIGKDD EXPLORATIONS, V6, P7; Zheng Z, 2004, SIGKDD EXPLORATIONS, V6, P80	25	65	72	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28226-2	LECT NOTES COMPUT SC			2005	3644						878	887				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDC09	WOS:000232528800091	
J	Lawrence, RD; Almasi, GS; Kotlyar, V; Viveros, MS; Duri, SS				Lawrence, RD; Almasi, GS; Kotlyar, V; Viveros, MS; Duri, SS			Personalization of supermarket product recommendations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						recommender systems; personalization; collaborative filtering; data mining; clustering; associations; pervasive computing		We describe a personalized recommender system designed to suggest new products to supermarket shoppers. The recommender functions in a pervasive computing environment, namely, a remote shopping system in which supermarket customers use Personal Digital Assistants (PDAs) to compost and transmit their orders to the store, which assembles them for subsequent pickup. The recommender is meant to provide an alternative source of new ideas for customers who now visit the store less frequently. Recommendations are generated by matching products to customers based on the expected appeal of the product and the previous spending of the customer. Associations mining in the product domain is used to determine relationships among product classes for use in characterizing the appeal of individual products. Clustering in the customer domain is used to identify groups of shoppers with similar spending histories. Cluster-specific lists of popular products are then used as input to the matching process. The recommender is currently being used in a pilot program with several hundred customers. Analysis of results to date have shown a 1.8% boost in program revenue as a result of purchases made directly from the list of recommended products. A substantial fraction of the accepted recommendations are from product classes new to the customer, indicating a degree of willingness to expand beyond present purchase patterns in response to reasonable suggestions.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Heights, NY 10598 USA	Lawrence, RD (reprint author), IBM Corp, Thomas J Watson Res Ctr, POB 218, Yorktown Heights, NY 10598 USA.						Aggarwal C. C., 1999, KNOWLEDGE DISCOVERY, P201; Agrawal R., 1994, P 20 INT C VER LARG; Almasi G. S., 2000, Proceedings of the Fifth International Conference on the Practical Application of Intelligent Agent and Multi Agent Technology; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Borchers A, 1998, COMPUTER, V31, P106, DOI 10.1109/2.666847; Everitt B. S., 1993, CLUSTER ANAL; Kohonen Teuvo, 1995, SELF ORG MAPS; KONSTAN J, 1997, COMMUNICATIONS ACM, V40; KOTLYAR V, 1999, P 10 INT C DAT EXP S, V1677; Lawrence RD, 1999, DATA MIN KNOWL DISC, V3, P171, DOI 10.1023/A:1009817804059; MICHAUD P, 1999, FUTURE GENERATION CO, V13; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; ROBBINS H, 1975, INTRO STAT; SALTON J, 1983, INTRO MODERN INFORMA; SALTON J, 1989, AUTOMATIC TEXT PROCE; SHARDANAND U, 1995, P CHI 95, P202; UNGAR LH, 1998, P 1988 AAAI WORKSH R	18	65	71	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					11	32		10.1023/A:1009835726774		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900002	
J	Fayyad, U; Stolorz, P				Fayyad, U; Stolorz, P			Data mining and KDD: Promise and challenges	FUTURE GENERATION COMPUTER SYSTEMS			English	Article						data mining; data analysis; science data analysis; overview article; knowledge discovery in databases; databases; parallel data mining	DIGITIZED POSS-II	Databases are growing in size to a stage where traditional techniques for analysis and visualization of the data are breaking down. Data mining and knowledge discovery in databases (KDD) are concerned with extracting models and patterns of interest from large databases. Data mining techniques have their origins in methods from statistics, pattern recognition, databases, artificial intelligence, high performance and parallel computing, and visualization. In this article, we provide an overview of this growing multi-disciplinary research area, outline the basic techniques, and provide brief coverage of how they are used in some applications. We discuss the role of high performance and parallel computing in data mining problems, and we provide a brief overview of a few applications in science data analysis. We conclude by listing challenges and opportunites for future research.	CALTECH,JET PROP LAB,PASADENA,CA 91109	Fayyad, U (reprint author), MICROSOFT CORP,RES,1 MICROSOFT WAY,REDMOND,WA 98052, USA.						AUBELE J, 1995, P 26 LUN PLAN SCI C, V1458; BRACHMAN R, 1996, COMMUN ACM, V39; Burl M. C., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), DOI 10.1109/CVPR.1994.323844; Codd EF, 1993, PROVIDING OLAP ONLIN; Duda R., 1973, PATTERN CLASSIFICATI; FAYYAD U, 1996, COMMUN ACM, V39, P8; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; GLYMOUR C, 1997, DATA MINING KNOWLEDG, V1; Glymour C, 1987, DISCOVERING CAUSAL S; GRAY J, 1997, DATA MINING KNOWLEDG, V1; HECKERMAN D, 1997, DATA MINING KNOWLEDG, V1; Hofacker IL, 1996, P 2 INT C KNOWL DISC, P20; JONES R, 1992, INT J SUPERCOMPUT AP, V6, P138, DOI 10.1177/109434209200600202; KENNEFICK JD, 1995, ASTRON J, V110, P78, DOI 10.1086/117498; KETTENRING J, 1996, STAT MASSIVE DATA SE; Leamer E.E., 1978, SPECIFICATION SEARCH; MEHTA M, 1996, P EDBT96 BERL; PFITZNER D, 1996, P 2 INT C KNOWL DISC, P208; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; STOLORZ P, 1996, P 2 INT C KNOWL DISC, P208; Stolorz P., 1995, P 1 INT C KNOWL DISC, P300; TUKEY J, 1975, EXPLORATORY DATA ANA; WATERMAN MS, 1978, STUDIES FDN COMBINAT; WEIR N, 1995, ASTRON J, V110, P1, DOI 10.1086/117493; WEIR N, 1995, ASTRON J, V109, P2401, DOI 10.1086/117459	26	65	75	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-739X		FUTURE GENER COMP SY	Futur. Gener. Comp. Syst.	NOV	1997	13	2-3					99	115		10.1016/S0167-739X(97)00015-0		17	Computer Science, Theory & Methods	Computer Science	YJ828	WOS:A1997YJ82800002	
J	Lian, W; Cheung, DWL; Mamoulis, N; Yiu, SM				Lian, W; Cheung, DWL; Mamoulis, N; Yiu, SM			An efficient and scalable algorithm for clustering XML documents by structure	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; clustering; XML; semistructured data; query processing	DISTANCE	With the standardization of XML as an information exchange language over the net, a huge amount of information is formatted in XML documents. In order to analyze this information efficiently, decomposing the XML documents and storing them in relational tables is a popular practice. However, query processing becomes expensive since, in many cases, an excessive number of joins is required to recover information from the fragmented data. If a collection consists of documents with different structures (for example, they come from different DTDs), mining clusters in the documents could alleviate the fragmentation problem. We propose a hierarchical algorithm (S-GRACE) for clustering XML documents based on structural information in the data. The notion of structure graph (s-graph) is proposed, supporting a computationally efficient distance metric defined between documents and sets of documents. This simple metric yields our new clustering algorithm which is efficient and effective, compared to other approaches based on tree-edit distance. Experiments on real data show that our algorithm can discover clusters not easily identified by manual inspection.	Univ Hong Kong, Dept Comp Sci & Informat Syst, Hong Kong, Hong Kong, Peoples R China	Lian, W (reprint author), Univ Hong Kong, Dept Comp Sci & Informat Syst, Hong Kong, Hong Kong, Peoples R China.						ABITEBOUL S, 1993, P INT C VER LARG DAT, P73; ABOULNAGA A, 2001, P 5 INT WORKSH WEB D; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; COPPERSMITH D, 1987, P 19 ANN ACM S THEOR; DeRose S., 2001, XML LINKING LANGUAGE; Deutsch A., 1999, P ACM SIGMOD INT C M, P431, DOI 10.1145/304182.304220; Diaz A., 1999, XML GENERATOR; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Guillaume D, 2000, COMPUT PHYS COMMUN, V127, P215, DOI 10.1016/S0010-4655(99)00511-1; KAUSHIK R, 2002, P 18 INT C DAT ENG; McHugh J., 1997, SIGMOD Record, V26; Ng R, 1994, P 20 INT C VER LARG, P144; Nierman Andrew, 2002, P 5 INT WORKSH WEB D; SALTON G, 1983, INTRO MODERN INFORMA; Shanmugasundaram J, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P302; Shimura T., 1999, P 10 INT C DAT EXP S, P206; World Wide Web Consortium, 1999, XML PATH LANG XPATH; Zamir O., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082; *INT PRESS TEL COU, 2000, NEWS IND TEXT FORM; *WORLD WID WEB CON, 2001, XQUER QUER LANG XML	22	64	75	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN	2004	16	1					82	96				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	755WY	WOS:000187435500008	
J	Tung, AKH; Lu, HJ; Han, JW; Feng, L				Tung, AKH; Lu, HJ; Han, JW; Feng, L			Efficient mining of intertransaction association rules	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; association rules; temporal pattern discovery		Most of the previous studies on mining association rules are on mining intra transaction associations, i.e., the associations among items within the same transaction where the notion of the transaction could be the items bought by the same customer, the events happened on the same day, etc. In this study, we break the barrier of transactions and extend the scope of mining association rules from traditional single-dimensional, intratransaction associations to multidimensional, intertransaction associations. An intertransaction association describes the association relationships among different transactions. In a database of stock price information, an example of such an association is "if (company) A's stock goes up on day one, B's stock will go down on day two but go up on day four." In this case, no matter whether we treat company or day as the unit of transaction, the associated items belong to different transactions. Moreover, such an intertransaction association can be extended to associate multiple properties in the same rule, so that multidimensional intertransaction associations can also be defined and discovered. Mining intertransaction associations pose more challenges on efficient processing than mining intratransaction associations because the number of potential association rules becomes extremely large after the boundary of transactions is broken. In this study, we introduce the notion of intertransaction association rule, define its measurements: support and confidence, and develop an efficient algorithm, FITI (an acronym for "First intra Then Intr"), for mining intertransaction associations, which adopts two major ideas: 1) an intertransaction frequent itemset contains only the frequent itemsets of its corresponding intratransaction counterpart; and 2) a special data structure is built among intratransaction frequent itemsets for efficient mining of intertransaction frequent itemsets. We compare FITI with EH-Apriori, the best algorithm in our previous proposal, and demonstrate a substantial performance gain of FITI over EH-Apriori. Further extensions of the method and its implications are also discussed in the paper.	Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore; Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Univ Illinois, DCL, Dept Comp Sci, Urbana, IL 61801 USA; Tilburg Univ, NL-5000 LE Tilburg, Netherlands	Tung, AKH (reprint author), Natl Univ Singapore, Dept Comp Sci, 3 Sci Dr 2, Singapore 117543, Singapore.	atung@comp.nus.edu.sg; luhj@cs.ust.hk; han@cs.uiuc.ca; ling@kub.nl					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bettini C, 1998, DATA ENG B, V21, P32; BETTINI C, 1996, P 15 ACM S PRINC DAT; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; Han J, 1995, P 21 INT C VER LARG, P420; Kamber M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; LAKSHMANAN LVS, 1999, P 1999 ACM SIGMOD IN, P157, DOI 10.1145/304182.304196; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Lu H., 1998, P 1998 SIGMOD WORKSH, P12; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; Meo R, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P122; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Savasere A, 1995, P 21 INT C VER LARG, P432; Silverstein C., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Srikant R., 1995, P 21 INT C VER LARG, P407; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134	25	64	64	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN-FEB	2003	15	1					43	56		10.1109/TKDE.2003.1161581		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	632NW	WOS:000180230300004	
J	Kurgan, LA; Cios, KJ; Tadeusiewicz, R; Ogiela, M; Goodenday, LS				Kurgan, LA; Cios, KJ; Tadeusiewicz, R; Ogiela, M; Goodenday, LS			Knowledge discovery approach to automated cardiac SPECT diagnosis	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						knowledge discovery and data mining; SPECT myocardial perfusion imaging; CLIP3 machine learning algorithm	PERFUSION QUANTIFICATION; MYOCARDIAL PERFUSION	The paper describes a computerized process of myocardial perfusion diagnosis from cardiac single proton emission computed tomography (SPECT) images using data mining and knowledge discovery approach. We use a six-step knowledge discovery process. A database consisting of 267 cleaned patient SPECT images (about 3000 2D images), accompanied by clinical information and physician interpretation was created first. Then, a new user-friendly algorithm for computerizing the diagnostic process was designed and implemented. SPECT images were processed to extract a set of features, and then explicit rules were generated, using inductive machine learning and heuristic approaches to mimic cardiologist's diagnosis. The system is able to provide a set of computer diagnoses for cardiac SPECT studies, and can be used as a diagnostic tool by a cardiologist. The achieved results are encouraging because of the high correctness of diagnoses. (C) 2001 Elsevier Science B.V. All rights reserved.	Univ Colorado, Hlth Sci Ctr, Denver, CO 80217 USA; Univ Colorado, Boulder, CO 80309 USA; 4cData, LLC, Golden, CO USA; Univ Min & Met Krakow, Krakow, Poland; Med Coll Ohio, Toledo, OH 43699 USA	Kurgan, LA (reprint author), Univ Colorado, Hlth Sci Ctr, POB 173364, Denver, CO 80217 USA.		Kurgan, Lukasz/B-5721-2009; Ogiela, Marek/A-7735-2013	Kurgan, Lukasz/0000-0002-7749-0314; Ogiela, Marek/0000-0002-8298-8627			BLOKLAND KJAK, 1992, EUR J NUCL MED, V19, P47; Cios K., 1998, DATA MINING METHODS; CIOS KJ, 1996, P CBMS 96 JUN 1 5 AN; CIOS KJ, 1995, KYBERNETES, V24, P29, DOI 10.1108/03684929510146813; Cios KJ, 1997, KYBERNETES, V26, P513, DOI 10.1108/03684929710176502; Cios KJ, 2000, IEEE ENG MED BIOL, V19, P17, DOI 10.1109/51.853478; CORBETT JR, 1995, CARDIAC SPECT IMAGIN; Crevier D, 1997, COMPUT VIS IMAGE UND, V67, P161, DOI 10.1006/cviu.1996.0520; CUARON A, 1980, J NUCL MED, V21, P1; CULLOM SJ, 1995, DARDIAC SPECT IMAGIN; FABER TL, 1991, J NUCL MED, V32, P2311; FABER TL, 1995, J NUCL MED, V36, P697; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FRANCISCO DA, 1982, CIRCULATION, V66, P370; GARCIA EV, 1986, J NUCL MED, V27, P1005; Goris M L, 1987, Am J Physiol Imaging, V2, P176; Kukar M, 1999, ARTIF INTELL MED, V16, P25, DOI 10.1016/S0933-3657(98)00063-3; Puentes J, 2000, ARTIF INTELL MED, V19, P155, DOI 10.1016/S0933-3657(00)00043-9; Sacha JP, 2000, IEEE ENG MED BIOL, V19, P78, DOI 10.1109/51.853485; VANTRAIN KF, 1995, CARDIAC SPECT IMAGIN	20	64	64	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	OCT	2001	23	2					149	169		10.1016/S0933-3657(01)00082-3		21	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	488BA	WOS:000171913100002	
J	Last, M; Klein, Y; Kandel, A				Last, M; Klein, Y; Kandel, A			Knowledge discovery in time series databases	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						computational theory of perception; data mining; fuzzy association rules; knowledge discovery in databases; time series databases		Adding the dimension of time to databases produces time series databases (TSDB) and introduces new aspects and difficulties to data mining and knowledge discovery. In this correspondence, we introduce a general methodology for knowledge discovery in TSDB. The process of knowledge discovery in TSDB includes cleaning and filtering of time series data, identifying the most important predicting, attributes, and extracting a set of association rules that can be used to predict the time series behavior in the future. Our method is based on signal processing techniques and the information-theoretic fuzzy approach to knowledge discovery. The computational theory of perception (CTP) is used to reduce the set of extracted rules by fuzzification and aggregation. We demonstrate our approach an two types of time series: stock-market data and weather data.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Tel Aviv Univ, Dept Elect Engn Syst, IL-69978 Tel Aviv, Israel	Last, M (reprint author), Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.	mlast@csee.usf.edu; kandel@csee.usf.edu	LAST, MARK/F-1424-2012	LAST, MARK/0000-0003-0748-7918			Cover T. M., 1991, ELEMENTS INFORMATION; Dreyer W., 1994, SIGMOD Record, V23; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; GAVRILOV M, 2000, P 6 ACM SIGKDD INT C; Guralnik V, 1999, P 5 ACM SIGKDD INT C, P33, DOI 10.1145/312129.312190; Han J, 1998, P 4 INT C KNOWL DISC, P214; Han J, 1999, P 1999 INT C DAT ENG; Keogh E, 1997, PROC INT C TOOLS ART, P578, DOI 10.1109/TAI.1997.632306; Liu B., 1999, P 5 ACM SIGKDD INT C, P125, DOI 10.1145/312129.312216; LU H, 1998, P 1998 SIGMOD WORKSH; MAILLA H, 1997, DATA MIN KNOWL DISC, V1, P259; MAIMON O, 1999, ADV SOFT COMPUTING E, P315; Maimon O., 2000, KNOWLEDGE DISCOVERY; Oppenheim AV, 1996, SIGNALS SYSTEMS; Pyle D, 1999, DATA PREPARATION DAT; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rao C. R., 1995, LINEAR MODELS LEAST; Srikant R., 1996, P ACM SIGMOD 1996 C; TSAI CC, 1999, P IEEE FUZZ SYST C, P719; Tung A., 1999, P INT C KNOWL DISC D, P297, DOI 10.1145/312129.312258; Wang L.X., 1997, COURSE FUZZY SYSTEMS; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; Weiss G. M., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Zadeh LA, 1999, LECT NOTES ARTIF INT, V1711, P10	25	64	79	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	FEB	2001	31	1					160	169		10.1109/3477.907576		10	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	407NC	WOS:000167276800016	
J	Enke, D; Thawornwong, S				Enke, D; Thawornwong, S			The use of data mining and neural networks for forecasting stock market returns	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						stock return forecasting; data mining; information gain; neural networks; trading strategies	ECONOMIC-SIGNIFICANCE; TRADING STRATEGIES; PREDICTING RETURNS; INDEX; REGRESSION; BUSINESS; MODELS; LEVEL	It has been widely accepted by many studies that non-linearity exists in the financial markets and that neural networks can be effectively used to uncover this relationship. Unfortunately, many of these studies fail to consider alternative forecasting techniques, the relevance of input variables, or the performance of the models when using different trading strategies. This paper introduces an information gain technique used in machine learning for data mining to evaluate the predictive relationships of numerous financial and economic variables. Neural network models for level estimation and classification are then examined for their ability to provide an effective forecast of future values. A cross-validation technique is also employed to improve the generalization ability of several models. The results show that the trading strategies guided by the classification models generate higher risk-adjusted profits than the buy-and-hold strategy, as well as those guided by the level-estimation based forecasts of the neural network and linear regression models. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Missouri, Lab Investment & Financial Engn, Smart Engn Syst Lab, Intelligent Syst Ctr, Rolla, MO 65409 USA	Enke, D (reprint author), Univ Missouri, Lab Investment & Financial Engn, Smart Engn Syst Lab, Intelligent Syst Ctr, Rolla, MO 65409 USA.	enke@umr.edu					Abhyankar A, 1997, J BUS ECON STAT, V15, P1, DOI 10.2307/1392068; Aggarwal R, 1997, J FUTURES MARKETS, V17, P781, DOI 10.1002/(SICI)1096-9934(199710)17:7<781::AID-FUT3>3.0.CO;2-J; BALVERS RJ, 1990, J FINANC, V45, P1109, DOI 10.2307/2328717; BREEN W, 1989, J FINANC, V44, P1177, DOI 10.2307/2328638; Burrell PR, 1997, NEURAL COMPUT APPL, V6, P193, DOI 10.1007/BF01501506; CAMPBELL JY, 1987, J FINANC ECON, V18, P373, DOI 10.1016/0304-405X(87)90045-6; Chenoweth T, 1996, NEUROCOMPUTING, V10, P275, DOI 10.1016/0925-2312(95)00109-3; Demuth H., 1997, NEURAL NETWORK TOOLB; Desai VS, 1998, DECISION SCI, V29, P405, DOI 10.1111/j.1540-5915.1998.tb01582.x; ELTON EJ, 1991, MODERN PORTFOLIO THE; FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486; FAMA EF, 1977, J FINANC ECON, V5, P115, DOI 10.1016/0304-405X(77)90014-9; FAMA EF, 1989, J FINANC ECON, V25, P23, DOI 10.1016/0304-405X(89)90095-0; FAMA EF, 1988, J FINANC ECON, V22, P3, DOI 10.1016/0304-405X(88)90020-7; FERSON WE, 1989, J FINANC, V44, P1191, DOI 10.2307/2328639; Gencay R, 1998, ECON LETT, V59, P249, DOI 10.1016/S0165-1765(98)00051-2; HAN J, 2000, DATA MIXING CONCEPTS; Hill T, 1996, MANAGE SCI, V42, P1082, DOI 10.1287/mnsc.42.7.1082; KEIM DB, 1986, J FINANC ECON, V17, P357, DOI 10.1016/0304-405X(86)90070-X; JENSEN MC, 1978, J FINANC ECON, V6, P95, DOI 10.1016/0304-405X(78)90025-9; LEITCH G, 1991, AM ECON REV, V81, P580; Leung MT, 2000, INT J FORECASTING, V16, P173, DOI 10.1016/S0169-2070(99)00048-5; Lo A. W., 1988, REV FINANC STUD, VI, P41, DOI DOI 10.1093/RFS/1.1.41; MABERLY ED, 1986, J FUTURES MARKETS, V6, P385; MALLIARIS M, 1993, APPL INTELL, V3, P193, DOI 10.1007/BF00871937; MILLS TC, 1991, J EC SURVEYS, V5, P215, DOI 10.1111/j.1467-6419.1991.tb00133.x; Motiwalla L, 2000, COMPUT OPER RES, V27, P1111, DOI 10.1016/S0305-0548(99)00148-3; Nelson M, 1999, J FORECASTING, V18, P359, DOI 10.1002/(SICI)1099-131X(199909)18:5<359::AID-FOR746>3.0.CO;2-P; Pantazopoulos KN, 1998, IEEE T SYST MAN CY B, V28, P520, DOI 10.1109/3477.704291; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PESARAN MH, 1992, J BUS ECON STAT, V10, P461, DOI 10.2307/1391822; PESARAN MH, 1995, J FINANC, V50, P1201, DOI 10.2307/2329349; PETERSON GE, 1995, IEEE T NEURAL NETWOR, V6, P949, DOI 10.1109/72.392257; Poddig T, 1996, NEUROCOMPUTING, V10, P251, DOI 10.1016/0925-2312(96)00049-5; Priestly M B, 1988, NONLINEAR NONSTATION; Qi M, 1999, J FORECASTING, V18, P151, DOI 10.1002/(SICI)1099-131X(199905)18:3<151::AID-FOR716>3.3.CO;2-M; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; SCHWERT GW, 1990, J FINANC, V45, P1237, DOI 10.2307/2328722; SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Swales G. S.  Jr., 1992, Financial Analysts Journal, V48, DOI 10.2469/faj.v48.n5.78; Vellido A, 1999, EXPERT SYST APPL, V17, P51, DOI 10.1016/S0957-4174(99)00016-0; Wasserman P.D., 1993, ADV METHODS NEURAL C; Wood D, 1996, COMPUT OPER RES, V23, P611, DOI 10.1016/0305-0548(95)00065-8; Wu YR, 1997, J INT MONEY FINANC, V16, P609	46	63	63	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	NOV	2005	29	4					927	940		10.1016/j.eswa.2005.06.024		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	976UA	WOS:000232757700018	
J	Kuramochi, M; Karypis, G				Kuramochi, M; Karypis, G			An efficient algorithm for discovering frequent subgraphs	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; scientific data sets; frequent pattern discovery; chemical compound data sets	BIOLOGICAL-ACTIVITY; PATTERNS	Over the years, frequent itemset discovery algorithms have been used to find interesting patterns in various application areas. However, as data mining techniques are being increasingly applied to nontraditional domains, existing frequent pattern discovery approaches cannot be used. This is because the transaction framework that is assumed by these algorithms cannot be used to effectively model the data sets in these domains. An alternate way of modeling the objects in these data sets is to represent them using graphs. Within that model, one way of formulating the frequent pattern discovery problem is that of discovering subgraphs that occur frequently over the entire set of graphs. In this paper, we present a computationally efficient algorithm, called FSG, for finding all frequent subgraphs in large graph data sets. We experimentally evaluate the performance of FSG using a variety of real and synthetic data sets. Our results show that despite the underlying complexity associated with frequent subgraph discovery, FSG is effective in finding all frequently occurring subgraphs in data sets containing more than 200,000 graph transactions and scales linearly with respect to the size of the data set.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Kuramochi, M (reprint author), Univ Minnesota, Dept Comp Sci, 4-192 EE-CS Bldg,200 Union St SE, Minneapolis, MN 55455 USA.	kuram@cs.umn.edu; karypis@cs.umn.edu					Agarwal RC, 2001, J PARALLEL DISTR COM, V61, P350, DOI 10.1006/jpdc.2000.1693; Agrawal R., 1994, P 20 INT C VER LARG, P487; Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; Asai T, 2002, SIAM PROC S, P158; BORGELT C, 2002, P 2002 IEEE INT C DA; CHEN CWK, 1998, P INT C SYST SIGN CO; CONG G, 2002, P 2 SIAM INT C DAT M; Cook DJ, 2000, IEEE INTELL SYST APP, V15, P32, DOI 10.1109/5254.850825; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DEHASPE L, 1997, P 7 INT WORKSH IND L, P125; DESHPANDE M, 2002, P 2 WORKSH DAT MIN B; Dixon J. D., 1996, GRADUATE TEXTS MATH, V163; DUNKEL B, 1999, P 15 IEEE INT C DAT; Dupplaw D, 2000, P SOC PHOTO-OPT INS, V3972, P253; Fortin S, 1996, TR9620 U ALB DEP COM; Garey M. R., 1979, COMPUTERS INTRACTABI; GHAZIZADEH S, 2002, P 5 INT C DISC SCI; GOETHALS B, 2002, THESIS U LIMBURG DIE; GONZALEZ J, 2001, P PRED TOX CHALL WOR; Han J., 2000, P ACM SIGMOD INT C M; HANSCH C, 1962, NATURE, V194, P178, DOI 10.1038/194178b0; Hipp J., 2000, ACM SIGKDD EXPLORATI, P58, DOI 10.1145/360402.360421; Holder L.B., 1994, P AAAI WORKSH KNOWL, P169; Inokuchi A., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); INOKUCHI A, 2002, RT0448 IBM RES TOK R; KALVIAINEN H, 1990, P STEP 90 FINN ART I, P354; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; Kramer S., 2001, P 7 ACM SIGKDD INT C, P136, DOI 10.1145/502512.502533; KURAMOCHI M, 2001, P 2001 IEEE INT C DA; LEUNG TK, 1995, P 5 IEEE INT C COMP; McKay B., 1981, C NUMERANTIUM, V30, P45; McKay B. D., 2003, NAUTY USERS GUIDE; Muggleton S, 1999, COMMUN ACM, V42, P42, DOI 10.1145/319382.319390; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; PALMER CR, 2002, P 8 ACM SIGKDD INT C; Pei J, 2001, PROC INT CONF DATA, P215; Petrakis EGM, 1997, IEEE T KNOWL DATA EN, V9, P435, DOI 10.1109/69.599932; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Savasere A, 1995, P 21 INT C VER LARG, P432; Shenoy P., 2000, P ACM SIGMOD INT C M, P22, DOI 10.1145/342009.335376; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; Srinivasan A, 1999, DATA MIN KNOWL DISC, V3, P37, DOI 10.1023/A:1009815821645; SRINIVASAN A, 1997, P 15 INT JOINT C ART, P1; Srinivasan A, 1997, P 7 INT WORKSH IND L, P273; Yan X.F., 2002, P 2002 IEEE INT C DA; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A; ZAKI MJ, 2002, P 8 ACM SIGKDD INT C; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291; ZAKI MJ, 2001, 011 RENSS POL I DEP	49	63	71	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP	2004	16	9					1038	1051		10.1109/TKDE.2004.33		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	839FA	WOS:000222767700002	
S	Papadimitriou, S; Kitagawa, H; Gibbons, PB; Faloutsos, C		Dayal, U; Ramamritham, K; Viyayaraman, TM		Papadimitriou, S; Kitagawa, H; Gibbons, PB; Faloutsos, C			LOCI: Fast Outlier detection using the local correlation integral	19TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING, PROCEEDINGS	PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON DATA ENGINEERING (SERIES)		English	Proceedings Paper	19th International Conference on Data Engineering	MAR 05-08, 2003	BANGALORE, INDIA	IEEE Comp Soc, Microsoft, AZTEC SOFTWARE, IBM Res, Infosys, Persistent, TATA Consultancy Serv, Infotech, Teradata			DIMENSIONS	Outlier detection is an integral part of data mining and has attracted much attention recently [8, 15, 19]. In this paper we propose a new method for evaluating outlierness, which we call the Local Correlation Integral (LOCI). As with the best previous methods, LOCI is highly effective for detecting outliers and groups of outliers (a.k.a. microclusters). In addition, it offers the following advantages and novelties: (a) It provides an automatic, data-dictated cutoff to determine whether a point is an outlier-in contrast, previous methods force users to pick cut-offs, without any hints as to what cut-off value is best for a given dataset. (b) It can provide a LOCI plot for each point; this plot summarizes a wealth of information about the data in the vicinity of the point, determining clusters, micro-clusters, their diameters and their inter-cluster distances. None of the existing outlier-detection methods can match this feature, because they output only a single number for each point: its outlier-ness score. (c) Our LOCI method can be computed as quickly as the best previous methods. (d) Moreover LOCI leads to a practically linear approximate method, aLOCI (for approximate LOCI), which provides fast highly-accurate outlier detection. To the best of our knowledge, this is the first work to use approximate computations to speed up outlier detection.	Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Papadimitriou, S (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.		Kitagawa, Hiroyuki/F-1438-2013				AGGARWAL CC, 2001, P SIGMOD; Arning A., 1996, P 2 INT C KNOWL DISC, P164; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Barbara D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347145; Barnett V., 1994, OUTLIERS STAT DATA; BELUSSI A., 1995, P 21 INT C VER LARG, P299; BERN M, 1993, INFORM PROCESS LETT, V45, P95, DOI 10.1016/0020-0190(93)90222-U; Breuning M.M., 2000, P ACM SIGMOD INT C M, P93, DOI DOI 10.1145/342009.335388; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; FIEGEL T, 1977, ACTA MATH, V139, P53; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Hawkins D. M., 1980, IDENTIFICATION OUTLI; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jin W, 2001, P 7 ACM SIGKDD INT C, P293, DOI 10.1145/502512.502554; Johnson T., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Knorr E. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Schuster H. G., 1988, DETERMINISTIC CHAOS; TRAINA A, 2001, P KDD, P184, DOI 10.1145/502512.502538; Jagadish HV, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P102	23	63	94	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6382	0-7803-7665-X	PROC INT CONF DATA			2003							315	326		10.1109/ICDE.2003.1260802		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BX92D	WOS:000186827800026	
J	Zaki, MJ; Parthasarathy, S; Ogihara, M; Li, W				Zaki, MJ; Parthasarathy, S; Ogihara, M; Li, W			Parallel algorithms for discovery of association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						parallel data mining; association rules; maximal hypergraph cliques; lattice traversal		Discovery of association rules is an important data mining task. Several parallel and sequential algorithms have been proposed in the literature to solve this problem. Almost all of these algorithms make repeated passes over the database to determine the set of frequent itemsets (a subset of database items), thus incurring high I/O overhead. In the parallel case, most algorithms perform a sum-reduction at the end of each pass to construct the global counts, also incurring high synchronization cost. In this paper we describe new parallel association mining algorithms. The algorithms use novel itemset clustering techniques to approximate the set of potentially maximal frequent itemsets. Once this set has been identified, the algorithms make use of efficient traversal techniques to generate the frequent itemsets contained in each cluster. We propose two clustering schemes based on equivalence classes and maximal hypergraph cliques, and study two lattice traversal techniques based on bottom-up and hybrid search. We use a vertical database layout to cluster related transactions together. The database is also selectively replicated so that the portion of the database needed for the computation of associations is local to each processor. After the initial set-up phase, the algorithms do not need any further communication or synchronization. The algorithms minimize I/O overheads by scanning the local database portion only twice. Once in the set-up phase, and once when processing the itemset clusters, Unlike previous parallel approaches, the algorithms use simple intersection operations to compute frequent itemsets and do not have to maintain or search complex hash structures. Our experimental testbed is a 32-processor DEC Alpha cluster inter-connected by the Memory Channel network. We present results on the performance of our algorithms on various databases, and compare it against a well known parallel algorithm. The best new algorithm outperforms it by an order of magnitude.	Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA; Oracle Corp, Java Prod Grp, Redwood Shores, CA 94065 USA	Zaki, MJ (reprint author), Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.						Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R., 1993, ACM SIGMOD INT C MAN; Agrawal R., 1996, ADV KNOWLEDGE DISCOV; AGRAWAL R, 1994, 20 VLDB C; Berge C., 1989, HYPERGRAPHS COMBINAT; CHEUNG D, 1996, 4 INT C PAR DISTR IN; Cheung DW, 1996, IEEE T KNOWL DATA EN, V8, P911, DOI 10.1109/69.553158; FAYYAD U, 1996, COMMUNICATIONS ACM D; Garey M. R., 1979, COMPUTERS INTRACTABI; GILLETT R, 1996, IEEE MICRO, V16; HAN EHK, 1997, ACM SIGMOD C MAN DAT; HOLSHEIMER M, 1995, 1 INT C KNOWL DISC D; HOUTSMA M, 1995, 11 INT C DAT ENG; MANNILA H, 1994, AAAI WKSHP KNOWL DIS; Park J.S., 1995, ACM INT C INF KNOWL; PARK JS, 1995, ACM SIGMOD INT C MAN; PARTHASARATHY S, 1997, 653 URCS TR; SAVASERE A, 1995, 21 VLDB C; TOIVONEN H, 1996, 22 VLDB C; Zaki M. J., 1997, 3 INT C KNOWL DISC D; ZAKI MJ, 1997, 651 URCS TR; ZAKI MJ, 1997, 7 INT WKSHP RES ISS; ZAKI MJ, 1996, SUPERCOMPUTING 96; ZAKI MJ, 1997, 9 ACM S PAR ALG ARCH	24	63	66	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	DEC	1997	1	4					343	373		10.1023/A:1009773317876		31	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA833	WOS:000072406600002	
J	Boyack, KW; Wylie, BN; Davidson, GS				Boyack, KW; Wylie, BN; Davidson, GS			Domain visualization using VxInsight (R) for science and technology management	JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article							INFORMATION-SCIENCE; CITATION; NETWORKS; DATABASE; CLASSIFICATION; SPACES; MAPS	We present the application of our knowledge visualization tool, VxInsight(R), to enable domain analysis for science and technology management within the enterprise. Data mining from sources of bibliographic information is used to define subsets of information relevant to a technology domain. Relationships between the individual objects (e.g., articles) are identified using citations, descriptive terms, or textual similarities. Objects are then clustered using a force-directed placement algorithm to produce a terrain view of the many thousands of objects. A variety of features that allow exploration and manipulation of the landscapes and that give detail on demand, enable quick and powerful analysis of the resulting landscapes. Examples of domain analyses used in S&T management at Sandia are given.	Sandia Natl Labs, Albuquerque, NM 87185 USA	Boyack, KW (reprint author), Sandia Natl Labs, POB 5800,MS-0318, Albuquerque, NM 87185 USA.						Bassecoulard E, 1999, SCIENTOMETRICS, V44, P323, DOI 10.1007/BF02458483; Beck DF, 1999, CHEMTECH, V29, P8; BORNER K, 2000, P IST SPIE 12 ANN S; BOYACK KW, 2000, P NEW PAR INF VIS MA; Chen CM, 1999, INFORM PROCESS MANAG, V35, P401, DOI 10.1016/S0306-4573(98)00068-5; Chen CM, 2001, J AM SOC INF SCI TEC, V52, P315, DOI 10.1002/1532-2890(2000)9999:9999<::AID-ASI1074>3.3.CO;2-U; Davidson GS, 1998, J INTELL INF SYST, V11, P259, DOI 10.1023/A:1008690008856; Davidson G. S., 2001, Proceedings IEEE Symposium on Information Visualization 2001. INFOVIS 2001; Fox KL, 1999, J AM SOC INFORM SCI, V50, P616, DOI 10.1002/(SICI)1097-4571(1999)50:7<616::AID-ASI6>3.0.CO;2-E; Hetzler B., 1998, Proceedings IEEE Symposium on Information Visualization (Cat. No.98TB100258), DOI 10.1109/INFVIS.1998.729570; HJORLAND B, 1995, J AM SOC INFORM SCI, V46, P400, DOI 10.1002/(SICI)1097-4571(199507)46:6<400::AID-ASI2>3.0.CO;2-Y; HONKELA T, 1998, CLASSIFICATION DATA; Kostoff RN, 1999, J AM SOC INFORM SCI, V50, P427; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; LEYDESDORFF L, 1994, SCIENTOMETRICS, V31, P59, DOI 10.1007/BF02018102; Losiewicz P, 2000, J INTELL INF SYST, V15, P99, DOI 10.1023/A:1008777222412; McCain KW, 1998, SCIENTOMETRICS, V41, P389, DOI 10.1007/BF02459053; NEDERHOF AJ, 1997, SCIENTOMETRICS, V40, P273; Newman MEJ, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.016131; Noyons ECM, 1998, SCIENTOMETRICS, V41, P61, DOI 10.1007/BF02457967; Noyons ECM, 1999, J AM SOC INFORM SCI, V50, P115, DOI 10.1002/(SICI)1097-4571(1999)50:2<115::AID-ASI3>3.0.CO;2-J; Picraux ST, 1998, IEEE SPECTRUM, V35, P24, DOI 10.1109/6.736447; Qin J, 2000, J AM SOC INFORM SCI, V51, P166, DOI 10.1002/(SICI)1097-4571(2000)51:2<166::AID-ASI8>3.3.CO;2-Q; SHNEIDERMAN B, 1996, P IEEE S VIS LANG 96; Small H, 1999, J AM SOC INFORM SCI, V50, P799, DOI 10.1002/(SICI)1097-4571(1999)50:9<799::AID-ASI9>3.3.CO;2-7; Small H, 1997, SCIENTOMETRICS, V38, P275, DOI 10.1007/BF02457414; Spasser MA, 1997, SCIENTOMETRICS, V39, P77, DOI 10.1007/BF02457431; White HD, 1998, J AM SOC INFORM SCI, V49, P327, DOI 10.1002/(SICI)1097-4571(19980401)49:4<327::AID-ASI4>3.0.CO;2-4; Wise JA, 1999, J AM SOC INFORM SCI, V50, P1224, DOI 10.1002/(SICI)1097-4571(1999)50:13<1224::AID-ASI8>3.0.CO;2-4	29	62	64	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1532-2882		J AM SOC INF SCI TEC	J. Am. Soc. Inf. Sci. Technol.	JUL	2002	53	9					764	774		10.1002/asi.10066		11	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	564ME	WOS:000176317500007	
J	Ruggieri, S				Ruggieri, S			Efficient C4.5	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						C4.5; decision trees; inductive learning; supervised learning; data mining	CLASSIFICATION ALGORITHMS; ATTRIBUTES	We present an analytic evaluation of the runtime behavior of the C4.5 algorithm which highlights some efficiency improvements. Based on the analytic evaluation, we have implemented a more efficient version of the algorithm, called EC4.5. it improves on C4.5 by adopting the best among three strategies for computing the information gain of continuous attributes. All the strategies adopt a binary search of the threshold in the whole training set starting from the local threshold computed at a rode. The first strategy computes the local threshold using the algorithm of C4.5, which, in particular, sorts cases by means of the quicksort method. The second strategy also uses the algorithm of C4.5, but adopts a counting sort method. The third strategy calculates the local threshold using a main-memory version of the RainForest algorithm, which does not need sorting. Our implementation computes the same decision trees as C4.5 with a performance gain of up to five times.	Univ Pisa, Dipartimento Informat, I-56125 Pisa, Italy	Ruggieri, S (reprint author), Univ Pisa, Dipartimento Informat, Corso Italia 40, I-56125 Pisa, Italy.						Alsabti K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; BAY SD, 1999, UCI KDD ARCH; Cormen T. H., 1992, INTRO ALGORITHMS; Elomaa T, 1999, MACH LEARN, V36, P201, DOI 10.1023/A:1007674919412; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; Fukuda T, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P146; Gehrke J, 2000, DATA MIN KNOWL DISC, V4, P127, DOI 10.1023/A:1009839829793; Gehrke J., 1999, P ACM SIGMOD INT C M, P169, DOI 10.1145/304182.304197; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; Joshi M. V., 1998, Proceedings of the First Merged International Parallel Processing Symposium and Symposium on Parallel and Distributed Processing (Cat. No.98TB100227), DOI 10.1109/IPPS.1998.669983; KEOGH E, 1998, UCI REPOSITORY MACHI; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Mehta M., 1996, P 5 INT C EXT DAT TE, P18; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1993, C45 PROGR MACH LEARN; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Rastogi R, 2000, DATA MIN KNOWL DISC, V4, P315, DOI 10.1023/A:1009887311454; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; SRIVASTAVA A, 1997, TR97010 U MINN DEP C; Srivastava A, 1999, DATA MIN KNOWL DISC, V3, P237, DOI 10.1023/A:1009832825273; *QUEST GROUP, 1999, QUEST SYN DAT GEN CO; *RUL RES LTD, 1999, C5 0 ONL DOC	22	62	80	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR-APR	2002	14	2					438	444		10.1109/69.991727		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	528CH	WOS:000174226200016	
J	Tan, PN; Kumar, V				Tan, PN; Kumar, V			Discovery of Web robot sessions based on their navigational patterns	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						web usage mining; web robot detection; classification; data mining	AGENTS	Web robots are software programs that automatically traverse the hyperlink structure of the World Wide Web in order to locate and retrieve information. There are many reasons why it is important to identify visits by Web robots and distinguish them from other users. First of all, e-commerce retailers are particularly concerned about the unauthorized deployment of robots for gathering business intelligence at their Web sites. In addition, Web robots tend to consume considerable network bandwidth at the expense of other users. Sessions due to Web robots also make it more difficult to perform clickstream analysis effectively on the Web data. Conventional techniques for detecting Web robots are often based on identifying the IP address and user agent of the Web clients. While these techniques are applicable to many well-known robots, they may not be sufficient to detect camouflaged and previously unknown robots. In this paper, we propose an alternative approach that uses the navigational patterns in the click-stream data to determine if it is due to a robot. Experimental results on our Computer Science department Web server logs show that highly accurate classification models can be built using this approach. We also show that these models are able to discover many camouflaged and previously unidentified robots.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Tan, PN (reprint author), Univ Minnesota, Dept Comp Sci, 200 Union St SE, Minneapolis, MN 55455 USA.						Balabanovic M., 1995, P AAAI SPRING S INF, P13; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Clark D, 2000, COMPUTER, V33, P18, DOI 10.1109/MC.2000.820034; COOLEY R, 1999, THESIS U MINNESOTA; Cooley R., 1999, Knowledge and Information Systems, V1; EICHMANN D, 1995, COMPUT NETWORKS ISDN, V28, P127, DOI 10.1016/0169-7552(95)00107-3; Graham L, 2000, IEEE SOFTWARE, V17, P106, DOI 10.1109/52.895177; GRAY M, 1993, MEASURING GROWTH WEB; JACKSON S, 1998, BUILDING BETTER SPID; KEPHART J, 1999, AGENTS, P378; KOLAR C, 1996, ROBOT EXCLUSION STAN; KOSTER M, 1994, GUIDELINES ROBOT WRI; Koster M., 1995, ConneXions, V9; Koster MA, 1994, STANDARD ROBOT EXCLU; Lieberman H., 1995, P 14 INT JOINT C ART, P924; PIROLLO P, 1996, CHI 96 P C HUM FACT, P118; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; ROSENSTEIN M, 2000, ACM C EL COMM MINN M, P38; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; YOON M, 2000, WEB ROBOT DETECTION	20	62	72	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		2002	6	1					9	35		10.1023/A:1013228602957		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	503VK	WOS:000172822000002	
S	Yao, YY			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Yao, YY			On modeling data mining with granular computing	25TH ANNUAL INTERNATIONAL COMPUTER SOFTWARE & APPLICATIONS CONFERENCE	Proceedings International Computer Software & Applications Conference		English	Proceedings Paper	25th Annual International Computer Software and Applications Conference (COMPSAC 2001)	OCT 08-12, 2001	CHICAGO, IL	IEEE Comp Soc				The main objective of this paper is to advocate for formal and mathematical modeling of data mining, which unfortunately has not received much attention. A framework is proposed for rule mining based on granular computing. It is developed in the Tarski's style through the notions of a model and satisfiability. The model is a database consisting of a finite set of objects described by a finite set of attributes. Within this framework, a concept is defined as a pair consisting of the intension, an expression in a certain language over the set of attributes, and the extension, a subset of the universe, of the concept. An object satisfies the expression of a concept if the object has the properties as specified by the expression, and the object belongs to the extension of the concepts. Rules are used to describe relationships between concepts. A rule is expressed in terms of the intensions of the two concepts and is interpreted in terms of the extensions of the concepts. Two interpretations of rules are examined in detail, one is based on logical implication and the other on conditional probability.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Yao, YY (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.	yyao@cs.uregina.ca	Yao, Yiyu/B-2926-2008				Bezdek JC, 1994, COMPUTATIONAL INTELL, P1; DEMRI S, 1998, INCOMPLETE INFORMATI, P347; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Goodman I.R., 1991, CONDITIONAL INFERENC; Pawlak Z., 1991, ROUGH SETS THEORETIC; Skowron A., 2001, B INT ROUGH SET SOC, V5, P9; Suzuki E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; WILLE R, 1992, COMPUT MATH APPL, V23, P493, DOI 10.1016/0898-1221(92)90120-7; Yao YY, 2000, PROCEEDINGS OF THE FIFTH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1 AND 2, P186; Yao Y. Y., 1999, P PAC AS C KNOWL DIS, P479; Yao Y. Y., 1999, P WORLD MULT SYST CY, P573; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zhong N, 1999, LECT NOTES ARTIF INT, V1704, P136	13	62	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0730-3157	0-7695-1372-7	P INT COMP SOFTW APP			2001							638	643		10.1109/CMPSAC.2001.960680		2	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BT20L	WOS:000172264100097	
J	Tresp, V				Tresp, V			A Bayesian committee machine	NEURAL COMPUTATION			English	Article							APPROXIMATION; REGRESSION; NETWORKS	The Bayesian committee machine (BCM) is a novel approach to combining estimators that were trained on different data sets. Although the BCM can be applied to the combination of any kind of estimators, the main foci are gaussian process regression and related systems such as regularization networks and smoothing splines for which the degrees of freedom increase with the number of training data. Somewhat surprisingly, we find that the performance of the BCM improves if several test points are queried at the same time and is optimal if the number of test points is at least as large as the degrees of freedom of the estimator. The BCM also provides a new solution for on-line learning with potential applications to data mining. We apply the BCM to systems with fixed basis functions and discuss its relationship to gaussian process regression. Finally, we show how the ideas behind the BCM can be applied in a non-Bayesian setting to extend the input-dependent combination of estimators.	Siemens AG, Corp Technol, Dept Informat & Commun, D-81730 Munich, Germany	Tresp, V (reprint author), Siemens AG, Corp Technol, Dept Informat & Commun, D-81730 Munich, Germany.						Bernardo J, 1994, BAYESIAN THEORY; FERRARITRECATE G, 1999, ADV NEURAL INFORMATI, V11, P218; Gibbs M, 1997, EFFICIENT IMPLEMENTA; GIROSI F, 1998, NEURAL COMPUT, V10, P1454; Hastie T.J., 1990, GEN ADDITIVE MODELS; MACKAY DJC, 1992, ADV NEUR IN, V4, P839; Mackay D. J. C., 1998, NEURAL NETWORKS MACH; MOODY J, 1997, ADV NEURAL INFORMATI, V9; MOODY JE, 1992, ADV NEUR IN, V4, P847; Neal R., 1997, 9702 U TOR DEP STAT; Neal R. M., 1996, BAYESIAN LEARNING NE; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Poggio T, 1998, NEURAL COMPUT, V10, P1445, DOI 10.1162/089976698300017250; Rasmussen C., 1996, THESIS U TORONTO; Sen A., 1990, REGRESSION ANAL; SKILLING J, 1993, PHYSICS PROBABILITY; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Taniguchi M, 1997, NEURAL COMPUT, V9, P1163, DOI 10.1162/neco.1997.9.5.1163; TRESP V, 1995, ADV NEURAL INFORMATI, V7, P419; Vapnik V.N., 1995, NATURE STAT LEARNING; WAHBA G, 1983, J ROY STAT SOC B MET, V45, P133; Wahba G, 1990, SPLINE MODELS OBSERV; Whittaker J., 1990, GRAPHICAL MODELS APP; Williams CKI, 1996, ADV NEUR IN, V8, P514; Williams CKI, 1998, NEURAL COMPUT, V10, P1203, DOI 10.1162/089976698300017412; WILLIAMS CKI, 1997, ADV NEURAL INFORMATI, V9; Williams CKI, 1998, NATO ADV SCI I D-BEH, V89, P599; ZHU H, 1998, NEURAL NETWORKS MACH, P315; Zhu HY, 1996, NEURAL COMPUT APPL, V4, P130, DOI 10.1007/BF01414873	29	62	64	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667		NEURAL COMPUT	Neural Comput.	NOV	2000	12	11					2719	2741		10.1162/089976600300014908		23	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	375LA	WOS:000165399700011	
J	Wang, K; Liu, HQ				Wang, K; Liu, HQ			Discovering structural association of semistructured data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						association rule; database; data mining; knowledge discovery; semistructured data; web mining		Many semistructured objects are similarly, though not identically, structured. We study the problem of discovering "typical" substructures of a collection of semistructured objects. The discovered structures can serve the following purposes: 1) the "table-of-contents" for gaining general information of a source, 2) a road map for browsing and querying information sources, 3) a basis for clustering documents, 4) partial schemas for providing standard database access methods, and 5) user/customer's interests and browsing patterns. The discovery task is impacted by structural features of semistructured data in a nontrivial way and traditional data mining frameworks are inapplicable. We define this discovery problem and propose a solution.	Natl Univ Singapore, Sch Comp Sci, Singapore 119260, Singapore; Natl Univ Singapore, BioInformat Ctr, Singapore 119260, Singapore	Wang, K (reprint author), Natl Univ Singapore, Sch Comp Sci, Singapore 119260, Singapore.	wangk@comp.nus.edu.sg; huiqing@bic.nus.edu.eg	WANG, Ke/H-6830-2013				ABITEBOUL S, 1997, QUERYING SEMISTRUCTU; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, VLDB, P487; Buneman P., 1996, P ACM SIGMOD INT C M, P505, DOI 10.1145/233269.233368; KONOPNICKI D, 1997, P INT JOINT C ART IN, P751; MENDELZON A, 1996, P 4 INT C PAR DISTR; Nestorov S., 1997, Proceedings of the Workshop on Management of Semi-Structured Data; NESTOROV S, 1997, P INT C DAT ENG; PAPAKONSTANTINOU Y, 1995, PROC INT CONF DATA, P251, DOI 10.1109/ICDE.1995.380386; REYNER S, 1977, SIAM J COMPUTING, V6; SEO DY, 1997, P WORKSH MAN SEM DAT, P54; WANG K, 1997, P 3 INT C KNOWL DISC, P271; Wang K., 1998, P SIGIR, P146, DOI 10.1145/290941.290982; 1997, WORKSH MAN SEM DAT	14	62	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY-JUN	2000	12	3					353	371				19	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	325GQ	WOS:000087668200002	
J	Meo, R; Psaila, G; Ceri, S				Meo, R; Psaila, G; Ceri, S			An extension to SQL for mining association rules	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						association rules; data mining and relational databases		Data mining evolved as a collection of applicative problems and efficient solution algorithms relative to rather peculiar problems, all focused on the discovery of relevant information hidden in databases of huge dimensions. In particular, one of the most investigated topics is the discovery of association rules. This work proposes a unifying model that enables a uniform description of the problem of discovering association rules. The model provides a SQL-like operator, named MINE RULE, which is capable of expressing all the problems presented so far in the literature concerning the mining of association rules. We demonstrate the expressive power of the new operator by means of several examples, some of which are classical, while some others are fully original and correspond to novel and unusual applications. We also present the operational semantics of the operator by means of an extended relational algebra.	Politecn Torino, Dipartimento Automat & Informat, I-10129 Turin, Italy; Politecn Milan, Dip Elettron & Informaz, I-20133 Milan, Italy	Meo, R (reprint author), Politecn Torino, Dipartimento Automat & Informat, Cso Duca degli Abruzzi 24, I-10129 Turin, Italy.	rosimeo@polito.it; psaila@elet.polimi.it; ceri@elet.polimi.it	Meo, Rosa/E-9345-2012				AGRAWAL R, 1995, KNOWLEDGE DISCOVERY, V2; Agrawal R, 1995, INT C DAT ENG TAIP T; Agrawal R., 1992, 18 INT C VER LARG DA, P560; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 1995, P 21 VLDB C ZUR SWIT; Agrawal R., 1994, P 20 VLDB C SANT CHI; AGRAWAL R, 1993, 4 INT C FDN DAT ORG; Atzeni P., 1993, RELATIONAL DATABASE; FALOUTSOS C, 1994, P ACM SIGMOD C MAN D; GRAY J, 1996, ICDE96 12 INT C DAT, P560; HAN J, 1995, P 21 VLDB C ZUR SWIT; HOUTSMA MAW, 1995, 11 INT C DAT ENG TAI; HOUTSMA MAW, 1996, IN PRESS DATA KNOWLE; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; MEO R, 1998, P IEEE INT C DAT ENG; Park J.S., 1995, P ACM SIGMOD INT C M; Srikant R, 1995, 9963 RJ IBM ALM RES; Srikant R., 1995, P 21 VLDB C ZUR SWIT; ULLMAN JD, 1988, PRINCIPLES COMPUTER, V1	20	62	62	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUN	1998	2	2					195	224		10.1023/A:1009774406717		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	123NZ	WOS:000076132400004	
S	Zaiane, OR; Xin, M; Han, JW			IEEE COMP SOC; IEEE COMP SOC	Zaiane, OR; Xin, M; Han, JW			Discovering web access patterns and trends by applying OLAP and data mining technology on web logs	IEEE INTERNATIONAL FORUM ON RESEARCH AND TECHNOLOGY ADVANCES IN DIGITAL LIBRARIES -ADL'98-, PROCEEDINGS	PROCEEDINGS - IEEE INTERNATIONAL FORUM ON RESEARCH AND TECHNOLOGY ADVANCES IN DIGITAL LIBRARIES		English	Proceedings Paper	IEEE International Forum on Research and Technology Advances in Digital Libraries (ADL 98)	APR 22-24, 1998	SANTA BARBARA, CA	IEEE Comp Soc, Tech Comm Digital Libs, NASA Goddard Space Flight Ctr, Natl Lib Med, Alexandria Digital Lib, Lib Congress, CESDIS, Hughes Aircraft, IBM				As a confluence of data mining and WWW technologies, it is now possible to perform data mining on web log records collected from the Internet web page access history. The behaviour of the web page readers is imprinted in the web server log files. Analyzing and exploring regularities in this behaviour can improve system performance, enhance the quality and delivery of Internet information services to the end user, and identify population of potential customers for electronic commerce. Thus, by observing people using collections of data, data mining can bring considerable contribution to digital library designers. In a joint effort between the TeleLearning-NCE project on Virtual University and NCE-IRIS project on data mining, we have been developing the knowledge discovery tool, WebLogMiner, for mining web server log files. This paper presents the design of the WebLogMiner, reports the current progress, and outlines the future work in this direction.	Simon Fraser Univ, Sch Comp Sci, Virtual U Res Lab, Burnaby, BC V5A 1S6, Canada	Zaiane, OR (reprint author), Simon Fraser Univ, Sch Comp Sci, Virtual U Res Lab, Burnaby, BC V5A 1S6, Canada.							0	62	85	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1092-9959	0-8186-8464-X	P IEEE INT FORUM RES			1998							19	29		10.1109/ADL.1998.670376		11	Computer Science, Information Systems	Computer Science	BK94U	WOS:000073925000003	
J	Hsieh, NC				Hsieh, NC			Hybrid mining approach in the design of credit scoring models	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; credit scoring model; clustering; class-wise classification; neural network	K-MEANS ALGORITHM; NEURAL-NETWORKS; MARKET-SEGMENTATION; PERFORMANCE; CUSTOMERS	Unrepresentative data samples are likely to reduce the utility of data classifiers in practical application. This study presents a hybrid mining approach in the design of an effective credit scoring model, based on clustering and neural network techniques. We used clustering techniques to preprocess the input samples with the objective of indicating unrepresentative samples into isolated and inconsistent clusters, and used neural networks to construct the credit scoring model. The clustering stage involved a class-wise classification process. A self-organizing map clustering algorithm was used to automatically determine the number of clusters and the starting points of each cluster. Then, the K-means clustering algorithm was used to generate clusters of samples belonging to new classes and eliminate the unrepresentative samples from each class. In the neural network stage, samples with new class labels were used in the design of the credit scoring model. The proposed method demonstrates by two real world credit data sets that the hybrid mining approach can be used to build effective credit scoring models. (c) 2005 Elsevier Ltd. All rights reserved.	Natl Taipei Coll Nursing, Dept Informat Management, Taipei 11257, Taiwan	Hsieh, NC (reprint author), Natl Taipei Coll Nursing, Dept Informat Management, 365 Min Ten Rd, Taipei 11257, Taiwan.	nchsieh@mail1.ntcn.edu.tw					Balakrishnan PV, 1996, EUR J OPER RES, V93, P346, DOI 10.1016/0377-2217(96)00046-X; Chen MC, 2003, EXPERT SYST APPL, V24, P433, DOI 10.1016/S0957-4174(02)00191-4; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; GOPALAKRISHNAN M, 1995, PATTERN RECOGN LETT, V16, P59, DOI 10.1016/0167-8655(94)00064-A; Hand D. J., 1981, DISCRIMINATION CLASS; Hornik K, 1989, NEURAL NETWORKS, V2, P336; Hruschka H, 1999, EUR J OPER RES, V114, P346, DOI 10.1016/S0377-2217(98)00170-2; Hsieh NC, 2004, EXPERT SYST APPL, V27, P623, DOI 10.1016/j.eswa.2004.06.007; Hush DR, 1993, IEEE SIGNAL PROC MAG, V10, P8, DOI 10.1109/79.180705; Johnson R. A., 1998, APPL MULTIVARIATE ST; Kim Y, 2004, DECIS SUPPORT SYST, V37, P215, DOI 10.1016/S0167-9236(03)00008-3; Kim YS, 2004, EXPERT SYST APPL, V26, P567, DOI 10.1016/j.eswa.2003.10.013; Kuo RJ, 2002, COMPUT OPER RES, V29, P1475, DOI 10.1016/S0305-0548(01)00043-0; Lancher R.C., 1995, EUR J OPER RES, V85, P53; Lee TS, 2002, EXPERT SYST APPL, V23, P245, DOI 10.1016/S0957-4174(02)00044-1; Malhotra R, 2003, OMEGA-INT J MANAGE S, V31, P83, DOI 10.1016/S0305-0483(03)00016-1; Morrison D. F., 1990, MULTIVARIATE STAT ME; Natter M., 1999, J RETAILING CONSUMER, V6, P237, DOI 10.1016/S0969-6989(98)00008-3; PUNJ G, 1983, J MARKETING RES, V20, P134, DOI 10.2307/3151680; Setiono R, 1998, INFORM MANAGE, V34, P91, DOI 10.1016/S0378-7206(98)00048-2; Sharda R., 1996, INT J COMPUTATIONAL, V1, P107; Sung AH, 1998, EXPERT SYST APPL, V15, P405, DOI 10.1016/S0957-4174(98)00041-4; Swales G. S.  Jr., 1992, Financial Analysts Journal, V48, DOI 10.2469/faj.v48.n5.78; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Thomas LC, 2000, INT J FORECASTING, V16, P149, DOI 10.1016/S0169-2070(00)00034-0; Vellido A, 1999, EXPERT SYST APPL, V17, P51, DOI 10.1016/S0957-4174(99)00016-0; West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5; Zhang GQ, 1999, EUR J OPER RES, V116, P16, DOI 10.1016/S0377-2217(98)00051-4	28	61	61	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2005	28	4					655	665		10.1016/j.eswa.204.12.022		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	913BD	WOS:000228124200006	
S	Goethals, B; Laur, S; Lipmaa, H; Mielikainen, T		Park, C; Chee, S		Goethals, B; Laur, S; Lipmaa, H; Mielikainen, T			On private scalar product computation for privacy-preserving data mining	INFORMATION SECURITY AND CRYPTOLOGY - ICISC 2004	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Information Security and Cryptology (ICISC 2004)	DEC 02-03, 2004	Seoul, SOUTH KOREA	Korea Inst Informat Secur Cryptol		privacy-preserving data mining; private scalar product protocol; vertically partitioned frequent pattern mining		In mining and integrating data from multiple sources, there are many privacy and security issues. In several different contexts, the security of the full privacy-preserving data mining protocol depends on the security of the underlying private scalar product protocol. We show that two of the private scalar product protocols, one of which was proposed in a leading data mining conference, are insecure. We then describe a provably private scalar product protocol that is based on homomorphic encryption and improve its efficiency so that it can also be used on massive datasets.	Univ Helsinki, Dept Comp Sci, HIIT Basic Res Unit, FIN-00014 Helsinki, Finland; Helsinki Univ Technol, Dept Comp Sci & Engn, Lab Theoret Comp Sci, FIN-02150 Espoo, Finland	Goethals, B (reprint author), Univ Helsinki, Dept Comp Sci, HIIT Basic Res Unit, FIN-00014 Helsinki, Finland.	goethals@cs.helsinki.fi; slaur@tcs.hut.fi; helger@tcs.hut.fi; tmielika@cs.helsinki.fi					Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Aiello W., 2001, LNCS, V2045, P119; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; CRAMER R, 1997, LECT NOTES COMPUTER, V1233, P103; Damgard I, 2001, LECT NOTES COMPUT SC, V1992, P119; DU WL, 2001, PROTOCOLS SECURE REM, V2, P192; DU WL, P 17 ANN COMP SEC AP, P102; DU WL, P NEW SEC PAR WORKSH, P127; Freedman MJ, 2004, LECT NOTES COMPUT SC, V3027, P1; Goldreich O., 2004, FDN CRYPTOGRAPHY BAS; JACOBUS H, 1992, COURCE COMBINATORIES; Laur S., 2004, P 9 NORD WORKSH SEC, P73; LAUR S, 2005, ADDITIVE CONDITIONAL; LIPMAA H, 2004, OBLIVIOUS TRANSFER P; Lipmaa H, 2003, LECT NOTES COMPUT SC, V2894, P398; Lipmaa Hi., 2002, LECT NOTES COMPUTER, V2357, P87; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; PEI J, 2000, 2000 ACM SIGMOD WORK; PINKAS B, 2002, KDD EXPLORATIONS, V4, P12; Vaida J., 2002, P 8 ACM SIGKDD INT C, P639; Wright R, 2004, P 10 ACM SIGKDD INT, P713, DOI 10.1145/1014052.1014145; 2000, LECT NOTES COMPUTER, V1805, P62	22	61	61	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26226-1	LECT NOTES COMPUT SC			2004	3506						104	120				17	Computer Science, Theory & Methods	Computer Science	BCO37	WOS:000230406700007	
J	Chen, X; Rusinko, A; Tropsha, A; Young, SS				Chen, X; Rusinko, A; Tropsha, A; Young, SS			Automated pharmacophore identification for large chemical data sets	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							COMBINATORIAL TECHNOLOGIES; CONFORMATIONAL HYPERSPACE; ASSAY TECHNOLOGIES; DRUG DISCOVERY; VALIDATION; DESCRIPTORS; ALGORITHMS; STRATEGIES; MOLECULES; LIBRARY	The identification of three-dimensional pharmacophores from large, heterogeneous data sets is still an unsolved problem. We developed a novel program, SCAMPI (statistical classification of activities of molecules for pharmacophore identification), for this purpose by combining a fast conformation search with recursive partitioning, a data-mining technique, which can easily handle large data sets. The pharmacophore identification process is designed to run recursively, and the conformation spaces are resampled under the constraints of the evolving pharmacophore model. This program is capable of deriving pharmacophores from a data set of 1000-2000 compounds, with thousands of conformations generated for each compound and in less than 1 day of computational time. For two test data sets, the identified pharmacophores are consistent with the known results from the literature.	Glaxo Wellcome Inc, Chemoinformat Grp, Res Informat Syst, Res Triangle Pk, NC 27709 USA; Univ N Carolina, Sch Pharm, Lab Mol Modeling, Chapel Hill, NC 27599 USA; Alcon Labs Inc, Med Chem, Ft Worth, TX 76134 USA	Young, SS (reprint author), Glaxo Wellcome Inc, Chemoinformat Grp, Res Informat Syst, Res Triangle Pk, NC 27709 USA.						Barnum D, 1996, J CHEM INF COMP SCI, V36, P563, DOI 10.1021/ci950273r; BEUSEN DD, 1996, DRUG DISCOV TODAY, V1, P429, DOI 10.1016/S1359-6446(96)80009-2; Bravi G, 1997, J COMPUT CHEM, V18, P1295, DOI 10.1002/(SICI)1096-987X(19970730)18:10<1295::AID-JCC4>3.0.CO;2-I; BRINT AT, 1987, J CHEM INF COMP SCI, V27, P152, DOI 10.1021/ci00056a002; BRINT AT, 1987, J MOL GRAPHICS, V5, P49; Brown RD, 1996, J CHEM INF COMP SCI, V36, P572, DOI 10.1021/ci9501047; Chen X, 1998, J CHEM INF COMP SCI, V38, P1054, DOI 10.1021/ci980089g; CLARK M, 1989, J COMPUT CHEM, V10, P982, DOI 10.1002/jcc.540100804; DAMMKOEHLER RA, 1989, J COMPUT AID MOL DES, V3, P3, DOI 10.1007/BF01590992; Dammkoehler RA, 1995, J COMPUT AID MOL DES, V9, P491, DOI 10.1007/BF00124320; DAVIES K, 3D PHARMACOPHORE SEA; DEPRIEST SA, 1993, J AM CHEM SOC, V115, P5372, DOI 10.1021/ja00066a004; FINN P, 1998, MACHINE LEARNING SPE, P1; GALLOP MA, 1994, J MED CHEM, V37, P1233, DOI 10.1021/jm00035a001; GOLENDER V, NET SCI; GOOD AC, 1996, REV COMP CH, V7, P67; GORDON EM, 1994, J MED CHEM, V37, P1385, DOI 10.1021/jm00036a001; GREENE J, 1994, J CHEM INF COMP SCI, V34, P1297, DOI 10.1021/ci00022a012; Hawkins D. M., 1982, TOPICS APPL MULTIVAR, P269; HAWKINS DM, 1997, QUANT STRUCT-ACT REL, V16, P1; HUMBLET C, 1980, ANNU REP MED CHEM, V15, P267, DOI 10.1016/S0065-7743(08)60389-9; HURST T, 1994, J CHEM INF COMP SCI, V34, P190, DOI 10.1021/ci00017a025; JAIN AN, 1994, J COMPUT AID MOL DES, V8, P635, DOI 10.1007/BF00124012; Leach A, 1991, REV COMPUTATIONAL CH, V2, P1, DOI 10.1002/9780470125793.ch1; Marshall G. R., 1979, ACS SYM SER, P205; MARTIN YC, 1993, J COMPUT AID MOL DES, V7, P83, DOI 10.1007/BF00141577; MAYCOCK AL, 1976, BIOCHEMISTRY-US, V15, P114, DOI 10.1021/bi00646a018; Mayer D, 1987, J Comput Aided Mol Des, V1, P3, DOI 10.1007/BF01680553; MILLER RG, 1981, SIMULTANEOUS STAT IN; MOTOC I, 1986, QUANT STRUCT-ACT REL, V5, P99, DOI 10.1002/qsar.19860050305; MOTOC I, 1985, MATH COMPUTATIONAL C, P222; MOTOC I, 1986, MATH COMPUTATIONAL C, P222; NELSON SD, 1976, SCIENCE, V193, P901, DOI 10.1126/science.7838; NICKLAUS MC, 1995, BIOORGAN MED CHEM, V3, P411, DOI 10.1016/0968-0896(95)00031-B; SHERIDAN RP, 1986, J MED CHEM, V29, P899, DOI 10.1021/jm00156a005; Silverman L, 1998, CURR OPIN CHEM BIOL, V2, P397, DOI 10.1016/S1367-5931(98)80015-X; Sittampalam GS, 1997, CURR OPIN CHEM BIOL, V1, P384, DOI 10.1016/S1367-5931(97)80078-6; SMELLIE A, 1995, J CHEM INF COMP SCI, V35, P285, DOI 10.1021/ci00024a018; SMELLIE A, 1995, J COMPUT CHEM, V16, P171, DOI 10.1002/jcc.540160205; Sprague PW, 1995, PERSPECT DRUG DISCOV, V3, P1, DOI 10.1007/BF02174464; Thompson S.K., 1992, SAMPLING; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; VanDrie JH, 1997, J COMPUT AID MOL DES, V11, P39; Van Drie JH, 1998, SAR QSAR ENVIRON RES, V9, P1, DOI 10.1080/10629369808039146; WANG SM, 1994, J MED CHEM, V37, P4479, DOI 10.1021/jm00052a007; Willett P, 1987, SIMILARITY CLUSTERIN; YOUNG SS, 1995, J MED CHEM, V38, P2784, DOI 10.1021/jm00014a030; Young SS, 1998, SAR QSAR ENVIRON RES, V8, P183, DOI 10.1080/10629369808039140; *BIOC CORP, 1993, CAT HYP TUT VERS 2 0; *MOL SIM INC, 1995, HIPH TUR VERS 2 3; *TRIP INC, 1995, MOL DIV MAN GEN LEAD; CONCORD PROGRAM RAPI	52	61	62	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	SEP-OCT	1999	39	5					887	896		10.1021/ci990327n		10	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	240YT	WOS:000082854900014	
B	Lee, W; Stolfo, SJ			USENIX	Lee, W; Stolfo, SJ			Data mining approaches for intrusion detection	PROCEEDINGS OF THE SEVENTH USENIX SECURITY SYMPOSIUM			English	Proceedings Paper	7th USENIX Security Symposium	JAN 26-29, 1998	SAN ANTONIO, TX	USENIX Assoc, Comp Emergency Response Team				In this paper we discuss our research in developing general and systematic methods for intrusion detection. The key ideas are to use data mining techniques to discover consistent and useful patterns of system features that describe program and user behavior, and use the set of relevant system features to compute (inductively learned) classifiers that can recognize anomalies and known intrusions. Using experiments on the sendmail system call data and the network tcpdump data, we demonstrate that we can construct concise and accurate classifiers to detect anomalies. We provide an overview on two general data mining algorithms that we have implemented: the association rules algorithm and the frequent episodes algorithm. These algorithms can be used to compute the intra-and inter-audit record patterns, which are essential in describing program or user behavior. The discovered patterns can guide the audit data gathering process and facilitate feature selection. To meet the challenges of both efficient learning (mining) and real-time detection, we propose an agent-based architecture for intrusion detection systems where the learning agents continuously compute and provide the updated (detection) models to the detection agents.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Lee, W (reprint author), Columbia Univ, Dept Comp Sci, 500 W 120th St, New York, NY 10027 USA.							0	61	78	USENIX ASSOC	BERKELEY	SUITE 215, 2560 NINTH ST, BERKELEY, CA 94710 USA		1-880446-92-8				1998							79	93				15	Computer Science, Theory & Methods	Computer Science	BK54E	WOS:000072521000006	
J	Hullermeier, E				Hullermeier, E			Fuzzy methods in machine learning and data mining: Status and prospects	FUZZY SETS AND SYSTEMS			English	Article						machine learning; data mining; knowledge discovery	SYSTEMS; RULES	Over the past years, methods for the automated induction of models and the extraction of interesting patterns from empirical data have attracted considerable attention in the fuzzy set community. This paper briefly reviews some typical applications and highlights potential contributions that fuzzy set theory can make to machine learning, data mining, and related fields. The paper concludes with a critical consideration of recent developments and some suggestions for future research directions. (c) 2005 Elsevier B.V All rights reserved.	Univ Magdeburg, Fac Comp Sci, D-39106 Magdeburg, Germany	Hullermeier, E (reprint author), Univ Magdeburg, Fac Comp Sci, Univ Pl 2, D-39106 Magdeburg, Germany.	eyke.huellermeier@iti.cs.uni-magdeburg.de					Agrawal R., 1994, P 20 INT C VER LARG, P487; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aha D.W., 1997, LAZY LEARNING; Babuska R., 1998, FUZZY MODELING CONTR; Bandemer H., 1992, FUZZY DATA ANAL; BORGELT C, 2002, GRAHICAL MODELS METH; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CASSILLAS J, 2003, INTERPRETABILITY ISS; Chen G., 2003, P ISIS 2003 4 INT S; Chen YX, 2003, IEEE T FUZZY SYST, V11, P716, DOI 10.1109/TFUZZ.2003.819843; Cordon O, 2004, FUZZY SET SYST, V141, P5, DOI 10.1016/S0165-0114(03)00111-8; Cordon O., 1998, MATHWARE SOFT COMPUT, V5, P321; DANG TH, 2004, P IPMU 2004 PER IT; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Delgado M, 2003, IEEE T FUZZY SYST, V11, P214, DOI 10.1109/TFUZZ.2003.809896; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DIAMOND P, 1998, FUZZY SETS DECISION, P349; Diamond P., 1994, METRIC SPACES FUZZY; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dubois D, 1996, IEEE T SYST MAN CY A, V26, P361, DOI 10.1109/3468.487961; Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8; Dubois D, 1998, INT J INTELL SYST, V13, P345, DOI 10.1002/(SICI)1098-111X(199804)13:4<345::AID-INT3>3.3.CO;2-I; Dubois D, 2002, IEEE T FUZZY SYST, V10, P322, DOI 10.1109/TFUZZ.2002.1006435; Dubois D., 2003, LECT NOTES ARTIF INT, V2715, P677; ELOUEDI Z, 2000, P INT C INF PROC MAN, V1, P141; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Freund Y., 1996, INT C MACH LEARN, P148; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; FURNKRAZ J, 2003, ECML 2003; Gasch AP, 2002, GENOME BIOL, V3; GEBHARDT J, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, P1089, DOI 10.1109/FUZZY.1992.258699; HARPELED S, 2002, P 13 INT C ALG LEARN, P365; Hoppner F., 1999, FUZZY CLUSTER ANAL; Hullermeier E, 2001, LECT NOTES ARTIF INT, V2168, P241; HULLERMEIER E, 2005, P IJCAI 05 19 INT JO; Hullermeier E, 2002, P ECML 02 13 EUR C M, P173; HULLERMEIER E, 2005, MATHWARE SOFTCOMPUT, V11, P109; Hullermeier E, 2003, ARTIF INTELL, V148, P335, DOI 10.1016/S0004-3702(03)00019-5; Janikow CZ, 1998, IEEE T SYST MAN CY B, V28, P1, DOI 10.1109/3477.658573; Kolodner J. L., 1993, CASE BASED REASONING; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; Kruse R, 2003, INT J APPROX REASON, V32, P63, DOI 10.1016/S0888-613X(02)00088-9; Laurent A, 2003, INTELL DATA ANAL, V7, P155; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MITCHELL TM, 1980, CBMTR117 TR RUTG U; Nauck D., 1997, FDN NEUROFUZZY SYSTE; OLARU C, 2003, FUZZY SETS SYSTEMS, V138; Pearl J., 1988, PROBABILISTIC REASON; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Riesbeck C., 1989, INSIDE CASE BASED RE; RUSPINI EH, 1991, UNCERTAINTY ARTIFICI, V6; SAVASERE A, 1995, VLDB 95, P11; Scholkopf B, 2001, LEARNING KERNELS SUP; Sudkamp T, 2000, P 90 IEEE INT C FUZZ, P735; SUDKAMP T, 2005, FUZZY SETS SYSTEMS, V149; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V. N., 2000, NATURE STAT LEARNING; Viertl R., 1996, STAT METHODS NONPREC; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; WEBER R, 1992, IIZUKA 92 P 2 INT C, V1, P265; Yager RR, 2004, APPL INTELL, V21, P277, DOI 10.1023/B:APIN.0000043560.57137.20	63	60	61	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	DEC 16	2005	156	3					387	406		10.1016/j.fss.2005.05.036		20	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	980XJ	WOS:000233051200009	
J	Tan, KC; Yu, Q; Heng, CM; Lee, TH				Tan, KC; Yu, Q; Heng, CM; Lee, TH			Evolutionary computing for knowledge discovery in medical diagnosis	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						medical diagnosis; knowledge discovery; data mining; evolutionary computing	BREAST-CANCER DIAGNOSIS; ARTIFICIAL NEURAL-NETWORKS; CLASSIFICATION RULES; ALGORITHM; OPTIMIZATION; COMPUTATION; SETS	One of the major challenges in medical domain is the extraction of comprehensible knowledge from medical diagnosis data. In this paper, a two-phase hybrid evolutionary classification technique is proposed to extract classification rules that can be used in clinical practice for better understanding and prevention of unwanted medical events. In the first phase, a hybrid evolutionary algorithm (EA) is utilized to confine the search space by evolving a pool of good candidate rules, e.g. genetic programming (GP) is applied to evolve nominal attributes for free structured rules and genetic algorithm (GA) is used to optimize the numeric attributes for concise classification rules without the need of discretization. These candidate rules are then used in the second phase to optimize the order and number of rules in the evolution for forming accurate and comprehensible rule sets. The proposed evolutionary classifier (EvoC) is validated upon hepatitis and breast cancer datasets obtained from the UCI machine-learning repository. Simulation results show that the evolutionary classifier produces comprehensible rules and good classification accuracy for the medical datasets. Results obtained from t-tests further justify its robustness and invariance to random partition of datasets. (C) 2003 Elsevier Science B.V. All rights reserved.	Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Tan, KC (reprint author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.	eletankc@nus.edu.sg					Banzhaf W., 1998, GENETIC PROGRAMMING; Bojarczuk CC, 2000, IEEE ENG MED BIOL, V19, P38, DOI 10.1109/51.853480; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; Cattral R., 1999, P C EV COMP CEC99, V1, P125; CESTNIK G, 1987, MACH LEARN, P31; CHANG YH, 1999, P INT JOINT C NEUR N, V5, P3674; CONGDON CB, 2000, P IEEE C EV COMP, V1, P442, DOI 10.1109/CEC.2000.870330; FIDELIS MV, 2000, P 2000 C EV COMP, V1, P805, DOI 10.1109/CEC.2000.870381; Frank E, 1998, P 15 INT C MACH LEAR, P144; FREITAS A. A, 2002, ADV EVOLUTIONARY COM; Garner S, 1995, P NZ COMP SCI RES ST, P57; Goldberg D.E., 1989, GENETIC ALGORITHMS S; HOWARD LM, 1995, IEEE EXPERT, V10, P11, DOI 10.1109/64.393137; Hruschka E. R., 2000, International Journal of Computers, Systems and Signals, V1; HU YJ, 1998, FEATURE EXTRACTION C, P257; John G.H, 1995, P 11 C UNC ART INT, P338; JOSHI MV, 2001, P ACM SIGMOD C SANT, P91, DOI 10.1145/375663.375673; Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0; Komosinski M, 2000, ARTIF INTELL MED, V19, P25, DOI 10.1016/S0933-3657(99)00048-2; Koza J. R., 1992, GENETIC PROGRAMMING; Kupinski MA, 1999, IEEE T MED IMAGING, V18, P675, DOI 10.1109/42.796281; Wong ML, 2000, GENET PROGR SER, V3, P1; Liu JNK, 2001, IEEE T SYST MAN CY C, V31, P249, DOI 10.1109/5326.941848; MEESAD P, 2001, P INT JOINT C NEUR N, V4, P2558; Michalewicz Z., 1994, GENETIC ALGORITHMS P; Montgomery D. C., 2001, ENG STAT; Pena-Reyes CA, 1999, ARTIF INTELL MED, V17, P131, DOI 10.1016/S0933-3657(99)00019-6; Pena-Reyes CA, 2000, ARTIF INTELL MED, V19, P1, DOI 10.1016/S0933-3657(99)00047-0; Pena-Reyes CA, 2001, IEEE T FUZZY SYST, V9, P727, DOI 10.1109/91.963759; Prechelt L, 1995, NEUROCOMPUTING, V9, P343, DOI 10.1016/0925-2312(95)00084-1; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; Setiono R, 2000, ARTIF INTELL MED, V18, P205, DOI 10.1016/S0933-3657(99)00041-X; Setiono R, 1996, ARTIF INTELL MED, V8, P37, DOI 10.1016/0933-3657(95)00019-4; Street W., 1993, IS T SPIE 1993 INT S, P861; TAHA I, 1996, TR9701106 U TEX COMP; Tan KC, 2002, IEEE C EVOL COMPUTAT, P1302; Tan KC, 2002, ARTIF INTELL MED, V25, P169, DOI 10.1016/S0933-3657(02)00014-3; Tan KC, 2001, IEEE T SYST MAN CY B, V31, P537, DOI 10.1109/3477.938259; Wang CH, 1998, IEEE T SYST MAN CY C, V28, P471; Wang CH, 2000, FUZZY SET SYST, V112, P141, DOI 10.1016/S0165-0114(97)00385-0; Witten I.H., 1999, DATA MINING PRACTICA; Wong ML, 2000, IEEE ENG MED BIOL, V19, P45; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107	43	60	61	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	FEB	2003	27	2					129	154		10.1016/S0933-3657(03)00002-2		26	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	662KR	WOS:000181946300002	
S	Schultz, MG; Eskin, E; Zadok, E; Stolfo, SJ			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Schultz, MG; Eskin, E; Zadok, E; Stolfo, SJ			Data mining methods for detection of new malicious executables	2001 IEEE SYMPOSIUM ON SECURITY AND PRIVACY, PROCEEDINGS	PROCEEDINGS: IEEE SYMPOSIUM ON SECURITY AND PRIVACY		English	Proceedings Paper	2001 IEEE Symposium on Security and Privacy (S&P 2001)	MAY 14-16, 2001	OAKLAND, CA	IEEE Comp Soc, Tech Comm Secur & Privacy				A serious security threat today is malicious executables, especially new, unseen malicious executables often arriving as email attachments. These new malicious executables are created at the rare of thousands every year and pose a serious security threat. Current anti-virus systems attempt to detect these new malicious programs with heuristics generated by hand. This approach is costly and oftentimes ineffective. In this paper we present a data-mining framework that detects new, previously unseen malicious executables accurately and automatically: The data-mining framework automatically found patterns in our data set and used these patterns to detect a set of new malicious binaries. Comparing our detection methods with a traditional signature-based method, our method more than doubles the current detection rates for new malicious executables.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Schultz, MG (reprint author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.						ARNOLD W, 2000, P 2000 INT VIR B C; COHEN F, 1990, SHORT COURSE COMPUTE; COHEN W, 1996, LEARNING TREES RULES; CRAWFORD R, 1993, P 6 INT COMP VIR SEC; ESKIN E, 2000, P 8 INT C INT SYST M; Gryaznov D., 1999, P 5 INT VIR B; Kephart J., 1994, 4 VIR B INT C, P178; KERCHEN P, 1990, P 13 NAT COMP SEC C, P350; Kohavi R., 1995, IJCAI; Lee W., 1997, AAAI WORKSH AI APPR, P50; Lee W, 1999, IEEE S SEC PRIV; LO RW, 1995, COMPUT SECUR, V14, P541, DOI 10.1016/0167-4048(95)00012-W; MICHIE D, 1994, MACHINE LEARNING RUL; Mitchell T. M, 1997, MACHINE LEARNING; NIGAM K, 1998, AAAI98; REUTERS, 2000, NY TIMES        1029; SPAFFORD EH, 1988, CSDTR823 PURD U DEP; Tesauro GJ, 1996, IEEE EXPERT, V11, P5, DOI 10.1109/64.511768; WHITE S, 1999, ANATOMY COMMERCIAL G; WHITE SR, 1998, VIR B C; ZOU KH, 1997, STAT MED; *MIT LINC LABS, 1999, 1999 DARPA INTR DET	22	60	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1081-6011	0-7695-1046-9	P IEEE S SECUR PRIV			2001							38	49		10.1109/SECPRI.2001.924286		12	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	BS28K	WOS:000169358400004	
J	Daszykowski, M; Walczak, B; Massart, DL				Daszykowski, M; Walczak, B; Massart, DL			Projection methods in chemistry	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						projection pursuit; Generative Topographic Mapping; visualization of data structure; data compression; nonlinear PCA	AUTOASSOCIATIVE NEURAL NETWORKS; PURSUIT; ALGORITHMS	Visualization of a data set structure is one of the most challenging goals in data mining. Often, chemical data sets are multidimensional, and therefore visualization of their structure is not directly possible. To overcome this problem, the original data is compressed to the few new features by using projection techniques, preserving the original data structure as good as possible, and allowing its visualization. In this paper, a survey of different projection techniques, linear and nonlinear, is given. Their performance is illustrated on chemical data sets, and the advantages and disadvantages are pointed out. (C) 2003 Elsevier Science B.V. All rights reserved.	Free Univ Brussels, FABI, ChemoAC, B-1090 Brussels, Belgium	Massart, DL (reprint author), Free Univ Brussels, FABI, ChemoAC, Laarbeeklaan 103, B-1090 Brussels, Belgium.						ACKLEY DH, 1985, COGNITIVE SCI, V9, P147, DOI 10.1016/S0364-0213(85)80012-4; Aldrich C, 1998, PATTERN RECOGN LETT, V19, P749, DOI 10.1016/S0167-8655(98)00054-3; Aldrich C, 2000, CHEM ENG COMMUN, V177, P121, DOI 10.1080/00986440008912164; BARNES RJ, 1989, APPL SPECTROSC, V43, P772, DOI 10.1366/0003702894202201; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; BISHOP CM, P 1996 INT C ART NEU, P165; BISHOP CM, 1996, ADV NEURAL INFORMATI, V8; Croux C, 1996, P COMP STAT, P211; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P817; Golub G. H., 1983, MATRIX COMPUTATIONS; Goodacre R, 1996, CHEMOMETR INTELL LAB, V34, P69, DOI 10.1016/0169-7439(96)00021-4; Guo Q, 2000, ANAL CHEM, V72, P2846, DOI 10.1021/ac0000123; HINTON GE, 1986, P ANN C COGN SCI SOC, V1; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; JONES MC, 1987, J ROY STAT SOC A STA, V150, P1, DOI 10.2307/2981662; KOHONEN T, 1997, SELFORGANIZING MAPS; KOHONEN T, 1990, SELFORGANISATION ASS; KRAMER MA, 1992, COMPUT CHEM ENG, V16, P313, DOI 10.1016/0098-1354(92)80051-A; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Kruskal J. B., 1969, STAT COMPUTATION; LUYPAERT J, IN PRESS J PHARM BIO; Malinowski E. R., 1991, FACTOR ANAL CHEM; Mardia K.V., 1979, MULTIVARIATE ANAL PR; MELSSEN WJ, 1994, CHEMOMETR INTELL LAB, V23, P267, DOI 10.1016/0169-7439(93)E0036-4; MORE J, 1977, LECT NOTES MATH, P630; NASON G, 1992, THESIS U BATH; NASON G, 1995, J ROYAL STAT SOC C, V44, P4; Pearson K, 1901, PHILOS MAG, V2, P559; Ripley B., 1996, PATTERN RECOGNITION; ROY SN, 1953, ANN MATH STAT, V24, P220, DOI 10.1214/aoms/1177729029; RUBIN DB, 1982, PSYCHOMETRIKA, V47, P69, DOI 10.1007/BF02293851; SAMMON JA, 1969, IEEE T COMPUT, V18, P459; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SCOTT D, 1983, COMPUTER SCI STAT; SILVERMAN BW, 1981, J ROY STAT SOC B MET, V43, P97; Svensen J. F. M., 1998, THESIS ASTON U; THEISSEN U, 2001, ANAL CHIM ACTA, V446, P371; Tibshirani R., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889678; Wasserman P.D., 1989, NEURAL COMPUTING; WOLD H, 1970, PERSPECTIVES PROBABI, P403; YENYUKOV IS, 1989, DATA ANALYSIS, LEARNING SYMBOLIC AND NUMERIC KNOWLEDGE, P181; Zupan J, 1999, NEURAL NETWORKS CHEM	46	59	60	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	JAN 28	2003	65	1					97	112		10.1016/S0169-7439(02)00107-7		16	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	635FC	WOS:000180387200007	
J	Losiewicz, P; Oard, DW; Kostoff, RN				Losiewicz, P; Oard, DW; Kostoff, RN			Textual data mining to support science and technology management	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						text data mining; information retrieval; knowledge discovery in databases; bibliometrics; computational linguistics		This paper surveys applications of data mining techniques to large text collections, and illustrates how those techniques can be used to support the management of science and technology research. Specific issues that arise repeatedly in the conduct of research management are described, and a textual data mining architecture that extends a classic paradigm for knowledge discovery in databases is introduced. That architecture integrates information retrieval from text collections, information extraction to obtain data from individual texts, data warehousing for the extracted data, data mining to discover useful patterns in the data, and visualization of the resulting patterns. At the core of this architecture is a broad view of data mining-the process of discovering patterns in large collections of data-and that step is described in some detail. The final section of the paper illustrates how these ideas can be applied in practice, drawing upon examples from the recently completed first phase of the textual data mining program at the Office of Naval Research. The paper concludes by identifying some research directions that offer significant potential for improving the utility of textual data mining for research management applications.	ACS Def Inc, Rome, NY USA; Univ Maryland, Coll Lib & Informat Serv, College Pk, MD 20742 USA; Off Naval Res, Arlington, VA 22217 USA	Losiewicz, P (reprint author), ACS Def Inc, Rome, NY USA.	losiewiczp@rl.af.mil; oard@glue.umd.edu; kostofr@onr.navy.mil					APTE C, 1997, IEEE COMPUTATIONAL S, P4; CALIFF ME, 1997, WORKSH NOT IJCAI 97, P7; Chen HC, 1998, J AM SOC INFORM SCI, V49, P582, DOI 10.1002/(SICI)1097-4571(19980515)49:7<582::AID-ASI2>3.0.CO;2-X; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; DOERMANN D, 1998, CMPUTER VISION IMAGE; Fayyad U, 1996, AI MAG, V17, P37; FOOTE J, IN PRESS ACM SPRINGE; FREEMAN LC, 1997, USING AVAILABLE GRAP; GALLIPPI A, 1996, THESIS U SO CALIFORN; GEY F, 1999, 3 IEEE MET C BETH MD; GILMAN M, 1988, NUGGETS DATA MINING; HAVLA MMK, 1997, S CROSS LANG TEXT SP; KOSTOFF RN, 1995, Patent No. 5440481; KOSTOFF RN, 1991, P PORTL INT C MAN EN; KOSTOFF RN, 1994, COMPETITIVE INTELLIG, V5, P1; Kostoff RN, 1997, J INF SCI, V23, P301, DOI 10.1177/016555159702300404; Kostoff RN, 1998, INFORM PROCESS MANAG, V34, P69, DOI 10.1016/S0306-4573(97)00066-6; Kostoff RN, 1999, TECHNOVATION, V19, P593, DOI 10.1016/S0166-4972(99)00084-X; Kostoff RN, 1999, J AM SOC INFORM SCI, V50, P427; KOSTOFF RN, 1993, COMPETITIVE INTELLIG, V4, P1; KOSTOFF RN, 1992, P 3 INT C MAN TECHN; Lawrence S, 1999, COMPUTER, V32, P67, DOI 10.1109/2.769447; MCCULLOCH WS, 1988, NEUROCOMPUTING FDN R; Oard D. W., 1998, AAAI WORKSH REC SYST; RILOFF E, 1998, P 6 WORKSH VER LARG; ROHRER RM, 1998, 4 IEEE S INF VIS DUR; SELDEN CR, 1996, 968 NAT LIBR MED; Sheth B. D., 1994, THESIS MIT; Westphal C., 1998, DATA MINING SOLUTION; WHITE AP, 1994, MACH LEARN, V15, P321, DOI 10.1023/A:1022694010754	30	59	60	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	SEP	2000	15	2					99	119		10.1023/A:1008777222412		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	333GP	WOS:000088122500001	
J	Sheikholeslami, G; Chatterjee, S; Zhang, AD				Sheikholeslami, G; Chatterjee, S; Zhang, AD			WaveCluster: a wavelet-based clustering approach for spatial data in very large databases	VLDB JOURNAL			English	Article							ALGORITHM	Many applications require the management of spatial data in a multidimensional feature space. Clustering large spatial databases is an important problem, which tries to find the densely populated regions in the feature space to be used in data mining, knowledge discovery, or efficient information retrieval. A good clustering approach should be efficient and detect clusters of arbitrary shape. It must be insensitive to the noise (outliers) and the order of input data. We propose WaveCluster, a novel clustering approach based on wavelet transforms, which satisfies all the above requirements. Using the multiresolution property of wavelet transforms, we can effectively identify arbitrarily shaped clusters at different degrees of detail. We also demonstrate that WaveCluster is highly efficient in terms of time complexity. Experimental results on very large datasets are presented, which show the efficiency and effectiveness of the proposed approach compared to the other recent clustering methods.	SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Sheikholeslami, G (reprint author), SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.						Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Allard D, 1997, J AM STAT ASSOC, V92, P1485, DOI 10.2307/2965419; ESTER M, 1996, P 2 INT C KDD; ESTER M, 1998, KI J; Gordon A.D, 1981, CLASSIFICATION METHO; GUDIVADA VN, 1995, IEEE COMPUT, V28; HON BKP, 1988, ROBOT VSION; Jacobs D, 1995, MATH PROBL ENG, V1, P95, DOI 10.1155/S1024123X9500010X; Jain R., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, DOI 10.1117/12.205318; Kaufman L., 1990, FINDING GROUPS DATA; Knuth D. E., 1998, ART COMPUTER PROGRAM; MALLAT SG, 1989, T AM MATH SOC, V315, P69, DOI 10.2307/2001373; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; NASSIMI D, 1980, SIAM J COMPUT, V9, P744, DOI 10.1137/0209058; Ng R, 1994, P 20 INT C VER LARG, P144; Openshaw S., 1981, QUANTITATIVE GEOGRAP, P60; OPENSHAW S, 1977, T I BRIT GEOGR, V2, P459, DOI 10.2307/622300; PAUWELS EJ, 1997, P 2 INT C VIS INF SY, P13; Schalkoff R, 1992, PATTERN RECOGNITION; Sengupta A., 1994, MULTIMEDIA SYSTEMS, V2, P218, DOI 10.1007/BF01215399; SHEIKHOLESLAMI G, 1997, P SPIE C VIS DAT EXP, V4, P322; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; SHEIKHOLESLAMI G, 1997, P 5 ACM INT WORKSH G, P58, DOI 10.1145/267825.267841; SHILOACH Y, 1982, J ALGORITHM, V3, P57, DOI 10.1016/0196-6774(82)90008-6; Smith J R, 1994, P IEEE INT C IM PROC, V12, P407, DOI 10.1109/ICIP.1994.413817; Strang G., 1996, WAVELETS FILTER BANK; UYTTERHOEVEN G, 1997, 11 ITA WP KATH U LEU; VAIDYANATHAN P, 1993, PRENTICE HALL SIGNAL; Wang Wei, 1997, P 23 VLDB C ATH GREE, P186; Xu XW, 1998, PROC INT CONF DATA, P324; YERS S, 1995, 295 U WASH DEP STAT; YU D, 1998, 988 STAT U NEW YORK; Zait M, 1997, FUTURE GENER COMP SY, V13, P149, DOI 10.1016/S0167-739X(97)00018-6; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	34	59	66	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1066-8888		VLDB J	VLDB J.	FEB	2000	8	3-4					289	304		10.1007/s007780050009		16	Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	295JV	WOS:000085963700009	
J	Tsumoto, S				Tsumoto, S			Mining diagnostic rules from clinical databases using rough sets and medical diagnostic model	INFORMATION SCIENCES			English	Article						data mining; knowledge discovery; rule induction; hierarchical decision rules		Since rule induction methods generate rules whose lengths are the shortest for discrimination between given classes, they tend to generate rules too short for medical experts. Thus, these rules are difficult for the experts to interpret from the viewpoint of domain knowledge. In this paper, the characteristics of experts' rules are closely examined and a new approach to generate diagnostic rules is introduced. The proposed method focuses on the hierarchical structure of differential diagnosis and consists of the following three procedures. First, the characterization of decision attributes (given classes) is extracted from databases and the classes are classified into several generalized groups with respect to the characterization. Then, two kinds of sub-rules, classification rules for each generalized group and rules for each class within each group are induced. Finally, those two parts are integrated into one rule for each decision attribute. The proposed method was evaluated on a medical database, the experimental results of which show that induced rules correctly represent experts' decision processes. (C) 2004 Elsevier Inc. All rights reserved.	Shimane Univ, Dept Med Informat, Sch Med, Izumo, Shimane 6938501, Japan	Tsumoto, S (reprint author), Shimane Univ, Dept Med Informat, Sch Med, 89-1 Enya Cho, Izumo, Shimane 6938501, Japan.	tsumoto@computer.org					BUCHNAN B, 1984, RULE BASED EXPERT SY; EVERITT BS, 1996, CLUSTER ANAL; MICHALSKI PS, 1986, P 5 NATL C ART INT M, P1041; Pawlak Z, 1991, ROUGH SETS; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; QUINLAN JR, 1993, PROGRAMS MACHINES LE; Skowron A., 1994, ADV DEMPSTER SHAFER, P193; SUMOTO S, 1998, J INTELLIGENT DATA A, V2; Tsumoto S, 1998, INFORM SCIENCES, V112, P67, DOI 10.1016/S0020-0255(98)10021-X; TSUMOTO S, 1995, COMPUT INTELL, V11, P389, DOI 10.1111/j.1467-8640.1995.tb00040.x; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	12	58	62	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	MAY 17	2004	162	2					65	80		10.1016/j.ins.2004.03.002		16	Computer Science, Information Systems	Computer Science	826VY	WOS:000221858800002	
J	Pal, SK; Mitra, P				Pal, SK; Mitra, P			Case generation using rough sets with fuzzy representation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						case-based reasoning; linguistic representation; rough dependency rules; granular computing; rough-fuzzy hybridization; soft computing; pattern recognition; data mining	LEARNING ALGORITHMS; CLASSIFICATION; GRANULATION; COMPLEX	In this article, we propose a rough-fuzzy hybridization scheme for case generation. Fuzzy set theory is used for linguistic representation of patterns, thereby producing a fuzzy granulation of the feature space. Rough set theory is used to obtain dependency rules which model informative regions in the granulated feature space. The fuzzy membership functions corresponding to the informative regions are stored as cases along with the strength values. Case retrieval is made using a similarity measure based on these membership functions. Unlike the existing case selection methods, the cases here are cluster granules and not sample points. Also, each case involves a reduced number of relevant features. These makes the algorithm suitable for mining data sets, large both in dimension and size, due to its low-time requirement in case generation as well as retrieval. Superiority of the algorithm in terms of classification accuracy and case generation and retrieval times is demonstrated on some real-life data sets.	Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, W Bengal, India	Pal, SK (reprint author), Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, W Bengal, India.	sankar@isical.ac.in; pabitra_r@isical.ac.in	Pal, Sankar /G-2243-2010				AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Banerjee M, 1998, IEEE T NEURAL NETWOR, V9, P1203, DOI 10.1109/72.728363; Blake C, 1998, UCI REPOSITORY MACHI; BURKHARD HD, 2000, SOFT COMPUTING CASE, P29; De RK, 2001, INFORM SCIENCES, V132, P179, DOI 10.1016/S0020-0255(01)00070-6; Dubitzky W, 1997, APPL INTELL, V7, P187, DOI 10.1023/A:1008216431052; Dubois D, 1998, INT J INTELL SYST, V13, P345, DOI 10.1002/(SICI)1098-111X(199804)13:4<345::AID-INT3>3.3.CO;2-I; Kolodner J. L., 1993, CASE BASED REASONING; Lin T. Y., 1999, COMPUTING WORDS INFO, P183; Pal Sankar K., 2000, SOFT COMPUTING CASE; Pal S.K., 1999, NEUROFUZZY PATTERN R; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pedrycz W, 2000, IEEE T SYST MAN CY A, V30, P151, DOI 10.1109/3468.833095; POLKOWSKI L, 1996, P 4 GERM WORKSH CAS, P144; Skowron A., 1992, INTELLIGENT DECISION, P331; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh L.A., 1975, FUZZY SETS THEIR APP; ZADEH LA, 1976, INT J MAN MACH STUD, V8, P249, DOI 10.1016/S0020-7373(76)80001-6; 2001, P INT WORKSH ROUGH S	25	58	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2004	16	3					292	300		10.1109/TKDE.2003.1262181		9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	775BK	WOS:000189020700001	
J	Changchien, SW; Lu, TC				Changchien, SW; Lu, TC			Mining association rules procedure to support on-line recommendation by customers and products fragmentation	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; SOM; rough set; association rules; on-line marketing	NEURAL NETWORKS	Electronic Commerce (EC) has offered a new channel for instant on-line shopping. However, there are too many various products available from a great number of virtual stores on the Internet for Internet shoppers to select. On-line one-to-one marketing therefore becomes a great assistance to Internet shoppers. One of the most important marketing resources is the prior daily transaction records in the database. The great amount of data not only gives the statistics, but also offers the resource of experiences and knowledge. It is quite natural that marketing managers can perform data mining on the daily transactions and treat the shoppers the way they prefer. However, the data mining on a significant amount of transaction records requires efficient tools. Data mining from automatic or semi-automatic exploration and analysis on a large amount of data items set in a database can discover significant patterns and rules underlying the database. The knowledge can be equipped in the on-line marketing system to promote Internet sales. The purpose of this paper is to develop a mining association rules procedure from a database to support on-line recommendation. By customers and products fragmentation, product recommendation based on the hidden habits of customers in the database is therefore very meaningful. The proposed data mining procedure consists of two essential modules. One is a clustering module based on a neural network, Self-Organization Map (SOM), which performs affinity grouping tasks on a large amount of database records. The other rule is extraction module employing rough set theory that can extract association rules for each homogeneous cluster of data records and the relationships between different clusters. The implemented system was applied to a sample of sales records from a database for illustration. (C) 2001 Elsevier Science Ltd. All rights reserved.	Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan	Changchien, SW (reprint author), Chaoyang Univ Technol, Dept Informat Management, 168 GiFeng E Rd, Taichung, Taiwan.						Agrawal R., 1993, INT P ACM SIGMOD INT, P207; Agrawal R., 1995, P INT C VER LARG DAT, P407; Anand SS, 1998, KNOWL-BASED SYST, V10, P449, DOI 10.1016/S0950-7051(98)00035-5; Basu A, 1998, EUR J OPER RES, V111, P1, DOI 10.1016/S0377-2217(97)00316-0; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; BEERY JA, 1997, DATA MINING TECHNIQU; Bhattacharyya S., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347186; Brijs T., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347156; Chan CC, 1998, INFORM SCIENCES, V107, P169, DOI 10.1016/S0020-0255(97)10047-0; Goulbourne G, 2000, KNOWL-BASED SYST, V13, P141, DOI 10.1016/S0950-7051(00)00055-1; DEOGUN S, 1997, DATA MINING TRENDS R; Dhond A., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347188; FLEXER A, 1999, P 3 INT EUR C PKDD 9; Griffin G, 1998, KNOWL-BASED SYST, V11, P249, DOI 10.1016/S0950-7051(98)00042-2; Ha SH, 1998, EXPERT SYST APPL, V15, P1; Han JW, 1999, IEEE T KNOWL DATA EN, V11, P798; Houtsma M., 1993, 9567 RJ IBM ALM RES; Kaski S, 1998, NEUROCOMPUTING, V21, P101, DOI 10.1016/S0925-2312(98)00039-3; KINGSMAN B, 1996, INT J PROD ECON, P219; Kleissner C, 1998, P ANN HICSS, P295, DOI 10.1109/HICSS.1998.649224; LIN TY, 1949, ROUGH SETS DATA MINI; MASTSUZAWA H, 2000, P 4 PAC AS C PAKDD, P233; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; Shaw MJ, 1997, DECIS SUPPORT SYST, V21, P149, DOI 10.1016/S0167-9236(97)00025-0; SMITH A, 2000, COMPUTERS OPERATIONS, V27, P1023; TSECHANSKY S, 1999, DECIS SUPPORT SYST, V27, P177; TSUR D, 1998, P ACM SIGMOD INT C M, P1, DOI 10.1145/276304.276306; Vellido A, 1999, EXPERT SYST APPL, V17, P303, DOI 10.1016/S0957-4174(99)00042-1; Yao JT, 1998, J INF SCI ENG, V14, P843; ZHANG T, 2000, P 4 PAC AS C PAKDD, P233; 1999, E BUSINESS IMPLEMENT	32	58	58	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2001	20	4					325	335		10.1016/S0957-4174(01)00017-3		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	436TE	WOS:000168951300003	
J	Jankowski, P; Andrienko, N; Andrienko, G				Jankowski, P; Andrienko, N; Andrienko, G			Map-centred exploratory approach to multiple criteria spatial decision making	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article							GEOGRAPHICAL INFORMATION-SYSTEMS; VISUALIZATION; KNOWLEDGE	Spatial decision support is one of the central functions ascribed to Geographical information Systems (GIS). One of the foci of developing decision support capabilities of GIS has been the integration of maps with multiple criteria decision models. Progress in this area has been slow due to a limited role played by maps as decision support tools. In this paper we present new prototype spatial decision support tools emphasising the role of maps as a source of structure in multiple criteria spatial decision problems. In these tools the role of map goes beyond the mere display of geographic decision space and multicriterion evaluation results. Maps becomes a 'visual index' through which the user orders decision options, assigns priorities to decision criteria, and augments the criterion outcome space by map-derived heuristic knowledge. As the additional means of structuring multicriterion spatial decision problems we present an experimental use of data mining, integrated with dynamic maps and multiple criteria decision models, in order to reduce a problem's dimensionality. We conclude the paper with future research directions emphasising map-based support for group decision malting.	Univ Idaho, Dept Geog, Moscow, ID 83843 USA; GMD, German Natl Res Ctr Informat Technol, D-53754 Sankt Augustin, Germany	Jankowski, P (reprint author), Univ Idaho, Dept Geog, Moscow, ID 83843 USA.						ANDRIENKO G, 1999, USER INTERFACES DATA, P162; Andrienko G, 1999, LECT NOTES COMPUT SC, V1642, P149; ANDRIENKO G, 2000, STUDY GROUP GEOGRAPH, P3015; Andrienko GL, 1999, INT J GEOGR INF SCI, V13, P355, DOI 10.1080/136588199241247; ARMSTRONG MP, 1992, CARTOGR GEOGR INFORM, V19, P154, DOI 10.1559/152304092783762263; Buja A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), DOI 10.1109/VISUAL.1991.175794; Buja A., 1996, J COMPUTATIONAL GRAP, V5, P78, DOI 10.2307/1390754; CARVER SJ, 1991, INT J GEOGR INF SYST, V5, P321, DOI 10.1080/02693799108927858; CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361; Chun KJ, 1998, INFORM MANAGE, V33, P313, DOI 10.1016/S0378-7206(98)00038-X; CHURCH RL, 1992, COMPUT GEOSCI, V8, P1095; Cohon JL, 1978, MULTIOBJECTIVE PROGR; Dykes JA, 1997, COMPUT GEOSCI, V23, P345, DOI 10.1016/S0098-3004(97)00009-5; Eastman J R, 1997, IDRISI WINDOWS VERSI; EASTMAN JR, 1995, PHOTOGRAMM ENG REM S, V61, P539; FABER B, 1995, P GIS 95 9 ANN S GEO, V1, P183; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; FISHER G, 1996, WP96006 INT I APPL S; Hwang C.L., 1981, MULTIPLE ATTRIBUTE D; Inselberg A, 1998, COMPUTATION STAT, V13, P47; JANKOWSKI P, 1996, GEOGRAPHICAL SYSTEMS, V3, P279; Jankowski P, 1999, SPATIAL MULTICRITERIA DECISION MAKING AND ANALYSIS, P127; JANKOWSKI P, 1995, INT J GEOGR INF SYST, V9, P251, DOI 10.1080/02693799508902036; JANKOWSKI P, ANN ASS AM GEOGRAPHE; Jankowski P, 1997, INT J GEOGR INF SCI, V11, P577, DOI 10.1080/136588197242202; JANSSEN R, 1990, GEOGRAPHICAL SYSTEMS; KIRKWOOD CW, 1997, STRATEGIC DECISION; LOTFI V, 1992, COMPUT OPER RES, V19, P671, DOI 10.1016/0305-0548(92)90036-5; LOTOV AV, 1999, DECISION ANAL SUPPOR, P145; LOTOV AV, 1997, J GEOGRAPHICAL INFOR, V1, P118; MACDOUGALL EB, 1992, CARTOGR GEOGR INFORM, V19, P237, DOI 10.1559/152304092783721268; Maceachren AM, 1997, COMPUT GEOSCI, V23, P335, DOI 10.1016/S0098-3004(97)00018-6; MacEachren A.M., 1994, VISUALIZATION MODERN, P1; Malczewski J., 1999, GEOMATICA, V53, P139; MALCZEWSKI J, 1999, GIS MULTICRITERIA DE; MONMONIER M, 1989, GEOGR ANAL, V21, P81; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Simon H.A., 1960, NEW SCI MANAGEMENT D; Tukey J.W., 1977, EXPLORATORY DATA ANA; Unwin A, 1998, INNOVATIONS IN GIS 5, P46; WROBEL S, 1996, P KDD 96 2 INT C KNO, P214; Wu FL, 1998, INT J GEOGR INF SCI, V12, P63, DOI 10.1080/136588198242012	42	58	61	TAYLOR & FRANCIS LTD	LONDON	11 NEW FETTER LANE, LONDON EC4P 4EE, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	MAR	2001	15	2					101	127		10.1080/13658810010005525		27	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	414WY	WOS:000167690200001	
J	Lu, H; Feng, L; Han, J				Lu, H; Feng, L; Han, J			Beyond intratransaction association analysis: Mining multidimensional intertransaction association rules	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						experimentation; performance; data mining; intra/intertransaction association rules; multidimensional context	DATABASES	In this paper, we extend the scope of mining association rules from traditional single-dimensional intratransaction associations, to multidimensional intertransaction associations. Intratransaction associations are the associations among items within the same transaction, where the notion of the transaction could be the items bought by the same customer, the events happened on the same day, and so on. However, an intertransaction association describes the association relationships among different transactions, such as "if (company) A's stock goes up on day I, B's stock will go down on day 2, but go up on day 4." In this case, whether we treat company or day as the unit of transaction, the associated items belong to different transactions. Moreover, such an intertransaction association can be extended to associate multiple contextual properties in the same rule, so that multidimensional intertransaction associations can be defined and discovered. A two-dimensional intertransaction association rule example is "After McDonald and Burger King open branches, KFC will open a branch two months later and one mile away," which involves two dimensions: time and space. Mining intertransaction associations poses more challenges on efficient processing than mining intratransaction associations. Interestingly, intratransaction association can be treated as a special case of intertransaction association from both a conceptual and algorithmic point of view. In this study, we introduce the notion of multidimensional intertransaction association rules, study their measurements-support and confidence-and develop algorithms for mining intertransaction associations by extension of Apriori. We overview our experience using the algorithms on both real-life and synthetic data sets. Further extensions of multidimensional intertransaction association rules and potential applications are also discussed.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Tilburg Univ, NL-5000 LE Tilburg, Netherlands; Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada	Lu, H (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.	luhj@cs.ust.hk; ling@kub.nl; han@cs.sfu.ca					AGGARWAL A, 1987, ALGORITHMICA, V2, P209; Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P478; Baralis E., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V9, DOI 10.1023/A:1008637019359; Bettini C, 1998, DATA ENG B, V21, P32; Bettini C., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237680; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094; Cheung DW, 1996, IEEE T KNOWL DATA EN, V8, P911, DOI 10.1109/69.553158; Das G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Fang M., 1998, P 24 INT C VER LARG, P299; Feng L, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P225, DOI 10.1145/319950.320007; Fukuda T., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237708; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; HAN EH, 1997, P ACM SIGMOD INT C M, P277, DOI 10.1145/253260.253330; HAN J, 1995, P 1 INT WORKSH INT K, P39; Han J, 1995, P 21 INT C VER LARG, P420; Kamber M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; MANNILA H, 1997, TECHNICAL REPORT S C; Meo R, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P122; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; PARK JS, 1996, P 16 C DISTR COMP SY, P385; Ramaswamy S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Savasere A, 1995, P 21 INT C VER LARG, P432; Silverstein C., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; SRIKANT R, 1995, P 21 INT C VER LARG, P409; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; TOIVONEN H., 1996, P 2 INT C KNOWL DISC, P146; TSUR D, 1998, P ACM SIGMOD INT C M, P1, DOI 10.1145/276304.276306; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	39	58	63	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1046-8188		ACM T INFORM SYST	ACM Trans. Inf. Syst.	OCT	2000	18	4					423	454		10.1145/358108.358114		32	Computer Science, Information Systems	Computer Science	397KF	WOS:000166694300003	
J	Hirota, K; Pedrycz, W				Hirota, K; Pedrycz, W			Fuzzy computing for data mining	PROCEEDINGS OF THE IEEE			English	Article						context-sensitive fuzzy clustering; data mining; fuzzy sets; granular computing; information granules; knowledge discovery; linguistic labels; unsupervised learning	KNOWLEDGE; FRAMEWORK; SETS	The study is devoted to linguistic data mining, an endeavor that exploits the concepts, constructs, and mechanisms of fuzzy set theory. The roles of information granules, information granulation, and the techniques therein arp discussed in detail. Particular attention is given to the manner in which these information granules arp represented as fuzzy sets and manipulated according to the main mechanisms of fuzzy sets. We introduce unsupervised learning (clustering) where optimization is supported by the linguistic gr rules of context, thereby giving rise to so-called context-sensitive fuzzy clustering. The combination of neuro, evolutionary, and granular computing in the context of data mining is explored. Derailed numerical experiments using well-known datasets are also included and analyzed.	Tokyo Inst Technol, Interdisciplinary Grad Sch Sci & Engn, Dept Computat Intelligence & Syst Sci, Yokohama, Kanagawa 226, Japan; Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2G7, Canada	Hirota, K (reprint author), Tokyo Inst Technol, Interdisciplinary Grad Sch Sci & Engn, Dept Computat Intelligence & Syst Sci, Yokohama, Kanagawa 226, Japan.						ANDERBERG MR, 1973, CULSTER ANAL APPL; Backer E., 1995, COMPUTER ASSISTED RE; BEZDEK J C, 1981, PATTEN RECOGNITION F; Breiman L, 1984, CLASSIFICATION REGRE; Brunk C., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Chattratichat J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; DAVE R, 1992, PATTERN RECOGN, V12, P657; Derthick M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Everitt B., 1974, CLUSTER ANAL; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Fayyad U, 1996, AI MAG, V17, P37; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Folger T.A., 1988, FUZZY SETS UNCERTAIN; Frawley W. J., 1991, Knowledge discovery in databases; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hirota K., 1993, IND APPL FUZZY TECHN; Hirota K., 1995, IND APPL FUZZY TECHN; Huber P. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kandel A., 1986, FUZZY MATH TECHNIQUE; Kaufman L., 1990, FINDING GROUPS DATA; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; Matheron G, 1975, RANDOM SETS INTEGRAL; MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037//0033-295X.101.2.343; Moore R., 1966, INTERVAL ANAL; PAPANTONAKIS A, 1995, J VISUAL LANG COMPUT, V6, P3, DOI 10.1006/jvlc.1995.1002; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pedrycz W., 1998, INTRO FUZZY SETS ANA; Pedrycz W, 1996, PATTERN RECOGN LETT, V17, P625, DOI 10.1016/0167-8655(96)00027-X; Pedrycz W, 1998, IEEE T NEURAL NETWOR, V9, P601, DOI 10.1109/72.701174; Pedrycz W., 1997, COMPUTATIONAL INTELL; PEDRYCZ W, 1993, P 5 IFSA WORLD C SEO, V2, P1187; Pedrycz W., 1995, FUZZY SETS ENG; PEDRYCZ W, 1992, INT J INTELL SYST, V7, P155, DOI 10.1002/int.4550070205; PEDRYCZ W, 1990, FUZZY SET SYST, V37, P123, DOI 10.1016/0165-0114(90)90037-7; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Nakhaeizadeh G., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Serra JP, 1982, IMAGE ANAL MATH MORP; Shahar Y, 1997, ARTIF INTELL, V90, P79, DOI 10.1016/S0004-3702(96)00025-2; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; STOFLO S, 1997, P 3 INT C KNOWL DISC, P74; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; WANG Y, 1996, P 2 INT C KNOWL DISC, P283; YAGER RR, 1983, INT J GEN SYST, V9, P249, DOI 10.1080/03081078308960825; YAGER RR, 1982, INT J GEN SYST, V8, P139, DOI 10.1080/03081078208547443; Yoda K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; Zadeh L.A., 1979, ADV FUZZY SET THEORY, P3; Zadeh L.A, 1965, FUZZY SETS INFORM CO, V8, P338, DOI DOI 10.1016/S0019-9958(65)90241-X; ZHONG N, 1995, P 1 INT C KNOWL DISC, P337; Zytkow J. M., 1996, Fundamenta Informaticae, V27; 1996, COMMUN ACM SPECIAL I, P11; 1992, INT J INTELL SYST SP, V7	57	58	60	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0018-9219		P IEEE	Proc. IEEE	SEP	1999	87	9					1575	1600		10.1109/5.784240		26	Engineering, Electrical & Electronic	Engineering	229CV	WOS:000082176700009	
J	Mangasarian, OL				Mangasarian, OL			Mathematical programming in data mining	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						mathematical programming; feature selection; clustering; robust representation	POLYNOMIAL-TIME ALGORITHM	Mathematical programming approaches to three fundamental problems will be described: feature selection, clustering and robust representation. The feature selection problem considered is that of discriminating between two sets while recognizing irrelevant and redundant features and suppressing them. This creates a lean model that often generalizes better to new unseen data. Computational results on real data confirm improved generalization of leaner models. Clustering is exemplified by the unsupervised learning of patterns and clusters that may exist in a given database and is a useful tool for knowledge discovery in databases (KDD). A mathematical programming formulation of this problem is proposed that is theoretically justifiable and computationally implementable in a finite number of steps. A resulting k-Median Algorithm is utilized to discover very useful survival curves for breast cancer patients from a medical database. Robust representation is concerned with minimizing trained model degradation when applied to new problems. A novel approach is proposed that purposely tolerates a small error in the training process in order to avoid overfitting data that may contain errors. Examples of applications of these concepts are given.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	Mangasarian, OL (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.						ALSULTAN KS, 1995, PATTERN RECOGN, V28, P1443, DOI 10.1016/0031-3203(95)00022-R; Bennet K.P., 1992, ADV OPTIMIZATION PAR, P56; BENNETT KP, 1997, IN PRESS GEOMETRY WO; Bennett K. P., 1993, Computational Optimization and Applications, V2, DOI 10.1007/BF01299449; Bennett K.P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bertsekas D. P, 1989, PARALLEL DISTRIBUTED; Bertsekas D.P., 1995, NONLINEAR PROGRAMMIN; BIXBY RE, 1992, OPER RES, V40, P885, DOI 10.1287/opre.40.5.885; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Bradley PS, 1997, ADV NEUR IN, V9, P368; BRADLEY PS, 1995, UNPUB INFORMS J COMP; BREDENSTEINER EJ, 1995, 218 RENSS POL I DEP; CORDELLIER F, 1978, MATH PROGRAM, V14, P295, DOI 10.1007/BF01588972; Dantzig G., 1963, LINEAR PROGRAMMING E; DELEONE R, 1993, CONCURRENCY-PRACT EX, V5, P623, DOI 10.1002/cpe.4330050802; DELEONE R, 1988, LECTURE NOTES EC MAT, V304, P103; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Ferris MC, 1994, SIAM J OPTIMIZ, V4, P815, DOI 10.1137/0804047; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Floudas C., 1995, NONLINEAR MIXED INTE; Fukunaga K., 1990, STAT PATTERN RECOGNI; GAIVORONSKI AA, 1994, OPTIMIZATION METHODS, V4; Garfinkel R. S., 1972, INTEGER PROGRAMMING; GLOVER F, 1990, DECISION SCI, V21, P771, DOI 10.1111/j.1540-5915.1990.tb01249.x; GRINOLD RC, 1972, MANAGE SCI, V19, P272, DOI 10.1287/mnsc.19.3.272; Hassoun M. H., 1995, FUNDAMENTALS ARTIFIC; Hertz J, 1991, INTRO THEORY NEURAL; Hillier F., 1995, INTRO OPERATIONS RES; Huber P.J., 1981, ROBUST STAT; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Jain A.K., 1988, ALGORITHMS CLUSTERIN; John G. H., 1994, P 11 INT C MACH LEAR; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; KARLIN S, 1992, MATH METHODS THEORY, V2; KARLIN S, 1992, MATH METHODS THEORY, V1; KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150; Klarbring A, 1993, COMPUTATIONAL METHOD, P233; Kleinbaum DG, 1996, SURVIVAL ANAL; Le Cun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Lustig I. J., 1994, ORSA Journal on Computing, V6; MANGASARIAN O. L., 1996, APPL MATH PARALLEL C, P175; Mangasarian O. L., 1994, OPTIMIZATION METHODS, V4, P103, DOI 10.1080/10556789408805581; Mangasarian O. L., 1969, NONLINEAR PROGRAMMIN; MANGASARIAN OL, 1979, SIAM J CONTROL OPTIM, V17, P745, DOI 10.1137/0317052; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Mangasarian O. L., 1993, ORSA Journal on Computing, V5; Mangasarian OL, 1996, NONLINEAR OPTIMIZATION AND APPLICATIONS, P283; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; MLADENIC D, 1993, P 10 INT C MACH LEAR, P205; Murphy PM, 1992, UCI REPOSITORY MACHI; Murty K. G, 1983, LINEAR PROGRAMMING; Murty K. G., 1992, NETWORK PROGRAMMING; MURTY KG, 1995, OPERATIONS RES; Nemhauser G.L., 1988, INTEGER COMBINATORIA; OVERTON ML, 1983, MATH PROGRAM, V27, P34, DOI 10.1007/BF02591963; Panagiotopoulos P. D., 1985, INEQUALITY PROBLEMS; RAO MR, 1971, J AM STAT ASSOC, V66, P622, DOI 10.2307/2283542; Rockafellar R., 1984, NETWORK FLOWS MONOTR; Rockafellar R. T., 1970, CONVEX ANAL; ROY A, 1993, NEURAL NETWORKS, V6, P535, DOI 10.1016/S0893-6080(05)80057-7; Rumelhart D, 1986, PARALLEL DISTRIBUTED; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; Shavlik J. W., 1990, READINGS MACHINE LEA; SMITH FW, 1968, IEEE T COMPUT, VC 17, P367, DOI 10.1109/TC.1968.229395; STREET WN, 1998, IN PRESS J OPTIMIZAT, V96; TSYPKIN Y., 1973, FDN THEORY LEARNING; Vanderbei R. J., 1997, LINEAR PROGRAMMING F; Vapnik V.N., 1995, NATURE STAT LEARNING; von Neumann John, 1944, THEORY GAMES EC BEHA; WOLBERG WH, 1995, WPBC WISCONSIN PROGN; Wolpert D. H., 1995, MATH GEN; *CPLEX OPT INC, 1992, US CPLEX IM LIN OPT	73	58	60	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	2					183	201		10.1023/A:1009735908398		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA828	WOS:000072406100003	
J	Alcala-Fdez, J; Fernandez, A; Luengo, J; Derrac, J; Garcia, S; Sanchez, L; Herrera, F				Alcala-Fdez, J.; Fernandez, A.; Luengo, J.; Derrac, J.; Garcia, S.; Sanchez, L.; Herrera, F.			KEEL Data-Mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING			English	Article; Proceedings Paper	10th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2009)	SEP 23-26, 2009	Burgos, SPAIN	Junta Castilla & Leon, Univ Burgos, Diputac Burgos, Ayuntamiento Burgos, GCI, CSA, FAE, FEC		Data mining; Data set repository; evolutionary algorithms; java; knowledge extraction; machine learning	STATISTICAL TESTS; CLASSIFICATION; RULES	This work is related to the KEEL1 (Knowledge Extraction based on Evolutionary Learning) tool, an open source software that supports data management and a designer of experiments. KEEL pays special attention to the implementation of evolutionary learning and soft computing based techniques for Data Mining problems including regression, classification, clustering, pattern mining and so on. The aim of this paper is to present three new aspects of KEEL: KEEL-dataset, a data set repository which includes the data set partitions in the KEEL format and shows some results of algorithms in these data sets; some guidelines for including new algorithms in KEEL, helping the researchers to make their methods easily accessible to other authors and to compare the results of many approaches already included within the KEEL software; and a module of statistical procedures developed in order to provide to the researcher a suitable tool to contrast the results obtained in any experimental study. A case of study is given to illustrate a complete case of application within this experimental analysis framework.	[Alcala-Fdez, J.; Fernandez, A.; Luengo, J.; Derrac, J.; Herrera, F.] Univ Granada, CITIC UGR, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain; [Garcia, S.] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain; [Sanchez, L.] Univ Oviedo, Dept Comp Sci, Gijon 33204, Spain	Alcala-Fdez, J (reprint author), Univ Granada, CITIC UGR, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	jalcala@decsai.ugr.es	Herrera, Francisco/C-6856-2008; Alcala Fernandez, Jesus/C-6795-2012	Herrera, Francisco/0000-0002-7283-312X; 			Abeel T, 2009, J MACH LEARN RES, V10, P931; Aguilar-Ruiz J, 2004, LECT NOTES COMPUT SC, V3102, P828; Aguilar-Ruiz JS, 2003, IEEE T SYST MAN CY B, V33, P324, DOI 10.1109/TSMCB.2002.805696; Aguilar-Ruiz JS, 2007, IEEE T EVOLUT COMPUT, V11, P466, DOI 10.1109/TEVC.2006.883466; Bergmann G., 1988, MULTIPLE HYPOTHESES, P100; Cochran WG, 1989, STAT METHODS; Cordon O., 2001, GENETIC FUZZY SYSTEM; Cox D. R., 1974, THEORETICAL STAT; Alcala-Fdez J, 2009, SOFT COMPUT, V13, P307, DOI 10.1007/s00500-008-0323-y; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Dorigo M, 2004, ANT COLONY OPTIMIZATION, pIX; Eiben AE, 2003, INTRO EVOLUTIONARY C; Fisher R. A., 1959, STAT METHODS SCI INF; Freitas A.A., 2002, DATA MINING KNOWLEDG; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Garcia S, 2009, SOFT COMPUT, V13, P959, DOI 10.1007/s00500-008-0392-y; Garcia S, 2005, J HEURISTICS, V15, P617, DOI 10.1007/s10732-008-9080-4; Garcia S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010; Garcia S., 2008, J MACH LEARN RES, V9, P2579; Ghosh A, 2005, EVOLUTIONARY COMPUTA; Gray JB, 2008, COMPUT STAT DATA AN, V52, P1362, DOI 10.1016/j.csda.2007.03.014; Grefenstette John J., 1993, GENETIC ALGORITHMS M; GUSTAVO EAP, 2004, SIGKDD EXPLORATIONS, V6, P20; Han J, 2006, DATA MINING CONCEPTS; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; HOCHBERG Y, 1988, BIOMETRIKA, V75, P800, DOI 10.1093/biomet/75.4.800; HOLM S, 1979, SCAND J STAT, V6, P65; IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904; Wong ML, 2000, GENET PROGR SER, V3, P1; Luengo J, 2009, EXPERT SYST APPL, V36, P7798, DOI 10.1016/j.eswa.2008.11.041; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Mansoori EG, 2008, IEEE T FUZZY SYST, V16, P1061, DOI 10.1109/TFUZZ.2008.915790; Nemenyi P., 1963, THESIS; PAK SK, 1996, GENETIC ALGORITHMS P; Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452; Sanchez L, 2007, IEEE T FUZZY SYST, V15, P551, DOI 10.1109/TFUZZ.2007.895942; Sheskin D., 2006, HDB PARAMETRIC NONPA; Sonnenburg S, 2007, J MACH LEARN RES, V8, P2443; Sun YM, 2009, INT J PATTERN RECOGN, V23, P687; Tan KC, 2006, INT J SYST SCI, V37, P835, DOI 10.1080/00207720600879641; Ventura S, 2008, SOFT COMPUT, V12, P381, DOI 10.1007/s00500-007-0172-0; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Wilk M. B, 1965, BIOMETRIKA, V52, P591; Witten IH, 2005, DATA MINING PRACTICA; WRIGHT SP, 1992, BIOMETRICS, V48, P1005, DOI 10.2307/2532694; Zar J.H., 1999, BIOSTATISTICAL ANAL	48	57	57	OLD CITY PUBLISHING INC	PHILADELPHIA	628 NORTH 2ND ST, PHILADELPHIA, PA 19123 USA	1542-3980		J MULT-VALUED LOG S	J. Mult.-Valued Log. Soft Comput.		2011	17	2-3			SI		255	287				33	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Logic	Computer Science; Science & Technology - Other Topics	730PF	WOS:000288045700008	
J	Riesen, K; Bunke, H				Riesen, Kaspar; Bunke, Horst			Approximate graph edit distance computation by means of bipartite graph matching	IMAGE AND VISION COMPUTING			English	Article; Proceedings Paper	6th International Workshop on Graph-Based Representations in Pattern Recognition	JUN 11-13, 2007	Alicante, SPAIN	IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat		Graph based representation; Graph edit distance; Bipartite graph matching	FINGERPRINT CLASSIFICATION; PATTERN-RECOGNITION; POLYNOMIAL-TIME; ALGORITHM; ASSIGNMENT; SEARCH	In recent years, the use of graph based object representation has gained popularity. Simultaneously, graph edit distance emerged as a powerful and flexible graph matching paradigm that can be used to address different tasks in pattern recognition, machine learning, and data mining. The key advantages of graph edit distance are its high degree of flexibility, which makes it applicable to any type of graph, and the fact that one can integrate domain specific knowledge about object similarity by means of specific edit cost functions. Its computational complexity, however, is exponential in the number of nodes of the involved graphs. Consequently, exact graph edit distance is feasible for graphs of rather small size only. In the present paper we introduce a novel algorithm which allows us to approximately, or suboptimally, compute edit distance in a substantially faster way. The proposed algorithm considers only local, rather than global, edge structure during the optimization process. In experiments on different datasets we demonstrate a substantial speed-up of our proposed method over two reference systems. Moreover, it is emprically verified that the accuracy of the suboptimal distance remains sufficiently accurate for various pattern recognition applications. (C) 2008 Elsevier B.V. All rights reserved.	[Riesen, Kaspar; Bunke, Horst] Univ Bern, Inst Appl Math & Sci Comp, CH-3012 Bern, Switzerland	Riesen, K (reprint author), Univ Bern, Inst Appl Math & Sci Comp, Neubruckstr 10, CH-3012 Bern, Switzerland.	riesen@iam.unibe.ch; bunke@iam.unibe.ch					Ambauen R, 2003, LECT NOTES COMPUT SC, V2726, P95; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Boeres MC, 2004, LECT NOTES COMPUT SC, V3059, P100; Borgwardt K. M., 2005, P 5 IEEE INT C DAT M, P74; BOURGEOI.F, 1971, COMMUN ACM, V14, P802, DOI 10.1145/362919.362945; Bunke H., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90033-8; Neuhaus M, 2006, PATTERN RECOGN, V39, P1852, DOI 10.1016/j.patcog.2006.04.012; Comaniciu D., 1997, IEEE C COMP VIS PATT, p[750, 1997]; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9; Dickinson PJ, 2003, LECT NOTES COMPUT SC, V2726, P13; Dosch P, 2006, LECT NOTES COMPUT SC, V3926, P381; Eshera M. A., 1984, P 7 INT C PATT REC, P75; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398; HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136; Henry E., 1900, CLASSIFICATION USES; Justice D, 2006, IEEE T PATTERN ANAL, V28, P1200, DOI 10.1109/TPAMI.2006.152; Kuhn H., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109; Levenshtein V., 1966, SOV PHYS DOKL, V10, P707; LUKS EM, 1982, J COMPUT SYST SCI, V25, P42, DOI 10.1016/0022-0000(82)90009-5; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32; NENE S, 1996, COIL100 COL U DEP CO; NEUHAUS M., 2007, BRIDGING GAP GRAPH E; Neuhaus M, 2004, LECT NOTES COMPUT SC, V3138, P180; Neuhaus M, 2005, LECT NOTES COMPUT SC, V3546, P191; NEUHAUS M, 2006, LNCS, V3059, P163; Riesen K, 2007, LECT NOTES COMPUT SC, V4538, P1; Riesen K, 2007, LECT NOTES COMPUT SC, V4538, P383; Robles-Kelly A, 2005, IEEE T PATTERN ANAL, V27, P365, DOI 10.1109/TPAMI.2005.56; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353; Schomburg I, 2004, NUCLEIC ACIDS RES, V32, pD431, DOI 10.1093/nar/gkh081; Sorlin S, 2005, LECT NOTES COMPUT SC, V3434, P172; Torsello A, 2005, IEEE T PATTERN ANAL, V27, P1087, DOI 10.1109/TPAMI.2005.146; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WATSON C, 1992, NATL SPECIAL DATABAS; WONG J, 1974, P 6 ANN ACM S THEOR, P172; Zhou RW, 1995, PATTERN RECOGN LETT, V16, P1267, DOI 10.1016/0167-8655(95)00078-X	37	57	57	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0262-8856		IMAGE VISION COMPUT	Image Vis. Comput.	JUN 4	2009	27	7					950	959		10.1016/j.imavis.2008.04.004		10	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	450ID	WOS:000266393300012	
J	Yavas, G; Katsaros, D; Ulusoy, O; Manolopoulos, Y				Yavas, G; Katsaros, D; Ulusoy, O; Manolopoulos, Y			A data mining approach for location prediction in mobile environments	DATA & KNOWLEDGE ENGINEERING			English	Article						location prediction; data mining; mobile computing; mobility patterns; mobility prediction	NETWORKS	Mobility prediction is one of the most essential issues that need to be explored for mobility management in mobile computing systems. In this paper, we propose a new algorithm for predicting the next inter-cell movement of a mobile user in a Personal Communication Systems network. In the first phase of our three-phase algorithm, user mobility patterns are mined from the history of mobile user trajectories. In the second phase, mobility rules are extracted from these patterns, and in the last phase, mobility predictions are accomplished by using these rules. The performance of the proposed algorithm is evaluated through simulation as compared to two other prediction methods. The performance results obtained in terms of Precision and Recall indicate that our method can make more accurate predictions than the other methods. (c) 2004 Elsevier B.V. All rights reserved.	Bilkent Univ, Dept Comp Engn, TR-06533 Bilkent, Turkey; Aristotle Univ Thessaloniki, Dept Informat, GR-54006 Thessaloniki, Greece	Ulusoy, O (reprint author), Bilkent Univ, Dept Comp Engn, TR-06533 Bilkent, Turkey.	gyavas@cs.bilkent.edu.tr; dimitris@skyblue.csd.auth.gr; oulusoy@cs.bilkent.edu.tr; manolopo@skyblue.csd.auth.gr					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Akyildiz IF, 1996, IEEE ACM T NETWORK, V4, P629, DOI 10.1109/90.532871; Aljadhai A, 2001, IEEE J SEL AREA COMM, V19, P1915, DOI 10.1109/49.957307; BHATTACHARYA A, 2002, ACM KLUWER WIRELESS, V8, P121; Gok HG, 2000, INFORM SCIENCES, V125, P37, DOI 10.1016/S0020-0255(00)00006-2; Gusfield D., 1997, ALGORITHMS STRINGS T; Katsaros D, 2003, LECT NOTES COMPUT SC, V2810, P319, DOI 10.1007/978-3-540-45231-7_30; Liang B., 1999, P IEEE INFOCOM, P1377; Liu G.Y., 1995, P IEEE INT C UN PERS, P268, DOI 10.1109/ICUPC.1995.496902; Liu T, 1998, IEEE J SEL AREA COMM, V16, P922; Mohan S., 1994, IEEE Personal Communications, V1, DOI 10.1109/98.295359; NANOPOULOS A, 2001, P WEBKDD WORKSH; Nanopoulos A, 2003, IEEE T KNOWL DATA EN, V15, P1155, DOI 10.1109/TKDE.2003.1232270; Rajagopal S., 2002, Proceedings 10th IEEE International Conference on Networks (ICON 2002). Towards Network Superiority (Cat. No.02EX588), DOI 10.1109/ICON.2002.1033316; Saygin Y, 2002, IEEE T KNOWL DATA EN, V14, P1387, DOI 10.1109/TKDE.2002.1047775; WU HK, 2001, P IEEE C COMP COMM I, P21	17	57	57	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	AUG	2005	54	2					121	146		10.1016/datak.2004.09.004		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	934JE	WOS:000229704300002	
J	Helma, C; Cramer, T; Kramer, S; De Raedt, L				Helma, C; Cramer, T; Kramer, S; De Raedt, L			Data mining and machine learning techniques for the identification of mutagenicity inducing substructures and structure activity relationships of noncongeneric compounds	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							AUTOMATED STRUCTURE EVALUATION; ARTIFICIAL-INTELLIGENCE; CARCINOGENESIS; PROGRAM; SYSTEM	This paper explores the utility of data mining and machine learning algorithms for the induction of mutagenicity structure-activity relationships (SARs) from noncongeneric data sets. We compare (i) a newly developed algorithm (MOLFEA) for the generation of descriptors (molecular fragments) for noncongeneric compounds with traditional SAR approaches (molecular properties) and (ii) different machine learning algorithms for the induction of SARs from these descriptors. In addition we investigate the optimal parameter settings for these programs and give an exemplary interpretation of the derived models. The predictive accuracies of models using MOLFEA derived descriptors is similar to10- 15 %age points higher than those using molecular properties alone. Using both types of descriptors together does not improve the derived models. From the applied machine learning techniques the rule learner PART and support vector machines gave the best results, although the differences between the learning algorithms are only marginal. We were able to achieve predictive accuracies up to 78% for 10-fold cross-validation. The resulting models are relatively easy to interpret and usable for predictive as well as for explanatory purposes.	Univ Freiburg, Machine Learning Lab, Inst Comp Sci, D-79110 Freiburg, Germany; Tech Univ Munich, Inst Comp Sci, D-85748 Garching, Germany	Helma, C (reprint author), Univ Freiburg, Machine Learning Lab, Inst Comp Sci, Georges Kohler Allee 79, D-79110 Freiburg, Germany.	helma@informatik.uni-freiburg.de	Cramer, Tobias/E-2602-2013				AMES BN, 1973, P NATL ACAD SCI USA, V70, P2281, DOI 10.1073/pnas.70.8.2281; ASHBY J, 1993, MUTAT RES, V286, P3, DOI 10.1016/0027-5107(93)90003-X; BENIGNI R, 1988, J TOXICOL ENV HLTH, V1, P135; De Raedt L., 2002, SIGKDD EXPLORATIONS, V4, P69; Frank E, 1998, P 15 INT C MACH LEAR; Gasteiger JR, 1990, TETRAHEDRON COMPUT M, V3, P537, DOI 10.1016/0898-5529(90)90156-3; Gold L. S., 1997, HDB CARCINOGENIC POT; HELMA C, 2003, P BEILST WORKSH 2002; Helma C, 2000, STAT METHODS MED RES, V9, P329, DOI 10.1191/096228000701555190; HILL A, 2002, THESIS U FREIBURG; KLOPMAN G, 1994, MUTAT RES, V305, P33, DOI 10.1016/0027-5107(94)90124-4; KLOPMAN G, 1992, MUTAT RES, V272, P59, DOI 10.1016/0165-1161(92)90008-A; KLOPMAN G, 1992, QUANT STRUCT-ACT REL, V11, P176, DOI 10.1002/qsar.19920110208; KLOPMAN G, 1984, J AM CHEM SOC, V106, P7315, DOI 10.1021/ja00336a004; Kramer S., 2001, P 7 ACM SIGKDD INT C, P136, DOI 10.1145/502512.502533; Kramer S, 2002, SAR QSAR ENVIRON RES, V13, P509, DOI 10.1080/10629360290023340; Livingstone DJ, 2000, J CHEM INF COMP SCI, V40, P195, DOI 10.1021/ci990162i; MALACARNE D, 1993, ENVIRON HEALTH PERSP, V101, P332, DOI 10.2307/3431444; MEYLAN WM, 1995, J PHARM SCI, V84, P83, DOI 10.1002/jps.2600840120; PEROTTA, 1996, ENV MOL MUTAGEN, V28, P31; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Todeschini R., 2000, HDB MOL DESCRIPTORS; Vapnik V.N., 1995, NATURE STAT LEARNING; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Witten I. H., 2000, DATA MINING	25	57	59	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	JUL-AUG	2004	44	4					1402	1411		10.1021/ci034254q		10	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	841RX	WOS:000222950200023	
J	Wang, YF; Chuang, YL; Hsu, MH; Keh, HC				Wang, YF; Chuang, YL; Hsu, MH; Keh, HC			A personalized recommender system for the cosmetic business	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; association rules; clustering; recommender system	WEB; ACCESS	In order to have an effective command of the relationship between customers and products, we have constructed a personalized recommender system which incorporates content-based, collaborative filtering, and data mining techniques. We have also introduced a new scoring approach to determine customers' interest scores on products. To demonstrate how our system works, we used it to analyze real cosmetic data and generate a recommender score table for sellers to refer to. After tracking its performance for I year, we have obtained quite impressive results. (C) 2003 Elsevier Ltd. All rights reserved.	Chang Gung Inst Technol, Dept Informat Management, Taoyuan, Taiwan	Wang, YF (reprint author), Chang Gung Inst Technol, Dept Informat Management, 261 Wen Hwa 1st Rd, Taoyuan, Taiwan.	yfwang@mail.cgit.edu.tw					Aggarwal CC, 1999, P 5 ACM SIGKDD INT C, P201, DOI 10.1145/312129.312230; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Avery C, 1997, COMMUN ACM, V40, P88, DOI 10.1145/245108.245127; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; BARAGOIN C, 2001, MINING YOUR OWN BUSI, P54; Canny J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/564376.564419; Carenini G., 2003, P 8 INT C INT US INT, P12; Chalmers M, 1998, COMPUT NETWORKS ISDN, V30, P359, DOI 10.1016/S0169-7552(98)00069-5; Chen H C, 2001, P ACM C INF KNOWL MA, P231; Cheng PJ, 1999, INFORM SCIENCES, V118, P37, DOI 10.1016/S0020-0255(99)00033-X; Cho YH, 2002, EXPERT SYST APPL, V23, P329, DOI 10.1016/S0957-4174(02)00052-0; Coster R., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Domingos P, 2001, P 7 ACM SIGKDD INT C, P57, DOI 10.1145/502512.502525; Fiore Andrew T., 2002, P SIGCHI C HUM FACT, P323; FLEISCHMAN M, 2002, P IUI 03 MIAMA FL, P242; GAUCH JM, 1999, INFORMATION PROCESSI, V35, P401; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Herlocker JL, 2000, P 2000 ACM C COMP SU, P241, DOI DOI 10.1145/358916.358995; Hill W, 1995, P ACM CHI 95 C HUM F, P194, DOI 10.1145/223904.223929; Huang Z., 2002, P 2 ACM IEEE CS JOIN, P65; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kautz H, 1997, COMMUN ACM, V40, P63, DOI 10.1145/245108.245123; Kim T, 2002, SIGNAL PROCESS-IMAGE, V17, P497, DOI 10.1016/S0923-5965(02)00025-5; Kohrs A, 2001, INTERACT COMPUT, V13, P695, DOI 10.1016/S0953-5438(01)00038-8; Kohrs A., 1999, Proceedings ACM Multimedia 99, DOI 10.1145/319463.319467; Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126; Kuo YF, 2001, EXPERT SYST APPL, V21, P203, DOI 10.1016/S0957-4174(01)00040-9; Lee CH, 2001, EXPERT SYST APPL, V21, P131, DOI 10.1016/S0957-4174(01)00034-3; Lee DS, 2003, PATTERN RECOGN, V36, P519; Lee WP, 2002, EXPERT SYST APPL, V22, P275, DOI 10.1016/S0957-4174(02)00015-5; Linden G., 2003, IEEE INTERNET COMPUT; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; McDonald David W., 2000, P ACM C COMP SUPP CO, P231, DOI DOI 10.1145/358916.3589941; McNee S.M., 2002, P ACM 2002 C COMP SU, P116; Miller B. N., 2003, P 8 INT C INT US INT, P263, DOI DOI 10.1145/604045.604094; MOONEY R. J, 2000, P 5 ACM C DIG LIB, P195, DOI DOI 10.1145/336597.336662; Rashid A.M., 2002, P 2002 INT C INT US, P127; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; Schafer J. B., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; SCHAFER JB, 1999, P 1 ACM C EL COMM DE, P158, DOI DOI 10.1145/336992.337035; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Soboroff I., 2000, P 23 ANN INT ACM SIG, P351, DOI 10.1145/345508.345646; Svensson M, 2000, P IUI 2000, P260, DOI 10.1145/325737.325866; TERVEEN L, 2002, P CHI 02 MINN MINN, P315; YU K, 2001, P ACM CIKM 01, P239; Jagadish HV, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P102	48	57	59	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2004	26	3					427	434		10.1016/j.eswa.2003.10.001		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	800GF	WOS:000220016200012	
J	Bayardo, RJ; Agrawal, R; Gunopulos, D				Bayardo, RJ; Agrawal, R; Gunopulos, D			Constraint-based rule mining in large, dense databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; association rules; rule induction		Constraint-based rule miners find all rules in a given data-set meeting user-specified constraints such as minimum support and confidence. We describe a new algorithm that directly exploits all user-specified constraints including minimum support, minimum confidence, and a new constraint that ensures every mined rule offers a predictive advantage over any of its simplifications. Our algorithm maintains efficiency even at low supports on data that is dense (e.g. relational tables). Previous approaches such as Apriori and its variants exploit only the minimum support constraint, and as a result are ineffective on dense data due to a combinatorial explosion of "frequent itemsets".	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Bayardo, RJ (reprint author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.						AGARWAL RC, 1998, RC21341 IBM; AGRAWAL R, 1994, RJ9839 IBM ALM RES C; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo R. J.  Jr., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Berry M. R. J., 1997, DATA MINING TECHNIQU; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; CLEARWATER SH, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P24, DOI 10.1109/TAI.1990.130305; Cohen W., 1995, P 12 INT C MACH LEAR, P115; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; GUNOPULOS G, 1997, P 6 INT C DAT THEOR, P215; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Lin DI, 1998, P 6 INT C EXT DAT TE, P105; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Murphy M A, 1994, J Clin Neurosci, V1, P257, DOI 10.1016/0967-5868(94)90066-3; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; PARK JS, 1996, P 1995 ACM SIGMOD C, P175; RYMON R, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P539; RYMON R, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P181; Savasere A, 1995, P 21 INT C VER LARG, P432; Schlimmer J.C., 1993, P 10 INT C MACH LEAR, P284; SEGAL R, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P619; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Webb GI, 1995, J ARTIF INTELL RES, V3, P431; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; *INT BUS MACH, 1996, IBM INT MIN US GUID	31	57	60	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2000	4	2-3					217	240				24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	325ZA	WOS:000087706100006	
J	Greco, G; Guzzo, A; Pontieri, L; Sacca, D				Greco, Gianluigi; Guzzo, Antonella; Pontieri, Luigi; Sacca, Domenico			Discovering expressive process models by clustering log traces	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						process mining; data mining; workflow management; clustering; classification; association rules	MANAGEMENT	Process mining techniques have recently received notable attention in the literature for their ability to assist in the ( re) design of complex processes by automatically discovering models that explain the events registered in some log traces provided as input. Following this line of research, the paper investigates an extension of such basic approaches, where the identification of different variants for the process is explicitly accounted for, based on the clustering of log traces. Indeed, modeling each group of similar executions with a different schema allows us to single out "conformant" models, which, specifically, minimize the number of modeled enactments that are extraneous to the process semantics. Therefore, a novel process mining framework is introduced and some relevant computational issues are deeply studied. As finding an exact solution to such an enhanced process mining problem is proven to require high computational costs, in most practical cases, a greedy approach is devised. This is founded on an iterative, hierarchical, refinement of the process model, where, at each step, traces sharing similar behavior patterns are clustered together and equipped with a specialized schema. The algorithm guarantees that each refinement leads to an increasingly sound model, thus attaining a monotonic search. Experimental results evidence the validity of the approach with respect to both effectiveness and scalability.	Univ Calabria, Dept Math, I-87036 Arcavacata Di Rende, CS, Italy; Univ Calabria, CNR, ICAR, Inst High Performance Comp & Networks, I-87036 Arcavacata Di Rende, CS, Italy; Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Greco, G (reprint author), Univ Calabria, Dept Math, Via Bucci 30B, I-87036 Arcavacata Di Rende, CS, Italy.	ggreco@mat.unical.it; guzzo@icar.cnr.it; pontieri@icar.cnr.it; sacca@unical.it	Guzzo, Antonella/C-2303-2008; Greco, Gianluigi/I-7052-2012	Guzzo, Antonella/0000-0003-3159-0536; 			AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Alves de Medeiros A. K., 2004, BETA WORKING PAPER S, V113; BASTEN T, 2002, THEORETICAL COMPUTER, V270, P125; COOK JE, 1995, PROC INT CONF SOFTW, P73, DOI 10.1145/225014.225021; Cook JE, 1999, ACM T SOFTW ENG METH, V8, P147, DOI 10.1145/304399.304401; Greco G, 2005, IEEE T KNOWL DATA EN, V17, P519, DOI 10.1109/TKDE.2005.63; GRECO G, 2005, P INT C BUS PROC MAN, P32; Guralnik V., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989516; Han J., 2000, P 6 ACM SIGKDD INT C, P355, DOI 10.1145/347090.347167; Herbst J., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<67::AID-ISAF186>3.0.CO;2-7; Junginger S, 2000, WIRTSCHAFTSINF, V42, P392; Kamath M., 1996, Distributed Systems Engineering, V3, DOI 10.1088/0967-1846/3/4/002; KELLER G., 1992, SEMANTISCHE PROCESSM; Kim Y., 2000, P 6 ACM SIGKDD INT C, P365, DOI 10.1145/347090.347169; Liu DR, 2003, INFORM SYST, V28, P505, DOI 10.1016/S0306-4379(02)00028-5; MOTODA H, 2002, HDB DATA MINING KNOW, P208; Padmanabhan B., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347103; PONTIERI L, 2005, DISCOVERING EXPRESSI; SCHEER IDS, 2002, ARIS PROCESS PERFORM; van der Aalst W. M. P., 2002, WORKFLOW MANAGEMENT; van der Aalst W. M. P., 2002, P EPK 2002 BUS PROC, P71; van Dongen B.F., 2005, P 26 INT C APPL THEO, P444; van der Aalst W, 2004, IEEE T KNOWL DATA EN, V16, P1128, DOI 10.1109/TKDE.2004.47; Van der Aalst WMP, 1998, J CIRCUIT SYST COMP, V8, P21, DOI 10.1142/S0218126698000043; VANDERAALST WMP, 2002, P INT C ENG DEPL COO, P45; VanGlabbeek RJ, 1996, J ACM, V43, P555, DOI 10.1145/233551.233556	28	56	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	AUG	2006	18	8					1010	1027		10.1109/TKDE.2006.123		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	053HX	WOS:000238297300002	
J	Jiao, JX; Zhang, YY; Helander, M				Jiao, JX; Zhang, YY; Helander, M			A Kansei mining system for affective design	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						affective design; customer needs; Kansei engineering; association rule mining; conjoint analysis	REQUIREMENTS ACQUISITION; PRODUCT DESIGN; MANAGEMENT	Affective design has received much attention from both academia and industries. It aims at incorporating customers' affective needs into design elements that deliver customers' affective satisfaction. The main challenge for affective design originates from difficulties in mapping customers' subjective impressions, namely Kansei, to perceptual design elements. This paper intends to develop an explicit decision support to improve the Kansei mapping process by reusing knowledge from past sales records and product specifications. As one of the important applications of data mining, association rule mining lends itself to the discovery of useful patterns associated with the mapping of affective needs. A Kansei mining system is developed to utilize valuable affect information latent in customers' impressions of existing affective designs. The goodness of association rules is evaluated according to their achievements of customers' expectations. Conjoint analysis is applied to measure the expected and achieved utilities of a Kansei mapping relationship. Based on goodness evaluation, mapping rules are further refined to empower the system with useful inference patterns. The system architecture and implementation issues are discussed in detail. An application of Kansei mining to mobile phone affective design is presented. (c) 2005 Elsevier Ltd. All rights reserved.	Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore 639798, Singapore	Jiao, JX (reprint author), Nanyang Technol Univ, Sch Mech & Aerosp Engn, Nanyang Ave 50, Singapore 639798, Singapore.	jiao@pmail.ntu.edu.sg	Jiao, Jianxin (Roger)/A-9212-2010				Agrawal R., 1994, P 20 INT C VER LARG, P487; BLECKER T, 2004, 4 INT ICSC S ENG INT; BYRNE JG, 1993, P 37 ANN M HUM FACT, V37, P427; Chan M, 2000, POPTRONICS, V1, P20; CHEN CH, 1995, P 4 IND ENG RES C E, V2, P926; Chen CH, 2002, ADV ENG INFORM, V16, P229, DOI 10.1016/S1474-0346(03)00003-X; Chen Chien-Yuan, 2000, P 6 AS PAC MAN C TAI, P45; CHEN LL, 2001, P INT C AFF HUM FACT, P531; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Clausing D. P., 1994, TOTAL QUALITY DEV ST; CORTAZZI D, 1975, ILLUMINATIVE INCIDEN; Cross N, 2000, ENG DESIGN METHODS S; Demirbilek O, 2003, ERGONOMICS, V46, P1346, DOI 10.1080/00140130310001610874; Desmet P., 2003, FUNOLOGY USABILITY E; FISHBEIN M, 1972, ANNU REV PSYCHOL, V23, P487, DOI 10.1146/annurev.ps.23.020172.002415; FUKUDA S, 1993, DESIGN MANUFACTURABI, V52, P13; FUNG RTK, 1995, P 3 INT C MAN TECHN, P287; Fung RYK, 2002, INT J PROD RES, V40, P585, DOI 10.1080/00207540110061634; Green P. E., 1985, MARKET SCI, V4, P1, DOI 10.1287/mksc.4.1.1; GREEN PE, 1978, J CONSUM RES, V5, P58, DOI 10.1086/208714; Griffin A., 1992, MARKET SCI, V12, P1; HAJIME N, 2002, APPL KANSEI ENG NEW; Han J., 2001, DATA MINING CONCEPTS; HAUGE PL, 1993, P DES THEOR METH DTM, V53, P73; Hclander M.G., 2001, P INT C AFF HUM FACT; Helander MG, 2003, ERGONOMICS, V46, P1269, DOI 10.1080/00140130310001610810; Helander M.G., 2005, HDB HUMAN FACTORS ER; HELANDER MG, 2003, P 15 TRIENN C INT ER; Huffman C, 1998, J RETAILING, V74, P491, DOI 10.1016/S0022-4359(99)80105-5; JENKINS S, 1995, MARKETING       0713, V6; JORDAN PW, 2000, P C PLEAS BAS HUM FA; Kano N., 1984, HINSHITSU, V14, P39; Kelly G.A., 1955, PSYCHOL PERSONAL CON; Khalid H.M., 2004, THEORETICAL ISSUES E, V5, P27, DOI 10.1080/1463922031000086744; Khalid HM, 2004, THEORETICAL ISSUES E, V5, P1, DOI 10.1080/1463922031000086753; KHALID HM, 2001, USABILITY EVALUATION, V1; Kotler Philip, 1994, MARKETING MANAGEMENT; KRLSSON BSA, 2003, ERGONOMICS, V46, P1408; KULLER R, 1975, SEMANTIC DESCRIPTION; LaChance-Porter S., 1993, P 14 NAT ON LIN M NE, P265; LOUDER D, 1988, CONSUMER BEHAV CONCE; LOUVIERE J, 1990, P IFIP TC 7 C MOD IN, P53; Maiden NAM, 1996, SOFTWARE ENG J, V11, P183; Matsubara Y, 1997, INT J IND ERGONOM, V19, P81, DOI 10.1016/S0169-8141(96)00005-4; McAdams DA, 1999, RES ENG DES, V11, P1, DOI 10.1007/s001630050001; McKay A, 2001, COMPUT AIDED DESIGN, V33, P511, DOI 10.1016/S0010-4485(01)00050-1; Mead M., 1928, COMING AGE SAMOA; Nadia B.B., 2001, P INT C IFSA NAFIPS; Nagamachi M., 1996, INTRO KANSEI ENG; Nagamachi M, 1989, KANSEI ENG; ISHIHARA S, 1995, INT J IND ERGONOM, V15, P13, DOI 10.1016/0169-8141(94)15053-8; OSGOOD C, 1967, MEASUREMENT MEANI; Piller F.T., 2003, ADV MASS CUSTOMIZATI; Rugg G., 1995, EXPERT SYST, V12, P279; Saaty TL, 1980, ANAL HIERARCHY PROCE; Scherer K, 1998, P 10 C INT SOC RES E, P142; SEDGWICK J, 2003, P 2003 INT C DES PLE; Shaw MLG, 1996, SOFTWARE ENG J, V11, P149; SHAW MLG, 1980, RECENT ADV PERSONAL; SHOJI S, 1993, NEW AM TQM; Tseng MM, 1998, CONCURRENT ENG-RES A, V6, P145, DOI 10.1177/1063293X9800600205; Turksen I.B., 1992, P SPIE INT SOC OPT E, P203; Wedel M., 1998, MARKET SEGMENTATION; Yan W, 2002, AI EDAM, V16, P59, DOI 10.1017/S0890060402020061; YAN W, 2001, EXPERT SYSTEM, V8, P219; Zeithaml V. A., 2001, SERVICES MARKETING I	66	56	62	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2006	30	4					658	673		10.1016/j.eswa.2005.07.020		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	022IH	WOS:000236048400011	
J	Laube, P; Imfeld, S; Weibel, R				Laube, P; Imfeld, S; Weibel, R			Discovering relative motion patterns in groups of moving point objects	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article						moving point objects; geographic knowledge discovery; data mining; pattern matching; temporal granularity	KNOWLEDGE DISCOVERY; SPATIOTEMPORAL DATABASES; ENVIRONMENTS; CONSTRAINTS; UNCERTAINTY; MOVEMENTS; LANGUAGE; SYSTEMS; MODELS	Technological advances in position-aware devices are leading to a wealth of data documenting motion. The integration of spatio-temporal data-mining techniques in GIScience is an important research field to overcome the limitations of static Geographic Information Systems with respect to the emerging volumes of data describing dynamics. This paper presents a generic geographic knowledge discovery approach for exploring the motion of moving point objects, the prime modelling construct to represent GPS tracked animals, people, or vehicles. The approach is based on the concept of geospatial lifelines and presents a formalism for describing different types of lifeline patterns that are generalizable for many application domains. Such lifeline patterns allow the identification and quantification of remarkable individual motion behaviour, events of distinct group motion behaviour, so as to relate the motion of individuals to groups. An application prototype featuring novel data-mining algorithms has been implemented and tested with two case studies: tracked soccer players and data points representing political entities moving in an abstract ideological space. In both case studies, a set of non-trivial and meaningful motion patterns could be identified, for instance highlighting the characteristic 'offside trap' behaviour in the first case and identifying trendsetting districts anticipating a political transformation in the latter case.	Univ Zurich, Dept Geog, CH-8057 Zurich, Switzerland	Laube, P (reprint author), Univ Zurich, Dept Geog, Winterhurerstr 190, CH-8057 Zurich, Switzerland.	plaube@geo.unizh.ch	Laube, Patrick/F-5385-2010				Abraham T., 1999, GeoInformatica, V3, DOI 10.1023/A:1009800916313; Andrienko GL, 1999, INT J GEOGR INF SCI, V13, P355, DOI 10.1080/136588199241247; ARONOFF S, 1989, GEOGRAPHIC INFORMATI; Batty M, 2003, INT J GEOGR INF SCI, V17, P673, DOI 10.1080/1365881031000135474; Bedard Y, 2003, INT J MED INFORM, V70, P79, DOI 10.1016/S1386-5056(02)00126-0; Bettini C, 2000, TIME GRANULARITIES D; Cheng R, 2004, IEEE T KNOWL DATA EN, V16, P1112, DOI 10.1109/TKDE.2004.46; CHEYLAN JP, 2001, GISDATA8 LIFE MOTION, P35; Edsall RM, 2000, COMPUT GEOSCI-UK, V26, P109, DOI 10.1016/S0098-3004(99)00037-0; Erwig M., 1999, GeoInformatica, V3, DOI 10.1023/A:1009805532638; Erwig M, 2003, J VISUAL LANG COMPUT, V14, P181, DOI 10.1016/S1045-926X(02)00057-5; Erwig M, 2002, IEEE T KNOWL DATA EN, V14, P881, DOI 10.1109/TKDE.2002.1019220; Fayyad U, 1996, AI MAG, V17, P37; Frangos SG, 2001, ENDOTHELIUM-NEW YORK, V8, P1; Frank AU, 2003, LECT NOTES COMPUT SC, V2520, P9; Friedl J.E.F., 2002, MASTERING REGULAR EX; Ganskopp D, 2001, APPL ANIM BEHAV SCI, V73, P251, DOI 10.1016/S0168-1591(01)00148-4; Golledge RG, 2002, ANN ASSOC AM GEOGR, V92, P1, DOI 10.1111/1467-8306.00276; Grumbach S, 2003, LECT NOTES COMPUT SC, V2520, P177; Grumbach S, 2001, GEOINFORMATICA, V5, P95, DOI 10.1023/A:1011464022461; GUETING RH, 2003, LECT NOTES COMPUTER, V2520, P117; HERMANN M, 2001, SWISS POLITICAL SCI, V7, P39, DOI 10.1002/j.1662-6370.2001.tb00327.x; HERMANN MHL, 2003, ATLAS POLITISCHEN LA; Hornsby K, 2002, ANN MATH ARTIF INTEL, V36, P177, DOI 10.1023/A:1015812206586; Hornsby K., 2001, T GIS, V5, P255, DOI 10.1111/1467-9671.00081; HUISMAN O, 1998, P 3 INT C GEOC U BRI; IWASE S, 2002, MVA P, P102; IWASE S, 2003, P SOC PHOTO-OPT INS, P288; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Knuth D. E., 1977, SIAM Journal on Computing, V6, DOI 10.1137/0206024; Koubarakis M, 2003, LECT NOTES COMPUT SC, V2520, P345; Kraak M.J., 2004, DEV SPATIAL DATA HAN, P189; Laube P., 2004, DEV SPATIAL DATA HAN, P201; Laube P., 2002, LECT NOTES COMPUTER, V2478, P132; Maceachren AM, 1999, INT J GEOGR INF SCI, V13, P311, DOI 10.1080/136588199241229; Mark D. M., 2003, FDN GEOGRAPHIC INFOR, P3; MARK DM, 1998, INTEGRATING SPATIAL, P98471; Michael T, 1998, DATA STRUCTURES ALGO; Miller H. J., 2003, COMPUTERS ENV URBAN, V27, P447, DOI 10.1016/S0198-9715(03)00059-0; MILLER HJ, 1991, INT J GEOGR INF SYST, V5, P287, DOI 10.1080/02693799108927856; Miller H. J., 2001, GEOGRAPHIC DATA MINI, P3, DOI 10.4324/9780203468029_chapter_1; Miller H. J., 2000, GeoInformatica, V4, DOI 10.1023/A:1009820006075; MOUNTAIN D, 2001, P 6 INT C GEOC U QUE; NYQUIST N, 1928, T AIEE, V47, P617; Openshaw S., 1994, GIS SPATIAL ANAL, P83; Openshaw S, 1984, MODIFIABLE AREAL UNI; OPENSHAW S, 1999, GEOGRAPHICAL ENV MOD, V3, P83; OSULLIVAN D, 2003, GEOGRAPHIC INFORMATI; Pfoser D, 1999, LECT NOTES COMPUT SC, V1651, P111; RAPER J, 1995, INT J GEOGR INF SYST, V9, P359, DOI 10.1080/02693799508902044; Raptopoulou K, 2003, GEOINFORMATICA, V7, P113, DOI 10.1023/A:1023403908170; Rivest S., 2001, GEOMATICA, V55, P539; Roddick John F., 2001, LECT NOTES ARTIF INT, V2007, P147; ROOT RB, 1984, ECOLOGY, V65, P147, DOI 10.2307/1939467; Sadahiro Y., 2002, CARTOGR GEOGR INF SC, V29, P67, DOI 10.1559/152304002782053332; SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969; Sibbald Angela M., 2001, P39; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; Sistla A., 1998, LECT NOTES COMPUTER, V1399, P310; SISTLA AP, 1997, P 13 INT C DAT ENG I; Smyth C. S., 2001, GEOGRAPHIC DATA MINI, P337, DOI 10.4324/9780203468029_chapter_14; SNODGRASS R, 1987, ACM T DATABASE SYST, V12, P247, DOI 10.1145/22952.22956; SNODGRASS RT, 1995, TSQL2 TEMPORAL QUERY, P3; Trajcevski G, 2004, ACM T DATABASE SYST, V29, P463, DOI 10.1145/1016028.1016030; Turchin P., 1998, QUANTITATIVE ANAL MO; TURCHIN P, 1991, ECOLOGY, V72, P1253, DOI 10.2307/1941099; WALL L, 1996, PROGRAMMING PERL; Wentz EA, 2003, INT J GEOGR INF SCI, V17, P623, DOI 10.1080/1365881031000135492; Wolfson O, 1998, TENTH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT - PROCEEDINGS, P111	70	56	57	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	JUL	2005	19	6					639	668		10.1080/13658810500105572		30	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	940GV	WOS:000230132600002	
J	Liu, HW; Sun, J; Liu, L; Zhang, HJ				Liu, Huawen; Sun, Jigui; Liu, Lei; Zhang, Huijie			Feature selection with dynamic mutual information	PATTERN RECOGNITION			English	Article						Classification; Feature selection; Mutual information; Filter method	FEATURE SUBSET-SELECTION; ALGORITHMS; RELEVANCE; CLASSIFICATION; DEPENDENCY; REDUNDANCY	Feature selection plays an important role in data mining and pattern recognition, especially for large scale data. During past years, various metrics have been proposed to measure the relevance between different features. Since mutual information is nonlinear and can effectively represent the dependencies of features, it is one of widely used measurements in feature selection. just owing to these, many promising feature selection algorithms based on mutual information with different parameters have been developed. In this paper, at first a general criterion function about mutual information in feature selector is introduced, which can bring most information measurements in previous algorithms together. In traditional selectors. mutual information is estimated on the whole sampling space. This, however, cannot exactly represent the relevance among features. To cope with this problem, the second purpose of this paper is to propose a new feature selection algorithm based on dynamic mutual information, which is only estimated on unlabeled instances. To verify the effectiveness of our method, several experiments are carried out on sixteen UCI datasets using four typical classifiers. The experimental results indicate that our algorithm achieved better results than other methods in most cases. (C) 2008 Elsevier Ltd. All rights reserved.	[Liu, Huawen; Sun, Jigui; Liu, Lei] Jilin Univ, Coll Comp Sci, Changchun 130012, Jilin, Peoples R China; [Sun, Jigui; Liu, Lei] Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China; [Zhang, Huijie] NE Normal Univ, Coll Comp, Changchun 130021, Peoples R China	Liu, L (reprint author), Jilin Univ, Coll Comp Sci & Technol, 2699 Qianjin St, Changchun 130012, Jilin, Peoples R China.	Huaw.Liu@gmail.com; JgSun@jlu.edu.cn; Liulei@jlu.edu.cn; Zhanghj167@nenu.edu.cn			Doctor Point Foundation of Educational Department [20060183044]; Science Foundation for Young Teachers of Northeast Normal University [20081003]	The authors are grateful to anonymous referees for their valuable and constructive comments, and Prof. Ying Kim for her valuable suggestions. This work is supported by the Doctor Point Foundation of Educational Department (20060183044) and Science Foundation for Young Teachers of Northeast Normal University (20081003).	AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Al-Ani A., 2003, Intelligent Data Analysis, V7; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Bazan J., 1998, ROUGH SETS KNOWLEDGE, V1, P321; Bell DA, 2000, MACH LEARN, V41, P175, DOI 10.1023/A:1007612503587; Bellman R., 1961, ADAPTIVE CONTROL PRO; BHAVANI SD, 2007, APPL SOFT COMPUT, V8, P555; Bishop CM, 1995, NEURAL NETWORKS PATT; Blake C, 1998, UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cover T. M., 1991, ELEMENTS INFORM THEO; DASGUPTA A, 2007, P 13 ACM SIGKDD INT, P230, DOI 10.1145/1281192.1281220; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Devijver P., 1992, PATTERN RECOGNITION; Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100; Dy JG, 2004, J MACH LEARN RES, V5, P845; Fayyad U, 1996, AI MAG, V17, P37; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fleuret F, 2004, J MACH LEARN RES, V5, P1531; Fodor IK, 2002, UCRLID148494 US DEP; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Gadat S, 2007, J MACH LEARN RES, V8, P509; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M. A., 1999, THESIS U WAIKATO HAM; Hall M. A., 2003, IEEE T KNOWL DATA EN, V15, P1041; Huang D, 2005, NEUROCOMPUTING, V63, P325, DOI 10.1016/j.neucom.2004.01.194; Huang JJ, 2007, PATTERN RECOGN LETT, V28, P1825, DOI 10.1016/j.patrec.2007.05.011; John G. H., 1994, P 11 INT C MACH LEAR, P121; John G.H, 1995, P 11 C UNC ART INT, P338; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I, 1994, P EUR C MACH LEARN, P171; Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861; Lee WK, 2000, ARTIF INTELL REV, V14, P533, DOI 10.1023/A:1006624031083; Liang JN, 2008, PATTERN RECOGN, V41, P1429, DOI 10.1016/j.patcog.2007.10.018; Lindenbaum M, 2004, MACH LEARN, V54, P125, DOI 10.1023/B:MACH.0000011805.60520.fe; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Liu H, 2004, ARTIF INTELL, V159, P49, DOI 10.1016/j.artini.2004.05.009; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9; Pawlak Z., 1991, ROUGH SETS THEORETIC; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Qu GZ, 2005, IEEE T KNOWL DATA EN, V17, P1199, DOI 10.1109/TKDE.2005.136; QUINLAN R, 1993, C 4 5 PROGRAMS MACHI; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Schein AI, 2007, MACH LEARN, V68, P235, DOI 10.1007/s10994-007-5019-5; Somol P, 2004, IEEE T PATTERN ANAL, V26, P900, DOI 10.1109/TPAMI.2004.28; Song YQ, 2008, PATTERN RECOGN, V41, P2789, DOI 10.1016/j.patcog.2008.01.001; Sousa E. P. M. d., 2007, DATA MIN KNOWL DISC, V14, P367, DOI [10.1007/s10618-006-0056-4, DOI 10.1007/S10618-006-0056-4]; SWETS DL, 1995, IEEE INT S COMP VIS, P85; Traina Jr C, 2000, P 15 BRAZ S DAT SBBD, P158; Wang G., 2004, P INT C INF KNOWL MA, P342, DOI 10.1145/1031171.1031241; Witten IH, 2005, DATA MINING PRACTICA; Wu S., 2002, ECML PKDD 02 WORKSH, P156; Xing E. P., 2001, P 18 INT C MACH LEAR, P601; Yu L, 2004, J MACH LEARN RES, V5, P1205; Zhang DQ, 2008, PATTERN RECOGN, V41, P1440, DOI 10.1016/j.patcog.2007.10.009; Zhao Z., 2007, P 24 INT C MACH LEAR, P1151, DOI 10.1145/1273496.1273641; ZHU X, 2007, 1530 U WISC DEP COMP	63	55	67	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUL	2009	42	7					1330	1339		10.1016/j.patcog.2008.10.028		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	435TF	WOS:000265365500012	
J	Wang, F; Zhang, CS				Wang, Fei; Zhang, Changshui			Label propagation through linear Neighborhoods	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						structured data mining; semisupervised learning; graph; label propagation; linear neighborhoods	NONLINEAR DIMENSIONALITY REDUCTION; GEOMETRIC FRAMEWORK; CLASSIFICATION; EM	In many practical data mining applications such as text classification, unlabeled training examples are readily available, but labeled ones are fairly expensive to obtain. Therefore, semisupervised learning algorithms have aroused considerable interests from the data mining and machine learning fields. In recent years, graph-based semisupervised learning has been becoming one of the most active research areas in the semisupervised learning community. In this paper, a novel graph- based semisupervised learning approach is proposed based on a linear neighborhood model, which assumes that each data point can be linearly reconstructed from its neighborhood. Our algorithm, named Linear Neighborhood Propagation ( LNP), can propagate the labels from the labeled points to the whole data set using these linear neighborhoods with sufficient smoothness. A theoretical analysis of the properties of LNP is presented in this paper. Furthermore, we also derive an easy way to extend LNP to out-of-sample data. Promising experimental results are presented for synthetic data, digit, and text classification tasks.	Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China	Wang, F (reprint author), Tsing Hua Univ, Dept Automat, Room 3-120, FIT Bldg, Beijing 100084, Peoples R China.	feiwang03@mails.thu.edu.cn; zcs@mails.thu.edu.cn					BALCAN MF, 2005, P ICML WORKSH LEARN; Belkin M., 2004, P 17 ANN C LEARN THE, P624; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2006, NEURAL COMPUT, V18, P2509, DOI 10.1162/neco.2006.18.10.2509; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Blum PR, 2001, STUD EUROP JUDAISM, V1, P19; Carreira-Perpinan M., 2005, ADV NEURAL INFORM PR, V17, P225; CHAPELLE O, 2006, SEMI SUPERVISED LEAR, P371; CHAPELLE O, 2003, ADV NEURAL INFORM PR, V15, P601; Chung Fan R.K., 1997, CBMS REG C SER MATH, V92; Delalleau O., 2005, P 10 INT WORKSH ART, P96; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Golub G. H., 1989, MATRIX COMPUTATION; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Joachims T., 2003, P 20 INT C MACH LEAR, P290; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; KAPOOR A, 2005, ADV NEURAL INFORM PR; LAWRENCE ND, 2005, ADV NEURAL INF PROCE, V17; Miller DJ, 1997, ADV NEUR IN, V9, P571; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul L., 2006, SEMISUPERVISED LEARN; Scholkopf B., 2002, LEARNING KERNELS; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; Szummer M, 2002, ADV NEUR IN, V14, P945; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang F., 2006, P 23 INT C MACH LEAR, P985, DOI DOI 10.1145/1143844.1143968; Zhou D., 2005, ADV NEURAL INFORM PR, V17, P1633; ZHOU D, 2004, P 26 PATT REC S DAGM; Zhou DY, 2004, ADV NEUR IN, V16, P321; ZHU X., 2002, CMUCALD02107; Zhu X., 2003, P 20 INT C MACH LEAR; Zhu X., 2003, CMUCS03175; ZHU X, 2002, CMUCALD02106; ZHU X, 2006, 1530 U WISCONSIN	39	55	76	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN	2008	20	1					55	67		10.1109/TKDE.2007.190672		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	232FI	WOS:000251003300005	
J	Yao, H; Hamilton, HJ				Yao, Hong; Hamilton, Howard J.			Mining itemset utilities from transaction databases	DATA & KNOWLEDGE ENGINEERING			English	Article						utility mining; data mining; semantic significance; user preference; itemset		The rationale behind mining frequent itemsets is that only itemsets with high frequency are of interest to users. However, the practical usefulness of frequent itemsets is limited by the significance of the discovered itemsets. A frequent itemset only reflects the statistical correlation between items, and it does not reflect the semantic significance of the items. In this paper, we propose a utility based itemset mining approach to overcome this limitation. The proposed approach permits users to quantify their preferences concerning the usefulness of itemsets using utility values. The usefulness of an itemset is characterized as a utility constraint. That is, an itemset is interesting to the user only if it satisfies a given utility constraint. We show that the pruning strategies used in previous itemset mining approaches cannot be applied to utility constraints. In response, we identify several mathematical properties of utility constraints. Then, two novel pruning strategies are designed. Two algorithms for utility based itemset mining are developed by incorporating these pruning strategies. The algorithms are evaluated by applying them to synthetic and real world databases. Experimental results show that the proposed algorithms are effective on the databases tested. (c) 2005 Elsevier B.V. All rights reserved.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Hamilton, HJ (reprint author), Univ Regina, Dept Comp Sci, 3737 Wascana Pkwy, Regina, SK S4S 0A2, Canada.	yao2hong@cs.uregina.ca; hamilton@cs.uregina.ca					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Barber B, 2003, DATA MIN KNOWL DISC, V7, P153, DOI 10.1023/A:1022419032620; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo RJ, 1999, PROC INT CONF DATA, P188, DOI 10.1109/ICDE.1999.754924; Burdick D, 2005, IEEE T KNOWL DATA EN, V17, P1490, DOI 10.1109/TKDE.2005.183; Cai C. H., 1998, Proceedings. IDEAS'98. International Database Engineering and Applications Symposium (Cat. No.98EX156), DOI 10.1109/IDEAS.1998.694360; Chan R, 2003, P 3 IEEE INT C DAT M, P19; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Kleinberg J, 1998, DATA MIN KNOWL DISC, V2, P311, DOI 10.1023/A:1009726428407; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; LIN TY, 2002, 6 PAC C TAIP, P328; Lu S., 2001, INTELL DATA ANAL, V5, P211; Mannila H., 1994, AAAI WORKSH KNOWL DI, P181; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Pei J., 2000, P 6 ACM SIGKDD INT C, P350, DOI 10.1145/347090.347166; Pei J, 2004, DATA MIN KNOWL DISC, V8, P227, DOI 10.1023/B:DAMI.0000023674.74932.4c; Salton G., 1989, AUTOMATIC TEXT PROCE; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; WANG K, 2002, 8 INT C EXT DAT TECH, P70; Yao H, 2004, SIAM PROC S, P482	23	55	59	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	DEC	2006	59	3			SI		603	626		10.1016/j.datak.2005.10.004		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	098OX	WOS:000241533800006	
J	Agrawal, R; Gehrke, J; Gunopulos, D; Raghavan, P				Agrawal, R; Gehrke, J; Gunopulos, D; Raghavan, P			Automatic subspace clustering of high dimensional data	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						subspace clustering; clustering; dimensionality reduction		Data mining applications place special requirements on clustering algorithms including: the ability to find clusters embedded in subspaces of high dimensional data, scalability, end-user comprehensibility of the results, non-presumption of any canonical data distribution, and insensitivity to the order of input records. We present CLIQUE, a clustering algorithm that satisfies each of these requirements. CLIQUE identifies dense clusters in subspaces of maximum dimensionality. It generates cluster descriptions in the form of DNF expressions that are minimized for ease of comprehension. It produces identical results irrespective of the order in which input records are presented and does not presume any specific mathematical form for data distribution. Through experiments, we show that CLIQUE efficiently finds accurate clusters in large high dimensional datasets.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA; Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Ver Inc, Sunnyvale, CA 94089 USA	Agrawal, R (reprint author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.	ragrawal@almaden.ibm.com; johannes@cs.cornell.edu; dg@cs.ucr.edu; pragh@verity.com					Aggarwal C. C., 2000, P ACM SIGMOD INT C M, P70, DOI 10.1145/342009.335383; AGGRAWAL C, 1999, P 1999 ACM SIGMOD IN; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Arabie P., 1996, CLUSTERING CLASSIFIC, P5; BAYARDO R, 1998, P ACM SIGMOD C MAN D; Berchtold S., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263671; BERGER M, 1991, IEEE T SYST MAN CYB, V21, P1278, DOI 10.1109/21.120081; Brin S., 1997, P ACM SIGMOD C MAN D; Bronnimann H., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, DOI 10.1145/177424.178029; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHHIKARA RS, 1979, TECHNOMETRICS, V21, P531, DOI 10.2307/1268293; DOMENICONI C, 2004, SIAM INT C DAT MIN S; Duda R., 1973, PATTERN CLASSIFICATI; EARLE RJ, 1994, Patent No. [5359724, 05359724]; Ester M., 1996, P 2 INT C KNOWL DISC; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FEIGE U, 1976, P 28 ANN ACM S THEOR, P314; FRANZBLAU DS, 1984, P 6 ANN S THEOR COMP, P268; FRANZBLAU DS, 1989, SIAM J DISCRETE MATH, V2, P307, DOI 10.1137/0402027; FRIEDMAN J, 1997, UW MSR SUMMER RES I; Fukunaga K., 1990, INTRO STAT PATTERN R; Gunopulos D., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263684; HO CT, 1997, P ACM SIGMOD C MAN D; HONG SJ, 1987, SELECTED PAPERS LOGI; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kaufman L., 1990, FINDING GROUPS DATA; LIN DI, 1998, P 6 INT C EXT DAT TE; LOVASZ L, 1975, DISCRETE MATH, V13, P383, DOI 10.1016/0012-365X(75)90058-8; Lund C., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167172; MAEK W, 1978, THESIS MIT; Mehta M., 1996, P 5 INT C EXT DAT TE; MICHALSKI RS, 1983, MACHINE LEARNING AI, V1, P331; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; NG RT, 1994, P VLDB C SANT CHIL; PROCOPIUC CM, 2002, SIGMOD; Reckhow R.A., 1987, P ACM 3 ANN COMP GEO, P268, DOI 10.1145/41958.41987; Rissanen J, 1989, STOCHASTIC COMPLEXIT; SCHROETER P, 1995, PATTERN RECOGN, V28, P695, DOI 10.1016/0031-3203(94)00133-7; Shafer J., 1996, P 22 INT C VER LARG; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; SHOSHANI A, 1997, COMMUNICATION; Sneath P.H.A., 1973, NUMERICAL TAXONOMY; Soltan V., 1992, Proceedings of the Eighth Annual Symposium on Computational Geometry, DOI 10.1145/142675.142735; Srikant R, 1996, P ACM SIGMOD C MAN D; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; Ullman J. D., 1974, DESIGN ANAL COMPUTER; WHARTON SW, 1983, PATTERN RECOGN, V16, P193, DOI 10.1016/0031-3203(83)90022-5; Xu X., 1995, P 1 INT C KNOWL DISC; Zait M, 1997, FUTURE GENER COMP SY, V13, P149, DOI 10.1016/S0167-739X(97)00018-6; ZHANG D, 1986, P 2 ANN ACM S COMP, P314; Zhang T., 1996, P ACM SIGMOD C MAN D; *ARB SOFTW CORP, APPL MAN US GUID ESS; *INT BUS MACH, 1996, IBM INT MIN US GUID	54	55	67	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2005	11	1					5	33		10.1007/s10618-005-1396-1		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	951LQ	WOS:000230932200001	
J	Torra, V				Torra, V			OWA operators in data modeling and reidentification	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						aggregation operators; learning models; ordered weighting averaging (OWA) operators; privacy preserving data mining; record linkage; reidentification methods; weighted mean	AGGREGATION OPERATORS; DECISION-MAKING; NEURAL-NETWORKS; RECORD-LINKAGE; CLASSIFICATION; WEIGHTS	This paper is devoted to the application of aggregation operators and to the application of ordered weighting averaging (OWA) operators to data mining. In particular, we consider two application of OWA operators in this field: model building and information extraction. The latter application is oriented to the reidentification procedures.	CSIC, Inst Invest Intel Iigencia Artif, E-08193 Barcelona, Spain	Torra, V (reprint author), CSIC, Inst Invest Intel Iigencia Artif, Campus UAB S-N, E-08193 Barcelona, Spain.	vtorra@iiia.csic.es					Bacher J, 2002, INT J UNCERTAIN FUZZ, V10, P589, DOI 10.1142/S0218488502001661; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Beliakov G, 2003, INT J INTELL SYST, V18, P903, DOI 10.1002/int.10120; Calvo T., 2002, AGGREGATION OPERATOR; Carbonell M, 1997, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I - III, P1695, DOI 10.1109/FUZZY.1997.619795; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DOMINGOFERRER J, 2003, INFORM SCI, V153, P153; Domingo-Ferrer J, 2003, STAT COMPUT, V13, P343, DOI 10.1023/A:1025666923033; Filev D, 1998, FUZZY SET SYST, V94, P157, DOI 10.1016/S0165-0114(96)00254-0; FILEV D, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P468, DOI 10.1109/FUZZY.1994.343740; Gill L, 2001, METHODS AUTOMATIC RE; GRABISCH M, 1995, FUNDAMENTALS UNCERTA; Grabisch Michel, 2003, INFORM FUSION DATA M, P135; JARO MA, 1989, J AM STAT ASSOC, V84, P414, DOI 10.2307/2289924; Merz CJ, 1999, MACH LEARN, V36, P33, DOI 10.1023/A:1007559205422; Merz CJ, 1999, MACH LEARN, V36, P9, DOI 10.1023/A:1007507221352; Murphy P., 1994, UCI REPOSITORY MACHI; Nettleton D, 2001, INT J MED INFORM, V63, P77, DOI 10.1016/S1386-5056(01)00173-3; NEWCOMBE HB, 1959, SCIENCE, V130, P954, DOI 10.1126/science.130.3381.954; O'Hagan M., 1988, P 22 ANN IEEE AS C S, P681; PAGLIUCA D, 1999, MI3D2 ESPR SDC; Rahm E., 2000, B TECHNICAL COMMITTE, V23, P3; REINHARD F, 1997, ATLAS MATH; Ribeiro RA, 1996, FUZZY SET SYST, V78, P155, DOI 10.1016/0165-0114(95)00166-2; Robison-Cox James F., 1998, Journal of Agricultural Biological and Environmental Statistics, V3, P48, DOI 10.2307/1400622; Saaty TL, 1980, ANAL HIERARCHY PROCE; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; SUGENO M, FUZZY MEASURES; Sugeno M, 1974, THESIS TOKYO I TECHN; TANAKA A, 1989, P 5 FUZZ SYST S KOB, P213; Torra V, 1999, INT J INTELL SYST, V14, P1089, DOI 10.1002/(SICI)1098-111X(199911)14:11<1089::AID-INT2>3.3.CO;2-J; Torra V, 2002, IEEE T FUZZY SYST, V10, P653, DOI 10.1109/TFUZZ.2002.803498; TORRA V, 2000, P 14 EUR C ART INT E, P326; Torra V, 1997, INT J INTELL SYST, V12, P153, DOI 10.1002/(SICI)1098-111X(199702)12:2<153::AID-INT3>3.0.CO;2-P; Torra V, 2000, FUZZY SET SYST, V113, P389, DOI 10.1016/S0165-0114(98)00040-2; TORRA V, 2000, 6 INT C SOFT COMP FU; Torra V., 1999, MATHWARE SOFT COMPUT, V6, P249; TORRA V, 2000, IEEE INT C IND EL CO; TORRA V, 2003, INFORMATION FUSION D; Torra V., 2003, INFORM FUSION DATA M, P101; TUMER K, 1996, WORK NOT WORKSH INT; Winkler W. E., 1995, P SECT SURV RES METH, P467; WINKLER WE, 1995, WILEY S PRO, P355; Xu ZS, 2003, INT J INTELL SYST, V18, P953, DOI 10.1002/int.10127; YAGER RR, 1993, FUZZY SET SYST, V59, P125, DOI 10.1016/0165-0114(93)90194-M; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; Zhong N, 1999, LECT NOTES ARTIF INT, V1704, P136; *US BUR CENS, 2000, REC LINK SOFTW US DO	49	55	55	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	OCT	2004	12	5					652	660		10.1109/TFUZZ.2004.834814		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	862FR	WOS:000224476300007	
J	Kleinberg, J				Kleinberg, J			Bursty and hierarchical structure in streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th ACM/SIGKDD International Conference on Knowledge Discovery and Data Mining	JUL, 2002	EDMONTON, CANADA	ACM, SIGKDD		data stream algorithms; text mining; Markov source models		A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time. E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale. Underlying much of the text mining work in this area is the following intuitive premise-that the appearance of a topic in a document stream is signaled by a "burst of activity," with certain features rising sharply in frequency as the topic emerges. The goal of the present work is to develop a formal approach for modeling such " bursts," in such a way that they can be robustly and efficiently identified, and can provide an organizational framework for analyzing the underlying content. The approach is based on modeling the stream using an infinite-state automaton, in which bursts appear naturally as state transitions; it can be viewed as drawing an analogy with models from queueing theory for bursty network traffic. The resulting algorithms are highly efficient, and yield a nested representation of the set of bursts that imposes a hierarchical structure on the overall stream. Experiments with e-mail and research paper archives suggest that the resulting structures have a natural meaning in terms of the content that gave rise to them.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Kleinberg, J (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Agrawal R., 1995, P INT C DAT ENG; AIGRAIN P, 1996, MULTIMEDIA TOOLS APP, V3; Allan J., 1998, P DARPA BROADC NEWS; ALLAN J, 1998, P SIGIR INT C INF RE; ANICK D, 1982, BELL SYST TECH J, V61; BECKER K, 2000, P 15 BRAZ S DAT; Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214; Berghel H, 1997, COMMUN ACM, V40, P11, DOI 10.1145/256175.256176; BIRRELL A, 1997, PACHYDERM E MAIL SYS; BLANTON T, 1995, WHITE HOUSE E MAIL; BOONE G, 1998, P 2 INT C AUT AG; CHARIKAR M, 2002, P 29 INT C AUT LANG; Chatfield C., 1996, ANAL TIME SERIES INT; Chatman Seymour, 1978, STORY DISCOURSE NARR; CHUDOVA D, 2001, KDD WORKSH TEMP DAT; COHEN WW, 1996, P AAAI SPRING S MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EHRICH R, 1976, IEEE T COMPUT, V25, P7; ELWALID A, 1993, IEEE ACM T NETWORKIN, V1; FINE S, 1998, MACHINE LEARNING, V32; Forster E. M., 1927, ASPECTS NOVEL; GAROFALAKIS M, 2002, ACM SIGMOD INT C MAN; GAY G, 2001, ED TECHNOLOGY SOC, V4; Genette Gerard, 1980, NARRATIVE DISCOURSE; Genette Gerard, 1988, NARRATIVE DISCOURSE; GROSZ BJ, 1986, COMPUTATIONAL LINGUI, V12; GRUBER T, HYPERMAIL; GURALNIK V, 1999, INT C KNOWL DISC DAT; HAN J, 1998, P INT C KNOWL DISC D; Hand D. J., 2001, PRINCIPLES DATA MINI; HAVRE S, 2000, P IEEE S INF VIS; HAWKINS D, 1976, APPL STAT, V25; HECKEL B, 1997, P WORKSH NEW PAR INF; HELFMAN J, 1995, ISHMAIL IMMEDIATE ID; Horvitz E., 1999, P ACM C HUM FACT COM; HUDSON DJ, 1966, J AM STAT ASSOC, V61, P1097, DOI 10.2307/2283203; Kelly F., 1996, STOCHASTIC NETWORKS; KEOGH E, 1997, P INT C KNOWL DISC D; LAST M, 2001, IEEE T SYSTEMS MAN B, V31; LAVRENKO V, 2000, KDD 2000 WORKSH TEXT; LEWIS DD, 1997, INF P MANAGEMENT, V33; LUKESH SS, 1999, 1 MONDAY, V4; Maes P., 1994, Communications of the ACM, V37, DOI 10.1145/176789.176792; MANNILA H, 2001, P INT C KNOWL DISC D; MARKUS ML, 1994, ACM T INFORM SYST, V12, P119, DOI 10.1145/196734.196738; MARTIN R, 2001, KDD WKSHP TEMP DAT M; MILLER N, 1998, P IEEE VISUALIZATION; Moore R. W., 2000, D LIB MAGAZINE, V6; MURPHY K, 2001, ADV NEURAL INFORMATI, V14; OLSEN F, 1999, CHRONICLE HIGHE 0824; Payne TR, 1997, APPL ARTIF INTELL, V11, P1, DOI 10.1080/088395197118325; POLLOCK S, 1988, ACM T INFORM SYST, V6, P232, DOI 10.1145/45945.214327; Rabiner L., 1989, P IEEE, V77; REDMOND M, 1998, P AAAI WORKSH CAS BA; RENNIE J, 2000, P KDD WORKSH TEXT MI; Sahami M., 1998, P AAAI WORKSH LEARN; Schneier B., 1996, APPL CRYPTOGRAPHY; SCOTT S, 1998, THESIS HARVARD U; SCOTT SL, 2002, MARKOV MODULATED POI; SEGAL R, 1999, P INT C AUT AG; SEGAL R, 2000, P INT C MACH LEARN; SHAW S, 1990, IEEE T ACOUSTICS SPE, V38, P2; SWAN R, 2000, P SIGIR INT C INF RE; SWAN R, 2000, KDD 2000 WORKSH TEXT; Swan R, 1999, P 8 INT C INF KNOWL; WHITTAKER S, 1996, P ACM SIGCHI C HUM F; WONG P, 2000, P IEEE INFORMATION V; YANG Y, 2000, P SIGIR INT C INF RE; YANG Y, 1998, P SIGIR INT C INF RE; GOGGLE ZEITGEIST SEA	70	55	58	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2003	7	4					373	397		10.1023/A:1024940629314		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	704UM	WOS:000184358900003	
J	Wang, G				Wang, G			Rough reduction, in algebra view and information view	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article								Rough set (RS) is a valid theory to deal with imprecise,, uncertain, and vague information. It has been applied successfully since it was developed by Professor Z. Pawlak in 1982 in such fields as machine learning, data mining, intelligent data analyzing, control algorithm acquiring, etc. The greatest advantage of the RS is its great ability to compute the reductions of information systems. Many researchers have done a lot of work in developing efficient algorithms to compute useful reductions of information systems. There also are some researchers working on the relationship between rough entropy and information entropy. They have developed some efficient reduction algorithms based on conditional information entropy. In this article, the relationship of the definitions of rough reduction in algebra view and information view is studied. Some relationships such as inclusion relationship under some conditions and equivalence relationship under some other conditions are presented. The inclusion relationship between the attribute importance defined in algebra view and information view is presented also. Some efficient heuristic reduction algorithms can be developed further using these results. (C) 2003 Wiley Periodicals, Inc.	Chongqing Univ Posts & Telecommun, Inst Comp Sci & Technol, Chongqing 400065, Peoples R China	Wang, G (reprint author), Chongqing Univ Posts & Telecommun, Inst Comp Sci & Technol, Chongqing 400065, Peoples R China.						BAZAN JG, 8 INT S ISMIS94, P346; Chang Li-Yun, 1999, Journal of Software, V10; GUNTSCH I, 1998, ARTIF INTELL, V106, P109; HU X, 1996, 12 INT C DAT ENG, P96; Miao Duo-Qian, 1999, Journal of Software, V10; Wang Guoyin, 2001, ROUGH SET THEORY KNO; Wang GY, 2001, P SOC PHOTO-OPT INS, V4384, P200, DOI 10.1117/12.421074; Wang GY, 2000, IEEE IND ELEC, P2536; WANG GY, 2000, 2 INT C ROUGH SETS C, P370	9	55	74	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0884-8173		INT J INTELL SYST	Int. J. Intell. Syst.	JUN	2003	18	6					679	688		10.1002/int.10109		10	Computer Science, Artificial Intelligence	Computer Science	681GB	WOS:000183027500005	
J	Padmanabhan, B; Tuzhilin, A				Padmanabhan, B; Tuzhilin, A			Unexpectedness as a measure of interestingness in knowledge discovery	DECISION SUPPORT SYSTEMS			English	Article						interestingness of patterns; unexpectedness; beliefs; belief-driven rule discovery		Organizations are taking advantage of "data-mining" techniques to leverage the vast amounts of data captured as they process routine transactions. Data mining is the process of discovering hidden structure or patterns in data. However, several of the pattern discovery methods in data-mining systems have the drawbacks that they discover too many obvious or irrelevant patterns and that they do not leverage to a full extent valuable prior domain knowledge that managers have, This research addresses these drawbacks by developing ways to generate interesting patterns by incorporating managers' prior knowledge in the process of searching for patterns in data. Specifically, we focus on providing methods that generate unexpected patterns with respect to managerial intuition by eliciting managers' beliefs about the domain and using these beliefs to seed the search for unexpected patterns in data. Our approach should lead to the development of decision-support systems that provide managers with more relevant patterns from data and aid in effective decision making. (C) 1999 Elsevier Science B.V. All rights reserved.	Univ Penn, Wharton Sch, Operat & Informat Management Dept, Philadelphia, PA 19104 USA; NYU, Stern Sch Business, Dept Informat Syst, New York, NY USA	Padmanabhan, B (reprint author), Univ Penn, Wharton Sch, Operat & Informat Management Dept, Philadelphia, PA 19104 USA.						ADOMAVICIUS G, 1997, P 3 INT C KNOWL DISC; Adriaans P, 1996, DATA MINING; Agrawal R., 1995, ADV KNOWLEDGE DISCOV; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Breiman L, 1984, CLASSIFICATION REGRE; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Liu B., 1997, P 3 INT C KNOWL DISC, P31; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Piatetsky-Shapiro G., 1994, P AAAI 94 WORKSH KNO, P25; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Reich RB, 1992, WORK NATIONS PREPARI; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; Suzuki E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; TUZHILIN A, 1996, IS9626 NYU LN STERN	17	55	60	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	DEC	1999	27	3					303	318		10.1016/S0167-9236(99)00053-6		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	267VC	WOS:000084379100006	
J	Liu, B; Hsu, W; Mun, LF; Lee, HY				Liu, B; Hsu, W; Mun, LF; Lee, HY			Finding interesting patterns using user expectations	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						knowledge discovery; interesting patterns; unexpectedness; post-analysis of patterns; pattern ranking	KNOWLEDGE DISCOVERY; DATABASES	One of the major problems in the field of knowledge discovery (or data mining) is the interestingness problem. Past research and applications have found that, in practice, it is all too easy to discover a huge number of patterns in a database. Most of these patterns are actually useless or uninteresting to the user. But due to the huge number of patterns, it is difficult for the user to comprehend them and to identify those interesting to him/her. To prevent the user from being overwhelmed by the large number of patterns, techniques are needed to rank them according to their interestingness. In this paper, we propose such a technique, called the user-expectation method. In this technique, the user is first asked to provide his/her expected patterns according to his/her past knowledge or intuitive feelings. Given these expectations, the system uses a fuzzy matching technique to match the discovered patterns against the user's expectations, and then rank the discovered patterns according to the matching results. A variety of rankings can be performed for different purposes, such as to confirm the user's knowledge and to identify unexpected patterns, which are by definition interesting. The proposed technique is general and interactive.	Natl Univ Singapore, Dept Informat Syst & Comp Sci, Singapore 119260, Singapore; Kent Ridge Digital Labs, Singapore 117685, Singapore	Liu, B (reprint author), Natl Univ Singapore, Dept Informat Syst & Comp Sci, Lower Kent Ridge Rd, Singapore 119260, Singapore.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Bezdek J.C., 1992, FUZZY MODELS PATTERN; BHANDARI I, 1993, P AAAI93 WORKSH KNOW; BUCHANAN BG, 1993, READINGS KNOWLEDGE A; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; Durkin J., 1994, EXPERT SYSTEMS DESIG; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Folger T.A., 1988, FUZZY SETS UNCERTAIN; Frawley W. J., 1991, Knowledge discovery in databases; Giarratano J.C., 1994, EXPERT SYSTEMS PRINC; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; HONG J, 1991, KNOWLEDGE DISCOVERY; Jamshidi M., 1993, FUZZY LOGIC CONTROL; Kamber M., 1996, P 2 INT C KNOWL DISC, P263; Kandel A., 1982, FUZZY TECHNIQUES PAT; Kandel A, 1991, FUZZY EXPERT SYSTEMS; KLEMETINEN M, 1994, P 1 INT C INF KNOWL; Klir G. J., 1995, FUZZY SETS FUZZY LOG; KLOSGEN W, 1992, INT J INTELL SYST, V7, P649, DOI 10.1002/int.4550070707; Kruse R., 1991, UNCERTAINTY VAGUENES; Li D., 1990, FUZZY PROLOG DATABAS; Liu B., 1997, P 3 INT C KNOWL DISC, P31; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; MAJOR JA, 1993, P AAAI 93 WORKSH KNO, P28; MATHEUS CJ, 1994, P AAAI94 WORKSH KNOW; MATHEUS CJ, 1993, IEEE T KNOWLEDGE DAT, V5; MIYAMOTO S, 1990, FUZZY SETS INFORMATI; PIATETSKYSHAPIR.G, 1994, AI MAGAZINE      FAL, P77; Piatetsky-Shapiro G., 1994, P AAAI 94 WORKSH KNO, P25; Quinlan J.R., 1992, C4 5 PROGRAM MACHINE; Russell S., 1995, ARTIFICIAL INTELLIGE; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Silberschatz A., 1995, P 1 INT C KNOWL DISC, P275; Sugeno M., 1985, IND APPL FUZZY CONTR; TUZHILIN A, 1997, P SIGMOD WORKSH RES, P71; UTHURUSAMY R, 1991, KNOWLEDGE DISCOVERY; Zimmermann H. J., 1987, FUZZY SETS DECISION; Zimmermann HJ, 1991, FUZZY SET THEORY ITS	38	55	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV-DEC	1999	11	6					817	832				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	287UD	WOS:000085524100001	
J	Han, J; Ma, KK				Han, Ju; Ma, Kai-Kuang			Rotation-invariant and scale-invariant Gabor features for texture image retrieval	IMAGE AND VISION COMPUTING			English	Article						content-based image retrieval; texture analysis; Gabor filter; rotation-invariant; scale-invariant; Brodatz; MPEG-7; metadata; data mining	SPATIAL-FREQUENCY; SEGMENTATION; FILTERS; CLASSIFICATION; CHANNELS; MODELS	Conventional Gabor representation and its extracted features often yield a fairly poor performance in retrieving the rotated and scaled versions of the texture image under query. To address this issue, existing methods exploit multiple stages of transformations for making rotation and/or scaling being invariant at the expense of high computational complexity and degraded retrieval performance. The latter is mainly due to the lost of image details after multiple transformations. In this paper, a rotation-invariant and a scale-invariant Gabor representations are proposed, where each representation only requires few summations on the conventional Gabor filter impulse responses. The optimum setting of the orientation parameter and scale parameter is experimentally determined over the Brodatz and MPEG-7 texture databases. Features are then extracted from these new representations for conducting rotation-invariant or scale-invariant texture image retrieval. Since the dimension of the new feature space is much reduced, this leads to a much smaller metadata storage space and faster on-line computation on the similarity measurement. Simulation results clearly show that our proposed invariant Gabor representations and their extracted invariant features significantly outperform the conventional Gabor representation approach for rotation-invariant and scale-invariant texture image retrieval. (C) 2007 Elsevier B.V. All rights reserved.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Ma, KK (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	ekkma@ntu.edu.sg	Ma, Kai-Kuang/A-5148-2011				BECK J, 1987, COMPUT VISION GRAPH, V37, P299, DOI 10.1016/S0734-189X(87)80006-3; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; Del Bimbo A., 1999, VISUAL INFORM RETRIE; DEWOUWER GV, 1999, IEEE T IMAGE PROCESS, V8, P592; FOGEL I, 1989, BIOL CYBERN, V61, P103; Gravano L., 1994, Proceedings of the Third International Conference on Parallel and Distributed Information Systems (Cat. No.94TH0668-4), DOI 10.1109/PDIS.1994.331726; Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; Kruizinga P, 1999, IEEE T IMAGE PROCESS, V8, P1395, DOI 10.1109/83.791965; Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794; LOURENS T, 1994, FUTURE GENER COMP SY, V10, P351, DOI 10.1016/0167-739X(94)90042-6; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; NYSTUEN JA, 1992, IEEE T GEOSCI REMOTE, V30, P502, DOI 10.1109/36.142928; Smith J R, 1994, P IEEE INT C IM PROC, V12, P407, DOI 10.1109/ICIP.1994.413817; TAN TN, 1995, PATTERN RECOGN, V28, P1283, DOI 10.1016/0031-3203(94)00017-G; TURNER MR, 1986, BIOL CYBERN, V55, P71; Weldon TP, 1996, OPT ENG, V35, P2852, DOI 10.1117/1.600971	23	54	61	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0262-8856		IMAGE VISION COMPUT	Image Vis. Comput.	SEP 1	2007	25	9					1474	1481		10.1016/j.imavis.2006.12.015		8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	190OH	WOS:000248068000008	
B	Giannotti, F; Nanni, M; Pedreschi, D; Pinelli, F		Berkhin, P; Caruana, R; Wu, X; Gaffney, S		Giannotti, Fosca; Nanni, Mirco; Pedreschi, Dino; Pinelli, Fabio			Trajectory Pattern Mining	KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING			English	Proceedings Paper	13th International Conference on Knowledge Discovery and Data Mining	AUG 12-15, 2007	San Jose, CA	ACM SIGKDD, ACM SIGMOD		Trajectory patterns; Spatio-temporal data mining		The increasing pervasiveness of location-acquisition technologies (GPS, GSM networks, etc.) is leading to the collection of large spatio-temporal datasets and to the opportunity of discovering usable knowledge about movement behaviour, which fosters novel applications and services. In this paper, we move towards this direction and develop an extension of the sequential pattern mining paradigm that analyzes the trajectories of moving objects. We introduce trajectory patterns as concise descriptions of frequent behaviours, in terms of both space (i.e., the regions of space visited during movements) and time (i.e., the duration of movements). in this setting, we provide a general formal statement of the novel mining problem and then study several different instantiations of different complexity. The various approaches are then empirically evaluated over real data and synthetic benchmarks, comparing their strengths and weaknesses.	[Giannotti, Fosca; Nanni, Mirco; Pinelli, Fabio] CNR, Area Ric Pisa, ISTI, I-56124 Pisa, Italy	Giannotti, F (reprint author), CNR, Area Ric Pisa, ISTI, Via Giuseppe Moruzzi 1, I-56124 Pisa, Italy.						Agrawal R., 1995, P ICDE; Ashok K., 1996, THESIS MIT; CAO H, 2005, ICDM; Giannotti F., 2006, P SIAM C DAT MIN, P346; GIANNOTTI F, 2006, T PATTERNS TEMPORALL; Giannotti F., 2005, GIS 05, P12; Kalnis P., 2005, P 9 INT S SPAT TEMP, P364; Mamoulis N, 2004, KDD; Pei J., 2001, ICDE, P215; VAUTIER A, 2000, P WORKSH MINING SPAT; YOSHIDA M, 2000, DATA MINING KNOWLEDG, V1; Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315	12	54	54	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA		978-1-59593-609-7				2007							330	339				10	Computer Science, Artificial Intelligence	Computer Science	BJK16	WOS:000266628300034	
J	Mikut, R; Jakel, J; Groll, L				Mikut, R; Jakel, J; Groll, L			Interpretability issues in data-based learning, of fuzzy systems	FUZZY SETS AND SYSTEMS			English	Article						classification; data mining; decision tree; linguistic fuzzy system; fuzzy rule; inductive learning; interpretability; machine learning	DECISION TREES; MODELS; SIMPLIFICATION; CONSTRUCTION; METHODOLOGY; INFORMATION; COMPLEXITY; INDUCTION; ALGORITHM	This paper presents a method for an automatic and complete design of fuzzy systems from data. The main objective is to build fuzzy systems with a user-controllable trade-off between accuracy and interpretability. Whereas criteria for accuracy mostly follow straightforwardly from the application, definition of interpretability and its criteria are subject to controversial discussion. For this reason, a set of interpretability criteria is given which guide the design process. Consequently, interpretability is maintained by structural choices regarding the type of membership functions, rules, and inference mechanism, on the one hand, and by including interpretability criteria in the rule/rule base evaluation, on the other hand. An application in Instrumented Gait Analysis, to characterize a certain group of patients in comparison to healthy subjects, illustrates the proposed algorithm. (C) 2004 Elsevier B.V. All rights reserved.	Forschungszentrum Karlsruhe, Inst Appl Comp Sci, D-76021 Karlsruhe, Germany	Mikut, R (reprint author), Forschungszentrum Karlsruhe, Inst Appl Comp Sci, POB 3640, D-76021 Karlsruhe, Germany.	ralf.mikut@iai.fzk.de; jens.jaekel@iai.fzk.de; lutz.groell@iai.fzk.de	Mikut, Ralf /A-5949-2013				ADLASSNIG KP, 1980, METHOD INFORM MED, V19, P141; Babuska R., 1998, FUZZY MODELING CONTR; BODENHOFER U, 2002, TRADE OFF ACCURANCY; BONARINI A, 1994, P 1 IEEE C EV COMP, V1, P51; Bonissone P. P., 1986, UNCERTAINTY ARTIFICI, P217; Boyen X, 1999, FUZZY SET SYST, V102, P3, DOI 10.1016/S0165-0114(98)00198-5; Breiman L, 1984, CLASSIFICATION REGRE; BUCKLEY JJ, 1994, FUZZY SET SYST, V66, P1, DOI 10.1016/0165-0114(94)90297-6; CASILLAS J, 2002, TRADE OFF ACCURANCY; Chen MY, 2004, FUZZY SET SYST, V142, P243, DOI 10.1016/S0165-0114(03)00160-X; Cios K., 1998, DATA MINING METHODS; Cordon O, 2003, FUZZY SET SYST, V138, P307, DOI 10.1016/S0165-0114(02)00388-3; Cordon O., 1997, FUZZY MODEL IDENTIFI, P215; Cordon O, 2000, IEEE T FUZZY SYST, V8, P335, DOI 10.1109/91.855921; Delgado M, 1998, FUZZY SET SYST, V97, P287, DOI 10.1016/S0165-0114(96)00351-X; de Oliveira JV, 1999, IEEE T SYST MAN CY A, V29, P128, DOI 10.1109/3468.736369; Drobics M, 2003, INT J APPROX REASON, V32, P131, DOI 10.1016/S0888-613X(02)00080-4; ESHRAGH F, 1979, INT J MAN MACH STUD, V11, P501, DOI 10.1016/S0020-7373(79)80040-1; Espinosa J, 2000, IEEE T FUZZY SYST, V8, P591; Hong TP, 1997, IEEE T KNOWL DATA EN, V9, P336; Hoppner F., 1999, FUZZY CLUSTER ANAL; ICHIBUCHI H, 1993, FUZZY SETS SYSTEMS, V59, P295; Jakel J, 2000, FRONT ARTIF INTEL AP, V57, P1; JAKEL J, 2001, P 9 ZITT FUZZ C 17 1, P230; JAKEL J, 1999, P 7 EUR C INT TECHN, P279; JANG JSR, 1995, P IEEE, V83, P378, DOI 10.1109/5.364486; Jin Y, 1998, P IEEE INT C FUZZ SY, P1188; Jin YC, 2000, IEEE T FUZZY SYST, V8, P212, DOI 10.1109/91.842154; KLAWONN F, 1995, P FUZZ NEUR SYST 95, P223; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KRONE A, 1997, INT J KNOWLEDGE BASE, V1, P207; Krone A, 2001, FUZZY SET SYST, V123, P343, DOI 10.1016/S0165-0114(00)00112-3; LOOSE T, 2002, GAIT POSTURE S1, V16, P176; LOOSE T, 2002, FZKA, V6767, P43; LOOSE T, 2002, P 2 EUR MED BIOL ENG, P798; Marsala C, 2003, IEEE INT CONF FUZZY, P584; MIKUT R, 2000, FUZZY CONTROL THEORY, P177; MIKUT R, 2002, P 10 ZITT FUZZ C HOC, P300; MIKUT R, 2000, P 8 FUZZ C ZITT, P103; Miller G. A., 1955, INFORMATION THEORY P, P95; MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037//0033-295X.101.2.343; Perry J., 1992, GAIT ANAL NORMAL PAT; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Renooij S, 1999, INT J APPROX REASON, V22, P169, DOI 10.1016/S0888-613X(99)00027-4; RIVES J, 1990, P 1 INT S UNC MOD AN, P457; Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575; Setnes M, 1998, IEEE T SYST MAN CY B, V28, P376, DOI 10.1109/3477.678632; Sugeno M., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390281; Wang CH, 1999, FUZZY SET SYST, V103, P91; Yager RR, 1998, IEEE T SYST MAN CY C, V28, P55, DOI 10.1109/5326.661090; Yen J, 1999, IEEE T SYST MAN CY B, V29, P13, DOI 10.1109/3477.740162; YOSHINARI Y, 1993, FUZZY SET SYST, V54, P157, DOI 10.1016/0165-0114(93)90273-K; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z; ZADEH LA, 2000, COMPUTING WORDS INFO, V2; ZADEH LA, 1999, IEEE T CIRCUITS SYST, V45, P105; ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4; ZADEH LA, 2000, COMPUTING WORDS INFO, V1	58	54	55	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	MAR 1	2005	150	2					179	197		10.1016/j.fss.2004.06.006		19	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	889MQ	WOS:000226447500001	
J	Kim, Y; Street, WN				Kim, Y; Street, WN			An intelligent system for customer targeting: a data mining approach	DECISION SUPPORT SYSTEMS			English	Article						customer targeting; data mining; feature selection; genetic algorithms; neural networks; ensemble	MARKET-SEGMENTATION; LEARNING ALGORITHMS; K-MEANS; PERFORMANCE; SELECTION	We propose a data mining approach for market managers that uses artificial neural networks (ANNs) guided by genetic algorithms (GAs). Our predictive model allows the selection of an optimal target point where expected profit from direct mailing is maximized. Our approach also produces models that are easier to interpret by using a smaller number of predictive features. Through sensitivity analysis, we also show that our chosen model significantly outperforms the baseline algorithms in terms of hit rate and expected net profit on key target points. (C) 2003 Elsevier B.V. All rights reserved.	Utah State Univ, Business Informat Syst, Logan, UT 84322 USA; Univ Iowa, Iowa City, IA 52242 USA	Kim, Y (reprint author), Utah State Univ, Business Informat Syst, Logan, UT 84322 USA.	ykim@b202.usu.edu; nick-street@uiowa.edu	Kim, Yong Seog/B-9421-2013				Balakrishnan PV, 1996, EUR J OPER RES, V93, P346, DOI 10.1016/0377-2217(96)00046-X; BANSLABEN J, 1992, DIRECT MARKETING HDB, P626; Bhattacharyya S., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347186; Bhattacharyya S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Bitran GR, 1996, MANAGE SCI, V42, P1364, DOI 10.1287/mnsc.42.9.1364; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Bult JR, 1995, MARKET SCI, V14, P378, DOI 10.1287/mksc.14.4.378; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chen S, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P129; Chou P. B., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347183; COETZEE F, 2001, S APPL INT SAINT SAN, P5; Domingos P, 2001, P 7 ACM SIGKDD INT C, P57, DOI 10.1145/502512.502525; FAWCETT T., 1996, P 2 INT C KNOWL DISC, P8; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Gersten W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347174; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Gonul F, 1998, MANAGE SCI, V44, P1249, DOI 10.1287/mnsc.44.9.1249; Green P. E, 1988, RES MARKETING DECISI; Hruschka H, 1999, EUR J OPER RES, V114, P346, DOI 10.1016/S0377-2217(98)00170-2; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; KAMAKURA WA, 1998, 9812009 U IOW DEP MA; KAMAKURA WA, 2000, CROSSSELLING FINANCI; AHALT SC, 1990, NEURAL NETWORKS, V3, P277, DOI 10.1016/0893-6080(90)90071-R; KIM Y, 2000, 200009 LEID U LEID I; KIM Y, IN PRESS CUSTOMER TA; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Mahfoud S. W., 1995, THESIS U ILLINOIS UR; PIATETSKYSHAPIR.G, 1999, P 5 ACM SIGKDD INT C, P185, DOI 10.1145/312129.312225; PIERSMA N, 2000, EI200034A ER U ROTT; Provost F., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Quinlan J.R., 1995, P 14 INT JOINT C ART, P1019; RAGHAVAN N, 2000, P 6 INT C KNOWL DISC, P447; RIEDMILLER M, 1994, COMP STAND INTER, V16, P265, DOI 10.1016/0920-5489(94)90017-5; Rosset S., 2001, P 7 ACM SIGKDD INT C, P456, DOI 10.1145/502512.502581; Rossi PE, 1996, MARKET SCI, V15, P321, DOI 10.1287/mksc.15.4.321; SALZBERG S., 1995, P 14 INT JOINT C ART, P1025; SCHMID J, 1998, DESKTOP DATABASE MAR; Shaw MJ, 2001, DECIS SUPPORT SYST, V31, P127, DOI 10.1016/S0167-9236(00)00123-8; Srivastava R.K., 1991, INT J RES MARK, V8, P329, DOI 10.1016/0167-8116(91)90030-B; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540	43	54	55	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	MAY	2004	37	2					215	228		10.1016/S0167-9236(03)00008-3		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	823SV	WOS:000221634400003	
J	Gunopulos, D; Khardon, R; Mannila, H; Saluja, S; Toivonen, H; Sharma, RS				Gunopulos, D; Khardon, R; Mannila, H; Saluja, S; Toivonen, H; Sharma, RS			Discovering all most specific sentences	ACM TRANSACTIONS ON DATABASE SYSTEMS			English	Article						algorithms; theory; data mining; association rules; maximal frequent sets; learning with membership queries; minimal keys	COMPLEXITY; DUALIZATION; SEARCH	Data mining can be viewed, in many instances, as the task of computing a representation of a theory of a model or a database, in particular by finding a set of maximally specific sentences satisfying some property. We prove some hardness results that rule out simple approaches to solving the problem. The a priori algorithm is an algorithm that has been successfully applied to many instances of the problem. We analyze this algorithm, and prove that is optimal when the maximally specific sentences are "small". We also point out its limitations. We then present a new algorithm, the Dualize and Advance algorithm, and prove worst-case complexity bounds that are favorable in the general case. Our results use the concept of hypergraph transversals. Our analysis shows that the a priori algorithm can solve the problem of enumerating the transversals of a hypergraph, improving on previously known results in a special case. On the other hand, using results for the general case of the hypergraph transversal enumeration problem, we can show that the Dualize and Advance algorithm has worst-case running time that is subexponential to the output size (i.e., the number of maximally specific sentences). We further show that the problem of finding maximally specific sentences is closely related to the problem of exact learning with membership queries studied in computational learning theory.	Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92507 USA; Tufts Univ, Dept EECS, Medford, MA 02155 USA; Univ Helsinki, Dept Comp Sci, HIIT Basic Res Unit, SF-00510 Helsinki, Finland; LSI Log, Milpitas, CA 95035 USA	Gunopulos, D (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92507 USA.	dg@cs.ucr.edu; roni@eecs.tufts.edu; Heikki.Mannila@cs.helsinki.fi; sanjeev@lsil.com; Hannu.Toivonen@ca.helsinki.fi; rssharma@cs.ucr.edu	Toivonen, Hannu/A-3657-2012	Toivonen, Hannu/0000-0003-1339-8022			AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; AGRAWAL RC, 2000, KNOWLEDGE DISCOVERY, P108; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; Bayardo R. J., 1998, P ACM SIGMOD INT C M; BELL S, 2003, UNPUB DECIDING DISTI; BELL S, 1995, LS814 U DORTM FACHB; BERGE C, 1973, HYPERRAPHS COMBINATO; BIOCH JC, 1995, INFORM COMPUT, V123, P50, DOI 10.1006/inco.1995.1157; BSHOUTY NH, 1996, P ACM S THEOR COMP S; Bshouty NH, 1996, J COMPUT SYST SCI, V52, P421, DOI 10.1006/jcss.1996.0032; BURDICK D, 2001, P INT C DAT ENG; EITER T, 1995, SIAM J COMPUT, V24, P1278, DOI 10.1137/S0097539793250299; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Fredman ML, 1996, J ALGORITHM, V21, P618, DOI 10.1006/jagm.1996.0062; Garey M. R., 1979, COMPUTERS INTRACTABI; Gouda K., 2001, ICDM, P163; GUNOPULOS D, 1997, P 16 ACM SIGACT SIGM; GUNOPULOS D, 1997, P INT C DAT THEOR IC; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Kavvadias DJ, 1999, LECT NOTES COMPUT SC, V1668, P72; Khardon R, 1995, J ARTIF INTELL RES, V3, P349; KNOBBE AJ, 1995, WORKSHOP NOTES ECML, P94; Langley P., 1995, ELEMENTS MACHINE LEA; LIN DI, 1998, EXTENDING DATABASE T, P105; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Mannila H., 1996, Proceedings. Eighth International Conference on Scientific and Statistical Database Management (Cat. No.96TB100051), DOI 10.1109/SSDM.1996.505910; MANNILA H, 1986, J COMPUT SYST SCI, V33, P126, DOI 10.1016/0022-0000(86)90015-2; MANNILA H, 1995, WORKSHOP NOTES ECML, P1; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Mannila H., 1992, DESIGN RELATIONAL DA; MANNILA H, 1994, DATA KNOWL ENG, V12, P83, DOI 10.1016/0169-023X(94)90023-X; Mishra N., 1997, Proceedings of the Tenth Annual Conference on Computational Learning Theory, DOI 10.1145/267460.267500; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; RYMON R, 1992, P INT C PRINC KNOWL; SCHLIMMER J, 1993, KNOWLEDGE DISCOVERY, P186; Ullman J. D., 1988, PRINCIPLES DATABASE, VI; VALIANT LG, 1979, SIAM J COMPUT, V8, P410, DOI 10.1137/0208032; Zheng Z., 2001, P 7 ACM SIGKDD INT C	41	54	55	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0362-5915		ACM T DATABASE SYST	ACM Trans. Database Syst.	JUN	2003	28	2					140	174		10.1145/777943.777945		35	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	686ER	WOS:000183308900002	
J	Haux, R; Ammenwerth, E; Herzog, W; Knaup, P				Haux, R; Ammenwerth, E; Herzog, W; Knaup, P			Health care in the information society. A prognosis for the year 2013	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						medical informatics; health care; information society	MEDICAL INFORMATICS; CHALLENGES; IMIA	Our society is increasingly influenced by modern information and communication technology (ICT). Health care has profited greatly by this development. Hove could health care provision look in the near future, in 10 years, or more precisely, in the year 2013? What measures must be undertaken by political and self-governing health institutions, and by medical informatics research, to ensure an efficient, medically advanced and yet affordable future health care system? Three factors will greatly influence the further development of information processing in health care within the near future: the development of the population. medical advances, and advances in informatics. These factors have motivated us to set up 30 theses for health care provision in the year 2013. The theses cover areas of health care, such as its people. its information systems, and its ICT tools. Three major goals requiring achievement have been identified: patient-centered recording and use of medical data for cooperative care, process-integrated decision support through current medical knowledge, comprehensive use of patient data for research and health care reporting. In consequence, political institutions should provide a framework for networked, patient-centered health care. They are called on to regulate the storage and exchange of health care data and of appropriate information system architectures. Finally, the health care institutions themselves must emphasize professional information management more strongly. Relevant research topics in medical informatics are: comprehensive electronic patient records, modern health information system architectures, architectures for medical knowledge centers, specific data processing methods ('medical data mining'), and multi-functional, mobile ICT tools, (C) 2002 Elsevier Science lreland Ltd. All rights reserved.	Univ Hlth Informat & Technol Tyrol, Inst Hlth Informat Syst, A-6020 Innsbruck, Austria; Univ Hlth Informat & Technol Tyrol, Res Grp Assessment Hlth Informat Syst, A-6020 Innsbruck, Austria; Univ Heidelberg, Univ Hosp Internal Med, D-69115 Heidelberg, Germany; Univ Heidelberg, Dept Med Informat, D-69120 Heidelberg, Germany	Haux, R (reprint author), Univ Hlth Informat & Technol Tyrol, Inst Hlth Informat Syst, Innrain 98, A-6020 Innsbruck, Austria.	reinhold.haux@umit.at	Ammenwerth, Elske/F-5430-2010				Ammenwerth E, 2001, METHOD INFORM MED, V40, P163; Ball MJ, 2001, INT J MED INFORM, V61, P1, DOI 10.1016/S1386-5056(00)00130-1; BALL MJ, 2000, INT EFFORTS INFO MAY, P50; CLADE H, 2000, DTSCH ARZTEBLATT, V97, pA1728; Fessler JM, 2001, METHOD INFORM MED, V40, P359; Greenes RA, 1998, J AM MED INFORM ASSN, V5, P395; HAUX R, UNPUB STRATEGIC INFO; HAUX R, 2001, YB MED INFORMATICS 2; Haux R, 1997, INT J MED INFORM, V44, P9, DOI 10.1016/S1386-5056(97)01254-9; Haux R, 2001, METHOD INFORM MED, V40, P156; HAUX R, 2002, IN PRESS BIOMETRIE E; Hohne KH, 2001, METHOD INFORM MED, V40, P83; Iakovidis I, 2000, ST HEAL T, V76, P23; Haux R, 2000, METHOD INFORM MED, V39, P267; Jaspers K., 1913, ALLGEMEINE PSYCHOPAT; Kuhn KA, 2001, METHOD INFORM MED, V40, P275; Kulikowski CA, 2002, METHOD INFORM MED, V41, P20; Reinhard O, 1998, ST HEAL T, V52, P89; Stead WW, 1999, J AM MED INFORM ASSN, V6, P341; vanBemmel JH, 1996, METHOD INFORM MED, V35, P157; VANBEMMEL J, 1997, YB MED INFORMATICS 1; VANBEMMEL J, 1996, YB MED INFORMATIONS; VANBEMMEL J, 1998, YB MED INFORMATICS 1; VANBEMMEL JH, 2000, YB MED INFORMATICS 2; VANBEMMEL JH, 1995, YB MED INFORMATICS 1; *EITO, 2000, EUR INF TECHN OBS MI; *GERM FED MIN EC T, 1996, INF 2000 DEUTSCHL WE; *GERM FED MIN EC T, 1999, INN JOBS INF SOC 21; *NAT LIB MED, 1998, GLOB VIS NAT LIB MED; *STAT BUND, 1999, STAT JB 1999; *STAT BUND, 1997, GES DEUTSCHL; 1999, DTSCH ARZTEBLATT, V96	32	54	54	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056		INT J MED INFORM	Int. J. Med. Inform.	NOV 20	2002	66	1-3					3	21		10.1016/S1386-5056(02)00030-8		19	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	631GA	WOS:000180158700002	
J	Mitra, P; Murthy, CA; Pal, SK				Mitra, P; Murthy, CA; Pal, SK			Density-based multiscale data condensation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data mining; multiscale condensation; scalability; density estimation; convergence in probability; instance learning	CLASSIFICATION; ALGORITHM; REDUCTION; IMAGES	A problem gaining interest in pattern recognition applied to data mining is that of selecting a small representative subset from a very large data set. In this article, a nonparametric data reduction scheme is suggested. It attempts to represent the density underlying the data. The algorithm selects representative points in a multiscale fashion which is novel from existing density-based approaches, The accuracy of representation by the condensed set is measured in terms of the error in density estimates of the original and reduced sets. Experimental studies on several real life data sets show that the multiscale approach is superior to several related condensation methods both in terms of condensation ratio and estimation error. The condensed set obtained was also experimentally shown to be effective for some important data mining tasks like classification, clustering, and rule generation on large data sets. Moreover, it is empirically found that the algorithm is efficient in terms of sample complexity.	Indian Stat Inst, Machine Intelligence Unit, Calcutta 700035, W Bengal, India	Mitra, P (reprint author), Indian Stat Inst, Machine Intelligence Unit, Calcutta 700035, W Bengal, India.						Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Aspin A., 1949, BIOMETRIKA, V36, P245; Astrahan M.M., 1970, SPEECH ANAL CLUSTERI; Breiman L, 1984, CLASSIFICATION REGRE; Catlett J., 1991, THESIS U SYDNEY AUST; Chakravarthy SV, 1996, IEEE T NEURAL NETWOR, V7, P1250, DOI 10.1109/72.536318; CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DENG K, 1995, P INT JOINT C ART IN; ESTER JSM, 1996, P 2 INT C KNOWL DISC, P226; FARAGO A, 1991, PROBL CONTROL INFORM, V20, P383; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; Fukunaga K., 1972, INTRO STAT PATTERN R; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; Gray R. M., 1984, IEEE ASSP Magazine, V1, DOI 10.1109/MASSP.1984.1162229; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Lehmann E.L., 1976, TESTING STAT HYPOTHE; Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396; Lewis David D., 1994, MACH LEARN P 11 INT, P148; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MOORE AW, 1997, MACH LEARN P 14 INT, P236; Pal SK, 2000, INT J REMOTE SENS, V21, P2269, DOI 10.1080/01431160050029567; Pal S.R., 1999, NEURO FUZZY PATTERN; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; PLUTOWSKI M, 1993, IEEE T NEURAL NETWOR, V4, P305, DOI 10.1109/72.207618; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Roy N., 2001, P 18 INT C MACH LEAR; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WONG YF, 1993, IEEE T GEOSCI REMOTE, V31, P634, DOI 10.1109/36.225530; XU L, 1993, IEEE T NEURAL NETWOR, V4, P636, DOI 10.1109/72.238318	34	54	63	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					734	747		10.1109/TPAMI.2002.1008381		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	556JU	WOS:000175846300003	
J	Blockeel, H; Dehaspe, L; Demoen, B; Janssens, G; Ramon, J; Vandecasteele, H				Blockeel, H; Dehaspe, L; Demoen, B; Janssens, G; Ramon, J; Vandecasteele, H			Improving the efficiency of inductive logic programming through the use of query packs	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							DISCOVERY	Inductive logic programming, or relational learning, is a powerful paradigm for machine learning or data mining. However, in order for ILP to become practically useful, the efficiency of ILP systems must improve substantially. To this end, the notion of a query pack is introduced: it structures sets of similar queries. Furthermore, a mechanism is described for executing such query packs. A complexity analysis shows that considerable efficiency improvements can be achieved through the use of this query pack execution mechanism. This claim is supported by empirical results obtained by incorporating support for query pack execution in two existing learning systems.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium; PharmaDM, B-3001 Louvain, Belgium	Blockeel, H (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Louvain, Belgium.		Ramon, Jan/E-8956-2010	Ramon, Jan/0000-0002-0558-7176			Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; AIT-KACI H., 1991, WARRENS ABSTRACT MAC; Blockeel H., 1997, LECT NOTES ARTIF INT, V1297, P77; Blockeel H, 1998, P 15 INT C MACH LEAR, P55; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; Blockeel H, 1999, DATA MIN KNOWL DISC, V3, P59, DOI 10.1023/A:1009867806624; BLOCKEEL H, 2000, 10 INT C IND LOG PRO, P43; Blockeel Hendrik, 1998, THESIS KATHOLIEKE U; Bongard M.M., 1970, PATTERN RECOGNITION; BRATKO I, 1990, PROLOG PROGRAMMING A; Breiman L, 1984, CLASSIFICATION REGRE; Chen WD, 1996, J ACM, V43, P20, DOI 10.1145/227595.227597; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; COSTA VS, 2000, LECT NOTES ARTIF INT, V1866, P225; Dehaspe L, 1999, DATA MIN KNOWL DISC, V3, P7, DOI 10.1023/A:1009863704807; DEKEYSER S, 2001, 0104 U ANTW; DEMOEN B, 1999, P 11 BEN WORKSH LOG, P1; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; DERAEDT L, 1995, LECT NOTES ARTIF INT, V997, P80; DeRaedt L, 1997, ARTIF INTELL, V95, P187, DOI 10.1016/S0004-3702(97)00041-6; Kramer S, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P812; Mehta M., 1996, P 5 INT C EXT DAT TE; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; QUINLAN J, 1993, LECT NOTES ARTIFICIA; Quinlan J. R., 1993, M KAUFMANN SERIES MA; SEBAG M, 1997, P 15 INT JOINT C ART; SELLIS TK, 1988, ACM T DATABASE SYST, V13, P23, DOI 10.1145/42201.42203; Srinivasan A, 2000, PRGTR1600 OXF U COMP; SRINIVASAN A, 1995, P 5 INT WORKSH IND L; Srinivasan A, 1999, DATA MIN KNOWL DISC, V3, P95, DOI 10.1023/A:1009824123462; TSUR D, 1998, ACM SIGMOD RECORD, V27, P1, DOI 10.1145/276305.276306	33	54	54	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757		J ARTIF INTELL RES	J. Artif. Intell. Res.		2002	16						135	166				32	Computer Science, Artificial Intelligence	Computer Science	527GW	WOS:000174179200001	
J	Thelwall, M				Thelwall, M			A web crawler design for data mining	JOURNAL OF INFORMATION SCIENCE			English	Article							IMPACT FACTORS; SEARCH ENGINE; SITE	The content of the web has increasingly become a focus for academic research. Computer programs are needed in order to conduct any large-scale processing of web pages, requiring the use of a web crawler at some stage in order to fetch the pages to be analysed. The processing of the text of web pages in order to extract information can be expensive in terms of processor time. Consequently a distributed design is proposed in order to effectively use idle computing resources and to help information scientists avoid the need to employ dedicated equipment. A system developed using the model is examined and the advantages and limitations of the approach are discussed.	Wolverhampton Univ, Sch Comp & Informat Technol, Wolverhampton WV1 1SB, England	Thelwall, M (reprint author), Wolverhampton Univ, Sch Comp & Informat Technol, Wulfruna St, Wolverhampton WV1 1SB, England.		Thelwall, Mike/C-1449-2013	Thelwall, Mike/0000-0001-6065-205X			AJCKSON MS, 1999, IEE INF C LOST WEB N; Bar-Ilan J, 2001, SCIENTOMETRICS, V50, P7, DOI 10.1023/A:1005682102768; Bar-Ilan J, 2000, J AM SOC INFORM SCI, V51, P432, DOI 10.1002/(SICI)1097-4571(2000)51:5<432::AID-ASI4>3.0.CO;2-7; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Broder A, 2000, COMPUT NETW, V33, P309, DOI 10.1016/S1389-1286(00)00083-9; CHEN C, 1997, P 8 ACM C HYP HYP 97; Chen CM, 1998, INTERACT COMPUT, V10, P353, DOI 10.1016/S0953-5438(97)00034-9; CHOO J, 2000, P 26 VLDB C CAIR EG, P200; Chun TY, 1999, ONLINE CDROM REV, V23, P135, DOI 10.1108/14684529910334047; Ferris MC, 2000, ACM T MATH SOFTWARE, V26, P1, DOI 10.1145/347837.347842; GIBSON D, 1998, HYP 98 9 ACM C HYP H; Haas SW, 2000, J AM SOC INFORM SCI, V51, P181, DOI 10.1002/(SICI)1097-4571(2000)51:2<181::AID-ASI9>3.3.CO;2-#; Heydon A., 1999, World Wide Web, V2, DOI 10.1023/A:1019213109274; Ingwersen P, 1998, J DOC, V54, P236, DOI 10.1108/EUM0000000007167; KELLY B, 2000, ARIADNE, V23; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; LUBANSKY A, 1998, IRISS 98 INT C BRIT; Middleton I, 1999, J INFORM SCI, V25, P219, DOI 10.1177/016555159902500306; MILLER H, 1998, IRISS 98 INT C BRIT; Miller RC, 1998, COMPUT NETWORKS ISDN, V30, P119, DOI 10.1016/S0169-7552(98)00064-6; Monrose F., 1999, Proceedings 1999 Network and Distributed System Security Symposium; Overmeer MACJ, 1999, COMPUT NETW, V31, P2271, DOI 10.1016/S1389-1286(99)00103-6; Smith AG, 1999, J DOC, V55, P577; Snyder H, 1999, J DOC, V55, P375, DOI 10.1108/EUM0000000007151; Sundaresan N, 2000, COMPUT NETW, V33, P699, DOI 10.1016/S1389-1286(00)00085-2; THEIMER MM, 1989, IEEE T SOFTWARE ENG, V15, P1444, DOI 10.1109/32.41336; Thelwall M, 2001, J DOC, V57, P177, DOI 10.1108/EUM0000000007081; Thelwall M, 2000, J DOC, V56, P185, DOI 10.1108/00220410010803801; THELWALL M, 2002, IN PRESS J AM SOC IN	29	54	55	BOWKER-SAUR	E GRINSTEAD	WINDSOR COURT, EAST GRINSTEAD HOUSE, E GRINSTEAD RH19 1XA, W SUSSEX, ENGLAND	0165-5515		J INFORM SCI	J. Inf. Sci.		2001	27	5					319	325		10.1177/0165551014233743		7	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	499QH	WOS:000172581500004	
J	Thomas, JC; Kellogg, WA; Erickson, T				Thomas, JC; Kellogg, WA; Erickson, T			The knowledge management puzzle: Human and social factors in knowledge management	IBM SYSTEMS JOURNAL			English	Article								Knowledge management is often seen as a problem of capturing, organizing, and retrieving information, evoking notions of data mining, text clustering, databases, and documents. We believe that this view is too simple. Knowledge is inextricably bound up with human cognition, and the management of knowledge occurs within an intricately structured social context. We argue that it is essential for those designing knowledge management systems to consider the human and social factors at play in the production and use of knowledge. We review work-ranging from basic research to applied techniques-that emphasizes cognitive and social factors in knowledge management. We then describe two approaches to designing socially informed knowledge management systems, social computing and knowledge socialization.	IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Thomas, JC (reprint author), IBM Corp, Div Res, Thomas J Watson Res Ctr, POB 704, Yorktown Hts, NY 10598 USA.		Wang, Charles/B-5565-2011				Arias E., 2000, ACM Transactions on Computer-Human Interaction, V7, DOI 10.1145/344949.345015; Aristotle, 1997, POETICS; ARMSTRONG D, 1992, MANAGING STORYING AR; Bakhtin Mikhail, 1981, DIALOGIC IMAGINATION; BAL M, 1992, NARRATOLOGY INTRO TH; Beyer H, 1998, CONTEXTUAL DESIGN; Bohm D., 1990, DIALOGUE; BOJE DM, 1991, ADMIN SCI QUART, V36, P106, DOI 10.2307/2393432; Bradner E., 1999, P 6 EUR C COMP SUPP, P139; Brannigan Edward, 1992, NARRATIVE COMPREHENS; BROWN JS, 1995, SOCIAL LIFE DOCUMENT, P1; BROWN JS, 2000, SOCIAL LIFE INFORMAT; CAPRA F, 1997, WEB LIFE NEW UNDERST; CHURCHILL EF, 1999, P INT JOINT C WORK A; Clark H.H., 1996, USING LANGUAGE; COHEN D., 2001, GOOD CO SOCIAL CAPIT; Collins J.C., 1997, BUILT LAST SUCCESSFU; DARLEY JM, 1968, J PERS SOC PSYCHOL, V8, P377, DOI 10.1037/h0025589; de Geus A., 1997, LIVING CO; De Marco T., 1987, PEOPLEWARE PRODUCTIV; Dewey J., 1933, WE THINK RESTATEMENT; DUNDES A, 1963, STUDY FOLKLORE; Earnshaw R.A., 2001, FRONTIERS HUMAN CENT; ERICKSON T, IN PRESS KNOWLEDGE M; ERICKSON T, 1996, INTERACTIONS; Erickson T., 2000, ACM Transactions on Computer-Human Interaction, V7, DOI 10.1145/344949.345004; ERICKSON T, 1995, SCENARIO BASED DESIG; ERICKSON T, 2001, P CHI 2001; Erickson T., 1999, P CHI 99 C HUM FACT, P72, DOI 10.1145/302979.302997; Erickson T., 2000, P 33 HAW INT C SYST; EVANS TG, 1968, SEMANTIC INFORMATION; FORD S, 1997, P C HUM FACT COMP SY; Gardner Howard, 1996, LEADING MINDS ANATOM; Gaver W. W., 1993, P INTERCHI 93, P228, DOI 10.1145/169059.169184; Goffman E., 1963, BEHAV PUBLIC PLACES; Goffman Erving, 1967, INTERACTION RITUAL; GORDON AS, 2001, 5 S LOG FORM COMM RE; GORDON AS, IN PRESS TEXTUAL DIS; Gordon W. J. J., 1961, SYNECTICS; GUILFORD JP, 1963, SCI CREATIVITY ITS R; HARRIS JA, 1999, P CHI 99 C HUM FACT, P88, DOI 10.1145/302979.303003; Hillier B, 1996, SPACE IS MACHINE; HUXOR A, 1998, P CVE 98; Isaacs W., 1999, DIALOGUE ART THINKIN; Kendon A., 1990, CONDUCTING INTERACTI; Labov W., 1967, ESSAYS VERBAL VISUAL, P12; Lakoff George, 1983, METAPHORS WE LIVE BY; Lave J, 1991, SITUATED LEARNING; LAWRENCE D, 1999, AAAI WORKSH NARR INT; MATTIMORE B, 1993, 99 PERCENT INSPIRATI; McKee R, 1997, STORY; MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037//0033-295X.101.2.343; MUNRO A, 1999, SOCIAL NAVIGATION IN; Nanetti R., 1993, MAKING DEMOCRACY WOR; Nonaka K., 1995, KNOWLEDGE CREATING C; Norrick NR, 1997, LANG SOC, V26, P199; OCHS E, 1992, DISCOURSE PROCESS, V15, P32; OLSON G, 2000, HUMAN COMPUTER INTER, V15, P107; Orlikowski W., 1992, P C COMP SUPP COOP W, P362, DOI 10.1145/143457.143549; Orr Julian E., 1996, TALKING MACHINES ETH; Piaget J., 1969, PSYCHOL CHILD; Polti G., 1916, 36 DRAMATIC SITUATIO; Schank R., 1997, VIRTUAL LEARNING REV; Schank R. C., 1990, TELL ME STORY NARRAT; Shneiderman B., 2000, ACM Transactions on Computer-Human Interaction, V7, DOI 10.1145/344949.345077; SNOWDEN D, 2000, J SCENARIO STRATEGY, V1; Snowden D.J., 1999, BUSINESS INFORMATION, V16, P30, DOI 10.1177/0266382994237045; STERNBERG R, 1986, ADV STUDY HUMAN INTE; Sternberg R. J., 1995, DEFYING CROWD CULTIV; Stuart R., 1996, DESIGN VIRTUAL ENV; CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006; THOMAS JC, 1978, INT J MAN MACH STUD, V10, P651, DOI 10.1016/S0020-7373(78)80026-1; THOMAS JC, 1983, OFFICE SYSTEMS RES J, V1, P75; THOMAS JC, 1977, RC6468 IBM TJ WATS R; THOMAS JC, 1999, KNOWLEDGE MANAGEMENT, V2, P14; UNDERWOOD P, 1999, 3 STRANDS BRAID GUID; Vygotsky L. S., 1962, THOUGHT LANGUAGE; Wenger E., 1998, COMMUNITIES PRACTICE; Wheatley M., 1993, LEADERSHIP NEW SCI	79	54	54	IBM CORP	ARMONK	OLD ORCHARD RD, ARMONK, NY 10504 USA	0018-8670		IBM SYST J	IBM Syst. J.		2001	40	4					863	884				22	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	489WY	WOS:000172016500005	
J	Bell, DA; Wang, H				Bell, DA; Wang, H			A formalism for relevance and its application in feature subset selection	MACHINE LEARNING			English	Article						machine learning; knowledge discovery; data mining; relevance; feature subset selection	ALGORITHMS; PRINCIPLE	The notion of relevance is used in many technical fields. In the areas of machine learning and data mining, for example, relevance is frequently used as a measure in feature subset selection (FSS). In previous studies, the interpretation of relevance has varied and its connection to FSS has been loose. In this paper a rigorous mathematical formalism is proposed for relevance, which is quantitative and normalized. To apply the formalism in FSS, a characterization is proposed for FSS: preservation of learning information and minimization of joint entropy. Based on the characterization, a tight connection between relevance and FSS is established: maximizing the relevance of features to the decision attribute, and the relevance of the decision attribute to the features. This connection is then used to design an algorithm for FSS. The algorithm is linear in the number of instances and quadratic in the number of features. The algorithm is evaluated using 23 public datasets, resulting in an improvement in prediction accuracy on 16 datasets, and a loss in accuracy on only 1 dataset. This provides evidence that both the formalism and its connection to FSS are sound.	Univ Ulster, Fac Informat, Sch Informat & Software Engn, Newtownabbey BT37 0QB, North Ireland	Bell, DA (reprint author), Univ Ulster, Fac Informat, Sch Informat & Software Engn, Shore Rd, Newtownabbey BT37 0QB, North Ireland.						ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; AMIRIKIAN B, 1994, NEURAL NETWORKS, V7, P321, DOI 10.1016/0893-6080(94)90026-4; Bankert R.L., 1994, AAAI94 WORKSH CAS BA, P106; BLUM A, 1994, RELEVANCE, P14; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Carnap Rudolf, 1962, LOGICAL FDN PROBABIL; Caruana R., 1994, P 11 INT C MACH LEAR, P28; Cover T. M., 1991, ELEMENTS INFORMATION; Davies S, 1994, P 1994 AAAI FALL S R, P37; FAYYAD UM, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P104; Fayyad U. M., 1990, AAAI-90 Proceedings. Eighth National Conference on Artificial Intelligence; GARDENFORS P, 1978, SYNTHESE, V37, P351, DOI 10.1007/BF00873245; GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5; GREINER R, 1994, RELEVANCE; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; Keynes J.M., 1921, TREATISE PROBABILITY; KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129; Kohavi R., 1995, P 1 INT C KNOWL DISC, P192; KOHAVI R, 1994, RELEVANCE, P122; Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621; Kononenko I, 1994, P EUR C MACH LEARN, P171; LAKEMEYER G, 1995, P IJCAI 95, P853; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Liu H, 1998, P 1 INT C DISC SCI D, P279; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; MUGGLETON S., 1992, INDUCTIVE LOGIC PROG; Pearl J., 1988, PROBABILISTIC REASON; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; SCHLIMMER JC, 1993, ML93, P284; SCHWEITZER HS, 1995, IEEE T PATTERN ANAL, V17, P1033, DOI 10.1109/34.473229; SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; SUBRAMANIAN D, 1987, P IJCAI 87, P416; Ullman J. D., 1989, PRINCIPLES DATABASE; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; WANG H, 1996, THESIS U ULSTER N IR; Wolpert D. H., 1990, Complex Systems, V4	39	54	57	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	NOV	2000	41	2					175	195		10.1023/A:1007612503587		21	Computer Science, Artificial Intelligence	Computer Science	359DR	WOS:000089596700003	
J	Bettini, C; Wang, XS; Jajodia, S; Lin, JL				Bettini, C; Wang, XS; Jajodia, S; Lin, JL			Discovering frequent event patterns with multiple granularities in time sequences	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; knowledge discovery; time sequences; temporal databases; time granularity temporal constraints; temporal patterns		An important usage of time sequences is to discover temporal patterns. The discovery process usually starts with a user-specified skeleton, called an event structure, which consists of a number of variables representing events and temporal constraints among these variables; the goal of the discovery is to find temporal patterns, i.e., instantiations of the variables in the structure that appear frequently in the time sequence. This paper introduces event structures that have temporal constraints with multiple granularities, defines the pattern-discovery problem with these structures, and studies effective algorithms to solve it. The basic components of the algorithms include timed automata with granularities (TAGs) and a number of heuristics. The TAGs are for testing whether a specific temporal pattern, called a candidate complex event type, appears frequently in a time sequence. Since there are often a huge number of candidate event types for a usual event structure, heuristics are presented aiming at reducing the number of candidate event types and reducing the time spent by the TAGs testing whether a candidate type does appear frequently in the sequence. These heuristics exploit the information provided by explicit and implicit temporal constraints with granularity in the given event structure. The paper also gives the results of an experiment to show the effectiveness of the heuristics on a real data set.	Univ Milan, Dept Informat Sci, I-20122 Milan, Italy; George Mason Univ, Dept Informat & Software Syst Engn, Fairfax, VA 22030 USA	Bettini, C (reprint author), Univ Milan, Dept Informat Sci, I-20122 Milan, Italy.	bettini@dsi.unimi.it; xywang@isse.gmu.edu; jajodia@isse.gmu.edu; jllin@isse.gmu.edu					AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; ALUR R, 1994, THEOR COMPUT SCI, V126, P183, DOI 10.1016/0304-3975(94)90010-8; Bettini C., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237680; Bettini C, 1998, ANN MATH ARTIF INTEL, V22, P29, DOI 10.1023/A:1018938007511; CHANDRA R, 1994, P DAT ENG C; DECHTER R, 1991, ARTIF INTELL, V49, P61, DOI 10.1016/0004-3702(91)90006-6; DIETTERICH TG, 1985, ARTIF INTELL, V25, P187, DOI 10.1016/0004-3702(85)90003-7; Dreyer W., 1994, SIGMOD Record, V23; LAIRD P, 1993, P 4 INT WORKSH ALG L, P1; Leban B., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; MARCECA R, 1996, THESIS U MILAN ITALY; NIEZETTE M, 1992, P CIKM BALT MD NOV; Soo M, 1993, P WORKSH INFR TEMP D, pFF1; Ullman J. D., 1974, DESIGN ANAL COMPUTER; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; WANG K, 1996, P WORKSH RES RES ISS; Wang XS, 1997, ACM T DATABASE SYST, V22, P115, DOI 10.1145/249978.249979	19	54	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR-APR	1998	10	2					222	237		10.1109/69.683754		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	ZU581	WOS:000074212400003	
J	Nanni, M; Pedreschi, D				Nanni, Mirco; Pedreschi, Dino			Time-focused clustering of trajectories of moving objects	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						spatio-temporal data mining; trajectory clustering; OPTICS		Spatio-temporal, geo-referenced datasets are growing rapidly, and will be more in the near future, due to both technological and social/commercial reasons. From the data mining viewpoint, spatio-temporal trajectory data introduce new dimensions and, correspondingly, novel issues in performing the analysis tasks. In this paper, we consider the clustering problem applied to the trajectory data domain. In particular, we propose an adaptation of a density-based clustering algorithm to trajectory data based on a simple notion of distance between trajectories. Then, a set of experiments on synthesized data is performed in order to test the algorithm and to compare it with other standard clustering approaches. Finally, a new approach to the trajectory clustering problem, called temporal focussing, is sketched, having the aim of exploiting the intrinsic semantics of the temporal dimension to improve the quality of trajectory clustering.	CNR, ISTI Inst, I-56124 Pisa, Italy; Univ Pisa, Dipartimento Informat, I-56127 Pisa, Italy	Nanni, M (reprint author), CNR, ISTI Inst, Via Moruzzi 1 Loc S Cataldo, I-56124 Pisa, Italy.	mirco.nanni@isti.cnr.it; pedre@di.unipi.it					Agrawal R., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases; Ankerst M., 1999, P ACM SIGMOD INT C M; Chomicki J., 1999, GeoInformatica, V3, DOI 10.1023/A:1009849314891; Chudova D., 2003, P 9 ACM SIGKDD INT C, P79; CIACCIA P, 1997, VLDB 97, P426; Ester M., 1996, 2 INT C KNOWL DISC D, P226; Faloutsos C., 1995, SIGMOD, P163; Gaffney S., 1999, KDD, p[63, 1999]; GIANNOTTI F, 2005, SYNTHETIC GENERATION; Gudmundsson J., 2004, GIS, P250; HADJIELEFTHERIO.M, 2003, P SSTD 03 SANT ISL G; Hwang SY, 2005, P 9 PAC AS C KNOWL D, P713; IYENGAR VS, 2004, KDD, P587; KALPAKIS K, 2001, ICDM, P273; KETTERLIN A, 1997, KDD 97, P215; KRIEGEL HP, 2003, SIGMOD 2003, P587; Kulldorff M, 1997, COMMUN STAT-THEOR M, V26, P1481, DOI 10.1080/03610929708831995; Li Y., 2004, KDD, P617; NANNI M, 2002, THESIS U PISA ITALY; Saltenisy S, 2000, P ACM SIGMOD INT C M, P331, DOI 10.1145/342009.335427; Vlachos M., 2002, ICDE, P673	21	53	64	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	NOV	2006	27	3					267	289		10.1007/s10844-006-9953-7		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	126FQ	WOS:000243498200005	
J	Hancock, T; Put, R; Coomans, D; Vander Heyden, Y; Everingham, Y				Hancock, T; Put, R; Coomans, D; Vander Heyden, Y; Everingham, Y			A performance comparison of modem statistical techniques for molecular descriptor selection and retention prediction in chromatographic QSRR studies	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						CART; bagging; random forests; gradient boosting; genetic algorithms; QSRR; retention prediction	LIQUID-CHROMATOGRAPHY; QUANTITATIVE STRUCTURE; STRUCTURE/RESPONSE CORRELATIONS; SIMILARITY/DIVERSITY ANALYSIS; GETAWAY DESCRIPTORS; PARAMETERS; REGRESSION; INDEXES	As datasets are becoming larger, a solution to the problem of variable prediction, this problem is becoming harder. The problem is to define which subset of variables produces optimum predictions. The example studied aims to predict the chromatographic retention of 83 basic drugs on a Unisphere PBD column at pH 11.7 using 1272 molecular descriptors. The goal of this paper is to compare the relative performance of recently developed data mining methods, specifically classification and regression trees (CART), stochastic gradient boosting for tree-based models (Treeboost), and random forests (RF), with common statistical techniques in chemometrics; and genetic algorithms on multiple linear regression (GA-MLR), uninformative variable elimination partial least squares (UVE-PLS), and SIMPLS. The comparison will be performed primarily on predictive performance, but also on the variables found to be most important for the predictions. The results of this study indicated that, individually, GA-MLR (R-2=0.93) outperformed all models. Further analysis found that a combination approach of GA-MLR and Treeboost (R-2=0.98) further improved these results. (c) 2004 Elsevier B.V. All rights reserved.	James Cook Univ N Queensland, Stat & Intelligent Data Anal Grp, Townsville, Qld 4814, Australia; Free Univ Brussels, Inst Pharmaceut, Dept Pharmaceut & Biomed Anal, B-1090 Brussels, Belgium	Hancock, T (reprint author), James Cook Univ N Queensland, Stat & Intelligent Data Anal Grp, Townsville, Qld 4814, Australia.	timothy.hancock@jcu.edu.au	everingham, yvette/A-8399-2012				ABRAHAM MH, 1987, CHROMATOGRAPHIA, V23, P577; BONCHEV D, 1991, CHEM GRAPH THEORY IN; BONCHEV D, 1983, INFORMATION THEORETI; BREIMAN L, 547 U CAL; BREIMAN L, 421 U CAL DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L., 2001, RANDOM FORESTS; BROTO P, 1984, EUR J MED CHEM, V19, P66; Centner V, 1996, ANAL CHEM, V68, P3851, DOI 10.1021/ac960321m; Consonni V, 2002, J CHEM INF COMP SCI, V42, P693, DOI 10.1021/ci0155053; Consonni V, 2002, J CHEM INF COMP SCI, V42, P682, DOI 10.1021/ci015504a; DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X; DIETTERICH TG, 1999, MACH LEARN, P1; Freund Y, 1995, COMPUT LEARN THEORY; Friedman J, 1999, GREEDY FUNCTION APPR; FRIEDMAN JH, 2002, ELEMENTS STAT LEARNI; GALVEZ J, 1994, J CHEM INF COMP SCI, V34, P520, DOI 10.1021/ci00019a008; Geary RC, 1954, INCORPORATED STATIST, V5, P115, DOI 10.2307/2986645; JINNO K, 1990, COMPUTER ASSISTED CH; JOUANRIMBAUD D, 1995, ANAL CHEM, V67, P4285; Kaliszan R, 1998, J CHROMATOGR B, V715, P229, DOI 10.1016/S0378-4347(98)00175-3; KALISZAN R, 1993, J CHROMATOGR A, V656, P417, DOI 10.1016/0021-9673(93)80812-M; Kaliszan R., 1987, QUANTITATIVE STRUCTU; KIER LB, 1981, J PHARM SCI, V70, P583, DOI 10.1002/jps.2600700602; Kier LB, 1986, MOL CONNECTIVITY STR; Konstantinova EV, 1996, J CHEM INF COMP SCI, V36, P54, DOI 10.1021/ci9502461; KOSTANTINOVA EV, 1997, J CHEM INF COMP SCI, V36, P54; Loukas YL, 2000, J CHROMATOGR A, V904, P119, DOI 10.1016/S0021-9673(00)00923-7; MEYLAN WM, 1995, J PHARM SCI, V84, P83, DOI 10.1002/jps.2600840120; MORAN PAP, 1950, BIOMETRIKA, V37, P17, DOI 10.2307/2332142; Nasal A, 1997, INT J PHARM, V159, P43, DOI 10.1016/S0378-5173(97)00267-6; Nord LI, 1998, CHEMOMETR INTELL LAB, V44, P257, DOI 10.1016/S0169-7439(98)00070-7; OOI T, 1987, P NATL ACAD SCI USA, V84, P3086, DOI 10.1073/pnas.84.10.3086; Palm K, 1998, J MED CHEM, V41, P5382, DOI 10.1021/jm980313t; Ridgeway G, 1999, COMPUTING SCI STAT, V31, P172; Ridgeway G, 2002, COMPUT STAT DATA AN, V38, P379, DOI 10.1016/S0167-9473(01)00066-4; RUCKER G, 1993, J CHEM INF COMP SCI, V33, P683; TODESCHINI R, DRAGON SOTWARE VERSI; Todeschini R., 2000, HDB MOL DESCRIPTORS; Todeschini R, 1997, QUANT STRUCT-ACT REL, V16, P120, DOI 10.1002/qsar.19970160204; TRINAJSTIC N, 1994, J CHEM INF COMP SCI, V34, P368, DOI 10.1021/ci00018a023; Trinajstic N., 1992, CHEM GRAPH THEORY; VISWANADHAN VN, 1989, J CHEM INF COMP SCI, V29, P163, DOI 10.1021/ci00063a006; Wang YW, 2002, ANAL CHIM ACTA, V463, P89, DOI 10.1016/S0003-2670(02)00376-8; Winiwarter S, 1998, J MED CHEM, V41, P4939, DOI 10.1021/jm9810102; *SRC, INT LOGKOW KOWWIN ME; CHEMOAC MATLAB TOOLB; R STAT LANGUAGE V 1	48	53	54	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	APR 28	2005	76	2					185	196		10.1016/j.chemolab.2004.11.001		12	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	918LE	WOS:000228542500007	
J	Hammer, B; Micheli, A; Sperduti, A; Strickert, M				Hammer, B; Micheli, A; Sperduti, A; Strickert, M			Recursive self-organizing network models	NEURAL NETWORKS			English	Article; Proceedings Paper	Workshop on New Developments in Self-Organizing Systems	SEP 11-14, 2003	Hibikino, JAPAN			self-organizing map; kohonen map; recursive models; structured data; sequence processing	SPATIOTEMPORAL CONNECTIONIST NETWORKS; RECURRENT NEURAL-NETWORKS; TEMPORAL KOHONEN MAP; VECTOR QUANTIZATION; GENERAL FRAMEWORK; CLASSIFICATION; REPRESENTATIONS; PRESERVATION; MACHINES; AUTOMATA	Self-organizing models constitute valuable tools for data visualization, clustering, and data mining. Here, we focus on extensions of basic vector-based models by recursive computation in such a way that sequential and tree-structured data can be processed directly. The aim of this article is to give a unified review of important models recently proposed in literature, to investigate fundamental mathematical properties of these models. and to compare the approaches by experiments. We first review several models proposed in literature from a unifying perspective. thereby making use of an underlying general framework which also includes supervised recurrent and recursive models as special cases. We shortly discuss how the models can be related to different neuron lattices. Then, we investigate theoretical properties of the models in detail: we explicitly formalize how structures are internally stored in different context models and which similarity measures are induced by the recursive mapping onto the structures. We assess the representational capabilities of the models, and we shortly discuss the issues of topology preservation and noise tolerance. The models are compared in an experiment with time series data. Finally, we add an experiment for one context model for tree-structured data to demonstrate the capability to process complex structures. (C) 2004 Elsevier Ltd. All rights reserved.	Univ Osnabruck, Res Grp LNM, Dept Math Comp Sci, D-49069 Osnabruck, Germany; Univ Pisa, Dipartimento Informat, Pisa, Italy; Univ Padua, Dipartimento Matemat Pura & Applicata, Padua, Italy	Hammer, B (reprint author), Univ Osnabruck, Res Grp LNM, Dept Math Comp Sci, Albrechtstr 28, D-49069 Osnabruck, Germany.	hammer@informatik.uni.osnabrueck.de; micheli@di.unipi.it; sperduti@math.unipd.it; marc@informatik.uni-osnabrueck.de	Hammer, Barbara /E-8624-2010				Baldi P., 1999, BIOINFORMATICS, V15; Barreto G., 2001, INT J COMPUT RES, V10, P139; Barreto GD, 2003, NEURAL COMPUT, V15, P1255, DOI 10.1162/089976603321780281; BAUER HU, 1992, IEEE T NEURAL NETWOR, V3, P570, DOI 10.1109/72.143371; Bauer HU, 1997, IEEE T NEURAL NETWOR, V8, P218, DOI 10.1109/72.557659; BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873; Bianucci AM, 2000, APPL INTELL, V12, P117, DOI 10.1023/A:1008368105614; Carrasco RC, 2001, IEEE T KNOWL DATA EN, V13, P148, DOI 10.1109/69.917555; CHAPPELL GJ, 1993, NEURAL NETWORKS, V6, P441, DOI 10.1016/0893-6080(93)90011-K; CLAUSSEN JC, 2003, EUR S ART NEUR NETW, P93; COSTA F, 2003, APPL INTELLIGENCE, V19; Cottrell M., 1994, European Symposium on Artificial Neural Networks. ESANN '94. Proceedings; de Mauro C, 2003, PATTERN RECOGN LETT, V24, P1115, DOI 10.1016/S0167-8655(02)00258-1; Diligenti M, 2003, IEEE T PATTERN ANAL, V25, P519, DOI 10.1109/TPAMI.2003.1190578; ERWIN E, 1992, BIOL CYBERN, V67, P47, DOI 10.1007/BF00201801; EULIANO N, 1999, KOHONEN MAPS; FARKAS I, 1999, P INT C ART NEUR NET, P251; FRANCESCONI E, 1997, LNCS, P104; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; FRASCONI P, 2001, SEQUENCES DATA STRUC, P351; GARTNER T, 2003, SURVEY KERNELS STRUC; GECSEG F., 1984, TREE AUTOMATA; GORI M, 1999, IEEE T NEUR NETW, V10; GUNTER S, 2001, P 3 IAPR TC15 WORKSH; Hagenbuchner M, 2001, ADVANCES IN SELF-ORGANISING MAPS, P21; Hagenbuchner M., 2003, IEEE T NEURAL NETWOR, V14, P191; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; Hammer B., 2004, EUR S ART NEUR NETW, P281; HAMMER B, 2002, EUR S ART NEUR NETW, P357; Hammer B, 2002, COGNITIVE SYSTEMS RE, V3, P145; Hammer B, 2003, NEURAL COMPUT, V15, P1897, DOI 10.1162/08997660360675080; Hammer B, 2004, NEUROCOMPUTING, V57, P3, DOI 10.1016/j.neucom.2004.01.008; HAMMER B, 2002, EUR S ART NEUR NETW, P389; HAMMER B, 2000, LNCIS, V254; Heskes T, 2001, IEEE T NEURAL NETWOR, V12, P1299, DOI 10.1109/72.963766; Hoekstra A., 1993, P INT C ART NEUR NET, P404; James D. L., 1994, ADV NEURAL INFORMATI, V7, P577; Kangas J., 1990, P IEEE IJCNN 90 C S, P331; Kaski S., 1998, NEURAL COMPUTING SUR, V1, P102; Kaski S, 2001, IEEE T NEURAL NETWOR, V12, P936, DOI 10.1109/72.935102; KILIAN J, 1996, INFORMATION COMPUTAT, V128; Kohonen T, 2002, NEURAL NETWORKS, V15, P945, DOI 10.1016/S0893-6080(02)00069-2; Kohonen T., 1995, HDB BRAIN THEORY NEU, P537; KOHONEN T, 1996, P INT C ART NEUR NET, P269; Kohonen T., 1997, SELF ORGANIZING MAPS; Koskela T., 1998, INT J KNOWLEDGE BASE, V2, P60; Koskela T., 1998, 6th European Symposium on Artificial Neural Networks. ESANN'98. Proceedings; Kremer SC, 2001, NEURAL COMPUT, V13, P249, DOI 10.1162/089976601300014538; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MARTINETZ T, 1994, NEURAL NETWORKS, V7, P507, DOI 10.1016/0893-6080(94)90109-0; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Omlin CW, 1996, J ACM, V43, P937, DOI 10.1145/235809.235811; ONTRUP J, 2001, LECT NOTES ARTIF INT, V2618, P338; POLLASTRI G, 2002, ADV NEURAL INFORMATI; RITTER H, 1986, BIOL CYBERN, V54, P99, DOI 10.1007/BF00320480; Ritter H, 1999, KOHONEN MAPS, P97, DOI 10.1016/B978-044450270-4/50007-3; RITTER H, 1993, P ICANN 93 INT C ART, P568; RITTER H, 1992, NEURAL COMPUTATION J; Sinkkonen J, 2002, NEURAL COMPUT, V14, P217, DOI 10.1162/089976602753284509; Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108; SPERDUTI A, 2001, ICANN 2001, P5; STRICKERT M, 2003, WSOM 03, P53; STRICKERT M, 2004, IN PRESS NEUROCOMPUT; STRICKERT M, 2003, EUR S ART NEUR NETW, P27; Sturt P, 2003, COGNITION, V88, P133, DOI 10.1016/S0010-0277(03)00026-X; Varsta M, 2001, NEURAL PROCESS LETT, V13, P237, DOI 10.1023/A:1011353011837; Vesanto J., 1997, P WORKSH SELF ORG MA, P209; Villmann T, 2003, NEURAL NETWORKS, V16, P389, DOI 10.1016/S0893-6080(03)00021-2; Villmann T, 1997, IEEE T NEURAL NETWOR, V8, P256, DOI 10.1109/72.557663; Voegtlin T, 2001, ADVANCES IN SELF-ORGANISING MAPS, P210; Voegtlin T, 2002, NEURAL NETWORKS, V15, P979, DOI 10.1016/S0893-6080(02)00072-2; VOEGTLIN T, 2000, P INT JOINT C NEURAL, V5, P20; VULLO A, 2003, P 18 ANN ACM S APPL; Yao Y, 2003, PATTERN RECOGN, V36, P397	74	53	53	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	OCT-NOV	2004	17	8-9					1061	1085		10.1016/j.neunet.2004.06.009		25	Computer Science, Artificial Intelligence	Computer Science	874GM	WOS:000225338900004	
J	Hong, TP; Lin, KY; Wang, SL				Hong, TP; Lin, KY; Wang, SL			Fuzzy data mining for interesting generalized association rules	FUZZY SETS AND SYSTEMS			English	Article						fuzzy data mining; fuzzy set; generalized association rule; learning; quantitative value; taxonomy	MEMBERSHIP FUNCTIONS; INDUCTION; PERSPECTIVE; ATTRIBUTES; SYSTEMS	Due to the increasing use of very large databases and data warehouses, mining useful information and helpful knowledge from transactions is evolving into an important research area. Most conventional data-mining algorithms identify the relationships among transactions using binary values and find rules at a single concept level. Transactions with quantitative values and items with hierarchy relation are, however, commonly seen in real-world applications. In this paper, we thus introduce the problem of mining fuzzy generalized association rules from quantitative data. A fuzzy mining algorithm based on Srikant and Agrawal's method is proposed for extracting implicit generalized knowledge from transactions stored as quantitative values. It integrates fuzzy-set concepts and generalized data mining technologies to achieve this purpose. Items in rules may be from any level of the given taxonomy. The effect of numbers of fuzzy regions on the performance of the proposed algorithm is also discussed. (C) 2002 Elsevier B.V. All rights reserved.	Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung 811, Taiwan; I Shou Univ, Grad Sch Informat Engn, Kaohsiung 840, Taiwan	Hong, TP (reprint author), Natl Univ Kaohsiung, Dept Elect Engn, Der Chung Rd, Kaohsiung 811, Taiwan.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R., 1993, 1993 ACM SIGMOD C WA; BLISHUN AF, 1987, FUZZY SET SYST, V22, P57, DOI 10.1016/0165-0114(87)90006-6; CHANG RLP, 1977, IEEE T SYST MAN CYB, V7, P28, DOI 10.1109/TSMC.1977.4309586; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; CLAIR C, 1998, 7 INT C INF KNOWL MA, P259; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; DECAMPOS LM, 1993, FUZZY SET SYST, V59, P247, DOI 10.1016/0165-0114(93)90470-3; DELGADO M, 1993, FUZZY SET SYST, V55, P121, DOI 10.1016/0165-0114(93)90125-2; FAMILI A, 1997, INTELL DATA ANAL, V1, P1, DOI 10.1016/S1088-467X(98)00006-7; GONZALEZ A, 1995, INT J INTELL SYST, V10, P57; HAN J, 1995, INT C VER LARG DAT; Hong T. P., 1999, INTELL DATA ANAL, V3, P363, DOI 10.1016/S1088-467X(99)00028-1; Hong TP, 1996, FUZZY SET SYST, V84, P33, DOI 10.1016/0165-0114(95)00305-3; Hong TP, 1999, FUZZY SET SYST, V103, P389; Hong TP, 2000, FUZZY SET SYST, V112, P127, DOI 10.1016/S0165-0114(98)00179-1; Kandel A, 1992, FUZZY EXPERT SYSTEMS, P8; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SRIKANT R, 1995, INT C VER LARG DAT; Srikant R., 1996, 1996 ACM SIGMOD INT, P1; Wang CH, 1999, FUZZY SET SYST, V103, P91; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	23	53	59	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	SEP 1	2003	138	2					255	269		10.1016/S0165-0114(02)00272-5		15	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	711GM	WOS:000184731300002	
J	Brossette, SE; Sprague, AP; Hardin, JM; Waites, KB; Jones, WT; Moser, SA				Brossette, SE; Sprague, AP; Hardin, JM; Waites, KB; Jones, WT; Moser, SA			Association rules and data mining in hospital infection control and public health surveillance	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							ANTIBIOTIC-RESISTANCE; EPIDEMIOLOGY; DISEASE	Objectives: The authors consider the problem of identifying new, unexpected, and interesting patterns in hospital infection control and public health surveillance data and present a new data analysis process and system based on association rules to address this problem. Design: The authors first illustrate the need for automated pattern discovery and data mining in hospital infection control and public health surveillance. Next, they define association rules, explain how those rules can be used in surveillance, and present a novel process and system-the Data Mining Surveillance System (DMSS)-that utilize association rules to identify new and interesting patterns in surveillance data. Results: Experimental results were obtained using DMSS to analyze Pseudomonas aeruginosa infection control data collected over one year (1996) at University of Alabama at Birmingham Hospital. Experiments using one-, three-, and six-month time partitions yielded 34, 57, and 28 statistically significant events, respectively. Although not all statistically significant events are clinically significant, a subset of events generated in each analysis indicated potentially significant shifts in the occurrence of infection or antimicrobial resistance patterns of P. aeruginosa. Conclusion: The new process and system are efficient and effective in identifying new, unexpected, and interesting patterns in surveillance data. The clinical relevance and utility of this process await the results of prospective studies currently in progress.	Univ Alabama, Dept Pathol, Birmingham, AL 35233 USA	Moser, SA (reprint author), Univ Alabama, Dept Pathol, P246,619 19th St S, Birmingham, AL 35233 USA.		Moser, Stephen/A-1168-2008				Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; BRIN S, 1994, ACM SIGMOD 1997, P255; Cheung DW, 1996, IEEE T KNOWL DATA EN, V8, P911, DOI 10.1109/69.553158; Crow E. L., 1960, STAT MANUAL; Dean AG, 1994, PRINCIPLES PRACTICE, P200; DOEBBELING NB, 1993, PREVENTION CONTROL N, P177; Farrington CP, 1996, J ROY STAT SOC A STA, V159, P547, DOI 10.2307/2983331; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Freeman J, 1996, INFECT CONT HOSP EP, V17, P249; Gaynes RP, 1997, INFECT CONT HOSP EP, V18, P475; HUTWAGNER C, 1997, EMERG INFECT DIS, V3, P395; IV Elder J.F., 1996, ADV KNOWLEDGE DISCOV, P83; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; MANILLA H, 1996, P 2 INT C KNOWL DISC, P189; MCGOWAN JE, 1994, INFECT CONT HOSP EP, V15, P478; NEU HC, 1992, DIAGN MICR INFEC DIS, V15, pS53; Ngo L, 1996, AM J EPIDEMIOL, V143, P637; OHANLEY P, 1989, AM J MED, V87, P605, DOI 10.1016/S0002-9343(89)80391-2; Thacker Stephen B., 1994, PRINCIPLES PRACTICE, P3; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; *NAT COMM CLIN LAB, 1997, METHODS DILUTION ANT	22	53	54	HANLEY & BELFUS INC	PHILADELPHIA	210 S 13TH ST, PHILADELPHIA, PA 19107 USA	1067-5027		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JUL-AUG	1998	5	4					373	381				9	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	ZY220	WOS:000074598300008	
J	Liu, XY; Wu, JX; Zhou, ZH				Liu, Xu-Ying; Wu, Jianxin; Zhou, Zhi-Hua			Exploratory Undersampling for Class-Imbalance Learning	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						Class-imbalance learning; data mining; ensemble learning; machine learning; undersampling	STACKED GENERALIZATION; FACE DETECTION; ALGORITHMS; CASCADE; MACHINE	Undersampling is a popular method in dealing with class-imbalance problems, which uses only a subset of the majority class and thus is very efficient. The main deficiency is that many majority class examples are ignored. We propose two algorithms to overcome this deficiency. EasyEnsemble samples several subsets from the majority class, trains a learner using each of them, and combines the outputs of those learners. BalanceCascade trains the learners sequentially, where in each step, the majority class examples that are correctly classified by the current trained learners are removed from further consideration. Experimental results show that both methods have higher Area Under the ROC Curve, F-measure, and G-mean values than many existing class-imbalance learning methods. Moreover, they have approximately the same training time as that of undersampling when the same number of weak classifiers is used, which is significantly faster than other methods.	[Liu, Xu-Ying; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China; [Wu, Jianxin] Georgia Inst Technol, Coll Comp, Sch Interact Comp, Atlanta, GA 30332 USA	Liu, XY (reprint author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.	liuxy@lamda.nju.edu.cn; wujx@cc.gatech.edu; zhouzh@lamda.nju.edu.cn	Wu, Jianxin/A-3700-2011; Wu, Jianxin/B-8539-2012		National Science Foundation of China [60635030, 60721002]; Jiangsu Science Foundation [BK2008018]; National High Technology Research and Development Program of China [2007AA01Z169]	This work was supported in part by the National Science Foundation of China under Grants 60635030 and 60721002, by the Jiangsu Science Foundation under Grant BK2008018, and by the National High Technology Research and Development Program of China under Grant 2007AA01Z169.	Batista G. E., 2004, ACM SIGKDD EXPLORATI, V6, P20, DOI DOI 10.1145/1007730.1007735; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C., UCI REPOSITORY MACHI, P55; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chawla NV, 2003, P 7 EUR C PRINC PRAC, P107; Chawla N.V., 2003, P ICML WORKSH LEARN; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Chawla N.V., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI DOI 10.1145/1007730.1007733; Chen C, 2004, 666 U CAL DEP STAT; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Drummond C., 2003, P WORK NOT ICML WORK; Elkan C, 2001, P 17 INT JOINT C ART, P973; Fan W., 1999, P 16 INT C MACH LEAR, P97; Fawcett T., 2003, HPL20034; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Fukunaga K., 1990, INTRO STAT PATTERN R; Guo H., 2004, ACM SIGKDD EXPLORATI, V6, P30, DOI 10.1145/1007730.1007736; Huang KZ, 2004, PROC CVPR IEEE, P558; JAPKOWICZ N, 2000, P AAAI WORKSH LEARN; KARAKOULAS GJ, 1999, P ADV NEURAL INF PRO, V11, P253; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Liu XY, 2006, IEEE DATA MINING, P965; MARCOS FZ, 2004, P SUMM SCH NEUR NETW, P357; Masnadi-Shirazi H., 2007, P 24 INT C MACH LEAR, P609, DOI 10.1145/1273496.1273573; Schapire R. E., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290996; SCHAPIRE RE, 1999, P 16 INT JOINT C ART, P1401; Ting KM, 1999, J ARTIF INTELL RES, V10, P271; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P, 2002, ADV NEUR IN, V14, P1311; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29; Weiss G. M., 2004, ACM SIGKDD EXPLORATI, V6, P7, DOI 10.1145/1007730.1007734; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Witten IH, 2005, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wu JX, 2008, IEEE T PATTERN ANAL, V30, P369, DOI 10.1109/TPAMI.2007.1181; YU Y, 2007, P 7 IEEE INT C DAT M, P721; Zadrozny B., 2003, P 3 IEEE INT C DAT M, P435; ZHOU XS, 2003, KLU INT S VIDEO COMP, V7, P1; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63; Zhou ZH, 2004, IEEE T KNOWL DATA EN, V16, P770; Zhou ZH, 2003, AI COMMUN, V16, P3; [Anonymous], 2000, P 11 EUR C MACH LEAR, P413	47	52	67	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2009	39	2					539	550		10.1109/TSMCB.2008.2007853		12	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	425IP	WOS:000264630500020	
J	Tan, SB				Tan, SB			An effective refinement strategy for KNN text classifier	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						KNN; text classification; information retrieval; data mining		Due to the exponential growth of documents on the Internet and the emergent need to organize them, the automated categorization of documents into predefined labels has received an ever-increased attention in the recent years. A wide range of supervised learning algorithms has been introduced to deal with text classification. Among all these classifiers, K-Nearest Neighbors (KNN) is a widely used classifier in text categorization community because of its simplicity and efficiency. However, KNN still suffers from inductive biases or model misfits that result from its assumptions, such as the presumption that training data are evenly distributed among all categories. In this paper, we propose a new refinement strategy, which we called as DragPushing, for the KNN Classifier. The experiments on three benchmark evaluation collections show that DragPushing achieved a significant improvement on the performance of the KNN Classifier. (c) 2005 Elsevier Ltd. All rights reserved.	Chinese Acad Sci, Software Dept, Comp Technol Inst, Beijing 100080, Peoples R China; Chinese Acad Sci, Grad Sch, Beijing 100864, Peoples R China	Tan, SB (reprint author), Chinese Acad Sci, Software Dept, Comp Technol Inst, POB 2704, Beijing 100080, Peoples R China.	tansongbo@software.ict.ac.cn	Tan, Songbo/A-7450-2012				CHAI, 2002, BAYESIAN ONLINE CLAS, P97; Croft W. B., 2001, SIGIR, P137; GHANI R, USING ERROR CORRECTI; Han E.-H., 2000, CENTROID BASED DOCUM; Kalt T, 1996, IR78 U MASS CTR INT; KJERSTI A, LINE EIKVIL TEXT CTE; LARKEY LS, 1996, COMBINING CLASSIFIER, P289; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; VANMUN PPT, TEXT CLASSIFICATION; YANG Y., 1997, COMP STUDY FEATURE S, P412	10	52	58	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2006	30	2					290	298		10.1016/j.eswa.2005.07.019		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	005TJ	WOS:000234846400014	
J	Newton, EM; Sweeney, L; Malin, B				Newton, EM; Sweeney, L; Malin, B			Preserving privacy by de-identifying face images	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						video surveillance; privacy; privacy-preserving data mining; k-anonymity	RECOGNITION ALGORITHMS	In the context of sharing video surveillance data, a significant threat to privacy is face recognition software, which can automatically identify known people, such as from a database of drivers' license photos, and thereby track people regardless of suspicion. This paper introduces an algorithm to protect the privacy of individuals in video surveillance data by de-identifying faces such that many facial characteristics remain but the face cannot be reliably recognized. A trivial solution to de-identifying faces involves blacking out each face. This thwarts any possible face recognition, but because all facial details are obscured, the result is of limited use. Many ad hoc attempts, such as covering eyes, fail to thwart face recognition because of the robustness of face recognition methods. This paper presents a new privacy-enabling algorithm, named k-Same, that guarantees face recognition software cannot reliably recognize de-identified faces, even though many facial details are preserved. The algorithm determines similarity between faces based on a distance metric and creates new faces by averaging image components, which may be the original image pixels (k-Same-Pixel) or eigenvectors (k-Same-Eigen). Results are presented on a standard collection of real face images with varying k.	Carnegie Mellon Univ, Dept Engn & Publ Policy, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Sch Comp Sci, Data Privacy Lab, Pittsburgh, PA 15213 USA	Newton, EM (reprint author), Carnegie Mellon Univ, Dept Engn & Publ Policy, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	enewton@andrew.cmu.edu; latanya@andrew.cmu.edu; malin@andrew.cmu.edu					Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; ALLIN AJ, 2003, P 5 INT C UB COMP UB; Atallah M, 1999, P 1999 IEEE KNOWL DA, P45; BLACKBURN D, 2001, FACE RECOGNITION VEN; CAI Y, 2003, TOP PRIV CARN MELL U; GROSS R, 2001, P IEEE C COMP VIS PA; JONES M, 2002, VIRGINIAN PILOT 0910; LAMPINEN J, 1995, IEEE T NEURAL NETWOR, V6, P539, DOI 10.1109/72.377961; Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896; Newton E., 2003, CMUCS03119; OGANIAN A, 2001, P JOINT EC COMM EUR; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; REEVES J, 2001, TIME            0716; RIZVI S, 2002, P 28 C VER LARG DAT; Saygin Y, 2001, SIGMOD RECORD, V30, P45; SAYGIN Y, 2002, P 12 INT WORKSH RES; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; SWEENEY L, 2003, BIOALIRT PROGR DEF A; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WALL B, 1996, US TODAY        0310; Weisstein E.W, 2002, CRC CONCISE ENCY MAT; *I APPL AUT, 2003, ISEE PROJ SURV WEB B	25	52	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2005	17	2					232	243		10.1109/TKDE.2005.32		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	879KD	WOS:000225715800007	
J	Kirkos, E; Spathis, C; Manolopoulos, Y				Kirkos, Efstathios; Spathis, Charalambos; Manolopoulos, Yannis			Data mining techniques for the detection of fraudulent financial statements	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						fraudulent financial statements; management fraud; data mining; auditing; Greece	MANAGEMENT FRAUD; EMPIRICAL-ANALYSIS; AUDITORS; MODEL	This paper explores the effectiveness of Data Mining (DM) classification techniques in detecting firms that issue fraudulent financial statements (FFS) and deals with the identification of factors associated to FFS. In accomplishing the task of management fraud detection, auditors could be facilitated in their work by using Data Mining techniques. This study investigates the usefulness of Decision Trees, Neural Networks and Bayesian Belief Networks in the identification of fraudulent financial statements. The input vector is composed of ratios derived from financial statements. The three models are compared in terms of their performances. (C) 2006 Elsevier Ltd. All rights reserved.	Aristotle Univ Thessaloniki, Dept Econ, Div Business Adm, Thessaloniki 54124, Greece; Technol Educ Inst Thessaloniki, Dept Accounting, Thessaloniki 57400, Greece; Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece	Spathis, C (reprint author), Aristotle Univ Thessaloniki, Dept Econ, Div Business Adm, Thessaloniki 54124, Greece.	stkirk@acc.teithe.gr; hspathis@econ.auth.gr; manolopo@csd.auth.gr					Abbott L.J., 2000, MANAGE FINANC, V26, P55, DOI 10.1108/03074350010766990; ALTMAN E, 2001, BANKRUPTCY CREDIT 1; ALTMAN EI, 1968, J FINANC, V23, P4; American Institute of Certified Public Accountants (AICPA), 1997, CONS FRAUD FIN STAT; Beasley MS, 1996, ACCOUNT REV, V71, P443; BELL T, 2000, AUDITING-J PRACT TH, V9, P169; Calderon T., 2002, INT J ACCOUNTING INF, V3, P203, DOI DOI 10.1016/S1467-0895(02)00068-4; CHENG J, 2001, P 14 BIENN C CAN SOC, P141; CHENG J, BAYESIAN BELIEF NETW; Coderre G.D., 1999, FRAUD DETECTION USIN; CULLINAN PG, 2002, CRIT PERSPECT, V13, P297; Eining MM, 1997, AUDITING-J PRACT TH, V16, P1; Fanning K. M., 1998, International Journal of Intelligent Systems in Accounting, Finance and Management, V7, DOI 10.1002/(SICI)1099-1174(199803)7:1<21::AID-ISAF138>3.3.CO;2-B; FEROZ EH, 1991, J ACCOUNTING RES, V29, P107, DOI 10.2307/2491006; FRASER IAM, 1997, BRIT ACCOUNTING REV, V29, P35, DOI 10.1006/bare.1996.0034; Green BP, 1997, AUDITING-J PRACT TH, V16, P14; Han J., 2000, DATA MINING CONCEPTS; Hansen JV, 1996, MANAGE SCI, V42, P1022, DOI 10.1287/mnsc.42.7.1022; Kantardzic M., 2002, DATA MINING CONCEPTS; KINNEY WR, 1989, J ACCOUNT ECON, V11, P71, DOI 10.1016/0165-4101(89)90014-1; KIRKOS S, 2004, FP 1 INT C ENT SYST, P63; Koh H., 2004, MANAGERIAL AUDITING, V19, P462, DOI 10.1108/02686900410524436; Koskivaara E., 2004, MANAGERIAL AUDITING, V19, P191, DOI 10.1108/02686900410517821; LOEBBECKE JK, 1989, AUDITING-J PRACT TH, V9, P1; Persons O. S., 1995, J APPL BUSINESS RES, V11, P38; PORTER B, 1987, ACCOUNTANTS J, P44; Schilit Howard, 2002, FINANCIAL SHENANIGAN; Sohl JE, 1995, INFORM MANAGE, V29, P297, DOI 10.1016/0378-7206(95)00033-4; Spathis C., 2003, INT J ACCOUNTING, V38, P267, DOI 10.1016/S0020-7063(03)00047-5; Spathis C., 2002, EUROPEAN ACCOUNTING, V11, P509, DOI 10.1080/0963818022000000966; Spathis C.T., 2002, MANAGERIAL AUDITING, V17, P179, DOI 10.1108/02686900210424321; STICE J, 1991, CPA J            APR, P52; STICE JD, 1991, ACCOUNT REV, V66, P516; Summers SL, 1998, ACCOUNT REV, V73, P131; WELLS J, 1997, OCCUPATIONAL FRAUD A; *IAPC, 2001, INT STAT AUD ISA, P240; *U LUM LYON 2, SIP RES ED DAT MIN; *U TX ARL NEUR DEC, NUCL 7 NONL NETW CLA	38	51	53	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2007	32	4					995	1003		10.1016/j.eswa.2006.02.016		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	130KF	WOS:000243797800004	
J	He, ZY; Xu, XF; Deng, SC				He, ZY; Xu, XF; Deng, SC			Discovering cluster-based local outliers	PATTERN RECOGNITION LETTERS			English	Article						outlier detection; clustering; data mining	ALGORITHM	In this paper, we present a new definition for outlier: cluster-based local outlier, which is meaningful and provides importance to the local data behavior. A measure for identifying the physical significance of an outlier is designed, which is called cluster-based local outlier factor (CBLOF). We also propose the FindCBLOF algorithm for discovering outliers. The experimental results show that our approach outperformed the existing methods on identifying meaningful and interesting outliers. (C) 2003 Elsevier Science B.V. All rights reserved.	Harbin Inst Technol, Dept Comp Sci & Engn, Harbin 150001, Peoples R China	He, ZY (reprint author), Harbin Inst Technol, Dept Comp Sci & Engn, 92 W Dazhi St, Harbin 150001, Peoples R China.						Aggarwal C C, 2001, P 2001 ACM SIGMOD IN, P37, DOI 10.1145/375663.375668; ANGIULLI F, 2002, P PKDD 02; Arning A., 1996, P 2 INT C KNOWL DISC, P164; BARNETT V, 1994, OUTLIERS STAT DATA, P1994; Beyer K., 1999, P 7 INT C DAT THEOR, P217; Breunig M. M., 2000, P SIGMOD 00 DALL TEX, P427; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Harkins S., 2002, P 4 INT C DAT WAR KN, P170; He Z., 2002, P 3 INT C WEB AG INF, P126; He ZY, 2002, J COMPUT SCI TECH-CH, V17, P611, DOI 10.1007/BF02948829; Jiang MF, 2001, PATTERN RECOGN LETT, V22, P691, DOI 10.1016/S0167-8655(00)00131-8; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Liu B, 1998, P 4 INT C KNOWL DISC, P80; MERZ CJ, 1996, UCI REP MACH LEARN D; Nanopoulos A., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; TAMASWAMY S, 2000, P SIGMOD 00 DALL TEX, P93; Yamanishi K., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347160; Yamanishi K., 2001, P 7 ACM SIGKDD INT C, P389, DOI 10.1145/502512.502570; Yu D., 1999, FINDOUT FINDING OUTL	20	51	63	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2003	24	9-10					1641	1650		10.1016/S0167-8655(03)00003-5		10	Computer Science, Artificial Intelligence	Computer Science	652FJ	WOS:000181368900049	
J	Vrahatis, MN; Boutsinas, B; Alevizos, P; Pavlides, G				Vrahatis, MN; Boutsinas, B; Alevizos, P; Pavlides, G			The new k-windows algorithm for improving the k-means clustering algorithm	JOURNAL OF COMPLEXITY			English	Article						k-means clustering algorithm; unsupervised teaming; data mining; range search		The process of partitioning a large set of patterns into disjoint and homogeneous clusters is fundamental in knowledge acquisition. It is called Clustering in the literature and it is applied in various fields including data mining, statistical data analysis, compression and vector quantization. The k-means is a very popular algorithm and one of the best for implementing the clustering process. The k-means has a time complexity that is dominated by the product of the number of patterns, the number of clusters, and the number of iterations. Also, it often converges to a local minimum. In this paper, we present an improvement of the k-means clustering algorithm, aiming at a better time complexity and partitioning accuracy. Our approach reduces the number of patterns that need to be examined for similarity, in each iteration, using a windowing technique. The latter is based on well known spatial data structures, namely the range tree, that allows fast range searches. (C) 2002 Elsevier Science (USA).	Univ Patras, UPAIRC, Dept Math, GR-26500 Patras, Greece; UOP, UPAIRC, Dept Business Adm, GR-26500 Patras, Greece; UOP, UPAIRC, Dept Comp Engn & Inf, GR-26500 Patras, Greece	Vrahatis, MN (reprint author), Univ Patras, UPAIRC, Dept Math, GR-26500 Patras, Greece.						Aldenderfer M. S., 1984, CLUSTER ANAL; Alevizos P., 1998, P 14 EUR WORKSH COMP; Alsabti K., 1995, P 1 WORKSH HIGH PERF; BENTLEY JL, 1980, ACTA INFORM, V13, P1551; Boutsinas B, 2002, PATTERN RECOGN LETT, V23, P999, DOI 10.1016/S0167-8655(02)00031-4; BRADLEY PS, 1983, P IJCAI 93 SAN MAT C, P1058; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chazelle B, 1986, ALGORITHMICA, V1, P163, DOI 10.1007/BF01840441; CHAZELLE B, 1986, SIAM J COMPUT, V15, P703, DOI 10.1137/0215051; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; GREENACRE M, 1984, THEORY APPL CORRES A; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain A.K., 1988, ALGORITHMS CLUSTERIN; JUDD D, 1996, P INT C PATT REC; LI X, 1989, PARALLEL COMPUT, V11, P275, DOI 10.1016/0167-8191(89)90036-7; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; PIFTZNER DW, 1998, DATA MIN KNOWL DISC, V2, P419; Pizzuti C, 1999, LECT NOTES ARTIF INT, V1704, P484; Preparata FP, 1985, COMPUTATIONAL GEOMET; RALAMBONDRAINY H, 1995, PATTERN RECOGN LETT, V16, P1147, DOI 10.1016/0167-8655(95)00075-R; RAMASUBRAMANIAN V, 1992, IEEE T SIGNAL PROCES, V40; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81	26	51	53	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0885-064X		J COMPLEXITY	J. Complex.	MAR	2002	18	1					375	391		10.1006/jcom.2001.0633		17	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	540AB	WOS:000174904800017	
J	Stefanovic, N; Han, JW; Koperski, K				Stefanovic, N; Han, JW; Koperski, K			Object-based selective materialization for efficient implementation of spatial data cubes	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data warehouse; data mining; online analytical processing (OLAP); spatial databases; spatial data analysis; spatial OLAP		With a huge amount of data stored in spatial databases and the introduction of spatial components to many relational or object-relational databases, it is important to study the methods for spatial data warehousing and OLAP of spatial data. In this paper, we study methods for spatial OLAP, by integration of nonspatial OLAP methods with spatial database implementation techniques. A spatial data warehouse model, which consists of both spatial and nonspatial dimensions and measures, is proposed. Methods for computation of spatial data cubes and analytical processing on such spatial data cubes are studied, with several strategies proposed, including approximation and selective materialization of the spatial objects resulted from spatial OLAP operations. The focus of our study is on a method for spatial cube construction, called object-based selective materialization, which is different from cuboid-based selective materialization proposed in previous studies of nonspatial data cube construction. Rather than using a cuboid as an atomic structure during the selective materialization, we explore granularity on a much finer level, that of a single cell of a cuboid. Several algorithms are proposed for object-based selective materialization of spatial data cubes and the performance study has demonstrated the effectiveness of these techniques.	Seagate Software, Vancouver, BC V6B 4J2, Canada; Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; MathSoft Inc, Seattle, WA 98109 USA	Stefanovic, N (reprint author), Seagate Software, 840 Cambie St, Vancouver, BC V6B 4J2, Canada.						Agarwal S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506; CHAUDHURI S., 1997, ACM SIGMOD RECORD, V26, P65, DOI 10.1145/248603.248616; EGENHOFER MJ, 1994, IEEE T KNOWL DATA EN, V6, P86, DOI 10.1109/69.273029; ESTER M, 1997, P 5 INT S LARG SPAT, P47; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163, DOI 10.1145/223784.223812; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843; Gunther O., 1993, Proceedings. Ninth International Conference on Data Engineering (Cat. No.92CH3258-1), DOI 10.1109/ICDE.1993.344078; Guting R. H., 1994, VLDB J, V3, P357, DOI 10.1007/BF01231602; Harinarayan V., 1996, P ACM SIGMOD INT C M, P205, DOI 10.1145/233269.233333; Inmon W.H., 1996, BUILDING DATA WAREHO; Keim D. A., 1994, Proceedings. The 10th International Conference Data Engineering (Cat. No.94CH3383-7), DOI 10.1109/ICDE.1994.283045; Kimball Ralph, 1996, DATA WAREHOUSE TOOLK; Knorr EM, 1996, IEEE T KNOWL DATA EN, V8, P884, DOI 10.1109/69.553156; Koperski K., 1998, P INT S SPAT DAT HAN, P45; KOPERSKI K., 1995, P 4 INT S LARG SPAT, P47; KOPERSKI K., 1997, P ACM SIGMOD INT C M, P553, DOI 10.1145/253260.253404; Lu W., 1993, P FAR E WORKSH GEOGR, P275; Ng R, 1994, P 20 INT C VER LARG, P144; Ross KA, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P116; Silberschatz A., 1996, ACM SIGMOD RECORD, V25, P52, DOI 10.1145/381854.381886; STEFANOVIC N, 1997, THESIS S FRASER U CA; Zhao Y., 1997, P ACM SIGMOD INT C M, P159, DOI 10.1145/253260.253288; ZHOU X, 1999, P 6 INT S LARG SPAT, P167	25	51	58	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV-DEC	2000	12	6					938	958		10.1109/69.895803		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	384KY	WOS:000165942700005	
J	Manganaris, S; Christensen, M; Zerkle, D; Hermiz, K				Manganaris, S; Christensen, M; Zerkle, D; Hermiz, K			A data mining analysis of RTID alarms	COMPUTER NETWORKS-THE INTERNATIONAL JOURNAL OF COMPUTER AND TELECOMMUNICATIONS NETWORKING			English	Article						intrusion detection; data mining; context-sensitive anomaly detection; adaptive alarm filtering; sensor profiling		IBM's emergency response service provides real-time intrusion detection (RTID) services through the Internet for a variety of clients. As the number of clients increases, the volume of alerts generated by the RTID sensors becomes intractable. This problem is aggravated by the fact that some sensors may generate hundreds or even thousands of innocent alerts per day. With an eye towards managing these alerts more effectively, IBM's data mining services group analyzed a database of RTID reports. The first objective was an approach for characterizing the "normal" stream of alerts from a sensor. Using such models tuned to individual sensors, we then developed a methodology for detecting anomalies. In contrast to many popular approaches, the decision to filter an alarm out or not takes into consideration the context in which it occurred and the historical behavior of the sensor it came from. Our second objective was to identify all the different profiles of our clients. Based on their history of alerts, we discovered several different types of clients, with different alert behaviors and thus different monitoring needs. We present the issues encountered, solutions, and findings, and discuss how our results may be used in large-scale RTID operations. (C) 2000 Elsevier Science B.V. All rights reserved.	Int Business Machines Corp, Res Triangle Pk, NC 27713 USA	Manganaris, S (reprint author), Int Business Machines Corp, 19 Lakehurst Court, Res Triangle Pk, NC 27713 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; AGRAWAL R, 1995, P INT C DAT ENG ICDE; Berry M. R. J., 1997, DATA MINING TECHNIQU; Bigus J. P., 1996, DATA MINING NEURAL N; Brin S., 1997, P ACM SIGMOD C MAN D; FAYYAD UM, 1996, ADV KNOWLEDGE DISCOV, pCH1; Lee W., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Mannila H., 1995, P 1 INT C KNOWL DISC; MICHAUD P, 1987, APPL STOCH MODEL BUS, V3, P173, DOI 10.1002/asm.3150030305; MUKHERJEE B, 1994, IEEE NETWORK, V8, P26, DOI 10.1109/65.283931; RIGOUTSOS I, 1998, P 2 ANN ACM INT C CO; WESPI A, 1998, P 1 INT WORKSH REC A; *CISC SYST INC, 1999, NETR US GUID; *IBM, 1996, INT MIN DAT US GUID	15	51	66	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1389-1286		COMPUT NETW	Comput. Netw.	OCT	2000	34	4					571	577		10.1016/S1389-1286(00)00138-9		7	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	352FH	WOS:000089203500003	
J	Apte, C; Weiss, S				Apte, C; Weiss, S			Data mining with decision trees and decision rules	FUTURE GENERATION COMPUTER SYSTEMS			English	Article						decision tree; rule induction; data mining	INDUCTION	This paper describes the use of decision tree and rule induction in data-mining applications. Of methods for classification and regression that have been developed in the fields of pattern recognition, statistics, and machine learning, these are of particular interest for data mining since they utilize symbolic and interpretable representations. Symbolic solutions can provide a high degree of insight into the decision boundaries that exist in the data, and the logic underlying them. This aspect makes these predictive-mining techniques particularly attractive in commercial and industrial data-mining applications. We present here a synopsis of some major state-of-the-art tree and rule mining methodologies, as well as some recent advances.	RUTGERS STATE UNIV,DEPT COMP SCI,NEW BRUNSWICK,NJ 08903	Apte, C (reprint author), IBM CORP,DIV RES,THOMAS J WATSON RES CTR,POB 218,YORKTOWN HTS,NY 10598, USA.						APTE C, 1995, ADV KNOWLEDGE DISCOV, P541; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; BREIMAN L, 1984, CLASSIFICATIONS REGR; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W., 1995, P 12 INT C MACH LEAR, P115; CRAVEN M, 1997, USING NEURAL NETWORK; FAYYAD U, 1995, ADV KNOWLEDGE DISCOV, P471; Fayyad U.M., 1995, ADV KNOWLEDGE DISCOV; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HONG SJ, 1997, IN PRESS IEEE T KNOW; HOSKING J, 1997, FUTURE GENERATION CO; James M., 1985, CLASSIFICATION ALGOR; KONONENKO I, 1997, FUTURE GENERATION CO; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Mehta M., 1996, P 5 INT C EXT DAT TE; MICHALSKI R, 1986, P AAAI, V86, P1041; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; Quinlan JR, 1993, P 10 INT C MACH LEAR, P236; Ripley B., 1996, PATTERN RECOGNITION; RISSANAN J, 1989, WORLD SCI SERIES COM, P15; Scheffe H, 1959, ANAL VARIANCE; SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926; Taylor C.C., 1994, MACHINE LEARNING NEU; WEISS SM, 1993, IEEE EXPERT, V8, P61, DOI 10.1109/64.248354; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	28	51	60	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-739X		FUTURE GENER COMP SY	Futur. Gener. Comp. Syst.	NOV	1997	13	2-3					197	210		10.1016/S0167-739X(97)00021-6		14	Computer Science, Theory & Methods	Computer Science	YJ828	WOS:A1997YJ82800008	
J	Craven, MW; Shavlik, JW				Craven, MW; Shavlik, JW			Using neural networks for data mining	FUTURE GENERATION COMPUTER SYSTEMS			English	Article						machine learning; neural networks; rule extraction; comprehensible models; decision trees; perceptrons		Neural networks have been successfully applied in a wide range of supervised and unsupervised learning applications. Neural-network methods are not commonly used for data-mining tasks, however, because they often produce incomprehensible models and require long training times. In this article, we describe neural-network learning algorithms that are able to produce comprehensible models, and that do not require excessive training times. Specifically, we discuss two classes of approaches for data mining with neural networks. The first type of approach, often called rule extraction, involves extracting symbolic models from trained neural networks. The second approach is to directly learn simple, easy-to-understand networks. We argue that, given the current state-of-the-art, neural-network methods deserve a place in the tool boxes of data-mining specialists.	UNIV WISCONSIN,DEPT COMP SCI,MADISON,WI 53706	Craven, MW (reprint author), CARNEGIE MELLON UNIV,SCH COMP SCI,5000 FORBES AVE,PITTSBURGH,PA 15213, USA.						ANDREWS R, 1995, KNOWLEDGE BASED SYST, V8; Bishop C., 1996, NEURAL NETWORKS PATT; Breiman L, 1984, CLASSIFICATION REGRE; Craven M.W., 1993, P 10 INT C MACH LEAR, P73; Craven M.W., 1996, THESIS U WISCONSIN M; CRAVEN MW, 1996, ADV NEURAL INFORMATI, V8; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FU LM, 1991, 9TH P NAT C ART INT, P590; Gallant S. I., 1993, NEURAL NETWORK LEARN; GILES CL, 1992, NEURAL COMPUT, V4, P393, DOI 10.1162/neco.1992.4.3.393; JACKSON J, 1996, ADV NEURAL INFORMATI, V8; Kohonen Teuvo, 1995, SELF ORG MAPS; Lawrence S., 1997, NEURAL NETWORKS CAPI; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; SAITO K, 1988, P IEEE INT C NEURAL, P255; SETHI IK, 1994, PATTERN RECOGNITION, V4; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; THRUN S, 1995, ADV NEURAL INFORMATI, V7; TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1007/BF00993103; WIDROW B, 1994, COMMUN ACM, V37, P93, DOI 10.1145/175247.175257	21	51	53	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-739X		FUTURE GENER COMP SY	Futur. Gener. Comp. Syst.	NOV	1997	13	2-3					211	229		10.1016/S0167-739X(97)00022-8		19	Computer Science, Theory & Methods	Computer Science	YJ828	WOS:A1997YJ82800009	
J	Lee, DH; Kim, MH				Lee, DH; Kim, MH			Database summarization using fuzzy ISA hierarchies	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						data mining; fuzzy set application; summary discovery		Summ. discovery is one of the major components of knowledge discovery in databases, which provides the user with comprehensive information for grasping the essence from a large amount of information in a database. In this paper, we propose an interactive top-down summary discovery process which utilizes fuzzy ISA hierarchies as domain knowledge. We define a generalized tuple as a representational form of a database summary including fuzzy concepts. By virtue of fuzzy ISA hierarchies where fuzzy ISA relationships common in actual domains are naturally expressed, the discovery process comes up with more accurate database summaries, We also present an informativeness measure for distinguishing generalized tuples that delivers much information to users, based on Shannon's information theory.	KOREA ADV INST SCI & TECHNOL,DEPT COMP SCI,TAEJON 305701,SOUTH KOREA	Lee, DH (reprint author), CHONNAM NATL UNIV,DEPT COMP SCI,KWANGJU,SOUTH KOREA.						COHEN P, 1982, HDB ARTIFICIAL INTEL, V3, P411; Frawley W. J., 1991, Knowledge discovery in databases; Han J., 1992, 18TH P INT C VER LAR, P547; KLIR GJ, 1988, FUZZY SETS UNCERTAIN, P260; LEE DH, 1994, P 10 INT C DAT ENG, P223; LEE DH, 1993, INFORM SYST, V18, P363, DOI 10.1016/0306-4379(93)90013-Q; SHANNON CE, 1948, AT&T TECH J, V27, P379; Ullman J. D., 1988, PRINCIPLES DATABASE; Yager R. R., 1991, Knowledge discovery in databases; Zadeh L.A., 1972, J CYBERNETICS, V2, P4; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zimmermann H. J., 1985, FUZZY SET THEORY ITS; *ISO, 1992, 9075 ISO	13	51	51	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	FEB	1997	27	1					68	78				11	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	WD892	WOS:A1997WD89200006	
J	Kao, YT; Zahara, E; Kao, IW				Kao, Yi-Tung; Zahara, Erwie; Kao, I-Wei			A hybridized approach to data clustering	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data clustering; K-means clustering; Nelder-Mead simplex search method; Particle swarm optimization	PARTICLE SWARM OPTIMIZATION; FUNCTION MINIMIZATION; GLOBAL OPTIMIZATION; GENETIC ALGORITHMS; SIMPLEX-METHOD; SEARCH	Data clustering helps one discern the structure of and simplify the complexity of massive quantities of data. It is a common technique for statistical data analysis and is used in many fields, including machine learning, data mining, pattern recognition, image analysis, and bioinformatics, in which the distribution of information can be of any size and shape. The well-known K-means algorithm, which has been successfully applied to many practical clustering problems, suffers from several drawbacks due to its choice of initializations. A hybrid technique based on combining the K-means algorithm, Nelder-Mead simplex search, and particle swarm optimization, called K-NM-PSO, is proposed in this research. The K-NM-PSO searches for cluster centers of an arbitrary data set as does the K-means algorithm, but it can effectively and efficiently find the global optima. The new K-NM-PSO algorithm is tested on nine data sets, and its performance is compared with those of PSO, NM-PSO, K-PSO and K-means clustering. Results show that K-NM-PSO is both robust and suitable for handling data clustering. (C) 2007 Elsevier Ltd. All rights reserved.	[Kao, Yi-Tung] Tatung Univ, Dept Comp Sci & Engn, Taipei 104, Taiwan; [Zahara, Erwie; Kao, I-Wei] St Johns Univ, Dept Ind Engn & Management, Tamsui 251, Taiwan	Zahara, E (reprint author), Tatung Univ, Dept Comp Sci & Engn, Taipei 104, Taiwan.	erwi@mail.sju.edu.tw					Bandyopadhyay S, 2002, INFORM SCIENCES, V146, P221, DOI 10.1016/S0020-0255(02)00208-6; Chen C.-Y., 2004, P IEEE INT C NETW SE, P789; Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P94, DOI 10.1109/CEC.2001.934376; Fan SKS, 2004, ENG OPTIMIZ, V36, P401, DOI 10.1080/0305215041000168521; HOOKE R, 1961, J ACM, V8, P212, DOI 10.1145/321062.321069; Hu X, 2001, P WORKSH PART SWARM; KAUFMAN L, 1990, FINGING GROUPS DATA; Kennedy J, 1995, P IEEE INT C NEUR NE, V4, DOI DOI 10.1109/ICNN.1995.488968; Murthy CA, 1996, PATTERN RECOGN LETT, V17, P825, DOI 10.1016/0167-8655(96)00043-8; NELDER JA, 1965, COMPUT J, V7, P308; OLSSON DM, 1975, TECHNOMETRICS, V17, P45, DOI 10.2307/1267998; Paterlini S, 2006, COMPUT STAT DATA AN, V50, P1220, DOI 10.1016/j.csda.2004.12.004; Renders JM, 1996, IEEE T SYST MAN CY B, V26, P243, DOI 10.1109/3477.485836; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; SPENDLEY W, 1962, TECHNOMETRICS, V4, P441, DOI 10.2307/1266283; Yen J, 1998, IEEE T SYST MAN CY B, V28, P173, DOI 10.1109/3477.662758	16	50	54	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2008	34	3					1754	1762		10.1016/j.eswa.2007.01.028		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	262YB	WOS:000253183700017	
J	Handl, J; Knowles, J; Dorigo, M				Handl, J; Knowles, J; Dorigo, M			Ant-based clustering and topographic mapping	ARTIFICIAL LIFE			English	Article						ant-based heuristic; ant-based clustering and sorting; clustering; topographic mapping; swarm intelligence	ALGORITHMS	Ant-based clustering and sorting is a nature-inspired heuristic first introduced as a model for explaining two types of emergent behavior observed in real ant colonies. More recently, it has been applied in a data-mining context to perform both clustering and topographic mapping. Early work demonstrated some promising characteristics of the heuristic but did not extend to a rigorous investigation of its capabilities. We describe an improved version, called ATTA, incorporating adaptive, heterogeneous ants, a time-dependent transporting activity, and a method (for Clustering applications) that transforms the spatial embedding produced by the algorithm into an explicit partitioning. ATTA is then subjected to the most rigorous experimental evaluation of an ant-based clustering and sorting algorithm undertaken to date: we compare its performance with standard techniques for clustering and topographic mapping using a set of analytical evaluation functions and a range of synthetic and real data collections. Our results demonstrate the ability of ant-based clustering and sorting to automatically identify the number of clusters inherent in a data collection, and to produce high quality solutions; indeed, we show that it is particularly robust for clusters of differing sizes and for overlapping clusters. The results obtained for topographic mapping are, however, disappointing. We provide evidence that the Solutions generated by the ant algorithm arc barely topology-preserving, and we explain in detail why results have-in spite of this-been misinterpreted (much more positively) in previous research.	Univ Manchester, Sch Chem, Manchester M60 1QD, Lancs, England; Univ Libre Brussels, IRIDIA, B-1050 Brussels, Belgium	Handl, J (reprint author), Univ Manchester, Sch Chem, POB 88,Sackville St, Manchester M60 1QD, Lancs, England.	j.handl@postgrad.manchester.ac.uk; j.knowles@manchester.ac.uk; mdorigo@ulb.ac.be	Dorigo, Marco/B-5664-2013	Dorigo, Marco/0000-0002-3971-0507			Blake C, 1998, UCI REPOSITORY MACHI; Bonabeau E., 1999, SWARM INTELLIGENCE N; CARREIRAPERPINA.M, 2001, THESIS U SHEFFIELD; Deneubourg J., 1991, P 1 INT C SIM AD BEH, V1, P356; Dorigo M, 2004, ANT COLONY OPTIMIZATION, P1, DOI 10.1007/b99492; Dorigo M, 1999, ARTIF LIFE, V5, P137, DOI 10.1162/106454699568728; Dorigo M, 2000, FUTURE GENER COMP SY, V16, P851, DOI 10.1016/S0167-739X(00)00042-X; Dorigo Marco, 1999, NEW IDEAS OPTIMIZATI, P11; Halkidi M, 2000, LECT NOTES COMPUT<D>, V1910, P265; Handl J., 2002, LNCS, V2439, P913; Handl J., 2003, THESIS U ERLANGEN NU; Handl J, 2004, LECT NOTES ARTIF INT, V2977, P90; Handl J, 2003, FR ART INT, V104, P204; Hoe K, 2002, LNCS, V2463, P256; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kohonen Teuvo, 1995, SELF ORG MAPS; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; Kuntz P., 1998, J HEURISTICS, V5, P327; KUNTZ P, 1994, P 3 INT C SIM AD BEH, V3, P494; Kuntz P., 1997, P 4 EUR C ART LIF, P417; Kuntz P., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.782654; LUMER E, 1999, UNPUB SWARM INTELLIG; Lumer E. D., 1994, P 3 INT C SIM AD BEH, V3, P501; MacQueen L., 1967, P 5 BERK S MATH STAT, P281; MARTIN IV, 2002, GENOME BIOL, V3, P7; MONMARCHE N, 2000, THESIS U TOURS FRANC; Ramos V., 2002, P 1 SPAN C EV BIOINS, P284; RIJSBERGEN CJV, 1979, INFORMATION RETRIEVA; TIBSHIRANI R, 2000, 208 STANF U DEP STAT; VESANTO A, 2000, A57 HELS U TECHN NEU; Vorhees E., 1985, THESIS CORNELL U ITH; WEISSTEIN EW, 1999, BOX WHISKER PLOT	32	50	53	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	1064-5462		ARTIF LIFE	Artif. Life	WIN	2006	12	1					35	61		10.1162/106454606775186400		27	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	000TB	WOS:000234484200003	
J	Cannataro, M; Congiusta, A; Pugliese, A; Talia, D; Trunfio, P				Cannataro, M; Congiusta, A; Pugliese, A; Talia, D; Trunfio, P			Distributed data mining on grids: Services, tools, and applications	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						grid computing; grid programming; grid scheduling; knowledge grid; data mining		Data mining algorithms are widely used today for the analysis of large corporate and scientific datasets stored in databases and data archives. Industry, science, and commerce fields often need to analyze very large datasets maintained over geographically distributed sites by using the computational power of distributed and parallel systems. The grid can play a significant role in providing an effective computational support for distributed knowledge discovery applications. For the development of data mining applications on grids we designed a system called KNOWLEDGE GRID. This paper describes the KNOWLEDGE GRID framework and presents the toolset provided by the KNOWLEDGE GRID for implementing distributed knowledge discovery. The paper discusses how to design and implement data mining applications by using the KNOWLEDGE GRID tools starting from searching grid resources, composing software and data components, and executing the resulting data mining process on a grid. Some performance results are also discussed.	Univ Catanzaro, I-88100 Catanzaro, Italy; Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Cannataro, M (reprint author), Univ Catanzaro, I-88100 Catanzaro, Italy.	cannataro@unicz.it; congiusta@si.deis.unical.it; apugliese@si.deis.unical.it; talia@si.deis.unical.it; trunfio@si.deis.unical.it	Talia, Domenico/F-8853-2010; Cannataro, Mario/B-1503-2012; Trunfio, Paolo/A-1274-2011	Cannataro, Mario/0000-0003-1502-2387; Trunfio, Paolo/0000-0002-5076-6544			ABRAHAM A, 2000, P IEEE 8 INT C ADV C; ARNOLD D, 2002, CONCUR COMPUT; AVERY P, 2001, GRIPHYN PROJECT DESC; BERMAN F, 2001, COMMUNICATION    NOV; Berman F, 2001, COMMUN ACM, V44, P27, DOI 10.1145/384150.384156; CANNATARO A, 2002, P C DAT MIN BOL IT; Cannataro M, 2003, LECT NOTES COMPUT SC, V2840, P619; Cannataro M., 2003, P 1 INT WORKSH SEM P, P113; Cannataro M, 2003, COMMUN ACM, V46, P89, DOI 10.1145/602421.602425; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV, p61 ; Chervenak A., 2001, J NETW COMPUT APPL, V23, P187; Clifton C., 2002, ACM SIGKDD EXPLORATI, V4, P28, DOI 10.1145/772862.772867; DAIL H, 2002, UCSD; Foster I, 1997, INT J SUPERCOMPUT AP, V11, P115, DOI 10.1177/109434209701100205; FOSTER I, 2000, BUILDING GRID INTEGR; Garey M. R., 1979, COMPUTERS INTRACTABI; Globus Project, GLOB RES SPEC LANG R; GU Y, UNPUB IEEE COMMUN LE; GUO Y, 2002, DISCOVERY NET; HINKE T, 2000, P 9 IEEE INT S HIGH; JOHNSTON WE, 2002, IN PRESS FUTURE GENE; Kargupta H., 2000, ADV DISTRIBUTED PARA; KESSELMAN C., 2001, INT J SUPERCOMPUT AP, V15, P3; Kwok Y.-K., 1999, ACM COMPUT SURV, V31; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; MIKA M, 2003, GRID RESOURCE MANAGE; Morita Y, 2001, PROCEEDINGS OF CHEP 2001, P699; ORLANDO S, 2002, EUROPAR; SIEGEL HJ, 2000, J SYST ARCHITECT, V46; Stockinger K., 2000, P 1 IEEE ACM INT WOR, P77; TANGMUNARUNKIT H, P 1 INT WORKSH SEM P, P85; WOLSKI R, 1999, FUTURE GENER COMPUT, V15; *GLOB PROJ, MON DISC SERV; *GLOB PROJ, GLOB RES ALL MAN; *GLOB PROJ, GLOB REPL CAT; *GLOB PROJ, GLOB REPL MAN API; *GLOB PROJ, GLOB HEARTB MON SPEC; *GLOB PROJ, DYN UPD REQ ONL COAL; *GLOB PROJ, GRIDFTP PROT; *GLOB PROJ, GRID SEC INFR	40	50	54	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	DEC	2004	34	6					2451	2465		10.1109/TSMCB.2004.836890		15	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	871YM	WOS:000225172500023	
J	Fayyad, U; Uthurusamy, R				Fayyad, U; Uthurusamy, R			Evolving data mining into solutions for insights - Introduction	COMMUNICATIONS OF THE ACM			English	Article									DigiMine Inc, Seattle, WA USA; GM Corp, Emerging Technol Informat Syst & Serv Div, Detroit, MI 48202 USA	Fayyad, U (reprint author), DigiMine Inc, Seattle, WA USA.						Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FAYYAD UM, 2002, INFORMATION VISUALIZ; Han J., 2000, DATA MINING CONCEPTS; Hand D. J., 2001, PRINCIPLES DATA MINI; PORTER J, DISK TREND 1998 REPO; Tukey J.W., 1977, EXPLORATORY DATA ANA	6	50	55	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0001-0782		COMMUN ACM	Commun. ACM	AUG	2002	45	8					28	31				4	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	577XC	WOS:000177087200010	
J	Guo, Q; Wu, W; Massart, DL; Boucon, C; de Jong, S				Guo, Q; Wu, W; Massart, DL; Boucon, C; de Jong, S			Feature selection in principal component analysis of analytical data	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						feature selection; principal component analysis; genetic algorithm; generalised procrustes analysis; data mining; gas chromatography	GENETIC ALGORITHMS; LIQUID-CHROMATOGRAPHY; VARIABLES	A feature selection method is proposed to select a subset of variables in principal component analysis (PCA) that preserves as much information present in the complete data as possible, The information is measured by means of the percentage of consensus in generalised Procrustes analysis. The best subset of variables is obtained by applying a genetic algorithm (GA) to optimise the consensus between the subset and the complete data set in order to avoid exhaustive searching. The method was evaluated on a standard data set known as the Alate data, and on a high-dimensional industrial gas chromatography (GC) data set. The results showed that the proposed method successfully identified structure-bearing variables in both data sets and that it leads to a better subset of variables than other studied feature selection methods. (C) 2002 Elsevier Science B.V. All rights reserved.	Free Univ Brussels, Inst Pharmaceut, ChemoAC, B-1090 Brussels, Belgium; SmithKline Beecham Pharmaceut, Safety Assessment, Welwyn Garden City AL6 9AR, Herts, England; Unilever Res Labs Vlaardingen, NL-3133 AT Vlaardingen, Netherlands	Massart, DL (reprint author), Free Univ Brussels, Inst Pharmaceut, ChemoAC, Laarbeeklaan 103, B-1090 Brussels, Belgium.						BUNCH JR, 1978, NUMER MATH, V31, P31, DOI 10.1007/BF01396012; BUNCH JR, 1978, NUMER MATH, V31, P111, DOI 10.1007/BF01397471; Czarnik AW, 1998, ANAL CHEM, V70, p378A; Dijksterhuis G., 1990, FOOD QUAL PREFER, V2, P255, DOI 10.1016/0950-3293(90)90017-O; Dijksterhuis GB, 1995, FOOD QUAL PREFER, V6, P263, DOI 10.1016/0950-3293(95)00025-9; Dijksterhuis GB, 1991, FOOD QUAL PREFER, V3, P67, DOI 10.1016/0950-3293(91)90027-C; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478; Guo Q, 2000, ANAL CHEM, V72, P2846, DOI 10.1021/ac0000123; Guo Q, 2001, ANAL CHIM ACTA, V446, P85, DOI 10.1016/S0003-2670(01)01000-5; JEFFERS J.N., 1967, APPLIED STATISTICS, V16, P225, DOI 10.2307/2985919; Jolliffe I., 1973, APPL STATIST, V22, P21, DOI 10.2307/2346300; Jolliffe I., 1986, PRINCIPAL COMPONENT; JOLLIFFE IT, 1972, J ROY STAT SOC C-APP, V21, P160; KRZANOWSKI WJ, 1987, APPL STAT-J ROY ST C, V36, P22, DOI 10.2307/2347842; LEARDI R, 1992, J CHEMOMETR, V6, P267, DOI 10.1002/cem.1180060506; LUCASIUS CB, 1993, CHEMOMETR INTELL LAB, V19, P1, DOI 10.1016/0169-7439(93)80079-W; Malinowski E. R., 1991, FACTOR ANAL CHEM; MALINOWSKI ER, 1982, ANAL CHIM ACTA, V134, P129, DOI 10.1016/S0003-2670(01)84184-2; MCCABE GP, 1984, TECHNOMETRICS, V26, P137, DOI 10.2307/1268108; RANNAR S, 1996, THESIS UMEA U SWEDEN; VANHUFFEL S, 1987, LINEAR ALGEBRA APPL, V88-9, P695, DOI 10.1016/0024-3795(87)90130-3; WARREN FV, 1987, ANAL CHEM, V59, P1897, DOI 10.1021/ac00142a003; WARREN FV, 1987, ANAL CHEM, V59, P1890, DOI 10.1021/ac00142a002; WOLD S, 1978, TECHNOMETRICS, V20, P397, DOI 10.2307/1267639	25	50	55	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	FEB 28	2002	61	1-2					123	132		10.1016/S0169-7439(01)00203-9		10	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	530KM	WOS:000174356900009	
S	Saeed, M; Lieu, C; Raber, G; Mark, RG		Murray, A		Saeed, M; Lieu, C; Raber, G; Mark, RG			MIMIC II: A massive temporal ICU patient database to support research in intelligent patient monitoring	COMPUTERS IN CARDIOLOGY 2002, VOL 29	COMPUTERS IN CARDIOLOGY		English	Proceedings Paper	29th Annual Conference on Computers in Cardiology	SEP 22-25, 2002	MEMPHIS, TN					Development and evaluation of Intensive Care Unit (ICU) decision-support systems would be greatly facilitated by the availability of a large-scale ICU patient database. Following our previous efforts with the MIMIC (Multi-parameter Intelligent Monitoring for Intensive Care) Database, we have leveraged advances in networking and storage technologies to develop a far more massive temporal database, MIMIC II. MIMIC II is an ongoing effort: data is continuously and prospectively archived from all ICU patients in our hospital. MIMIC II now consists of over 800 ICU patient records including over 120 gigabytes of data and is growing. A customized archiving system was used to store continuously up to four waveforms and 30 different parameters from ICU patient monitors. An integrated user-friendly relational database was developed for browsing of patients' clinical information (lab results, fluid balance, medications, nurses' progress notes). Based upon its unprecedented size and scope, MIMIC H will prove to be an important resource for intelligent patient monitoring research, and will support efforts in medical data mining and knowledge-discovery.	Harvard Univ, MIT, Cambridge, MA 02139 USA	Saeed, M (reprint author), Harvard Univ, MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.						GREENSPUN P, PHIL ALEXS GUIDE WEB; Moody G.B., 1996, COMPUT CARDIOL, V23, P657; SAEED M, 2001, P COMPUTERS CARDIOLO; *AG TECHN, 2000, CAR CLIN DAT MAN INF	4	50	53	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0276-6574	0-7803-7735-4	COMPUT CARDIOL			2002	29						641	644				4	Engineering, Biomedical; Engineering, Electrical & Electronic; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Radiology, Nuclear Medicine & Medical Imaging	BW27D	WOS:000181394600163	
J	Nasukawa, T; Nagano, T				Nasukawa, T; Nagano, T			Text analysis and knowledge mining system	IBM SYSTEMS JOURNAL			English	Article								Large text databases potentially contain a great wealth of knowledge. However, text represents factual information (and information about the author's communicative intentions) in a complex, rich, and opaque manner. Consequently, unlike numerical and fixed field data, it cannot be analyzed by standard statistical data mining methods. Relying on human analysis results in either huge workloads or the analysis of only a tiny fraction of the database. We are working on text mining technology to extract knowledge from very large amounts of textual data. Unlike information retrieval technology that allows a user to select documents that meet the user's requirements and interests, or document clustering technology that organizes documents, we focus on finding valuable patterns and rules in text that indicate trends and significant features about specific topics. By applying our prototype system named TAKMI (Text Analysis and Knowledge Mining) to textual databases in PC help centers, we can automatically detect product failures; determine issues that have led to rapid increases in the number of calls and their underlying reasons; and analyze help center productivity and changes in customers' behavior involving a particular product, without reading any of the text. We have verified that our framework is also effective for other data such as patent documents.	IBM Corp, Div Res, Tokyo Res Lab, Kanagawa, Japan	Nasukawa, T (reprint author), IBM Corp, Div Res, Tokyo Res Lab, 1623-14 Shimotsuruma, Kanagawa, Japan.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Lent B., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Cohen W. W., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Feldman R., 1995, P 1 INT C KNOWL DISC, P112; Feldman R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Hahn U., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Hatzivassiloglou V., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640; HEARST AM, 1999, P ACL 99, P3; MARUYAMA H, 1995, FORMAL APPROACH JAPA; MATSUZAWA H, 2000, P 4 PAC AS INT C KNO, P233; Mladenic D, 1999, IEEE INTELL SYST APP, V14, P44, DOI 10.1109/5254.784084; MOROHASHI M, 1995, P INT S DIG LIB, P151; NIGHT K, 1999, COMMUN ACM, V42, P58; NOMIYAMA H, 1996, TR0129 IBM TOK RES L; PAZIENZA MT, 1997, LECT NOTES ARTIFICIA; SALTON G, 1983, SMART SIRE EXPT RETR; Xia P., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zamir O., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	18	50	51	IBM CORP	ARMONK	OLD ORCHARD RD, ARMONK, NY 10504 USA	0018-8670		IBM SYST J	IBM Syst. J.		2001	40	4					967	984				18	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	489WY	WOS:000172016500011	
J	Feldman, R; Dagan, I; Hirsh, H				Feldman, R; Dagan, I; Hirsh, H			Mining text using keyword distributions	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						data mining; text mining; text categorization; distribution comparison; trend analysis		Knowledge Discovery in Databases (KDD) focuses on the computerized exploration of large amounts of data and on the discovery of interesting patterns within them. While most work on KDD has been concerned with structured databases, there has been little work on handling the huge amount of information that is available only in unstructured textual form. This paper describes the KDT system for Knowledge Discovery in Text, in which documents are labeled by keywords, and knowledge discovery is performed by analyzing the co-occurrence frequencies of the various keywords labeling the documents. We show how this keyword-frequency approach supports a range of KDD operations, providing a suitable foundation for knowledge discovery and exploration for collections of unstructured text.	Bar Ilan Univ, Dept Math, Ramat Gan, Israel; Bar Ilan Univ, Dept Comp Sci, Ramat Gan, Israel; Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08855 USA	Feldman, R (reprint author), Bar Ilan Univ, Dept Math, Ramat Gan, Israel.						AGRAWAL R, P ACM SIGMOD C MAN D, P207; ANAND T, 1993, P 1993 WORKSH KNOWL; APTE C, 1994, P ACM SIGIR C INF RE; BRACHMAN R, 1993, INT J INTELLIGENT CO; Cover T. M., 1991, ELEMENTS INFORMATION; CUTTING C, 1993, P ACM SIGIR C INF RE; Dagan I., 1994, P 32 ANN M ASS COMP, P272, DOI 10.3115/981732.981770; DAGAN I, 1996, P 5 ANN S DOC AN INF; EZAWA K, 1995, P 1 INT C KNOWL DISC; FELDMAN R, 1996, IN PRESS P PAP 96 LO; FELDMAN R, IN PRESS P 9 INT S M; FELDMAN R, 1996, P 4 C APPL NAT LANG; FELDMAN R, 1995, P 1 INT C KNOWL DISC; Frawley W. J., 1991, Knowledge discovery in databases; Han J, 1995, P 21 INT C VER LARG, P420; HEARST MA, 1995, P ACM SIGCHI C HUM F; IWAYAMA M, 1994, P 4 C APPL NAT LANG; JACOBS P, 1992, P 3 C APPL NAT LANG; KLOSGEN W, 1992, INT J INTELL SYST, V7, P649, DOI 10.1002/int.4550070707; KLOSGEN W, 1995, ADV KNOWLEDGE DISCOV, P2249; Klosgen W., 1995, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V4, DOI 10.1007/BF00962822; LEWIS D, 1992, P ACM SIGIR C INF RE; Lewis D.D., 1994, P 11 INT C MACH LEAR; MANNILA H, KDD 94 AAAI WORKSH K, P181; Salton G., 1989, AUTOMATIC TEXT PROCE; Srikant R., 1995, P 21 INT C VER LARG; TOIVONEN H, WORKS NOT STAT MACH; WILLIAMSON C, 1992, P ACM SIGIR	28	50	54	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	MAY-JUN	1998	10	3					281	300		10.1023/A:1008623632443		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	103GP	WOS:000075150000003	
J	Rowlands, I; Nicholas, D; Williams, P; Huntington, P; Fieldhouse, M; Gunter, B; Withey, R; Jamali, HR; Dobrowolski, T; Tenopir, C				Rowlands, Ian; Nicholas, David; Williams, Peter; Huntington, Paul; Fieldhouse, Maggie; Gunter, Barrie; Withey, Richard; Jamali, Hamid R.; Dobrowolski, Tom; Tenopir, Carol			The Google generation: the information behaviour of the researcher of the future	ASLIB PROCEEDINGS			English	Article						students; information retrieval; young adults; internet	LITERACY	Purpose - This article is an edited version of a report commissioned by the British Library and JISC to identify how the specialist researchers of the future (those born after 1993) are likely to access and interact with digital resources in five to ten years' time. The purpose is to investigate the impact of digital transition on the information behaviour of the Google Generation and to guide library and information services to anticipate and react to any new or emerging behaviours in the most effective way. Design/methodology/approach - The study was virtually longitudinal and is based on a number of extensive reviews of related literature, survey data mining and a deep log analysis of a British Library and a JISC web site intended for younger people. Findings - The study shows that much of the impact of ICTs on the young has been overestimated. The study claims that although voting people demonstrate an apparent ease and familiarity with computers, they rely heavily on search engines, view rather than read and do not possess the critical and analytical skills to assess the information that they find oil the web, Originality/value - The paper reports on a study that overturns the common assumption that the "Google generation" is the most web-literate.	[Rowlands, Ian; Nicholas, David; Williams, Peter; Huntington, Paul; Fieldhouse, Maggie] UCL, Sch Lib Arch & Informat Studies, CIBER, London, England; [Gunter, Barrie] Univ Leicester, Dept Media & Commun, Leicester, Leics, England; [Withey, Richard] CIBER Associate, London, England; [Withey, Richard] Independent News & Media Grp, London, England; [Jamali, Hamid R.] Tarbiat Moallem Univ, Dept Educ Technol, Fac Psychol & Educ, Tehran, Iran; [Dobrowolski, Tom] Univ Warsaw, Inst Informat Sci, Warsaw, Poland; [Tenopir, Carol] Univ Tennessee, Sch Informat Sci, Knoxville, TN USA	Rowlands, I (reprint author), UCL, Sch Lib Arch & Informat Studies, CIBER, London, England.	i.rowlands@ucl.ac.uk	Jamali, Hamid R./C-4239-2008; van Lent, Laurence/G-5298-2010; Rowlands, Ian/A-3519-2012	Jamali, Hamid R./0000-0003-1232-6473; van Lent, Laurence/0000-0002-9354-0932; Rowlands, Ian/0000-0001-8831-540X	British Library; JISC	The authors would like to register their gratitude to the British Library and JISC for funding the study.	Frand J.L., 2000, EDUCAUSE REV, V35, P15; GREENEMEIER L, 2007, SCI AM          1005; Gross M, 2007, LIBR INFORM SCI RES, V29, P332, DOI 10.1016/j.lisr.2007.04.012; Horrigan J. B., 2007, TYPOLOGY INFORM COMM; Large A., 2006, ANNU REV INFORM SCI, V39, P347; Lippincott J.K., 2005, EDUCAUSE REV, V40, P56; Long S. A., 2005, New Library World, V106, DOI 10.1108/03074800510587381; Merchant L, 2002, J LIBR INF SCI, V34, P81, DOI 10.1177/096100060203400203; NAUGHTON J, 2008, THANKS GUTENBERG WER; NICHOLAS D, 2008, DIGITAL CONSUMERS; OBLINGER DG, 2006, EDUCAUSE REV, V41, P12; OCLC, 2006, COLL STUD PERC LIB I; OCLC, 2007, SHAR PRIV TRUST OUR; Ofcom, 2007, COMM MARK REP CONV C; Williams P., 2007, INFORM BEHAV RES FUT; *CIBER, 2007, INF BEH RES FUT CAS; *SYN, 2007, LEIS TIM CLEAN LIV Y	17	49	50	EMERALD GROUP PUBLISHING LIMITED	BINGLEY	HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND	0001-253X		ASLIB PROC	Aslib Proc.		2008	60	4					290	310		10.1108/00012530810887953		21	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	348IE	WOS:000259203400002	
J	Lariviere, B; Van den Poel, D				Lariviere, B; Van den Poel, D			Predicting customer retention and profitability by using random forests and regression forests techniques	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; customer relationship management; customer retention and profitability; random forests and regression forests	LONG-LIFE CUSTOMERS; FINANCIAL SERVICES; IMPACT; SEGMENTATION; SATISFACTION; PROVIDERS; MODEL; BASE	In an era of strong customer relationship management (CRM) emphasis, firms strive to build valuable relationships with their existing customer base. In this study, we attempt to better understand three important measures of customer outcome: next buy, partial-defection and customers' profitability evolution. By means of random forests techniques we investigate a broad set of explanatory variables, including past customer behavior, observed customer heterogeneity and some typical variables related to intermediaries. We analyze a real-life sample of 100,000 customers taken from the data warehouse of a large European financial services company. Two types of random forests techniques are employed to analyze the data: random forests are used for binary classification, whereas regression forests are applied for the models with linear dependent variables. Our research findings demonstrate that both random forests techniques provide better fit for the estimation and validation sample compared to ordinary linear regression and logistic regression models. Furthermore, we find evidence that the same set of variables have a different impact on buying versus defection versus profitability behavior. Our findings suggest that past customer behavior is more important to generate repeat purchasing and favorable profitability evolutions, while the intermediary's role has a greater impact on the customers' defection proneness. Finally, our results demonstrate the benefits of analyzing different customer outcome variables simultaneously, since an extended investigation of the next buy-partial-defection-customer profitability triad indicates that one cannot fully understand a particular outcome without understanding the other related behavioral outcome variables. (C) 2005 Elsevier Ltd. All rights reserved.	State Univ Ghent, Dept Mkt, B-9000 Ghent, Belgium	Lariviere, B (reprint author), State Univ Ghent, Dept Mkt, Hoveniersberg 24, B-9000 Ghent, Belgium.	bart.lariviere@ugent.be					Athanassopoulos AD, 2000, J BUS RES, V47, P191, DOI 10.1016/S0148-2963(98)00060-5; Baesens B, 2004, EUR J OPER RES, V156, P508, DOI [10.1016/S0377-2217(03)00043-2, 10.1016/s0377-2217(03)00043-2]; Baesens B, 2002, EUR J OPER RES, V138, P191, DOI 10.1016/S0377-2217(01)00129-1; Bhattacharya CB, 1998, J ACAD MARKET SCI, V26, P31, DOI 10.1177/0092070398261004; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buckinx W, 2005, EUR J OPER RES, V164, P252, DOI 10.1016/j.ejor.2003.12.010; Colgate MR, 2000, J ACAD MARKET SCI, V28, P375, DOI 10.1177/0092070300283006; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Deng Y. P., 2004, BMC BIOINFORMATICS, V5, P1; Duda R.O., 2001, PATTERN CLASSIFICATI; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; GANESAN S, 1994, J MARKETING, V58, P1, DOI 10.2307/1252265; Ganesh J, 2000, J MARKETING, V64, P65, DOI 10.1509/jmkg.64.3.65.18028; Guenzi P, 2004, INT J SERV IND MANAG, V15, P365, DOI 10.1108/09564230410552059; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hoch SJ, 1999, MARKET SCI, V18, P527, DOI 10.1287/mksc.18.4.527; Hsieh NC, 2004, EXPERT SYST APPL, V27, P623, DOI 10.1016/j.eswa.2004.06.007; HUBER CP, 1998, MCKINSEY Q, P148; Hwang H, 2004, EXPERT SYST APPL, V26, P181, DOI 10.1016/S0957-4174(03)00133-7; Ishwaran H, 2004, J AM STAT ASSOC, V99, P591, DOI 10.1198/016214504000000638; Lariviere B, 2004, EXPERT SYST APPL, V27, P277, DOI 10.1016/j.eswa.2004.02.002; Lewis B. R., 1991, INT J BANK MARKETING, V9, P3, DOI 10.1108/02652329110001143; Luo T, 2004, IEEE T SYST MAN CY B, V34, P1753, DOI 10.1109/TSMCB.2004.830340; McNeal J. U, 1999, KIDS MARKET MYTHS RE; Patterson PG, 2003, J RETAILING, V79, P107, DOI 10.1016/S0022-4359(03)00009-5; Reinartz WJ, 2003, J MARKETING, V67, P77, DOI 10.1509/jmkg.67.1.77.18589; Reinartz WJ, 2000, J MARKETING, V64, P17, DOI 10.1509/jmkg.64.4.17.18077; Srivastava R.K., 1991, INT J RES MARK, V8, P329, DOI 10.1016/0167-8116(91)90030-B; Van den Poel D, 2004, EUR J OPER RES, V157, P196, DOI 10.1016/S0377-2217(03)00069-9; van Dolen W, 2002, J RETAILING, V78, P265, DOI 10.1016/S0022-4359(02)00067-2	30	49	50	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2005	29	2					472	484		10.1016/j.eswa.2005.04.043		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	951RE	WOS:000230947400025	
J	Wild, S; Curry, J; Dougherty, A				Wild, S; Curry, J; Dougherty, A			Improving non-negative matrix factorizations through structured initialization	PATTERN RECOGNITION			English	Article						non-negative matrix factorization; k-means clustering; constrained optimization; rank reduction; data mining; compression; feature extraction	DECOMPOSITIONS	In this paper we explore a recent iterative compression technique called non-negative matrix factorization (NMF). Several special properties are obtained as a result of the constrained optimization problem of NMF. For facial images, the additive nature of NMF results in a basis of features, such as eyes, noses, and lips. We explore various methods for efficiently computing NMF, placing particular emphasis on the initialization of current algorithms. We propose using Spherical K-Means clustering to produce a structured initialization for NMF. We demonstrate some of the properties that result from this initialization and develop an efficient way of choosing the rank of the low-dimensional NMF representation. (C) 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Colorado, Dept Math Appl, Boulder, CO 80309 USA	Wild, S (reprint author), Cornell Univ, Sch Operat Res & Ind Engn, 283 Rhodes, Ithaca, NY 14853 USA.	stefan@orie.cornell.edu					Berry M.W., 1999, UNDERSTANDING SEARCH; Chu MT, 2002, SIAM J MATRIX ANAL A, V23, P1025, DOI 10.1137/S0895479800382555; CISI, 2002, CLASS DAT SET; DHILLON IS, 2002, WORKSH CLUST HIGH DI; DHILLON IS, 2001, EFFICIENT CLUSTERING; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; DING C, 2002, P ICDM 2002, P107; Golub G.H., 1996, MATRIX COMPUTATIONS; Hartigan J.A., 1975, CLUSTERING ALGORITHM; KAWAMOTO T, 2000, NEURAL NETW WORLD, V3, P429; Kolda TG, 1998, ACM T INFORM SYST, V16, P322, DOI 10.1145/291128.291131; Lawson C. L., 1974, SOLVING LEAST SQUARE; LEE DD, 2000, ADV NEURAL INFORMATI, V13, P556; Lee DD, 1997, ADV NEUR IN, V9, P515; Lee DD, 1999, NATURE, V401, P788; LI SZ, 2001, P IEEE INT C COMP VI; Saul LK, 2002, ADV NEUR IN, V14, P897; Wild S., 2003, THESIS U COLORADO	18	49	56	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	NOV	2004	37	11					2217	2232		10.1016/j.patcog.2004.02.013		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	848XI	WOS:000223501000009	
J	Hu, YC; Chen, RS; Tzeng, GH				Hu, YC; Chen, RS; Tzeng, GH			Finding fuzzy classification rules using data mining techniques	PATTERN RECOGNITION LETTERS			English	Article						data mining; fuzzy sets; classification problems; genetic algorithms	PATTERN-CLASSIFICATION; SYSTEMS	Data mining techniques can be used to discover useful patterns by exploring and analyzing data, so, it is feasible to incorporate data mining techniques into the classification process to discover useful patterns or classification rules from training samples. This paper thus proposes a data mining technique to discover fuzzy classification rules based on the well-known Apriori algorithm. Significantly, since it is difficult for users to specify the minimum fuzzy support used to determine the frequent fuzzy grids or the minimum fuzzy confidence used to determine the effective classification rules derived from frequent fuzzy grids, therefore the genetic algorithms are incorporated into the proposed method to determine those two thresholds with binary chromosomes. For classification generalization ability, the simulation results from the iris data and the appendicitis data demonstrate that the proposed method performs well in comparison with other classification methods. (C) 2002 Elsevier Science B.V. All rights reserved.	Natl Chiao Tung Univ, Inst Management Technol, Hsinchu 300, Taiwan; Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan	Tzeng, GH (reprint author), Natl Chiao Tung Univ, Inst Management Technol, Hsinchu 300, Taiwan.		Tzeng, Gwo-Hshiung/B-2775-2009				AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Anderson E., 1935, B AM IRIS SOC, V59, P2; Berry M. R. J., 1997, DATA MINING TECHNIQU; Chen SM, 1997, IEEE T SYST MAN CY B, V27, P714; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Grabisch M, 1992, P 2 INT C FUZZ LOG N, P659; Han J., 2001, DATA MINING CONCEPTS; Hong TP, 2001, INT J UNCERTAIN FUZZ, V9, P587, DOI 10.1142/S0218488501001071; Hu YC, 2002, COMPUT IND ENG, V43, P735, DOI 10.1016/S0360-8352(02)00136-5; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; Ishibuchi H, 1999, IEEE T SYST MAN CY B, V29, P601, DOI 10.1109/3477.790443; Ishibuchi H., 2001, P IEEE INT S IND EL, P118; Ishihara H, 2001, PROCEEDINGS OF THE 2000 INTERNATIONAL CONFERENCE ON EXCITONIC PROCESSES IN CONDENSED MATTER, P241, DOI 10.1109/ICDM.2001.989525; ISHIBUCHI H, 1992, FUZZY SET SYST, V52, P21, DOI 10.1016/0165-0114(92)90032-Y; JANG JSR, 1995, P IEEE, V83, P378, DOI 10.1109/5.364486; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Kosko B., 1992, NEURAL NETWORKS FUZZ; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768; Pedrycz W., 1998, INTRO FUZZY SETS ANA; ROOIJ AJF, 1996, NEURLA NETWORK TRAIN; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; ZIMMERMANN HJ, 1991, FUZZY SETS DECISION	27	49	51	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN	2003	24	1-3					509	519		10.1016/S0167-8655(02)00273-8		11	Computer Science, Artificial Intelligence	Computer Science	630KE	WOS:000180105400045	
J	Dittenbach, M; Rauber, A; Merkl, D				Dittenbach, M; Rauber, A; Merkl, D			Uncovering hierarchical structure in data using the growing hierarchical self-organizing map	NEUROCOMPUTING			English	Article; Proceedings Paper	8th European Symposium on Artificial Neural Networks (ESANN)	APR 26-28, 2001	BRUGGE, BELGIUM			self-organizing map (SOM); unsupervised hierarchical clustering; document classification; data mining; exploratory data analysis	TEXT RETRIEVAL	Discovering the inherent structure in data has become one of the major challenges in data mining applications. It requires stable and adaptive models that are capable of handling the typically very high-dimensional feature spaces. In particular, the representation of hierarchical relations and intuitively visible cluster boundaries are essential for a wide range of data mining applications. Current approaches based on neural networks hardly fulfill these requirements within a single model. In this paper we present the growing hierarchical self-organizing map (GHSOM), a neural network model based on the self-organizing map. The main feature of this novel architecture is its capability of growing both in terms of map size as well as in a three-dimensional tree-structure in order to represent the hierarchical structure present in a data collection during an unsupervised training process. This capability, combined with the stability of the self-organizing map for high-dimensional feature space representation, makes it an ideal tool for data analysis and exploration. We demonstrate the potential of the GHSOM with an application from the information retrieval domain, which is prototypical both of the high-dimensional feature spaces frequently encountered in today's applications as well as of the hierarchical nature of data. (C) 2002 Elsevier Science B.V. All rights reserved.	Vienna Univ Technol, Inst Software Technol, A-1040 Vienna, Austria	Rauber, A (reprint author), Vienna Univ Technol, Inst Software Technol, Favoritenstr 9-11-188, A-1040 Vienna, Austria.						Blackmore J., 1993, P IEEE INT C NEUR NE, V1, P450; Deboeck G.J., 1998, VISUAL EXPLORATIONS; Fritzke B, 1995, NEURAL PROCESS LETT, V2, P1; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kaski S., 1998, NEURAL COMPUTING SUR, V1, P1; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T., 1998, P ICANN98 8 INT C AR, V1, P65; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; Kohonen T., 1989, SELF ORG ASS MEMORY; KOHONOEN T, 1995, SELF ORG MAPS; KOIKKALAINEN P, 1995, P ICANN 95 INT C ART, V2, P63; Koikkalainen Pasi, 1990, P INT JOINT C NEUR N, VII, P279; LIN X, 1991, ACM SIGIR C RES DEV, P262; MERKL D, 2000, HDB NATURAL LANGUAGE, P889; Merkl D, 1998, NEUROCOMPUTING, V21, P61, DOI 10.1016/S0925-2312(98)00032-0; Merkl D., 1997, P WORKSH SELF ORG MA, P106; MERKL D, 1999, P INT JOINT C ART IN, P89; Miikkulainen R., 1990, Connection Science, V2; RAUBER A, 1999, LNCS LNAI, V1574, P228; Rauber A, 1999, LECT NOTES COMPUT SC, V1696, P323; Ripley B., 1996, PATTERN RECOGNITION; ROUSSINOV D, 1998, P 3 ACM C DIG LIB 23, P303, DOI 10.1145/276675.276746; Salton G., 1989, AUTOMATIC TEXT PROCE; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SIMULA O, 1999, IND APPL NEURAL NETW; TURTLE HR, 1992, COMPUT J, V35, P279, DOI 10.1093/comjnl/35.3.279; ULTSCH A, 1992, STUDIES CLASSIFICATI, P307	27	49	49	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	OCT	2002	48						199	216		10.1016/S0925-2312(01)00655-5		18	Computer Science, Artificial Intelligence	Computer Science	601TT	WOS:000178464600013	
J	Lin, FY; McClean, S				Lin, FY; McClean, S			A data mining approach to the prediction of corporate failure	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	20th SGES International Conference on Knowledge Based Systems and Applied Artificial Intelligence (ES2000)	DEC 11-13, 2000	CAMBRIDGE, ENGLAND	SGES, British Comp Soc		corporate failure; data mining; hybrid method	NEURAL NETWORKS; DISCRIMINANT-ANALYSIS; BANKRUPTCY; DISTRESS	This paper uses a data mining approach to the prediction of corporate failure. Initially, we use four single classifiers - discriminant analysis, logistic regression, neural networks and C5.0 - each based on two feature selection methods for predicting corporate failure. Of the two feature selection methods - human judgement based on financial theory and ANOVA statistical method - we found the ANOVA method performs better than the human judgement method in all classifiers except discriminant analysis. Among the individual classifiers, decision trees and neural networks were found to provide better results. Finally, a hybrid method that combines the best features of several classification models is developed to increase the prediction performance. The empirical tests show that such a hybrid method produces higher prediction accuracy than individual classifiers. (C) 2001 Elsevier Science B.V. All rights reserved.	Univ Ulster, Fac Informat, Coleraine BT52 1SA, Londonderry, North Ireland	Lin, FY (reprint author), Univ Ulster, Fac Informat, Coleraine BT52 1SA, Londonderry, North Ireland.						ALTMAN EI, 1994, J BANK FINANC, V18, P505, DOI 10.1016/0378-4266(94)90007-8; ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; Argenti J., 1976, CORPORATE COLLAPSE C, P5; BALL R, 1982, J ACCOUNTING RES, V20, P161, DOI 10.2307/2674681; Bierman H.J, 1970, MANAGE SCI, V16, P519, DOI 10.1287/mnsc.16.8.B519; BREIMAN JR, 1984, CLASSIFICATION REGRE, P18; Casey M., 1986, ACCOUNT REV      APR, P249; Clarke P., 1990, IRISH BUSINESS ADM R, V11, P40; CRASK MR, 1977, J MARKETING RES, V14, P60, DOI 10.2307/3151055; Dimitras AI, 1999, EUR J OPER RES, V114, P263, DOI 10.1016/S0377-2217(98)00255-0; ELMER PJ, 1988, FINANC MANAGE, V17, P66, DOI 10.2307/3666073; EZZAMUEL M, 1987, J BUSINESS FINANCE A, P519; FRYDMAN H, 1985, J FINANC, V40, P269, DOI 10.2307/2328060; Gupta Y.P., 1990, J BUSINESS FINANCE A, V17, P593; HELD G, 1997, P 8 INT S APPL STOCH, P155; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; KEASEY K, 1990, OMEGA-INT J MANAGE S, V18, P85, DOI 10.1016/0305-0483(90)90020-A; LACHER RC, 1995, EUR J OPER RES, V85, P53, DOI 10.1016/0377-2217(93)E0274-2; LAURENT CR, 1979, J BUSINESS FINANCE A, P401; LINCOLN M, 1984, J BANK FINANC, P321; Martin D., 1977, J BANK FINANC, V1, P249, DOI DOI 10.1016/0378-4266(77)90022-X; OHLSON JA, 1980, J ACCOUNTING RES, V18, P109, DOI 10.2307/2490395; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SALCHENBERGER LM, 1992, DECISION SCI, V23, P899, DOI 10.1111/j.1540-5915.1992.tb00425.x; SKOGSVIK K, 1990, J BUSINESS FINANCE A, V17, P137, DOI 10.1111/j.1468-5957.1990.tb00554.x; TAFFLER RJ, 1982, J ROYAL STAT SOC A 3, V124, P342; WATSON ID, 1995, THESIS U ULSTER; WEBB A, 1999, STAT PATTERN RECOGNI, P213; WELKER RB, 1974, ACCOUNT REV, V49, P514; WILSON RL, 1994, DECIS SUPPORT SYST, V11, P545, DOI 10.1016/0167-9236(94)90024-8; Zavgren CV, 1985, J BUSINESS FINANCE A, V12, P19, DOI 10.1111/j.1468-5957.1985.tb00077.x; Zopounidis C, 1999, EUR J OPER RES, V119, P404, DOI 10.1016/S0377-2217(99)00142-3	32	49	52	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	JUN	2001	14	3-4			SI		189	195		10.1016/S0950-7051(01)00096-X		7	Computer Science, Artificial Intelligence	Computer Science	440MX	WOS:000169180000010	
B	Meo, R; Psaila, G; Ceri, S		Vijayaraman, TM; Buchmann, A; Mohan, C; Sarda, NL		Meo, R; Psaila, G; Ceri, S			A new SQL-like operator for mining association rules	PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES			English	Proceedings Paper	22nd International Conference on Very Large Data Bases	SEP 03-06, 1996	MUMBAI, INDIA	Comp Soc India, VLDB Endowment India, Akshay Software Technol Ltd, Coromandel Software Ltd, Digital Equipment India Ltd, Fujitsu ICIM Ltd, Ind Dev Bank India, Informix Int Inc, Infosys Technol Ltd, Int Business Machines, Mastek Ltd, Natl Assoc Software & Serv Co, NIIT Ltd, Onward Novell Software India Ltd, Persistent Syst Pvt Ltd, Siemens Informat Syst Ltd, Tata Consultancy Serv, Tata Informat Syst Ltd, Santa Cruz Operat Inc, Unit Trust India, IBM Almaden Res Ctr, US, Indian Inst Technol, Bombay, India, Natl Ctr Soft Technol, Mumbai, India, Onward Technol, Mumbai, India, Persistent Syst Pvt Ltd, Pune, India, Tata Ynisys Ltd, Mumbai, India, Tech Univ, Darmstadt, Germany				Data mining evolved as a collection of applicative problems and efficient solution algorithms relative to rather peculiar problems, all focused on the discovery of relevant information hidden in databases of huge dimensions. In particular, one of the most investigated topics is the discovery of association rules. This work proposes a unifying model that enables a uniform description of the problem of discovering association rules. The model provides SQL-like operator, named MINE RULE, which is capable of expressing all the problems presented so far in the literature concerning the mining of association rules. We demonstrate the expressive power of the new operator by means of several examples, some of which are classical, while some others are fully original and correspond to novel and unusual applications. We also present the operational semantics of the operator by means of an extended relational algebra.		Meo, R (reprint author), POLITECN TORINO, DIPARTIMENTO AUTOMAT & INFORMAT, TURIN, ITALY.							0	49	51	MORGAN KAUFMANN PUB INC	SAN FRANCISCO	340 PINE STR, 6TH FLR, SAN FRANCISCO, CA 94104-3205 USA		1-55860-382-4				1996							122	133				12	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	BH34P	WOS:A1996BH34P00013	
J	Kim, KJ				Kim, KJ			Artificial neural networks with evolutionary instance selection for financial forecasting	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						instance selection; genetic algorithms; artificial neural networks; financial forecasting	NEAREST-NEIGHBOR RULE; GENETIC ALGORITHM; INDEX FUTURES; EXPERT-SYSTEM; BACKPROPAGATION	In this paper, I propose a genetic algorithm (GA) approach to instance selection in artificial neural networks (ANNs) for financial data mining. ANN has preeminent learning ability, but often exhibit inconsistent and unpredictable performance for noisy data. In addition, it may not be possible to train ANN or the training task cannot be effectively carried out without data reduction when the amount of data is so large. In this paper, the GA optimizes simultaneously the connection weights between layers and a selection task for relevant instances. The globally evolved weights mitigate the well-known limitations of gradient descent algorithm. In addition, genetically selected instances shorten the learning time and enhance prediction performance. This study applies the proposed model to stock market analysis. Experimental results show that the GA approach is a promising method for instance selection in ANN. (c) 2005 Elsevier Ltd. All rights reserved.	Dongguk Univ, Dept Informat Syst, Seoul 100715, South Korea	Kim, KJ (reprint author), Dongguk Univ, Dept Informat Syst, 3-26 Pil Dong, Seoul 100715, South Korea.	kjkim@dongguk.edu					Adeli H, 1995, MACHINE LEARNING NEU; Bauer R. J., 1994, GENETIC ALGORITHMS I; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Choi J.H., 1995, P 3 ANN INT C ART IN, P63; Coakley J. R., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<119::AID-ISAF182>3.0.CO;2-Y; Cooper D.R., 1995, BUSINESS RES METHODS; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Deboeck G.J, 1994, TRADING EDGE, P133; DUKE LS, 1993, SOC WORLDWIDE INTERB, P121; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Gupta JND, 1999, OMEGA-INT J MANAGE S, V27, P679, DOI 10.1016/S0305-0483(99)00027-4; Hansson A, 1999, SPACE POLICY, V15, P3; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hertz A, 2000, EUR J OPER RES, V126, P1, DOI 10.1016/S0377-2217(99)00435-X; HIEMSTRA Y, 1995, CHAOS NONLINEAR DYNA, P163; Kamijo K., 1990, P INT JOINT C NEUR N, P215; Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0; Kohara K., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<11::AID-ISAF115>3.3.CO;2-V; KUNCHEVA LI, 1993, PATTERN RECOGN LETT, V14, P619, DOI 10.1016/0167-8655(93)90046-G; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Lee KH, 1999, EXPERT SYST APPL, V16, P357, DOI 10.1016/S0957-4174(99)00011-1; LIU H, 1998, CANCER BIOTHER RADI, V13, P2; LIU H, 2001, INSTANCE SELECTION C, P3; McSherry D, 2000, KNOWL-BASED SYST, V13, P133, DOI 10.1016/S0950-7051(00)00054-X; NIKOLOPOULOS C, 1994, EXPERT SYST, V11, P245, DOI 10.1111/j.1468-0394.1994.tb00332.x; ODETAYO MO, 1995, EXPERT SYST, V12, P3, DOI 10.1111/j.1468-0394.1995.tb00021.x; Oh KJ, 2000, EXPERT SYST APPL, V19, P105, DOI 10.1016/S0957-4174(00)00025-7; Reeves C. R., 2001, INSTANCE SELECTION C, P339; Reeves CR, 1998, PARALLEL PROBLEM SOL; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sexton RS, 1998, DECIS SUPPORT SYST, V22, P171, DOI 10.1016/S0167-9236(97)00040-7; TRIPPI RR, 1992, J PORTFOLIO MANAGE, V19, P27, DOI 10.3905/jpm.1992.409432; SMYTH B, 1998, P 11 INT C IND ENG A, P507; Takeoka M., 1990, P INT JOINT C NEUR N, P1; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Tsaih R, 1998, DECIS SUPPORT SYST, V23, P161, DOI 10.1016/S0167-9236(98)00028-1; Tetko IV, 1997, NEURAL NETWORKS, V10, P1361, DOI 10.1016/S0893-6080(97)00005-1; Weiss S. M., 1998, PREDICTIVE DATA MINI; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wong F., 1994, TRADING EDGE	41	48	51	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2006	30	3					519	526		10.1016/j.eswa.2005.10.007		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	011IG	WOS:000235261000011	
J	Wang, JY; Han, JW; Lu, Y; Tzvetkov, P				Wang, JY; Han, JW; Lu, Y; Tzvetkov, P			TFP: An efficient algorithm for mining top-K frequent closed itemsets	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; frequent itemset; association rules; mining methods and algorithms		Frequent itemset mining has been studied extensively in literature. Most previous studies require the specification of a min_support threshold and aim at mining a complete set of frequent itemsets satisfying min_support. However, in practice, it is difficult for users to provide an appropriate min_support threshold. In addition, a complete set of frequent itemsets is much less compact than a set of frequent closed itemsets. In this paper, we propose an alternative mining task: mining top-k frequent closed itemsets of length no less than min_l, where k is the desired number of frequent closed itemsets to be mined, and min_l is the minimal length of each itemset. An efficient algorithm, called TFP, is developed for mining such itemsets without mins_support. Starting at min_support = 0 and by making use of the length constraint and the properties of top-k frequent closed itemsets, min_support can be raised effectively and FP-Tree can be pruned dynamically both during and after the construction of the tree using our two proposed methods: the closed node count and descendant_sum. Moreover, mining is further speeded up by employing a top-down and bottom-up combined FP-Tree traversing strategy, a set of search space pruning methods, a fast 2-level hash-indexed result tree, and a novel closed itemset verification scheme. Our extensive performance study shows that TFP has high performance and linear scalability in terms of the database size.	Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; Univ Illinois, Dept Comp Sci, Siebel Ctr Sci 2132, Urbana, IL 61801 USA	Wang, JY (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	jianyong@mail.tsinghua.edu.cn; hanj@uiuc.edu; yinglu@uiuc.edu; tzvetkov@uiuc.edu					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bastide Yves, 2000, SIGKDD EXPLORATIONS, V2, P66, DOI DOI 10.1145/380995.381017; Bay S., 1999, P 5 ACM SIGKDD INT C, P302, DOI 10.1145/312129.312263; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; BONCHI F, 2003, P 7 EUR C PRINC PRAC; BOULICAUT JF, 2000, P PAKDD, P62; Boulicaut JF, 2003, DATA MIN KNOWL DISC, V7, P5, DOI 10.1023/A:1021571501451; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Burdick D, 2001, PROC INT CONF DATA, P443, DOI 10.1109/ICDE.2001.914857; Cohen E., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839448; Fu AWC, 2000, P INT S METH INT SYS, P59; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J, 1995, P 21 INT C VER LARG, P420; HIDBER C, 1999, P ACM SIGMOD INT C M, P145, DOI 10.1145/304182.304195; LEE YK, 2003, P 2003 INT C DAT MIN; LIU G, 2003, P 2003 ACM SIGKDD IN; MORISHITA S, 1999, LARGE SCALE PARALLEL, P127; MORISHITA S, 2001, P 2000 ACM SIGMOD SI, P226; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; PAN F, 2003, P 2003 ACM SIGKDD IN; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J., 2000, P 2000 ACM SIGMOD IN, P11; RIOULT F, 2003, P 8 ACM SIGMOD WORKS; Wang J., 2003, P 9 ACM SIGKDD INT C, P236; WANG K, 2001, P 2001 ACM CIKM INT, P81; Zaki MJ, 2002, SIAM PROC S, P457	27	48	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2005	17	5					652	664				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	908BU	WOS:000227763000006	
J	Greco, S; Pawlak, Z; Slowinski, R				Greco, S; Pawlak, Z; Slowinski, R			Can Bayesian confirmation measures be useful for rough set decision rules?	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						confirmation measures; Bayes' theorem; rough sets; decision rules; decision algorithm; monotonicity property	ALGORITHMS; DEFENSE	Bayesian confirmation theory considers a variety of non-equivalent confirmation measures which say in what degree a piece of evidence confirms a hypothesis. In this paper, we apply some well-known confirmation measures within the rough set approach to discovering relationships in data in terms of decision rules. Moreover, we discuss some interesting properties of these confirmation measures and we propose a new property of monotonicity that is particularly relevant within rough set approach. The main result of this paper states that only two from among confirmation measures considered in the literature have the desirable properties from the viewpoint of the rough set approach. Moreover, we clarify relationships between logical implications and decision rules, and we compare the confirmation measures to several related measures, like independence (dependence) of logical formulas, interestingness measures in data mining and Bayesian solutions of raven's paradox. (C) 2004 Elsevier Ltd. All rights reserved.	Univ Catania, Fac Econ, I-95129 Catania, Italy; Polish Acad Sci, Inst Theoret & Appl Informat, PL-44100 Gliwice, Poland; Warsaw Sch Informat Technol, PL-01447 Warsaw, Poland; Poznan Tech Univ, Inst Comp Sci, PL-60965 Poznan, Poland; Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland	Greco, S (reprint author), Univ Catania, Fac Econ, Corso Italia 55, I-95129 Catania, Italy.	salgreco@mbox.unict.it; zpw@ii.pw.edu.pl; slowinsk@sol.put.poznan.pl	Slowinski, Roman/A-5751-2013				Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Carnap Rudolf, 1962, LOGICAL FDN PROBABIL; Christensen D, 1999, J PHILOS, V96, P437, DOI 10.2307/2564707; Earman J., 1992, BAYES BUST CRITICAL; EDGINGTON D, 1995, MIND, V104, P235, DOI 10.1093/mind/104.414.235; Eells E., 2002, PHILOS STUD, V107, P129, DOI DOI 10.1023/A:1014712013453; Eells Ellery, 1982, RATIONAL DECISION CA; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Fitelson B, 2003, ANALYSIS, V63, P194, DOI 10.1111/1467-8284.00420; Fitelson Branden, 2001, THESIS U WISCONSIN M; Flach PA, 2001, MACH LEARN, V42, P61, DOI 10.1023/A:1007656703224; FLACH PA, 1995, THESIS TILBURG U; GILLIES D, 1986, PHILOS SCI, V53, P110, DOI 10.1086/289295; GOOD IJ, 1984, J STAT COMPUT SIM, V19, P294, DOI 10.1080/00949658408810739; Good I. J., 1967, BRIT J PHILOS SCI, V17, P322, DOI 10.1093/bjps/17.4.322; Greco S, 2002, LECT NOTES ARTIF INT, V2475, P93; HAJEK P, 1978, MECHANISING HYPOTHES; Heckerman D., 1986, UNCERTAINTY ARTIFICI, P137; Heckerman D., 1988, UNCERTAINTY ARTIFICI, V2, P11; Hempel C. G., 1945, MIND, V54, P1; Hilderman R., 2001, KNOWLEDGE DISCOVERY; Horwich Paul, 1982, PROBABILITY EVIDENCE; Hosiasson-Lindenbaum Janina, 1940, J SYMBOLIC LOGIC, V5, P133, DOI 10.2307/2268173; Jeffrey Richard C, 1992, PROBABILITY ART JUDG; Joyce James M., 1999, FDN CAUSAL DECISION; Kamber M., 1996, P 2 INT C KNOWL DISC, P263; Kemeny John, 1952, PHILOS SCI, V19, P307, DOI 10.1086/287214; Keynes J.M., 1921, TREATISE PROBABILITY; KYBURG H, 1983, RECENT WORK PHILOS, P89; Kyburg Jr Henry E., 1970, PROBABILITY INDUCTIV; LUKASIEWICZ J, 1913, JAN LUKASIEWICZ SELE, P16; MACKIE JL, 1969, BRIT J PHILOS SCI, V20, P27, DOI 10.1093/bjps/20.1.27; MACKIE JL, 1963, BRIT J PHILOS SCI, V13, P265; Michalski R. S., 1998, MACHINE LEARNING DAT; Milne P, 1996, PHILOS SCI, V63, P21, DOI 10.1086/289891; MILNE P, 1995, ANALYSIS, V55, P213, DOI 10.2307/3328583; Nicod J., 1923, PROBLEME LOGIQUE IND; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z, 2002, EUR J OPER RES, V136, P181, DOI 10.1016/S0377-2217(01)00029-7; Pawlak Z, 2004, LECT NOTES ARTIF INT, V3066, P1; PAWLAK Z, 2003, LECT NOTES ARTIF INT, P1; Pawlak Z., 1991, ROUGH SETS THEORETIC; PEARL J, 1988, PROBALISTIC REASONIN; Pollard S, 1999, ANALYSIS, V59, P335, DOI 10.1111/1467-8284.00190; Popper K., 1959, LOGIC SCI DISCOVERY; ROSENKRANTZ RD, 1994, BRIT J PHILOS SCI, V45, P467, DOI 10.1093/bjps/45.2.467; SCHLESINGER GN, 1995, ANALYSIS, V55, P208, DOI 10.2307/3328582; Schum D. A., 1994, EVIDENTIAL FDN PROBA; Stalnaker R., 1968, AM PHILOS Q MONOGRAP, V2, P98; Tsumoto S, 2002, LECT NOTES ARTIF INT, V2475, P381; Yao Y., 1999, LECT NOTES ARTIF INT, V1574, P479; Zembowicz R., 1996, ADV KNOWLEDGE DISCOV, P329	52	48	50	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	JUN	2004	17	4					345	361		10.1016/j.engappai.2004.04.008		17	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	838PG	WOS:000222724700005	
J	Lisi, FA; Malerba, D				Lisi, FA; Malerba, D			Inducing multi-level association rules from multiple relations	MACHINE LEARNING			English	Article; Proceedings Paper	11th International Conference on Inductive Logic Programming (ILP 01)	SEP 09-11, 2001	Strasbourg, FRANCE			inductive logic programming; description logics; spatial data mining	DESCRIPTION LOGICS; KNOWLEDGE DISCOVERY; SPATIAL DATA; DATABASES; INDUCTION; DATALOG	Recently there has been growing interest both to extend ILP to description logics and to apply it to knowledge discovery in databases. In this paper we present a novel approach to association rule mining which deals with multiple levels of description granularity. It relies on the hybrid language AL-log which allows a unified treatment of both the relational and structural features of data. A generality order and a downward refinement operator for AL-log pattern spaces is defined on the basis of query subsumption. This framework has been implemented in SPADA, an ILP system for mining multi-level association rules from spatial data. As an illustrative example, we report experimental results obtained by running the new version of SPADA on geo-referenced census data of Manchester Stockport.	Univ Bari, Dipartimento Informat, I-70125 Bari, Italy	Lisi, FA (reprint author), Univ Bari, Dipartimento Informat, Via Orabona 4, I-70125 Bari, Italy.	lisi@di.uniba.it; malerba@di.uniba.it	Malerba, Donato/H-3850-2012				Agrawal R., 1994, P 20 INT C VER LARG, P487; Baader F., 2003, DESCRIPTION LOGIC HD; Badea L., 2000, LECT NOTES ARTIF INT, V1866, P40; BHAT C, 2000, TX01749381 U TEX AUS; Blockeel H, 1999, DATA MIN KNOWL DISC, V3, P59, DOI 10.1023/A:1009867806624; Borgida A, 1996, ARTIF INTELL, V82, P353, DOI 10.1016/0004-3702(96)00004-5; BUNTINE W, 1988, ARTIF INTELL, V36, P149, DOI 10.1016/0004-3702(88)90001-X; COHEN WW, 1994, MOR KAUF R, P121; Cohen W., 1992, P 10 NAT C ART INT, P754; Dehaspe L, 1999, DATA MIN KNOWL DISC, V3, P7, DOI 10.1023/A:1009863704807; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; Donini FM, 1998, J INTELL INF SYST, V10, P227, DOI 10.1023/A:1008687430626; Dzeroski S, 2001, RELATIONAL DATA MINING, P339; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P117; EGENHOFER MJ, 1994, 9 INTERSECTION FORMA, P183; Ester M, 2000, DATA MIN KNOWL DISC, V4, P193, DOI 10.1023/A:1009843930701; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FERRI F, 2000, P 12 INT C SCI STAT; Flach P, 2001, MACH LEARN, V44, P207, DOI 10.1023/A:1010925220406; Gatrell A. C., 1999, GEOGRAPHICAL INFORMA, V2, P925; Guting R. H., 1994, VLDB J, V3, P357, DOI 10.1007/BF01231602; Han J., 1995, VLDB, P420; HAN J, 1999, IEEE T KNOWL DATA EN, V11, P5; HELFT N, 1987, PROGR MACHINE LEARNI, P149; KIETZ JU, 1994, MACH LEARN, V14, P193, DOI 10.1023/A:1022626200450; KOPERSKI K., 1997, P ACM SIGMOD INT C M, P553, DOI 10.1145/253260.253404; Koperski K, 1995, LECT NOTES COMPUT SC, V951, P47; Krogel M.-A., 2001, LECT NOTES ARTIF INT, V2157, P142; Levy AY, 1998, ARTIF INTELL, V104, P165, DOI 10.1016/S0004-3702(98)00048-4; Lisi FA, 2002, FR ART INT, V77, P375; Ludl MC, 2000, LECT NOTES COMPUT<D>, V1910, P148; MALERBA D, 2001, LECT NOTES ARTIF INT, V2157, P156; Malerba D., 2001, GEOGRAPHIC DATA MINI, P291, DOI 10.4324/9780203468029_chapter_12; MALERBA D, 2001, ECML PKDD 2001 WORKS, P18; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; MARTIN D, 1999, GEOGRAPHICAL INFORMA, V1, P71; Nienhuys-Cheng S.-H., 1997, LECT NOTES ARTIFICIA, V1228; Nijssen S., 2001, P 17 INT JOINT C ART, P891; Plotkin G.D., 1970, MACH INTELL, V5, P153; Popelinsky L, 1998, LECT NOTES ARTIF INT, V1510, P185; REITER R, 1980, J ACM, V27, P235, DOI 10.1145/322186.322189; Rouveirol C., 2000, LECT NOTES ARTIF INT, P191; SCHMIDTSCHAUSS M, 1991, ARTIF INTELL, V48, P1, DOI 10.1016/0004-3702(91)90078-X; Semeraro G., 1998, LECT NOTES COMPUTER, V1463, P300, DOI 10.1007/3-540-49674-2_16; Srikant R., 1995, P 21 INT C VER LARG, P407; Tanca Letizia, 1990, LOGIC PROGRAMMING DA; WEBER I, 1999, LECT NOTES ARTIF INT, V1609, P253	48	48	50	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAY	2004	55	2					175	210		10.1023/B:MACH.0000023151.65011.a3		36	Computer Science, Artificial Intelligence	Computer Science	810NV	WOS:000220711900004	
J	Cannataro, M; Talia, D; Trunfio, P				Cannataro, M; Talia, D; Trunfio, P			Distributed data mining on the grid	FUTURE GENERATION COMPUTER SYSTEMS			English	Article						knowledge discovery; distributed data mining; grid services		In many industrial, scientific and commercial applications, it is often necessary to analyze large data sets, maintained over geographically distributed sites, by using the computational power of distributed and parallel systems. The grid can play a significant role in providing an effective computational support for knowledge discovery applications. We describe a software architecture for geographically distributed high-performance knowledge discovery applications called KNOWLEDGE GRID, which is designed on top of computational grid mechanisms, provided by grid environments such as Globus. The KNOWLEDGE GRID uses the basic grid services such as communication, authentication, information, and resource management to build more specific parallel and distributed knowledge discovery tools and services. The paper discusses how the KNOWLEDGE GRID can be used to implement distributed data mining services. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy; CNR, ICAR, I-87036 Arcavacata Di Rende, CS, Italy	Talia, D (reprint author), Univ Calabria, DEIS, Via P Bucci,Cubo 41-C, I-87036 Arcavacata Di Rende, CS, Italy.		Talia, Domenico/F-8853-2010; Cannataro, Mario/B-1503-2012; Trunfio, Paolo/A-1274-2011	Cannataro, Mario/0000-0003-1502-2387; Trunfio, Paolo/0000-0002-5076-6544			AVERY P, 2001, GRIPHYN PROJECT DESC; Berman F, 2001, COMMUN ACM, V44, P27, DOI 10.1145/384150.384156; Chervenak A., 2001, J NETW COMPUT APPL, V23, P187; Foster I, 1997, INT J SUPERCOMPUT AP, V11, P115, DOI 10.1177/109434209701100205; Foster I., 2001, INT J SUPERCOMPUTER, V15; FOSTER I, 2000, BUILDING GRID INTEGR; Gong L, 2001, IEEE INTERNET COMPUT, V5, P88; Hoschek W., 2000, LECT NOTES COMPUTER, V1971, P77; Morita Y, 2001, PROCEEDINGS OF CHEP 2001, P699; Prodromidis AL, 2000, ADVANCES IN DISTRIBUTED AND PARALLEL KNOWLEDGE DISCOVERY, P81	10	48	52	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-739X		FUTURE GENER COMP SY	Futur. Gener. Comp. Syst.	OCT	2002	18	8					1101	1112		10.1016/S0167-739X(02)00088-2		12	Computer Science, Theory & Methods	Computer Science	608PU	WOS:000178856200010	
J	Kusiak, A; Kern, JA; Kernstine, KH; Tseng, BTL				Kusiak, A; Kern, JA; Kernstine, KH; Tseng, BTL			Autonomous decision-making: A data mining approach	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						data mining; lung cancer diagnosis; machine learning; medical decision making; rough set theory	SOLITARY PULMONARY NODULES; MANAGEMENT; PET	The researchers and practitioners of today create models, algorithms, functions, and other constructs defined in abstract spaces. The research of the future will likely be data driven. Symbolic and numeric data that are becoming available in large volumes will define the need for new data analysis techniques and tools. Data mining is an emerging area of computational intelligence that offers new theories, techniques, and tools for analysis of large data sets. In this paper, a novel approach for autonomous decision-making is developed based on the rough set theory of data mining. The approach has been tested on a medical data set for patients with lung abnormalities referred to as solitary pulmonary nodules (SPNs), The two independent algorithms developed in this paper either generate an accurate diagnosis or make no decision. The methodolgy discussed in the paper depart from the developments in data mining as well as current medical literature, thus creating a variable approach for autonomous decision-making.	Univ Iowa, Seamans Ctr Engn Arts & Sci 4312, Intelligent Syst Lab, Iowa City, IA 52242 USA; Univ Iowa, Dept Internal Med, Iowa City, IA 52242 USA; Univ Iowa, Dept Surg, Iowa City, IA 52242 USA	Kusiak, A (reprint author), Univ Iowa, Seamans Ctr Engn Arts & Sci 4312, Intelligent Syst Lab, Iowa City, IA 52242 USA.						Adriaans P, 1996, DATA MINING; GROSS TJ, 1997, SOLITARY PULMONARY N; Grzymala-Busse J. W., 1997, Fundamenta Informaticae, V31; Gupta NC, 1996, J NUCL MED, V37, P943; KHOURI NF, 1987, CHEST, V91, P128, DOI 10.1378/chest.91.1.128; KLEIN GA, DECISION MAKING ACTI, P138; Kononenko I, 1998, MACHINE LEARNING DAT, P389; Kowalczyk W, 1997, LECT NOTES ARTIF INT, V1263, P4; Kusiak A., 2000, COMPUTATIONAL INTELL; Landis SH, 1999, CA-CANCER J CLIN, V49, P8, DOI 10.3322/canjclin.49.1.8; LILLINGTON GA, 1993, HOSP PRACT, V28, P41; Pawlak Z., 1991, ROUGH SETS THEORETIC; PAWLAK Z, 1997, P IPMM 97, V1, P663; PAWLAK Z, 1986, INT J MAN MACH STUD, V24, P413, DOI 10.1016/S0020-7373(86)80001-3; Ruhe G., 1996, P 4 INT WORKSH ROUGH, P292; SHAN N, 1995, P 1 INT C KNOWL DISC, P263; SKOWRON A, 1994, P INT WORKSH ROUGH S, P108; SLOWINSKI R, 1993, NEW APPROACHES CLASS, P482; STEFANOWSKI J, 1997, ROUGH SETS DATA MINI, P177; Hubner KF, 1996, CLIN NUCL MED, V21, P941, DOI 10.1097/00003072-199612000-00005; STONE M, 1974, J ROY STAT SOC, V36, P11; Swensen SJ, 1999, MAYO CLIN PROC, V74, P319; TSUMOTO S, 1996, P 9 INT S FDN INT SY, P438; Tsumoto S, 1997, LECT NOTES ARTIF INT, V1263, P58; WOJCIK ZM, 1993, P INT WORKH ROUGH SE, P421	25	48	54	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	DEC	2000	4	4					274	284		10.1109/4233.897059		11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	397QU	WOS:000166707600002	
J	Gehrke, J; Ramakrishnan, R; Ganti, V				Gehrke, J; Ramakrishnan, R; Ganti, V			RainForest - A framework for fast decision tree construction of large datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; decision trees; classification; scalability	DISCRIMINANT-ANALYSIS; CLASSIFICATION; ALGORITHMS; KNAPSACK	Classification of large datasets is an important data mining problem. Many classification algorithms have been proposed in the literature, but studies have shown that so far no algorithm uniformly outperforms all other algorithms in terms of quality. In this paper, we present a unifying framework called Rain Forest for classification tree construction that separates the scalability aspects of algorithms for constructing a tree from the central features that determine the quality of the tree. The generic algorithm is easy to instantiate with specific split selection methods from the literature (including C4.5, CART, CHAID, FACT, ID3 and extensions, SLIQ, SPRINT and QUEST). In addition to its generality, in that it yields scalable versions of a wide range of classification algorithms, our approach also offers performance improvements of over a factor of three over the SPRINT algorithm, the fastest scalable classification algorithm proposed previously. In contrast to SPRINT, however, our generic algorithm requires a certain minimum amount of main memory, proportional to the set of distinct values in a column of the input relation. Given current main memory costs, this requirement is readily met in most if not all workloads.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	Gehrke, J (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; Agresti A, 1990, CATEGORICAL DATA ANA; ASTRAHAN MM, 1987, INFORM SYST, V12, P11, DOI 10.1016/0306-4379(87)90014-7; Bishop CM, 1995, NEURAL NETWORKS PATT; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Breiman L, 1984, CLASSIFICATION REGRE; BRODLEY CE, 1992, 8 U MASS DEP COMP SC; CATLETT J, 1991, P EUR WORK SESS LEAR, V482, P164; Catlett J., 1991, THESIS U SYDNEY; Chan P., 1993, P 2 INT C INF KNOWL, P314; Chan P. K., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); CHEESEMAN P, 1988, P 5 INT C MACH LEARN; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHIRSTENSEN R, 1997, LOG LINEAR MODELS LO; CURRAM SP, 1994, J OPER RES SOC, V45, P440, DOI 10.1057/jors.1994.62; Dougherty J., 1995, MACHINE LEARNING; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FAYYAD UM, 1991, THESIS U MICHIGAN; Fayyad Usama, 1996, COMMUNICATIONS ACM, V39; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; FUKUDA T, 1996, P 22 VLDB C MUMB IND; Garey M.R., 1979, COMPUTER INTRACTABIL; GILLO MW, 1972, BEHAV SCI, V17, P251; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Graefe G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Haas P., 1995, P VLDB C, P311; Hand DJ, 1997, CONSTRUCTION ASSESSM; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; INMAN WH, 1996, COMMUNICATIONS ACM, V39; James M., 1985, CLASSIFICATION ALGOR; KERBER R, 1991, P 10 INT C ART INT, P123; IBARRA OH, 1975, J ACM, V22, P463, DOI 10.1145/321906.321909; KOHAVI R, 1995, LECT NOTES COMPUTER, V912; Kohonen Teuvo, 1995, SELF ORG MAPS; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Lim T.-S., 1997, 979 U WISC DEP STAT; LIU H, 1996, P IEEE TOOLS AI; Loh WY, 1997, STAT SINICA, V7, P815; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Maass W., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181016; MAGIDSON J, 1993, J DATABASE MARKETING, V1; MAGIDSON J, 1993, HDB MARKETING RES; MAGIDSON J, 1989, 11130 MARKT INF SYST; Mehta M., 1995, P 1 INT C KNOWL DISC; Mehta M., 1996, P 5 INT C EXT DAT TE; MORGAN JN, 1973, THAID SEQUANTIAL SEA; MORIMOTO Y, 1998, P 24 INT C VER LARG; MURPHY OJ, 1991, IEEE T COMPUT, V40, P315, DOI 10.1109/12.76408; MURTHY SK, 1995, THESIS J HOPKINS U B; Naumov G. E., 1991, Soviet Physics - Doklady, V36; BROWN DE, 1993, PATTERN RECOGN, V26, P953, DOI 10.1016/0031-3203(93)90060-A; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1983, MACHINE LEARNING ART; Rastogi R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ripley B., 1996, PATTERN RECOGNITION; Rissanen J, 1989, STOCHASTIC COMPLEXIT; SAHNI S, 1975, J ACM, V22, P115, DOI 10.1145/321864.321873; Sarle W., 1994, P 19 ANN SAS US GROU, P1538; Shafer J., 1996, P 22 INT C VER LARG; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; Sonquist J, 1971, SEARCHING STRUCTURE; Taylor C.C., 1994, MACHINE LEARNING NEU; Zighed D. A., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	67	48	51	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2000	4	2-3					127	162		10.1023/A:1009839829793		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	325ZA	WOS:000087706100003	
J	Cooper, GF				Cooper, GF			A simple constraint-based algorithm for efficiently mining observational databases for causal relationships	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						causal discovery; data mining; observational data	BAYESIAN NETWORKS	This paper presents a simple, efficient computer-based method for discovering causal relationships from databases that contain observational data. Observational data is passively observed, as contrasted with experimental data. Most of the databases available for data mining are observational. There is great potential for mining such databases to discover causal relationships. We illustrate how observational data can constrain the causal relationships among measured variables, sometimes to the point that we can conclude that one variable is causing another variable. The presentation here is based on a constraint-based approach to causal discovery. A primary purpose of this paper is to present the constraint-based causal discovery method in the simplest possible fashion in order to (1) readily convey the basic ideas that underlie more complex constraint-based causal discovery techniques, and (2) permit interested readers to rapidly program and apply the method to their own databases, as a start toward using more elaborate causal discovery algorithms.	Univ Pittsburgh, Ctr Biomed Informat, Pittsburgh, PA 15213 USA	Cooper, GF (reprint author), Univ Pittsburgh, Ctr Biomed Informat, Suite 8084,Forbes Tower, Pittsburgh, PA 15213 USA.						ALIFERIS C, 1994, P 10 C UNC ART INT S, P8; ALMOND RG, 1997, WEB PAGE SOFTWARE LE; Bishop Y.M.M., 1975, DISCRETE MULTIVARIAT; BOUCKAERT RR, 1995, THESIS U UTRECHT UTR; Castillo E., 1997, EXPERT SYSTEMS PROBA; CHICKERING DM, 1996, P 12 C UNC ART INT S, P158; COOPER G, 1995, P 5 INT WORKSH ART I, P140; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; GEIGER D, 1990, NETWORKS, V20, P507, DOI 10.1002/net.3230200504; Heckerman D., 1996, MSRTR9506; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Herskovits E., 1991, THESIS STANFORD U; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Little RJA, 1987, STAT ANAL MISSING DA; Meek C., 1995, P 11 C UNC ART INT, P411; Pearl J., 1988, PROBABILISTIC REASON; PEARL J, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P441; PEARL J, 1994, R218L U CAL LOS ANG; PEARL J, 1996, P 12 C UNC ART INT, P420; Richardson T, 1996, P 12 C UNC ART INT, P454; Scheines R., 1993, CAUSATION PREDICTION; SCHEINES R, 1995, TETRAD, V2; Spirtes P, 1995, P 11 C UNC ART INT U, P499	23	48	51	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	2					203	224		10.1023/A:1009787925236		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA828	WOS:000072406100004	
J	Guan, NY; Tao, DC; Luo, ZG; Yuan, B				Guan, Naiyang; Tao, Dacheng; Luo, Zhigang; Yuan, Bo			NeNMF: An Optimal Gradient Method for Nonnegative Matrix Factorization	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						L-1-norm; L-2-norm; manifold regularization; nonnegative matrix factorization (NMF); optimal gradient method	ALGORITHMS	Nonnegative matrix factorization (NMF) is a powerful matrix decomposition technique that approximates a nonnegative matrix by the product of two low-rank nonnegative matrix factors. It has been widely applied to signal processing, computer vision, and data mining. Traditional NMF solvers include the multiplicative update rule (MUR), the projected gradient method (PG), the projected nonnegative least squares (PNLS), and the active set method (AS). However, they suffer from one or some of the following three problems: slow convergence rate, numerical instability and nonconvergence. In this paper, we present a new efficient NeNMF solver to simultaneously overcome the aforementioned problems. It applies Nesterov's optimal gradient method to alternatively optimize one factor with another fixed. In particular, at each iteration round, the matrix factor is updated by using the PG method performed on a smartly chosen search point, where the step size is determined by the Lipschitz constant. Since NeNMF does not use the time consuming line search and converges optimally at rate O(1/k(2)) in optimizing each matrix factor, it is superior to MUR and PG in terms of efficiency as well as approximation accuracy. Compared to PNLS and AS that suffer from numerical instability problem in the worst case, NeNMF overcomes this deficiency. In addition, NeNMF can be used to solve L-1-norm, L-2-norm and manifold regularized NMF with the optimal convergence rate. Numerical experiments on both synthetic and real-world datasets show the efficiency of NeNMF for NMF and its variants comparing to representative NMF solvers. Extensive experiments on document clustering suggest the effectiveness of NeNMF.	[Guan, Naiyang; Luo, Zhigang] Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Hunan, Peoples R China; [Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia; [Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia; [Yuan, Bo] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China	Guan, NY (reprint author), Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Hunan, Peoples R China.	ny_guan@nudt.edu.cn; dacheng.tao@uts.edu.au; zgluo@nudt.edu.cn; boyuan@sjtu.edu.cn			Australian ARC [ARC DP-120103730]; National Natural Science Foundation of China [91024030/G03]; Program for Changjiang Scholars and Innovative Research Team in University [IRT1012]	This work was supported in part by the Australian ARC discovery project (ARC DP-120103730), the National Natural Science Foundation of China (by Grant No. 91024030/G03), and by the Program for Changjiang Scholars and Innovative Research Team in University (No. IRT1012).	Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006; Bertsekas D.P., 1999, NONLINEAR PROGRAMMIN; Bonettini S, 2011, IMA J NUMER ANAL, V31, P1431, DOI 10.1093/imanum/drq024; Cai D, 2008, IEEE DATA MINING, P63, DOI 10.1109/ICDM.2008.57; CICHOCKI A, 2006, P IEEE INT C AC SPEE, V5, P621; Cieri C., 1999, P DARPA BROADC NEWS; Grippo L., OPERAT RES LETT, V26; Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496; Guan NY, 2011, IEEE T NEURAL NETWOR, V22, P1218, DOI 10.1109/TNN.2011.2157359; Han LX, 2009, ELECTRON T NUMER ANA, V36, P54; Hoyer P., 2002, P IEEE WORKSH NEUR N, P557, DOI DOI 10.1109/NNSP.2002.1030067; Ji S. W., 2009, P INT C MACH LEARN, V382, P457; Kim DM, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P343; Kim H, 2008, SIAM J MATRIX ANAL A, V30, P713, DOI 10.1137/07069239X; Kim J., 2008, P 8 IEEE INT C DAT M; Lee D. D., 2000, ADV NEURAL INF PROCE, V12, P556; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756; Lin CJ, 2007, IEEE T NEURAL NETWOR, V18, P1589, DOI 10.1109/TNN.2007.895831; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Nesterov Y. E., 1983, SOVIET MATH DOKLADY, V27; Nesterov Yu, 2004, INTRO LECT CONVEX OP; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Pauca VP, 2004, SIAM PROC S, P452; Rockafellar R. T., 1970, CONVEX ANAL; Song ML, 2010, IEEE T PATTERN ANAL, V32, P1537, DOI 10.1109/TPAMI.2009.74; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tian X., 2011, ACM T MULTIMED COMPU; Wang XC, 2011, IEEE T IMAGE PROCESS, V20, P2627, DOI 10.1109/TIP.2011.2114354; Xu W., 2003, DOCUMENT CLUSTERING, P267; Yu J, 2011, IEEE T IMAGE PROCESS, V20, P3257, DOI 10.1109/TIP.2011.2158225; Zdunek R, 2006, LECT NOTES COMPUT SC, V4029, P870; Zhou TF, 2009, P NIPS WORKSH DISCR, P1	34	47	47	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-587X		IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	JUN	2012	60	6					2882	2898		10.1109/TSP.2012.2190406		17	Engineering, Electrical & Electronic	Engineering	943VU	WOS:000304154500014	
J	Hong, GH; Park, SC; Jang, DS; Rho, HM				Hong, GH; Park, SC; Jang, DS; Rho, HM			An effective supplier selection method for constructing a competitive supply-relationship	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						supply selection; data mining; mixed-integer programming; supply-relationship management; customer demand	MANAGEMENT	We propose an effective supplier selection method to maintain a continuous supply-relationship with suppliers. Costs have been sharply increasing and profit decreasing as the global competition among companies has increased and customer demands have diversified in the current business environment. Many other functions are now outsourced globally to strengthen competition. As a result, one of the issues is how to select good suppliers which can maintain a continuous supply-relationship. We suggest a mathematical programming model that considers the change in suppliers' supply capabilities and customer needs over a period in time. We design a model which not only maximizes revenue but also satisfies customer needs. The suggested model is applied to supplier selection and management of the agriculture industry in Korea. (c) 2005 Elsevier Ltd. All rights reserved.	Korea Adv Inst Sci & Technol, Dept Ind Engn, Taejon 305701, South Korea; Korea Univ, Seoul, South Korea; Korea Inst Sci & Technol, CADCAM Res Ctr, Seoul, South Korea	Hong, GH (reprint author), Korea Adv Inst Sci & Technol, Dept Ind Engn, 373-1 Kusong Dong, Taejon 305701, South Korea.	kistduck@kaist.ac.kr					CHOY KL, 2002, EXPERT SYSTEM APPL; de Boer L, 2001, EUROPEAN J PURCHASIN, V7, P75, DOI 10.1016/S0969-7012(00)00028-9; Dickson G., 1966, J PURCHASING, V2, P5; Ha SH, 1998, EXPERT SYST APPL, V15, P1; Holt G. D., 1998, International Journal of Project Management, V16, DOI 10.1016/S0263-7863(97)00035-5; KRALJIC P, 1983, HARVARD BUS REV, V61, P109; Lee EK, 2001, IEEE T ENG MANAGE, V48, P307; Park JH, 2003, DECIS SUPPORT SYST, V35, P311, DOI 10.1016/S0167-9236(02)00111-2; Talluri S, 2002, INT J PROD RES, V40, P4257, DOI 10.1080/00207540210152894; Weber CA, 1998, EUR J OPER RES, V108, P208, DOI 10.1016/S0377-2217(97)00131-8; Weber CA, 1996, EUR J OPER RES, V90, P142, DOI 10.1016/0377-2217(94)00336-X	11	47	51	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2005	28	4					629	639		10.1016/j.eswa.2004.12.020		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	913BD	WOS:000228124200004	
J	Hsieh, NC				Hsieh, NC			An integrated data mining and behavioral scoring model for analyzing bank customers	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; behavioral scoring model; customer segmentation; neural network; association rule	ARTIFICIAL NEURAL-NETWORKS; MARKET-SEGMENTATION; ASSOCIATION RULES; CREDIT; PERFORMANCE; PATTERNS	Analyzing bank databases for customer behavior management is difficult since bank databases are multi-dimensional, comprised of monthly account records and daily transaction records. This study proposes an integrated data mining and behavioral scoring model to manage existing credit card customers in a bank. A self-organizing map neural network was used to identify groups of customers based on repayment behavior and recency, frequency, monetary behavioral scoring predicators. It also classified bank customers into three major profitable groups of customers. The resulting groups of customers were then profiled by customer's feature attributes determined using an Apriori association rule inducer. This study demonstrates that identifying customers by a behavioral scoring model is helpful characteristics of customer and facilitates marketing strategy development. (C) 2004 Elsevier Ltd. All rights reserved.	Natl Taipei Coll Nursing, Dept Informat Management, Taipei, Taiwan	Hsieh, NC (reprint author), Natl Taipei Coll Nursing, Dept Informat Management, 365,Min Te Rd, Taipei, Taiwan.	nchsieh@ntcn.edu.tw					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Baesens B, 2002, EUR J OPER RES, V138, P191, DOI 10.1016/S0377-2217(01)00129-1; Balakrishnan PV, 1996, EUR J OPER RES, V93, P346, DOI 10.1016/0377-2217(96)00046-X; Bastide I, 2000, LECT NOTES ARTIF INT, V1861, P972; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bayardo RJ, 1999, PROC INT CONF DATA, P188, DOI 10.1109/ICDE.1999.754924; Bult JR, 1995, MARKET SCI, V14, P378, DOI 10.1287/mksc.14.4.378; Chen MC, 2003, EXPERT SYST APPL, V24, P433, DOI 10.1016/S0957-4174(02)00191-4; DASGUPTA CG, 1994, INT J FORECASTING, V10, P235, DOI 10.1016/0169-2070(94)90004-3; Davies F., 1996, MARKETING INTELLIGEN, V14, P26, DOI 10.1108/02634509610110778; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; Donato JM, 1999, FUTURE GENER COMP SY, V15, P433, DOI 10.1016/S0167-739X(98)00086-7; Dyche J., 2001, CRM HDB BUSINESS GUI; FISH KE, 1995, IND MARKET MANAG, V24, P431, DOI 10.1016/0019-8501(95)00033-7; Hand D. J., 1981, DISCRIMINATION CLASS; Heckerman D., 1996, ADV KNOWLEDGE DISCOV, P273; Hornik K, 1989, NEURAL NETWORKS, V2, P336; Johnson R. A., 1998, APPL MULTIVARIATE ST; KELMETTINEN M, 1994, P CIKM C, P401; Kim YS, 2004, EXPERT SYST APPL, V26, P567, DOI 10.1016/j.eswa.2003.10.013; Kohonen T, 1995, SELF ORGANIZING MAPS; Lancher R.C., 1995, EUR J OPER RES, V85, P53; Lee TS, 2002, EXPERT SYST APPL, V23, P245, DOI 10.1016/S0957-4174(02)00044-1; Malhotra R, 2003, OMEGA-INT J MANAGE S, V31, P83, DOI 10.1016/S0305-0483(03)00016-1; Mazanec J. A., 1992, Journal of Travel & Tourism Marketing, V1, P39, DOI 10.1300/J073v01n01_04; MORRIOSN DF, 1990, MULTIVARIATE STAT ME; Moutinho L., 1996, J RETAILING CONSUMER, V3, P135, DOI 10.1016/0969-6989(95)00064-X; Pasquier N, 1999, P 15 JOURN BAS DONN, P361; Setiono R, 1998, INFORM MANAGE, V34, P91, DOI 10.1016/S0378-7206(98)00048-2; SHARMA SK, 1996, ITAL J FOOD SCI, V2, P107; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Silverstein C, 1998, DATA MIN KNOWL DISC, V2, P39, DOI 10.1023/A:1009713703947; Srikant R., 1995, P 21 INT C VER LARG, P407; Thomas LC, 2000, INT J FORECASTING, V16, P149, DOI 10.1016/S0169-2070(00)00034-0; Vellido A, 1999, EXPERT SYST APPL, V17, P51, DOI 10.1016/S0957-4174(99)00016-0; Zhang GQ, 1999, EUR J OPER RES, V116, P16, DOI 10.1016/S0377-2217(98)00051-4; ZURADA JM, 1994, IEEE INT S CIRC SYST	37	47	50	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	NOV	2004	27	4					623	633		10.1016/j.eswa.2004.06.007		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	856BP	WOS:000224018900010	
J	Yip, KY; Cheung, DW; Ng, MK				Yip, KY; Cheung, DW; Ng, MK			HARP: A practical projected clustering algorithm	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; mining methods and algorithms; clustering; bioinformatics		In high-dimensional data, clusters can exist in subspaces that hide themselves from traditional clustering methods. A number of algorithms have been proposed to identify such projected clusters, but most of them rely on some user parameters to guide the clustering process. The clustering accuracy can be seriously degraded if incorrect values are used. Unfortunately, in real situations, it is rarely possible for users to supply the parameter values accurately, which causes practical difficulties in applying these algorithms to real data. In this paper, we analyze the major challenges of projected clustering and suggest why these algorithms need to depend heavily on user parameters. Based on the analysis, we propose a new algorithm that exploits the clustering status to adjust the internal thresholds dynamically without the assistance of user parameters. According to the results of extensive experiments on real and synthetic data, the new method has excellent accuracy and usability. It outperformed the other algorithms even when correct parameter values were artificially supplied to them. The encouraging results suggest that projected clustering can be a practical tool for various kinds of real applications.	Univ Hong Kong, Dept Comp Sci & Informat Syst, Hong Kong, Hong Kong, Peoples R China; Univ Hong Kong, Dept Math, Hong Kong, Hong Kong, Peoples R China	Yip, KY (reprint author), Univ Hong Kong, Dept Comp Sci & Informat Syst, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.	ylyip@csis.hku.hk; dcheung@csis.hku.hk; mng@maths.hku.hk	Ng, Michael/B-7189-2009; HKBU, Mathematics/B-5086-2009				AGGARWAL C, 2000, P ACM SIGMOD INT C M; AGGARWAL CC, 1999, P ACM SIGMOD INT C M; Agrawal R., 1998, P ACM SIGMOD INT C M; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; BENDOR A, 1999, P ANN INT C COMP MOL; Bickel P. J., 1977, MATH STAT BASIC IDEA; CHENG Y, 1990, P 8 INT C INT SYST M; EPPSTEIN D, 1998, P SODA ACM SIAM S DI; GUHA S., 1998, P ACM SIGMOD INT C M; Han J., 2000, DATA MINING CONCEPTS; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HUANG Z, 1997, P 1 PAC AS C KNOWL D; Kaufman L., 1990, FINDING GROUPS DATA; Lazzeroni L, 2002, STAT SINICA, V12, P61; Ng R.T., 1994, P 20 INT C VER LARG; PEI J, 2003, P IEEE INT C DAT MIN; PROCOPIUC CM, 2002, P ACM SIGMOD INT C M; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; WANG H, 2002, P ACM SIGMOD INT C M; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763; YIP KYL, 2004, THESIS U HONG KONG H; 1999, P 15 INT C DAT ENG	22	47	49	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2004	16	11					1387	1397		10.1109/TKDE.2004.74		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	855ML	WOS:000223977300006	
S	Chawla, NV; Lazarevic, A; Hall, LO; Bowyer, KW		Lavrac, N; Gamberger, D; Todorovski, L; Blockeel, H		Chawla, NV; Lazarevic, A; Hall, LO; Bowyer, KW			SMOTEBoost: Improving prediction of the minority class in boosting	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2003, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th European Conferenc on Priciples and Practice of Knowledge Discovery in Databases	SEP 22-26, 2003	CAVTAT, CROATIA	Croatian Minist Sci & Technol, Slovenian Minist Educ, Sci & Sports, Knowledge Discovery Network Excellence				Many real world data mining applications involve learning from imbalanced data sets. Learning from data sets that contain very few instances of the minority (or interesting) class usually produces biased classifiers that have a higher predictive accuracy over the majority class(es), but poorer predictive accuracy over the minority class. SMOTE (Synthetic Minority Over-sampling TEchnique) is specifically designed for learning from imbalanced data sets. This paper presents a novel approach for learning from imbalanced data sets, based on a combination of the SMOTE algorithm and the boosting procedure. Unlike standard boosting where all misclassified examples are given equal weights, SMOTEBoost creates synthetic examples from the rare or minority class, thus indirectly changing the updating weights and compensating for skewed distributions. SMOTEBoost applied to several highly and moderately imbalanced data sets shows improvement in prediction performance on the minority class and overall improved F-values.	Canadian Imperial Bank Commerce, Business Analyt Solut, Toronto, ON M5J 2S8, Canada; Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA; Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA	Chawla, NV (reprint author), Canadian Imperial Bank Commerce, Business Analyt Solut, BCE Pl,161 Bay St,11th Floor, Toronto, ON M5J 2S8, Canada.						Blake C, 1998, UCI REPOSITORY MACHI; BUCKLAND M, 1994, J AM SOC INFORM SCI, V45, P12, DOI 10.1002/(SICI)1097-4571(199401)45:1<12::AID-ASI2>3.0.CO;2-L; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Cohen W., 1995, P 12 INT C MACH LEAR, P115; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; Fan W, 1999, P 16 INT C MACH LEAR; Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238163; Japkowicz N., 2000, P 2000 INT C ART INT; JOSHI M, 2001, 1 IEEE INT C DAT MIN; JOSHI M, 2001, 1 SIAM C DAT MIN CHI; JOSHI M, 2002, P 8 ACM C ACM SIGKDD; KARAKOULAS G, 1999, ADV NEURAL INFORMATI, P11; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; Ling CX, 1998, P 4 INT C KNOWL DISC; Lippmann R.P., 2000, P DARPA INF SURV C E, V2, P12; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Ting K., 2000, P 17 INT C MACH LEAR, P983	22	47	48	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-20085-1	LECT NOTES ARTIF INT			2003	2838						107	119				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BX96Y	WOS:000187062000012	
J	Moran, CJ; Bui, EN				Moran, CJ; Bui, EN			Spatial data mining for enhanced soil map modelling	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article							REFERENCE AREA; PREDICTION; TERRAIN	The principle of using induction rules based on spatial environmental data to model a soil map has previously been demonstrated Whilst the general pattern of classes of large spatial extent and those with close association with geology were delineated small classes and the detailed spatial pattern of the map were less well rendered Here we examine several strategies to improve the quality of the soil map models generated by rule induction Terrain attributes that are better suited to landscape description at a resolution of 250 m are introduced as predictors of soil type A map sampling strategy is developed Classification error is reduced by using boosting rather than cross validation to improve the model Further the benefit of incorporating the local spatial context for each environmental variable into the rule induction is examined The best model was achieved by sampling in proportion to the spatial extent of the mapped classes boosting the decision trees and using spatial contextual information extracted from the environmental variables.	CSIRO, Canberra, ACT 2601, Australia	Moran, CJ (reprint author), CSIRO, GPO Box 1666, Canberra, ACT 2601, Australia.		Minerals Institute, Sustainable/F-8043-2010; Bui, Elisabeth/C-8849-2011	Bui, Elisabeth/0000-0001-7632-1992			Bui EN, 1999, AUST J SOIL RES, V37, P495, DOI 10.1071/S98047; BUI EN, UNPUB GEODERMA; CARTER GPB, 1994, GEOGRAPHIC INFORMATI; DRUCKER H, 1994, NEURAL COMPUT, V6, P1289, DOI 10.1162/neco.1994.6.6.1289; Freund Y., 1996, MACHINE LEARNING; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GESSLER PE, 1995, INT J GEOGR INF SYST, V9, P421, DOI 10.1080/02693799508902047; HARUNO M, 1999, MACH LEARN, V43, P131; HUDSON BD, 1992, SOIL SCI SOC AM J, V56, P836; Kearns M, 1999, J COMPUT SYST SCI, V58, P109, DOI 10.1006/jcss.1997.1543; LACACHERIE P, 1997, INT J GEOGR INF SYST, V11, P183; LAGACHERIE P, 1995, GEODERMA, V65, P283, DOI 10.1016/0016-7061(94)00040-H; LAGACHERIE P, 1992, THESIS I NATL RECHER; MCBRATNEY AB, 1998, 16 WORLD C SOIL SCI; McKenzie NJ, 1999, GEODERMA, V89, P67, DOI 10.1016/S0016-7061(98)00137-2; Minasny B, 1999, VESPER VERSION 1 0; MOORE ID, 1993, SOIL SCI SOC AM J, V57, P443; Press W. H., 1988, NUMERICAL RECIPES C; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Schapire RE, 1998, ANN STAT, V26, P1651; Schetselaar EM, 2000, REMOTE SENS ENVIRON, V71, P89, DOI 10.1016/S0034-4257(99)00069-3; Switzer P, 1980, MATH GEOL, V12, P367; THOMPSON GG, 1959, QUEENSLAND SOILS LAN, V28; Voltz M, 1997, EUR J SOIL SCI, V48, P19, DOI 10.1111/j.1365-2389.1997.tb00181.x; *AUSLIG, 1996, GEODATA, V9; *GEOIMAGE, 1995, AUSTR LANDS MSS MOS	26	47	53	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	SEP	2002	16	6					533	549		10.1080/13658810210138715		17	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	592PR	WOS:000177946500002	
J	Pendharkar, PC; Rodger, JA; Yaverbaum, GJ; Herman, N; Benner, M				Pendharkar, PC; Rodger, JA; Yaverbaum, GJ; Herman, N; Benner, M			Association, statistical, mathematical and neural approaches for mining breast cancer patterns	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; data envelopment analysis; artificial neural networks		Using several association and classification approaches to study breast cancer patterns, this study illustrates how these approaches can be used to predict and diagnose the occurrence of breast cancer. The results of the study, based on data obtained hom a large medical facility in western Pennsylvania, show that data mining can be a viable tool for breast cancer diagnosis. (C) 1999 Elsevier Science Ltd. All rights reserved.	Penn State Univ, Middletown, PA 17057 USA; Univ Pittsburgh, Dept Business, Johnstown, PA 15904 USA; AMP Inc, Harrisburg, PA USA	Pendharkar, PC (reprint author), Penn State Univ, 777 W Harrisburg Pike, Middletown, PA 17057 USA.	pxp19@psu.edu; gjy1@psu.edu					AGRAWAL R, 1993, P 4 INT C FDN DAT OR; Agrawal R., 1995, P 21 INT C VER LARG, P490; AGRAWAL R, 1995, P 20 INT C VER LARG, P478; ALTMAN E. I., 1981, APPL CLASSIFICATION; ATLAS L, 1990, ADV NEURAL INFORMATI, V2; BHATTACHARYYA S, 1998, DECISION SCI, V28; Breiman L, 1984, CLASSIFICATION REGRE; CHARNES A, 1978, EUROPEAN J OPERATION, V2, P1978; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; Chen MS, 1996, INT CON DISTR COMP S, P385; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Cheung DW, 1996, IEEE T KNOWL DATA EN, V8, P911, DOI 10.1109/69.553158; CHUNG HMM, 1992, DECISION SCI, V23, P687, DOI 10.1111/j.1540-5915.1992.tb00412.x; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; CLARK P, 1987, PROGR MACHINE LEARNI, P11; ELMORE JG, 1994, NEW ENGL J MED, V331, P1493, DOI 10.1056/NEJM199412013312206; Ester M, 1995, P 4 INT S LARG SPAT, P67; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163, DOI 10.1145/223784.223812; FISCHER DH, 1989, P 11 INT JOINT C ART, P788; FISHER D, 1995, P 1 INT C KNOWL DISC, P118; Fisher Douglas H., 1987, P 1987 AAAI C SEATTL, P461; Fisher RA, 1936, ANN EUGENIC, V7, P179; Freed N., 1981, Decision Sciences, V12, DOI 10.1111/j.1540-5915.1981.tb00061.x; Han J, 1995, P 21 INT C VER LARG, P420; Hand D. J., 1981, DISCRIMINATION CLASS; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Koehler G. J., 1991, ORSA Journal on Computing, V3; Kovalerchuk B, 1997, ARTIF INTELL MED, V11, P75, DOI 10.1016/S0933-3657(97)00021-3; LI CS, 1996, P 12 INT C DAT ENG; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Ng R, 1994, P 20 INT C VER LARG, P144; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; PASS S, 1997, OR MS TODAY, P24; PENDHARKAR PC, 1998, P 3 INFORMS C INF SY, P347; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1; Savasere A, 1995, P 21 INT C VER LARG, P432; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; Srikant R., 1995, P 21 INT C VER LARG, P407; TROUTT MD, 1995, COMPUTERS OPERATIONS, V4, P405; WEISS SM, 1989, P 11 INT JOINT C ART, P688; WINGO PA, 1995, CA-CANCER J CLIN, V45, P8, DOI 10.3322/canjclin.45.1.8; Wolpert D.H., 1995, SFITR9502010	45	47	48	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	OCT	1999	17	3					223	232		10.1016/S0957-4174(99)00036-6		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	249XJ	WOS:000083358200006	
B	Shepitsen, A; Gemmell, J; Mobasher, B; Burke, R			ACM	Shepitsen, Andriy; Gemmell, Jonathan; Mobasher, Bamshad; Burke, Robin			Personalized Recommendation in Social Tagging Systems Using Hierarchical Clustering	RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS			English	Proceedings Paper	ACM Conference on Recommender Systems	OCT 23-25, 2008	Lausanne, SWITZERLAND	ACM SIGCHI, ACM SIGIR, ACM SIGWEB, ACM SIGKDD, ACM SIGART		Collaborative tagging; clustering; personalization; recommender systems	RETRIEVAL	Collaborative tagging applications allow Internet users to annotate resources with personalized tags. The complex network created by many annotations, often called a folksonomy, permits users the freedom to explore tags, resources or even other user's profiles unbound from a rigid predefined conceptual hierarchy. However, the freedom afforded users comes at a cost: an uncontrolled vocabulary can result in tag redundancy and ambiguity hindering navigation. Data mining techniques, such as clustering, provide a means to remedy these problems by identifying trends and reducing noise. Tag clusters can also be used as the basis for effective personalized recommendation assisting users in navigation. We present a personalization algorithm for recommendation in folksonomies which relies on hierarchical tag clusters. Our basic recommendation framework is independent of the clustering method, but we use a context-dependent variant of hierarchical agglomerative clustering which takes into account the user's current navigation context in cluster selection. We present extensive experimental results on two real world dataset. While the personalization algorithm is successftil in both cases, our results suggest that folksonomics encompassing only one topic domain, rather than many topics, present an easier target for recommendation, perhaps because they are more focused and often less sparse. Furthermore, context dependent cluster selection, an integral step in our personalization algorithm, demonstrates more utility for recommendation in multi-topic folksonomies than in single-topic folksonomies. This observation suggests that topic selection is an important strategy for recommendation in multi-topic folksonomies.	[Shepitsen, Andriy; Gemmell, Jonathan; Mobasher, Bamshad; Burke, Robin] Depaul Univ, Ctr Web Intelligence, Sch Comp, Chicago, IL 60604 USA	Shepitsen, A (reprint author), Depaul Univ, Ctr Web Intelligence, Sch Comp, Chicago, IL 60604 USA.	ashepits@cs.depaul.edu; jgemmell@cs.depaul.edu; mobasher@cs.depaul.edu; rburke@cs.depaul.edu					Bao S., 2007, P 16 INT C WORLD WID, P501, DOI 10.1145/1242572.1242640; BEGELMAN G, 2006, P COLL WEB TAGG WORK, P6; Chen H., 2000, P ACM SIGCHI C HUM F, P145, DOI 10.1145/332040.332418; FEINBERG Jonathan, 2006, P SIGCHI C HUM FACT, P111, DOI 10.1145/1124772.1124792; GEMMELL J, 2008, P 10 INT C DAT WAR K; GEMMELL J, 2008, INTELLIGENT TECHNIQU; Hammond T., 2005, D LIB MAGAZINE, V11, P1082; HAYES C, 2007, INT C WEBL SOC MED; Heymann P., 2006, 200610 COMP SCI DEP; Hotho A, 2006, LECT NOTES COMPUT SC, V4011, P411; Mathes A., 2004, COMPUTER MEDIATED CO; MIKA P, 2007, WEB SEMANTICS SCI SE, V5, P5, DOI 10.1016/j.websem.2006.11.002; Niwa S., 2006, P 3 INT C INF TECHN, P388; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; VOORHEES E, 1999, P TREC, V8, P77; Wu X., 2006, P 15 INT C WORLD WID, P417, DOI 10.1145/1135777.1135839; Xu Z., 2006, COLL WEB TAGG WORKSH; YAN R, 2007, EFFICIENT MANUAL IMA	20	46	46	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA		978-1-60558-093-7				2008							259	266				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BJS80	WOS:000267113700033	
J	Freitas, AA; Timmis, J				Freitas, Alex A.; Timmis, Jon			Revisiting the foundations of artificial immune systems for data mining	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						artificial immune systems (AIS); classification; data mining; machine learning	NEGATIVE SELECTION ALGORITHM; PATTERN-RECOGNITION; ANOMALY DETECTION; CLONAL SELECTION; FAULT-DETECTION; DETECTORS; NETWORKS; MEMORY; TIME	This paper advocates a problem-oriented approach for the design of artificial immune.systems (AIS) for data mining. By problem-oriented approach we mean that, in real-world data mining applications the design of an AIS should take into account the characteristics of the data to be mined together with the application domain: the components of the AIS-such as its representation, affinity function, and immune process-should be tailored for the data and the application. This is in contrast with the majority of the literature, where a very generic AIS algorithm for data mining is developed and there is little or no concern in tailoring the components of the AIS for the data to be mined or the application domain. To support this problem-oriented approach, we provide an extensive critical review of the current literature on AIS for data mining, focusing on the data mining tasks of classification and anomaly detection. We discuss several important lessons to be taken from the natural immune system to design new AIS that are considerably more adaptive than current AIS. Finally, we conclude this paper with a summary of seven limitations of current AIS for data mining and ten suggested research directions.	Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England; Univ York, Dept Elect, Heslington YO10 5DD, Yorks, England; Univ York, Dept Comp Sci, Heslington YO10 5DD, Yorks, England	Freitas, AA (reprint author), Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England.	A.A.Freitas@kent.ac.uk; jtimmis@cs.york.ac.uk	Freitas, Alex/H-1249-2011				AHA DW, 1997, ARTIFICIAL INTELLIGE, V11; Aha D.W., 1998, FEATURE EXTRACTION C, P13; ALVES RT, 2002, DATA MINING KNOWLEDG; Alves RT, 2004, LECT NOTES COMPUT SC, V3242, P1011; Anchor K. P., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004384; Ayara M, 2005, LECT NOTES COMPUT SC, V3627, P404; BACK T, 2000, EVOLUTIONARY COMPUTA, V1, P132; Balthrop J., 2002, P GEN EV COMP C GECC, P3; Bezerra GB, 2004, LECT NOTES COMPUT SC, V3239, P14; Carvalho DR, 2004, INFORM SCIENCES, V163, P13, DOI 10.1016/j.ins.2003.03.013; Castro PD, 2005, LECT NOTES COMPUT SC, V3627, P469; Chao D. L., 2003, Genetic Programming and Evolvable Machines, V4, DOI 10.1023/A:1026139027539; Clare A, 2002, BIOINFORMATICS, V18, P160, DOI 10.1093/bioinformatics/18.1.160; Cserey G, 2004, LECT NOTES COMPUT SC, V3239, P250; Dasgupta D, 1999, ARTIFICIAL IMMUNE SY; DASGUPTA D, 1999, P GEN EV COMP C, P149; Dasgupta D., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004386; Dasgupta D, 2004, LECT NOTES COMPUT SC, V3239, P1; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; de Castro L. N., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1007011; de Castro L. N., 2000, P GECCO 00 WORKSH AR, P36; de Castro LN, 2002, DATA MINING: A HEURISTIC APPROACH, P231; De Castro L.N., 2000, P 6 BRAZ S NEUR NETW, P84; De Castro L. N., 2001, International Journal of Computational Intelligence and Applications, V1, DOI 10.1142/S1469026801000238; De Castro LN, 2002, ARTIFICIAL IMMUNE SY; DOMINGOS P, 1996, P 14 INT JOINT C ART, P1; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FLACH, 2004, P 21 INJT C MACH LEA; FLACH, 2003, P 20 INT C MACH LEAR, P194; Forrest S., 1994, Proceedings of 1994 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.94CH3444-7), DOI 10.1109/RISP.1994.296580; Freitas AA, 2003, LECT NOTES COMPUT SC, V2787, P229; FREITAS AA, 2000, ACM SIGKDD EXPLORATI, V2, P65, DOI 10.1145/360402.360423; Garrett SM, 2005, EVOL COMPUT, V13, P145, DOI 10.1162/1063656054088512; Gonzalez F., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1007012; Gonzalez Fabio A., 2002, P GEN EV COMP C GECC, P1081; Greensmith J, 2005, LECT NOTES COMPUT SC, V3627, P153; Hart E, 2005, LECT NOTES COMPUT SC, V3627, P29; Hart E, 2005, LECT NOTES COMPUT SC, V3627, P483; Hart E, 2004, LECT NOTES COMPUT SC, V3239, P413; Hofmeyr S. A., 1999, P GEN EV COMP C GECC, P1289; Ji Z, 2004, LECT NOTES COMPUT SC, V3102, P287; KIM J, 2002, P C EV COMP, P1015; KIM J, 2003, P C EV COMP, V405; Langley P, 1996, ELEMENTS MACHINE LEA; Liao TW, 1998, APPL ARTIF INTELL, V12, P267, DOI 10.1080/088395198117730; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Lopes AD, 2000, LECT NOTES ARTIF INT, V1952, P33; Michalski R. S, 1983, ARTIF INTELL, V20, P11; MIMS C, WAR MANS GUIDE INFEC; Mirkin B, 2000, GENOMICS AND PROTEOMICS, P157; Mitchell T. M, 1997, MACHINE LEARNING; MITCHELL TM, 1980, NEED BIASES LEARNING; Neal M, 2003, LECT NOTES COMPUT SC, V2787, P168; Perelson A.S., 1989, IMMUNOL REV, V10, P5; Quinlan JR, 1993, P 10 INT C MACH LEAR, P236; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; Sahan S, 2005, LECT NOTES COMPUT SC, V3627, P456; Sarafijanovic S, 2004, LECT NOTES COMPUT SC, V3239, P342; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Secker A., 2003, P C EV COMP CANB AUS, P131; Sompayrac L, 2003, IMMUNE SYSTEM WORKS; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Stepney Susan, 2005, INT J UNCONV COMPUT, V1, P315; Stibor T, 2005, LECT NOTES COMPUT SC, V3627, P262; Tan P-N, 2006, INTRO DATA MINING; Tarakanov A. O., 2003, IMMUNOCOMPUTING PRIN; TARAKANOV AO, 2004, LECT NOTES COMPUTER, V3685, P394; Tarakanov AO, 2004, LECT NOTES COMPUT SC, V3239, P236; Taylor C.C., 1994, MACHINE LEARNING NEU; Taylor DW, 2003, LECT NOTES COMPUT SC, V2787, P34; Timmis J, 2002, DATA MINING: A HEURISTIC APPROACH, P209; Timmis J, 2000, BIOSYSTEMS, V55, P143, DOI 10.1016/S0303-2647(99)00092-1; TIMMIS J, 2004, COMPUTATION CELLS TI, P51; Timmis J, 2001, KNOWL-BASED SYST, V14, P121, DOI 10.1016/S0950-7051(01)00088-0; Ting K., 1994, P 10 CAN C ART INT, P91; Walter P, 2002, MOL BIOL CELL; Watkins A., 2001, THESIS MISSISSIPPI S; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; Watkins A., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004472; Watkins A. B., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1007049; Weiss S. M., 1998, PREDICTIVE DATA MINI; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; White JA, 2003, LECT NOTES COMPUT SC, V2787, P181; Witten IH, 2005, DATA MINING PRACTICA	84	46	52	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	AUG	2007	11	4					521	540		10.1109/TEVC.2006.884042		20	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	197TL	WOS:000248579300007	
J	Kim, SY; Jung, TS; Suh, EH; Hwang, HS				Kim, SY; Jung, TS; Suh, EH; Hwang, HS			Customer segmentation and strategy development based on customer lifetime value: A case study	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						customer lifetime value; customer segmentation; data mining	MODEL	The more a marketing paradigm evolves, the more long-term relationship with customers gains its importance. CRM, a recent marketing paradigm, pursues long-term relationship with profitable customers. It can be a starting point of relationship management to understand and measure the true value of customers since marketing management as a whole is to be deployed toward the targeted customers and profitable customers, to foster customers' full profit potential. Corporate success depends on an organization's ability to build and maintain loyal and valued customer relationships. Therefore, it is essential to build refined strategies for customers based on their value. In this paper, we propose a framework for analyzing customer value and segmenting customers based on their value. After segmenting customers based on their value, strategies building according to customer segment will be illustrated through a case study on a wireless telecommunication company. (c) 2005 Elsevier Ltd. All rights reserved.	Hallym Univ, Dept Business Adm, Chunchon 200702, Gangwon do, South Korea; Daegu Univ, Sch Comp & Informat Technol, Gyongsan 712714, Geyongbuk, South Korea; Samsung Econ Res Inst, Dept Management Strategy, Seoul 140722, South Korea; POSTECH, Dept Ind Engn, Pohang 790784, Gyeongbuk, South Korea	Hwang, HS (reprint author), Hallym Univ, Dept Business Adm, 39 Hallymdaehak gil, Chunchon 200702, Gangwon do, South Korea.	hshwang@hallym.ac.kr					Duboff R S, 1992, J Bus Strategy, V13, P10, DOI 10.1108/eb039521; Dwyer F. Robert, 1997, J DIRECT MARKETING, V11, P6, DOI 10.1002/(SICI)1522-7138(199723)11:4<6::AID-DIR3>3.0.CO;2-T; Gloy B. A., 1997, Agribusiness (New York), V13, P335, DOI 10.1002/(SICI)1520-6297(199705/06)13:3<335::AID-AGR7>3.3.CO;2-A; HAWKES VA, 2000, CRM FORUM RESOURCES, P1; HOEKSTRA JC, 1999, J MARKET FOCUSED MAN, V3, P257, DOI 10.1023/A:1009842805871; Hwang H, 2004, EXPERT SYST APPL, V26, P181, DOI 10.1016/S0957-4174(03)00133-7; Jain D., 2002, J INTERACT MARK, V16, P34, DOI DOI 10.1002/DIR.10032; JUTLA D, 2001, P 34 ANN HAW INT C S, P1; Kim BD, 1999, J INTERACT MARK, V13, P2, DOI 10.1002/(SICI)1520-6653(199923)13:4<2::AID-DIR1>3.0.CO;2-D; Kim J, 2003, J INTERACT MARK, V17, P5, DOI 10.1002/dir.10051; Kotler P., 1997, MARKETING MANAGEMENT; Mulhern FJ, 1999, J INTERACT MARK, V13, P25, DOI 10.1002/(SICI)1520-6653(199924)13:1<25::AID-DIR3>3.0.CO;2-L; Percy L., 1997, ADVERTISING COMMUNIC; Rosset S., 2002, P ACM SIGKDD INT C K, P332; Stone M, 1996, LONG RANGE PLANN, V29, P675, DOI 10.1016/0024-6301(96)00061-1; Verhoef PC, 2001, DECIS SUPPORT SYST, V32, P189, DOI 10.1016/S0167-9236(01)00110-5	16	46	48	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2006	31	1					101	107		10.1016/j.eswa.2005.09.004		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	034CY	WOS:000236903700011	
J	Perner, P; Perner, H; Muller, B				Perner, P; Perner, H; Muller, B			Mining knowledge for HEp-2 cell image classification	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						image mining; data mining; medical diagnosis; HEp-2 cell classification; fluorescence image analysis; decision tree induction; texture classification		HEp-2 cells are used for the identification of antinuclear autoantibodies (ANAs). They allow for recognition of over 30 different nuclear and cytoplasmic patterns, which are given by upwards of 100 different autoantibodies. The identification of the patterns has recently been done manually by a human inspecting the slides with a microscope. In this paper, we present results on the analysis and classification of cells using image analysis and data mining techniques. Starting from a knowledge acquisition process with a human operator, we developed an image analysis and feature extraction algorithm. The collection of the dataset was done based on an expert's image reading and based on the automatic extracted features. A dataset containing 132 features for each entry was set up and given to a data mining algorithm to find out the relevant features among this large feature set and to construct the classification knowledge. The classifier was evaluated by cross validation. The results gave the expert new insights into the necessary features and the classification knowledge and show the feasibility of an automated inspection system. (C) 2002 Elsevier Science B.V. All rights reserved.	Inst Comp Vis & Appl Comp Sci, D-04275 Leipzig, Germany	Perner, P (reprint author), Inst Comp Vis & Appl Comp Sci, August Bebel Str 16-20, D-04275 Leipzig, Germany.						ABE Y, 1994, CLIN CHIM ACTA, V224, P103, DOI 10.1016/0009-8981(94)90126-0; BAIRD HS, 1995, SHAPE STRUCTURE PATT, P100; BRADWELL AR, 1995, ATLAS HEP 2 PATTERNS; CIOS KJ, IEEE ENG MED BIOL MA, V19, P17; CONRAD K, 2000, AUTOANTIGENS AUTOANT; Garcia P, 1999, COMPUT VIS IMAGE UND, V74, P227, DOI 10.1006/cviu.1999.0760; Matheron G, 1975, RANDOM SETS INTEGRAL; NAKABAYASHI I, 2001, AM J CLIN PATHOL, P115; Niemann H., 1990, PATTERN ANAL UNDERST; OTSU N, 1979, IEEE T SMC, V9, P38; PERNER P, 1998, LNCS, V1451, P475; PERNER P, 1994, MACH VISION APPL, V7, P135, DOI 10.1007/BF01211659; Petrou M., 1999, IMAGE PROCESSING FUN; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Stoyan D., 1987, STOCHASTIC GEOMETRY; WEISS SM, 1990, COMPUTER SYSTEMS THA	16	46	46	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	SEP-OCT	2002	26	1-2					161	173		10.1016/S0933-3657(02)00057-X		13	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	597BJ	WOS:000178201900009	
J	Barbara, D; Couto, J; Jajodia, S; Wu, NN				Barbara, D; Couto, J; Jajodia, S; Wu, NN			ADAM: A testbed for exploring the use of data mining in intrusion detection	SIGMOD RECORD			English	Article						intrusion detection software; data mining; pattern analysis; cyber attacks		Intrusion detection systems have traditionally been based on the characterization of an attack and the tracking of the activity on the system to see if it matches that characterization. Recently, new intrusion detection systems based on data mining are making their appearance in the field. This paper describes the design and experiences with the ADAM (Audit Data Analysis and Mining) system, which we use as a testbed to study how useful data mining techniques can be in intrusion detection.	George Mason Univ, Ctr Secure Informat Syst, Fairfax, VA 22303 USA	Barbara, D (reprint author), George Mason Univ, Ctr Secure Informat Syst, Fairfax, VA 22303 USA.						Agrawal R., 1993, P ACM SIGMOD C MAN D; ANDERSON D, NIDES SUMMARY; Anderson D., 1995, SRICSL9506; BARBARA D, 2001, P IEEE SMC INF ASS W; Barbara D., 2001, P 1 SIAM INT C DAT M; Barnett V., 1994, OUTLIERS STAT DATA; Bishop Y.M.M., 1975, DISCRETE MULTIVARIAT; Cohen W.W., 1995, P 12 INT C MACH LEAR; Denning D.E., 1997, IEEE T SOFTWARE ENG, P222; FAYYAD UM, 1966, ADV KNOWLEDGE DISCOV; General Accounting Office, 1996, GAOAIMD9684; ILGUN K, 1992, THESIS U CALIFORNA S; JAVITZ HS, SRI IDES STAT ANOMAL; LEE W, 1998, P 7 UNSENIX SEC S; Lee W, 1999, P IEEE S SEC PRIV; LEE W, 1998, P INT C KNOWL DAT MI; LINDQVIST U, P 1999 IEEE S SEC PR, P146; LUNT TF, 1988, P IEEE S SEC PRIV, P18; MUKKAMALA R, 1999, P 13 ANN IFIP WG 11; Porras P., 1997, P 20 NAT INF SYST SE, P353; PORRAS PA, 1992, THESIS U CALIFORNIA; SAGER I, 2000, BUSINESS WEEK   0221; SMAHA S, 1990, HAYSTACK AUDIT TRAIL; Van Trees H. L., 2001, DETECTION ESTIMATION; VIGNA G, 1998, P 14 ANN INF THEOR 5; Witten IH, 2000, DATA MINING PRACTICA; *MIT LINC LAB, MIT LINC LAB DARPA I	27	46	48	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0163-5808		SIGMOD RECORD	Sigmod Rec.	DEC	2001	30	4					15	24				10	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	499JA	WOS:000172567000002	
J	Spiliopoulou, M; Pohle, C				Spiliopoulou, M; Pohle, C			Data mining for measuring and improving the success of web sites	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						web usage mining; contact efficiency; conversion efficiency; web merchandizing; web site analysis; data mining; e-commerce	TOOL	For many companies, competitiveness in e-commerce requires a successful presence on the web. Web sites are used to establish the company's image, to promote and sell goods and to provide customer support. The success of a web site affects and reflects directly the success of the company in the electronic market. In this study, we propose a methodology to improve the "success" of web sites. based on the exploitation of navigation pattern discovery. In particular, we present a theory, in which success is modelled on the basis of the navigation behaviour of the site's users. We then exploit WUM, a navigation pattern discovery miner, to study how the success of a site is reflected in the users' behaviour. With WUM we measure the success of a site's components and obtain concrete indications of how the site should be improved. We report on our first experiment!; with an online catalog, the success of which we have studied. Our mining analysis has shown very promising results, on the basis of which the site is currently undergoing concrete improvements.	Humboldt Univ, Inst Informat Syst, D-10178 Berlin, Germany	Spiliopoulou, M (reprint author), Humboldt Univ, Inst Informat Syst, Spandauer Str 1, D-10178 Berlin, Germany.						AGRAWAL R, 1995, P INT C DAT ENG TAIP; Agrawal R., 1993, SIGMOD, P207; ALPAR P, 1999, 4 INT TAG WIRTSCH 19; Berendt B, 2000, VLDB J, V9, P56, DOI 10.1007/s007780050083; Berthon P, 1996, J ADVERTISING RES, V36, P43; BUCHNER AG, 1998, ACM SIGMOD RECOR DEC; BUCHNER AG, 1999, NAVIGATION PATTERN D; Chen MS, 1996, INT CON DISTR COMP S, P385; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Cooley R., 1999, J KNOWLEDGE INFORM S, V1, P5; COOLEY R, 1997, 9 IEEE INT C TOOLS A; Dreze X, 1997, J ADVERTISING RES, V37, P77; Eighmey J, 1997, J ADVERTISING RES, V37, P59; GREEN PE, 1978, J CONSUM RES, V5, P103, DOI 10.1086/208721; Ho J., 1997, J COMPUTER MEDIATED, V3; Joachims T., 1997, P 15 INT JOINT C ART, P770; MARTIN D, 1999, WEBKDD 99; Masand B, 2000, LNAI, V1836; PARTHASARATHY S, 1999, P C INF KNOWL MAN; Perkowitz M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Spiliopoulou M, 1999, COMPUT SYST SCI ENG, V14, P113; SPILIOPOULOU M, 1999, P WORKSH MACH LEARN; SPILIOPOULOU M, 2000, HDB DATA MINING MARK; Spiliopoulou M, 1999, LECT NOTES COMPUT SC, V1590, P184; SULLIVAN T, 1997, P WEB C 97; WEXELBLAT A, 1996, P AAAI SPRING S ACQ; Wu KL, 1998, IBM SYST J, V37, P89; ZAIANE O, 1998, ADV DIGITAL LIB, P19; Zamir O., 1997, KDD 97, P287	29	46	47	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					85	114		10.1023/A:1009800113571		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900005	
J	Han, EH; Karypis, G; Kumar, V				Han, EH; Karypis, G; Kumar, V			Scalable parallel data mining for association rules	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; parallel processing; association rules; load balance; scalability	DATABASES	In this paper, we propose two new parallel formulations of the Apriori algorithm that is used for computing association rules. These new formulations, IDD and HD, address the shortcomings of two previously proposed parallel formulations CD and DD. Unlike the CD algorithm, the IDD algorithm partitions the candidate set intelligently among processors to efficiently parallelize the step of building the hash tree. The IDD algorithm also eliminates the redundant work inherent in DD, and requires substantially smaller communication overhead than DD. But IDD suffers from the added cost due to communication of transactions among processors. HD is a hybrid algorithm that combines the advantages of Co and DD. Experimental results on a 128-processor Gray T3E show that HD scales just as well as the CD algorithm with respect to the number of transactions, and scales as well as IDD with respect to increasing candidate set size.	Univ Minnesota, USA, HPC Res Ctr, Minneapolis, MN 55455 USA; Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Han, EH (reprint author), Univ Minnesota, USA, HPC Res Ctr, Minneapolis, MN 55455 USA.	han@cs.umn.edu; karypis@cs.umn.edu; kumar@cs.umn.edu					Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; AGRAWAL R, 1993, P 1993 ACM SIGMOD IN; Agrawal R., 1994, P 20 INT C VER LARG, P487; Cheung DW, 1996, IEEE T KNOWL DATA EN, V8, P911, DOI 10.1109/69.553158; HAN E, 1997, P 1997 ACM SIGMOD IN; Kumar V., 1994, INTRO PARALLEL COMPU; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; Park J., 1995, P 4 INT C INF KNOWL; PARK JS, 1995, P 1995 ACM SIGMOD IN; Savasere A, 1995, P 21 INT C VER LARG, P432; SHINTANI T, 1996, P C PAR DISTR INF SY; Srikant R., 1995, P 21 INT C VER LARG, P407; STONEBRAKER M, 1993, P 19 VLDB C, P688; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; Zaki M.J., 1997, P 3 INT C KNOWL DISC; ZAKI MJ, 1997, DATA MINING KNOWLEDG, V1	16	46	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY-JUN	2000	12	3					337	352				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	325GQ	WOS:000087668200001	
J	Chan, CC				Chan, CC			A rough set approach to attribute generalization in data mining	INFORMATION SCIENCES			English	Article						rough sets; data mining; inductive learning		This paper presents a method for updating approximations of a concept incrementally. The results can be used to implement a quasi-incremental algorithm for learning classification rules from very large data bases generalized by dynamic conceptual hierarchies provided by users. In general, the process of attribute generalization may introduce inconsistency into a generalized relation. This issue is resolved by using the inductive learning algorithm, LERS based on rough set theory. (C) 1998 Elsevier Science Inc. All rights reserved.	Univ Akron, Dept Math Sci, Akron, OH 44325 USA	Chan, CC (reprint author), Univ Akron, Dept Math Sci, Akron, OH 44325 USA.						Cai Y., 1991, Knowledge discovery in databases; CHAN CC, 1989, P 4 INT S METH INT S, P281; CHAN CC, 1991, INT J SOFTW ENG KNOW, V1, P439, DOI 10.1142/S0218194091000299; GRZYMALABUSSE JW, 1991, MANAGING UNCERTAINTY; Grzymala-Busse J. W., 1988, Journal of Intelligent and Robotic Systems: Theory and Applications, V1, DOI 10.1007/BF00437317; GRZYMALABUSSE JW, 1991, P 3 MIDW ART INT COG, P103; Han J., 1996, ADV KNOWLEDGE DISCOV, P399; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; RAGHAVAN VV, 1995, 23 ANN COMP SCI WORK, P1	9	46	54	ELSEVIER SCIENCE INC	NEW YORK	655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JUN	1998	107	1-4					169	176		10.1016/S0020-0255(97)10047-0		8	Computer Science, Information Systems	Computer Science	ZW328	WOS:000074399500009	
J	Glymour, C; Madigan, D; Pregibon, D; Smyth, P				Glymour, C; Madigan, D; Pregibon, D; Smyth, P			Statistical inference and data mining	COMMUNICATIONS OF THE ACM			English	Article									UNIV CALIF SAN DIEGO, LA JOLLA, CA 92093 USA; UNIV WASHINGTON, SEATTLE, WA USA; AT&T BELL LABS, MURRAY HILL, NJ 07974 USA	Glymour, C (reprint author), CARNEGIE MELLON UNIV, PITTSBURGH, PA 15213 USA.						EFRON B, 1982, SOC IND APPLIED MATH, V38; HECKERMAN D, UNPUB DATA MINING KN; Hoaglin D. C., 1983, UNDERSTANDING ROBUST; MILLER RG, 1981, SIMULTANEOUS STATIST; RAFTERY AE, 1994, CTR STUDIES DEMOGRAP; Scheines R., 1994, TETRAD 2 TOOLS CAUSA; Scheines R., 1993, CAUSATION PREDICTION; Schervish M. J., 1995, THEORY STAT; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SMITH AFM, 1993, J ROY STAT SOC B MET, V55, P3; Spirtes P, 1995, P 11 C UNC ART INT U, P499; Stigler S. M., 1986, HIST STAT	12	46	48	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0001-0782		COMMUN ACM	Commun. ACM	NOV	1996	39	11					35	41		10.1145/240455.240466		7	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	VR306	WOS:A1996VR30600010	
J	Huang, CL; Dun, JF				Huang, Cheng-Lung; Dun, Jian-Fan			A distributed PSO-SVM hybrid system with feature selection and parameter optimization	APPLIED SOFT COMPUTING			English	Article						particle swarm optimization; support vector machines; distributed computing; web service; data mining; feature selection	PARTICLE SWARM OPTIMIZATION; SUPPORT VECTOR MACHINES; ALGORITHM; GA	This study proposed a novel PSO-SVM model that hybridized the particle swarm optimization (PSO) and support vector machines (SVM) to improve the classification accuracy with a small and appropriate feature subset. This optimization mechanism combined the discrete PSO with the continuous-valued PSO to simultaneously optimize the input feature subset selection and the SVM kernel parameter setting. The hybrid PSO-SVM data mining system was implemented via a distributed architecture using the web service technology to reduce the computational time. In a heterogeneous computing environment, the PSO optimization was performed on the application server and the SVM model was trained on the client (agent) computer. The experimental results showed the proposed approach can correctly select the discriminating input features and also achieve high classification accuracy. (C) 2007 Elsevier B.V. All rights reserved.	[Huang, Cheng-Lung] Natl Kaohsiung First Univ Sci & Technol, Dept Informat Management, Kaohsiung 811, Taiwan; [Dun, Jian-Fan] Huafan Univ, Dept Informat Management, Taipei, Taiwan	Huang, CL (reprint author), Natl Kaohsiung First Univ Sci & Technol, Dept Informat Management, 2 Juoyue Rd, Kaohsiung 811, Taiwan.	clhuang@ccms.nkfust.edu.tw			National Science Council of the Republic of China, Taiwan [NSC 94-2213-E327-007]	The authors would like to thank the National Science Council of the Republic of China, Taiwan, for financially supporting this research under Contract No. NSC 94-2213-E327-007.	Agrafiotis DK, 2002, J MED CHEM, V45, P1098, DOI 10.1021/jm0104668; Allahverdi A, 2006, COMPUT OPER RES, V33, P1056, DOI 10.1016/j.cor.2004.09.002; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chatterjee A, 2006, COMPUT OPER RES, V33, P859, DOI 10.1016/j.cor.2004.08.012; Cristianini N., 2000, INTRO SUPPORT VECTOR; Da Y., 2005, NEUROCOMPUTING, V63, P527, DOI 10.1016/j.neucom.2004.07.002; Du Feng, 2005, Pattern Recognition Letters, V26, DOI 10.1016/j.patrec.2004.11.002; Eberhart R., 2001, P 2001 C EV COMP, P81; Frohlich H, 2003, PROC INT C TOOLS ART, P142, DOI 10.1109/TAI.2003.1250182; Gorodetsky V, 2003, INTERNATIONAL CONFERENCE ON INTEGRATION OF KNOWLEDGE INTENSIVE MULTI-AGENT SYSTEMS, P710, DOI 10.1109/KIMAS.2003.1245125; Hsu C.W., 2003, PRACTICAL GUIDE SUPP; Hsu C.W., 2002, MACH LEARN, V46, P219; Huang CL, 2006, EXPERT SYST APPL, V31, P231, DOI 10.1016/j.eswa.2005.09.024; Jiang CW, 2005, MATH COMPUT SIMULAT, V68, P57, DOI 10.1016/j.matcom.2004.10.003; Kecman V., 2001, LEARNING SOFT COMPUT; KENNEDY J, 1995, P IEEE INT C NEUR NE, P1942, DOI DOI 10.1109/ICNN.1995.488968; KENNEDY J, 1997, P WORLD MULT SYST CY, P4104, DOI DOI 10.1109/ICSMC.1997.637339; Kennedy JF, 2001, SWARM INTELLIGENCE; Knerr S., 1990, NEUROCOMPUTING ALGOR; KREBEL U, 1999, ADV KERNEL METHODS S, P254; LI ST, 2001, P 34 ANN HAW INT C S; Lian ZG, 2006, APPL MATH COMPUT, V175, P773, DOI 10.1016/j.amc.2005.07.042; Lin HT, 2003, STUDY SIGMOID KERNEL; Mendes R, 2004, IEEE T EVOLUT COMPUT, V8, P204, DOI [10.1109/TEVC.2004.826074, 10.1109/tevc.2004.826074]; Murphy P. M., 2001, UCI REPOSITORY MACHI; Ong CS, 2005, EXPERT SYST APPL, V29, P41, DOI 10.1016/j.eswa.2005.01.003; Punch W.F., 1993, 5 INT C GEN ALG CHAM, P557; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Scholkopf B., 2000, STAT LEARNING KERNEL; Shi XH, 2005, INFORM PROCESS LETT, V93, P255, DOI 10.1016/j.ipl.2004.11.003; Shi Y., 1998, P IEEE INT C EV COMP, P69, DOI DOI 10.1109/ICEC.1998.699146; van den Bergh F, 2006, INFORM SCIENCES, V176, P937, DOI 10.1016/j.ins.2005.02.003; Vapnik V.N., 1995, NATURE STAT LEARNING; Yin PY, 2006, COMPUT STAND INTER, V28, P441, DOI 10.1016/j.csi.2005.03.005; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	36	45	51	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946		APPL SOFT COMPUT	Appl. Soft. Comput.	SEP	2008	8	4					1381	1391		10.1016/j.asoc.2007.10.007		11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	343DW	WOS:000258833900011	
J	Chien, CF; Wang, WC; Cheng, JC				Chien, Chen-Fu; Wang, Wen-Chih; Cheng, Jen-Chieh			Data mining for yield enhancement in semiconductor manufacturing and an empirical study	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; decision tree; clustering; defect diagnosis; yield enhancement; semiconductor manufacturing		During wafer fabrication, process data, equipment data, and lot history will be automatically or semi-automatically recorded and accumulated in database for monitoring the process, diagnosing faults, and managing manufacturing. However, in high-tech industry such as semiconductor manufacturing, many factors that are interrelated affect the yield of fabricated wafers. Engineers who rely on personal domain knowledge cannot find possible root causes of defects rapidly and effectively. This study aims to develop a framework for data mining and knowledge discovery from database that consists of a Kruskal Wallis test, K-means clustering, and the variance reduction splitting criterion to investigate the huge amount of semiconductor manufacturing data and infer possible causes of faults and manufacturing process variations. The extracted information and knowledge is helpful to engineers as a basis for trouble shooting and defect diagnosis. We validated this approach with an empirical study in a semiconductor foundry company in Taiwan and the results demonstrated the practical viability of this approach. (c) 2006 Elsevier Ltd. All rights reserved.	Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, Hsinchu 30033, Taiwan	Chien, CF (reprint author), Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, 101 Sect 2 Kuang Fu Rd, Hsinchu 30033, Taiwan.	cfchien@mx.nthu.edu.tw					Berry M. R. J., 1997, DATA MINING TECHNIQU; Bose I, 2001, INFORM MANAGE-AMSTER, V39, P211, DOI 10.1016/S0378-7206(01)00091-X; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Braha D, 2002, IEEE T SEMICONDUCT M, V15, P91, DOI 10.1109/66.983448; Breiman L, 1984, CLASSIFICATION REGRE; CUNNINGHAM SP, 1995, IEEE T SEMICONDUCT M, V8, P103, DOI 10.1109/66.382273; Daniel W.W., 1990, APPL NONPARAMETRIC S; Deboeck G., 1998, VISUAL EXPLORATION F; Evans S, 1997, COMPUT BIOMED RES, V30, P337, DOI 10.1006/cbmr.1997.1454; FAN CM, 2001, P IEEE INT S SEM MAN, P171; Fayyad U., 1997, Proceedings. Ninth International Conference on Scientific and Statistical Database Management (Cat. No.97TB100150), DOI 10.1109/SSDM.1997.621141; Fayyad U., 1996, COMMUN ACM, V39, P11; FU Y, 1997, IEEE POTENTIALS, V164, P18; Han J., 2001, DATA MINING CONCEPTS; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; KRUSKAL WH, 1952, ANN MATH STAT, V30, P271; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; McQueen J., 1967, P 5 BERK S MATH STAT, P281; Peng C.-Y, 2003, INT J SERVICE TECHNO, V4, P365, DOI 10.1504/IJSTM.2003.003621; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Tsuda H., 2000, Proceedings of ISSM2000. Ninth International Symposium on Semiconductor Manufacturing (IEEE Cat. No.00CH37130), DOI 10.1109/ISSM.2000.993660	23	45	45	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2007	33	1					192	198		10.1016/j.eswa.2006.04.014		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	134UV	WOS:000244110600018	
J	Nielsen, AA				Nielsen, Allan Aasbjerg			The regularized iteratively reweighted MAD method for change detection in multi- and hyperspectral data	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article						canonical correlation analysis (CCA); iteratively reweighted multivariate alteration detection (IR-MAD); MAD transformation; regularization or penalization; remote sensing	UNSUPERVISED CHANGE DETECTION; PRINCIPAL COMPONENTS; REGRESSION; VARIABLES; IMAGERY; SETS	This paper describes new extensions to the previously published multivariate alteration detection (MAD) method for change detection in bi-temporal, multi- and hypervariate data such as remote sensing imagery. Much like boosting methods often applied in data mining work, the iteratively reweighted (IR) MAD method in a series of iterations places increasing focus on "difficult" observations, here observations whose change status over time is uncertain. The MAD method is based on the established technique of canonical correlation analysis: for the multivariate data acquired at two points, in time and covering the same geographical region, we calculate the canonical variates and subtract them from each other. These orthogonal differences contain maximum information on joint change in all variables (spectral bands). The change detected in this fashion is invariant to separate linear (affine) transformations in the originally measured variables at the two points in time, such as 1) changes in gain and offset in the measuring device used to acquire the data, 2) data normalization or calibration schemes that are linear (affine) in the gray values of the original variables, or 3) orthogonal or other affine transformations, such as principal component (PC) or maximum autocorrelation factor (MAF) transformations. The IR-MAD method first calculates ordinary canonical and original MAD variates. In the following iterations we apply different weights to the observations, large weights being assigned to observations that show little change, i.e., for which the sum of squared, standardized MAD variates is small, and small weights being assigned to observations for which the sum is large. Like the original MAD method, the iterative extension is invariant to linear (affine) transformations of the original variables. To stabilize solutions to the (IR-)MAD problem, some form of regularization may be needed. This is especially useful for work on hyperspectral data. This paper describes ordinary two-set canonical correlation analysis, the MAD transformation, the iterative extension, and three regularization schemes. A simple case with real Landsat Thematic Mapper (TM) data at one point in time and (partly) constructed data at the other point in time that demonstrates the superiority of the iterative scheme over the original MAD method is shown. Also, examples with SPOT High Resolution Visible data from an agricultural region in Kenya, and hyperspectral airborne HyMap data from a small rural area in southeastern Germany are given. The latter case demonstrates the need for regularization.	Tech Univ Denmark, Informat & Math Modelling, DK-2800 Lyngby, Denmark	Nielsen, AA (reprint author), Tech Univ Denmark, Informat & Math Modelling, DK-2800 Lyngby, Denmark.	aa@imm.dtu.dk					Anderson TW, 2003, INTRO MULTIVARIATE S; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009; Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678; BRUZZONE L, 2001, MULTITEMP C TRENT IT; CANTY MJ, INT J REMOTE SENS; Canty MJ, 2004, REMOTE SENS ENVIRON, V91, P441, DOI 10.1016/j.rse.2003.10.024; CANTY MJ, 2004, 11 SPIE INT S REM SE; Carroll J. D., 1968, P 76 ANN CONV AM PSY, P227; Cocks T., 1998, P 1 EARSEL WORKSH IM, P37; COOLEY WW, 1971, MULTIVARIATE DATA AN; Coppi R, 1989, MULTIWAY DATA ANAL; Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675; DEVLIN SJ, 1981, J AM STAT ASSOC, V76, P354, DOI 10.2307/2287836; FUNG T, 1987, PHOTOGRAMM ENG REM S, V53, P1649; GATH I, 1988, IEEE T PATTERN ANAL, V3, P773; GONG P, 1993, CANADIAN J REMOTE SE, V19, P22; Greenberger D. B., 1988, J SMALL BUS MANAGE, V26, P1; Hansen P C, 1998, RANK DEFICIENT DISCR; Hastie T., 2001, ELEMENTS STAT LEARNI; HAVERKAMP D, 2003, CHANGE DETECTION USI; HILGER KB, 2001, THESIS TU DENMARK LY; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Huber P.J., 1981, ROBUST STAT; Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P2653, DOI 10.1109/36.803413; KETTENRI.JR, 1971, BIOMETRIKA, V58, P433, DOI 10.2307/2334380; KING RL, 2005, MULTITEMP C BIL MS M; MacKay D. J., 2003, INFORM THEORY INFERE; Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962; NIELSEN AA, 2005, 4 EARSEL WORKSH IM S; NIELSEN AA, 2005, 6 GEOM WEEK C BARC S; Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4; NIELSEN AA, 2003, P 3 EARSEL WORKSH IM, P115; NIELSEN AA, 1997, MULTIVARIATE ALTERAT; NIELSEN AA, 2005, MULTITEMP C BIL MS M; NIELSEN AA, 1999, MACH VIS ADV IMAGE P; Nielsen A.A., 1994, THESIS TU DENMARK LY; NIELSEN AA, 2004, 12 AUSTR REM SENS PH; NIEMEYER I, 2003, 25 S SAF NUCL MAT MA; NIEMEYER I, 2004, IMPROVEMENTS OBJECT; Press WH, 1992, NUMERICAL RECIPES C; Ramsay JO, 1997, FUNCTIONAL DATA ANAL; Rice J, 1995, MATH STAT DATA ANAL; SINGH A, 1989, INT J REMOTE SENS, V10, P989; SMITS P, 2003, MULTITEMP C ISPR IT; Switzer P., 1984, 6 STANF U; SWITZER P, 1986, REMOTE SENS ENVIRON, V20, P85, DOI 10.1016/0034-4257(86)90015-5; Vinod H. D., 1976, J ECONOMETRICS, V4, P147, DOI 10.1016/0304-4076(76)90010-5; Wiemker R., 1997, P 3 INT AIRB REM SEN, V1, P640; WINDFELD K, 1992, THESIS TU DENMARK LY; Yu B, 1999, IEEE T GEOSCI REMOTE, V37, P2569, DOI 10.1109/36.789651; ZHANG W, 2004, P 11 SPIE INT S REM, V5574, P184	54	45	46	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1057-7149		IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	FEB	2007	16	2					463	478		10.1109/TIP.2006.888195		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	127XI	WOS:000243619200015	
J	Wang, LX				Wang, LX			The WM method completed: A flexible fuzzy system approach to data mining	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						data mining; fuzzy systems; predictive models		In this paper, the so-called Wang-Mendel (WM) method for generating fuzzy rules from data is enhanced to make it a comprehensive and flexible fuzzy system approach to data description and prediction. In the description part, the core ideas of the WM method are used to develop three methods to extract fuzzy IF-THEN rules from data. The first method shows how to extract rules for the user-specifed cases, the second method generates all the rules that can be generated directly from the data, and the third method extrapolates the rules generated by the second method over the entire domain of interest. In the prediction part, two fuzzy predictive models are constructed based on the fuzzy IF-THEN rules extracted by the methods of the description part. The first model gives a continuous output and is suitable for predicting continuous variables, and the second model gives a piecewise constant output and is suitable for predicting categorical variables. We show that by comparing the prediction accuracy of the fuzzy predictive models with different numbers of fuzzy sets covering the input variables, we can rank the importance of the input variables. We also propose an algorithm to optimalize the fuzzy predictive models, and show how to use the models to solve pattern recognition problems. Throughout this paper, we use a set of real data from a steel rolling plant to demonstrate the ideas and test the models. The core codes of the WM method are included in the Appendix.	Hong Kong Univ Sci & Technol, Dept Elect & Elect Engn, Kowloon, Hong Kong, Peoples R China	Wang, LX (reprint author), Hong Kong Univ Sci & Technol, Dept Elect & Elect Engn, Kowloon, Hong Kong, Peoples R China.	eewang@ee.ust.hk	wang, li-xin/J-5076-2012				BELLMAN RE, 1961, ADAPTIVE CONTRL PROC; BREIMAN L, 1981, CLASSIFICATION REGRE; Brown M., 1994, NEUROFUZZY ADAPTIVE; CHERKASSKY V, 1994, STAT NEURAL NETWORKS; Cox E., 1999, FUZZY SYSTEMS HDB PR; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Groth Robert, 2000, DATA MINING BUILDING; Guillaume S, 2001, IEEE T FUZZY SYST, V9, P426, DOI 10.1109/91.928739; LIN CT, 1991, IEEE T COMPUT, V40, P1320, DOI 10.1109/12.106218; QUINNLAN J, 1988, C45 PROGRAMS MACHINE; Rumelhart D, 1986, PARALLEL DISTRIBUTED; Wang L. X., 1994, ADAPTIVE FUZZY SYSTE; Wang L.X., 1997, COURSE FUZZY SYSTEMS; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; Wang LX, 2000, IEEE T FUZZY SYST, V8, P470; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; Zimmermann H.J., 1991, FUZZY SET THEORY	19	45	55	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	DEC	2003	11	6					768	782		10.1109/TFUZZ.2003.819839		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	761DW	WOS:000187885700006	
J	Yun, HY; Ha, DS; Hwang, BY; Ryu, KH				Yun, HY; Ha, DS; Hwang, BY; Ryu, KH			Mining association rules on significant rare data using relative support	JOURNAL OF SYSTEMS AND SOFTWARE			English	Article						data mining; potential information; association rules; significant rare data		Recently, data mining, a technique to analyze the stored data in large databases to discover potential information and knowledge, has been a popular topic in database research. In this paper, we study the techniques discovering the association rules which are one of these data mining techniques. And we propose a technique discovering the association rules for significant rare data that appear infrequently in the database but are highly associated with specific data. Furthermore, considering these significant rare data, we evaluate the performance of the proposed algorithm by comparing it with other existing algorithms for discovering the association rules. (C) 2002 Elsevier Inc. All rights reserved.	Chungbuk Natl Univ, Sch Elect & Comp Engn, Cheongju 361763, South Korea; Chonnam Natl Univ, Dept Comp Sci, Kwangju, South Korea; LG Elect Inc, Seoul, South Korea	Ryu, KH (reprint author), Chungbuk Natl Univ, Sch Elect & Comp Engn, Cheongju 361763, South Korea.	martinayun@naver.com; dsha@lge.com; bhhwang@chonnam.ac.kr					ADRIANS P, 1996, DATA MINING; AGRAWAL R, 1995, P C DAT ENG; AGRAWAL R, 1994, P VLDB C; Agrawal R., 1993, P ACM SIGMOD C; Berry M. R. J., 1997, DATA MINING TECHNIQU; CHEN X, 1998, P INT WORKSH ISS APP; CHEN X, 1998, P 9 INT C DAT EXP SY; Garofalakis MN, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P223; HOUTSMA M, 1993, SET ORIENTED MINING; KIM DH, 2000, J SYSTEMS SOFTWARE, V55; KOPERSKI K, 1995, P SSD 95; LIU B, 1999, P ACM SIGKDD KDD 99; OZDEN B, 1998, P ICDE; PARK J, 1998, J KOREA INFORMATION, V16; RAMASWAMY S, 2000, P ACM SIGMOD C; RAMASWAMY S, 1998, P VLDB C; RODDICK JF, 1999, ARC99007 U S AUSTR; SIMOUDIS E, 1996, IEEE EXPERT INTELLIG, V11; YE S, 1998, P INT C SYST MAN CYB	19	45	45	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0164-1212		J SYST SOFTWARE	J. Syst. Softw.	SEP 15	2003	67	3					181	191		10.1016/S0164-1212(02)00128-0		11	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	708DT	WOS:000184552400004	
J	Shekhar, S; Lu, CT; Zhang, PS				Shekhar, S; Lu, CT; Zhang, PS			A unified approach to detecting spatial outliers	GEOINFORMATICA			English	Article						outlier detection; spatial data mining; scalable algorithm for outlier detection	ALGORITHMS	Spatial outliers represent locations which are significantly different from their neighborhoods even though they may not be significantly different from the entire population. Identification of spatial outliers can lead to the discovery of unexpected, interesting, and implicit knowledge, such as local instability. In this paper, we first provide a general definition of S-outhers for spatial outliers. This definition subsumes the traditional definitions of spatial outliers. Second, we characterize the computation structure of spatial outlier detection methods and present scalable algorithms. Third, we provide a cost model of the proposed algorithms. Finally, we experimentally evaluate our algorithms using a Minneapolis-St. Paul (Twin Cities) traffic data set.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Shekhar, S (reprint author), Univ Minnesota, Dept Comp Sci, 200 Union St SE, Minneapolis, MN 55455 USA.						Ankerst M, 1999, P ACM SIGMOD INT C M, P49, DOI 10.1145/304182.304187; Barnett V., 1994, OUTLIERS STAT DATA; Breunig MM, 1999, LECT NOTES ARTIF INT, V1704, P262; COOK D, 1996, VARIOGRAM CLOUD LINK; GRAY J, 1995, P 12 IEEE INT C DAT, P152; GUNTHER O, 1989, P 5 INT C DAT ENG FE; Haining R.P., 1993, SPATIAL DATA ANAL SO; Hawkins D. M., 1980, IDENTIFICATION OUTLI; Johnson RA, 1992, APPL MULTIVARIATE ST; Karypis G, 1998, J PARALLEL DISTR COM, V48, P96, DOI 10.1006/jpdc.1997.1404; Knorr E. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; KNORR E, 1998, P 24 VLDB C; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; LUE A, 1994, NEW TOOLS SPATIAL AN, P45; LUE A, 1995, GEOGR ANAL, V27, P93; ORENSTEIN A, 1984, P S PRINC DAT SYST S, P181; Preparata F., 1988, COMPUTATIONAL GEOMET; Ramaswamy S, 2000, SIGMOD REC, V29, P427; Ruts I, 1996, COMPUT STAT DATA AN, V23, P153, DOI 10.1016/S0167-9473(96)00027-8; SHEKHAR S, 2001, 01045 U MINN DEP COM; SHEKHAR S, 2003, TOUR SPATIAL DATABAS; SHEKHAR S, 2001, GEORGRAPHIC DATA MIN; Shekhar S, 1997, IEEE T KNOWL DATA EN, V9, P102, DOI 10.1109/69.567054; Shekhar S, 1999, IEEE T KNOWL DATA EN, V11, P45, DOI 10.1109/69.755614; Worboys M. F., 1995, GIS COMPUTING PERSPE; YU D, 1999, 9903 U NEW YORK DEP	26	45	63	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-6175		GEOINFORMATICA	Geoinformatica	JUN	2003	7	2					139	166		10.1023/A:1023455925009		28	Computer Science, Information Systems; Geography, Physical	Computer Science; Physical Geography	671KQ	WOS:000182464300004	
J	Smith, KA; Ng, A				Smith, KA; Ng, A			Web page clustering using a self-organizing map of user navigation patterns	DECISION SUPPORT SYSTEMS			English	Article						data mining; self-organizing maps; clustering; web usage mining		The continuous growth in the size and use of the Internet is creating difficulties in the search for information. A sophisticated method to organize the layout of the information and assist user navigation is therefore particularly important. In this paper, we evaluate the feasibility of using a self-organizing map (SOM) to mine web log data and provide a visual tool to assist user navigation. We have developed LOGSOM, a system that utilizes Kohonen's self-organizing map to organize web pages into a two-dimensional map. The organization of the web pages is based solely on the users' navigation behavior, rather than the content of the web pages. The resulting map not only provides a meaningful navigation tool (for web users) that is easily incorporated with web browsers, but also serves as a visual analysis tool for webmasters to better understand the characteristics and navigation behaviors of web users visiting their pages. (C) 2002 Elsevier Science B.V. All rights reserved.	Monash Univ, Sch Business Syst, Clayton, Vic, Australia	Smith, KA (reprint author), Monash Univ, Sch Business Syst, POB 63B, Clayton, Vic, Australia.		Smith-Miles, Kate/B-7493-2008				Cooley R., 1999, J KNOWLEDGE INFORM S, V1, P5; Fu YJ, 2000, LECT NOTES COMPUT SC, V1836, P21; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Kaski S, 1998, NEUROCOMPUTING, V21, P101, DOI 10.1016/S0925-2312(98)00039-3; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; KOHONEN T, 1981, TKKFA463 HELS U TECH; LAGUS K, 1996, 2 INT C KNOWL DISC D, P238; Lan B, 2000, LECT NOTES COMPUT SC, V1836, P112; MOBASHER B, 1999, TR99010 DEP U DEP CO; Murray D, 2000, LECT NOTES COMPUT SC, V1836, P7; Nielsen J., 1990, Communications of the ACM, V33, DOI 10.1145/77481.77483; PERKOWITZ M, 1997, P WWW6	13	45	53	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	MAY	2003	35	2					245	256		10.1016/S0167-9236(02)00109-4		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	672YE	WOS:000182550800005	
J	Garofalakis, M; Rastogi, R; Shim, K				Garofalakis, M; Rastogi, R; Shim, K			Mining sequential patterns with regular expression constraints	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; constraints; sequential patterns; regular expressions; finite automata		Discovering sequential patterns is an important problem in data mining with a host of application domains including medicine, telecommunications. and the World Wide Web. Conventional sequential pattern mining systems provide users with only a very restricted mechanism (based on minimum support) for specifying patterns of interest. As a consequence, the pattern mining process is typically characterized by lack of focus and users often end up paying inordinate computational costs just to be inundated with an overwhelming number of useless results. In this paper, we propose the use of Regular Expressions (REs) as a flexible constraint specification tool that enables user-controlled focus to be incorporated into the pattern mining process, We develop a family of novel algorithms (termed SPIRIT-Sequential Pattern mining with Regular expression consTraints) for mining frequent sequential patterns that also satisfy user-specified RE constraints. The main distinguishing factor among the proposed schemes is the degree to which the RE constraints are enforced to prune the search space of patterns during computation, Our solutions provide valuable insights into the trade-offs that arise when constraints that do not subscribe to nice properties (like antimonotonicity) are integrated into the mining process. A quantitative exploration of these trade-offs is conducted through an extensive experimental study on synthetic and real-life data sets. The experimental results clearly validate the effectiveness of our approach, showing that speedups of more than an order of magnitude are possible when RE constraints are pushed deep inside the mining process. Our experimentation with real-life data also illustrates the versatility of REs as a user-level tool for focusing on interesting patterns.	Bell Labs, Murray Hill, NJ 07974 USA; Seoul Natl Univ, Sch Elect Engn & Comp Sci, Seoul 151742, South Korea	Garofalakis, M (reprint author), Bell Labs, 600 Mt Ave, Murray Hill, NJ 07974 USA.						AGRAWAL R, 1995, P 11 INT C DAT ENG M; Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R., 1995, P 21 INT C VER LARG; CHAKRABARTI S, 1997, P 23 INT C VER LARG; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; HATONEN K, 1996, P 12 INT C DAT ENG, P155; Lewis H. R., 1981, ELEMENTS THEORY COMP; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; MANNILA H, 1996, P 2 INT C KNOWL DISC; NG RT, 1998, P 1998 ACM SIGMOD IN; SRIKANT R, 1997, P 3 INT C KNOWL DISC; Srikant R., 1996, P 5 INT C EXT DAT TE; TSUR D, 1998, P ACM SIGMOD INT C M, P1, DOI 10.1145/276304.276306; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863	14	45	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY-JUN	2002	14	3					530	552		10.1109/TKDE.2002.1000341		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	547DG	WOS:000175317300005	
J	Traina, C; Traina, A; Faloutsos, C; Seeger, B				Traina, C; Traina, A; Faloutsos, C; Seeger, B			Fast indexing and visualization of metric data sets using slim-trees	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						metric databases; metric access methods; index structures; multimedia databases; selectivity estimation; similarity search	QUERIES; ACCESS	Many recent database applications must deal with similarity queries. For such applications, it is important to measure the similarity between two objects using the distance between them. Focusing on this problem, this paper proposes the Slim-tree, a new dynamic tree for organizing metric data sets in pages of fixed size. The Slim-tree uses the triangle inequality to prune distance calculations needed to answer similarity queries over objects in metric spaces. The proposed insertion algorithm uses new policies to select the nodes where incoming objects are stored. When a node overflows, the Slim-tree uses a Minimal Spanning Tree to help with the split. The new insertion algorithm leads to a tree with high storage utilization and improved query performance. The Slim-tree is the first metric access method to tackle the problem of overlap between nodes in metric spaces and to propose a technique to minimize it. The proposed "fat-factor" is a way to quantify whether a given tree can be improved and also to compare two trees. We show how to use the fat-factor to achieve accurate estimates of the search performance and also how to improve the performance of a metric tree through the proposed "Slim-down" algorithm. This paper also presents a new tool in the arsenal of resources of Slim-tree aimed at visualizing it, Visualization is a powerful tool for interactive data mining and for the visual tracking of the behavior of a tree under updates, Finally, we present a formula to estimate the number of disk accesses in range queries. Results from experiments with real and synthetic data sets show that the new algorithms of the Slim-tree lead to performance improvements. These results show that the Slim-tree outperforms the M-tree up to 200 percent for range queries. For insertion and split, the Minimal-Spanning-Tree-based algorithm achieves up to 40 times faster insertions. We observed improvements up to 40 percent in range queries after applying the Slim-down algorithm.	Univ Sao Paulo, Dept Comp Sci, BR-13560970 Sao Carlos, SP, Brazil; Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; Univ Marburg, Dept Math & Comp Sci, D-35032 Marburg, Germany	Traina, C (reprint author), Univ Sao Paulo, Dept Comp Sci, C Postal 668, BR-13560970 Sao Carlos, SP, Brazil.	caetano@icmc.sc.usp.br; agma@icmc.sc.usp.br; christos@cs.cmu.edu; seegar@Mathematik.Uni-Marburg.de	Traina, Caetano/E-9814-2011; Traina, Agma/F-1299-2011	Traina, Caetano/0000-0002-6625-6047; 			Baeza-Yates R, 1994, P 5 ANN S COMB PATT, P198; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Berchtold S., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263671; Bozkaya T, 1997, P ACM SIGMOD INT C M, P357, DOI 10.1145/253260.253345; Bozkaya T, 1999, ACM T DATABASE SYST, V24, P361, DOI 10.1145/328939.328959; BRIN S., 1995, P 21 INT C VER LARG, P574; BURKHARD WA, 1973, COMMUN ACM, V16, P230, DOI 10.1145/362003.362025; Chiueh T., 1994, P 20 INT C VER LARG, P582; Ciaccia P., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275495; Ciaccia P, 1998, AUST COMP S, V20, P15; CIACCIA P, 1997, P ATTI QUINTO CONVEG, P67; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Faloutsos C., 1994, Proceedings of the Thirteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1994, DOI 10.1145/182591.182593; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163, DOI 10.1145/223784.223812; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; Garcia Y. J. R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Guttman A., 1984, P ACM SIGMOD INT C M, P47; HRISTESCU G, 1999, 9950 DIMACS; Johnson T., 1989, Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, DOI 10.1145/73721.73745; Kruskal J.B., 1956, P AM MATH SOC, V7, P48, DOI DOI 10.1090/S0002-9939-1956-0078686-7; MARTINS RT, 1997, NATURAL LANGUAGE ENG, V4, P287; Pagel B.-U., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839457; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; Shah M. A., 1999, Proceedings User Interfaces to Data Intensive Systems, DOI 10.1109/UIDIS.1999.791469; SHASHA D, 1990, ACM T INFORM SYST, V8, P140, DOI 10.1145/96105.96111; TRAINA C, P INT C EXTENDING DA, P51; TRAINA C, 1999, CMUCS99110; TRAINA C, 2000, P 16 INT C DAT ENG I, P195, DOI 10.1109/ICDE.2000.839409; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Wactlar HD, 1996, COMPUTER, V29, P46, DOI 10.1109/2.493456; Wang J. T. L., 1999, P ACM SIGKDD INT C K, P307, DOI 10.1145/312129.312264; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311	32	45	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR-APR	2002	14	2					244	260		10.1109/69.991715		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	528CH	WOS:000174226200004	
J	Song, HS; Kim, JK; Kim, SM				Song, HS; Kim, JK; Kim, SM			Mining the change of customer behavior in an internet shopping mall	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; association rule mining; change mining	KNOWLEDGE DISCOVERY; PATTERNS; DATABASE	Understanding and adapting to changes of customer behavior is an important aspect for a internet-based company to survive in a continuously changing environment. The aim of this paper is to develop a methodology which detects changes of customer behavior automatically from customer profiles and sales data at different time snapshots. For this purpose, we first define the three types of changes as emerging pattern, unexpected change and the added/perished rule, then, we develop similarity and difference measures for rule matching to detect all types of change. Finally, the degree of change is evaluated to detect significantly changed rules. Our proposed methodology can evaluate the degree of changes as well as detect all kinds of change automatically from different time snapshot data. A case study on an internet shopping mall for evaluation of this methodology is also provided. (C) 2001 Elsevier Science Ltd. All rights reserved.	Korea Adv Inst Sci & Technol, Grad Sch Management, Seoul 130012, South Korea; Kyung Hee Univ, Sch Business Adm, Seoul 130701, South Korea	Song, HS (reprint author), Korea Adv Inst Sci & Technol, Grad Sch Management, 207-43 Cheongryangri, Seoul 130012, South Korea.	hssong@kgsm.kaist.ac.kr	Kim, Soung Hie/C-1863-2011				Aggarwal C. C., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288644; AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1997, P 3 INT C KNOWL DISC, P67; Agrawal R., 1994, P 20 INT C VER LARG, P487; Bay S., 1999, P 5 ACM SIGKDD INT C, P302, DOI 10.1145/312129.312263; Cheung D., 1996, P 2 INT C KNOWL DISC, P307; Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094; Das G, 1997, LECT NOTES ARTIF INT, V1263, P88; Das G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; FELDMAN R, 1997, SIGMOD 97 WORKSH RES, P59; Freund Y., 1997, Computational Learning Theory. Third European Conference, EuroCOLT '97. Proceedings; Ganti V., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, DOI 10.1145/303976.303989; Han JW, 1999, PROC INT CONF DATA, P106; HELMBOLD DP, 1994, MACH LEARN, V14, P27, DOI 10.1007/BF00993161; HUSSAIN F, 2000, P PAC AS C KNOWL DIS, P86; HUSSAIN F, 1999, TRC699 NAT U SING; Lanquillon C., 1999, P INT JOINT C ART IN, P41; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li J, 2000, P 4 PAC AS C KNOWL D, P220; Liu B., 2000, 2 INT C DAT WAR KNOW, P337; Liu B., 1997, P 3 INT C KNOWL DISC, P31; LIU B, 1999, P 5 ACM SIGKDD INT C, P430, DOI 10.1145/312129.312311; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; NAKHAEIZADEH G, 1998, P 4 INT C KNOWL DISC; Padmanabhan B, 1999, DECIS SUPPORT SYST, V27, P303, DOI 10.1016/S0167-9236(99)00053-6; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Suzuki E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Thomas S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280	31	45	49	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	OCT	2001	21	3					157	168		10.1016/S0957-4174(01)00037-9		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	488LW	WOS:000171937500005	
J	Agrafiotis, DK; Lobanov, VS				Agrafiotis, DK; Lobanov, VS			Nonlinear mapping networks	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							PROJECTION; LIBRARIES	Among the many dimensionality reduction techniques that have appeared in the statistical literature, multidimensional scaling and nonlinear mapping are unique for their conceptual simplicity and ability to reproduce the topology and structure of the data space in a faithful and unbiased manner. However, a major shortcoming of these methods is their quadratic dependence on the number of objects scaled, which imposes severe limitations on the size of data sets that can be effectively manipulated. Here we describe a novel approach that combines conventional nonlinear mapping techniques with feed-forward neural networks, and allows the processing of data sets orders of magnitude larger than those accessible with conventional methodologies. Rooted on the principle of probability sampling, the method employs a classical algorithm to project a small random sample, and then "learns" the underlying nonlinear transform using a multilayer neural network trained with the back-propagation algorithm. Once trained, the neural network can be used in a feed-forward manner to project the remaining members of the population as well as new, unseen samples with minimal distortion. Using examples from the fields of image processing and combinatorial chemistry, we demonstrate that this method can generate projections that are virtually indistinguishable from those derived by conventional approaches. The ability to encode the nonlinear transform in the form of a neural network makes nonlinear mapping applicable to a wide variety of data mining applications involving very large data sets that are otherwise computationally intractable.	3 Dimens Pharmaceut Inc, Exton, PA 19341 USA	Agrafiotis, DK (reprint author), 3 Dimens Pharmaceut Inc, 665 Stockton Dr, Exton, PA 19341 USA.						AGRAFIOTIS DK, 1998, ENCY COMPUTATIONAL C, P742; AGRAFIOTIS DK, 1999, ANN REPORTS COMBINAT, V2, P71; AGRAFIOTIS DK, IN PRESS J COMP CHEM; AGRAFIOTIS DK, 1999, MOL DIVERS, V4, P1; Agrafiotis DK, 1997, PROTEIN SCI, V6, P287; Bellman R., 1961, ADAPTIVE CONTROL PRO; BISWAS G, 1981, IEEE T PATTERN ANAL, V3, P701; Blake C. L., 1998, UCI RESPOSITORY MACH; CHANG CL, 1973, IEEE T SYST MAN CYB, VSMC3, P197; COOLEY WW, 1971, MULTIVARIATE DATA AN; Cramer RD, 1998, J CHEM INF COMP SCI, V38, P1010, DOI 10.1021/ci9800209; FREY PW, 1991, MACH LEARN, V6, P491; Groenen P., 1997, MODERN MULTIDIMENSIO; Haykin S., 1998, NEURAL NETWORKS COMP; Kohonen T., 1996, SELF ORG MAPS; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; Lee R.C.T., 1977, IEEE T COMPUT, V27, P288; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; PYKETT CE, 1978, ELECTRON LETT, V14, P799, DOI 10.1049/el:19780539; RASSOKHIN DN, IN PRESS J COMP CHEM; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SCOTT DW, 1992, MUTLIVARIATE DENSITY; Thompson LA, 1996, CHEM REV, V96, P555, DOI 10.1021/cr9402081; Torgerson W. S., 1952, PSYCHOMETRIKA, V14, P401, DOI DOI 10.1007/BF02288916; WEGMAN EJ, 1970, ANN MATH STAT, V41, P457, DOI 10.1214/aoms/1177697085	25	45	45	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	NOV-DEC	2000	40	6					1356	1362		10.1021/ci000033y		7	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	378PX	WOS:000165593700008	
J	Mennis, JL; Peuquet, DJ; Qian, LJ				Mennis, JL; Peuquet, DJ; Qian, LJ			A conceptual framework for incorporating cognitive principles into geographical database representation	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article							INFORMATION-SYSTEMS; SPATIAL RELATIONS; DATA MODELS; CATEGORIES; OBJECTS; SCENES; DESIGN; SPACE	The advancement of GIS data models to allow the effective utilization of very large heterogeneous geographic databases requires a new approach that incorporates models of human cognition. The ultimate goal is to provide a cooperative human-computer environment for spatial analysis. We describe the pyramid framework as an example of this new approach within the context of some important aspects of how humans conceptually store spatial information. The proposed framework provides the means to create multiple structural interpretations of observed geographic data and the ability to build knowledge hierarchies through the application of data mining and other statistical techniques.	Penn State Univ, Dept Geog, University Pk, PA 16802 USA; Oracle Corp, Spatial Prod, Nashua, NH 03062 USA	Mennis, JL (reprint author), Penn State Univ, Dept Geog, University Pk, PA 16802 USA.		Namikawa, Laercio/C-5559-2013	Namikawa, Laercio/0000-0001-7847-1804			Andersen R.A., 1987, HDB PHYSL 1, VV, P483; Booch G., 1994, OBJECT ORIENTED ANAL; Borgida A., 1991, Entity-Relationship Approach: the Core of Conceptual Modelling. Proceedings of the Ninth International Conference; Burrough P. A., 1996, GEOGRAPHIC OBJECTS I; BURROUGH PA, 1995, INT J GEOGR INF SYST, V9, P101, DOI 10.1080/02693799508902028; CARLETON AM, 1991, SATELLITE REMOTE SEN; Chappell C. F., 1986, MESOSCALE METEOROLOG, P289; Chen P., 1976, ACM T DATABASE SYST, V1, P1; CODD EF, 1970, COMMUN ACM, V13, P377, DOI 10.1145/362384.362685; COUCLELIS H, 1993, INT C GIS SPAC TERR, P635; Downs R, 1973, IMAGE ENV; EASTMAN JR, 1985, CARTOGRAPHICA, V22, P1, DOI 10.3138/FJK4-2776-485N-6464; EGENHOFER MJ, 1989, AUTO CARTO 9 : NINTH INTERNATIONAL SYMPOSIUM ON COMPUTER-ASSISTED CARTOGRAPHY, P588; FARAH MJ, 1988, COGNITIVE PSYCHOL, V20, P439, DOI 10.1016/0010-0285(88)90012-6; FRANK AU, 1992, COMPUT GEOSCI, V18, P409, DOI 10.1016/0098-3004(92)90070-8; FREKSA C, 1996, GEOGRAPHIC OBJECTS I, P109; Golledge R, 1993, BEHAV ENV PSYCHOL GE, P16; HERRING JR, 1992, COMPUT GEOSCI, V18, P443, DOI 10.1016/0098-3004(92)90074-2; HULL R, 1987, ACM COMPUT SURV, V19, P201, DOI 10.1145/45072.45073; Kosslyn S. M., 1992, WET MIND NEW COGNITI; KOSSLYN SM, 1992, J EXP PSYCHOL HUMAN, V18, P562, DOI 10.1037/0096-1523.18.2.562; Lakoff G., 1987, WOMEN FIRE DANGEROUS; Lakoff G., 1980, METAPHORS WE LIVE; LANDAU B, 1993, BEHAV BRAIN SCI, V16, P217; Landry D J, 1998, Issues Brief (Alan Guttmacher Inst), P1; LANGRAN G, 1993, CAN C GIS OTT CAN I, P869; Lloyd R, 1996, PROF GEOGR, V48, P181, DOI 10.1111/j.0033-0124.1996.00181.x; Maddox RA, 1986, MESOSCALE METEOROLOG, P390; MADDOX RA, 1983, MON WEATHER REV, V111, P1475, DOI 10.1175/1520-0493(1983)111<1475:LSMCAW>2.0.CO;2; MARK DM, 1999, WORKSH GEOGR INF SCI; Mark DM, 1996, ENVIRON PLANN B, V23, P3, DOI 10.1068/b230003; Marr D., 1982, VISION; MILNE P, 1993, INT J GEOGR INF SYST, V7, P39, DOI 10.1080/02693799308901938; Minsky M., 1975, PSYCHOL COMPUTER VIS, P211; MURPHY GL, 1989, J EXP PSYCHOL LEARN, V15, P572, DOI 10.1037//0278-7393.15.4.572; NYERGES TL, 1991, ENVIRON PLANN A, V23, P1483, DOI 10.1068/a231483; PECKHAM J, 1988, COMPUT SURV, V20, P153; PEUQUET DJ, 1988, ANN ASSOC AM GEOGR, V78, P375, DOI 10.1111/j.1467-8306.1988.tb00214.x; PEUQUET DJ, 1996, INT S SPAT DAT HANDL; PEUQUET DJ, 1994, ANN ASSOC AM GEOGR, V84, P441, DOI 10.1111/j.1467-8306.1994.tb01869.x; PORTUGALL J, 1996, CONSTRUCTION COGNITI; RAPER J, 1995, INT J GEOGR INF SYST, V9, P359, DOI 10.1080/02693799508902044; RENNISON E, 1995, SPATIAL INFORMATION, P69; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; Rosch E., 1983, NEW TRENDS CONCEPTUA, P73; Rosch E., 1978, COGNITION CATEGORIZA, P27; Rosch Eleanor, 1973, COGNITIVE DEV ACQUIS, P111; Rumbaugh J, 1991, OBJECT ORIENTED MODE; SERGENT J, 1991, J EXP PSYCHOL HUMAN, V17, P762; SINTON DF, 1978, INHERENT STRUCTURE I; STEVENS A, 1978, COGNITIVE PSYCHOL, V10, P422, DOI 10.1016/0010-0285(78)90006-3; Tang AY, 1996, INT J GEOGR INF SYST, V10, P643, DOI 10.1080/02693799608902102; Thorndyke P. W., 1984, TUTORIALS LEARNING M, P167; TVERSKY B, 1984, J EXP PSYCHOL GEN, V113, P169, DOI 10.1037/0096-3445.113.2.169; TVERSKY B, 1983, COGNITIVE PSYCHOL, V15, P121, DOI 10.1016/0010-0285(83)90006-3; Ungerleider L. G, 1982, ANAL VISUAL BEHAV, P549; USERY L, 1993, CARTOGRAPHY GEOGRAPH, V20, P5; WORBOYS MF, 1994, INT J GEOGR INF SYST, V8, P385, DOI 10.1080/02693799408902008; *UCGIS, 1996, CARTOGRAPHY GEOGRAPH, V23	59	45	54	TAYLOR & FRANCIS LTD	LONDON	11 NEW FETTER LANE, LONDON EC4P 4EE, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	SEP	2000	14	6					501	520		10.1080/136588100415710		20	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	347NV	WOS:000088936800001	
J	Gaizauskas, R; Wilks, Y				Gaizauskas, R; Wilks, Y			Information extraction: Beyond document retrieval	JOURNAL OF DOCUMENTATION			English	Article								In this paper we give a synoptic view of the growth of the text processing technology of information extraction (Ie) whose function is to extract information about a pre-specified set of entities, relations or events from natural language texts and to record this information in structured representations called templates. Here we describe the nature of the re task, review the history of the area from its origins in AI work in the 1960s and 70s till the present, discuss the techniques being used to carry out the task, describe application areas where IE systems are or are about to be at work, and conclude with a discussion of the challenges facing the area. What emerges is a picture of an exciting new text processing technology with a host of new applications, both on its own and in conjunction with other technologies, such as information retrieval, machine translation and data mining.	Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England	Gaizauskas, R (reprint author), Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.						Aberdeen J.B., 1995, P 6 MESS UND C MUC 6, P141, DOI 10.3115/1072399.1072413; Andersen P. M., 1992, P 3 C APPL NAT LANG, P170, DOI 10.3115/974499.974531; APPELT D, 1995, P 6 MESS UND C MUC 6, P237, DOI 10.3115/1072399.1072420; APPELT DE, 1993, P 5 MESS UND C MUC 5, P221, DOI 10.3115/1072017.1072039; AZZAM S, 1997, IN PRESS P IJCAI 97; BLACK WJ, 1997, NATURAL LANGUAGE PRO, P119; Brill E., 1992, P 3 C APPL NAT LANG, P152, DOI 10.3115/974499.974526; CHINCHOR N, 1993, P 5 MESS UND C MUC 5, P79, DOI 10.3115/1072017.1072027; CIRAVEGNA F, 1992, P COLING 2, P1244; COLLIER R, 1996, CS9607 U SHEFF DEP C; Cowie J, 1996, COMMUN ACM, V39, P80, DOI 10.1145/234173.234209; COWIE JR, 1983, P ACL C APPL NAT LAN, P117, DOI 10.3115/974194.974218; CUNNINGHAM H, 1997, P 5 C APPL NAT LANG, P237, DOI 10.3115/974557.974592; ELLMAN J, 1997, NATURAL LANGUAGE PRO, P77; EVANS R, 1995, J NATURAL LANGUAGE E, V1, P363; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P37; G Dejong, 1982, STRATEGIES NATURAL L, P149; GAIZAUSKAS R, 1997, IN PRESS DISCOURSE A; GAIZAUSKAS R, 1995, CS9524 U SHEFF DEP C; GAIZAUSKAS R, 1997, P 5 COMP ASS INF SEA, P356; Gaizauskas R, 1996, PROC INT C TOOLS ART, P58, DOI 10.1109/TAI.1996.560401; GAIZAUSKAS R, 1995, CS9525 U SHEFF DEP C; Gazdar G., 1989, NATURAL LANGUAGE PRO; GIANETTI A, 1992, ENHANCING KNOWLEDGE; GRISHMAN R, 1996, TIPSTER ARCHITECTURE; GRISHMAN R, 1995, TIPSTER ARCHITECTURE; GRISHMAN R, P 5 MESS UND C MUC 5, P181; Grishman R., 1996, P 16 INT C COMP LING, P466; HOBBS JR, 1992, P 4 MESS UND C MUC 4, P268, DOI 10.3115/1072064.1072103; HOBBS JR, 1993, ARTIF INTELL, V63, P69, DOI 10.1016/0004-3702(93)90015-4; HOBBS JR, 1991, P 3 MESS UND C MUC 3, P200, DOI 10.3115/1071958.1071991; HOBBS JR, 1986, COMPUTATIONAL LINGUI, V12, P220; HOBBS JR, 1993, P 5 MESS UND C MUC 5, P87, DOI 10.3115/1072017.1072029; HUMPHREYS K, 1996, VIE TECHNICAL SPECIF; JACOBS PS, 1990, COMMUN ACM, V33, P88, DOI 10.1145/92755.92769; KAMEYAMA M, 1997, AAAI SPRING S CROSS; Krupka G.R., 1995, P 6 MESS UND C MUC 6, P221, DOI 10.3115/1072399.1072419; LEHNERT W, 1994, J EXPT THEORETICAL A, V7, P49; LIN D, 1995, P 6 MESS UND C MUC 6, P113, DOI 10.3115/1072399.1072411; Lytinen S. L., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Marcus M., 1994, COMPUTATIONAL LINGUI, V19, P313; Miller George A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; MONTGOMERY C, 1983, P ACL C APPL NAT LAN; MORGAN RG, 1996, 896 U DURH DEP COMP; PIETROSANTI E, 1997, NATURAL LANGUAGE PRO, P277; ROBERTSON AM, 1997, P 19 ANN BCS IRSG C, P60; ROCCA G, 1994, P ART INT C MAY; Sager N, 1981, NATURAL LANGUAGE INF; Schank R. C., 1977, SCRIPTS PLANS GOALS; Schank R. C., 1973, COMPUTER MODELS THOU; Schank RC, 1981, INSIDE COMPUTER UNDE; Schank Roger C., 1975, CONCEPTUAL INFORMATI; SUNDHEIM B, 1993, P 5 MESS UND C MUC 5, P27, DOI 10.3115/1072017.1072023; THURMAIR G, 1997, NATURAL LANGUAGE PRO, P135; UZKOREIT H, 1997, SURVEY STATE ART HUM; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; Vilain M., 1995, P 6 MESS UND C MUC 6, P45, DOI 10.3115/1072399.1072405; WAKAO T, 1996, P 16 INT C COMP LING, P418; WEISCHEDEL R, 1995, P 6 MESS UND C MUC 6, P55, DOI 10.3115/1072399.1072407; Wilks Y., 1996, ELECT WORDS; Witten I. H., 1994, MANAGING GIGABYTES; ZARRI GP, 1983, P ACL C APPL NAT LAN, P143, DOI 10.3115/974194.974222; *AVENTINUS, ADV INF SYST MULT DR; *ECRAN, EXTR CONT RES NEAR M; *EMPATHIE, ENZ MET PATH INF EXT; *FACILE, FAST ACC CAT INF LAN; *TREE, T EUR EMPL; 1992, P 4 MESS UND C MUC 4; 1995, P 6 MESS UND C MUC 6; 1991, P 3 MESS UND C MUC 3; 1993, P 5 MESS UND C MUC 5	71	45	45	ASLIB	LONDON	STAPLE HALL, STONE HOUSE COURT, LONDON EC3A 7PB, ENGLAND	0022-0418		J DOC	J. Doc.	JAN	1998	54	1					70	105		10.1108/EUM0000000007162		36	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	YL615	WOS:000070974100005	
J	Tsai, CF				Tsai, Chih-Fong			Feature selection in bankruptcy prediction	KNOWLEDGE-BASED SYSTEMS			English	Article						Feature selection; Data mining; Bankruptcy prediction; Neural networks	SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; GENETIC ALGORITHM; FINANCIAL RATIOS; BANK FAILURE; CLASSIFICATION; PARAMETERS; OPTIMIZATION; BUSINESS; FIRMS	For many corporations, assessing the credit of investment targets and the possibility of bankruptcy is a vital issue before investment. Data mining and machine learning techniques have been applied to solve the bankruptcy prediction and credit scoring problems. As feature selection is an important step to select more representative data from a given dataset in data mining to improve the final prediction performance, it is unknown that which feature selection method is better. Therefore, this paper aims at comparing five well-known feature selection methods used in bankruptcy prediction, which are t-test, correlation matrix, stepwise regression, principle component analysis (PCA) and factor analysis (FA) to examine their prediction performance. Multi-layer perceptron (MLP) neural networks are used as the prediction model. Five related datasets are used in order to provide a reliable conclusion. Regarding the experimental results, the t-test feature selection method outperforms the other ones by the two performance measurements. (C) 2008 Elsevier B.V. All rights reserved.	Natl Cent Univ, Dept Informat Management, Jhongli 32001, Taiwan	Tsai, CF (reprint author), Natl Cent Univ, Dept Informat Management, 300 Jhongda Rd, Jhongli 32001, Taiwan.	actcft@ccu.edu.tw			National Science Council of Taiwan [NSC 96-2416-H-194-010-MY3]	This research is partially supported by National Science Council of Taiwan (NSC 96-2416-H-194-010-MY3).	ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; Atiya AF, 2001, IEEE T NEURAL NETWOR, V12, P929, DOI 10.1109/72.935101; BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171; BEAVER WH, 1968, ACCOUNT REV, V43, P113; Canbas S, 2005, EUR J OPER RES, V166, P528, DOI 10.1016/j.ejor.2004.03.023; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Dimitras AI, 1996, EUR J OPER RES, V90, P487, DOI 10.1016/0377-2217(95)00070-4; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2001, ELEMENTS STAT LEARNI; Hornik K, 1989, NEURAL NETWORKS, V2, P336; Huang CL, 2006, EXPERT SYST APPL, V31, P231, DOI 10.1016/j.eswa.2005.09.024; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; Huysmans J, 2006, EXPERT SYST APPL, V30, P479, DOI 10.1016/j.eswa.2005.10.005; Jolliffe I., 1986, PRINCIPAL COMPONENT; Kim MJ, 2003, EXPERT SYST APPL, V25, P637, DOI 10.1016/S0957-4174(03)00102-7; Kumar PR, 2007, EUR J OPER RES, V180, P1, DOI 10.1016/j.ejor.2006.08.043; Lee KD, 2005, EXPERT SYST APPL, V29, P1, DOI 10.1016/j.eswa.2005.01.004; Lee TS, 2002, EXPERT SYST APPL, V23, P245, DOI 10.1016/S0957-4174(02)00044-1; Lensberg T, 2006, EUR J OPER RES, V169, P677, DOI 10.1016/j.ejor.2004.06.013; Malhotra R, 2002, EUR J OPER RES, V136, P190, DOI 10.1016/S0377-2217(01)00052-2; McKee TE, 2002, EUR J OPER RES, V138, P436, DOI 10.1016/S0377-2217(01)00130-8; Min JH, 2005, EXPERT SYST APPL, V28, P603, DOI 10.1016/j.eswa.2004.12.008; Min SH, 2006, EXPERT SYST APPL, V31, P652, DOI 10.1016/j.eswa.2005.09.070; Olafsson S, 2008, EUR J OPER RES, V187, P1429, DOI 10.1016/j.ejor.2006.09.023; Ong CS, 2005, EXPERT SYST APPL, V29, P41, DOI 10.1016/j.eswa.2005.01.003; PAGANO R, 2001, UNDERSTANDING STAT B; PIETRUSZKIEWICZ W, 2004, THESIS SZCZECIN TECH; Piramuthu S, 2004, EUR J OPER RES, V156, P483, DOI [10.1016/S0377-2217(02)00911-6, 10.1016/s0377-2217(02)00911-6]; Rokach L, 2008, PATTERN RECOGN, V41, P1676, DOI 10.1016/j.patcog.2007.10.013; Schipul S. E., 2012, STAT NEURAL CLASSIFI; Shin KS, 2002, EXPERT SYST APPL, V23, P321, DOI 10.1016/S0957-4174(02)00051-9; Shin KS, 2005, EXPERT SYST APPL, V28, P127, DOI 10.1016/j.eswa.2004.08.009; Smith KA, 2000, COMPUT OPER RES, V27, P1023, DOI 10.1016/S0305-0548(99)00141-0; Suykens J., 2006, EUR J OPER RES, V172, P979, DOI 10.1016/j.ejor.2004.11.009; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Tsai CF, 2008, EXPERT SYST APPL, V34, P2639, DOI 10.1016/j.eswa.2007.05.019; Tsakonas A, 2006, EXPERT SYST APPL, V30, P449, DOI 10.1016/j.eswa.2005.10.009; Uncu O, 2007, INFORM SCIENCES, V177, P449, DOI 10.1016/j.ins.2006.03.022; Wu CH, 2007, EXPERT SYST APPL, V32, P397, DOI 10.1016/j.eswa.2005.12.008; Yang JY, 2006, COMPUT OPER RES, V33, P3088, DOI 10.1016/j.cor.2005.01.021; Yin HJ, 2002, NEURAL NETWORKS, V15, P1005, DOI 10.1016/S0893-6080(02)00075-8; Zhang GQ, 1999, EUR J OPER RES, V116, P16, DOI 10.1016/S0377-2217(98)00051-4	42	44	44	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	MAR	2009	22	2					120	127		10.1016/j.knosys.2008.08.002		8	Computer Science, Artificial Intelligence	Computer Science	423VN	WOS:000264523900002	
J	Ha, SH; Krishnan, R				Ha, Sung Ho; Krishnan, Ramayya			A hybrid approach to supplier selection for the maintenance of a competitive supply chain	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						supply chain; supply chain management; supplier selection; data mining	ANALYTIC HIERARCHY PROCESS; VENDOR SELECTION; DECISION-SUPPORT; METHODOLOGY; CRITERIA; SYSTEM	This article outlines a hybrid method, incorporating multiple techniques into an evaluation process, in order to select competitive suppliers in a supply chain. It enables a purchaser to do single sourcing and multiple sourcing by calculating a combined supplier score (CSS), which accounts for both qualitative and quantitative factors that impact on supply chain performance. By performing a cluster analysis, it draws a supplier map (SM) so as to position suppliers within the qualitative and quantitative dimensions of performance efficiency, and to select a portfolio of suppliers from supplier segments, which are different in performance with regard to key factors. (C) 2007 Elsevier Ltd. All rights reserved.	[Ha, Sung Ho] Kyungpook Natl Univ, Sch Business Adm, Taejon 702701, South Korea; [Krishnan, Ramayya] Carnegie Mellon Univ, Heinz Sch, Pittsburgh, PA 15213 USA	Ha, SH (reprint author), Kyungpook Natl Univ, Sch Business Adm, 1370 Sangyeok dong, Taejon 702701, South Korea.	hsh@mail.knu.ae.kr; rk2x@andrew.cmu.edu					ABRATT R, 1986, IND MARKET MANAG, V15, P293, DOI 10.1016/0019-8501(86)90021-0; Billesbach T., 1991, INT J PURCHASING MAT, V27, P24; Chopra S., 2003, SUPPLY CHAIN MANAGEM; de Boer L, 2001, EUROPEAN J PURCHASIN, V7, P75, DOI 10.1016/S0969-7012(00)00028-9; Degraeve Z, 2000, EUR J OPER RES, V125, P34, DOI 10.1016/S0377-2217(99)00199-X; Dickson G., 1966, J PURCHASING, V2, P5; DYER RF, 1992, DECIS SUPPORT SYST, V8, P99, DOI 10.1016/0167-9236(92)90003-8; Ghodsypour SH, 1998, INT J PROD ECON, V56-7, P199, DOI 10.1016/S0925-5273(97)00009-1; Holt G. D., 1998, International Journal of Project Management, V16, DOI 10.1016/S0263-7863(97)00035-5; Kumar M, 2004, COMPUT IND ENG, V46, P69, DOI 10.1016/j.cie.2003.09.010; Lai VS, 2002, EUR J OPER RES, V137, P134, DOI 10.1016/S0377-2217(01)00084-4; LEHMANN DR, 1974, J MARKETING, V38, P36, DOI 10.2307/1250195; Min H, 1999, INT J OPER PROD MAN, V19, P909, DOI 10.1108/01443579910280232; MORLACCHI P, 1999, P 8 INT ANN ISERA C; PERREAULT WD, 1976, J MARKETING, V40, P3, DOI 10.2307/1251000; SEGEV A, 1998, WP981033 CMIT U CAL; SHANG J, 1995, EUR J OPER RES, V85, P297, DOI 10.1016/0377-2217(94)00041-A; Sinuany-Stern Z., 2000, International Transactions in Operational Research, V7, DOI 10.1016/S0969-6016(00)00013-7; SONMEZ M, 2006, BUSINESS SCH PAPERS, V1; Stavropolous N., 2000, TELECOMMUN J, V50, P27; Takamura Y., 2003, SOCIOECONOMIC PLANNI, V37, P85, DOI 10.1016/S0038-0121(02)00049-6; Talluri S, 2003, EUR J OPER RES, V146, P543, DOI 10.1016/S0377-2217(02)00230-8; Wang G, 2004, INT J PROD ECON, V91, P1, DOI 10.1016/S0925-5273(03)00221-4; Weber C. A., 2000, SUPPLY CHAIN MANAG, V2, P90, DOI 10.1108/13598540010320009; Weber CA, 1998, EUR J OPER RES, V108, P208, DOI 10.1016/S0377-2217(97)00131-8; WEBER CA, 1991, EUR J OPER RES, V50, P2, DOI 10.1016/0377-2217(91)90033-R; Wind Y., 1968, J PURCHASING, V25, P29; WISE R, 2000, HARVARD BUSINESS NOV, P86; Yang TH, 2003, EUR J OPER RES, V147, P128, DOI 10.1016/S0377-2217(02)00251-5	29	44	45	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					1303	1311		10.1016/j.eswa.2006.12.008		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900052	
J	Liang, YL; Reyes, ML; Lee, JD				Liang, Yulan; Reyes, Michelle L.; Lee, John D.			Real-time detection of driver cognitive distraction using support vector machines	IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS			English	Article						classification; driving performance; eye movement; logistic regression; secondary task; support vector machine (SVM)	CELLULAR PHONE USE; MENTAL WORKLOAD; VISUAL-ATTENTION; SYSTEM; TASKS	As use of in-vehicle information systems (IVISs) such as cell phones, navigation systems, and satellite radios has increased, driver distraction has become an important and growing safety concern. A promising way to overcome this problem is to detect driver distraction and adapt in-vehicle systems accordingly to mitigate such distractions. To realize this strategy, this paper applied support vector machines (SVMs), which is a data mining method, to develop a real-time approach for detecting cognitive distraction using drivers' eye movements and driving performance data. Data were collected in a simulator experiment in which ten participants interacted with an IVIS while driving. The data were used to train and test both SVM and logistic regression models, and three different model characteristics were investigated: how distraction was defined, which data were input to the model, and how the input data were summarized. The results show that the SVM models were able to detect driver distraction with an average accuracy of 81.1%, outperforming more traditional logistic regression models. The best performing model (96.1% accuracy) resulted when distraction was defined using experimental conditions (i.e., IVIS drive or baseline drive), the input data were comprised of eye movement and driving measures, and these data were summarized over a 40-s window with 95% overlap of windows. These results demonstrate that eye movements and simple measures of driving performance can be used to detect driver distraction in real time. Potential applications of this paper include the design of adaptive in-vehicle systems and the evaluation of driver distraction.	Univ Iowa, Dept Mech & Ind Engn, Iowa City, IA 52242 USA; Univ Iowa, Ctr Comp Aided Design, Iowa City, IA 52242 USA	Liang, YL (reprint author), Univ Iowa, Dept Mech & Ind Engn, Iowa City, IA 52242 USA.	Yulan-liang@uiowa.edu; mlries@engineering.uiowa.edu; jdlee@engineering.uiowa.edu	Lee, John/A-9774-2009; Lee, John/E-9987-2010	Lee, John/0000-0001-9808-2160			Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598; Byun H, 2002, LECT NOTES COMPUT SC, V2388, P213; Chang C.-C, LIBSVM LIB SUPPORT V; Cristianini N., 2000, INTRO SUPPORT VECTOR; Donmez B., 2003, P HUM FACT ERG SOC 4, P1865; Gibbs WW, 2005, SCI AM, V292, P54; Wang JS, 1996, P ANN C ASS, P377; Haigney D, 2001, ERGONOMICS, V44, P132, DOI 10.1080/00140130118417; Hayhoe MM, 2004, INFANCY, V6, P267, DOI 10.1207/s15327078in0602_7; Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368; HSU CHIH-WEI, PRACTICAL GUIDE SUPP; Jacob R.J.K., 1995, Advanced Interface Design and Virtual Environments, P258; Lee JD, 2001, HUM FACTORS, V43, P631, DOI 10.1518/001872001775870340; MANDALIA HM, 2005, P HUM FACT ERG SOC 4, P1965; MAY JG, 1990, ACTA PSYCHOL, V75, P75, DOI 10.1016/0001-6918(90)90067-P; MCCALL J, IN PRESS IEEE T INTE; McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595; MCKNIGHT AJ, 1993, ACCIDENT ANAL PREV, V25, P259, DOI 10.1016/0001-4575(93)90020-W; NAKAYAMA O, 1999, INT C EXP DETR MI MA; Rantanen EM, 1999, ERGONOMICS, V42, P816, DOI 10.1080/001401399185315; Recarte MA, 2003, J EXP PSYCHOL-APPL, V9, P119, DOI 10.1037/1076-898X.9.2.119; Recarte MA, 2000, J EXP PSYCHOL-APPL, V6, P31, DOI 10.1037//0278-7393.6.1.31; Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342; Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704; Strayer DL, 2001, PSYCHOL SCI, V12, P462, DOI 10.1111/1467-9280.00386; Strayer DL, 2003, J EXP PSYCHOL-APPL, V9, P23, DOI 10.1037/1076-898X.9.1.23; Stutts J.C., 2001, AAA FDN TRAFFIC SAFE; Vapnik V.N., 1995, NATURE STAT LEARNING; Walter R., 1985, TRANSPORT RES REC, V1047, P40; Zhang Y., 2004, P IEEE INT TRANSP SY, P642	31	44	46	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1524-9050		IEEE T INTELL TRANSP	IEEE Trans. Intell. Transp. Syst.	JUN	2007	8	2					340	350		10.1109/TITS.2007.895298		11	Engineering, Civil; Engineering, Electrical & Electronic; Transportation Science & Technology	Engineering; Transportation	176TB	WOS:000247106700016	
J	Beringer, J; Hullermeier, E				Beringer, J; Hullermeier, E			Online clustering of parallel data streams	DATA & KNOWLEDGE ENGINEERING			English	Article						data mining; clustering; data streams; fuzzy sets		In recent years, the management and processing of so-called data streams has become a topic of active research in several fields of computer science such as, e.g., distributed systems, database systems, and data mining. A data stream can roughly be thought of as a transient, continuously increasing sequence of time-stamped data. In this paper, we consider the problem of clustering parallel streams of real-valued data, that is to say, continuously evolving time series. In other words, we are interested in grouping data streams the evolution over time of which is similar in a specific sense. In order to maintain an up-to-date clustering structure, it is necessary to analyze the incoming data in an online manner, tolerating not more than a constant time delay. For this purpose, we develop an efficient online version of the classical K-means clustering algorithm. Our method's efficiency is mainly due to a scalable online transformation of the original data which allows for a fast computation of approximate distances between streams. (c) 2005 Elsevier B.V. All rights reserved.	Otto Von Guericke Univ, Fak Informat, Magdeburg, Germany	Hullermeier, E (reprint author), Otto Von Guericke Univ, Fak Informat, Magdeburg, Germany.	juergen.beringer@iti.cs.uni-magdeburg.de; eyke.huellermeier@iti.cs.uni-magdeburg.de					Babcock B., 2002, P 21 ACM SIGACT SIGM, P1; BERCKEN J, 2001, P VLDB, P39; Bezdek J., 1981, PATTERN RECOGNITION; CHERNIACK M, 2003, P CIDR 03 1 BIENN C; CONSIDINE J, 2004, ICDE 04 20 IEEE INT; Cormode G, 2003, P ACM PRINC DAT SYST, P296, DOI 10.1145/773153.773182; Das A., 2003, P 2003 ACM SIGMOD IN, P40; DATAR M, 2002, P ANN ACM SIAM S DIS; DATAR SM, 2002, ALGORITHMS ESA 2002, P323; DAVE RN, 1991, PATTERN RECOGN LETT, V12, P657, DOI 10.1016/0167-8655(91)90002-4; DOMINGOS P, 2003, J COMPUTATIONAL GRAP, V12; Domingos P, 2001, P 18 INT C MACH LEAR, P106; Drineas P, 2004, MACH LEARN, V56, P9, DOI 10.1023/B:MACH.0000033113.59016.96; GABER MM, 2004, P 2 WORKSH AUSTR INF, P109; Garofalakis M., 2002, P 2002 ACM SIGMOD IN, P635; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Giannella C., 2003, NEXT GENERATION DATA; Gilbert A.C., 2001, VLDB J, P79; Golab L, 2003, SIGMOD REC, V32, P5; GUHA S, 2000, IEEE S FDN COMP SCI, P359; GUNOPULOS D, 2001, P 2001 ACM SIGMOD IN; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hastie T., 2001, ELEMENTS STAT LEARNI; Hoppner F., 1999, FUZZY CLUSTER ANAL; Hulten G., 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; Keogh E.J., 2002, 8 ACM SIGKDD INT C K, P102; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; LERMAN I, 2002, CLASSIFICATION CLUST, P147; Mishra N., 2002, STREAMING DATA ALGOR; PAPADIMITRIOU S, 2003, 29 INT C VER LARG DA; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; ZHU Y, 2002, STATSTREAM STAT MONI	33	44	51	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	AUG	2006	58	2					180	204		10.1016/j.datak.2005.05.009		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	057NM	WOS:000238602500004	
J	Kuramochi, M; Karypis, G				Kuramochi, M; Karypis, G			Finding frequent patterns in a large sparse graph	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						pattern discovery; frequent subgraph; graph mining	EFFICIENT ALGORITHM; INDEPENDENT SETS; PROTEINS; MOTIFS	Graph-based modeling has emerged as a powerful abstraction capable of capturing in a single and unified framework many of the relational, spatial, topological, and other characteristics that are present in a variety of datasets and application areas. Computationally efficient algorithms that find patterns corresponding to frequently occurring subgraphs play an important role in developing data mining-driven methodologies for analyzing the graphs resulting from such datasets. This paper presents two algorithms, based on the horizontal and vertical pattern discovery paradigms, that find the connected subgraphs that have a sufficient number of edge-disjoint embeddings in a single large undirected labeled sparse graph. These algorithms use three different methods for determining the number of edge-disjoint embeddings of a subgraph and employ novel algorithms for candidate generation and frequency counting, which allow them to operate on datasets with different characteristics and to quickly prune unpromising subgraphs. Experimental evaluation on real datasets from various domains show that both algorithms achieve good performance, scale well to sparse input graphs with more than 120,000 vertices or 110,000 edges, and significantly outperform previously developed algorithms.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Kuramochi, M (reprint author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	kuram@cs.umn.edu; karypis@cs.umn.edu					AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; BERENDT B, 2002, INT SEM WEB C ISWC, P264; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BERMAN P, 1995, P 4 WORKSH ALG DAT S, P449; Blake C, 1998, UCI REPOSITORY MACHI; Borgelt C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183885; CHEW LP, 1999, P 3 ACM RECOMB INT C, P104, DOI 10.1145/299432.299464; COHEN M, 2004, P 9 INT WORKSH DAT M, P51, DOI 10.1145/1008694.1008702; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Cook DJ, 2000, IEEE INTELL SYST APP, V15, P32, DOI 10.1109/5254.850825; COOK ER, 1995, HOLOCENE, V5, P229, DOI 10.1177/095968369500500211; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DERAEDT L, 1921, P 17 INT JOINT C ART, P853; DERAEDT L, 2001, P 17 INT JOINT C ART, P853; DESHPANDE M, 2002, P WORKSH DAT MIN BIO, P11; Deshpande M., 2003, P 3 IEEE INT C DAT M, P35; FEIGE U, 1991, PROCEEDINGS - 32ND ANNUAL SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, P2, DOI 10.1109/SFCS.1991.185341; Fortin S, 1996, TR9620 U ALB DEP COM; Garey M. R., 1979, COMPUTERS INTRACTABI; GHAZIZADEH S, 2002, CSTR4364 U MAR DEP C; GHAZIZADEH S, 2002, P 5 INT C DISC SCI, P71; GONZALEZ J, 2001, P PRED TOX CHALL WOR; Gouda K., 2003, P 9 ACM SIGKDD INT C, P326; GRINDLEY HM, 1993, J MOL BIOL, V229, P707, DOI 10.1006/jmbi.1993.1074; GURALNIK V, 2001, P 2001 IEEE INT C DA; Halldorsson MM, 1997, ALGORITHMICA, V18, P145, DOI 10.1007/BF02523693; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HOCHBAUM DS, 1983, DISCRETE APPL MATH, V6, P243, DOI 10.1016/0166-218X(83)90080-X; Holder L.B., 1994, P AAAI WORKSH KNOWL, P169; Hong MS, 2003, LECT NOTES ARTIF INT, V2637, P40; Huan J, 2003, P 3 IEEE INT C DAT M, P549; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; Inokuchi A., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); INOKUCHI A, 2002, RT0448 IBM RES TOK R; JENSEN D, 1998, ARTIFICIAL INTELLIGE; JONYER I, 2001, J MACHINE LEARNING R, V2, P19, DOI 10.1162/153244302760185234; Jonyer I., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000441; Khanna S., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), DOI 10.1109/SFCS.1994.365712; Kleinberg J. M., 1999, LECT NOTES COMPUTER, V1627, P1, DOI DOI 10.1007/3-540-48686-0_1; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; KO C, 2000, IEEE S SEC PRIV S P, P142; Koch I, 1996, J COMPUT BIOL, V3, P289, DOI 10.1089/cmb.1996.3.289; Kramer S., 2001, P 7 ACM SIGKDD INT C, P136, DOI 10.1145/502512.502533; Kuramochi M, 2004, IEEE T KNOWL DATA EN, V16, P1038, DOI 10.1109/TKDE.2004.33; Kuramochi M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989534; KURAMOCHI M, 2004, P 2004 SIAM INT C DA; Kuramochi M, 2002, 02026 U MINN DEP COM; KURAMOCHI M, 2004, IN PRESS DATA MINING, P315; Lee W., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382914; Leibowitz N, 2001, J COMPUT BIOL, V8, P93, DOI 10.1089/106652701300312896; Leibowitz N, 1999, Proc Int Conf Intell Syst Mol Biol, P169; Li W., 2001, P IEEE INT C DAT MIN, P369; Liu H, 1998, ELEC SOC S, V98, P86; MCKAY B, NAUTY USERS GUIDE; McKay B., 1981, C NUMERANTIUM, V30, P45; MITCHELL EM, 1990, J MOL BIOL, V212, P151, DOI 10.1016/0022-2836(90)90312-A; MOONEY RJ, 2004, RELATIONAL DATA MINI, P239; Muggleton S, 1999, COMMUN ACM, V42, P42, DOI 10.1145/319382.319390; Ostergard PRJ, 2002, DISCRETE APPL MATH, V120, P195; Palmer C.R., 2002, P 8 ACM SIGKDD INT C, P81; Pennec X, 1998, BIOINFORMATICS, V14, P516, DOI 10.1093/bioinformatics/14.6.516; Raymond JW, 2002, J CHEM INF COMP SCI, V42, P305, DOI 10.1021/ci010381f; READ RC, 1977, J GRAPH THEOR, V1, P339, DOI DOI 10.1002/JGT.3190010410; ROBSON JM, 1986, J ALGORITHM, V7, P425, DOI 10.1016/0196-6774(86)90032-5; Srinivasan A., 1997, LECT NOTES ARTIF INT, V1297, P273; Vanetik N., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183988; Wang X, 2002, IEEE T KNOWL DATA EN, V14, P731; Wasserman S, 1994, SOCIAL NETWORK ANAL; Yan X., 2002, P 2002 IEEE INT C DA, P721; YAN X, 2003, P 9 ACM SIGKDD INT C, P286; YOSHIDA K, 1994, APPL INTELL, V4, P297, DOI 10.1007/BF00872095; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A	74	44	52	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2005	11	3					243	271		10.1007/s10618-005-0003-9		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	990GZ	WOS:000233732500003	
J	Aggarwal, CC; Yu, PS				Aggarwal, CC; Yu, PS			Redefining clustering for high-dimensional applications	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; clustering; high dimensions; dimensionality curse		Clustering problems are well-known in the database literature for their use in numerous applications, such as customer segmentation, classification, and trend analysis. High-dimensional data has always been a challenge for clustering algorithms because of the inherent sparsity of the points. Recent research results indicate that, in high-dimensional data, even the concept of proximity or clustering may not be meaningful. We introduce a very general concept of projected clustering which is able to construct clusters in arbitrarily aligned subspaces of lower dimensionality. The subspaces are specific to the clusters themselves. This definition is substantially more general and realistic than the currently available techniques which limit the method to only projections from the original set of attributes. The generalized projected clustering technique may also be viewed as a way of trying to redefine clustering for high-dimensional applications by searching for hidden subspaces with clusters which are created by interattribute correlations. We provide a new concept of using extended cluster feature vectors in order to make the algorithm scalable for very large databases. The running time and space requirements of the algorithm are adjustable and are likely to trade-off with better accuracy.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Aggarwal, CC (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.		Yu, Philip/A-2815-2012				AGGARWAL CC, 1999, P ACM SIGMOD C; AGGARWAL CC, 2000, P ACM SIGMOD C; AGRAWAL R, 1998, P ACM SIGMOD C; ANKERST M, 1999, P ACM SIGMOD C; BEYER K, 1999, P INT C DATABASE THE; Bezdek J., 1999, HDB FUZZY SETS SERIE; CHAKRABARTI K, 2000, P VERY LARGE DATA BA; Cheng C. H., 1999, P 5 ACM SIGKDD INT C, P84, DOI 10.1145/312129.312199; ESTER M, 1998, P VERY LARGE DATA BA; ESTER M, 1996, P KNOWLEDGE DISCOVER; ESTIVILLCASTRO V, 1999, P PACIFIC ASIA KDD C; ESTIVILLCASTRO V, 1999, P AUSTR DATABASE C, P165; FALOUTSOS C, 1995, P ACM SIGMOD C; GANTI V, 1999, P ACM SIGKDD C; GANTI V, 1999, P INT C DATA ENG; GIBSON D, 1998, P VERY LARGE DATA BA; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; GUHA S, 1999, P INT C DATA ENG; GUHA S, 1998, P ACM SIGMOD C; GUSTAFSON EE, 1979, P IEEE C DECISION CO; HINNEBURG A, 1999, P 25 VERY LARGE DATA; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; JAGADISH HV, 1999, P ACM SIGMOD C; Jain AK, 1998, ALGORITHMS CLUSTERIN; Jolliffe I., 1986, PRINCIPAL COMPONENT; KANTH KVR, 1998, P ACM SIGMOD C; Kaufman L., 1990, FINDING GROUPS DATA; KLEINBERG J, 1997, P ACM S THEORY COMPU; KOHAVI R, 1995, P INT C KNOWLEDGE DI; NG R, 1994, P VERY LARGE DATA BA; SCHIKUTA E, 1997, BANG CLUSTERING SYST; SCHIKUTA E, 1996, P INT C PATTERN RECO, V2; THOMASIAN A, 1998, P C INFORMATION KNOW; XU X, 1998, P INT C DATA ENG; ZAIT M, 1997, FUTURE GENERATION CO; ZHANG Y, 1996, P ACM SIGMOD C; ZHANG Y, 2000, P INT C DATA ENG; ZHOU B, 1999, P PACIFIC ASIA KNOWL	39	44	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR-APR	2002	14	2					210	225		10.1109/69.991713		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	528CH	WOS:000174226200002	
J	Zhang, YQ; Fraser, MD; Gagliano, RA; Kandel, A				Zhang, YQ; Fraser, MD; Gagliano, RA; Kandel, A			Granular neural networks for numerical-linguistic data fusion and knowledge discovery	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						data compression; data fusion; data mining; distributed KDD; fuzzy logic; granular computing; knowledge discovery; linguistic computing; neural networks; parallel KDD; soft computing	FUZZY; SYSTEMS	In this paper, we present a neural-networks-based knowledge discovery and data mining (KDDM) methodology based on granular computing, neural computing, fuzzy computing, linguistic computing, and pattern recognition. The major issues include 1) how to make neural networks process both numerical and linguistic data in a data base, 2) how to convert fuzzy linguistic data into related numerical features, 3) how to use neural networks to do numerical-linguistic data fusion. 4) how to use neural networks to discover granular knowledge from numerical-linguistic data bases, and 5) how to use discovered granular knowledge to predict missing data. In order to answer the above concerns, a granular neural network (GNN) is designed to deal with numerical-linguistic data fusion and granular knowledge discovery in numerical-linguistic databases. From a data granulation point of view, the GNN can process granular data in a database. From a data fusion point of view, the GNN makes decisions based on different kinds of granular data. From a KDDM point of view, the GNN is able to learn internal granular relations between numerical-linguistic inputs and outputs, and predict new relations in a database. The GNN is also capable of greatly compressing low-level granular data to high-level granular knowledge with some compression error and a data compression rate. To do KDDM in huge data bases, parallel GNN and distributed GNN will be investigated in the future.	Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA; Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	Zhang, YQ (reprint author), Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA.						FRAYMAN Y, 1998, P PAKDD 98, P122; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Klir G. J., 1995, FUZZY SETS FUZZY LOG; Lin C T, 1994, NEURAL FUZZY CONTROL; Lin T. Y., 1998, ROUGH SETS KNOWLEDGE, P107; Lin T.Y., 1998, ROUGH SETS KNOWLEDGE, P121; Sugeno M., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390281; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Westphal C., 1998, DATA MINING SOLUTION; Yao Y. Y., 1999, P WORLD MULT SYST CY, V5, P573; Yao Y.Y., 1999, ADV SOFT COMPUTING E, P539; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZHANG Y, 1998, SERIES MACHINE PERCE, V30; Zhang YQ, 1998, CYBERNET SYST, V29, P5; Zhang YQ, 1998, IEEE T NEURAL NETWOR, V9, P83, DOI 10.1109/72.655032; Zhong N., 1998, Transactions of the Information Processing Society of Japan, V39; Zhou YH, 1997, LECT NOTES ARTIF INT, V1263, P376	19	44	45	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2000	11	3					658	667				10	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	326JM	WOS:000087732100011	
J	Moreira, JE; Midkiff, SP; Gupta, M; Artigas, PV; Snir, M; Lawrence, RD				Moreira, JE; Midkiff, SP; Gupta, M; Artigas, PV; Snir, M; Lawrence, RD			Java programming for high-performance numerical computing	IBM SYSTEMS JOURNAL			English	Article								First proposed as a mechanism for enhancing Web content the Java(TM) language has taken off as a serious general-purpose programming language. Industry and academia alike have expressed great interest in using the Java language as a programming language for scientific and engineering computations. Applications in these domains are characterized by intensive numerical computing and often have very high performance requirements, in this paper we discuss programming techniques that lead to Java numerical codes with performance comparable to FORTRAN or C, the more traditional languages for this field. The techniques are centered around the use of a high-performance numerical library, written entirely in the Java language, and on compiler technology. The numerical library takes the form of the Array package for Java. Proper use of this package, and of other appropriate tools for compiling and running a Java application, results in code that is clean, portable, and fast We illustrate the programming and performance issues through case studies in data mining and electromagnetism.	IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Moreira, JE (reprint author), IBM Corp, Div Res, Thomas J Watson Res Ctr, POB 218, Yorktown Hts, NY 10598 USA.	jmoreira@us.ibm.com; smidki@us.ibm.com; mgupta@us.ibm.com; artigas@us.ibm.com; snir@us.ibm; ricklawr@us.ibm.com	Snir, Marc/B-1050-2009				ADAMS JC, 1992, FORTRAN 90 HDB COMPL; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Anderson E., 1995, LAPACK USERS GUIDE; ARTIGAS PV, 1999, 12 INT WORKSH LANG C; BANERJEE U, 1996, DEPENDENCE ANAL; BIK AJC, 1997, WORKSH JAV COMP SCI, V2; Bik AJC, 1997, CONCURRENCY-PRACT EX, V9, P1091; Blount B, 1998, LECT NOTES COMPUT SC, V1505, P35; Bodin F., 1993, Scientific Programming, V2; Boisvert R. F, 1998, ACM 1998 WORKSH JAV; Casanova H, 1997, CONCURRENCY-PRACT EX, V9, P1279, DOI 10.1002/(SICI)1096-9128(199711)9:11<1279::AID-CPE339>3.0.CO;2-E; CASANOVA H, 1997, WORKSH JAV COMP SCI, V2; CHING WM, 1991, IBM J RES DEV, V35, P767; CIERNIAK M, 1997, WORKSH JAV COMP SCI, V2; Cierniak M, 1997, CONCURRENCY-PRACT EX, V9, P1063, DOI 10.1002/(SICI)1096-9128(199711)9:11<1063::AID-CPE344>3.0.CO;2-G; Dongarra J. J., 1991, SOLVING LINEAR SYSTE; GETOV V, 1998, ACM 1998 WORKSH JAV; Golub G, 1989, J HOPKINS SERIES MAT; Gustavson FG, 1997, IBM J RES DEV, V41, P737; Kandemir M, 1998, LECT NOTES COMPUT SC, V1470, P422; Kandemir M., 1998, Proceedings. 1998 International Conference on Parallel Architectures and Compilation Techniques (Cat. No.98EX192), DOI 10.1109/PACT.1998.727266; Midkiff SP, 1998, IBM SYST J, V37, P409; MOREIRA JE, 1998, P 11 INT WORKSH LANG, P1; Moreira JE, 1998, IEEE COMPUT SCI ENG, V5, P39, DOI 10.1109/99.683741; MUCHNICK S. S., 1997, ADV COMPILER DESIGN; PARSONS R, 1993, P SCAL PAR LIB C OCT, P77; Press W, 1992, NUMERICAL RECIPES FO; Reynders J. V. W., 1996, Proceedings. First International Workshop on High-Level Programming Models and Supportive Environments; RIVERA G, 1998, P ACM SIGPLAN C PROG, P38, DOI 10.1145/277650.277661; Sarkar V, 1997, IBM J RES DEV, V41, P233; SCHWAB M, 1998, ACM 1998 WORKSH JAV; SESHADRI A, 1997, AIXPERT MAGAZINE SEP; SIMOUDIS E, 1996, IEEE EXPERT INTELLIG, V1, P26; WILLHOFT RG, 1991, IBM SYST J, V30, P498; WILSON GV, 1996, PARALLEL PROGRAMMING; Wu P., 1999, P ACM 1999 JAV GRAND, P109, DOI 10.1145/304065.304109; WU P, 1998, P 11 INT WORKSH LANG, P197; *IBM CORP, 1997, IBM PAR ENG SCI SUBR; *IBM CORP, 1997, IBM ENG SCI SUBR LIB; *JAV GRAND FOR PAN, 1998, JAV GRAND FOR REP MA	40	44	44	IBM CORP	ARMONK	1 NEW ORCHARD ROAD, ARMONK, NY 10504 USA	0018-8670		IBM SYST J	IBM Syst. J.		2000	39	1					21	56				36	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	287RW	WOS:000085520700003	
J	Wong, ML; Lam, W; Leung, KS				Wong, ML; Lam, W; Leung, KS			Using evolutionary programming and minimum description length principle for data mining of Bayesian networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						evolutionary computation; Bayesian networks; unsupervised learning; minimum description length principle; genetic algorithms	GENETIC ALGORITHMS	We have developed a new approach (MDLEP) to learning Bayesian network structures based on the Minimum Description Length (MDL) principle and Evolutionary Programming (EP). It employs a MDL metric, which is founded on information theory, and integrates a knowledge-guided genetic operator for the optimization in the search process.	Lingnan Coll, Dept Informat Syst, Tuen Mun, Hong Kong; Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Shatin, Hong Kong; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong	Wong, ML (reprint author), Lingnan Coll, Dept Informat Syst, Tuen Mun, Hong Kong.						Beinlich IA, 1989, P 2 EUR C ART INT ME, P247; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956; Fogel L.J., 1966, ARTIFICIAL INTELLIGE; Goldberg D.E., 1989, GENETIC ALGORITHMS S; HECKERMAN D, 1995, COMMUN ACM, V38, P27, DOI 10.1145/203330.203336; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; HERSKOVITS E, 1990, KSL9022 STANF U KNOW; HICKERING D, 1995, P 5 C ART INT STAT, P112; HOLLAND JH, 1992, ADAPTATION NATURAL A; Lam W, 1998, IEEE T PATTERN ANAL, V20, P240; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Scheines R., 1993, CAUSATION PREDICTION; Spirtes P, 1995, P 1 INT C KNOWL DISC, P294	17	44	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1999	21	2					174	178				5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	167NL	WOS:000078639900006	
J	Kusiak, A; Zheng, HY; Song, Z				Kusiak, Andrew; Zheng, Haiyang; Song, Zhe			Short-Term Prediction of Wind Farm Power: A Data Mining Approach	IEEE TRANSACTIONS ON ENERGY CONVERSION			English	Article						Data mining algorithms; multiperiod prediction; multiscale prediction; time series model; wind farm power prediction	NEURAL-NETWORK MODELS; TIME-SERIES; SPEED; REGRESSION; TREES; FORECAST	This paper examines time series models for predicting the power of a wind farm at different time scales, i.e., 10-min and hour-long intervals. The time series models are built with data mining algorithms. Five different data mining algorithms have been tested on various wind farm datasets. Two of the five algorithms performed particularly well. The support vector machine regression algorithm provides accurate predictions of wind power and wind speed at 10-min intervals up to I h into the future, while the multilayer perceptron algorithm is accurate in predicting power over hour-long intervals up to 4 h ahead. Wind speed can be predicted fairly accurately based on its historical values; however, the power cannot be accurately determined given a power curve model and the predicted wind speed. Test computational results of all time series models and data mining algorithms are discussed. The tests were performed on data generated at a wind farm of 100 turbines. Suggestions for future research are provided.	[Kusiak, Andrew; Zheng, Haiyang; Song, Zhe] Univ Iowa, Intelligent Syst Lab, Dept Mech & Ind Engn, Iowa City, IA 52242 USA	Kusiak, A (reprint author), Univ Iowa, Intelligent Syst Lab, Dept Mech & Ind Engn, Iowa City, IA 52242 USA.	andrew-kusiak@uiowa.edu			Iowa Energy Center [IEC 07-01]	This work was supported by Iowa Energy Center under Grant IEC 07-01.	Backus P, 2006, IEEE T SEMICONDUCT M, V19, P252, DOI 10.1109/TSM.2006.873400; Barbounis TG, 2006, IEEE T ENERGY CONVER, V21, P273, DOI 10.1109/TEC.2005.847954; Berry M. J. A., 2004, DATA MINING TECHNIQU; Box G., 1976, TIME SERIES ANAL; Breiman L, 1984, CLASSIFICATION REGRE; BROWN BG, 1984, J CLIM APPL METEOROL, V23, P1184, DOI 10.1175/1520-0450(1984)023<1184:TSMTSA>2.0.CO;2; DAMAOUSIS IG, 2004, IEEE T ENERGY CONVER, V19, P352; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Espinosa J., 2005, FUZZY LOGIC IDENTIFI; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; HARDING JA, 2006, ASME T, V128, P969; Hothorn T, 2005, COMPUT STAT DATA AN, V49, P1068, DOI 10.1016/j.csda.2004.06.019; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kusiak A, 2006, IEEE T IND INFORM, V2, P176, DOI 10.1109/TII.2006.873598; Kusiak A, 2009, RENEW ENERG, V34, P583, DOI 10.1016/j.renene.2008.05.032; Li SH, 2001, J SOL ENERG-T ASME, V123, P327, DOI 10.1115/1.1413216; Martin M, 1999, INT J CLIMATOL, V19, P197, DOI 10.1002/(SICI)1097-0088(199902)19:2<197::AID-JOC360>3.0.CO;2-H; Potter CW, 2006, IEEE T POWER SYST, V21, P965, DOI 10.1109/TPWRS.2006.873421; Seidel P, 2007, NEURAL NETWORKS, V20, P646, DOI 10.1016/j.neunet.2006.12.004; Sfetsos A, 2002, RENEW ENERG, V27, P163, DOI 10.1016/S0960-1481(01)00193-8; Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Spera D. A., 1994, WIND TURBINE TECHNOL; Torres JL, 2005, SOL ENERGY, V79, P65, DOI 10.1016/j.solener.2004.09.013; WANG Y, 1997, 9 EUR C MACH LEARN U; Witten IH, 2005, DATA MINING PRACTICA	28	43	45	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0885-8969		IEEE T ENERGY CONVER	IEEE Trans. Energy Convers.	MAR	2009	24	1					125	136		10.1109/TEC.2008.2006552		12	Energy & Fuels; Engineering, Electrical & Electronic	Energy & Fuels; Engineering	411HC	WOS:000263639000014	
J	Luo, J; Xu, L; Jamont, JP; Zeng, L; Shi, Z				Luo, J.; Xu, L.; Jamont, J. -P.; Zeng, L.; Shi, Z.			Flood decision support system on agent grid: method and implementation	ENTERPRISE INFORMATION SYSTEMS			English	Article						Agent; Application integration; Data mining; Case studies; Data integration; Legacy systems		In this paper, we introduce the concept and architecture of agent grid. Agent grid is an intelligent platform that enables the independent operating entities ( agents) to interact with one another to form dynamic services on the Grid. Under this view, we built an agent grid platform named AGrIP that includes four layers and several useful toolkits. With the platform support, we implemented the flood decision support system which combines the wireless sensor network for data acquisition and software agent technology for legacy system integration. Additionally, we developed a toolkit for programmers to visually develop software agents which makes the development process easier. Besides, the MWAC model proposed is for sensor network to save power which can transit the information for long distance. This system is now applied as a module in the city emergency interact project.	[Luo, J.; Xu, L.; Zeng, L.; Shi, Z.] Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China; [Jamont, J. -P.] INPG, LCIS, F-26000 Valence, France; [Xu, L.] Old Dominion Univ, Dept Informat Technol & Decis Sci, Norfolk, VA 23529 USA; [Luo, J.; Zeng, L.] Chinese Acad Sci, Grad Univ, Beijing 100049, Peoples R China	Luo, J (reprint author), Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.	luojw@ics.ict.ac.cn			National Science Foundation of China [60435010, 90604017, 60675010]; National Basic Research Priorities Programme [2003CB317004]; Nature Science Foundation of Beijing [4052025]	This work is supported by the National Science Foundation of China ( No. 60435010, 90604017, 60675010). National Basic Research Priorities Programme No. 2003CB317004 and the Nature Science Foundation of Beijing No. 4052025.	Berstis V., 2002, FUNDAMENTALS GRID CO; CALISTI M, 2004, AAMAS WORKSH AG UB C; FOSTER I, 2004, BRAIN MEETS BRAWN WH, P8; Foster I., 2004, GRID BLUEPRINT NEW C; JAMONT JP, 2002, P 2002 IEEE INT S VI, P20; JAMONT JP, 2006, P 19 INT C IND ENG O; JEFFRY KG, 2000, KNOWLEDGE INFORM DAT; Krishanamachari B., 2002, P INT WORKSH DISTR E; LUO J, 2005, VASTUDIO GENERIC MUL, P451; Luo JW, 2006, LECT NOTES COMPUT SC, V3842, P590; PARK J, 2004, AAMAS WORKSH AG UB C; SHI Zhongzhi, 2003, INT J INFORM TECHNOL, V2, P407, DOI 10.1142/S0219622003000732; SHI ZZ, 2004, MAGE AGENT ORIENTED, P250; SHI ZZ, 2005, MSMINER DEV PLATFORM; SHOHAM Y, 1993, ARTIF INTELL, V60, P51, DOI 10.1016/0004-3702(93)90034-9; [Anonymous], GLOB TOOLK	16	43	43	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1751-7575		ENTERP INFORM SYST	Enterp. Inf. Syst.		2007	1	1					49	68		10.1080/17517570601092184		20	Computer Science, Information Systems	Computer Science	V10LW	WOS:000207466500004	
J	Kolter, JZ; Maloof, MA				Kolter, J. Zico; Maloof, Marcus A.			Learning to detect and classify malicious executables in the wild	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						data mining; concept learning; computer security; invasive software	CLASSIFICATION; RECOGNITION; ALGORITHMS	We describe the use of machine learning and data mining to detect and classify malicious executables as they appear in the wild. We gathered 1; 971 benign and 1; 651 malicious executables and encoded each as a training example using n-grams of byte codes as features. Such processing resulted in more than 255 million distinct n-grams. After selecting the most relevant n-grams for prediction, we evaluated a variety of inductive methods, including naive Bayes, decision trees, support vector machines, and boosting. Ultimately, boosted decision trees outperformed other methods with an area under the ROC curve of 0.996. Results suggest that our methodology will scale to larger collections of executables. We also evaluated how well the methods classified executables based on the function of their payload, such as opening a backdoor and mass-mailing. Areas under the ROC curve for detecting payload function were in the neighborhood of 0.9, which were smaller than those for the detection task. However, we attribute this drop in performance to fewer training examples and to the challenge of obtaining properly labeled examples, rather than to a failing of the methodology or to some inherent difficulty of the classification task. Finally, we applied detectors to 291 malicious executables discovered after we gathered our original collection, and boosted decision trees achieved a true-positive rate of 0.98 for a desired false-positive rate of 0.05. This result is particularly important, for it suggests that our methodology could be used as the basis for an operational system for detecting previously undiscovered malicious executables.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA; Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA	Kolter, JZ (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	KOLTER@CS.STANFORD.EDu; MALOOF@CS.GEORGETOWN.EDU					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AIKEN A, 1994, MOSS SYSTEM DETECTIN; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Breiman L, 1998, ANN STAT, V26, P801; CHRISTODORESCU M, 2003, P 12 USENIX SEC S BE; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; DURNINGLAWRENCE E, 1910, BACON IS SHAKESPEARE; Fisher RA, 1936, ANN EUGENIC, V7, P179; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gray A., 1997, P 3 BIANN C INT ASS; Hand D. J., 2001, PRINCIPLES DATA MINI; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JANKOWITZ HT, 1988, COMPUT J, V31, P1, DOI 10.1093/comjnl/31.1.1; JOACHIMS T, 1998, P 10 EUR C MACH LEAR, P487; Kephart J. O., 1995, P 14 INT JOINT C ART, P985; KJELL B, 1994, INFORM PROCESS MANAG, V30, P141, DOI 10.1016/0306-4573(94)90029-9; Kolter J., 2004, P 10 ACM SIGKDD INT, P470, DOI 10.1145/1014052.1014105; KRSUL I, 1994, THESIS PURDUE U W LA; KRSUL I, 1995, P 18 NAT INF SYST SE, P514; LO RW, 1995, COMPUT SECUR, V14, P541, DOI 10.1016/0167-4048(95)00012-W; MARON ME, 1960, J ACM, V7, P216, DOI 10.1145/321033.321035; MCGRAW G, 2000, IEEE SOFTWARE    SEP, P33; METZ CE, 2003, ROC SOFTWARE; MILLER P, 1999, HEXDUMP 1 4 SOFTWARE; Mitchell T. M, 1997, MACHINE LEARNING; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; Platt JC, 2000, ADV NEUR IN, P61; Platt J, 1998, ADV KERNEL METHODS S; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Sahami M., 1998, LEARNING TEXT CATEGO; Schultz MG, 2001, P IEEE S SECUR PRIV, P38, DOI 10.1109/SECPRI.2001.924286; SOMAN S, 2003, P 12 USENIX SEC S BE; Spafford E. H., 1993, Computers & Security, V12, DOI 10.1016/0167-4048(93)90055-A; Swets JA, 1982, EVALUATION DIAGNOSTI; Tesauro GJ, 1996, IEEE EXPERT, V11, P5, DOI 10.1109/64.511768; Witten IH, 2005, DATA MINING PRACTICA; Yang Y, 1997, P 14 INT C MACH LEAR, P412; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; 2003, MAXIMUM SECURITY	44	43	50	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	DEC	2006	7						2721	2744				24	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152VT	WOS:000245390800009	
J	Greco, S; Inuiguchi, M; Slowinski, R				Greco, S; Inuiguchi, M; Slowinski, R			Fuzzy rough sets and multiple-premise gradual decision rules	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article; Proceedings Paper	5th International Workshop on Fuzzy Logic and Applications	OCT 09-11, 2003	Naples, ITALY			rough sets; fuzzy sets; decision rides; gradual rules; credibility		We propose a new fuzzy rough set approach which.. differently from most known fuzzy set extensions of rough set theory, does not use any fuzzy logical connectives (t-norm, t-conorm, fuzzy implication). As there is no rationale for a particular choice of these connectives, avoiding this choice permits to reduce the part of arbitrary in the fuzzy rough approximation. Another advantage of the new approach is that it is based on the ordinal properties of fuzzy membership degrees only. The concepts of fuzzy lower and Upper approximations are thus proposed, creating a base for induction or fuzzy decision rules having syntax and semantics of gradual rules. The proposed approach to rule induction is also interesting from the viewpoint Of philosophy supporting data mining and knowledge discovery, because it is concordant with the method of concomitant variations by John Stuart Mill. The decision rules are induced from lower and upper approximations defined for positive and negative relationships between credibility degrees of multiple premises, on one hand, and conclusion, on the other hand. (C) 2005 Elsevier Inc. All rights reserved.	Univ Catania, Fac Econ, I-95129 Catania, Italy; Osaka Univ, Grad Sch Engn Sci, Osaka 5608531, Japan; Poznan Univ Technol, Inst Comp Sci, PL-60965 Poznan, Poland; Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland	Greco, S (reprint author), Univ Catania, Fac Econ, Corso Italia 55, I-95129 Catania, Italy.	salgreco@unict.it; inuiguti@sys.es.osaka-u.ac.jp; roman.slowisnki@cs.put.poznan.pl	Slowinski, Roman/A-5751-2013				ARAGONES E, 2002, 02027 PIER; BENSUSAN H, 2000, ECAI2000 WORKSH NOT, P9; CORNISH TAO, 1995, PR CONF ART INT APPL, P347, DOI 10.1109/CAIA.1995.378801; DUBOIS D, 1992, INFORM SCIENCES, V61, P103, DOI 10.1016/0020-0255(92)90035-7; DUBOIS D, 1997, INFORM ENG; Dubois D., 1992, INTELLIGENT DECISION, P203; Greco S., 2004, LECT NOTES COMPUTER, V3135, P156; Greco S, 2005, INT SER OPER RES MAN, V78, P507, DOI 10.1007/0-387-23081-5_13; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; Greco S, 2003, LECT NOTES ARTIF INT, V2639, P156; Greco S, 2004, ENG APPL ARTIF INTEL, V17, P345, DOI 10.1016/j.engappai.2004.04.008; GRECO S, 1999, ADV MULTIPLE CRITERI, pCH14; Klement E.P., 2000, TRIANGULAR NORMS; Marchant T, 2004, FUZZY SET SYST, V148, P157, DOI 10.1016/j.fss.2004.03.013; MILL JS, 1843, COLLECTED WORKS, V7; NAKAMURA A, 1991, FUZZY SET SYST, V39, P127, DOI 10.1016/0165-0114(91)90208-8; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z, 1991, ROUGH SETS; Williamson J, 2004, MIND MACH, V14, P539, DOI 10.1023/B:MIND.0000045990.57744.2b; WITTGENSTEIN L, 1951, TRACTATUS LOGICO PHI; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	21	43	57	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X		INT J APPROX REASON	Int. J. Approx. Reasoning	FEB	2006	41	2					179	211		10.1016/j.ijar.2005.06.014		33	Computer Science, Artificial Intelligence	Computer Science	007CR	WOS:000234945900008	
J	Chen, MC; Chiu, AL; Chang, HH				Chen, MC; Chiu, AL; Chang, HH			Mining changes in customer behavior in retail marketing	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; association rules; retailing; customer behavior; change patterns	KNOWLEDGE DISCOVERY; MODEL	During the past decade, there have been a variety of significant developments in data mining techniques. Some of these developments are implemented in customized service to develop customer relationship. Customized service is actually crucial in retail markets. Marketing managers can develop long-term and pleasant relationships with customers if they can detect and predict changes in customer behavior. In the dynamic retail market, understanding changes in customer behavior can help managers to establish effective promotion campaigns. This study integrates customer behavioral variables, demographic variables, and transaction database to establish a method of mining changes in customer behavior. For mining change patterns, two extended measures of similarity and unexpectedness are designed to analyze the degree of resemblance between patterns at different time periods. The proposed approach for mining changes in customer behavior can assist managers in developing better marketing strategies. (c) 2005 Elsevier Ltd. All rights reserved.	Natl Taipei Univ Technol, Dept Business Management, Taipei 106, Taiwan; SAS, Taipei, Taiwan; Natl Taipei Coll Business, Dept Business Adm, Taipei, Taiwan	Chen, MC (reprint author), Natl Taipei Univ Technol, Dept Business Management, 1,Sect 3 Chung Hsiao E Rd, Taipei 106, Taiwan.	bmcchen@ntut.edu.tw					AGRAWAL R, 1993, ACM SIGMOD C WASH DC, P254; Changchien SW, 2001, EXPERT SYST APPL, V20, P325, DOI 10.1016/S0957-4174(01)00017-3; Chaniotakis ES, 2004, COMPUT COMMUN, V27, P1, DOI [10.1016/S0140-3664(03)00178-6, 10.1016/S0140-3664(03)00178-9]; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; DONG G, 1999, KDD 99; Giudici P, 2002, COMPUT STAT DATA AN, V38, P533, DOI 10.1016/S0167-9473(01)00077-9; Han J., 2001, DATA MINING CONCEPTS; Lanquillon C., 1999, P INT JOINT C ART IN, P41; Liu B., 2000, 2 INT C DAT WAR KNOW, P337; Liu B., 1996, P 13 NAT C KNOWL DIS, P220; Liu B, 1999, IEEE T KNOWL DATA EN, V11, P817; Marcus C, 1998, J CONSUMER MARKETING, V15, P494, DOI 10.1108/07363769810235974; Miglautsch J. R., 2000, J DATABASE MARKETING, V8, P67, DOI 10.1057/palgrave.jdm.3240019; Mitra S, 2002, IEEE T NEURAL NETWOR, V13, P3, DOI 10.1109/72.977258; Padmanabhan B, 1999, DECIS SUPPORT SYST, V27, P303, DOI 10.1016/S0167-9236(99)00053-6; Parr Rud O, 2001, DATA MINING COOKBOOK; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; Song HS, 2001, EXPERT SYST APPL, V21, P157, DOI 10.1016/S0957-4174(01)00037-9; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Stone B., 1995, SUCCESSFUL DIRECT MA; Suh EH, 1999, EXPERT SYST APPL, V17, P89, DOI 10.1016/S0957-4174(99)00026-3; Tsai CY, 2004, EXPERT SYST APPL, V27, P265, DOI 10.1016/j.eswa.2004.02.005	22	43	48	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2005	28	4					773	781		10.1016/j.eswa.2004.12.033		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	913BD	WOS:000228124200018	
J	Bernstein, A; Provost, F; Hill, S				Bernstein, A; Provost, F; Hill, S			Toward intelligent assistance for a data mining process: An ontology-based approach for cost-sensitive classification	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						cost-sensitive learning; data mining; data mining process; intelligent assistants; knowledge discovery; knowledge; discovery process; machine learning; metalearning	BIAS SELECTION; SUPPORT; ALGORITHMS; KNOWLEDGE	A data mining (DM) process involves multiple stages. A simple, but typical, process might include preprocessing data, applying a data mining algorithm, and postprocessing the mining results. There are many possible choices for each stage, and only some combinations are valid. Because of the large space and nontrivial interactions, both novices and data mining specialists need assistance in composing and selecting DM processes. Extending notions developed for statistical expert systems we present a prototype Intelligent Discovery Assistant (IDA), which provides users with 1) systematic enumerations of valid DM processes, in order that important, potentially fruitful options are not overlooked, and 2) effective rankings of these valid processes by different criteria, to facilitate the choice of DM processes to execute. We use the prototype to show that an IDA can indeed provide useful enumerations and effective rankings in the context of simple classification processes. We discuss how an IDA could be an important tool for knowledge sharing among a team of data miners. Finally, we illustrate the claims with a demonstration of cost-sensitive classification using a more complicated process and data from the 1998 KDDCUP competition.	Univ Zurich, Dept Informat, CH-8057 Zurich, Switzerland; NYU, Stern Sch Business, New York, NY 10012 USA	Bernstein, A (reprint author), Univ Zurich, Dept Informat, Winterthurerstr 190, CH-8057 Zurich, Switzerland.	bernstein@ifi.unizh.ch; fprovost@stern.nyu.edu; shill@stern.nyu.edu					Ackerman MS, 1999, J ORG COMP ELECT COM, V9, P105, DOI 10.1207/s15327744joce0902&3_2; AGRAWAL N, 1998, URBAN SCI WINS KDD 9; ANKOLEKAR A, 2001, P SEM WEB WORK S; Blake C, 2000, UCI REPOSITORY MACHI; BRAZDIL P, 2000, P 11 EUR C MACH LEAR, P63; Brazdil P., 1994, P EUR C MACH LEARN E, P83; BRAZDIL PB, 1998, P 10 EUR C MACH LEAR, P11; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; BUCHANAN B, 1975, ENCY COMPUTER SCI TE, P24; BUNTINE WL, 1999, P 5 INT C KNOWL DISC, P372, DOI 10.1145/312129.312286; CHANDRASEKARAN B, 1992, COMMUN ACM, V35, P124, DOI 10.1145/130994.131002; CHAPMAN P, 2000, CRISP DM 1 0 STEP BY; CHRISTENSEN E, 2001, WORLD WIDE WEB CONSO; CRAW S, 1992, RES DEV EXPERT SYSTE, V9, P5; DAVIS R, 1984, ADDISON WESLEY SERIE, P171; Engels R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; ENGELS R., 1996, P 2 INT C KNOWL DISC, P170; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Furnkranz Johannes, 2001, P ECML WKSHOP INT AS, P57; GALE WA, 2006, ARTIFICIAL INTELLIGE; Gama J., 1995, Progress in Artificial Intelligence. 7th Portuguese Conference on Artificial Intelligence, EPIA '95. Proceedings; GHALLAB M, 1998, TR98003DCSTR1165 CT; GORDON DF, 1995, MACH LEARN, V20, P5, DOI 10.1023/A:1022630017346; HAND D, 1994, CHANCE, V7, P28; HILARIO M, 2001, UNIGEAI0101 U GEN; Hoeting JA, 1999, STAT SCI, V14, P382; Kerber R., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; KOHAVI R., 2000, SIGKDD EXPLORATIONS, V2, P86; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LENAT D, 1982, MCGRAW HILL ADV CO D, P3; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; LIVINGSTON G, 2003, J KNOWLEDGE INFORMAT, V5, P133; LUBINSKY D, 1988, J ECONOMETRICS, V38, P247, DOI 10.1016/0304-4076(88)90035-8; MORIK K, 2000, P 11 EUR C MACH LEAR, P4; Morik K., 2003, INTELLIGENT TECHNOLO, P47; Nishisato S., 1994, ELEMENTS DUAL SCALIN; Oates T, 1997, P 14 INT C MACH LEAR, P254; OLDFORD R, 1985, ARTIF INTELL, P335; OLDFORD R, 1997, P 29 S INT; PENTLAND BT, 1992, ADMIN SCI QUART, V37, P527, DOI 10.2307/2393471; Perlich C, 2004, J MACH LEARN RES, V4, P211, DOI 10.1162/153244304322972694; PETRAK J, 2000, TR200007 AUSTR RES I; Pfahringer B., 2000, P 17 INT C MACH LEAR, P743; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; SCHOLZ M, 2002, TR1205; Senator T. E., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347102; SOARES C, 2001, 7 JORN CLASS AN DAD, P72; St Amant R, 1998, J COMPUT GRAPH STAT, V7, P545; Suyama A., 1998, P 1998 AAAI WORKSH M, P29; Taylor C.C., 1994, MACHINE LEARNING NEU; Tcheng D., 1989, P 11 INT JOINT C ART, P806; TURNEY P, 2001, COST SENSITIVE LEARN; Ulrich K. T., 2004, PRODUCT DESIGN DEV; VERDENIUS F, 1997, P 7 BELG DUTCH C MAC, P119; WIRTH R, 1997, P 1 EUR S PRINC DAT, P55; Witten I.H., 1999, DATA MINING PRACTICA; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540	61	43	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2005	17	4					503	518		10.1109/TKDE.2005.67		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	897IB	WOS:000226996100005	
J	Cormode, G; Muthukrishnan, S				Cormode, G; Muthukrishnan, S			What's hot and what's not: Tracking most frequent items dynamically	ACM TRANSACTIONS ON DATABASE SYSTEMS			English	Article						algorithms; measurement; data stream processing; approximate query answering	ELEMENTS; STREAMS; SPACE	Most database management systems maintain statistics on the underlying relation. One of the important statistics is that of the "hot items" in the relation: those that appear Man. times (most frequently, or mote than some threshold): For example, end-biased histograms keep the hot items as part of the histogram and are used in selectivity estimation. Hot items are used as simple outliers in data mining, and in anomaly detection in many applications. We present new methods for dynamically determining the hot items at any time in a relation which is undergoing deletion operations as well as inserts. Our methods maintain small space data structures that monitor the transactions on the relation, and, when required, quickly output all hot items without rescanning the relation in the database. With user-specified probability, all hot items are correctly reported. Our methods rely on ideas from "group testing." They are simple to implement, and have provable quality, space, and time guarantees. Previously known algorithms for this problem that make similar quality and performance guarantees cannot handle deletions, and those that handle deletions cannot make similar. guarantees without rescanning the database. Our experiments with real and synthetic data show that our algorithms are accurate in dynamically tracking the hot items independent of the rate of insertions and deletions.	Dept Comp & Informat Sci, Piscataway, NJ 08854 USA	Cormode, G (reprint author), Bell Labs, Room 2B-315,600 Mt Ave, Murray Hill, NJ 07974 USA.	graharn@dimacs.rutgers.edu; muthu@cs.rutgers.edu					Aho A.V., 1987, DATA STRUCTURES ALGO; Alon N, 1999, J COMPUT SYST SCI, V58, P137, DOI 10.1006/jcss.1997.1545; Alon N., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, DOI 10.1145/303976.303978; Babcock B., 2003, P ACM SIGMOD INT C M; Barbara D., 2001, P 1 SIAM INT C DAT M; BOYER B, 1982, 35 U TEX I COMP SCI; CARTER JL, 1979, J COMPUT SYST SCI, V18, P143, DOI 10.1016/0022-0000(79)90044-8; Charikar M., 2002, P 29 INT C AUT LANG, P693; Cormode G, 2003, P ACM PRINC DAT SYST, P296, DOI 10.1145/773153.773182; CORMODE G, 2004, IN PRESS J ALGORITHM; CORMODE G, 2004, P IEEE INFOCOM; Demaine ED, 2002, LECT NOTES COMPUT SC, V2461, P348; DU D, 1993, SERIES APPL MATH, V3; ESTAN C, 2002, J VERSION COMPUT COM, V32, P323; Fang M., 1998, P 24 INT C VER LARG, P299; Fischer M., 1982, J ALGORITHMS, V3, P376; Garofalakis M., 2002, P ACM SIGMOD INT C M; GIBBONS P, 1998, J VERSION ACM SIGMOD, V27, P331; Gibbons PB, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P466; GIBBONS PB, 1999, DIMACS SERIES DISC A; Gilbert A., 2001, 200143 DIMACS; Gilbert A. C., 2002, P 34 ANN ACM S THEOR, P389; Gilbert A. C., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; IOANNIDIS YE, 1993, ACM T DATABASE SYST, V18, P709, DOI 10.1145/169725.169708; Ioannidis Y.E., 1995, P ACM SIGMOD C, P233, DOI 10.1145/223784.223841; Karp RM, 2003, ACM T DATABASE SYST, V28, P51, DOI 10.1145/762471.762473; Kushilevitz Eyal, 1997, COMMUNICATION COMPLE; Manku GS, 2002, P 28 INT C VER LARG, P346; MISRA J, 1982, SCI COMPUT PROGRAM, V2, P143, DOI 10.1016/0167-6423(82)90012-0; Motwani R., 1995, RANDOMIZED ALGORITHM; MUTHUKRISHNAN S, 2003, P 14 ANN ACM SIAM S; Thorup M, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P496; Yi B.-K., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839383	33	43	46	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0362-5915		ACM T DATABASE SYST	ACM Trans. Database Syst.	MAR	2005	30	1					249	278		10.1145/1061318.1061325		30	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	912UB	WOS:000228104300007	
J	Pasquier, N; Taouil, R; Bastide, Y; Stumme, G; Lakhal, L				Pasquier, N; Taouil, R; Bastide, Y; Stumme, G; Lakhal, L			Generating a condensed representation for association rules	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						data mining; Galois closure operator; frequent closed itemsets; generators; min-max association rules; basis for association rules; condensed representation	KNOWLEDGE DISCOVERY; DATABASES	Association rule extraction from operational datasets often produces several tens of thousands, and even millions, of association rules. Moreover, many of these rules are redundant and thus useless. Using a semantic based on the closure of the Galois connection, we define a condensed representation for association rules. This representation is characterized by frequent closed itemsets and their generators. It contains the non-redundant association rules having minimal antecedent and maximal consequent, called min-max association rules. We think that these rules are the most relevant since they are the most general non-redundant association rules. Furthermore, this representation is a basis, i.e., a generating set for all association rules, their supports and their confidences, and all of them can be retrieved needless accessing the data. We introduce algorithms for extracting this basis and for reconstructing all association rules. Results of experiments carried out on real datasets show the usefulness of this approach. In order to generate this basis when an algorithm for extracting frequent itemsets-such as APRIORI for instance-is used, we also present an algorithm for deriving frequent closed itemsets and their generators from frequent itemsets without using the dataset.	Univ Nice, CNRS, UMR 6070, F-06903 Sophia Antipolis, France; Univ Francois Rabelais Tours, LI, F-41000 Blois, France; Inst Natl Rech Informat & Automat, IRISA, F-35042 Rennes, France; Univ Kassel, Fachbereich Math Informat, D-34121 Kassel, Germany; Univ Mediterranee, CNRS, FRE 2246, LIM, F-13288 Marseille, France	Pasquier, N (reprint author), Univ Nice, CNRS, UMR 6070, I3S, F-06903 Sophia Antipolis, France.	nicolas.pasquier@unice.fr; taouil@univ-tours.fr; yves.bastide@irisa.fr; stumme@uni-kassel.de; lotfi.lakhal@lim.univ-mrs.fr					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P478; Armstrong W. W., 1974, P IFIP C, P580; BARANOVSKII SD, 1997, J PHYS-CONDENS MAT, V9, P1; BASTIDE Y, 2000, MINING FREQUENT PATT, V2, P66; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; Beeri C., 1979, ACM Transactions on Database Systems, V4, DOI 10.1145/320064.320066; Blake C.L., 1998, UCI MACHINE LEARNING; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Duquenne V., 1986, MATH SCI HUM, V24, P5; Ganter B., 1999, FORMAL CONCEPT ANAL; Han JW, 1999, IEEE T KNOWL DATA EN, V11, P798; HETTICH S, 1999, UCI KNOWLEDGE DISCOV; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; Lin DI, 1998, P 6 INT C EXT DAT TE, P105; Liu B., 1999, P 5 ACM SIGKDD INT C, P125, DOI 10.1145/312129.312216; Luxenburger M., 1991, MATH INFORMATIQUE SC, V29, P35; MAIER D, 1980, J ACM, V27, P664, DOI 10.1145/322217.322223; Mannila H., 1996, P 2 INT C KNOWL DISC, P189; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; Meo R, 1998, DATA MIN KNOWL DISC, V2, P195, DOI 10.1023/A:1009774406717; Morimoto Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Pasquier N., 1998, P 14 INT C BAS DONN, P177; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; Pasquier N, 1999, P 15 JOURN BAS DONN, P361; Pei J., 2000, P ACM SIGMOD WORKSH, P21; Piatetsky-Shapiro G., 1994, P AAAI 94 WORKSH KNO, P25; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; SILVA SS, 1998, POLIMEROS CIENCIA TE, V2, P1; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Srikant R., 1995, P 21 INT C VER LARG, P407; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; TAOUIL R, 2000, P 16 INT C DAT ENG I, P307, DOI 10.1109/ICDE.2000.839424; TOIVONEN H, 1995, P MLNET WORKSH STAT, P47; Zaki M. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347101; ZAKI MJ, 1998, P DMKD WORKSH RES IS; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; ZAKI MJ, 1999, 9910 ASS RUL MIN	44	43	44	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	JAN	2005	24	1					29	60		10.1007/s10844-005-0266-z		32	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	898LO	WOS:000227078500002	
J	Li, X; Yeh, AGO				Li, X; Yeh, AGO			Data mining of cellular automata's transition rules	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article							LAND-COVER CLASSIFICATION; DECISION TREES; SAN-FRANCISCO; URBAN-GROWTH; MODEL; GIS; SIMULATION; DYNAMICS; CALIBRATION; INTEGRATION	This paper presents a new method to discover knowledge for geographical cellular automata (CA) by using a data-mining technique. CA have the ability to simulate complex geographical phenomena. Very few studies have been carried out on how to determine and validate the transition rules of CA from observed data. The transition rules of traditional CA are usually expressed by mathematical equations. This paper demonstrates that the explicit transition rules of CA can be automatically reconstructed through the rule induction procedure of data mining. The explicit transition rules are more intuitive to decision-makers. The transition rules are obtained by applying data-mining techniques to spatial data. The proposed method can reduce the uncertainties in defining transition rules and help to generate more reliable simulation results.	Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Peoples R China; Univ Hong Kong, Ctr Urban Planning & Environm Management, Hong Kong, Hong Kong, Peoples R China	Li, X (reprint author), Sun Yat Sen Univ, Sch Geog & Planning, 135 W Xingang Rd, Guangzhou 510275, Peoples R China.	lixia@graduate.hku.hk; hdxugoy@hkucc.hku.hk	LI, XIA/A-1235-2013; LI, XIA/H-1585-2011; Zhao, Kefei/A-1080-2012	LI, XIA/0000-0003-3050-8529; LI, XIA/0000-0003-3050-8529; Zhao, Kefei/0000-0002-0369-0874			BATTY M, 1989, ENVIRON PLANN A, V21, P1447, DOI 10.1068/a211447; Batty M, 1997, ENVIRON PLANN B, V24, P175, DOI 10.1068/b240175; Batty M., 1999, Computers, Environment and Urban Systems, V23, DOI 10.1016/S0198-9715(99)00015-0; Batty M., 1994, ENVIRON PLANN B, V21, P531; Batty M, 1994, FRACTAL CITIES GEOME; Berry M. R. J., 1997, DATA MINING TECHNIQU; Breiman L, 1984, CLASSIFICATION REGRE; CLARKE KC, 1994, PHOTOGRAMM ENG REM S, V60, P1355; Clarke KC, 1997, ENVIRON PLANN B, V24, P247, DOI 10.1068/b240247; Clarke KC, 1998, INT J GEOGR INF SCI, V12, P699; COUCLELIS H, 1985, ENVIRON PLANN A, V17, P585, DOI 10.1068/a170585; Couclelis H, 1997, ENVIRON PLANN B, V24, P165, DOI 10.1068/b240165; COUCLELIS H, 1988, ENVIRON PLANN A, V20, P99, DOI 10.1068/a200099; DeFries RS, 2000, REMOTE SENS ENVIRON, V74, P503, DOI 10.1016/S0034-4257(00)00142-5; Friedl MA, 1999, IEEE T GEOSCI REMOTE, V37, P969, DOI 10.1109/36.752215; GARDNER M, 1971, SCI AM, V224, P112; GOODCHILD MF, 1986, SPATIAL AUTOCORRELAT, P47; Haruno M, 1999, MACH LEARN, V34, P131, DOI 10.1023/A:1007597902467; Huang XQ, 1997, PHOTOGRAMM ENG REM S, V63, P1185; Li X, 2000, INT J GEOGR INF SCI, V14, P131, DOI 10.1080/136588100240886; Li X, 2001, ENVIRON PLANN A, V33, P1445, DOI 10.1068/a33210; Li X, 1998, INT J REMOTE SENS, V19, P1501, DOI 10.1080/014311698215315; Li X, 2002, INT J GEOGR INF SCI, V16, P323, DOI 10.1080/13658810210137004; Moran CJ, 2002, INT J GEOGR INF SCI, V16, P533, DOI 10.1080/13658810210138715; Ward D. P., 2000, Computers, Environment and Urban Systems, V24, DOI 10.1016/S0198-9715(00)00008-9; Portugali J., 2000, SELF ORG CITY; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; ROMANIUK SG, 1993, TRH393 NAT U SING DE; Eklund PW, 1998, INT J GEOGR INF SCI, V12, P247, DOI 10.1080/136588198241888; Tobler W. R., 1979, PHILOS GEOGRAPHY, P379; Webster CJ, 1999, ENVIRON PLANN A, V31, P1433, DOI 10.1068/a311433; White R, 1997, ENVIRON PLANN B, V24, P323, DOI 10.1068/b240323; WHITE R, 1993, ENVIRON PLANN A, V25, P1175, DOI 10.1068/a251175; WOLFRAM S, 1984, NATURE, V311, P419, DOI 10.1038/311419a0; Wu F, 1998, ENVIRON PLANN B, V25, P103, DOI 10.1068/b250103; Wu FL, 2002, INT J GEOGR INF SCI, V16, P795, DOI 10.1080/13658810210157769; Yeh AGO, 2002, ENVIRON PLANN B, V29, P431, DOI 10.1068/b1288; Yeh AGO, 1998, INT J GEOGR INF SCI, V12, P169; Yeh AGO, 2001, PHOTOGRAMM ENG REM S, V67, P83; Yeh AGO, 2001, ENVIRON PLANN B, V28, P733, DOI 10.1068/b2740	42	43	69	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	DEC	2004	18	8					723	744		10.1080/13658810410001705325		22	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	873QT	WOS:000225296700001	
S	Torra, V		DomingoFerrer, J; Torra, V		Torra, V			Microaggregation for categorical variables: A median based approach	PRIVACY IN STATISTICAL DATABASES, PROCEEDINGS	ANNALS OF THE NEW YORK ACADEMY OF SCIENCES		English	Article; Proceedings Paper	Conference on Privacy in Statistical DataBases (PSD 2004)	JUN 09-11, 2004	Barcelona, SPAIN			privacy preserving data mining; data protection; masking methods; clustering; microaggregation; categorical data	AGGREGATION OPERATORS; LINGUISTIC LABELS; INFORMATION; SEMANTICS; ALGORITHM	Microaggregation is a masking procedure used for protecting confidential data prior to their public release. This technique, that relies on clustering and aggregation techniques, is solely used for numerical data. In this work we introduce a microaggregation procedure for categorical variables. We describe the new masking method and we analyse the results it obtains according to some indices found in the literature. The method is compared with Top and Bottom Coding, Global recoding, Rank Swapping and PRAM.	Inst Invest Intelligencia Artificial, Bellaterra 08193, Catalonia, Spain	Torra, V (reprint author), Inst Invest Intelligencia Artificial, Campus Bellaterra, Bellaterra 08193, Catalonia, Spain.	vtorra@iiia.csic.es; vtorra@iiia.csic.es					AGRAWAL R, P 2000 ACM SIGMOD IN, P439; Chiang JH, 2003, IEEE T FUZZY SYST, V11, P518, DOI 10.1109/TFUZZ.2003.814839; Doming-Ferrer J., 2001, CONFIDENTIALITY DISC, P111; Domingo-Ferrer J, 2003, INT J INTELL SYST, V18, P633, DOI 10.1002/int.10107; Doyle P., 2001, CONFIDENTIALITY DISC; Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902; Felso F, 2001, CONFIDENTIALITY DISC, P17; Godo L, 2000, IEEE T FUZZY SYST, V8, P143, DOI 10.1109/91.842149; HERRERA F, 1995, INFORM SCIENCES, V85, P223, DOI 10.1016/0020-0255(95)00025-K; Huang ZX, 1999, IEEE T FUZZY SYST, V7, P446; INKLER WE, 1995, BUSINESS SURVEY METH, P355; Kolen JF, 2002, IEEE T FUZZY SYST, V10, P263, DOI 10.1109/91.995126; KOOIMAN P, 1998, PRAM METHOD DISCLOSU; Leski JM, 2003, IEEE T FUZZY SYST, V11, P709, DOI 10.1109/TFUZZ.2003.819844; MIYAMOTO S, 2000, SOFT COMPUTING HUMAN, P85; Miyamoto S., 1999, INTRO FUZZY CLUSTERI; Sande G, 2002, INT J UNCERTAIN FUZZ, V10, P459, DOI 10.1142/S0218488502001582; Sugeno M, 1974, THESIS TOKYO I TECHN; Torra V, 2001, INT J INTELL SYST, V16, P513, DOI 10.1002/int.1021; Torra V, 1997, INT J INTELL SYST, V12, P153, DOI 10.1002/(SICI)1098-111X(199702)12:2<153::AID-INT3>3.0.CO;2-P; Torra V., 2001, CONFIDENTIALITY DISC, P91; Torra V, 1996, INT J INTELL SYST, V11, P975, DOI 10.1002/(SICI)1098-111X(199611)11:11<975::AID-INT5>3.0.CO;2-W; Willenborg L, 2001, LECT NOTES STAT; WILLENBORG L, 1996, SPRINGER LNS, V111; Xu ZS, 2003, INT J INTELL SYST, V18, P953, DOI 10.1002/int.10127; Yancey W. E., 2002, LECT NOTES COMPUTER, V2316, P135	26	43	44	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0077-8923	3-540-22118-2	ANN NY ACAD SCI	Ann.NY Acad.Sci.		2004	3050						162	174				13	Computer Science, Theory & Methods; Statistics & Probability	Computer Science; Mathematics	BAG23	WOS:000222059700013	
J	Pedrycz, W; Bargiela, A				Pedrycz, W; Bargiela, A			Granular clustering: A granular signature of data	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						complex systems; confidence limits analysis; data mining; feature analysis; granular time series; hyperboxes; information abstraction; information granules and granulation; interval analysis; principle of balanced information granularity	FUZZY-LOGIC; CLASSIFICATION	The study is devoted to a granular analysis of data. We develop a new clustering algorithm that organizes findings about data in the form of a collection of information granules-hyperboxes. The clustering carried out here is an example of a granulation mechanism. We discuss a compatibility measure guiding a construction (growth) of the clusters and explain a rationale behind their development. The clustering promotes a data mining way of problem solving by emphasizing the transparency of the results (hyperboxes). We discuss a number of indexes describing hyperboxes and expressing relationships between such information granules. It is also shown how the resulting family of the information granules is a concise descriptor of the structure of the data-a granular signature of the data. We examine the properties of features (variables) occurring of the problem as they manifest in the setting of the information granules. Numerical experiments are carried out based on two-dimensional (2-D) synthetic data as well as multivariable Boston data available on the WWW.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada; Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; Nottingham Trent Univ, Dept Comp, Nottingham NG1 4BU, England	Pedrycz, W (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.						Anderberg M.R., 1973, CLUSTER ANAL APPL; BARGIELA A, UNPUB IEEE T SYST B; Bargiela A., 2001, GRANULAR COMPUTING, P23; Bezdek J., 1981, PATTERN RECOGNITION; Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747; HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2; Kandel A., 1986, FUZZY MATH TECHNIQUE; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen Teuvo, 1995, SELF ORG MAPS; Pedrycz W, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P69, DOI 10.1109/NAFIPS.2000.877387; Pedrycz W., 1998, INTRO FUZZY SETS; Pedrycz W, 2001, FUZZY SET SYST, V119, P329, DOI 10.1016/S0165-0114(99)00135-9; Pedrycz W., 1997, COMPUTATIONAL INTELL; Simpson P. K., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390282; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; Zadeh L.A., 1979, ADV FUZZY SET THEORY, P3	18	43	44	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2002	32	2					212	224		10.1109/3477.990878		13	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	532DE	WOS:000174455700009	
J	Blower, P; Fligner, M; Verducci, J; Bjoraker, J				Blower, P; Fligner, M; Verducci, J; Bjoraker, J			On combining recursive partitioning and simulated annealing to detect groups of biologically active compounds	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							DESCRIPTORS; SETS	Statistical data mining methods have proven to be powerful tools for investigating correlations between molecular structure and biological activity. Recursive partitioning (RP), in particular, offers several advantages in mining large, diverse data sets resulting from high throughput screening. When used with binary molecular descriptors, the standard implementation of RP splits on single descriptors. We use simulated annealing (SA) to find combinations of molecular descriptors whose simultaneous presence best separates off the most active, chemically similar group of compounds. The search is incorporated into a recursive partitioning design to produce a regression tree for biological activity on the space of structural fingerprints. Each node is characterized by a specific combination of structural features, and the terminal nodes with high average activities correspond, roughly, to different classes of compounds. Using LeadScope structural features as descriptors to mine a database from the National Cancer Institute, the merging of RP and SA consistently identifies structurally homogeneous classes of highly potent anticancer agents.	Leadscope Inc, Columbus, OH 43212 USA; Ohio State Univ, Dept Stat, Columbus, OH 43210 USA	Blower, P (reprint author), Leadscope Inc, 1245 Kinnear Rd, Columbus, OH 43212 USA.						BOYD MR, 1995, DRUG DEVELOP RES, V34, P91, DOI 10.1002/ddr.430340203; Breiman L, 1984, CLASSIFICATION REGRE; Chen X, 1998, J CHEM INF COMP SCI, V38, P1054, DOI 10.1021/ci980089g; Chen X, 1999, J CHEM INF COMP SCI, V39, P887, DOI 10.1021/ci990327n; Cho SJ, 2000, J CHEM INF COMP SCI, V40, P668, DOI 10.1021/ci9908190; Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585892; FOYE WE, 1993, CANC CHEMOTHERAPEUTI; GOBBI A, 1997, 1 INT EL C SYNTH ORG; Hawkins D. M., 1982, TOPICS APPL MULTIVAR, P269; Hawkins DM, 1997, QUANT STRUCT-ACT REL, V16, P296, DOI 10.1002/qsar.19970160404; HOLLAND JH, 1975, ADAPTATION NATURAL A; Izrailev S, 2001, J CHEM INF COMP SCI, V41, P176, DOI 10.1021/ci000036s; Jones-Hertzog DK, 1999, J PHARMACOL TOXICOL, V42, P207, DOI 10.1016/S1056-8719(00)00073-3; Kearsley SK, 1996, J CHEM INF COMP SCI, V36, P118, DOI 10.1021/ci950274j; Kirkpatrick S., 1983, SCIENCE, V220, P67; LU MC, 1993, CANC CHEMOTHERAPEUTI, P345; Miller DW, 2001, J CHEM INF COMP SCI, V41, P168, DOI 10.1021/ci0000348; Roberts G, 2000, J CHEM INF COMP SCI, V40, P1302, DOI 10.1021/ci0000631; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Zheng WF, 1999, J CHEM INF COMP SCI, V39, P738, DOI 10.1021/ci980103p	20	43	43	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	MAR-APR	2002	42	2					393	404		10.1021/ci0101049		12	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	537AF	WOS:000174733500030	
J	Kim, KS; Han, I				Kim, KS; Han, I			The cluster-indexing method for case-based reasoning using self-organizing maps and learning vector quantization for bond rating cases	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						hybrid model; case-based reasoning; cluster-indexing method; self-organizing maps; learning vector quantization; bond rating	NEURAL NETWORKS; ALGORITHM	This paper presents a hybrid data mining model for the prediction of corporate bond rating. This model uses a new case-indexing method of case-based reasoning (CBR), which utilizes the cluster information of financial data in order to improve classification accuracy, This method uses not only case-specific knowledge of past problems like conventional CBR, but also uses additional knowledge derived from the clusters of cases. The cluster-indexing method assumes that there are some distinct subgroups (clusters) in each rated group. Competitive artificial neural networks are used to generate the centroid values of clusters because these techniques produce better adaptive clusters than statistical clustering algorithms. The experiments using corporate bond rating cases show that the cluster-indexing CBR is superior to conventional CBR and inductive learning-indexing CBR-a rival case indexing method. (C) 2001 Published by Elsevier Science Ltd.	Korea Adv Inst Sci & Technol, Grad Sch Management, Seoul 130012, South Korea	Kim, KS (reprint author), Korea Adv Inst Sci & Technol, Grad Sch Management, 207-43 Cheongryangri Dong, Seoul 130012, South Korea.		Han, Ingoo/C-2031-2011				Alam P, 2000, EXPERT SYST APPL, V18, P185, DOI 10.1016/S0957-4174(99)00061-5; Anderberg M.R., 1973, CLUSTER ANAL APPL; Back B., 1998, ACCOUNTING MANAGEMEN, V8, P191, DOI 10.1016/S0959-8022(98)00009-5; Barletta R., 1991, AI Expert, V6; Brown C. E., 1994, International Journal of Intelligent Systems in Accounting, Finance and Management, V3; Bryant S. M., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199709)6:3<195::AID-ISAF132>3.0.CO;2-F; Buta P., 1994, AI Expert, V9; Chen Y. P., 1995, VIS COGN, V2, P235, DOI 10.1080/13506289508401733; Dutta S., 1988, P IEEE INT C NEURAL, V2, P443; Ha SH, 1998, EXPERT SYST APPL, V15, P1; KIM BO, 1995, EXPERT SYST APPL, V9, P63, DOI 10.1016/0957-4174(94)00049-2; KIM JW, 1993, EXPERT SYST, V10, P167, DOI 10.1111/j.1468-0394.1993.tb00093.x; KIM K, 1997, P KOR EXP SYST SOC C, P231; KIVILUOTO K, 1998, NEUROCOMPUTING, V21, P203; KOHONEN T, 1989, SELF ORG MAP; Kolodner J. L., 1993, CASE BASED REASONING; Kwon Y. S., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<23::AID-ISAF113>3.3.CO;2-W; Lee JK, 1996, DECIS SUPPORT SYST, V18, P1, DOI 10.1016/0167-9236(96)00013-9; Mangiameli P, 1996, EUR J OPER RES, V93, P402, DOI 10.1016/0377-2217(96)00038-0; MILLIGAN GW, 1980, PSYCHOMETRIKA, V45, P325, DOI 10.1007/BF02293907; Nour MA, 1996, EUR J OPER RES, V93, P428, DOI 10.1016/0377-2217(96)00033-1; Petersohn H, 1998, INT J UNCERTAIN FUZZ, V6, P139, DOI 10.1142/S0218488598000124; SerranoCinca C, 1996, DECIS SUPPORT SYST, V17, P227, DOI 10.1016/0167-9236(95)00033-X; SHAW M, 1990, IEEE EXPERT, P47; Shin KS, 1999, EXPERT SYST APPL, V16, P85, DOI 10.1016/S0957-4174(98)00063-3; SHIN KS, 1997, P MS OR SOC C SEOUL, P199; Vellido A, 1999, EXPERT SYST APPL, V17, P303, DOI 10.1016/S0957-4174(99)00042-1; WILSON RL, 1994, DECIS SUPPORT SYST, V11, P545, DOI 10.1016/0167-9236(94)90024-8; Yuan ST, 2001, EXPERT SYST APPL, V20, P187, DOI 10.1016/S0957-4174(00)00058-0	29	43	45	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	OCT	2001	21	3					147	156		10.1016/S0957-4174(01)00036-7		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	488LW	WOS:000171937500004	
J	Berzal, F; Cubero, JC; Marin, N; Serrano, JM				Berzal, F; Cubero, JC; Marin, N; Serrano, JM			TBAR: An efficient method for association rule mining in relational databases	DATA & KNOWLEDGE ENGINEERING			English	Article						data mining; association rules; relational databases		In this paper, we propose a new algorithm for efficient association rule mining, which we apply in order to discover interesting patterns in relational databases. Our algorithm, which is called Tree-Based Association Rule mining (TBAR), redefines the notion of item and employs an effective tree data structure. It can also use techniques such as Direct Hashing and Pruning (DHP). Experiments with real-life datasets show that TEAR outperforms Apriori, a well-known and widely used algorithm. (C) 2001 Elsevier Science B.V. All rights reserved.	Univ Granada, Dept Ciencias Comp & Intelligencia Artifical, Granada 18071, Spain	Berzal, F (reprint author), Univ Granada, Dept Ciencias Comp & Intelligencia Artifical, Ave Andalucia 38, Granada 18071, Spain.	fberzal@decsai.ugr.es; jc.cubero@decsai.ugr.es; nicm@decsai.ugr.es; jmserrano@decsai.ugr.es	Cubero, Juan-Carlos/C-2413-2012; Berzal, Fernando/C-6078-2012; Serrano, Jose/K-2734-2012				Aggarwal C. C., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275490; AGGARWAL CC, 1998, B IEEE COMP SOC TECH; AGRAWAL R, 1996, P 2 INT C KNOWL DISC, P287; Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; AGRAWAL R, 1994, RJ9839 IBM ALM RES C; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Ali K., 1997, KDD 97 P 3 INT C KNO, P115; Bayardo R.J., 1998, SIGMOD, P85; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Cheung D., 1996, P 2 INT C KNOWL DISC, P307; Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094; FELDMAN R, 1997, KDD TECHNIQUES APPL, P227; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HAN JL, 1996, P CIKM 96 NOV, P73, DOI 10.1145/238355.238440; Hipp J., 2000, SIGKDD EXPLORATIONS, V2, P58; HOUTSMA M, 1993, RJ9567 IBM ALM RES C; MANNILA H, 1994, IMPROVED METHODS FIN; PARK SS, 1995, MATER LETT, V22, P175, DOI 10.1016/0167-577X(94)00241-X; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sarawagi S., 1998, SIGMOD, P343; SKIRANT R, 1997, KDD 97 P 3 INT C KNO, P67; SKIRANT R, 1996, P 1996 ACM SIGMOD IN, P1	22	43	55	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	APR	2001	37	1					47	64		10.1016/S0169-023X(00)00055-0		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	415BU	WOS:000167701300003	
J	Adomavicius, G; Tuzhilin, A				Adomavicius, G; Tuzhilin, A			Expert-driven validation of rule-based user models in personalization applications	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						personalization; profiling; rule discovery; post-analysis; validation	KNOWLEDGE DISCOVERY; ASSOCIATION RULES	In many e-commerce applications, ranging from dynamic Web content presentation, to personalized ad targeting, to individual recommendations to the customers, it is important to build personalized profiles of individual users from their transactional histories. These profiles constitute models of individual user behavior and can be specified with sets of rules learned from user transactional histories using various data mining techniques. Since many discovered rules can be spurious, irrelevant, or trivial, one of the main problems is how to perform post-analysis of the discovered rules, i.e., how to validate user profiles by separating "good" rules from the "bad." This validation process should be done with an explicit participation of the human expert. However, complications may arise because there can be very large numbers of rules discovered in the applications that deal with many users, and the expert cannot perform the validation on a rule-by-rule basis in a reasonable period of time. This paper presents a framework for building behavioral profiles of individual users. It also introduces a new approach to expert-driven validation of a very large number of rules pertaining to these users. In particular, it presents several types of validation operators, including rule grouping, filtering, browsing, and redundant rule elimination operators, that allow a human expert validate many individual rules at a time. By iteratively applying such operators, the human expert can validate a significant part of all the initially discovered rules in an acceptable time period. These validation operators were implemented as a part of a one-to-one profiling system. The paper also presents a case study of using this system for validating individual user rules discovered in a marketing application.	NYU, Courant Inst Math Sci, Dept Comp Sci, New York, NY 10012 USA; NYU, Stern Sch Business, Dept Informat Syst, New York, NY 10012 USA	Adomavicius, G (reprint author), NYU, Courant Inst Math Sci, Dept Comp Sci, 251 Mercer St, New York, NY 10012 USA.						ADOMAVICIUS G, 1999, P 5 ACM SIGKDD INT C; ADOMAVICIUS G, 1997, P 3 INT C KNOWL DISC; AGGARWAL C, 1998, P 4 INT C KNOWL DISC; AGGARWAL CC, 1998, P 14 INT C DAT ENG; AGRAWAL R, 1996, ADV KNOWLEDGE DISCOV, pCH12; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Allen C., 1998, INTERNET WORLD GUIDE; BAUDISCH P, 1999, CHI 99 WORKSH INT RE; Bayardo R. J., 1999, P 5 ACM SIGKDD INT C; BAYARDO RJ, 1999, P 15 INT C DAT ENG; BRACHMAN RJ, 1996, ADV KNOWLEDGE DISCOV, pCH2; Breiman L, 1984, CLASSIFICATION REGRE; BRIN S, 1997, P ACM SIGMOD C; BRUNK C, 1997, P 3 INT C KNOWL DISC; CHAN PK, 1999, WORKSH WEB US AN US; Cheung DW, 1996, P 1996 INT C DAT ENG; Clearwater SH, 1990, P 2 INT IEEE C TOOLS; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; FAWCETT T, 1996, P 2 INT C KNOWL DISC; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FAYYAD UM, 1996, ADV KNOWLEDGE DISCOV, pCH1; FELDMAN R, 1997, P WORKSH RES ISS DAT; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; GOETHALS B, 1999, P 1999 ACM SIGMOD WO; Hagel J., 1999, NET WORTH SHAPING MA; HAGEL J, 1999, COMMUNICATION   1116; HAN J, 1996, P SIGMOD WORKSH RES; Imielinski T, 1999, DATA MIN KNOWL DISC, V3, P373, DOI 10.1023/A:1009816913055; KAUTZ H, 1998, 1988 WORKSHOP TECH R; KLEMETTINEN M, 1994, P 3 INT C INF KNOWL; Lee Y, 1998, MACH LEARN, V30, P217, DOI 10.1023/A:1007404308006; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Liu B., 1999, P 5 ACM SIGKDD INT C; LIU B, 1997, P 3 INT C KNOWL DISC; Liu B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P828; Meo R, 1998, DATA MIN KNOWL DISC, V2, P195, DOI 10.1023/A:1009774406717; Morimoto Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; MORISHITA S, 1998, P 1 INT C DISC SCI; PADMANABHAN B, 1998, P 4 INT C KNOWL DISC; Padmanabhan B, 1999, DECIS SUPPORT SYST, V27, P303, DOI 10.1016/S0167-9236(99)00053-6; PEPPERS D, 1993, ONE ONE FUTURE; PIATETSKYSHAPIR.G, 1994, P AAAI 94 WORKSH KNO; PROVOST F, 1998, TUTORIAL 4 INT C KNO; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SAHAR S, 1999, P 5 ACM SIGKDD INT C; SHEN WM, 1996, ADV KNOWLEDGE DISCOV, pCH15; SILBERSCHATZ A, 1996, P SIGMOD WORKSH RES; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; SOBOROFF I, 1999, ACM SIGIR 99 WORKSH; Srikant R., 1996, THESIS U WISCONSIN M; Srikant R., 1995, P 21 INT C VER LARG; SRIKANT R, 1997, P 3 INT C KNOWL DISC; STEDMAN C, 1997, COMPUTERWORLD, V31; SUZUKI E, 1997, P 3 INT C KNOWL DISC; THOMAS S, 1997, P 3 INT C KNOWL DISC; TOIVONEN H, 1995, ECML 95 WORKSH STAT; TUZHILIN A, 1996, IS9626 NEW YORK U ST; TUZHILIN A, 1999, CHI 99 WORKSH INT RE; WANG K, 1998, P 4 INT C KNOWL DISC; *CACM, 1997, COMMUN ACM, V40, P56; 1999, PERS SUMM SAN FRANC	61	43	49	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JAN-APR	2001	5	1-2					33	58		10.1023/A:1009839827683		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	406WV	WOS:000167239900003	
J	Kewley, RH; Embrechts, MJ; Breneman, C				Kewley, RH; Embrechts, MJ; Breneman, C			Data strip mining for the virtual design of pharmaceuticals with neural networks	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						computational chemistry; data mining; pharmaceuticals		A novel neural network based technique, called "data strip mining" extracts predictive models from data sets which have a large number of potential inputs and comparatively few data points. This methodology uses neural network sensitivity analysis to determine which predictors are most significant in the problem. Neural network sensitivity analysis holds all but one input to a trained neural network constant while varying each input over its entire range to determine its effect on the output. The least sensitive variables are iteratively removed from the input set. For each iteration, model cross-validation uses multiple splits of training and validation data to determine an estimate of the model's ability to predict the output for data points not used during training, Elimination of variables through neural network sensitivity analysis and predicting performance through model cross-validation allows the analyst to reduce the number of inputs and improve the model's predictive ability at the same time. This paper illustrates this technique using a cartoon problem from classical physics. It then demonstrates its effectiveness on a pair of challenging problems from combinatorial chemistry with over 400 potential inputs each. For these data sets, model selection by neural sensitivity analysis outperformed other variable selection methods including forward selection and a genetic algorithm.	US Mil Acad, Dept Syst Engn, W Point, NY 10996 USA; Rensselaer Polytech Inst, Dept Decis Sci & Engn Syst, Troy, NY 12181 USA; Rensselaer Polytech Inst, Dept Chem, Troy, NY 12181 USA	Kewley, RH (reprint author), US Mil Acad, Dept Syst Engn, W Point, NY 10996 USA.						BERRY MJA, 1994, DATA MINING TECHNIQU; Bigus J. P., 1996, DATA MINING NEURAL N; Bishop CM, 1995, NEURAL NETWORKS PATT; BRENEMAN CM, 1995, COMPUT CHEM, V19, P161, DOI 10.1016/0097-8485(94)00052-G; HAYKIN S, 1994, NERUAL NETWORKS COMP; Hines W.W., 1980, PROBABILITY STAT ENG; Jang J.S.R., 1997, NEUROFUZZY SOFT COMP; JOHNSON RA, 1992, APPL MULTIVARIATE AN; KEWLEY R, INTELLIGENT ENG SYST, V8, P391; Montgomery D. C., 1997, DESIGN ANAL EXPT; Neter J., 1996, APPL LINEAR REGRESSI; STONE M, 1974, J R STAT SOC B, V36, P111; 1999, PARTEK PRO 2000 ON L	13	43	43	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2000	11	3					668	679		10.1109/72.846738		12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	326JM	WOS:000087732100012	
J	Mitchell, TM				Mitchell, TM			Machine learning and data mining	COMMUNICATIONS OF THE ACM			English	Article									Carnegie Mellon Univ, Sch Comp Sci, Ctr Automated Learning & Discovery, Pittsburgh, PA 15213 USA	Mitchell, TM (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Ctr Automated Learning & Discovery, Pittsburgh, PA 15213 USA.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Chauvin Y., 1995, BACKPROPAGATION THEO; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Faloutsos C., 1995, ACM SIGMOD RECORD, V24, P163, DOI 10.1145/568271.223812; GRAY J, 1995, MSRTR9522 MICR T; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Mitchell T. M, 1997, MACHINE LEARNING; MUGGLETON S, 1995, FDN INDUCTIVE LOGIC; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN	9	43	44	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0001-0782		COMMUN ACM	Commun. ACM	NOV	1999	42	11					30	36		10.1145/319382.319388		7	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	252FQ	WOS:000083491800012	
J	Case, J; Jain, S; Lange, S; Zeugmann, T				Case, J; Jain, S; Lange, S; Zeugmann, T			Incremental concept learning for bounded data mining	INFORMATION AND COMPUTATION			English	Article							SYSTEMS; SET	Important refinements of concept learning in the limit from positive data considerably restricting the accessibility of input data are studied. Let c be any concept; every infinite sequence of elements exhausting c is called positive presentation of c. In all learning models considered the learning machine computes a sequence of hypotheses about the target concept from a positive presentation of it. With iterative learning, the learning machine, in making a conjecture, has access to its previous conjecture and the latest data items coming in. In k-bounded example-memory inference (k is a priori fixed) the learner is allowed to access, in making a conjecture, its previous hypothesis, its memory of up to k data items it has already seen, and the next element coming in. In the case of k-feedback identification, the learning machine, in making a conjecture, has access to its previous conjecture, the latest data item coming in, and, on the basis of this information, it can compute k items and query the database of previous data to find out, for each of the k items, whether or not it is in the database (k is again a priori fixed). In all cases, the sequence of conjectures has to converge to a hypothesis correctly describing the target concept. Our results are manyfold. An infinite hierarchy of more and more powerful feedback learners in dependence on the number k of queries allowed to be asked is established. However, the hierarchy collapses to 1-feedback inference if only indexed families of infinite concepts are considered, and moreover, its learning power is then equal to learning in the limit. But it remains infinite for concept classes of only infinite r.e. concepts. Both k-feedback inference and k-bounded example-memory identification are more powerful than iterative learning but incomparable to one another. Furthermore, there are cases where redundancy in the hypothesis space is shown to be a resource increasing the learning power of iterative learners. Finally, the union of at most k pattern languages is shown to be iteratively inferable. (C) 1999 Academic Press.	Kyushu Univ, Dept Informat, Katsuta, Ibaraki 8168580, Japan; Univ Delaware, Dept CIS, Newark, DE 19716 USA; Natl Univ Singapore, Dept ISCS, Singapore 119260, Singapore; Univ Leipzig, Fak Math & Informat, Inst Informat, D-04109 Leipzig, Germany	Zeugmann, T (reprint author), Kyushu Univ, Dept Informat, Katsuta, Ibaraki 8168580, Japan.						ANGLUIN D, 1980, J COMPUT SYST SCI, V21, P46, DOI 10.1016/0022-0000(80)90041-0; ARIKAWA S, 1992, THEOR COMPUT SCI, V95, P97, DOI 10.1016/0304-3975(92)90068-Q; ARIMURA H, 1994, P INF MOD KNOWL BAS, V5, P365; BLUM L, 1975, INFORM CONTR, V28, P122; BLUM M, 1967, J ACM, V14, P322, DOI 10.1145/321386.321395; Brachman R., 1996, ADV KNOWLEDGE DISCOV, P37; CASE J, 1994, J EXP THEOR ARTIF IN, V6, P3, DOI 10.1080/09528139408953778; CASE J, 1983, THEOR COMPUT SCI, V25, P193, DOI 10.1016/0304-3975(83)90061-0; CASE J, 1988, P 1 WORKSH COMP LEAR, P196; CASE J, 1996, LP9608 U AMST I LOG; Case J., 1974, Mathematical Systems Theory, V8, DOI 10.1007/BF01761704; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P471; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FILE G, 1988, P 5 ANN S THEOR ASP, V294, P184; FREIVALDS R, 1993, INFORM COMPUT, V107, P237, DOI 10.1006/inco.1993.1068; FULK M, 1994, J COMPUT SYST SCI, V49, P589, DOI 10.1016/S0022-0000(05)80072-8; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; JAIN S, 1994, LECT NOTES ARTIF INT, V872, P349; JAIN S, 1995, LECT NOTES ARTIF INT, V961, P108; JIANG T, 1993, LECTURE NOTES COMPUT, V700, P301; KLOESGEN W, 1995, J INTELL INF SYST, V4, P53; Lange S., 1993, International Journal of Foundations of Computer Science, V4, DOI 10.1142/S0129054193000110; Lange S, 1996, MATH SYST THEORY, V29, P599, DOI 10.1007/BF01301967; Lange S, 1996, J COMPUT SYST SCI, V53, P88, DOI 10.1006/jcss.1996.0051; Lange S., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168320; Lange S., 1991, New Generation Computing, V8; Matheus C., 1996, ADV KNOWLEDGE DISCOV, P495; MEYER L, 1997, LECT NOTES ARTIF INT, V1208, P66; MEYER L, 1995, LECT NOTES ARTIF INT, V997, P169; NIX RP, 1983, 280 YALE U DEP COMP; OSHERSON DN, 1906, SYSTEMS LEARN INTRO; RAO MK, 1996, LECT NOTES ARTIF INT, V1160, P272; Rogers Jr H., 1967, THEORY RECURSIVE FUN; ROSSMANITH P, 1998, LECT NOTES ARTIF INT, V1433, P13; SALOMAA A, 1994, EATCS B, V55, P144; SALOMAA A, 1994, EATCS B, V54, P46; Shimozono S., 1994, Transactions of the Information Processing Society of Japan, V35; SHINOHARA T, 1996, LECT NOTES ARTIF INT, V1160, P256; SHINOHARA T, 1983, B INFORMATICS CYBERN, V20, P83; Shinohara T., 1991, New Generation Computing, V8; Shinohara T., 1995, LECT NOTES ARTIF INT, V961, P259; Smullyan R. M., 1961, ANN MATH STUDIES, V47; Ullman J. D., 1969, FORMAL LANGUAGES THE; WIEHAGEN R, 1994, J EXP THEOR ARTIF IN, V6, P131, DOI 10.1080/09528139408953785; Wiehagen R., 1976, J INFORMATION PROCES, V12, P93; Wright K., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory; Zeugmann T, 1998, ANN MATH ARTIF INTEL, V23, P117, DOI 10.1023/A:1018964207937; ZEUGMANN T, 1995, RIFISTRCS111 KYUSH U; Zeugmann T., 1993, LECTURE NOTES ARTIFI, V<IT>659</IT>, P254; ZEUGMANN T, 1995, INFORM COMPUT, V120, P155, DOI 10.1006/inco.1995.1107; Zeugmann T., 1995, LECT NOTES ARTIF INT, V961, P190	51	43	43	ACADEMIC PRESS INC	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0890-5401		INFORM COMPUT	Inf. Comput.	JUL 10	1999	152	1					74	110		10.1006/inco.1998.2784		37	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	218RR	WOS:000081565900005	
J	Melamed, ID				Melamed, ID			Bitext maps and alignment via pattern recognition	COMPUTATIONAL LINGUISTICS			English	Article								Texts that are available in two languages (bitexts) are becoming more and move plentiful, both in private data warehouses and on publicly accessible sites on the World Wide Web. As with other kinds of data, the value of bitexts largely depends on the efficacy of the available data mining tools. The first step in extracting useful information from bitexts is to find corresponding words and/or text segment boundaries in their two halves (bitext maps). This article advances the state of the ari of bitext mapping by formulating the problem in terms of pattern recognition. From this point Of view the success of a bitext mapping algorithm hinges on how well it performs three tasks: signal generation, noise filtering, and search. The Smooth Injective Map Recognizer (SIMR) algorithm presented here integrates innovative approaches to each of these tasks. Objective evaluation has shown that SIMR's accuracy is consistently high for language pairs as diverse as French/English and Korean/English. If necessary, SIMR's bitext maps can be efficiently converted into segment alignments using the Geometric Segment Alignment (GSA) algorithm, which is also presented here. SIMR has produced bitext maps for oz,er 200 megabytes of French-English bitexts. GSA has converted these maps into alignments. Both the maps and the alignments are available from the Linguistic Data Consortium.(1)	West Grp, Eagan, MN 55123 USA	Melamed, ID (reprint author), West Grp, 610 Opperman Dr,D1-66F, Eagan, MN 55123 USA.						Bellman R, 1957, DYNAMIC PROGRAMMING; Brown P. F., 1993, Computational Linguistics, V19; Brown P.F., 1991, P 29 ANN M ASS COMP, P169, DOI 10.3115/981344.981366; CATIZONE R, 1993, P 1 INT LEX ACQ WORK; CHEN S, 1996, THESIS HARVARD U CAM; CHURCH KW, 1993, P 31 ANN M ASS COMP, P1, DOI 10.3115/981574.981575; CHURCH KW, 1993, P PACFCOL 93 TAIP TA; COUSIN PH, 1991, COLLINS PAPERBACK FR; Dagan I., 1993, P WORKSH VER LARG CO, P1; DEBILI F, 1992, P 14 INT C COMP LING, P517; Dempster A., 1977, J R STAT SOC B, V34, P1; Fung P., 1995, P 33 ANN M BOST MA A, P236, DOI 10.3115/981658.981690; Fung P., 1994, P 1 C ASS MACH TRANS, P81; FUNG P, 1994, P 15 INT C COMP LING, P1096; GALE W. A., 1991, P 29 ANN M ASS COMP, P177, DOI 10.3115/981344.981367; Gale WA, 1991, P 4 DARPA SPEECH NAT, P152, DOI 10.3115/112405.112428; HARRIS B, 1988, LANGUAGE MONTHLY, V54, P8; HUNT JW, 1977, COMMUN ACM, V20, P350, DOI 10.1145/359581.359603; ISABELLE P, 1992, P 8 ANN C UW CTR NEW, P1; Kay M., 1993, Computational Linguistics, V19; Knight K, 1997, P 35 ANN M ASS COMP, P128; MACKLOVITCH E, 1996, META, V41; MCENERY T, 1995, P TEXTS TAGS ISS MUL, P77; MELAMED ID, 1996, 9626 U PENNS I RES C; MELAMED ID, 1996, P 16 INT C COMP LING, P764; Melamed I.D., 1997, P 35 ANN M ASS COMP, P305; MELAMED ID, 1996, P 2 C ASS MACH TRANS, P125; MELAMED ID, 1998, THESIS U PENNSYLVANI; MELAMED ID, 1998, 9805 U PENNS I RES C; NERBONNE J, 1997, P 5 ACL C APPL NAT L, P135, DOI 10.3115/974557.974577; PAPAGEORGIOU H, 1994, P 32 ANN M STUD SESS, P334, DOI 10.3115/981732.981784; RENE VV, 1993, APPL SIMULATED ANNEA; RESNIK P, 1997, P 5 C APPL NAT LANG, P340, DOI 10.3115/974557.974607; SIMARD M, 1996, P C ASS MACH TRANSL, P135; Simard M., 1992, P 4 INT C THEOR METH, P67; Wu D., 1994, P 32 ANN M ASS COMP, P80, DOI 10.3115/981732.981744	36	43	43	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	0891-2017		COMPUT LINGUIST	Comput. Linguist.	MAR	1999	25	1					107	130				24	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Computer Science; Linguistics	188AT	WOS:000079822200003	
J	Takeuchi, J; Yamanishi, K				Takeuchi, J; Yamanishi, K			A unifying framework for detecting outliers and change points from time series	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						time series; change point; data mining; network security; AR model		We are concerned with the issue of detecting outliers and change points from time series. In the area of data mining, there have been increased interest in these issues since outlier detection is related to fraud detection, rare event discovery, etc., while change-point detection is related to event/trend change detection, activity monitoring, etc. Although, in most previous work, outlier detection and change point detection have not been related explicitly, this paper presents a unifying framework for dealing with both of them. In this framework, a probabilistic model of time series is incrementally learned using an online discounting learning algorithm, which can track a drifting data source adaptively by forgetting out-of-date statistics gradually. A score for any given data is calculated in terms of its deviation from the learned model, with a higher score indicating a high possibility of being an outlier. By taking an average of the scores over a window of a fixed length and sliding the window, we may obtain a new time series consisting of moving-averaged scores. Change point detection is then reduced to the issue of detecting outliers in that time series. We compare the performance of our framework with those of conventional methods to demonstrate its validity through simulation and experimental applications to incidents detection in network security.	NEC Corp Ltd, Internet Syst Res Labs, Nakahara Ku, Kawasaki, Kanagawa 2118666, Japan	Takeuchi, J (reprint author), NEC Corp Ltd, Internet Syst Res Labs, Nakahara Ku, 1753 Shimonumabe, Kawasaki, Kanagawa 2118666, Japan.	tak@ap.jp.nec.com; k-yamanishi@cw.jp.nec.com					AKAIKE H, 1994, PRACTICES TIME SERIE, V1; AKAIKE H, 1995, PRACTICES TIME SERIE, V2; Barnett V., 1994, OUTLIERS STAT DATA; Cover T. M., 1991, ELEMENTS INFORM THEO; Fawcett T., 1999, P 5 ACM SIGKDD INT C, P53, DOI 10.1145/312129.312195; Guralnik V, 1999, P 5 ACM SIGKDD INT C, P33, DOI 10.1145/312129.312190; GUTHERY SB, 1974, J AM STAT ASSOC, V69, P945, DOI 10.2307/2286168; Hawkins D. M., 1976, Applied Statistics, V25, DOI 10.2307/2346519; HUSKOVA M, 1993, APPL CHANGE POINT PR; Kitagawa G., 1996, LECT NOTES STAT, V116; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Murad U, 1999, LECT NOTES ARTIF INT, V1704, P251; NEAL RM, VIEW EM ALGORITHM JU; OZAKI T, 1995, METHOD TIME SERIES A; P Burge, 1997, P AI APPR FRAUD DET, P9; RISSANEN J, 1996, IEEE T INFORM THEORY, V42, P407; YAMAGUCHI S, 1994, FREE RADICAL BIO MED, V17, P389, DOI 10.1016/0891-5849(94)90165-1; Yamanishi K., 2002, P 8 ACM SIGKDD INT C; Yamanishi K, 2004, DATA MIN KNOWL DISC, V8, P275, DOI 10.1023/B:DAMI.0000023676.72185.7c; YI BK, 2000, P 16 INT C DAT ENG	20	42	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2006	18	4					482	492		10.1109/TKDE.2006.1599387		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	012WO	WOS:000235371800005	
J	Aggarwal, CC; Yu, PS				Aggarwal, CC; Yu, PS			An effective and efficient algorithm for high-dimensional outlier detection	VLDB JOURNAL			English	Article						data mining; high-dimensional spaces; outlier detection		The outlier detection problem has important applications in the field of fraud detection, network robustness analysis, and intrusion detection. Most such applications are most important for high-dimensional domains in which the data can contain hundreds of dimensions. Many recent algorithms have been proposed for outlier detection that use several concepts of proximity in order to find the outliers based on their relationship to the other points in the data. However, in high-dimensional space, the data are sparse and concepts using the notion of proximity fail to retain their effectiveness. In fact, the sparsity of high-dimensional data can be understood in a different way so as to imply that every point is an equally good outlier from the perspective of distance-based definitions. Consequently, for high-dimensional data, the notion of finding meaningful outliers becomes substantially more complex and nonobvious. In this paper, we discuss new techniques for outlier detection that find the outliers by studying the behavior of projections from the data set.	IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Aggarwal, CC (reprint author), IBM TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.		Yu, Philip/A-2815-2012				Aggarwal C., 1999, P 1999 ACM SIGMOD IN, P61, DOI 10.1145/304182.304188; Aggarwal C. C., 2000, P ACM SIGMOD INT C M, P70, DOI 10.1145/342009.335383; Aggarwal CC, 2001, SIGMOD RECORD, V30, P13; Aggarwal CC, 1997, OPER RES, V45, P226, DOI 10.1287/opre.45.2.226; Aggarwal C.C., 2001, P 8 INT C DAT THEOR, P420; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Arning A., 1996, P 2 INT C KNOWL DISC, P164; Beyer K., 1999, P 7 INT C DAT THEOR, P217; Breuning M.M., 2000, P ACM SIGMOD INT C M, P93, DOI DOI 10.1145/342009.335388; Chakrabarti K., 2000, P 26 INT C VER LARG, P89; Darwin C., 1859, ORIGIN SPECIES NATUR; Dejong K. A., 1975, THESIS U MICHIGAN; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Hinneburg A., 2000, P 26 INT C VER LARG, P506; HOLLAND JH, 1975, ADAPTATION NATURAL A; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211; Parthasarathy S, 2003, IEEE T KNOWL DATA EN, V15, P1512, DOI 10.1109/TKDE.2003.1245289; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	24	42	52	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1066-8888		VLDB J	VLDB J.	APR	2005	14	2					211	221		10.1007/s00778-004-0125-5		11	Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	915GP	WOS:000228286400006	
J	Chou, SM; Lee, TS; Shao, YE; Chen, IF				Chou, SM; Lee, TS; Shao, YE; Chen, IF			Mining the breast cancer pattern using artificial neural networks and multivariate adaptive regression splines	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; breast cancer; classification; neural networks; multivariate adaptive regression splines	SCORING MODELS; CLASSIFICATION; PERSPECTIVE; STATISTICS; DIAGNOSIS; KNOWLEDGE; INDEX	Data mining is a very popular technique and has been widely applied in different areas these days. The artificial neural network has become a very popular alternative in prediction and classification tasks due to its associated memory characteristics and generalization capability. However. the relative importance of potential input variables and the long training process have often been criticized and hence limited its application in handling classification problems. The objective of the proposed study is to explore the performance of data classification by integrating artificial neural networks with the multivariate adaptive regression splines (MARS) approach. The rationale under the analyses is firstly to use MARS in modeling the classification problem, then the obtained significant variables are used as the input variables of the designed neural networks model. To demonstrate the inclusion of the obtained important variables from MARS would improve the classification accuracy of the networks, diagnostic tasks are performed on one fine needle aspiration cytology breast cancer data set. As the results reveal. the proposed integrated approach outperforms the results using discriminant analysis, artificial neural networks and multivariate adaptive regression splines and hence provides an efficient alternative in handling breast cancer diagnostic problems. (C) 2003 Elsevier Ltd. All rights reserved.	Fu Jen Catholic Univ, Grad Inst Management, Taipei 24205, Taiwan; Chang Jung Christian Univ, Dept Nursing, Tainan, Taiwan; Fu Jen Catholic Univ, Dept Stat & Informat Sci, Taipei, Taiwan	Lee, TS (reprint author), Fu Jen Catholic Univ, Grad Inst Management, 510 Chung Cheng Rd, Taipei 24205, Taiwan.	badm1004@mails.fju.edu.tw					Anderson J. A., 1988, NEUROCOMPUTING FDN R; Anderson T. W., 1984, INTRO MULTIVARIATE S; BENNUN LA, 1992, ORNITHOLOGY, V7, P1; Breiman L, 1984, CLASSIFICATION REGRE; Cabena P., 1998, DISCOVERING DATA MIN; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; Chiu CC, 2003, J INTELL MANUF, V14, P379, DOI 10.1023/A:1024657911399; Chung H. M., 1999, J MANAGE INFORM SYST, V16, P11; Craven M.W., 1997, FUTURE GENER COMP SY, V13, P221; Craven P, 1979, NUMER MATH, V31, P317; Curt H., 1995, INTELLIGENT SOFTWARE, P1; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Davies P.C., 1994, NEUROVEST, V5, P21; De Gooijer JG, 1998, J INT MONEY FINANC, V17, P513, DOI 10.1016/S0261-5606(98)00017-5; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; Dillon W.R., 1984, MULTIVARIATE ANAL ME; ELMORE JG, 1994, NEW ENGL J MED, V331, P1493, DOI 10.1056/NEJM199412013312206; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; FENTIMAN IS, 1998, DETECTION TREATMENT; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Friedman J H, 1995, Stat Methods Med Res, V4, P197, DOI 10.1177/096228029500400303; Griffin WL, 1997, J GEOCHEM EXPLOR, V59, P233, DOI 10.1016/S0375-6742(97)00015-0; Hand D. J., 1981, DISCRIMINATION CLASS; Harrell F.E., 1985, BIOSTATISTICS STAT B; Hastie T.J., 1990, GEN ADDITIVE MODELS; Haykin S., 1994, NEURAL NETWORKS COMP; Hecht-Nielsen R, 1990, NEUROCOMPUTING; Hornik K, 1989, NEURAL NETWORKS, V2, P336; Jensen H. L., 1992, MANAGE FINANC, V18, P15; Johnson RA, 2002, APPL MULTIVARIATE ST; Kang S. Y., 1991, THESIS KENT STATE U; Kovalerchuk B, 1997, ARTIF INTELL MED, V11, P75, DOI 10.1016/S0933-3657(97)00021-3; Kuhnert PM, 2000, COMPUT STAT DATA AN, V34, P371, DOI 10.1016/S0167-9473(99)00099-7; Lee G., 1999, J MANAGE INFORM SYST, V16, P63; Lee JH, 2001, KOREAN J GENETIC, V23, P3; Lee TS, 2002, INT J SYST SCI, V33, P229, DOI 10.1080/00207720110092216; Lee TS, 2002, EXPERT SYST APPL, V22, P225, DOI 10.1016/S0957-4174(01)00056-2; LEWIS PAW, 1991, J AM STAT ASSOC, V86, P864, DOI 10.2307/2290499; Lippmann R. P., 1987, IEEE ASSP MAGAZI APR, P4; MANGASARIAN L, 1990, LARGE SCALE NUMERICA, P2; Neter J, 1996, APPL LINEAR STAT MOD; Ngan PS, 1999, ARTIF INTELL MED, V16, P73; NguyenCong V, 1996, EUR J MED CHEM, V31, P797, DOI 10.1016/0223-5234(96)83973-0; Ohmann C, 1996, ARTIF INTELL MED, V8, P23, DOI 10.1016/0933-3657(95)00018-6; Pendharkar PC, 1999, EXPERT SYST APPL, V17, P223, DOI 10.1016/S0957-4174(99)00036-6; Piramuthu S, 1999, EUR J OPER RES, V112, P310, DOI 10.1016/S0377-2217(97)00398-6; Reichert A. K., 1983, J BUS ECON STAT, V1, P101, DOI 10.2307/1391851; REPLEY B, 1994, J ROYAL STAT SOC B, V56, P409; RUMELHART DE, 1996, LEARNING INTERNAL RE, P318; SANCHEZ MS, 1995, CHEMOMETR INTELL LAB, V28, P287, DOI 10.1016/0169-7439(94)00086-X; Sharma S, 1996, APPL MULTIVARIATE TE; Stern HS, 1996, TECHNOMETRICS, V38, P205, DOI 10.2307/1270601; Tang Z., 1993, ORSA Journal on Computing, V5; Vellido A, 1999, EXPERT SYST APPL, V17, P51, DOI 10.1016/S0957-4174(99)00016-0; West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5; WINGO PA, 1995, CA-CANCER J CLIN, V45, P8, DOI 10.3322/canjclin.45.1.8; Wong FS, 1992, NEUROCOMPUTING, V2, P147, DOI 10.1016/0925-2312(91)90045-D; Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7; [Anonymous], 2001, MARS 2 0 WIND 95 98; *SPSS IC, 1998, STAT MOD WIND 95 98; *VEST SERV, 1998, QNET 97 NEUR NETW MO	62	42	42	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2004	27	1					133	142		10.1016/j.eswa.2003.12.013		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	815HX	WOS:000221034500011	
J	Carvalho, DR; Freitas, AA				Carvalho, DR; Freitas, AA			A hybrid decision tree/genetic algorithm method for data mining	INFORMATION SCIENCES			English	Article						classification; genetic algorithms; decision trees; data mining; machine learning		This paper addresses the well-known classification task of data mining, where the objective is to predict the class which an example belongs to. Discovered knowledge is expressed in the form of high-level, easy-to-interpret classification rules. In order to discover classification rules, we propose a hybrid decision tree/genetic algorithm method. The central idea of this hybrid method involves the concept of small disjuncts in data mining, as follows. In essence, a set of classification rules can be regarded as a logical disjunction of rules, so that each rule can be regarded as a disjunct. A small disjunct is a rule covering a small number of examples. Due to their nature, small disjuncts are error prone. However, although each small disjunct covers just a few examples, the set of all small disjuncts can cover a large number of examples, so that it is important to develop new approaches to cope with the problem of small disjuncts. In our hybrid approach, we have developed two genetic algorithms (GA) specifically designed for discovering rules covering examples belonging to small disjuncts, whereas a conventional decision tree algorithm is used to produce rules covering examples belonging to large disjuncts. We present results evaluating the performance of the hybrid method in 22 real-world data sets. (C) 2003 Elsevier Inc. All rights reserved.	Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England; UTP, Dept Comp Sci, BR-80215090 Curitiba, Parana, Brazil	Freitas, AA (reprint author), Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England.	deborah@utp.br; a.a.freitas@ukc.ac.uk	Freitas, Alex/H-1249-2011				Beasley D, 1993, EVOL COMPUT, V1, P101, DOI 10.1162/evco.1993.1.2.101; Blickle T., 2000, EVOLUTIONARY COMPUTA, P181; CARBALHO DR, 2002, P GEN EV COMP C GECC, P1035; CARVALHO DR, 2000, P 4 EUR C PKDD 2000, V1910, P345, DOI 10.1007/3-540-45372-5_35; Carvalho D. R., 2002, Applied Soft Computing, V2, DOI 10.1016/S1568-4946(02)00031-5; Cohen W. W., 1993, P 13 INT JOINT C ART, P988; Cover T. M., 1991, ELEMENTS INFORMATION; Danyluk A. P., 1993, P 10 INT C MACH LEAR, P81; Dhar V, 2000, DATA MIN KNOWL DISC, V4, P251, DOI 10.1023/A:1009848126475; FREITAS A, 2002, HDB DATA MINING KNOW, P698; Freitas A.A., 2000, P GEN EV COMP C GECC, P1061; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Freitas A.A., 2002, DATA MINING KNOWLEDG; Goldberg D. E., 1987, P 2 INT C GEN ALG, P41; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; HAND DJ, 1997, CONSTRUNTION ASSESSM; HOLTE RC, 1989, CONCEPT LEARNING PRO, V89, P813; LIU B, 2000, P 6 ACM SIGKDD INT C, P208, DOI 10.1145/347090.347128; Lopes AD, 2000, LECT NOTES ARTIF INT, V1952, P33; MAHFOUD SW, 1995, 95001 U ILL; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Papagelis A, 2001, P 18 INT C MACH LEAR, P393; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rendell L., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00298.x; RENDELL L, 1993, P 13 INT JOINT C ART, P952; Ting K., 1994, P 10 CAN C ART INT, P91; WEISS G M, 1995, P 12 INT C MACH LEAR, P558; WEISS GM, 1998, P 15 INT C MACH LEAR, P574; Weiss G. M., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000)	30	42	43	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JUN 14	2004	163	1-3					13	35		10.1016/j.ins.2003.03.013		23	Computer Science, Information Systems	Computer Science	829TY	WOS:000222074100003	
S	van der Aalst, WMP; van Dongen, BF		Han, Y; Wikarski, D; Tai, S		van der Aalst, WMP; van Dongen, BF			Discovering workflow performance models from timed logs	ENGINEERING AND DEPLOYMENT OF COOPERATIVE INFORMATION SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Engineering and Deployment of Cooperative Information Systems	SEP 17-20, 2002	BEIJING, PEOPLES R CHINA	China Comp Federat, EASST, IEEE, Chinese Acad Sci, Inst Comp, Fraunhofer Inst Software & Syst Technol, Brandenburg Univ Appl Sci, Tsinghua Univ, IBM Res		workflow mining; workflow management; data mining; Petri nets	PETRI NETS; MANAGEMENT	Contemporary workflow management systems are driven by explicit process models, i.e., a completely specified workflow design is required in order to enact a given workflow process. Creating a workflow design is a complicated time-consuming process and typically there are discrepancies between the actual workflow processes and the processes as perceived by the management. Therefore, we have developed techniques for discovering workflow models. Starting point for such techniques are so-called "workflow logs" containing information about the workflow process as it is actually being executed. In this paper, we extend our existing mining technique a [4] to incorporate time. We assume that events in workflow logs bear timestamps. This information is used to attribute timing such as queue times to the discovered workflow model. The approach is based on Petri nets and timing information is attached to places. This paper also presents our workflow-mining tool EMiT. This tool translates the workflow log of several commercial systems (e.g., Staffware) to an independent XML format. Based on this format the tool mines for causal relations and produces a graphical workflow model expressed in terms of Petri nets.	Eindhoven Univ Technol, Dept Technol Management, NL-5600 MB Eindhoven, Netherlands	van der Aalst, WMP (reprint author), Eindhoven Univ Technol, Dept Technol Management, POB 513, NL-5600 MB Eindhoven, Netherlands.		van Dongen, Boudewijn/C-2133-2011; van der Aalst, Wil/G-1248-2011	van der Aalst, Wil/0000-0002-0955-6940			Agrawal R., 1998, 6 INT C EXT DAT TECH, P469; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Cook J.E., 1998, P 6 INT S FDN SOFTW, P35, DOI 10.1145/288195.288214; Cook JE, 1999, ACM T SOFTW ENG METH, V8, P147, DOI 10.1145/304399.304401; DESEL J, 1995, CAMBRIDGE TRACTS THE, V40; Fischer L., 2001, WORKFLOW HDB 2001 WO; Herbst J, 2000, LECT NOTES ARTIF INT, V1810, P183; Herbst J., 1999, P IJCAI 99 WORKSH IN, P52; Herbst J., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<67::AID-ISAF186>3.0.CO;2-7; HERBST J, 2000, EUROPEAN CONCURRENT; HULSMAN BJP, 1994, PERSONEELSINFORMATIE; Jablonski S., 1996, WORKFLOW MANAGEMENT; Leymann F., 1999, PRODUCTION WORKFLOW; MARINESCU DC, 2002, WILEY SERIES PARALLE, V40; Maruster L., 2001, P 13 BELG NETH C ART, P183; Maxeiner M.K., 2001, P DAT BUR TECHN WISS, P75; MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143; Reisig W., 1998, LECT NOTES COMPUTER, V1491; SAUERWEIN LB, 2001, GUIDELINES PERSONAL; van der Aalst W. M. P., 2002, WORKFLOW MANAGEMENT; van der Aalst Wil M. P., 2000, LECT NOTES COMPUTER, V1806; Van der Aalst WMP, 1998, J CIRCUIT SYST COMP, V8, P21, DOI 10.1142/S0218126698000043; VANDERAALST WMP, 2002, BETA WORKING PAPERS; Verbeek HMW, 2001, COMPUT J, V44, P246, DOI 10.1093/comjnl/44.4.246; Weijters A., 2001, P 13 BELG NETH C ART, P283; Weijters A.J.M.M., 2001, P 11 DUTCH BELG C MA, P93	26	42	42	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-44222-7	LECT NOTES COMPUT SC			2002	2480						45	63				19	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BY01V	WOS:000187254100004	
J	Lagus, K; Honkela, T; Kaski, S; Kohonen, T				Lagus, K; Honkela, T; Kaski, S; Kohonen, T			Websom for textual data mining	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						data mining; document filtering; exploratory data analysis; information retrieval; self-organizing map; SOM; text document collection; WEBSOM	INFORMATION-RETRIEVAL; MAPS	New methods that are user-friendly and efficient are needed for guidance among the masses of textual information available in the Internet and the World Wide Web. We have developed a method and a tool called the WEBSOM which utilizes the self-organizing map algorithm (SOM) for organizing large collections of text documents onto visual document maps. The approach to processing text is statistically oriented, computationally feasible, and scalable - over a million text documents have been ordered on a single map. In the article we consider different kinds of information needs and tasks regarding organizing, visualizing, searching, categorizing and filtering textual data. Furthermore, we discuss and illustrate with examples how document maps can aid in these situations. An example is presented where a document map is utilized as a tool for visualizing and filtering a stream of incoming electronic mail messages.	Helsinki Univ Technol, Neural Networks Res Ctr, Lab Comp & Informat Sci, FIN-02015 HUT, Finland	Lagus, K (reprint author), Helsinki Univ Technol, Neural Networks Res Ctr, Lab Comp & Informat Sci, POB 2200, FIN-02015 HUT, Finland.						Anderberg M.R., 1973, CLUSTER ANAL APPL; CALLANT SI, 1992, ACM SIGIR FORUM, V26, P34; Chen SS, 1996, J VIS COMMUN IMAGE R, V7, P1, DOI 10.1006/jvci.1996.0001; Deboeck G.J., 1998, VISUAL EXPLORATIONS; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Golub G. H., 1983, MATRIX COMPUTATIONS; GOSER K, 1989, IEEE MICRO, V9, P28, DOI 10.1109/40.42985; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Honkela T., 1997, P WSOM 97 WORKSH SEL, P310; HONKELA T, 1995, P ICANN 95 INT C ART, V2, P3; Honkela T., 1997, THESIS HELSINKI U TE; HONKELA TK, 1996, A32 HELS U TECHN LAB; Hyotyniemi H., 1996, P FINN ART INT C GEN, P64; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jardine N, 1971, MATH TAXONOMY; KASKI S, 1998, IN PRESS NEUROCOMPUT; Kaski S., 1998, NEURAL COMPUTING SUR, V1, P102; Kaski S., 1996, Neural Networks in Financial Engineering. Proceedings of the Third International Conference on Neural Networks in the Capital Markets; Kaski S., 1998, P IJCNN 98 INT JOINT, V1, P413; KASKI S, 1996, P WCNN 96 WORLD C NE, P814; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1996, A33 HELS U TECHN LAB; Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105; Kohonen T., 1997, SELF ORG MAPS; Kohonen T., 1996, LECT NOTES COMPUTER, V1112, P269; Kohonen T., 1996, A31 HELS U TECHN LAB; KOHONEN T, 1997, P ICNN 97 INT C NEUR, pPL1; LAGUS K, 1996, P 2 INT C KNOWL DISC, P238; LAGUS K, 1997, P WSOM 97 WORKSH SEL; LIN X, 1991, P 14 ANN INT ACM SIG, V262, P91; Lin X, 1997, J AM SOC INFORM SCI, V48, P40, DOI 10.1002/(SICI)1097-4571(199701)48:1<40::AID-ASI6>3.0.CO;2-1; Lin X., 1992, Proceedings. Visualization '92 (Cat. No.92CH3201-1), DOI 10.1109/VISUAL.1992.235198; MERKL D, 1995, P ICNN 95 IEEE INT C, V2, P1986; MERKL D, 1997, P SIGIR 97 20 ANN IN; MERKL D, 1993, P IJCNN 93 NAG INT J, V3, P2468, DOI 10.1109/IJCNN.1993.714224; Orwig RE, 1997, J AM SOC INFORM SCI, V48, P157; RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171; SALTON G, 1987, 87881 CORN U DEP COM; SALTON G, 1983, INTRO MODERN INFORMA; Salton G., 1989, AUTOMATIC TEXT PROCE; SCHOLTES J, 1993, THESIS U AMSTERDAM A; SIMULA O, 1997, PROGR CONNECTIONSIST, V2, P1313; Tryon R., 1973, CLUSTER ANAL; Ultsch A., 1993, INFORM CLASSIFICATIO, P307; Zavrel J, 1996, ARTIF INTELL REV, V10, P477, DOI 10.1007/BF00130695; *HELS U TECHN NEUR, 1997, P WSOM 97 WORKSH SEL	46	42	42	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	DEC	1999	13	5-6					345	364		10.1023/A:1006586221250		20	Computer Science, Artificial Intelligence	Computer Science	317YH	WOS:000087254300002	
J	Sohn, SY				Sohn, SY			Meta analysis of classification algorithms for pattern recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data mining; meta analysis; legit model; multivariate statistics	DECISION TREES; RELIABILITY; SELECTION	Various classification algorithms became available due to a surge of interdisciplinary research interests in the areas of data mining and knowledge discovery. We develop a statistical meta-model which compares the classification performances of several algorithms in terms of data characteristics. This empirical model is expected to aid decision making processes of finding the best classification tool in the sense of providing the minimum classification error among alternatives.	Yonsei Univ, Dept Comp Sci & Ind Syst Engn, Seoul 120749, South Korea	Sohn, SY (reprint author), Yonsei Univ, Dept Comp Sci & Ind Syst Engn, Shichondong 134, Seoul 120749, South Korea.		Sohn, So Young/G-8043-2012				AEBERHARD S, 1994, PATTERN RECOGN, V27, P1065, DOI 10.1016/0031-3203(94)90145-7; Breiman L, 1984, CLASSIFICATION REGRE; BRILL FZ, 1992, IEEE T NEURAL NETWOR, V3, P324, DOI 10.1109/72.125874; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; DRAPER BA, 1994, IEEE T PATTERN ANAL, V16, P888, DOI 10.1109/34.310684; Efron B., 1982, JACKKNIFE BOOTSTRAP; FAYYAD U, 1997, TUT NOT 1 PAC AS C K; GNANADESIKAN R, 1995, J CLASSIF, V12, P113, DOI 10.1007/BF01202271; Hosmer Jr D.W., 1989, APPL LOGISTIC REGRES; JOACHIMSTHALER EA, 1988, DECISION SCI, V19, P323; JUNG BJ, 1997, IE INTERFACES, V10, P47; Koller D., 1996, P 13 INT C MACH LEAR; LIVARINEN J, 1994, P INT C ART NEUR NET, V1; LOWE D, 1991, IEEE T PATTERN ANAL, V13, P355, DOI 10.1109/34.88570; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SHAUDYS FE, 1992, P INT JOINT C NEUR N; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; SMITH JE, 1994, P IEE C GEN ALG IM P, P193; SOHN SY, 1997, UNPUB VARIABLE SELEC; SOHN SY, 1994, NAV RES LOG, V41, P707, DOI 10.1002/1520-6750(199410)41:6<707::AID-NAV3220410603>3.0.CO;2-R; Sohn SY, 1997, IEEE T RELIAB, V46, P122; SOHN SY, 1992, J STAT COMPUT SIM, V40, P247, DOI 10.1080/00949659208811380; Sohn SY, 1997, COMPUT IND ENG, V33, P741; SOHN SY, 1997, FAC MAINT ENG P SEOU, P157; Sohn SY, 1996, IIE TRANS, V28, P995; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Taylor C.C., 1994, MACHINE LEARNING NEU; Wasserman P.D., 1993, ADV METHODS NEURAL C; WONG MA, 1983, J ROY STAT SOC B MET, V45, P362	31	42	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1137	1144				8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	259YG	WOS:000083921100003	
J	Anand, SS; Bell, DA; Hughes, JG				Anand, SS; Bell, DA; Hughes, JG			EDM: A general framework for data mining based on evidence theory	DATA & KNOWLEDGE ENGINEERING			English	Article						data mining; knowledge discovery in databases; uncertainty handling; evidence theory; parallel discovery		Data Mining or Knowledge Discovery in Databases [1,15,23] is currently one of the most exciting and challenging areas where database techniques are coupled with techniques from Artificial Intelligence and mathematical sub-disciplines to great potential advantage. It has been defined as the non-trivial extraction of implicit, previously unknown and potentially useful information from data. A lot of research effort is being directed towards building tools for discovering interesting patterns which are hidden below the surface in databases. However, most of the work bring done in this field has been problem-specific and no general framework has yet been proposed for Data Mining. In this paper we seek to remedy this by proposing, EDM - Evidence-based Data Mining - a general framework for Data Mining based on Evidence Theory. Having a general framework for Data Mining offers a number of advantages. It provides a common method for representing knowledge which allows prior knowledge from the user or knowledge discovered by another discovery process to be incorporated into the discovery process. A common knowledge representation also supports the discovery of meta-knowledge from knowledge discovered by different Data Mining techniques. Furthermore, a general framework can provide facilities that are common to most discovery processes, e.g. incorporating domain knowledge and dealing with missing values. The framework presented in this paper has the following additional advantages. The framework is inherently parallel. Thus, algorithms developed within this framework will also be parallel and will therefore be expected to be efficient for large data sets - a necessity as most commercial data sets, relational or otherwise, are very large. This is compounded by the fact that the algorithms are complex. Also, the parallelism within the framework allows its use in parallel, distributed and heterogeneous databases. The framework is easily updated and new discovery methods can be readily incorporated within the framework, making it 'general' in the functional sense in addition to the representational sense considered above. The framework provides an intuitive way of dealing with missing data during the discovery process using the concept of Ignorance borrowed from Evidence Theory. The framework consists of a method for representing data and knowledge, and methods for data manipulation or knowledge discovery(1). We suggest an extension of the conventional definition of mass functions in Evidence Theory for use in Data Mining, as a means to represent evidence of the existence of rules in the database. The discovery process within EDM consists of a series of operations on the mass functions. Each operation is carried out by an EDM operator. We provide a classification for the EDM operators based on the discovery functions performed by them and discuss aspects of the induction, domain and combination operator classes. The application of EDM to two separate Data Mining tasks is also addressed, highlighting the advantages of using a general framework for Data Mining in general and, in particular, using one that is based on Evidence Theory.		Anand, SS (reprint author), UNIV ULSTER,FAC INFORMAT,SCH INFORMAT & SOFTWARE ENGN,JORDANSTOWN,NORTH IRELAND.		Hughes, John/H-1661-2012				AGARWAL R, 1993, IEEE T KNOWLEDGE DAT; ANAND SS, 1994, P AAAI94 WORKSH KNOW; ANAND SS, 1995, LECTURE NOTES COMPUT, P190; ANAND SS, 1995, 4 INT ACM C INF KNOW; ANAND SS, 1993, ASPECTS UNCERTAINTY; ANAND SS, 1994, P 20 VLDR C SEP; BELL D, 1992, DISTRIBUTED DATABASE; Bell D. A., 1995, Journal of Intelligent Systems, V5, DOI 10.2190/CH2P-0P19-CVTK-76GL; BELL DA, 1994, USING DEMPSTER SHAFE; BELL DA, 1994, INT WORKSH SPAT TEMP; BELL DA, 1993, IEEE T KNOWLEDGE DAT, V5; CODD EF, 1970, CACM             JUN, V13; DATE CJ, 1983, INTRO DATABASE SYSTE, V2; FAYYAD UM, 1993, AAAI93 WORKSH KNOWL; Frawley W. J., 1991, Knowledge discovery in databases; Guan J. W., 1992, EVIDENCE THEORY ITS, V2; Guan J. W., 1991, EVIDENCE THEORY ITS, V1; GUAN JW, 1993, P C UNC ART INT; GUAN JW, 1993, 4 INT C DAT EXP SYST, P413; HAN JW, 1994, THEOR COMPUT SCI, V133, P361, DOI 10.1016/0304-3975(94)90194-5; IMAM IF, 1993, WORKSH KNOWL DISC DA; Krause P., 1993, REPRESENTING UNCERTA; MATHEUS C, 1993, IEEE T KNOWLEDGE DAT; MORAL S, 1994, AAAI 94, P269; ORPONEN P, 1990, ARTIF INTELL, V44, P245, DOI 10.1016/0004-3702(90)90103-7; PIETETSKYSHAPIR.G, 1991, DISCOVERY ANAL PRESE, P229; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Shafer G, 1976, MATH THEORY EVIDENCE; SHI S, 1994, CYBERNET SYST, V1, P241; SMYTH P, 1991, RULE INDUCTION USING, P159; TAN MG, 1995, P DAT MIN SEM UNICOM; WONG YC, PARALLELIZING DEMPST, V19, P807; WU Q, 1991, INTEGRATION HEURISTI, P249; Yager R.R., 1991, LINGUISTIC SUMMARIES, P347; ZIARKO W, 1991, DISCOVERY ANAL REPRE, P195	35	42	54	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	APR	1996	18	3					189	223		10.1016/0169-023X(95)00038-T		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	UJ363	WOS:A1996UJ36300001	
J	Kim, E; Helal, S; Cook, D				Kim, Eunju; Helal, Sumi; Cook, Diane			Human Activity Recognition and Pattern Discovery	IEEE PERVASIVE COMPUTING			English	Article						Hidden Markov models; Markov processes; Humans; Data mining; Standards; Pervasive computing; pervasive computing; activity modeling; activity recognition; pattern discovery			[Kim, Eunju; Helal, Sumi] Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA; [Cook, Diane] Washington State Univ, Pullman, WA 99164 USA	Kim, E (reprint author), Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.	ejkim@cise.ufl.edu; helal@cise.ufl.edu; cook@eecs.wsu.edu					Gu T., 2009, P IEEE INT C PERV CO, P1; HELAL A, 2009, SENSORY DATASET DESC; Huynh T., 2008, P 10 INT C UB COMP, P10, DOI DOI 10.1145/1409635.1409638.URL; INTILLE S, 2008, NSF CRI CRD DEV LONG; Maurer U., 2006, P INT WORKSH WEAR IM, P99; Munguia-Tapia E, 2004, P PERV 04, P158; Ogale A, 2005, P IEEE WORKSH DYN VI, P115; Sutton C, 2006, INTRO STAT RELATIONA	8	41	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1536-1268		IEEE PERVAS COMPUT	IEEE Pervasive Comput.	JAN-MAR	2010	9	1					48	53		10.1109/MPRV.2010.7		6	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	540OA	WOS:000273342000009	
B	Wang, YT; Zang, YH; Xing, YF		Pan, YH; Lin, ZK; Hu, ZY; Sun, SQ; Vergeest, J; Huang, Q		Wang, Yantao; Zang, Yanhong; Xing, Yifei			Study on webparts-based complex product commercial design	7TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED INDUSTRIAL DESIGN & CONCEPTUAL DESIGN	International Conference on Computer-Aided Design & Conceptual Design		English	Proceedings Paper	7th International Conference on Computer-Aided Industrial Design and Conceptual Design (CAID&CD)	NOV 17-19, 2006	Hangzhou, PEOPLES R CHINA	Zhejiang Univ, CAD&CG Assoc, Chinese Comp Assoc, Chinese Mech Engn Soc, Ind Design Inst, Carnegie Mellon Univ, Delft Univ Technol, Hong Kong Polytechn Univ, Wenzhou Med Coll, Natl Sci Museum, IEEE Beijing Sect, Zhejiang Univ, Modern Ind Design Inst		agent; commercial design; search engine; webparts		The product commercial development mode will make an important impact on the creative product development style. In this paper, the basis of the product commercial development that is the webparts data integrated model is proposed first. In this data model, three important parts such as the data mining, the data processing and the data expressing are analyzed. Then, the Internet-based webparts application system is set up. And the components searching engine playing an important role in system is discussed. At last, the agent-based webparts search engine is studied. And with the help of the searching engine, the optimized commercial result will be achieved.	Yantai Univ, Sch Mech & Elect Engn & Automobile Engn, Yantai 264005, Peoples R China	Wang, YT (reprint author), Yantai Univ, Sch Mech & Elect Engn & Automobile Engn, Yantai 264005, Peoples R China.						Li Xin, 2001, Journal of China Institute of Communications, V22; Wang Yan-tao, 2006, P 10 INT C COMP SUPP, P596; WANG YT, 2006, J YANTAI U, V19, P52; WANG YT, 2005, P 6 INT C COMP AID I, P5; WEI YQ, 2005, P 6 INT C COMP AID I, P762	5	41	45	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0683-8	I C COMP AID DES CON			2006							1	4				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BFZ93	WOS:000245718100001	
J	Au, WH; Chan, KCC				Au, WH; Chan, KCC			Mining fuzzy association rules in a bank-account database	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						customer relationship management; data mining; fuzzy association rules; rule interestingness measures; transformation functions	SYSTEMS	This paper describes how we applied a fuzzy technique to a data-mining task involving a large database that was provided by an international bank with offices in Hong Kong. The database contains the demographic data of over 320,000 customers and their banking transactions, which were collected over a six-month period. By mining the database, the bank would like to be able to discover interesting patterns in the data. The bank expected that the hidden patterns would reveal different characteristics about different customers so that they could better serve and retain them. To help the bank achieve its goal, we developed a fuzzy technique, called Fuzzy Association Rule Mining 11 (FARM 11), which can mine fuzzy association rules. FARM 11 is able to handle both relational and transactional data. It can also handle fuzzy data. The former type of data allows FARM 11 to discover multidimensional association rules, whereas the latter data allows some of the patterns to be more-easily revealed and expressed. To effectively uncover the hidden associations in the bank-account database, FARM 11 performs several steps. First, it combines the relational and transactional data together by performing data transformations. Second, it identifies fuzzy attributes and performs fuzzification so that linguistic terms can be used to represent the uncovered patterns. Third, it makes use of an efficient rule-search process that is guided by an objective interestingness measure. This measure is defined in terms of fuzzy confidence and support measures, which reflect the differences in the actual and the expected degrees to which a customer is characterized by different linguistic terms. These steps are described in detail in this paper. With FARM 11, fuzzy association rules were obtained that were judged by experts from the bank to be very useful. In particular, they discovered that they had identified some interesting characteristics about the customers who had once used the bank's loan services but then decided later to cease using them. The bank translated what they discovered into actionable items by offering some incentives to retain their existing customers.	Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China	Au, WH (reprint author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.	cswhau@comp.polyu.edu; cskcchan@comp.polyu.edu.hk					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Chan K. C. C., 1997, Proceedings of the Sixth International Conference on Information and Knowledge Management. CIKM'97, DOI 10.1145/266714.266898; Chan K. C. C., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00129.x; CHAN KCC, 2001, DATA MINING COMPUTAT, P95; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; Date C. J., 2000, INTRO DATABASE SYSTE; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Han J., 2000, DATA MINING CONCEPTS; HESKETT JL, 1994, HARVARD BUS REV, V72, P164; Hirota K, 1999, P IEEE, V87, P1575, DOI 10.1109/5.784240; Kacprzyk J, 2001, ADV SOFT COMP, P475; Lee DH, 1997, IEEE T SYST MAN CY B, V27, P671; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; MENDEL JM, 1995, P IEEE, V83, P345, DOI 10.1109/5.364485; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; Peppard J., 2000, EUROPEAN MANAGEMENT, V18, P312, DOI 10.1016/S0263-2373(00)00013-X; Reichheld F.F., 1996, LOYALTY EFFECT HIDDE; Savasere A, 1995, P 21 INT C VER LARG, P432; Schwaiger M., 1998, ELECTRON MARK, V8, P23, DOI 10.1080/10196789800000051; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Ullman J. D., 1988, PRINCIPLES DATABASE, VI; WU WH, 1999, P 8 IEEE INT C FUZZ, P1217; WU WH, 1998, P 7 IEEE INT C FUZZ, P1314; Yager R. R., 1991, Knowledge discovery in databases; YEN J, 1999, IEEE T KNOWL DATA EN, V11, P159; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	27	41	44	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	APR	2003	11	2					238	248		10.1109/TFUZZ.2003.809901		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	664ZN	WOS:000182095300008	
J	Mladenic, D; Grobelnik, M				Mladenic, D; Grobelnik, M			Feature selection on hierarchy of web documents	DECISION SUPPORT SYSTEMS			English	Article						text mining; feature selection; document categorization; maintaining document ontology; machine learning; data mining	RETRIEVAL; PROFILES	The paper describes feature subset selection used in learning on text. data (text learning) and gives a brief overview of feature subset selection commonly used in machine learning. Several known and some new feature scoring measures appropriate for feature subset selection on large text data are described and related to each other. Experimental comparison of the described measures is given on real-world data collected from the Web. Machine learning techniques are used on data collected from Yahoo, a large text hierarchy of Web documents. Our approach includes some original ideas for handling large number of features, categories and documents. The high number of features is reduced by feature subset selection and additionally by using 'stop-list', pruning low-frequency features and using a short description of each document given in the hierarchy instead of using the document itself. Documents are represented as feature-vectors that include word sequences instead of including only single words as commonly used when learning on text data. An efficient approach to generating word sequences is proposed. Based on the hierarchical structure, we propose a way of dividing the problem into subproblems, each representing one of the categories included in the Yahoo hierarchy. In our learning experiments, for each of the subproblems, naive Bayesian classifier was used on text data. The result of learning is a set of independent classifiers, each used to predict probability that a new example is a member of the corresponding category. Experimental evaluation on real-world data shows that the proposed approach gives good results. The best performance was achieved by the feature selection based on a feature scoring measure known from information retrieval called Odds ratio and using relatively small number of features. (C) 2002 Elsevier Science B.V. All rights reserved.	Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia; Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Mladenic, D (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova 39, Ljubljana 1000, Slovenia.						Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; AH DW, 1994, P AAAI 94 WORKSH CAS, P106; ALMUALLIN H, 1991, P 9 CAN C ART INT, P38; Apte C., 1994, P 17 ANN INT ACM SIG, P23; Bala J, 1995, P 14 INT JOINT C ART, P719; BALABANOVI M, 1995, P AAAI 1995 SPRING S, P80; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; Cardie C., 1993, P 10 INT C MACH LEAR, P25; CARUANA R, 1994, P 11 INT C MACH LEAR, P26; Cherkauer K. J., 1996, P 2 INT C KNOWL DISC, P315; COHEN WW, 1995, P WORKSH IND LOG PRO, P231; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; FILO D, 1997, YAHOO; FRAKES WR, 1992, INFORMATION RETRIEVA; GROBELNIK M, 1998, P ECML 98 TEXT MIN W; GROBELNIK M, 1998, IJSDP7824 DEP INT SY; Joachims T, 1997, P 14 INT C MACH LEAR, P143; John G. H., 1994, P 11 INT C MACH LEAR, P121; KINDO T, 1997, P 15 INT JOINT C ART, P716; Kira K, 1992, P 10 NAT C ART INT, P129; Koller D., 1997, P 14 INT C MACH LEAR, P170; Koller D., 1996, P 13 INT C MACH LEAR, P284; Kononenko I., 1995, P 14 INT JOINT C ART, P1034; LAM W, 1997, P 15 INT JOINT C ART, P745; LEWIS D. D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; Lewis D.D., 1995, P 18 ANN INT ACM SIG, P246, DOI 10.1145/215206.215366; Liu H, 1996, P 13 INT C MACH LEAR, P319; Manly B.F., 1994, MULTIVARIATE STAT ME; MANSURIPUR M, 1987, INTRO INFORMATION TH; McCallum A., 1998, P 15 INT C MACH LEAR, P359; Mitchell T. M, 1997, MACHINE LEARNING; Mladenic D., 1998, P 10 EUR C MACH LEAR, P95; MLADENIC D, 1995, THESIS U LJUBLJANA S; MLADENIC D, 1995, P MLNET FAM WORKSH K; MLADENIC D, 1996, IJSDP7472 DEP INT SY; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; PFAHRINGER B, 1995, P IJCAI 95 WORKSH DA; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN, P17; Shapiro A.D., 1987, STRUCTURED INDUCTION; SHAW WM, 1995, INFORM PROCESS MANAG, V31, P491, DOI 10.1016/0306-4573(95)00011-5; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Vafaie H., 1993, Proceedings. Fifth International Conference on Tools with Artificial Intelligence TAI '93 (Cat. No.93CH3325-8), DOI 10.1109/TAI.1993.633981; VANRIJSBERGEN CJ, 1981, INFORM PROCESS MANAG, V17, P77, DOI 10.1016/0306-4573(81)90029-7; Yang Y, 1997, P 14 INT C MACH LEAR, P412	45	41	49	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	APR	2003	35	1					45	87		10.1016/S0167-9236(02)00097-0		43	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	636AY	WOS:000180433400004	
J	Du, YP; Liang, YZ; Yun, D				Du, YP; Liang, YZ; Yun, D			Data mining for seeking an accurate quantitative relationship between molecular structure and GC retention indices of alkenes by projection pursuit	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							RESOLUTION GAS-CHROMATOGRAPHY; CRYSTAL GLASS-CAPILLARIES; TOPOLOGICAL ORGANIC-CHEMISTRY; LINEAR ALKENES; GRAPH-THEORY; KNOWLEDGE DISCOVERY; MASS-SPECTROMETRY; SQUALANE; IDENTIFICATION; SEPARATION	Primary data mining on alkenes for seeking an accurate quantitative relationship between the molecular structure and retention indices of gas chromatography is developed in this paper. Based on the results obtained from projection pursuit, all alkenes investigated show an interesting classification. Thus, a new variable named class distance variable of alkenes, which essentially describes information about the branch, position of the double bonds, the number of double bonds. and so on for alkenes, is proposed, With the help of the new variable, both fitting and prediction accuracy of the regression model can be dramatically improved. The results obtained in this work show that the technique of projection pursuit developed in statistics is a quite promising tool for seeking an accurate quantitative structure-retention relationship (QSRR).	Cent S Univ, Coll Chem & Chem Engn, Inst Chemometr & Intelligent Analyt Instruments, Changsha 410083, Peoples R China; Shandong Univ Sci & Technol, Coll Chem Engn, Zibo 255012, Peoples R China; Cent S Univ, Coll Chem & Chem Engn, Changsha 410083, Peoples R China	Liang, YZ (reprint author), Cent S Univ, Coll Chem & Chem Engn, Inst Chemometr & Intelligent Analyt Instruments, Changsha 410083, Peoples R China.	yzliang@public.cs.hn.cn					BONEVA S, 1986, CHROMATOGRAPHIA, V21, P149, DOI 10.1007/BF02311743; BUJA A, 1991, ANN STAT, V19, P93, DOI 10.1214/aos/1176347967; CHRETIEN JR, 1977, ANAL CHEM, V49, P747, DOI 10.1021/ac50014a021; Cundari TR, 2001, J CHEM INF COMP SCI, V41, P281, DOI 10.1021/ci0000068; Debska BJ, 1997, COMPUT CHEM, V21, P51, DOI 10.1016/S0097-8485(96)00012-5; DU YP, 2001, CHIN 8 COMP APPL CHE, P147; DU YP, UNPUB COMPUT CHEM; DUBOIS JE, 1980, J CHROMATOGR, V194, P121, DOI 10.1016/S0021-9673(00)87288-X; EISEN O, 1972, CHROMATOGRAPHIA, V5, P229, DOI 10.1007/BF02270600; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; Fayyad U, 1996, COMMUN ACM, V39, P51, DOI 10.1145/240455.240471; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; FRIEDMAN JL, UNPUB; Glymour C, 1996, COMMUN ACM, V39, P35, DOI 10.1145/240455.240466; HIVELY RA, 1968, J GAS CHROMATOGR, V6, P203; Hu CY, 1996, J CHEM INF COMP SCI, V36, P82, DOI 10.1021/ci9501150; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Inmon WH, 1996, COMMUN ACM, V39, P49, DOI 10.1145/240455.240470; Kaliszan R., 1987, QUANTITATIVE STRUCTU; Katritzky AR, 2000, ANAL CHEM, V72, P101, DOI 10.1021/ac990800w; Kier L. B., 1976, MOL CONNECTIVITY CHE; Kier LB, 1999, TOPOLOGICAL INDICES, P455; LIANG YZ, 2001, ANAL CHIM ACTA, V446, P107; LOEWENGUTH JC, 1968, Z ANAL CHEM, V236, P170; MATUKUMA A, 1969, GAS CHROMATOGRAPHY 1, P55; PACAKOVA V, 1978, CHROMATOGRAPHIA, V11, P266, DOI 10.1007/BF02282952; PAPAZOVA D, 1988, CHROMATOGRAPHIA, V25, P177, DOI 10.1007/BF02316441; RIJKS JA, 1974, CHROMATOGRAPHIA, V7, P99, DOI 10.1007/BF02269819; ROHRBAUGH RH, 1985, ANAL CHEM, V57, P2770, DOI 10.1021/ac00291a008; SCHOMBURG G, 1969, GAS CHROMATOGRAPHY, P45; SCHRODER H, 1980, HRC-J HIGH RES CHROM, P3; SCHRODER H, 1980, HRC-J HIGH RES CHROM, P119; SCHRODER H, 1980, HRC-J HIGH RES CHROM, P38; SCHRODER H, 1980, HRC-J HIGH RES CHROM, P362; SCHRODER H, 1980, HRC-J HIGH RES CHROM, P95; SCHULTZ HP, 1989, J CHEM INF COMP SCI, V29, P227, DOI 10.1021/ci00063a012; SCHULTZ HP, 1990, J CHEM INF COMP SCI, V33, P863; SCHULTZ HP, 1995, J CHEM INF COMP SCI, V35, P864, DOI 10.1021/ci00027a011; SCHULTZ HP, 1990, J CHEM INF COMP SCI, V30, P27, DOI 10.1021/ci00065a007; SOJAK L, 1980, J CHROMATOGR, V191, P199, DOI 10.1016/S0021-9673(00)86380-3; SOJAK L, 1987, J CHROMATOGR, V406, P43, DOI 10.1016/S0021-9673(00)94016-0; SOJAK L, 1980, J CHROMATOGR, V195, P43, DOI 10.1016/S0021-9673(00)81542-3; SOJAK L, 1986, J CHROMATOGR, V356, P105, DOI 10.1016/S0021-9673(00)91470-5; SOJAK L, 1970, J CHROMATOGR, V51, P75, DOI 10.1016/S0021-9673(01)96841-4; SOJAK L, 1984, J CHROMATOGR, V292, P241, DOI 10.1016/S0021-9673(01)96207-7; SOJAK L, 1974, J CHROMATOGR, V91, P613, DOI 10.1016/S0021-9673(01)97942-7; SOJAK L, 1973, ANAL CHEM, V45, P293; SOJAK L, 1980, J CHROMATOGR, V191, P187, DOI 10.1016/S0021-9673(00)86379-7; SOJAK L, 1990, J CHROMATOGR, V520, P75, DOI 10.1016/0021-9673(90)85086-B; SOJAK L, 1982, J CHROMATOGR, V238, P51, DOI 10.1016/S0021-9673(00)82710-7; SOJAK L, 1972, J CHROMATOGR, V65, P137, DOI 10.1016/S0021-9673(00)86926-5; SOJAK L, 1990, J CHROMATOGR, V509, P93, DOI 10.1016/S0021-9673(01)93241-8; SOJAK L, 1972, J CHROMATOGR, V65, P93, DOI 10.1016/S0021-9673(00)86921-6; SOJAK L, 1991, J CHROMATOGR, V609, P283; TOURRES DA, 1967, J GAS CHROMATOGR, V5, P35; VANEERTUM R, 1975, J CHROMATOGR SCI, V13, P150; WELSCH T, 1978, CHROMATOGRAPHIA, V11, P5, DOI 10.1007/BF02262945; YAO YY, 1993, ACTA CHIM SINICA, V51, P463; ZULAICA J, 1966, B SOC CHIM FR, P1343	59	41	42	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	NOV-DEC	2002	42	6					1283	1292		10.1021/ci020285u		10	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	620HH	WOS:000179527600003	
J	Yager, RR				Yager, RR			The power average operator	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article						aggregation operator; averaging; data mining; information fusion	AGGREGATION; CONNECTIVES	We introduce the power average to provide an aggregation operator which allows argument values to support each other in the aggregation process. The properties of this operator are described. We discuss the idea of a power median. We introduce some possible formulations for the support function used in the power average. We extend the facility of empowerment, supported aggregation, to a wider class of mean operators such as the OWA and generalized mean.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				Chiu S.L., 1994, J INTELL FUZZY SYST, V2, P267; DUBOIS D, 1985, INFORM SCIENCES, V36, P85, DOI 10.1016/0020-0255(85)90027-1; DYCKHOFF H, 1984, FUZZY SET SYST, V14, P143, DOI 10.1016/0165-0114(84)90097-6; Yager R., 1994, ESSENTIALS FUZZY MOD; YAGER RR, 1993, FUZZY SET SYST, V59, P125, DOI 10.1016/0165-0114(93)90194-M; Yager RR, 1997, INT J INTELL SYST, V12, P233, DOI 10.1002/(SICI)1098-111X(199703)12:3<233::AID-INT4>3.0.CO;2-Q; Yager R.R., 1997, ORDERED WEIGHTED AVE; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; Yager RR, 1996, INT J APPROX REASON, V15, P93, DOI 10.1016/0888-613X(96)00026-6; Yager RR, 1996, IEEE T SYST MAN CY B, V26, P209, DOI 10.1109/3477.485833; YAGER RR, 1994, IEEE T SYST MAN CYB, V24, P1279, DOI 10.1109/21.299710; ZADEH LA, 1999, IEEE T CIRCUITS SYST, V45, P105	12	41	48	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1083-4427		IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	NOV	2001	31	6					724	731		10.1109/3468.983429		8	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	521MF	WOS:000173843200024	
S	Tung, AKH; Hou, J; Han, JW			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Tung, AKH; Hou, J; Han, JW			Spatial clustering in the presence of obstacles	17TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING, PROCEEDINGS	IEEE International Conference on Data Engineering		English	Proceedings Paper	17th International Conference on Data Engineering	APR 02-06, 2001	HEIDELBERG, GERMANY	IEEE Comp Soc, Tech Comm Data Engn, ABB, HP Invent, Software AG, XML Co, EML, IBM, Microsoft, Software Design & Management				Clustering in spatial data mining is to group similar objects based on their distance, connectivity, or their relative density in space. In the real world, there exist many physical obstacles such as rivers, lakes and highways, and their presence may affect the result of clustering substantially. In this paper, we study the problem of clustering in the presence of obstacles and define it as a COD (Clustering with Obstructed Distance) problem. As a solution to this problem, we propose a scalable clustering algorithm, called COD-CLARANS. We discuss various forms of pre-processed information that could enhance the efficiency of COD-CLARANS. In the strictest sense, the COD problem can be treated as a change in distance function and thus could be handled by current clustering algorithms by changing the distance function. However, we show that by pushing the task of handling obstacles into COD-CLARANS instead of abstracting it at the distance function level, more optimization can be done in the form of a pruning function E'. We conduct various performance studies to show that COD-CLARANS is both efficient and effective.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Tung, AKH (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	khtung@cs.sfu.ca; jhou@cs.sfu.ca; han@cs.sfu.ca					Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Ankerst M, 1999, P ACM SIGMOD INT C M, P49, DOI 10.1145/304182.304187; BERCHTOLD S, 1997, P 16 ACM S PRINC DAT; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Cormen T.H., 1990, INTRO ALGORITHMS; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Kaufman L., 1990, FINDING GROUPS DATA; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; LU W, 1992, P 8 INT C DAT ENG PH, P284; NG R, 1994, P 1994 INT C VER LAR, P44; O'Rourke J, 1998, COMPUTATIONAL GEOMET; Rotem D., 1991, Proceedings. Seventh International Conference on Data Engineering (Cat. No.91CH2968-6), DOI 10.1109/ICDE.1991.131499; Shavlik J. W., 1990, READINGS MACHINE LEA; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; VALDURIEZ P, 1987, ACM T DATABASE SYST, V12, P218, DOI 10.1145/22952.22955; Wang W., 1997, P 1997 INT C VER LAR, P186; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324; *SIL GRAPH INC, BSP TREE	21	41	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1084-4627	0-7695-1001-9	PROC INT CONF DATA			2001							359	367		10.1109/ICDE.2001.914848		9	Computer Science, Information Systems	Computer Science	BR97Q	WOS:000168248100041	
J	Gibson, D; Kleinberg, J; Raghavan, P				Gibson, D; Kleinberg, J; Raghavan, P			Clustering categorical data: an approach based on dynamical systems	VLDB JOURNAL			English	Article						clustering; data mining; categorial data; dynamical systems; hypergraphs	GRAPHS	We describe a novel approach for clustering collections of sets, and its application to the analysis and mining of categorical data. By "categorical data," we mean tables with fields that cannot be naturally ordered by a metric e.g., the names of producers of automobiles, or the names of products offered by a manufacturer. Our approach is based on an iterative method for assigning and propagating weights on the categorical values in a table; this facilitates a type of similarity measure arising from the co-occurrence of values in the dataset. Our techniques can be studied analytically in terms of certain types of non-linear dynamical systems.	Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA; Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Gibson, D (reprint author), Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA.						Agrawal R., 1993, SIGMOD Record, V22; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Agresti A, 1990, CATEGORICAL DATA ANA; Alon N, 1991, PROBABILISTIC METHOD; ALON N, 1986, COMBINATORICA, V6, P83, DOI 10.1007/BF02579166; BERGE C, 1973, HYPERGRAPHS; BLUM A, 1995, J ALGORITHM, V19, P204, DOI 10.1006/jagm.1995.1034; Boppana R. B., 1987, P 28 IEEE S FDN COMP, P280; Brin S., 1997, SIGMOD Record, V26; Brin S., 1997, SIGMOD Record, V26; Charniak E., 1993, STAT LANGUAGE LEARNI; Chiueh T., 1994, P 20 INT C VER LARG, P582; Chung F, 1997, SPECTRAL GRAPH THEOR; Das G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devaney R. L., 1989, INTRO CHAOTIC DYNAMI; DONATH WE, 1973, IBM J RES DEV, V17, P420; DUDA RO, 1973, PATTERN CLASSIFFCATI; Faloutsos C., 1996, SEARCHING MULTIMEDIA; FIEDLER M, 1973, CZECH MATH J, V23, P298; Flickner M., 1995, IEEE COMPUT, V28, P23; Garey M. R., 1979, COMPUTERS INTRACTABI; Golub G.H., 1989, MATRIX COMPUTATIONS; HAN EH, 1997, WORKSH RES ISS DAT M; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; HUANG Z, 1997, WORKSH RES ISS DAT M; Jerrum M., 1996, APPROXIMATION ALGORI, P482; Jolliffe I., 1986, PRINCIPAL COMPONENT; KLEINBERG J, 1997, IN PRESS J ACM; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Page L., 1998, P 7 INT WORLD WID WE, P107; Ritter H., 1992, NEURAL COMPUTATION S; Rumelhart D, 1986, PARALLEL DISTRIBUTED; SEIFERAS J, 1999, LARGE BIBLIO THEORY; Spielman D. A., 1996, Proceedings. 37th Annual Symposium Foundations of Computer Science (Cat. No.96CH35973), DOI 10.1109/SFCS.1996.548468; Srikant R., 1995, P 21 INT C VER LARG, P407; TOIVONEN H, 1996, VLDB, P134; WIEDERHOLD G, 1999, BIBLIO DATABASE SYST; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	42	41	41	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1066-8888		VLDB J	VLDB J.	FEB	2000	8	3-4					222	236		10.1007/s007780050005		15	Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	295JV	WOS:000085963700005	
J	Ziarko, W				Ziarko, Wojciech			Probabilistic approach to rough sets	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						Rough sets; Probabilistic rough sets; Data dependencies; Data mining; Machine learning; Data reduction	MODEL; SYSTEMS	The article introduces the basic ideas and investigates the probabilistic version of rough set theory. It relies on both classification knowledge and probabilistic knowledge in analysis of rules and attributes. Rough approximation evaluative measures and one-way and two-way inter-set dependency measures are proposed and adopted to probabilistic rule evaluation. A new probabilistic dependency measure for attributes is also introduced and proven to have the monotonicity property. This property makes it possible for the measure to be used to optimize and evaluate attribute-based representations through computation of probabilistic measures of attribute reduct, core and significance factors. (C) 2007 Elsevier Inc. All rights reserved.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Ziarko, W (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.	ziarko@sasktel.net			Natural Sciences and Engineering Council of Canada	The research reported in this article was supported in part by a research grant awarded to the author by Natural Sciences and Engineering Council of Canada.	BEYNON M, 2004, LECT NOTES ARTIF INT, V1711, P412; Beynon MJ, 2003, LECT NOTES ARTIF INT, V2639, P287; FERNANDEZBAIZAN M, 2000, LECT NOTES ARTIF INT, V2005, P286; GALVEZ J, 2000, LECT NOTES ARTIF INT, V2005, P296; Greco S., 2001, LECT NOTES ARTIF INT, V2005, P170; GRECO S, 2008, PARAMETERIZED ROUGH, V49, P285; Greco S, 2005, LECT NOTES ARTIF INT, V3641, P314; GRZYMALABUSSE J, 1991, HDB APPL ADV ROUGH S, P3; MIESZKOWICZ A, 2004, LECT NOTES ARTIF INT, V1711, P402; MURAI T, 2004, LECT NOTES ARTIF INT, V1711, P103; PAWLAK Z, 1988, INT J MAN MACH STUD, V29, P81, DOI 10.1016/S0020-7373(88)80032-4; Pawlak Z., 1991, ROUGH SETS THEORETIC; SKOWRON A, 191 ICS WARS U TECHN; Slezak D, 2004, LECT NOTES ARTIF INT, V3066, P384; Slezak D, 2005, INT J APPROX REASON, V40, P81, DOI 10.1016/j.ijar.2004.11.004; Tsumoto S, 2003, LECT NOTES ARTIF INT, V2639, P78; Tsumoto S., 2000, LECT NOTES ARTIF INT, V2005, P362; Tsumoto S, 1998, LECT NOTES ARTIF INT, V1424, P475; Wei LL, 2003, LECT NOTES ARTIF INT, V2639, P173; WONG M, 2000, LECT NOTES ARTIF INT, V2005, P511; WONG S, 1986, P ACM SIGART 1 INT M, P207, DOI 10.1145/12808.12832; Wong S. K. M., 1986, P 6 INT WORKSH EXP S, P713; WONG SKM, 1986, INT J FUZZY SETS SYS, V21, P357; XIE G, 2008, VARIABLE PRECISION R, V49, P331; YAO Y, 2008, PROBABILISTIC ROUGH, V49, P255; YAO YY, 1992, INT J MAN MACH STUD, V37, P793, DOI 10.1016/0020-7373(92)90069-W; Yao YY, 2003, EXPERT SYST, V20, P287, DOI 10.1111/1468-0394.00253; Ziarko W., 2002, HDB DATA MINING KNOW, P328; Ziarko W, 2004, LECT NOTES ARTIF INT, V3066, P394; Ziarko W, 1996, COMPUT INTELL, V12, P223, DOI 10.1111/j.1467-8640.1996.tb00260.x; Ziarko W, 2001, SOFT COMPUTING SYSTE, P442; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	32	40	46	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X		INT J APPROX REASON	Int. J. Approx. Reasoning	OCT	2008	49	2					272	284		10.1016/j.ijar.2007.06.014		13	Computer Science, Artificial Intelligence	Computer Science	370IC	WOS:000260754900003	
J	Alatas, B; Akin, E; Karci, A				Alatas, Bilal; Akin, Erhan; Karci, Ali			Modenar: Multi-objective differential evolution algorithm for mining numeric association rules	APPLIED SOFT COMPUTING			English	Article						data mining; machine learning; evolutionary computation; multi-objective optimization; differential evolution	GENETIC ALGORITHM	In this paper, a Pareto-based multi-objective differential evolution ( DE) algorithm is proposed as a search strategy for mining accurate and comprehensible numeric association rules ( ARs) which are optimal in the wider sense that no other rules are superior to them when all objectives are simultaneously considered. The proposed DE guided the search of ARs toward the global Pareto-optimal set while maintaining adequate population diversity to capture as many high-quality ARs as possible. ARs mining problem is formulated as a four-objective optimization problem. Support, confidence value and the comprehensibility of the rule are maximization objectives while the amplitude of the intervals which conforms the itemset and rule is minimization objective. It has been designed to simultaneously search for intervals of numeric attributes and the discovery of ARs which these intervals conform in only single run of DE. Contrary to the methods used as usual, ARs are directly mined without generating frequent itemsets. The proposed DE performs a database-independent approach which does not rely upon the minimum support and the minimum confidence thresholds which are hard to determine for each database. The efficiency of the proposed DE is validated upon synthetic and real databases. (C) 2007 Elsevier B.V. All rights reserved.	Firat Univ, Fac Engn, Dept Comp Engn, TR-23119 Elazig, Turkey	Alatas, B (reprint author), Firat Univ, Fac Engn, Dept Comp Engn, TR-23119 Elazig, Turkey.	balatas@firat.edu.tr; eakin@firat.edu.tr; akarci@firat.edu.tr					ABBASS R, 2001, P 2001 C EV COMP SEO, V2, P971; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; ALATAS B, 2005, J SCI ENG FIRAT U, V17, P42; Alatas B, 2006, SOFT COMPUT, V10, P230, DOI 10.1007/s00500-005-0476-x; ALATAS B, 2004, J POLYTECH GAZI U, V7, P269; ALATAS B, 2005, P 2 INT C EL COMP EN, P173; Aumann Y, 2003, J INTELL INF SYST, V20, P255, DOI 10.1023/A:1022812808206; Baluja S., 1994, CMUCS94163; Coello CAC, 2000, ACM COMPUT SURV, V32, P109, DOI 10.1145/358923.358929; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; Fukushima O, 1996, INT J CONFL MANAGE, V7, P191, DOI 10.1108/eb022781; Ghosh A, 2004, INFORM SCIENCES, V163, P123, DOI 10.1016/j.ins.2003.03.021; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GUVENIR HA, 2000, BILKENT U FUNCTION A; Han J., 2001, DATA MINING CONCEPTS; Karaboga D., 2004, Turkish Journal Electrical Engineering and Computer Sciences, Elektrik, V12; Kaya M, 2005, FUZZY SET SYST, V152, P587, DOI 10.1016/j.fss.2004.09.014; KE K, 2006, P ICDE 06, P112; Lampinen J, 1999, P MENDEL 99 5 INT ME, P71; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Mata J, 2002, P 6 PAC AS C KNOWL D, P40; MILLER RJ, 1997, P ACM SIGMOD INT C M, V29, P452; PEREZGUERRERO R, 2004, THESIS U PUERTO RICO; Rechenberg I, 1994, EVOLUTION STRATEGY, P147; SAETROM P, 2003, P 8 SCAND C ART INT; SAETROM P, 2003, MULTIOBJECTIVE EVOLU; Sarker R, 2004, ASIA PAC J OPER RES, V21, P225, DOI 10.1142/S0217595904000217; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; STORN R, 1996, USE DIFFERENTIAL EVO; STORN R, 1995, TR95012 ICSI; Vannucci M., 2004, P EUR S ART NEUR NET, P489; Yoda K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969	33	40	44	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946		APPL SOFT COMPUT	Appl. Soft. Comput.	JAN	2008	8	1					646	656		10.1016/j.asoc.2007.05.003		11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	211FA	WOS:000249508500056	
J	Li, YJ; Chung, SM; Holt, JD				Li, Yanjun; Chung, Soon M.; Holt, John D.			Text document clustering based on frequent word meaning sequences	DATA & KNOWLEDGE ENGINEERING			English	Article						text documents; clustering; frequent word sequences; frequent word meaning sequences; web search; WordNet	SUFFIX TREE CONSTRUCTION	Most of existing text clustering algorithms use the vector space model, which treats documents as bags of words. Thus, word sequences in the documents are ignored, while the meaning of natural languages strongly depends on them. In this paper, we propose two new text clustering algorithms, named Clustering based on Frequent Word Sequences (CFWS) and Clustering based on Frequent Word Meaning Sequences (CFWMS). A word is the word form showing in the document, and a word meaning is the concept expressed by synonymous word forms. A word (meaning) sequence is frequent if it occurs in more than certain percentage of the documents in the text database. The frequent word (meaning) sequences can provide compact and valuable information about those text documents. For experiments, we used the Reuters-21578 text collection, CISI documents of the Classic data set [Classic data set, ftp://ftp.cs.cornell.edu/pub/smart/], and a corpus of the Text Retrieval Conference (TREC) [High Accuracy Retrieval from Documents (HARD) Track of Text Retrieval Conference, 2004]. Our experimental results show that CFWS and CFWMS have much better clustering accuracy than Bisecting k-means (BKM) [M. Steinbach, G. Karypis, V. Kumar, A Comparison of Document Clustering Techniques, KDD-2000 Workshop on Text Mining, 2000], a modified bisecting k-means using background knowledge (BBK) [A. Hotho, S. Staab, G. Stumme, Ontologies improve text document clustering, in: Proceedings of the 3rd IEEE International Conference on Data Mining, 2003, pp. 541-544] and Frequent Itemset-based Hierarchical Clustering (FIHC) [B.C.M. Fung, K. Wang, M. Ester, Hierarchical document clustering using frequent itemsets, in: Proceedings of SIAM International Conference on Data Mining, 2003] algorithms. (c) 2007 Elsevier B.V. All rights reserved.	[Chung, Soon M.; Holt, John D.] Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA; [Li, Yanjun] Fordham Univ, Dept Comp & Informat Sci, Bronx, NY 10458 USA	Chung, SM (reprint author), Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.	soon.chung@wright.edu					Agrawal R., 1994, P 20 INT C VER LARG, P487; AHONENMYKA H, 2002, P ESF EXPL WORKSH PA, P16; AHONENMYKA H, 1999, P 16 INT C MACH LEAR, P11; ALLAN J, 2003, P TEXT RETR C, P24; Beil F., 2002, P 8 ACM SIGKDD INT C, P436; CHOUDHARY B, 2002, P 11 INT WORLD WID W; CUTTING DR, 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; DOUCET A, 2004, P 42 ANN M ASS COMP, P88, DOI 10.3115/1613186.1613198; Farach M., 1998, Proceedings 39th Annual Symposium on Foundations of Computer Science (Cat. No.98CB36280), DOI 10.1109/SFCS.1998.743441; Farach M., 1997, Proceedings. 38th Annual Symposium on Foundations of Computer Science (Cat. No.97CB36150), DOI 10.1109/SFCS.1997.646102; Fellbaum C., 1998, WORDNET ELECT LEXICA; Fung B, 2003, P SIAM INT C DAT MIN; FUNG BCM, 2005, ENCY DATA WAREHOUSIN; Giegerich R, 1997, ALGORITHMICA, V19, P331, DOI 10.1007/PL00009177; Holt J. D., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011664; Hotho A, 2003, P 3 IEEE INT C DAT M, P541; Jain AK, 1998, ALGORITHMS CLUSTERIN; Karypis G., CLUTO CLUSTERING TOO; Kaufman L., 1990, FINDING GROUPS DATA; Kurtz S, 1999, SOFTWARE PRACT EXPER, V29, P1149, DOI 10.1002/(SICI)1097-024X(199911)29:13<1149::AID-SPE274>3.0.CO;2-O; LANDAU GM, 1989, J ALGORITHM, V10, P157, DOI 10.1016/0196-6774(89)90010-2; Larsen B, 1999, P 5 ACM SIGKDD INT C, DOI 10.1145/312129.312186; MCCREIGHT EM, 1976, J ACM, V23, P262, DOI 10.1145/321941.321946; Sedding J., 2004, P COLING 2004 WORKSH; Steinbach M., 2000, KDD 2000 WORKSH TEXT; UKKONEN E, 1995, ALGORITHMICA, V14, P249, DOI 10.1007/BF01206331; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; WANG E, 1999, P 8 INT C INF KNOWL, P483; Weiner P., 1973, P 14 IEEE S SWITCH A, P1; Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290956; Zamir O., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6; [Anonymous], LEMUR TOOLKIT LANGUA; 2004, TRACK TEXT RETR C	34	40	50	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	JAN	2008	64	1					381	404		10.1016/j.datak.2007.08.001		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	241EJ	WOS:000251639400020	
J	Hong, TP; Chen, CH; Wu, YL; Lee, YC				Hong, TP; Chen, CH; Wu, YL; Lee, YC			A GA-based fuzzy mining approach to achieve a trade-off between number of rules and suitability of membership functions	SOFT COMPUTING			English	Article						data mining; genetic algorithm; fuzzy set; membership function; association rule	GENETIC ALGORITHMS; INDUCTION; ATTRIBUTES; COMPLEXITY	Data mining is most commonly used in attempts to induce association rules from transaction data. Transactions in real-world applications, however, usually consist of quantitative values. This paper thus proposes a fuzzy data-mining algorithm for extracting both association rules and membership functions from quantitative transactions. We present a GA-based framework for finding membership functions suitable for mining problems and then use the final best set of membership functions to mine fuzzy association rules. The fitness of each chromosome is evaluated by the number of large 1-itemsets generated from part of the previously proposed fuzzy mining algorithm and by the suitability of the membership functions. Experimental results also show the effectiveness of the framework.	Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung 811, Taiwan; Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan; I Shou Univ, Inst Informat Management, Kaohsiung 840, Taiwan; I Shou Univ, Inst Informat Engn, Kaohsiung 840, Taiwan	Hong, TP (reprint author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung 811, Taiwan.	tphong@nuk.edu.tw; wuyulung@isu.edu.tw; d9003007@stmail.isu.edu.tw					Agrawal R., 1994, INT C VER LARG DAT B, P487; Cai CH, 1998, IDEAS 98 - INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P68; Cordon O, 2001, IEEE T FUZZY SYST, V9, P667, DOI 10.1109/91.940977; GRAHAM I, 1998, EXPERT SYSTEMS KNOWL, P117; Herrera F, 1997, FUZZY SET SYST, V92, P21, DOI 10.1016/S0165-0114(96)00179-0; Hong T. P., 1999, INTELL DATA ANAL, V3, P363, DOI 10.1016/S1088-467X(99)00028-1; Hong TP, 2001, INT J UNCERTAIN FUZZ, V9, P587, DOI 10.1142/S0218488501001071; Hong TP, 1996, FUZZY SET SYST, V84, P33, DOI 10.1016/0165-0114(95)00305-3; Hong TP, 1997, IEEE T KNOWL DATA EN, V9, P336; Hong TP, 1999, FUZZY SET SYST, V103, P389; Hong TP, 2000, FUZZY SET SYST, V112, P127, DOI 10.1016/S0165-0114(98)00179-1; Hou RH, 1997, J AUTOM REASONING, V18, P5, DOI 10.1023/A:1005726727996; Kandel A, 1992, FUZZY EXPERT SYSTEMS, P8; Kaya M, 2003, IEEE INT CONF FUZZY, P881; Lee YC, 2004, LECT NOTES COMPUT SC, V3214, P1283; Mamdani E.H., 1974, IEEE P, P1585; PARODI A, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P223; Roubos H, 2001, IEEE T FUZZY SYST, V9, P516, DOI 10.1109/91.940965; Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575; SRINIVAS M, 1994, COMPUTER, V27, P17, DOI 10.1109/2.294849; Wang C. H., 1998, IEEE T EVOLUTIONARY, V2, P138; Wang CH, 2000, FUZZY SET SYST, V112, P141, DOI 10.1016/S0165-0114(97)00385-0; Wang WL, 2000, IEEE-EMBS ASIA PACIFIC CONFERENCE ON BIOMEDICAL ENGINEERING - PROCEEDINGS, PTS 1 & 2, P131; Weber R., 1992, 2 INT C FUZZ LOG NEU, P265; Yue S., 2000, IEEE INT C SYST MAN, P1906	25	40	42	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	SEP	2006	10	11					1091	1101		10.1007/s00500-006-0046-x		11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	053PW	WOS:000238318100011	
J	Wang, H				Wang, H			Nearest neighbors by neighborhood counting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; machine learning; nearest neighbors; distance; similarity; neighborhood counting measure	CLASSIFICATION	Finding nearest neighbors is a general idea that underlies many artificial intelligence tasks, including machine learning, data mining, natural language understanding, and information retrieval. This idea is explicitly used in the k- nearest neighbors algorithm ( kNN), a popular classification method. In this paper, this idea is adopted in the development of a general methodology, neighborhood counting, for devising similarity functions. We turn our focus from neighbors to neighborhoods, a region in the data space covering the data point in question. To measure the similarity between two data points, we consider all neighborhoods that cover both data points. We propose to use the number of such neighborhoods as a measure of similarity. Neighborhood can be defined for different types of data in different ways. Here, we consider one definition of neighborhood for multivariate data and derive a formula for such similarity, called neighborhood counting measure or NCM. NCM was tested experimentally in the framework of kNN. Experiments show that NCM is generally comparable to VDM and its variants, the state- of- the- art distance functions for multivariate data, and, at the same time, is consistently better for relatively large k values. Additionally, NCM consistently outperforms HEOM ( a mixture of Euclidean and Hamming distances), the " standard" and most widely used distance function for multivariate data. NCM has a computational complexity in the same order as the standard Euclidean distance function and NCM is task independent and works for numerical and categorical data in a conceptually uniform way. The neighborhood counting methodology is proven sound for multivariate data experimentally. We hope it will work for other types of data.	Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland; Univ Metz, LITA, F-57045 Metz, France	Wang, H (reprint author), Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland.	h.wang@ulster.ac.uk	jia, lp/H-5750-2011				Ash R., 2000, PROBABILITY MEASURE; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Blake C, 1998, UCI REPOSITORY MACHI; Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DOMINGOS P, 1995, P 1995 INT JOINT C A; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; ELKAN C, 1999, RESULTS KDD 99 CLASS; Fix E., 1951, TR4 US AIR FORC SCH; Gardenfors P., 2000, CONCEPTUAL SPACES GE; Hand D. J., 2001, PRINCIPLES DATA MINI; HAYASHI H, 2001, OPTIMIZATION NEAREST; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; MITCHELL TM, 1997, MACHINE LEARING; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; OSBORNE H, 1997, P INT WORKSH SIM CAT, P173; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SNEDECOR GW, 2002, STAT METHODS; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STEVENS SS, 1951, MATH MEASUREMENT PSY; TOWELL GG, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P861; Wang H, 2004, INT J APPROX REASON, V36, P223, DOI 10.1016/j.ijar.2003.10.007; Widdows D., 2004, GEOMETRY MEANING; Wikipedia Foundation, WIK FREE ENC; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	29	40	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					942	953				12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	031WB	WOS:000236734400008	
J	Chi, Y; Xia, Y; Yang, YR; Muntz, RR				Chi, Y; Xia, Y; Yang, YR; Muntz, RR			Mining closed and maximal frequent subtrees from databases of labeled rooted trees	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						trees; graph algorithms; data mining; mining methods and algorithms; frequent subtree; closed frequent subtree; maximal frequent subtree		Tree structures are used extensively in domains such as computational biology, pattern recognition, XML databases, computer networks, and so on. One important problem in mining databases of trees is to find frequently occurring subtrees. Because of the combinatorial explosion, the number of frequent subtrees usually grows exponentially with the size of frequent subtrees and, therefore, mining all frequent subtrees becomes infeasible for large tree sizes. In this paper, we present CMTreeMiner, a computationally efficient algorithm that discovers only closed and maximal frequent subtrees in a database of labeled rooted trees, where the rooted trees can be either ordered or unordered. The algorithm mines both closed and maximal frequent subtrees by traversing an enumeration tree that systematically enumerates all frequent subtrees. Several techniques are proposed to prune the branches of the enumeration tree that do not correspond to closed or maximal frequent subtrees. Heuristic techniques are used to arrange the order of computation so that relatively expensive computation is avoided as much as possible. We study the performance of our algorithm through extensive experiments, using both synthetic data and data sets from real applications. The experimental results show that our algorithm is very efficient in reducing the search space and quickly discovers all closed and maximal frequent subtrees.	Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	Chi, Y (reprint author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.	ychi@cs.ula.edu; xiayi@cs.ucla.edu; yyr@cs.ucla.edu; muntz@cs.ucla.edu					ASAI T, 2002, P 2 SIAM INT C DAT M; ASAI T, 2003, P 6 INT C DISC SCI O; CHALMERS R, 2002, TOPOLOGY MULTICAST T; CHI Y, 2003, P INT C DAT MIN ICDM; CHI Y, 2004, P 8 PAC AS C KNOWL D; Chi Y., 2004, P 16 INT C SCI STAT; CHI Y, IN PRESS KNOWLEDGE I; CUI J, 2002, P IFIP NETW C 2002 M; Garey M. R., 1979, COMPUTERS INTRACTABI; HAN J, 2000, P INT C MAN DAT ACM; Hein J, 1996, DISCRETE APPL MATH, V71, P153, DOI 10.1016/S0166-218X(96)00062-5; HUAN J, 2003, P INT C DAT MIN ICDM; Inokuchi A., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); KUDO T, 2003, FREQT IMPLEMENTATION; KURAMOCHI M, 2001, P INT C DAT MIN ICDM; LUCCIO F, 2004, TR0413 U PIS; NIJSSEN S, 2003, P INT WORKSH MIN GRA; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; RUCKERT U, 2004, P ACM S APPL COMP SA; SHASHA D, 2004, P 20 INT C DAT ENG; WANG C, 2004, P 8 PAC AS C KNOWL D; Wang K., 1998, P SIGIR, P146, DOI 10.1145/290941.290982; XIAO Y, 2003, P INT C DAT MIN ICDM; YAN X, 2003, P INT C KNOWL DISC D; YAN X, 2002, P INT C DAT MIN ICDM; YANG LH, 2003, P 8 INT C DAT SYST A; ZAKI MJ, 2002, P 8 INT C KNOWL DISC; ZAKI MJ, 2003, P INT C KNOWL DISC D	28	40	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2005	17	2					190	202				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	879KD	WOS:000225715800004	
J	Yamanishi, K; Takeuchi, JI; Williams, G; Milne, P				Yamanishi, K; Takeuchi, JI; Williams, G; Milne, P			On-line unsupervised outlier detection using finite mixtures with discounting learning algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						outlier detection; intrusion detection; anomaly detection; fraud detection; finite mixture model; EM algorithm		Outlier detection is a fundamental issue in data mining, specifically in fraud detection, network intrusion detection, network monitoring, etc. SmartSifter is an outlier detection engine addressing this problem from the viewpoint of statistical learning theory. This paper provides a theoretical basis for SmartSifter and empirically demonstrates its effectiveness. SmartSifter detects outliers in an on-line process through the on-line unsupervised learning of a probabilistic model ( using a finite mixture model) of the information source. Each time a datum is input SmartSifter employs an on-line discounting learning algorithm to learn the probabilistic model. A score is given to the datum based on the learned model with a high score indicating a high possibility of being a statistical outlier. The novel features of SmartSifter are: ( 1) it is adaptive to non-stationary sources of data; ( 2) a score has a clear statistical/information-theoretic meaning; ( 3) it is computationally inexpensive; and ( 4) it can handle both categorical and continuous variables. An experimental application to network intrusion detection shows that SmartSifter was able to identify data with high scores that corresponded to attacks, with low computational costs. Further experimental application has identified a number of meaningful rare cases in actual health insurance pathology data from Australia's Health Insurance Commission.	NEC Corp Ltd, Internet Syst Res Labs, Kanagawa 2168555, Japan; CSIRO Math & Informat Sci, Data Min Grp, Canberra, ACT 2601, Australia	Yamanishi, K (reprint author), NEC Corp Ltd, Internet Syst Res Labs, 4-1-1 Miyazaki, Kanagawa 2168555, Japan.	k-yamanishi@cw.jp.nec.com; tak@ap.jp.nec.com; Graham.Williams@cmis.csiro.au; Peter.Milne@cmis.csiro.au					Allan J., 1998, P DARPA BROADC NEWS, P194; Barnett V., 1994, OUTLIERS STAT DATA; Bonchi F., 1999, P 5 ACM SIGKDD INT C, P175, DOI 10.1145/312129.312224; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Cover T. M., 1991, ELEMENTS INFORMATION; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Fawcett T., 1999, P 5 ACM SIGKDD INT C, P53, DOI 10.1145/312129.312195; FAWCETT T, 1997, P AI APPR FRAUD DET, P14; GRABEC I, 1990, BIOL CYBERN, V63, P403, DOI 10.1007/BF00202757; Guralnik V, 1999, P 5 ACM SIGKDD INT C, P33, DOI 10.1145/312129.312190; Hawkins D. M., 1980, IDENTIFICATION OUTLI; Hunt L.A., 1999, AUST NZ J STAT, V40, P153; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211; KRICHEVSKY RE, 1981, IEEE T INFORM THEORY, V27, P199, DOI 10.1109/TIT.1981.1056331; LANE T, 1998, P KDD 98, P66; Lee W., 1999, P 5 ACM SIGKDD INT C, P114, DOI 10.1145/312129.312212; LEE W, 1998, P KDD 98; MARRON JS, 1992, ANN STAT, V20, P712, DOI 10.1214/aos/1176348653; MCLACHLAN G., 2000, WILEY SERIES PROBABI; MOREAU Y, DETECTION MOBILE PHO; NEAL R, 1993, VIEW EM ALGORITHM JU; NG SK, 2002, IN PRESS STAT COMPUT; P Burge, 1997, P AI APPR FRAUD DET, P9; Rocke DM, 1996, ANN STAT, V24, P1327, DOI 10.1214/aos/1032526972; ROSSET S, 1999, P 5 ACM SIGKDD INT C, P409, DOI 10.1145/312129.312303; WILLIAMS GJ, 1997, ADV TOPICS ARTIFICIA, V1342, P340, DOI 10.1007/3-540-63797-4_87; Yamanishi K., 2000, P 6 ACM SIGKDD INT C, P250	28	40	41	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2004	8	3					275	300		10.1023/B:DAMI.0000023676.72185.7c		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	812CQ	WOS:000220818000004	
J	Mitra, P; Murthy, CA; Pal, SK				Mitra, P; Murthy, CA; Pal, SK			A probabilistic active support vector learning algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data mining; learning theory; query learning; incremental learning; statistical query model; classification		The paper describes a probabilistic active learning strategy for support vector machine (SVM) design in large data applications. The learning strategy is motivated by the statistical query model. While most existing methods of active SVM learning query for points based on their proximity to the current separating hyperplane, the proposed method queries for a set of points according to a distribution as determined by the current separating hyperplane and a newly defined concept of an adaptive confidence factor. This enables the algorithm to have more robust and efficient learning capabilities. The confidence factor is estimated from local information using the k nearest neighbor principle. The effectiveness of the method is demonstrated on real-life data sets both in terms of generalization performance, query complexity, and training time.	Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, W Bengal, India	Mitra, P (reprint author), Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, W Bengal, India.	pabitra_r@isical.ac.in; murthy@isical.ac.in; sankar@isical.ac.in	Pal, Sankar /G-2243-2010				Blake C, 1998, UCI REPOSITORY MACHI; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P1, DOI [DOI 10.1023/A:1009715923555, 10.1023/A:1009715923555]; Campbell C., 2000, P 17 INT C MACH LEAR, P111; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; KAUFMAN L, 1998, ADV KERNEL METHODS S, P147; Kearns M., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167200; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; MANDAL DP, 1992, INT J GEN SYST, V20, P307, DOI 10.1080/03081079208945038; MITRA P, 2000, P 15 INT C PATT REC, P712; Platt J.C., 1998, ADV KERNEL METHODS S, P185; SAYEED NA, 1999, P 1 INT C KNOWL DISC, P272; Schohn G., 2000, P 17 INT C MACH LEAR, P839; Scholkopf B., 1998, ADV KERNEL METHODS S; Seo S., 2000, P INT JOINT C NEUR N, V3, P241; TIPPING ME, 2003, P INT WORKSH AL STAT; Tong S, 2009, J MACHINE LEARNING R, V2, P45, DOI 10.1162/153244302760185243; Vapnik V. N., 1998, STAT LEARNING THEORY; WILLIAMS CKI, 2001, P ADV NEUR INF PROC, V14	18	40	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					413	418		10.1109/TPAMI.2004.1262340		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	773WZ	WOS:000188949400012	
J	Bojarczuk, CC; Lopes, HS; Freitas, AA; Michalkiewicz, EL				Bojarczuk, CC; Lopes, HS; Freitas, AA; Michalkiewicz, EL			A constrained-syntax genetic programming system for discovering classification rules: application to medical data sets	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						constrained-syntax genetic programming; data mining; classification rules		This paper proposes a new constrained-syntax genetic programming (GP) algorithm for discovering classification rules in medical data sets. The proposed GP contains several syntactic constraints to be enforced by the system using a disjunctive normal form representation, so that individuals represent valid rule sets that are easy to interpret. The GP is compared with C4.5, a well-known decision-tree-building algorithm, and with another GP that uses Boolean inputs (BGP), in five medical data sets: chest pain, Ljubljana breast cancer, dermatology, Wisconsin breast cancer, and pediatric adrenocortical tumor. For this last data set a new preprocessing step was devised for survival prediction. Computational experiments show that, overall, the GP algorithm obtained good results with respect to predictive accuracy and rule comprehensibility, by comparison with C4.5 and BGP. (C) 2004 Elsevier B.V. All rights reserved.	Ctr Fed Educ Tecnol Parana, CEFETPR, CPGEI, Lab Bioinformat, BR-80230901 Curitiba, Parana, Brazil; Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England; Hosp Erasto Gaertner, Setor Cirurgia Pediat, BR-81520060 Curitiba, Parana, Brazil	Lopes, HS (reprint author), Ctr Fed Educ Tecnol Parana, CEFETPR, CPGEI, Lab Bioinformat, Av 7 Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.	celiacri@cefetpr.br; hslopes@cefetpr.br; a.a.freitas@kent.ac.uk; emichalk@netpar.com.br	Freitas, Alex/H-1249-2011				Banzhaf W., 1998, GENETIC PROGRAMMING; BOJARCZUK CC, 2003, P 6 EUR C GEN PROGR, P11; Bojarczuk CC, 2000, IEEE ENG MED BIOL, V19, P38, DOI 10.1109/51.853480; CLACK C, 1998, P 3 ANN C GEN PROGR, P416; Dhar V, 2000, DATA MIN KNOWL DISC, V4, P251, DOI 10.1023/A:1009848126475; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FREEMAN JJ, 1998, P 3 ANN C GEN PROGR, P72; FREITAS A, 2002, HDB DATA MINING KNOW, P698; Freitas A. A., 2002, ADV EVOLUTIONARY COM, P819; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Freitas A.A., 2002, DATA MINING KNOWLEDG; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Gruau F., 1992, 9221 EC NORM SUP LYO; Hand DJ, 1997, CONSTRUCTION ASSESSM; JANIKOW CZ, 1998, P 3 ANN C GEN PROGR, P73; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; Koza J. R., 1992, GENETIC PROGRAMMING; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Wong ML, 2000, GENET PROGR SER, V3, P1; LOPES HS, 1997, MED BIOL ENG COM 1 S, V35, P514; Mitchell T. M, 1997, MACHINE LEARNING; Montana DJ, 1995, EVOL COMPUT, V3, P199, DOI 10.1162/evco.1995.3.2.199; NGAN PS, 1998, P 3 ANN GEN PROGR C, P254; Papagelis A, 2001, P 18 INT C MACH LEAR, P393; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Taylor C.C., 1994, MACHINE LEARNING NEU; Veloso M., 1996, SYMBOLIC VISUAL LEAR, P81; Whigham P. A., 1995, P WORKSH GEN PROGR T, P33; Witten IH, 2000, DATA MINING PRACTICA	31	40	40	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	JAN	2004	30	1					27	48		10.1016/j.artmed.2003.06.001		22	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	765NQ	WOS:000188290200002	
S	Dwork, C; Nissim, K		Franklin, M		Dwork, C; Nissim, K			Privacy-preserving datamining on vertically partitioned databases	ADVANCS IN CRYPTOLOGY - CRYPTO 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	24th Annual International Cryptology Conference	AUG 15-19, 2004	Sant Barbara, CA	Int Assoc Cryptol Res, IEEE Comp Soc, TC Secur & Privacy, Univ Calif Santa Barbara, Comp Sci Dept		data privacy; statistical databases; data mining; vertically partitioned databases			SVC, Microsoft Res, Mountain View, CA 94043 USA	Dwork, C (reprint author), SVC, Microsoft Res, 1065 La Avenida, Mountain View, CA 94043 USA.	dwork@microsoft.com; kobbi@microsoft.com	Nissim, Kobbi/B-4912-2012; Nissim, Kobbi/F-1442-2012	Nissim, Kobbi/0000-0002-6632-8645; 			ADAM NR, 1989, COMPUT SURV, V21, P515; Agrawal D., 2001, P 20 S PRINC DAT SYS; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; CHAWLA S, 2004, UNPUB PRIVACY PUBLIC; Dinur I., 2003, P 22 ACM SIGACT SIGM, P202, DOI DOI 10.1145/773153.773173; DUNCAN G, 2001, INT ENCY SOCIAL BEHA; Evfimievski A., 2003, P 22 ACM SIGMOD SIGA, P211, DOI 10.1145/773153.773174; FIENBERG S, 2000, IAOS C STAT DEV HUM; Fienberg S.E., 1998, J OFF STAT, V14, P485; FRANCONI L, 2003, 30 UN STAT COMM EUR; Goldwasser S, 1982, STOC, P365; Raghunathan T. E., 2003, J OFF STAT, V19, P1; Rubin D.B., 1993, J OFF STAT, V9, P461; Shoshani A., 1982, Proceedings of Very Large Data Bases. Eighth International Conference on Very Large Data Bases	14	40	40	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22668-0	LECT NOTES COMPUT SC			2004	3152						528	544				17	Computer Science, Theory & Methods	Computer Science	BAU22	WOS:000223568800032	
J	Harms, SK; Deogun, JS				Harms, SK; Deogun, JS			Sequential association rule mining with time lags	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article; Proceedings Paper	13th International Symposium on Methodologies for Intelligent Systems (ISMIS 2002)	JUN 27-29, 2002	LYON, FRANCE	Univ Claude Bernard Lyon 1, Univ Lumiere Lyon 2, Inst Natl Sci Appl Lyon		sequential rule discovery; time lag; knowledge discovery; drought risk management		This paper presents MOWCATL, an efficient method for mining frequent association rules from multiple sequential data sets. Our goal is to find patterns in one or more sequences that precede the occurrence of patterns in other sequences. Recent work has highlighted the importance of using constraints to focus the mining process on the association rules relevant to the user. To refine the data mining process, this approach introduces the use of separate antecedent and consequent inclusion constraints, in addition to the traditional frequency and support constraints in sequential data mining. Moreover, separate antecedent and consequent maximum window widths are used to specify the antecedent and consequent patterns that are separated by either a maximal width time lag or a fixed width time lag. Multiple time series drought risk management data are used to show that our approach can be effectively employed in real-life problems. This approach is compared to existing methods to show how they complement each other to discover associations in the drought risk management domain. The experimental results validate the superior performance of our method for efficiently finding relationships between global climatic episodes and local drought conditions. Both the maximal and fixed width time lags are shown to be useful when finding interesting associations.	Univ Nebraska, Dept Comp Sci & Informat Syst, Kearney, NE 68849 USA; Univ Nebraska, Dept Comp Sci & Comp Engn, Lincoln, NE 68588 USA	Harms, SK (reprint author), Univ Nebraska, Dept Comp Sci & Informat Syst, Kearney, NE 68849 USA.						Bettini C, 1998, IEEE T KNOWL DATA EN, V10, P222, DOI 10.1109/69.683754; CONG G, 2002, P 2002 IEEE INT C DA; FENG L, 1999, P 1999 INT C INF KNO; Goddard S, 2003, COMMUN ACM, V46, P35; Goldin D. Q., 1995, Principles and Practice of Constraint Programming - CP '95. First International Conference, CP'95. Proceedings; Harms S. K., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989576; HARMS SK, 2002, P 2002 INT S METH IN, P432; KRYSZKIEWICZ M, 1998, LECT NOTES ARTIF INT, V1424, P214; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Mannila H., 1997, C199715 U HELS DEP C; MCGEE TB, 1995, P 9 C APPL CLIM BOST, P233; NG RT, 1998, P 1998 ACM SIGMOD IN; ROSS T, 2000, 200002 US DEP COMM N; Zaki M. J., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354849; Srikant R., 1996, P 5 INT C EXT DAT TE; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Tan P., 2001, KDD 2001 WORKSH TEMP; WILHITE DA, 2000, DROUGHT, V2, P3; *US DROUGHT MON, 2002, HOST MAINT NAT DROUG	19	40	45	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	JAN	2004	22	1					7	22		10.1023/A:1025824629047		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	725ZC	WOS:000185571500002	
S	Lin, TY		Wang, GY; Liu, Q; Yao, YY; Skowron, A		Lin, TY			Granular computing - Structures, representations, and applications	ROUGH SETS, FUZZY SETS, DATA MINING, AND GRANULAR COMPUTING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th International Conference on Rough Sets, Fuzzy Sets, Data Mining and Grandular Computing (RSFDGrC 2003)	MAY 26-29, 2003	CHONGQING, PEOPLES R CHINA	Natl Nat Sci Fdn China, Chongqing Municipal Educ Comm, Chongqing Municipal Sci & Technol Comm, Chongqing Bur Informat Ind		granular computing; rough set; binary relation; conflict of interests	CONFLICTS; LOGIC	The structure and representation theories of (crisp/fuzzy) granulations are presented. The results are applied to data mining, fuzzy control, security and etc.	San Jose State Univ, Dept Comp Sci, San Jose, CA 95192 USA	Lin, TY (reprint author), San Jose State Univ, Dept Comp Sci, San Jose, CA 95192 USA.						Bargiela A, 2002, P INT COMP SOFTW APP, P1164, DOI 10.1109/CMPSAC.2002.1045169; Brewer D. C., 1988, IEEE S SEC PRIV OAKL, P206; Date C. J., 2000, INTRO DATABASE SYSTE; Garcia-Molina H., 2002, DATABASE SYSTEMS COM; Kelly J. L., 1955, GEN TOPOLOGY; Lin T. Y., 2002, DATA MINING ROUGH SE; Lin T. Y., 1999, COMPUTING WORDS INFO, P183; Lin TY, 2002, LECT NOTES ARTIF INT, V2475, P296; Lin TY, 2002, P INT COMP SOFTW APP, P966, DOI 10.1109/CMPSAC.2002.1045131; Lin T.Y., 1998, ROUGH SETS KNOWLEDGE, P121; LIN TY, 1998, LECT NOTES ARTIF INT, V1424, P387; Lin T. Y., 1994, Rough Sets, Fuzzy Sets and Knowledge Discovery. Proceedings of the International Workshop on Rough Sets and Knowledge Discovery (RSKD'93); Lin TY, 1989, P 5 AER COMP SEC APP, P286; Lin T.Y., 2001, GRANULAR COMPUTING E, P125; Lin T.Y., 1998, ROUGH SETS KNOWLEDGE, P107; LIN TY, 2002, LECT NOTES ARTIF INT, P14; Lin TY, 1988, P 1988 ACM 16 ANN CO, P725, DOI 10.1145/322609.323183; LIN TY, 2001, LECT NOTES ARTIF INT, V2035, P174; LIN TY, 1999, LECT NOTES ARTIF INT, V1574, P24; Lin TY, 1989, P 4 INT S METH INT S, P75; LIN TY, 1996, P 4 INT WORKSH ROUGH, P404; Lin TY, 2000, APPL INTELL, V13, P113, DOI 10.1023/A:1008384328214; LIN TY, 2001, LECT NOTES ARTIF INT, P125; LIN TY, 2003, P INT C ROUGH SETS F; LIN TY, 2002, P INT C DAT MIN MAEB, P282; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 1997, JOINT C INF SCI RES, P350; PAWLAK Z, 1984, INT J MAN MACH STUD, V21, P127, DOI 10.1016/S0020-7373(84)80062-0; PEDRYCZ W, 2002, GRANULAR COMPUTING; VIVEROS M, 1989, THESIS CALIFORNIA ST; Yao J.T, 2002, PAKDD 2002 WORKSH EN, V5, P101; YAO YY, 2002, DATA MINING ROUGH SE, P102; ZADEH L, 1996, 1996 IEEE INT C FUZZ, P1; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; ZADEH LA, 2002, DATA MINING ROUGH SE; Zadeh L.A., 1979, ADV FUZZY SET THEORY, P3; ZHONG N, 1999, LNCS, V1711; *ACM, 1989, P 1989 ACM 17 ANN CO, P453	38	40	40	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-14040-9	LECT NOTES ARTIF INT			2003	2639						16	24				9	Computer Science, Artificial Intelligence	Computer Science	BX12N	WOS:000184350600003	
J	Braha, D; Shmilovici, A				Braha, D; Shmilovici, A			Data mining for improving a cleaning process in the semiconductor industry	IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING			English	Article						composite classifiers; data mining; laser cleaning; machine learning	YIELD	As device geometry continues to shrink, micro-contaminants have an increasingly negative impact on yield. By diminishing the contamination problem, semiconductor manufacturers will significantly improve the wafer yield. This paper presents a comprehensive and successful application of data mining methodologies to the refinement of a new dry cleaning technology that utilizes a laser beam for the removal of micro-contaminants. Experiments with three classification-based data mining methods (decision tree induction, neural networks, and composite classifiers) have been conducted. The composite classifier architecture has been shown to yield higher accuracy than the accuracy of each individual classifier on its own. The paper suggests that data mining methodologies may be particularly useful when data is scarce, and the various physical and chemical parameters that affect the process exhibit highly complex interactions. Another implication is that on-line monitoring of the cleaning process using data mining may be highly effective.	MIT, Ctr Innovat Prod Dev, Cambridge, MA 02139 USA; Ben Gurion Univ Negev, Dept Ind Engn & Management, IL-84105 Beer Sheva, Israel	Braha, D (reprint author), MIT, Ctr Innovat Prod Dev, 77 Massachusetts Ave, Cambridge, MA 02139 USA.		SHMILOVICI, ARMIN/F-2136-2012				ANAND SS, 1997, DECISION SUPPORT USI; BENEDIKTSSON JA, 1993, P IEEE INT C NEUR NE, P27; Berry M. R. J., 1997, DATA MINING TECHNIQU; Brachman R., 1996, ADV KNOWLEDGE DISCOV; Braha D, 2001, DATA MINING DESIGN M; BREIMAN L, 1994, BAGGING PREDICTORS, P421; BRODLEY CE, 1994, RECURSIVE AUTOMATIC; CLEMEN RT, 1989, INT J FORECASTING, V5, P559, DOI 10.1016/0169-2070(89)90012-5; CUNNINGHAM SP, 1995, IEEE T SEMICONDUCT M, V8, P103, DOI 10.1109/66.382273; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; GENUT M, 1998, P SPIE, V3274; Hertz J, 1991, INTRO THEORY NEURAL; Klir G. J., 1985, ARCHITECTURE SYSTEMS; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kuo W, 1999, P IEEE, V87, P1329; LIVSHITS B, 1997, SOLID STATE TECHNOL, V197, P197; Mitchell T. M, 1997, MACHINE LEARNING; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SKALAK DB, 1995, PROTOTYPE SELECTION; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; TAM AC, 1992, J APPL PHYS, V71, P3515, DOI 10.1063/1.350906; WOLPERT D, 1993, LECT COMPLEX SYSTEMS; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; ZHANG X, 1992, J MOL BIOL, V225, P1049, DOI 10.1016/0022-2836(92)90104-R; ORAMIR SEMICONDUCTOR	26	40	42	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0894-6507		IEEE T SEMICONDUCT M	IEEE Trans. Semicond. Manuf.	FEB	2002	15	1					91	101		10.1109/66.983448		11	Engineering, Manufacturing; Engineering, Electrical & Electronic; Physics, Applied; Physics, Condensed Matter	Engineering; Physics	521MH	WOS:000173843400011	
J	Abidi, SSR				Abidi, SSR			Knowledge management in healthcare: towards 'knowledge-driven' decision-support services	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						knowledge management; data mining; decision-support; healthcare enterprise memory; strategic decision-support services; healthcare delivery info-structure		In this paper, we highlight the involvement of Knowledge Management in a healthcare enterprise. We argue that the 'knowledge quotient' of a healthcare enterprise can be enhanced by procuring diverse facets of knowledge from the seemingly placid healthcare data repositories, and subsequently operationalising the procured knowledge to derive a suite of Strategic Healthcare Decision-Support Services that can impact strategic decision-making, planning and management of the healthcare enterprise. In this paper, we firstly present a reference Knowledge Management environment-a Healthcare Enterprise Memory-with the functionality to acquire, share and operationalise the various modalities of healthcare knowledge. Next, we present the functional and architectural specification of a Strategic Healthcare Decision-Support Services Info-structure, which effectuates a synergy between knowledge procurement (vis-a-vis Data Mining) and knowledge operationalisation (vis-a-vis Knowledge Management) techniques to generate a suite of strategic knowledge-driven decision-support services. In conclusion, we argue that the proposed Healthcare Enterprise Memory is an attempt to rethink the possible sources of leverage to improve healthcare delivery, hereby providing a valuable strategic planning and management resource to healthcare policy makers. (C) 2001 Elsevier Science Ireland Ltd. All rights reserved.	Univ Sains Malaysia, Sch Comp Sci, Hlth Informat Res Grp, George Town 11800, Malaysia	Abidi, SSR (reprint author), Univ Sains Malaysia, Sch Comp Sci, Hlth Informat Res Grp, George Town 11800, Malaysia.		Wang, Charles/B-5565-2011				Abecker A, 1998, IEEE INTELL SYST APP, V13, P40, DOI 10.1109/5254.683209; ABIDI S, 1998, 9 WORLD C MED INF ME; ABIDI SSR, 1999, MED INFORMATICS EURO; Abidi S. S. R., 1997, Informatica, V21; Abidi S.S.R., 2000, 3 INT C PRACT APPL K; ABIDI SSR, 1998, INT C MULT INF TECHN; ABIDI SSR, 1998, LECT NOTES ART INT; BABIC A, 1999, MED INFORMATICS EURO; Chandrasekaran B, 1999, IEEE INTELL SYST APP, V14, P20, DOI 10.1109/5254.747902; CHEAH YN, 2000, 3 INT C PRACT APPL K; CHEAH YN, 1999, MED INFORMATICS EURO; CHEAH YN, 1999, JOINT C ART INT IJCA; Davenprot T. H., 1998, SLOAN MANAGEMENT WIN, P43; EUZENAT J, 1996, CORPORATE MEMORY COO; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Gruber T.R., 1993, INT WORKSH FORM ONT; HAN JW, 1999, IEEE COMPUTER    AUG; HOLENA M, 1999, MED INFORMATICS EURO; KIRCHER A, 1999, MED INFORMATICS EURO; Lavrac N, 1997, INTELLIGENT DATA ANA; O'Leary DE, 1998, IEEE INTELL SYST APP, V13, P30, DOI 10.1109/MIS.1998.683179; Sveiby K. E., 1997, NEW ORG WEALTH MANAG; ZUPAN B, 1999, DATA MINING TECHNIQU, P15; *CRFP GOV MAL, 1997, CRFP TEL FLAGSH APPL	24	40	40	ELSEVIER SCI IRELAND LTD	CLARE	CUSTOMER RELATIONS MANAGER, BAY 15, SHANNON INDUSTRIAL ESTATE CO, CLARE, IRELAND	1386-5056		INT J MED INFORM	Int. J. Med. Inform.	SEP	2001	63	1-2					5	18		10.1016/S1386-5056(01)00167-8		14	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	471LV	WOS:000170931600002	
J	Fukuda, T; Morimoto, Y; Morishita, S; Tokuyama, T				Fukuda, T; Morimoto, Y; Morishita, S; Tokuyama, T			Data mining with optimized two-dimensional association rules	ACM TRANSACTIONS ON DATABASE SYSTEMS			English	Article						algorithms; management; association rules; convex hull searching; data mining; image segmentation; matrix searching	SEGMENTATION	We discuss data mining based on association rules for two numeric attributes and one Boolean attribute. For example, in a database of bank customers, "Age" and "Balance" are two numeric attributes, and "CardLoan" is a Boolean attribute. Taking the pair (Age, Balance) as a point in two-dimensional space, we consider an association rule of the form ((Age, Balance) is an element of P) double right arrow (CardLoan = Yes), which implies that bank customers whose ages and balances fall within a planar region P tend to take out credit card loans with a high probability. We consider two classes of regions, rectangles and admissible (i.e., connected and x-monotone) regions. For each class, we propose efficient algorithms for computing the regions that give optimal association rules for gain, support, and confidence, respectively. We have implemented the algorithms for admissible regions as well as several advanced functions based on them in our data mining system named SONAR (System for Optimized Numeric Association Rules), where the rules are visualized by using a graphic user interface to make it easy for users to gain an intuitive understanding of rules.	IBM Corp, Tokyo Res Lab, Kanagawa 242, Japan; Univ Tokyo, Tokyo, Japan	Fukuda, T (reprint author), IBM Corp, Tokyo Res Lab, 1623-14 Shimo Tsuruma, Kanagawa 242, Japan.	fukudat@trl.ibm.co.jp; morimoto@trl.ibm.co.jp; ShinichiMorishita@acm.org; ttoku@trl.ibm.co.jp	Morimoto, Yasuhiko/D-8282-2011				AGGARWAL A, 1987, ALGORITHMICA, V2, P209; AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; AGRAWAL R, 1992, PROC INT CONF VERY L, P560; Asano T, 1996, PROCEEDINGS OF THE SEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P104; Bentley J., 1984, Communications of the ACM, V27, DOI 10.1145/358234.381162; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Breiman L, 1984, CLASSIFICATION REGRE; FISCHER P, 1993, P 9 INT C FUND COMP; FUKUDA T, 1996, P ACM SIGMOD C MAN D, P553, DOI 10.1145/233269.280359; Fukuda T., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237708; Fukuda T, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P146; GAREY MR, 1977, SIAM J APPL MATH, V32, P836; HAN JW, 1992, PROC INT CONF VERY L, P547; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; Karp R.M., 1972, COMPLEXITY COMPUTER, P85; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Keim D. A., 1994, Proceedings. The 10th International Conference Data Engineering (Cat. No.94CH3383-7), DOI 10.1109/ICDE.1994.283045; Mehta M., 1996, P 5 INT C EXT DAT TE; MORIMOTO Y, 1998, P KDD 98 WORKSH DAT; MORIMOTO Y, 1997, P 23 INT C VER LARG, P166; Morimoto Y., 1997, Constraints, V2, DOI 10.1023/A:1009755828992; NEMHAUSER GL, 1989, OPTIMIZATION HDB OPE, V1; Ng R, 1994, P 20 INT C VER LARG, P144; PARK SS, 1995, MATER LETT, V22, P175, DOI 10.1016/0167-577X(94)00241-X; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Piatetsky-Shapiro G., 1991, KNOWLEDGE DISCOVERY; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; STONEBRAKER M, 1993, P 19 VLDB C, P688; Yoda K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, DOI 10.1016/S0146-664X(76)80014-7	35	40	41	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0362-5915		ACM T DATABASE SYST	ACM Trans. Database Syst.	JUN	2001	26	2					179	213		10.1145/383891.383893		35	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	486YP	WOS:000171847200002	
J	Blockeel, H; de Raedt, L; Jacobs, N; Demoen, B				Blockeel, H; de Raedt, L; Jacobs, N; Demoen, B			Scaling up inductive logic programming by learning from interpretations	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						inductive logic programming; knowledge discovery in databases; first order decision trees; learning from interpretations	DISCOVERY	When comparing inductive logic programming (ILP) and attribute-value learning techniques, there is a trade-off between expressive power and efficiency. Inductive logic programming techniques are typically more expressive but also less efficient. Therefore, the data sets handled by current inductive logic programming systems are small according to general standards within the data mining community. The main source of inefficiency lies in the assumption that several examples may be related to each other, so they cannot be handled independently. Within the learning from interpretations framework for inductive logic programming this assumption is unnecessary, which allows to scale up existing ILP algorithms. In this paper we explain this learning setting in the context of relational databases. We relate the setting to propositional data mining and to the classical ILP setting, and show that learning from interpretations corresponds to learning from multiple relations and thus extends the expressiveness of propositional learning, while maintaining its efficiency to a large extent (which is not the case in the classical ILP setting). As a case study, we present two alternative implementations of the ILP system TILDE (Top-down Induction of Logical DEcision trees): TILDEclassic, which loads all data in main memory, and TILDELDS, which loads the examples one by one. We experimentally compare the implementations, showing TILDELDS can handle large data sets (in the order of 100,000 examples or 100 MB) and indeed scales up linearly in the number of examples.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium	Blockeel, H (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Heverlee, Belgium.						Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Blockeel H., 1997, LECT NOTES ARTIF INT, V1297, P77; Blockeel H, 1998, P 15 INT C MACH LEAR, P55; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; Bongard M.M., 1970, PATTERN RECOGNITION; BRATKO I, 1990, PROLOG PROGRAMMING A; BRATKO I, 1995, COMMUN ACM, V38, P65, DOI 10.1145/219717.219771; Breiman L, 1984, CLASSIFICATION REGRE; COHEN WW, NEW GEN COMPUTING, V13, P95; Cohen W. W., 1995, Journal of Artificial Intelligence Research, V2; CUSSENS J, 1997, LECT NOTES ARTIF INT, V1297, P93; Dehaspe L, 1997, LECT NOTES ARTIF INT, V1297, P125; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; DERAEDT L, 1998, IN PRESS LECT NOTES; DERAEDT L, 1996, FRONTIERS ARTIFICIAL, V32; DERAEDT L, 1998, LECT NOTES ARTIF INT, V446, P1; DERAEDT L, 1995, LECT NOTES ARTIF INT, V997, P80; DeRaedt L, 1997, ARTIF INTELL, V95, P187, DOI 10.1016/S0004-3702(97)00041-6; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Dougherty J, 1995, P 12 INT C MACH LEAR; Dzeroski S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130399; Elmasri R., 1989, FUNDAMENTALS DATABAS; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FURNKRANZ J, 1997, P 15 INT JOINT C ART, P852; FURNKRANZ J, 1997, P IJCAI 97 WORKSH FR; JACOBS N, 1998, P 8 INT C IND LOG PR, P145; KITANO H, 1997, P 15 INT JOINT C ART, P24; KRAMER S, 1996, P 13 NAT C ART INT A; LAVRAC N, 1997, LECT NOTES ARTIFICIA, V1297; Mehta M., 1996, P 5 INT C EXT DAT TE; Morik K, 1997, MACH LEARN, V27, P287, DOI 10.1023/A:1007317925872; MUGGLETON S, 1995, NEW GEN COMPUTING, V13; MUGGLETON S, 1997, LECT NOTES ARTIFICIA, V1314; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; MUGGLETON S, 1993, P 4 C ALG LEARN THEO; PAGE D, 1998, LECT NOTES ARTIFICIA, V1446; Plotkin G.D., 1970, MACH INTELL, V5, P153; QUINLAN J, 1993, LECT NOTES ARTIFICIA; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SEBAG M, 1998, LECT NOTES ARTIF INT, V1446, P95; Shafer J., 1996, P 22 INT C VER LARG; SRINIVASAN A, 1996, ARTIF INTELL, P85; VANLAER W, 1997, LECT NOTES ARTIF INT, V1325, P277; WATANABE L, 1991, P 12 INT JOINT C ART, P770; WROBEL S, 1996, P 2 INT C KNOWL DISC	48	40	42	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAR	1999	3	1					59	93		10.1023/A:1009867806624		35	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	192WR	WOS:000080103100004	
B	Cai, CH; Fu, AWC; Cheng, CH; Kwong, WW			IEEE	Cai, CH; Fu, AWC; Cheng, CH; Kwong, WW			Mining association rules with weighted items	IDEAS 98 - INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS			English	Proceedings Paper	International Database Engineering and Applications Symposium (IDEAS 98)	JUL 08-10, 1998	CARDIFF, WALES	Concordia Univ, Univ Bradford, Cardiff Univ, IEEE, Comp Soc		data mining; association rules; basket data; support; confidence; weighted items		Discovery of association rules has been found useful in many applications. In previous work, all items in a basket database are treated uniformly. We generalize this to the case where items are given weights to reflect their importance to the user. The weights may correspond to special promotions on some products? or the profitability of different items. We can mine the weighted association rules with weights. The downward closure property of the support measure in the unweighted case no longer exist and previous algorithms cannot be applied. In this paper, two new algorithms will be introduced to handle this problem. In these algorithms we make use of a metric called the k-support bound in the mining process. Experimental results show the efficiency of the algorithms for large databases.	Chinese Univ Hong Kong, Dept Comp Sci & Engn, Sha Tin 100083, Hong Kong	Cai, CH (reprint author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Sha Tin 100083, Hong Kong.							0	40	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-8186-8308-2				1998							68	77				10	Computer Science, Information Systems	Computer Science	BL34E	WOS:000075209200011	
J	Zait, M; Messatfa, H				Zait, M; Messatfa, H			A comparative study of clustering methods	FUTURE GENERATION COMPUTER SYSTEMS			English	Article						clustering; data mining; data generation; unsupervised classification		In this paper we propose a methodology for comparing clustering methods based on the quality of the result and the performance of the execution. We applied it to several known clustering methods: FastClust, Autoclass, Relational data analysis, and Kohonen nets. The quality of a clustering result depends on both the similarity measure used by the method and its implementation. An important feature of our methodology is a synthetic data generation program that allows producing data sets with specific (or desired) patterns using a combination of parameters, such as the number and the type of the attributes, the number of records, etc. We define a metric to measure the quality of a clustering method, i.e., its ability to discover some or all of the ''hidden'' patterns. The performance study is based on the resource consumption, i.e., CPU time and memory space.	IBM SCI CTR,F-75592 PARIS 12,FRANCE	Zait, M (reprint author), ORACLE CORP,500 ORACLE PKWY,REDWOOD SHORES,CA 94065, USA.						AFZAL M, 1996, ANN S COMPUTATIONAL, P343; CHEESEMAN P, 1988, P 5 INT MACH LEARN C; Hartigan J.A., 1975, CLUSTERING ALGORITHM; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Mangiameli P, 1996, EUR J OPER RES, V93, P402, DOI 10.1016/0377-2217(96)00038-0; MARCOTORCHINO F, 1986, COMPSTAT P COMPUTATI; MESSATFA H, 1992, J CLASSIF, V9, P5, DOI 10.1007/BF02618465; MICHAUD P, 1997, FUTURE GENERATION CO; MICHAUD P, 1991, APPL STOCHASTIC MODE, V7; MURTAGH F, 1995, J CLASSIFICATION, V12; SNEATH P.H.A., 1973, NUMERICAL TAXONOMY P; *SAS I, 1995, SAS MANUAL	12	40	40	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-739X		FUTURE GENER COMP SY	Futur. Gener. Comp. Syst.	NOV	1997	13	2-3					149	159		10.1016/S0167-739X(97)00018-6		11	Computer Science, Theory & Methods	Computer Science	YJ828	WOS:A1997YJ82800005	
J	Xu, LD; Liang, N; Gao, Q				Xu, Lida; Liang, Ning; Gao, Qiong			An integrated approach for agricultural ecosystem management	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						enterprise information systems (EIS); information infrastructure; service industry; service sector; system integration; systems approach	DECISION-SUPPORT-SYSTEM; SUSTAINABLE DEVELOPMENT; INFORMATION-SYSTEM; SIMULATION; MODEL; IRRIGATION; DYNAMICS; NITROGEN; PROGRAM; DSIRR	Sustainable development and growth of agriculture sector calls for improving its competitiveness through a better understanding of lands, weather and climate, and planting, especially prediction of events with increased accuracy, and systematic integration of observations and prediction into decision-making in agriculture management. In this short paper, a systematic approach based on integrated information systems (IISs) for agricultural ecosystem management is proposed. The approach involves establishing an IIS called agricultural ecosystem enterprise information system (AEEIS) that extracts data on terrain, land use, planting, and others, and integrates them for the purpose of agricultural and ecosystem management. The integration helps in generating managerial/policy alternatives in consultation not only with agricultural and ecological specialists, but also with agriculture and ecosystems management. AEEIS, a platform of enterprise information systems, includes operational database, extract transform and load, data warehouse, data mining, simulation modeling, and knowledge management for generating managerial strategies on land use, planting species/variety, and optimal coverage of plants. AEEIS is part of efforts on integrated agricultural information services that is one of the main applications of China's sustainable agricultural development plan. The short paper concludes that, for effective management of agriculture and ecosystems, a systematic approach is essential in which IISs play a crucial role.	[Xu, Lida] Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China; [Xu, Lida] Old Dominion Univ, Dept Informat Technol & Decis Sci, Norfolk, VA 23529 USA; [Liang, Ning] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA; [Gao, Qiong] Beijing Normal Univ, Inst Resource Sci, Beijing 100875, Peoples R China	Xu, LD (reprint author), Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.	lxu@odu.edu; chenzz@ns.ibcas.ac.cn; gaoq@bun.edu.cn					Awad E.M, 2003, KNOWLEDGE MANAGEMENT; Barrington S, 2002, COMPUT ELECTRON AGR, V36, P79, DOI 10.1016/S0168-1699(02)00092-3; Bazzani GM, 2005, J ENVIRON MANAGE, V77, P301, DOI 10.1016/j.jenvman.2005.09.001; Bazzani GM, 2005, ENVIRON MODELL SOFTW, V20, P153, DOI 10.1016/j.envsoft.2003.12.017; Bretthauer KM, 2004, DECISION SCI, V35, P325, DOI 10.1111/j.0011-7315.2004.35031.x; Cabezas H, 2005, J CLEAN PROD, V13, P455, DOI 10.1016/j.jclepro.2003.09.011; Chaudhary S., 2008, P IEEE CROWNCOM 07 S, P1; Duan L, 2007, INFORM SYST, V32, P978, DOI 10.1016/j.is.2006.10.006; Fraisse CW, 2006, COMPUT ELECTRON AGR, V53, P13, DOI 10.1016/j.compag.2006.03.002; Gao Q, 1997, ECOL MODEL, V98, P163, DOI 10.1016/S0304-3800(96)01912-6; Gomann H, 2005, ENVIRON MODELL SOFTW, V20, P261, DOI 10.1016/j.envsoft.2004.01.004; Hou H, 2007, ENTERP INFORM SYST, V1, P287, DOI 10.1080/17517570701546741; Jongschaap REE, 2006, EUR J AGRON, V24, P316, DOI 10.1016/j.eja.2005.10.009; Kishore R, 2006, DECIS SUPPORT SYST, V42, P48, DOI 10.1016/j.dss.2004.09.011; Laliwala Z., 2006, P 26 IEEE INT C DIST, P24; LIANG N, 2005, PLANNING ADVISORY SY; Lorentzos NA, 1999, COMPUT ELECTRON AGR, V22, P233, DOI 10.1016/S0168-1699(99)00021-6; Nhan DK, 2007, AGR SYST, V94, P445, DOI 10.1016/j.agsy.2006.11.017; Pacini C, 2003, AGR ECOSYST ENVIRON, V95, P273, DOI 10.1016/S0167-8809(02)00091-9; Perini A, 2004, ENVIRON MODELL SOFTW, V19, P821, DOI 10.1016/j.envsoft.2003.03.001; QIU B, 2005, P IEEE GEOSC REM SEN, P862; Rao DP, 2001, IEEE T SYST MAN CY C, V31, P207, DOI 10.1109/5326.941844; Rao M, 2007, ENVIRON MODELL SOFTW, V22, P1270, DOI 10.1016/j.envsoft.2006.08.003; Saroinsong F, 2007, LANDSCAPE URBAN PLAN, V79, P38, DOI 10.1016/j.landurbplan.2006.03.002; Sell J, 2006, ECOL ECON, V58, P17, DOI 10.1016/j.ecolecon.2005.05.020; Shaffer MJ, 1998, COMPUT ELECTRON AGR, V21, P135, DOI 10.1016/S0168-1699(98)00031-3; Shi T, 2005, ECOL ECON, V53, P223, DOI 10.1016/j.ecolecon.2004.08.006; SHI Z, 2007, MSMINER 3 0; Sullivan TJ, 2005, KNOWL-BASED SYST, V18, P55, DOI 10.1016/j.knosys.2004.04.007; Wagner WC, 1999, INT J PARASITOL, V29, P1, DOI 10.1016/S0020-7519(98)00173-8; Warfield JN, 2007, ENTERP INFORM SYST, V1, P235, DOI 10.1080/17517570701241079; Xu SB, 2006, SYST RES BEHAV SCI, V23, P251, DOI 10.1002/sres.749; Zhu GuoQun, 2005, Journal of Zhejiang University (Agriculture and Life Sciences), V31, P7	33	39	39	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	JUL	2008	38	4					590	599		10.1109/TSMCC.2007.913894		10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	316RM	WOS:000256967400011	
J	Chien, CF; Chen, LF				Chien, Chen-Fu; Chen, Li-Fei			Data mining to improve personnel selection and enhance human capital: A case study in high-technology industry	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						personnel selection; human capital; data mining; decision tree; semiconductor industry	RESOURCE INFORMATION-SYSTEMS; ROUGH SET-THEORY; KNOWLEDGE MANAGEMENT; DISTRIBUTION FEEDER; DIAGNOSIS	The quality of human capital is crucial for high-tech companies to maintain competitive advantages in knowledge economy era. However, high-technology companies suffering from high turnover rates often find it hard to recruit the right talents. In addition to conventional human resource management approaches, there is an urgent need to develop effective personnel selection mechanism to find the talents who are the most suitable to their own organizations. This study aims to fill the gap by developing a data mining framework based on decision tree and association rules to generate useful rules for personnel selection. The results can provide decision rules relating personnel information with work performance and retention. An empirical study was conducted in a semiconductor company to support their hiring decision for indirect labors including engineers and managers with different job functions. The results demonstrated the practical viability of this approach. Moreover, based on discussions among domain experts and data miner, specific recruitment and human resource management strategies were created from the results. (c) 2006 Elsevier Ltd. All rights reserved.	Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, Hsinchu 300, Taiwan; Tahua Inst Technol, Dept Ind Engn & Management, Hsinchu 307, Taiwan	Chien, CF (reprint author), Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, 101 Sect 2 Kuang Fu Rd, Hsinchu 300, Taiwan.	cfchien@mx.nthu.edu.tw					Appleyard MM, 2001, IND RELAT, V40, P436, DOI 10.1111/0019-8676.00219; Beckers AM, 2002, INFORM SYST MANAGE, V19, P41; Berry M. R. J., 1997, DATA MINING TECHNIQU; Borman WC, 1997, ANNU REV PSYCHOL, V48, P299, DOI 10.1146/annurev.psych.48.1.299; Braha D, 2002, IEEE T SEMICONDUCT M, V15, P91, DOI 10.1109/66.983448; BREIMAN L, 1984, CALSSIFICATION REGRE; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Chien CF, 2003, IEEE T SEMICONDUCT M, V16, P704, DOI 10.1109/TSM.2003.818955; Chien CF, 2002, IEEE T POWER DELIVER, V17, P785; Chien C.-F., 2004, J CHINESE I IND ENG, V21, P313; Chien C.-F., 2007, EXPERT SYSTEMS APPL, V33, P1; CHIEN CF, 2005, J QUALITY, V12, P9; Cho V, 2003, EXPERT SYST, V20, P123, DOI 10.1111/1468-0394.00235; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Fu Y., 1997, IEEE POTENTIALS, V16, P18; Han J., 2001, DATA MINING CONCEPTS; HARTIGAN JA, 1975, CHUSTERING ALGORITHM; Hooper RS, 1998, EXPERT SYST APPL, V14, P425; Hough LM, 2000, ANNU REV PSYCHOL, V51, P631, DOI 10.1146/annurev.psych.51.1.631; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Kovach KA, 1999, PUBLIC PERS MANAGE, V28, P275; Kusiak A, 2001, IEEE T ELECTRON PA M, V24, P44, DOI 10.1109/6104.924792; Liao SH, 2003, EXPERT SYST APPL, V25, P155, DOI 10.1016/S0957-4174(03)00043-5; Lievens F, 2002, PERS REV, V31, P580, DOI 10.1108/00483480210438771; Nussbaum M, 1999, INFORM MANAGE, V36, P55, DOI 10.1016/S0378-7206(99)00007-5; Peng C.-Y, 2003, INT J SERVICE TECHNO, V4, P365, DOI 10.1504/IJSTM.2003.003621; Peng JT, 2004, IEE P-GENER TRANSM D, V151, P689, DOI 10.1049/ip-gtd:20040917; Pyle D, 1999, DATA PREPARATION DAT; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Robertson IT, 2001, J OCCUP ORGAN PSYCH, V74, P441, DOI 10.1348/096317901167479; Sattler L, 1999, IEEE T ENG MANAGE, V46, P387, DOI 10.1109/17.797961; Shaw MJ, 2001, DECIS SUPPORT SYST, V31, P127, DOI 10.1016/S0167-9236(00)00123-8; Shiue YR, 2003, INT J COMP INTEG M, V16, P48, DOI 10.1080/0951192021000025689; Wei CP, 2002, EXPERT SYST APPL, V23, P103, DOI 10.1016/S0957-4174(02)00030-1; Wu CH, 2005, EXPERT SYST APPL, V29, P291, DOI 10.1016/j.eswa.2005.04.002	36	39	41	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JAN	2008	34	1					280	290		10.1016/j.eswa.2006.09.003		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	222KP	WOS:000250295300028	
J	Hsu, MH				Hsu, Mei-Hua			A personalized English learning recommender system for ESL students	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						online learning; learning system; ESL; data mining; association rules; clustering; recommender system		This paper has developed an online personalized English learning recommender system capable of providing ESL students with reading lessons that suit their different interests and therefore increase the motivation to learn. The system, using content-based analysis, collaborative filtering, and data mining techniques, analyzes real students' reading data and generates recommender scores, based on which to help select appropriate lessons for respective students. Its performance having been tracked over a period of one year, this recommender system has proved to be very useful in heightening ESL learners' motivation and interest in reading. (c) 2006 Elsevier Ltd. All rights reserved.	Chang Gung Inst Technol, Dept Gen Educ, Tao Yuan, Taiwan	Hsu, MH (reprint author), Chang Gung Inst Technol, Dept Gen Educ, 261 Wen Hwa 1st Rd, Tao Yuan, Taiwan.	mhsu@mail.cgit.edu.tw					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Carenini G., 2003, P 8 INT C INT US INT, P12; CHEN JF, 2001, STEEL COMPOS STRUCT, V1, P231; Cheng PJ, 1999, INFORM SCIENCES, V118, P37, DOI 10.1016/S0020-0255(99)00033-X; Cho YH, 2002, EXPERT SYST APPL, V23, P329, DOI 10.1016/S0957-4174(02)00052-0; FOLTZ PW, 1992, COMMUN ACM, V35, P51, DOI 10.1145/138859.138866; GAUCH JM, 1999, INFORMATION PROCESSI, V35, P401; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kim T, 2002, SIGNAL PROCESS-IMAGE, V17, P497, DOI 10.1016/S0923-5965(02)00025-5; Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126; Lee CH, 2001, EXPERT SYST APPL, V21, P131, DOI 10.1016/S0957-4174(01)00034-3; Linden G., 2003, IEEE INTERNET COMPUT; Miller B. N., 2003, P 8 INT C INT US INT, P263, DOI DOI 10.1145/604045.604094; MOONEY R. J, 2000, P 5 ACM C DIG LIB, P195, DOI DOI 10.1145/336597.336662; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Resnick P., 1997, COMMUN ACM, V40; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Svensson M, 2000, P IUI 2000, P260, DOI 10.1145/325737.325866; Wang YF, 2004, EXPERT SYST APPL, V26, P427, DOI 10.1016/j.eswa.2003.10.001; 2004, DIAMOND BULLET PROVI	22	39	41	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JAN	2008	34	1					683	688		10.1016/j.eswa.2006.10.004		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	222KP	WOS:000250295300070	
J	Fung, BCM; Wang, K; Yu, PS				Fung, Benjamin C. M.; Wang, Ke; Yu, Philip S.			Anonymizing classification data for privacy preservation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						privacy protection; anonymity; security; integrity; data mining; classification; data sharing		Classification is a fundamental problem in data analysis. Training a classifier requires accessing a large collection of data. Releasing person-specific data, such as customer data or patient records, may pose a threat to an individual's privacy. Even after removing explicit identifying information such as Name and SSN, it is still possible to link released records back to their identities by matching some combination of nonidentifying attributes such as {Sex; Zip; Birthdate}. A useful approach to combat such linking attacks, called k-anonymization [1], is anonymizing the linking attributes so that at least k released records match each value combination of the linking attributes. Previous work attempted to find an optimal k-anonymization that minimizes some data distortion metric. We argue that minimizing the distortion to the training data is not relevant to the classification goal that requires extracting the structure of predication on the "future" data. In this paper, we propose a k-anonymization solution for classification. Our goal is to find a k-anonymization, not necessarily optimal in the sense of minimizing data distortion, which preserves the classification structure. We conducted intensive experiments to evaluate the impact of anonymization on the classification on future data. Experiments on real-life data show that the quality of classification can be preserved even for highly restrictive anonymity requirements.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Fung, BCM (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	bfung@cs.sfu.ca; wangk@cs.sfu.ca; psyu@us.ibm.com	Yu, Philip/A-2815-2012; WANG, Ke/H-6830-2013				AGGARWAL G, 2005, J PRIVACY TECHNOLOGY; Bayardo R.J., 2005, P 21 INT C DAT ENG I, P217; Dalenius T., 1986, J OFF STAT, V2, P329; FUNG B, 2005, P 21 INT C DAT ENG I, P205; Hundepool A., 1996, P 3 INT SEM STAT CON; Iyengar V.S., 2002, P 8 ACM SIGKDD INT C, P279; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Le Fevre K., 2006, P 22 IEEE INT C DAT; Lefevre K., 2005, P ACM SIGMOD INT C M, P49, DOI 10.1145/1066157.1066164; LEFEVRE K, 2006, P 12 ACM SIGKDD INT; Machanavajjhala A, 2006, P 22 INT C DAT ENG I; Meyerson A., 2004, P 23 ACM SIGMOD SIGA, P223, DOI 10.1145/1055558.1055591; Newman D.J., 1998, UCI REPOSITORY MACHI; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Samarati P., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275508; Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193; Shannon E., 1948, BELL SYST TECH J, V27, P623; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P571, DOI 10.1142/S021848850200165X; Sweeney L., 1998, P DAT SEC, P356; WANG K, 2005, P 2005 IEEE INT C IN, P171; WANG K, 2006, KNOWLEDGE INFORM SYS; Wang K., 2005, P 5 IEEE INT C DAT M, P466; WANG K, 2004, P 4 IEEE INT C DAT M; Wang K., 2006, P 12 ACM SIGKDD INT, P414, DOI 10.1145/1150402.1150449; Wong R., 2006, P 12 ACM SIGKDD INT; XIAO X, 2006, P 2006 ACM SIGMOD IN; XU J, 2006, P 12 ACM SIGKDD INT	27	39	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2007	19	5					711	725		10.1109/TKDE.2007.1015		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	145VZ	WOS:000244895200009	
J	Huang, MJ; Chen, MY; Lee, SC				Huang, Mu-Jung; Chen, Mu-Yen; Lee, Show-Chin			Integrating data mining with case-based reasoning for chronic diseases prognosis and diagnosis	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						chronic disease; data mining; case-based reasoning	CARDIAC SPECT DIAGNOSIS; MEDICAL DIAGNOSIS; KNOWLEDGE MANAGEMENT; DECISION-SUPPORT; DYSMORPHIC SYNDROMES; EXPERT KNOWLEDGE; SYSTEMS; PERSPECTIVE/; ARCHITECTURE; DISCOVERY	The threats to people's health from chronic diseases are always exist and increasing gradually. How to decrease these threats is an important issue in medical treatment. Thus, this paper suggests a model of a chronic diseases prognosis and diagnosis system integrating data mining (M) and case-based reasoning (CBR). The main processes of the system include: (1) adopting data mining techniques to discover the implicit meaningful rules from health examination data, (2) using the extracted rules for the specific chronic diseases prognosis, (3) employing CBR to support the chronic diseases diagnosis and treatments, and (4) expanding these processes to work within a system for the convenience of chronic diseases knowledge creating, organizing, refining, and sharing. The experiment data are collected from a professional health examination center, MJ health screening center, and implemented through the system for analysis. The findings are considered as helpful references for doctors and patients in chronic diseases treatments. (C) 2006 Elsevier Ltd. All rights reserved.	Natl Changhua Univ Educ, Dept Informat Management, Changhua 50058, Taiwan; Natl Changhua Univ Educ, Dept Accounting, Changhua 50058, Taiwan	Huang, MJ (reprint author), Natl Changhua Univ Educ, Dept Informat Management, Changhua 50058, Taiwan.	mjhuang@cc.ncue.edu.tw; chenmy@cc.ncue.edu.tw					Alonso F, 2002, EXPERT SYST APPL, V23, P367, DOI 10.1016/S0957-4174(02)00072-6; Baumgartner C, 2005, J BIOMED INFORM, V38, P89, DOI 10.1016/j.jbi.2004.08.009; Becerra-Fernandez I, 2000, KNOWL-BASED SYST, V13, P315, DOI 10.1016/S0950-7051(00)00091-5; Bellazzi Riccardo, 2005, Artif Intell Med, V34, P25, DOI 10.1016/j.artmed.2004.07.010; Bolloju N, 2002, DECIS SUPPORT SYST, V33, P163, DOI 10.1016/S0167-9236(01)00142-7; Bose I, 2001, INFORM MANAGE-AMSTER, V39, P211, DOI 10.1016/S0378-7206(01)00091-X; Bradburn C., 1993, P EUR WORKSH CBR, P365; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Buta P., 1994, AI Expert, V9; Chang CL, 2005, EXPERT SYST APPL, V28, P237, DOI 10.1016/j.eswa.2004.09.002; Chi R. T. H., 1992, Computer Science in Economics and Management, V5, DOI 10.1007/BF00435279; Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0; COSTA E, 1992, INTELLIGENT TUTORING; Daskalaki S, 2003, EUR J OPER RES, V145, P239, DOI 10.1016/S0377-2217(02)00532-5; Ellman T., 1989, ACM COMPUT SURV, V21, P163, DOI 10.1145/66443.66445; EVANS CD, 1995, MED INFORM, V20, P121; FREITUS AA, 2002, ADV EVOLUTIONARY COM; Frize M, 2000, MED ENG PHYS, V22, P671, DOI 10.1016/S1350-4533(00)00078-3; Gierl L, 1994, Artif Intell Med, V6, P29, DOI 10.1016/0933-3657(94)90056-6; Gunnlaugsdottir J, 2003, INT J INFORM MANAGE, V23, P363, DOI 10.1016/S0268-4012(03)00064-1; Hammond K.J., 1989, CASE BASED PLANNING; Hendriks PHJ, 1999, INFORM MANAGE, V35, P113, DOI 10.1016/S0378-7206(98)00080-9; Hsu CC, 2004, INFORM SCIENCES, V166, P231, DOI 10.1016/j.ins.2003.11.009; Kintsch W, 2002, J BIOMED INFORM, V35, P3, DOI 10.1016/S1532-0464(02)00004-7; Kolodner J. L., 1993, CASE BASED REASONING; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; Koton P., 1988, 1 WORKSH CBR, P260; Kukar M, 1996, ARTIF INTELL MED, V8, P431, DOI 10.1016/S0933-3657(96)00351-X; Kurgan LA, 2001, ARTIF INTELL MED, V23, P149, DOI 10.1016/S0933-3657(01)00082-3; Kusiak A, 2005, COMPUT BIOL MED, V35, P311, DOI 10.1016/j.compbiomed.2004.02.004; LIANG TP, 1993, J MANAGEMENT INFORMA, V9, P5; Lopez B, 1997, ARTIF INTELL MED, V9, P29, DOI 10.1016/S0933-3657(96)00360-0; MACURA R, 1995, P 1 INT C CBR, P43; Pakhomov SV, 2005, J BIOMED INFORM, V38, P145, DOI 10.1016/j.jbi.2004.11.016; PUPPE F, 1995, P ART INT MED, P427; Sacha JP, 2000, IEEE ENG MED BIOL, V19, P78, DOI 10.1109/51.853485; Schmidt R, 2001, ARTIF INTELL MED, V23, P171, DOI 10.1016/S0933-3657(01)00083-5; Schmidt R, 1999, INT J MED INFORM, V53, P253, DOI 10.1016/S1386-5056(98)00164-6; Seitz A, 1999, ARTIF INTELL MED, V15, P255, DOI 10.1016/S0933-3657(98)00057-8; Setiono R, 1996, ARTIF INTELL MED, V8, P37, DOI 10.1016/0933-3657(95)00019-4; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; Tan KC, 2003, ARTIF INTELL MED, V27, P129, DOI 10.1016/S0933-3657(03)00002-2; Turner R., 1988, 1 WORKSH CBR SAN MAT, P435; Wenkebach U, 1992, Proc Annu Symp Comput Appl Med Care, P18; *ATT SOFTW LTD, 2002, XPERTRULER MIN KNOWL	45	39	43	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2007	32	3					856	867		10.1016/j.eswa.2006.01.038		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	130KS	WOS:000243799100013	
J	Chen, YQ; Yang, Q; Yin, J; Chai, XY				Chen, YQ; Yang, Q; Yin, J; Chai, XY			Power-efficient access-point selection for indoor location estimation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining in mobile wireless networks; power efficient computation		An important goal of indoor location estimation systems is to increase the estimation accuracy while reducing the power consumption. In this paper, we present a novel algorithm known as CaDet for power-efficient location estimation by intelligently selecting the number of Access Points (APs) used for location estimation. We show that by employing machine learning techniques, CaDet is able to use a small subset of the APs in the environment to detect a client's location with high accuracy. CaDet uses a combination of information theory, clustering analysis, and a decision tree algorithm. By collecting data and testing our algorithms in a realistic WLAN environment in the computer science department area of the Hong Kong University of Science and Technology, we show that CaDet ( Clustering and Decision Tree-based method) can be much higher in accuracy as compared to other methods. We also show through experiments that, by intelligently selecting APs, we are able to save the power on the client device while achieving the same level of accuracy.	Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Chen, YQ (reprint author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.	yqchen@ict.ac.cn; qyang@cs.ust.hk; yinjie@cs.ust.hk; chai@cs.purdue.edu	Yin, Jessie Jie/B-3850-2011				Bahl P., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), DOI 10.1109/INFCOM.2000.832252; Bahl Paramvir, 2000, ENHANCEMENTS RADAR U; Bhasker E. S., 2004, Proceedings. Second IEEE Annual Conference on Pervasive Computing and Communications; DELANEY B, 2004, THESIS GEORGIA I TEC; Duda R.O., 2001, PATTERN CLASSIFICATI; Ebert J.-P., 2002, P EUR WIR 2002 FLOR, P230; FOX D, 2002, IEEE PERVAS COMPUT, V2, P24; Gentile C., 2004, P IEEE INT C COMM, V3, P1360; GURUMURTHI S, 2003, ACM SIGARCH COMPUTER, V31; HASHEMI H, 1993, P IEEE, V81, P943, DOI 10.1109/5.231342; Heinzelman W. R., 2000, P HAW INT C SYST SCI, P1, DOI DOI 10.1109/HICSS.2000.926982; HONG I, 1996, P 1996 IEEE ACM INT, P10; Kravets R., 1998, P 4 INT C MOB COMP N, P157, DOI 10.1145/288235.288276; Ladd A. M., 2002, P 8 ANN INT C MOB CO, P227; Lee W. C., 1996, J DISTRIBUTED PARALL, V4, P205; Lorch JR, 1997, WIREL NETW, V3, P311, DOI 10.1023/A:1019177822227; Mitchell T. M, 1997, MACHINE LEARNING; Ni LM, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P407, DOI 10.1109/PERCOM.2003.1192765; PAPERS AW, 2003, POWER CONSUMPTION EN; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Roos T., 2002, International Journal of Wireless Information Networks, V9, DOI 10.1023/A:1016003126882; Shivakumar N., 1996, ACM BALTZER MOBILE N, V1, P433; Stemm M, 1997, IEICE T COMMUN, VE80B, P1125; Weiser M., 1994, Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation (OSDI); Xu Y., 2004, P IEEE INT C MOB DAT, P346; Xu Y., 2003, P 1 INT WORKSH MOB D, P434; Yin J, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P578; Youssef M., 2004, P COMM NETW DISTR SY; Youssef M., 2004, P IEEE INFOCOM 2003, V2, P1023; Youssef MA, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P143, DOI 10.1109/PERCOM.2003.1192736	30	39	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL	2006	18	7					877	888				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	043CJ	WOS:000237576600002	
J	Angiulli, F; Basta, S; Pizzuti, C				Angiulli, F; Basta, S; Pizzuti, C			Distance-based detection and prediction of outliers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						distance-based outliers; outlier detection; outlier prediction; data mining		A distance-based outlier detection method that finds the top outliers in an unlabeled data set and provides a subset of it, called outlier detection solving set, that can be used to predict the outlierness of new unseen objects, is proposed. The solving set includes a sufficient number of points that permits the detection of the top outliers by considering only a subset of all the pairwise distances from the data set. The properties of the solving set are investigated, and algorithms for computing it, with subquadratic time requirements, are proposed. Experiments on synthetic and real data sets to evaluate the effectiveness of the approach are presented. A scaling analysis of the solving set size is performed, and the false positive rate, that is, the fraction of new objects misclassified as outliers using the solving set instead of the overall data set, is shown to be negligible. Finally, to investigate the accuracy in separating outliers from inliers, ROC analysis of the method is accomplished. Results obtained show that using the solving set instead of the data set guarantees a comparable quality of the prediction, but at a lower computational cost.	Italian Natl Res Council, Inst High Performance Comp & Networking, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Italian Natl Res Council, Inst High Performance Comp & Networking, Via Pietro Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.	angiulli@icar.cnr.it; basta@icar.cnr.it; pizzuti@icar.cnr.it					ANGIULLI F, 2005, IEEE T KNOWL DATA EN, V2, P203; Arning A., 1996, P 2 INT C KNOWL DISC, P164; Barnett V., 1994, OUTLIERS STAT DATA; BAY SD, 2003, P INT C KNOWL DISC D; BREUNIG MM, 2000, P INT C MAN DAT SIGM; DARPA DARPA Intrusion Detection Evaluation, 1998, INTR DET EV; Eskin E., 2002, APPL DATA MINING COM; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FENG C, 1993, P AI STAT C 93; Floyd S, 1995, MACH LEARN, V21, P269, DOI 10.1007/BF00993593; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; Garey M.R., 1979, COMPUTER INTRACTABIL; Han J., 2001, DATA MINING CONCEPTS; JIN W, 2001, P ACM SIGKDD INT C K; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Lazarevic A., 2003, P SIAM INT C DAT MIN; Lee W., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; MANGASARIAN L, 1990, SIAM NEWS, V25, P1; Peleg D, 1997, ALGORITHMICA, V18, P44, DOI 10.1007/BF02523687; PROVOST F, 1998, P INT C MACH LEARN I; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Scholkopf B., 1995, P 1 INT C KNOWL DISC, P252; TORGO L, 2003, P INT C PRINC DAT MI, P447; Yamanishi K., 2001, P 7 ACM SIGKDD INT C, P389, DOI 10.1145/502512.502570	26	39	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2006	18	2					145	160		10.1109/TKDE.2006.29		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	003AD	WOS:000234653100001	
J	Hammami, M; Chahir, Y; Chen, LM				Hammami, M; Chahir, Y; Chen, LM			WebGuard: A Web filtering engine combining textual, structural, and visual content-based analysis	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Web classification and categorization; data mining; Web textual and structural content; visual content analysis; skin color model; pornographic Web site filtering		Along with the ever-growing Web comes the proliferation of objectionable content, such as sex, violence, racism, etc. We need efficient tools for classifying and filtering undesirable Web content. In this paper, we investigate this problem and describe WebGuard, an automatic machine learning-based pornographic Web site classification and filtering system. Unlike most commercial filtering products, which are mainly based on textual content-based analysis such as indicative keywords detection or manually collected black list checking, WebGuard relies on several major data mining techniques associated with textual, structural content-based analysis, and skin color related visual content-based analysis as well. Experiments conducted on a testbed of 400 Web sites including 200 adult sites and 200 nonpornographic ones showed WebGuard's filtering effectiveness, reaching a 97.4 percent classification accuracy rate when textual and structural content-based analysis was combined with visual content-based analysis. Further experiments on a black list of 12,311 adult Web sites manually collected and classified by the French Ministry of Education showed that Web(Guard scored a 95.62 percent classification accuracy rate. The basic framework of WebGuard can apply to other categorization problems of Web sites which combine, as most of them do today,textual and visual content.	Ecole Cent Lyon, LIRIS, CNRS, UMR 5205, F-69134 Ecully, France; Univ Caen, CNRS, URA 6072, GREYC, F-14032 Caen, France	Hammami, M (reprint author), Ecole Cent Lyon, LIRIS, CNRS, UMR 5205, 36 Av Guy de Collongue, F-69134 Ecully, France.	mohamed.hammami@ec-lyon.fr; youssef.chahir@info.unicaen.fr; liming.chen@ec-lyon.fr					ALBIOL A, 2000, P IEEE INT C IM PROC, V2, P239; Breiman L, 1984, CLASSIFICATION REGRE; BRIN S, 1998, P WWW7; Chahir Y, 2000, J VIS COMMUN IMAGE R, V11, P302, DOI 10.1006/jvic.1999.0428; CHAKRABARTI S, 1998, P 1998 ACM SIGMOD IN; Cho J, 1998, COMPUT NETWORKS ISDN, V30, P161, DOI 10.1016/S0169-7552(98)00108-1; Efron B., 1993, INTRO BOOTSTRAP; Flake G. W., 2000, P 6 INT C KNOWL DISC; FLAKE GW, 2003, WEB DYNAMICS; FURNKRANZ J, 1999, INTELLIGENT DATA ANA, P487; GLOVER EJ, 2002, P WWW2002; GRALLA P, 2001, INTERNET ENFANTS, P74; HAMMAMI M, 2003, P 3 INT WORKSH CONT, P157; HAMMAMI M, 2003, REV RIA ECA, V17, P219; Hammami M., 2003, Proceedings IEEE/WIC International Conference on Web Intelligence (WI 2003); HAMMAMI M, 2002, DEFINITION MODELE PE, P186; Jones M. J., 1998, 9811 CRL; KARPOVA E, 2003, P IAPR INT C IM SIGN, P47; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LEE PY, 2002, IEEE INTELLIGENT SEP, P48; MAHDI W, 2002, Patent No. 0302406; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SCHUPP S, 2002, MEDIANET2002, P73; Sebastian F., 1999, P THAI 99 EUR S TEL, V99, P105; STAYRYNKEVITCH B, 2002, POESIA SOFTWARE ARCH; Wang YP, 1999, ACTA PHARMACOL SIN, V20, P10; Wang HL, 1997, IEEE T CIRC SYST VID, V7, P615; YANG MH, 1998, P IEEE INT C IM PROC, P127; YANG Y, 2001, J INTELLIGENT INFORM; Zighed D.A., 1996, METHOD NONARBORESCEN, P2; *BIONET SYST LLC, 2005, NET NANN 4 04; *ICOGNITO TECHN LT, 2005, PUR HOM 1 6; *SOL OAK SOFTW INC, 2002, CYB 2002; *SURFCONTROL PLC, 2005, CYB PATR 5 0; *SYM CORP, 2005, NORT INT SEC 2003	36	39	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2006	18	2					272	284		10.1109/TKDE.2006.34		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	003AD	WOS:000234653100010	
J	Zhang, SC; Qin, ZX; Ling, CX; Sheng, SL				Zhang, SC; Qin, ZX; Ling, CX; Sheng, SL			"Missing is useful": Missing values in cost-sensitive decision trees	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						induction; knowledge acquisition; machine learning	KNOWLEDGE	Many real-world data sets for machine learning and data mining contain missing values and much previous research regards it as a problem and attempts to impute missing values before training and testing. In this paper, we study this issue in cost-sensitive learning that considers both test costs and misclassification costs. If some attributes ( tests) are too expensive in obtaining their values, it would be more cost-effective to miss out their values, similar to skipping expensive and risky tests ( missing values) in patient diagnosis ( classification). That is, "missing is useful" as missing values actually reduces the total cost of tests and misclassifications and, therefore, it is not meaningful to impute their values. We discuss and compare several strategies that utilize only known values and that "missing is useful" for cost reduction in cost-sensitive decision tree learning.	Beijing Univ Aeronaut & Astronaut, Dept Automat Control, Beijing 100083, Peoples R China; Univ Technol Sydney, Fac Informat Technol, Sydney, NSW 2007, Australia; Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada	Zhang, SC (reprint author), Beijing Univ Aeronaut & Astronaut, Dept Automat Control, Beijing 100083, Peoples R China.	zhangsc@it.uts.edu.au; zqin@it.uts.edu.au; cling@csd.uwo.ca; ssheng@csd.uwo.ca					Ali KM, 1993, P 13 INT JOINT C ART, P1064; Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI 10.1080/08839510390219309; Blake C, 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Chai X., 2004, P 4 IEEE INT C DAT M; Cheeseman P, 1995, ADV KNOWLEDGE DISCOV, P153; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; DATE CJ, 1989, RELATIONAL DATABASE, P343; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Elkan C, 2001, P 17 INT JOINT C ART, P973; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Greiner R, 2002, ARTIF INTELL, V139, P137, DOI 10.1016/S0004-3702(02)00209-6; KAI MT, 1998, P 2 EUR S PRINC DAT, P23; Lakshminarayan K, 1999, APPL INTELL, V11, P259, DOI 10.1023/A:1008334909089; Ling C. X., 2004, P 21 INT C MACH LEAR; Little RJA, 1987, STAT ANAL MISSING DA; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; TURNEY P, 2000, P WORKSH COST SENS L; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Zubek V. B., 2002, P 19 INT C MACH LEAR, P27	24	39	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	DEC	2005	17	12					1689	1693				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	975LT	WOS:000232664700008	
S	van der Aalst, WMP; de Beer, HT; van Dongen, BF		Meersman, R; Tari, Z; Hacid, MS; Mylopoulos, J; Pernici, B; Baboglu, O; Jacobsen, HA; Loyall, J; Kifer, M; Spaccapietra, S		van der Aalst, WMP; de Beer, HT; van Dongen, BF			Process mining and verification of properties: An approach based on temporal logic	ON THE MOVE TO MEANINGFUL INTERNET SYSTEMS 2005: COOPIS, DOA, AND ODBASE, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	OTM Confederated International Conference and Workshop	OCT 31-NOV 04, 2005	Agia Napa, CYPRUS	RMIT Univ, Vrije Univ Brussels, Dept Comp Sci, Interop		process mining; temporal logic; business process management; workflow management; data mining; Petri nets	DYNAMIC CHANGES; MODELS	Information systems are facing conflicting requirements. On the one hand, systems need to be adaptive and self-managing to deal with rapidly changing circumstances. On the other hand, legislation such as the Sarbanes-Oxley Act, is putting increasing demands on monitoring activities and processes. As processes and systems become more flexible, both the need for, and the complexity of monitoring increases. Our earlier work on process mining has primarily focused on process discovery, i.e., automatically constructing models describing knowledge extracted from event logs. In this paper, we focus on a different problem complementing process discovery. Given an event log and some property, we want to verify whether the property holds. For this purpose we have developed a new language based on Linear Temporal Logic (LTL) and we combine this with a standard XML format to store event logs. Given an event log and an LTL property, our LTL Checker verifies whether the observed behavior matches the (un)expected/(un) desirable behavior.	Eindhoven Univ Technol, Dept Technol Management, NL-5600 MB Eindhoven, Netherlands	van der Aalst, WMP (reprint author), Eindhoven Univ Technol, Dept Technol Management, POB 513, NL-5600 MB Eindhoven, Netherlands.	w.m.p.v.d.aalst@tm.tue.nl	van der Aalst, Wil/G-1248-2011	van der Aalst, Wil/0000-0002-0955-6940			Agrawal R., 1998, 6 INT C EXT DAT TECH, P469; Busi N., 2004, 2 INT WORKSH SEC ISS, P69; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Cook JE, 2001, PROC IEEE INT CONF S, P332, DOI 10.1109/ICSM.2001.972746; Cook JE, 1999, ACM T SOFTW ENG METH, V8, P147, DOI 10.1145/304399.304401; de Beer H., 2004, LTL CHECKER PLUGINS; Ellis C. A., 1995, P C ORG COMP SYST, P10, DOI 10.1145/224019.224021; Fickas S., 2002, Proceedings ASE 2002. 17th IEEE International Conference on Automated Software Engineering, DOI 10.1109/ASE.2002.1115035; Giannakopoulou D., 2001, Proceedings 16th Annual International Conference on Automated Software Engineering (ASE 2001), DOI 10.1109/ASE.2001.989841; Grigori D, 2004, COMPUT IND, V53, P321, DOI 10.1016/j.compind.2003.10.007; Grigori D., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Havelund K., 2001, Proceedings 16th Annual International Conference on Automated Software Engineering (ASE 2001), DOI 10.1109/ASE.2001.989799; Havelund K, 2002, LECT NOTES COMPUT SC, V2280, P342; Herbst J, 2000, LECT NOTES ARTIF INT, V1810, P183; Hoffman T., 2004, COMPUTER WORLD, V38, P14; KELLER G, 1998, SAP R3 PROCESS ORIEN; Manna Z., 1991, TEMPORAL LOGIC REACT; Pnueli A., 1977, P 18 IEEE S FDN COMP, P46; Reichert M, 1998, J INTELL INF SYST, V10, P93, DOI 10.1023/A:1008604709862; Rinderle S, 2004, DATA KNOWL ENG, V50, P9, DOI 10.1016/j.datak.2004.01.002; Robinson W.N., 2002, P 35 ANN HAW IEEE IN, P276; Robinson W.N., 2003, P 11 IEEE INT C REQ, P56; Rosemann M., 2000, P 33 HAW INT C SYST, P1; Sarbanes P., 2002, SARBANES OXLEY ACT 2; Sayal M., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; van der Aalst W. M. P., 2002, WORKFLOW MANAGEMENT; van der Aalst W.M.P., 2004, P 5 WORKSH BUS PROC, V2, P138; van der Aalst W, 2004, IEEE T KNOWL DATA EN, V16, P1128, DOI 10.1109/TKDE.2004.47; van der Aalst WMP, 2005, LECT NOTES COMPUT SC, V3536, P48; van der Aalst WMP, 2003, DATA KNOWL ENG, V47, P237, DOI 10.1016/S0169-023X(03)00066-1; van der Aalst WMP, 2004, LECT NOTES COMPUT SC, V3080, P244; van der Aalst WMP, 2001, INFORM SYST FRONT, V3, P297, DOI 10.1023/A:1011409408711; VANDERAALST WMP, 2004, SPECIAL ISSUE COMPUT, V53; Weijters AJMM, 2003, INTEGR COMPUT-AID E, V10, P151	34	39	39	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29736-7	LECT NOTES COMPUT SC			2005	3760						130	147				18	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDJ17	WOS:000233741400011	
J	Lariviere, B; Van den Poel, D				Lariviere, B; Van den Poel, D			Investigating the role of product features in preventing customer churn, by using survival analysis and choice modeling: The case of financial services	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; customer relationship management; cross-sell analysis; multinomial probit; survival analysis; savings and investment features; retention behavior	MULTINOMIAL PROBIT MODEL; PROBABILITIES; REGRESSION	The enhancement of existing relationships is of pivotal importance to companies, since attracting new customers is known to be more expensive. Therefore, as part of their customer relationship management (CRM) strategy, many researchers have been analyzing 'why' customers decide to switch. However, despite its practical relevance, few studies have investigated how companies can react to defection prone customers by offering the right set of products. Additionally, within the current customer attention 'hype', one tends to overlook the nature of different products when investigating customer defection. In this research, we study the defection of the savings and investment (SI) customers of a large Belgian financial service provider. We created different SI chum behavior categories by introducing two dimensions: (i) duration of the products (fixed term versus infinity) and (ii) capital/revenue risks involved. Considering these product features, we first gain explorative insight in the timing of the chum event by means of Kaplan-Meier estimates. Secondly, we elaborate on the most alarming group of customers that emerged from the former explorative analysis. A hazard model is built to detect the most convenient product categories to cross-sell in order to reduce their churn likelihood. Complementary, a multinomial probit model is estimated to explore the customers' preferences with respect to the product features involved and to test whether these correspond with the findings of the survival analysis. The results of our study indicate that customer retention cannot be understood by solely relying on customer characteristics. In sum, it might be true that 'not all customers are created equal', but neither are all products. (C) 2004 Elsevier Ltd. All rights reserved.	State Univ Ghent, Dept Marketing, B-9000 Ghent, Belgium	Lariviere, B (reprint author), State Univ Ghent, Dept Marketing, Hoveniersberg 24, B-9000 Ghent, Belgium.	bart.lariviere@ugent.be					ALLISON DA, 1999, LOGISTIC REGRESSION, P167; Baesens B, 2004, EUR J OPER RES, V156, P508, DOI [10.1016/S0377-2217(03)00043-2, 10.1016/s0377-2217(03)00043-2]; Bland JM, 1998, BRIT MED J, V317, P1572; BRESLAW JA, 2002, ECONOMETRICS J, V5, P417, DOI 10.1111/1368-423X.00091; Chiang DA, 2003, EXPERT SYST APPL, V25, P293, DOI 10.1016/S0957-4174(03)00073-3; CHINTAGUNTA PK, 1992, MARKET SCI, V11, P386, DOI 10.1287/mksc.11.4.386; CURRIM IS, 1982, J MARKETING RES, V19, P208, DOI 10.2307/3151621; DAWES J, 1999, INT J BANK MARKETING, V17, P36, DOI 10.1108/02652329910254037; EFRON B, 1988, J AM STAT ASSOC, V83, P414, DOI 10.2307/2288857; GEWEKE J, 1994, REV ECON STAT, V76, P609, DOI 10.2307/2109766; Haaijer R, 1998, MARKET SCI, V17, P236, DOI 10.1287/mksc.17.3.236; Hajivassiliou V, 1996, J ECONOMETRICS, V72, P85, DOI 10.1016/0304-4076(94)01716-6; HORROWITZ J, 1981, TRANSPORT SCI, V15, P153; KEANE MP, 1992, J BUS ECON STAT, V10, P193, DOI 10.2307/1391677; Krishnan MS, 1999, MANAGE SCI, V45, P1194, DOI 10.1287/mnsc.45.9.1194; Meyer R. J., 1991, HDB CONSUMER BEHAV, P85; Pastor JM, 1997, EUR J OPER RES, V98, P395, DOI 10.1016/S0377-2217(96)00355-4; REICHHELD FF, 1990, HARVARD BUS REV, V68, P105; RITTER DS, 1993, RELATIONSHIP BANKING, P3; Stare J, 2001, COMPUT METH PROG BIO, V64, P45, DOI 10.1016/S0169-2607(00)00083-3; VANDENPOEL D, 2004, IN PRESS EUROPEAN J	21	39	40	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2004	27	2					277	285		10.1016/j.eswa.2004.02.002		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	833IT	WOS:000222331700011	
J	Li, YF; Zhong, N				Li, YF; Zhong, N			Web mining model and its applications for information gathering	KNOWLEDGE-BASED SYSTEMS			English	Article						Web intelligence; semantic Web; Web mining; information gathering	PERSPECTIVE; FRAMEWORK	Web mining is used to automatically discover and extract information from Web-related data sources such as documents, log, services, and user profiles. Although standard data mining methods may be applied for mining on the Web, many specific algorithms need to be developed and applied for various purposes of Web based information processing in multiple Web resources, effectively and efficiently. In the paper, we propose an abstract Web mining model for extracting approximate concepts hidden in user profiles on the semantic Web. The abstract Web mining model represents knowledge on user profiles by using an ontology which consists of both 'part-of' and 'is-a' relations. We also describe the details of using the abstract Web mining model for information gathering. In this application, classes of the ontology are represented as subsets of a list of keywords. An efficient filtering algorithm is also developed to filter out most non-relevant inputs. (C) 2004 Elsevier B.V. All rights reserved.	Queensland Univ Technol, Sch Software Engn & Data Commun, Brisbane, Qld 4001, Australia; Maebashi Inst Technol, Dept Syst & Informat Engn, Maebashi, Gumma 3710816, Japan	Li, YF (reprint author), Queensland Univ Technol, Sch Software Engn & Data Commun, Brisbane, Qld 4001, Australia.	y2.li@qut.edu.au; zhong@maebashi-it.acjp	Li, Yuefeng/I-9883-2012				AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; BAEZA- YATES R., 1999, MODERN INFORMATION R; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Feigenbaum EA, 1996, COMMUN ACM, V39, P97, DOI 10.1145/229459.229471; GROSSMAN D, 1998, INFORMATION RETRIEVA; GUAN J, 1991, STUDIES COMPUTER SCI, V1; GUAN JW, 1993, P IJCAI, P592; HENDLER J, 2001, LNAI, V2198; HULL DA, 1999, TREC8; JANICKI R, 2002, 3 INT C ROUGH SETS C, P113; Jennings N. R., 1998, AUTON AGENT MULTI-AG, V1, P7, DOI 10.1023/A:1010090405266; KRUSE R, 1991, UNCERTAINITY VAGUENE; Lesser V, 2000, ARTIF INTELL, V118, P197, DOI 10.1016/S0004-3702(00)00005-9; LESSER V, 1996, TR9635; LI Y, 1999, INT I ADV STUDIES SY, P97; LI Y, 2001, LECT NOTES ARTIF INT, V2198, P433; LI Y, 2002, 7 INT C INT SYST, P493; Li Y, 2000, KNOWL-BASED SYST, V13, P285, DOI 10.1016/S0950-7051(00)00088-5; Liu Dayou, 1997, Chinese Journal of Computers, V20; Mostafa J, 1997, ACM T INFORM SYST, V15, P368, DOI 10.1145/263479.263481; Pal SK, 2002, IEEE T NEURAL NETWOR, V13, P1163, DOI 10.1109/TNN.2002.1031947; PAWLAK Z, 2002, 3 INT C ROUGH SETS C, P1; Robertson S., 2000, TREC9; Runkler TA, 2003, INT J APPROX REASON, V32, P217, DOI 10.1016/S0888-613X(02)00084-1; SALTON G, 1983, INTRO MODERN INFORMA; SCHOCKEN S, 1993, INT J MAN MACH STUD, V39, P843, DOI 10.1006/imms.1993.1086; Shafer G, 1976, MATH THEORY EVIDENCE; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Subramanian DK, 2003, KNOWL-BASED SYST, V16, P37, DOI 10.1016/S0950-7051(02)00050-3; TESSEM B, 1993, ARTIF INTELL, V61, P315, DOI 10.1016/0004-3702(93)90072-J; Yao Y., 1997, ROUGH SETS DATA MINI, P47; Yao YY, 2001, LECT NOTES ARTIF INT, V2198, P1; YAO YY, 1992, INT J MAN MACH STUD, V37, P793, DOI 10.1016/0020-7373(92)90069-W; Zhong N, 2002, COMPUTER, V35, P27; RDF VOC DESCRIPTION; 2001, WEBONTOLOGY WORK GRO	37	39	39	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	AUG	2004	17	5-6					207	217		10.1016/j.knosys.2004.05.002		11	Computer Science, Artificial Intelligence	Computer Science	859HZ	WOS:000224255300005	
J	Chan, EY; Ching, WK; Ng, MK; Huang, JZ				Chan, EY; Ching, WK; Ng, MK; Huang, JZ			An optimization algorithm for clustering using weighted dissimilarity measures	PATTERN RECOGNITION			English	Article						clustering; data mining; optimization; attributes weights	CATEGORICAL-DATA; DATA SETS	One of the main problems in cluster analysis is the weighting of attributes so as to discover structures that may be present. By using weighted dissimilarity measures for objects, a new approach is developed, which allows the use of the k-means-type paradigm to efficiently cluster large data sets. The optimization algorithm is presented and the effectiveness of the algorithm is demonstrated with both synthetic and real data sets. (C) 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Hong Kong, Dept Math, Hong Kong, Hong Kong, Peoples R China; Univ Hong Kong, E Business Technol Inst, Hong Kong, Hong Kong, Peoples R China	Ng, MK (reprint author), Univ Hong Kong, Dept Math, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.	mng@maths.hku.hk	Ching, Wai Ki/D-3062-2009; Ng, Michael/B-7189-2009; HKBU, Mathematics/B-5086-2009				Anderberg M.R., 1973, CLUSTER ANAL APPL; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1; Duda R., 1973, PATTERN CLASSIFICATI; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Huang ZX, 1999, IEEE T FUZZY SYST, V7, P446; Jain A.K., 1988, ALGORITHMS CLUSTERIN; MACQUEEN JB, 1967, P 5 S MATH STAT PROB, V7, P281; Ng MK, 2002, PATTERN RECOGN, V35, P2783, DOI 10.1016/S0031-3203(02)00021-3	10	39	47	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAY	2004	37	5					943	952		10.1016/j.patcog.2003.11.003		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	810AM	WOS:000220677200007	
J	Speier, C; Morris, MG				Speier, C; Morris, MG			The influence of query interface design on decision-making performance	MIS QUARTERLY			English	Article						database; computer interface; decision-making	INFORMATION VISUALIZATION; INDIVIDUAL-DIFFERENCES; STRATEGY SELECTION; TASK COMPLEXITY; DSS; CHOICE; MODELS; LOAD; REPRESENTATIONS; ORIENTATION	Managers in modern organizations are confronted with ever-increasing volumes of information that they must evaluate when making a decision. Data warehousing and data mining technologies have given managers a number of valuable tools that can help them store, retrieve, and analyze information contained in large databases; however, maximizing user performance with these tools remains a challenge for information systems professionals. One important and under-explored aspect of the effectiveness of these tools is the design of the query interface. In this study, we compared the use of visual and text-based interfaces on both low and high complexity tasks. Results demonstrated that decision maker performance was more accurate using the text-based interface when task complexity was low; however, decision makers using the visual interface performed better when task complexity was high. In addition, decision makers' subjective mental workload was significantly lower when using the visual interface, regardless of task complexity. In contrast to expectations, less time was needed to make a decision on low complexity tasks when using the visual interface, but those results were reversed under conditions of high task complexity. These results have important implications for the design of managerial decision-making systems, particularly in complex decision-making environments.	Michigan State Univ, Eli Broad Coll Business, E Lansing, MI 48824 USA; Univ Virginia, McIntire Sch Commerce, Charlottesville, VA 22904 USA	Speier, C (reprint author), Michigan State Univ, Eli Broad Coll Business, E Lansing, MI 48824 USA.						Ahlberg C., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), DOI 10.1109/INFVIS.1995.528688; Ahlberg C., 1994, P CHI 94, P313, DOI 10.1145/191666.191775; Allen B, 2000, J AM SOC INFORM SCI, V51, P508, DOI 10.1002/(SICI)1097-4571(2000)51:6<508::AID-ASI3>3.3.CO;2-H; AU P, 2000, P 23 ANN INT ACM SIG, P307, DOI 10.1145/345508.345610; Beach L. R., 1978, ACAD MANAGE REV, V3, P439, DOI 10.2307/257535; BRASSEUR L, 1997, COMPUTERS TECHNICAL, P75; CAMPBELL DJ, 1988, ACAD MANAGE REV, V13, P40, DOI 10.2307/258353; Card S.K., 1983, PSYCHOL HUMAN COMPUT; Card SK, 1996, IEEE COMPUT GRAPH, V16, P63, DOI 10.1109/38.486683; CARD SK, 1999, READINGS INFORMATION; Chambers J. M., 1983, GRAPHICAL METHODS DA; CHEN C, 1999, INFORMATION VISUALIZ; Chen CM, 1996, HUM-COMPUT INTERACT, V11, P125, DOI 10.1207/s15327051hci1102_2; Chen CM, 2000, J AM SOC INFORM SCI, V51, P499, DOI 10.1002/(SICI)1097-4571(2000)51:6<499::AID-ASI2>3.0.CO;2-K; CHEWNING EG, 1990, ACCOUNT ORG SOC, V15, P527, DOI 10.1016/0361-3682(90)90033-Q; COMPEAU DR, 1995, MIS QUART, V19, P189, DOI 10.2307/249688; Cooper BL, 2000, MIS QUART, V24, P547, DOI 10.2307/3250947; CRIBBIN T, 2001, P 9 INT C HUM COMP I, P948; Davenport Thomas H., 2001, ATTENTION EC; Dillon A, 2000, J AM SOC INFORM SCI, V51, P521, DOI 10.1002/(SICI)1097-4571(2000)51:6<521::AID-ASI4>3.0.CO;2-5; Egan D. E., 1988, HDB HUMAN COMPUTER I, P543; EINHORN HJ, 1971, ORGAN BEHAV HUM PERF, V6, P1, DOI 10.1016/0030-5073(71)90002-X; Ekstrom R. B, 1976, MANUAL KIT FACTOR RE; FINKE RA, 1986, HDB PERCEPTION HUMAN, P1; FOSS CL, 1989, INFORM PROCESS MANAG, V25, P407, DOI 10.1016/0306-4573(89)90068-X; Frese M, 1987, Psychological Issues of Human-Computer Interaction in the Work Place, P313; Hancock P. A., 1988, ADV PSYCHOL, V52, P139, DOI DOI 10.1016/S0166-4115(08)62386-9; HEAD CG, 1984, NEW INSIGHTS CARTOGR, P1; Heo M, 2001, J AM SOC INF SCI TEC, V52, P666, DOI 10.1002/asi.1117; Hochheiser H, 2001, J AM SOC INF SCI TEC, V52, P331, DOI 10.1002/1532-2890(2000)9999:9999<::AID-ASI1066>3.3.CO;2-P; Hutchins E.L., 1986, USER CTR SYSTEM DESI, P87; JACOBY J, 1974, J CONSUM RES, V1, P33, DOI 10.1086/208579; JACOBY J, 1974, J MARKETING RES, V11, P532; JOHNSON EJ, 1985, MANAGE SCI, V31, P395, DOI 10.1287/mnsc.31.4.395; KEIM D, 1994, IEEE VIS 93 WORKSH D, P210; Kim J, 2000, INFORM SYST RES, V11, P284, DOI 10.1287/isre.11.3.284.12206; KIRLIK A, 1993, IEEE T SYST MAN CYB, V23, P929, DOI 10.1109/21.247880; KLEINMUNTZ DN, 1993, PSYCHOL SCI, V4, P221, DOI 10.1111/j.1467-9280.1993.tb00265.x; Koenemann J., 1996, P ACM SIGCHI C HUM F, P205, DOI 10.1145/238386.238487; KOSSLYN SM, 1989, APPL COGNITIVE PSYCH, V3, P185, DOI 10.1002/acp.2350030302; Kosslyn Stephen M., 1985, J AM STAT ASSOC, V80, P499, DOI 10.2307/2288463; Kumar H. P., 1997, International Journal of Human-Computer Studies, V46, DOI 10.1006/ijhc.1996.0085; Lohse G. L., 1993, Human-Computer Interaction, V8, DOI 10.1207/s15327051hci0804_3; Lohse GL, 1997, BEHAV INFORM TECHNOL, V16, P297, DOI 10.1080/014492997119707; Lohse GL, 1997, J ADVERTISING, V26, P61; LOY SL, 1991, DECISION SCI, V22, P846, DOI 10.1111/j.1540-5915.1991.tb00367.x; Mackay JM, 1992, INFORMATION SYSTEMS, V3, P150, DOI 10.1287/isre.3.2.150; March J., 1958, ORGANIZATIONS, P136; McCormick B H, 1987, IEEE COMPUT GRAPH, V7, P61; Mennecke B. E., 1997, J GEOGRAPHIC INFORMA, V1, P44; Messick S, 1976, INDIVIDUALITY LEARNI; MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037//0033-295X.101.2.343; Mirel B, 1998, TECH COMMUN-STC, V45, P491; Morris MG, 1999, DECISION SCI, V30, P107, DOI 10.1111/j.1540-5915.1999.tb01603.x; Myers B, 1996, ACM COMPUT SURV, V28, P794, DOI 10.1145/242223.246855; Newell A, 1972, HUMAN PROBLEM SOLVIN; Nielsen J., 1990, HYPERTEXT HYPERMEDIA; Norman D., 1993, THINGS THAT MAKE US; Orford S, 1999, SOC SCI COMPUT REV, V17, P289; PAYNE JW, 1988, J EXP PSYCHOL LEARN, V14, P534, DOI 10.1037//0278-7393.14.3.534; Pinker S., 1990, ARTIF INTELL, P73; Robertson G. G., 1993, Communications of the ACM, V36; ROBINSON EP, 1994, EUR J OPER RES, V76, P393, DOI 10.1016/0377-2217(94)90276-3; Rossano MJ, 1998, BRIT J PSYCHOL, V89, P481; Roth SF, 1997, HUM-COMPUT INTERACT, V12, P131, DOI 10.1207/s15327051hci1201&2_5; SCERBO MS, 1999, AUTOMATION TECHNOLOG; SCHKADE DA, 1994, ORGAN BEHAV HUM DEC, V57, P319, DOI 10.1006/obhd.1994.1018; SCRIABIN M, 1975, MANAGE SCI, V22, P172, DOI 10.1287/mnsc.22.2.172; SHIFFRIN R, 1977, PSYCHOL REV, V84, P119; Shneiderman B, 1998, DESIGNING USER INTER; Silver M.S., 1990, INFORMATION SYSTEMS, V1, P47, DOI 10.1287/isre.1.1.47; SIMON HA, 1979, ANNU REV PSYCHOL, V30, P363, DOI 10.1146/annurev.ps.30.020179.002051; Smelcer JB, 1997, DECISION SCI, V28, P391, DOI 10.1111/j.1540-5915.1997.tb01316.x; Spoerri A., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), DOI 10.1109/VISUAL.1993.398863; STANNEY KM, 1995, ERGONOMICS, V38, P1184, DOI 10.1080/00140139508925181; STASZ C, 1980, N1594ONR RAND CORP; STREUFERT SC, 1973, MEM COGNITION, V1, P389; SUH KS, 1992, INFORMATION SYSTEMS, V3, P252, DOI 10.1287/isre.3.3.252; Swink M, 1995, DECISION SCI, V26, P503, DOI 10.1111/j.1540-5915.1995.tb01438.x; Swink M, 1999, DECISION SCI, V30, P169, DOI 10.1111/j.1540-5915.1999.tb01605.x; TAYLOR PB, 1980, OMEGA-INT J MANAGE S, V8, P183, DOI 10.1016/0305-0483(80)90022-5; TEENI D, 1991, DECISION SCI, V22, P644, DOI 10.1111/j.1540-5915.1991.tb01287.x; Tegarden D.P., 1999, COMMUNICATIONS AIS, V1, P1; Todd P, 1999, INFORM SYST RES, V10, P356, DOI 10.1287/isre.10.4.356; Tufte E. R., 2001, VISUAL DISPLAY QUANT; Vessey I., 1994, Information and Management, V27, DOI 10.1016/0378-7206(94)90010-8; Vessey I., 1991, INFORM SYST RES, V2, P63, DOI 10.1287/isre.2.1.63; VESSEY I, 1991, DECISION SCI, V22, P219, DOI 10.1111/j.1540-5915.1991.tb00344.x; WARE C, 2000, INFORMATION VISUALIZ; Wickens CD, 1995, HUM FACTORS, V37, P473, DOI 10.1518/001872095779049408; WIERWILLE WW, 1993, HUM FACTORS, V35, P263; Wixom BH, 2001, MIS QUART, V25, P17, DOI 10.2307/3250957; WOOD RE, 1986, ORGAN BEHAV HUM DEC, V37, P60, DOI 10.1016/0749-5978(86)90044-0; Wright W, 1997, IEEE COMPUT GRAPH, V17, P66, DOI 10.1109/38.595273; *SPSS INC, 1990, SPSS ADV STAT US GUI	95	39	39	SOC INFORM MANAGE-MIS RES CENT	MINNEAPOLIS	UNIV MINNESOTA-SCH MANAGEMENT 271 19TH AVE SOUTH, MINNEAPOLIS, MN 55455 USA	0276-7783		MIS QUART	MIS Q.	SEP	2003	27	3					397	423				27	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	719GZ	WOS:000185196400004	
J	Giudici, P; Castelo, R				Giudici, P; Castelo, R			Improving Markov Chain Monte Carlo model search for data mining	MACHINE LEARNING			English	Article						Bayesian structural learning; convergence diagnostics; Dirichlet distribution; market basket analysis; Markov chain Monte Carlo	GRAPHICAL MODELS; INDEPENDENCE; SELECTION	The motivation of this paper is the application of MCMC model scoring procedures to data mining problems, involving a large number of competing models and other relevant model choice aspects. To achieve this aim we analyze one of the most popular Markov Chain Monte Carlo methods for structural learning in graphical models, namely, the MC3 algorithm proposed by D. Madigan and J. York (International Statistical Review, 63, 215-232, 1995). Our aim is to improve their algorithm to make it an effective and reliable tool in the field of data mining. In such context, typically highly dimensional in the number of variables, little can be known a priori and, therefore, a good model search algorithm is crucial. We present and describe in detail our implementation of the MC3 algorithm, which provides an efficient general framework for computations with both Directed Acyclic Graphical (DAG) models and Undirected Decomposable Models (UDG). We believe that the possibility of commuting easily between the two classes of models constitutes an important asset in data mining, where an a priori knowledge of causal effects is usually difficult to establish. Furthermore, in order to improve the MC3 method we propose provide several graphical monitors which can help extracting results and assessing the goodness of the Markov chain Monte Carlo approximation to the posterior distribution of interest. We apply our proposed methodology first to the well-known coronary heart disease dataset (D. Edwards & T. Havranek, Biometrika, 72:2, 339-351, 1985). We then introduce a novel data mining application which concerns market basket analysis.	Univ Pavia, Dept Econ & Quantitat Methods, I-27100 Pavia, Italy; Univ Utrecht, Inst Comp & Informat Sci, NL-3508 TC Utrecht, Netherlands	Giudici, P (reprint author), Univ Pavia, Dept Econ & Quantitat Methods, Via San Felice 5, I-27100 Pavia, Italy.		Castelo, Robert/A-4679-2010				Brooks SP, 1998, J ROY STAT SOC D-STA, V47, P69; Buntine W., 1991, P 7 C UNC ART INT, p[52, 524]; Chickering D. M., 1995, P 11 C UNC ART INT, p[87, 515]; Cowell R. G., 1999, PROBABILISTIC NETWOR; DAWID AP, 1993, ANN STAT, V21, P1272, DOI 10.1214/aos/1176349260; DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1; Dellaportas P, 1999, BIOMETRIKA, V86, P615, DOI 10.1093/biomet/86.3.615; EDWARDS D, 1985, BIOMETRIKA, V72, P339, DOI 10.1093/biomet/72.2.339; FRYDENBERG M, 1989, BIOMETRIKA, V76, P539, DOI 10.1093/biomet/76.3.539; GILLISPIE S, 2001, P C UNC ART INT, P171; GIUDICI P, 2001, IN PRESS J COMPUTATI; Giudici P, 1999, BIOMETRIKA, V86, P785, DOI 10.1093/biomet/86.4.785; Heckerman D., 1995, MACH LEARN, V20, P194; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; Lauritzen SL, 1996, GRAPHICAL MODELS; LAURITZEN SL, 1990, NETWORKS, V20, P491, DOI 10.1002/net.3230200503; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; Madigan D, 1996, COMMUN STAT THEORY, V25, P2493, DOI 10.1080/03610929608831853; Pearl J., 1988, PROBABILISTIC REASON; PEARL J, 1987, P C AM ASS ART INT, P374; Robinson R. W., 1973, NEW DIRECTIONS THEOR, p[239, 508]; TARJAN RE, 1984, SIAM J COMPUT, V13, P566, DOI 10.1137/0213035; Verma T. S., 1990, P 6 ANN C UNC ART IN, P255; WORMALD NC, 1985, GRAPH COMBINATOR, V1, P193, DOI 10.1007/BF02582944	25	39	40	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	JAN-FEB	2003	50	1-2					127	158		10.1023/A:1020202028934		32	Computer Science, Artificial Intelligence	Computer Science	594FB	WOS:000178037200005	
S	Bernado, E; Llora, X; Garrell, JM		Lanzi, P; Stolzmann, W; Wilson, SW		Bernado, E; Llora, X; Garrell, JM			XCS and GALE: A comparative study of two learning classifier systems on data mining	ADVANCES IN LEARNING CLASSIFIER SYSTEMS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Workshop on Learning Classifier Systems	JUL 07-08, 2001	SAN FRANCISCO, CALIFORNIA				ALGORITHMS	This paper compares the learning performance, in terms of prediction accuracy, of two genetic-based learning systems, XCS and GALE, with six well-known learning algorithms, coming from instance based learning, decision tree induction, rule-learning, statistical modeling and support vector machines. The experiments, performed on several datasets, show the suitability of the genetic-based learning classifier systems for classification tasks. Both XCS and GALE significantly achieved better results than IB1 and Naive Bayes. Besides, any method could not outperform XCS and GALE significantly.	Engn & Arquitectura La Salle, Barcelona 08022, Spain	Bernado, E (reprint author), Engn & Arquitectura La Salle, Psg Bonanova 8, Barcelona 08022, Spain.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Altenberg L, 1995, FDN GENETIC ALGORITH, P23; Blake C, 1998, UCI REPOSITORY MACHI; BONELLI P, 1991, 4 INT C GEN ALG ICGA, P288; BUTZ MV, 2000, 2000017 ILLIGAL U IL; CANTUPAZ E, 2000, GENETIC EVOLUTIONARY, P1053; Conover WJ., 1971, PRACTICAL NONPARAMET, P206; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DIEFERSON LA, 2000, WORKSH DAT MIN EV CO, P89; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; FLOCKHART IW, 1995, 10 EPCC AIKMS GA MIN; Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Han J., 2001, DATA MINING CONCEPTS; HARTLEY A, 1999, P GEN EV COMP C 1999, P266; Holland J. H, 1986, MACHINE LEARNING ART, VII, P593; Holland J. H., 1978, PATTERN DIRECTED INF, P313; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOLMES JH, 1997, P 7 INT C GEN ALG IC, P426; HOLMES JH, 2000, 3 INT WORKSH LEARN C; Janikow C. Z., 1993, MACH LEARN, V13, P198; John G. H., 1995, 11 C UNC ART INT, P338; Kovacs T., 1999, P GEN EV COMP C GECC, P329; Kovacs T., 1997, SOFT COMPUTING ENG D, P59; Koza J. R., 1992, GENETIC PROGRAMMING; LANZI PL, 1999, P GEN EV COMP C GECC, P353; Lanzi P-L., 2000, LEARNING CLASSIFIER, P223; LLORA X, 2000, P GEN EV COMP C GECC, P868; LLORA X, 2001, IN PRESS P 18 INT C; LLORA X, 2001, IN PRESS P GEN EV CO; LLORA X, 2000, P LEARN 00 WORKSH; Marti J, 1998, P SOC PHOTO-OPT INS, V3338, P1215, DOI 10.1117/12.310849; MARTIN JK, 1996, 9621 U CAL DEP INF C; MARTINEZ E, 1996, 8 MED EL C IND APPL, P1067; Murthy S, 1994, J ARTIFICIAL INTELLI, V2, P1; Platt J, 1998, ADV KERNEL METHODS S; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan R.J., 1993, C4 5 PROGRAMS MACHIN; Smith S. F., 1983, P 8 INT JOINT C ART, P422; WILSON SW, 1999, FESTSCHRIFT HONOR JH; WILSON SW, 1999, 9911 PRED DYN; WILSON SW, 1998, GEN PROGR P 3 ANN C; WILSON SW, 2000, 3 INT WORKSH LEARN C; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; Witten IH, 2000, DATA MINING PRACTICA	49	39	39	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-43793-2	LECT NOTES ARTIF INT			2002	2321						115	132				18	Computer Science, Artificial Intelligence	Computer Science	BW13N	WOS:000180978300008	
J	Xiao, YQ; Dunham, MH				Xiao, YQ; Dunham, MH			Efficient mining of traversal patterns	DATA & KNOWLEDGE ENGINEERING			English	Article						data mining; clickstream analysis; traversal patterns; suffix tree	CONSTRUCTION	A new problem of mining traversal patterns from Web access logs is introduced. The traversal patterns are defined to keep duplicates as well as consecutive ordering in the sessions. Then an efficient algorithm is proposed. The algorithm is online, which allows the user to see the incremental results with respect to the scanned part of the database. The algorithm also adapts to large databases through dynamic compressions and effective pruning. Finally the algorithm is evaluated through experiments with real Web logs. (C) 2001 Published by Elsevier Science B.V.	So Methodist Univ, Dept Comp Sci & Engn, Dallas, TX 75275 USA	Xiao, YQ (reprint author), So Methodist Univ, Dept Comp Sci & Engn, Dallas, TX 75275 USA.						Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1995, P 11 INT C DAT ENG T; Agrawal R., 1994, P 20 INT C VER LARG, P487; BIEGNASKI P, 1994, GEN SUFFIX TREES BIO; BUCHNER AG, 1999, WORKSH WEB US AN US; Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209; HIDBER C, 1999, P ACM SIGMOD INT C M, P145, DOI 10.1145/304182.304195; HUI LCK, 1992, LECT NOTES COMPUT SC, V644, P230; LAN B, 1999, WORKSH WEB US AN US; LIN JL, 1998, P 14 INT C DAT ENG O; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; MCCREIGHT EM, 1976, J ACM, V23, P262, DOI 10.1145/321941.321946; MOSS K, 1999, JAVA SERVLETS; PEI J, 2000, P 2000 PAC AS C KNOW, P592, DOI 10.1145/342009.336572; Savasere A, 1995, P 21 INT C VER LARG, P432; Spiliopoulou M, 2000, COMMUN ACM, V43, P127, DOI 10.1145/345124.345167; UKKONEN E, 1995, ALGORITHMICA, V14, P249, DOI 10.1007/BF01206331; Wang JTL, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; Weiner P., 1973, 14th Annual Symposium on Switching Automata Theory, DOI 10.1109/SWAT.1973.13	19	39	46	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	NOV	2001	39	2					191	214		10.1016/S0169-023X(01)00039-8		24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	483CQ	WOS:000171616500005	
J	Ganti, V; Gehrke, J; Ramakrishnan, R				Ganti, V; Gehrke, J; Ramakrishnan, R			DEMON: Mining and monitoring evolving data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article; Proceedings Paper	16th International Conference on Data Engineering (ICDE 2000)	FEB 29-MAR 03, 2000	SAN DIEGO, CALIFORNIA			Data Mining; dynamic databases; evolving data; trends		Data mining algorithms have been the focus of much research recently. In practice, the input data to a data mining process resides in a large data warehouse whose data is kept up-to-date through periodic or occasional addition and deletion of blocks of data. Most data mining algorithms have either assumed that the input data is static, or have been designed for arbitrary insertions and deletions of data records. In this paper, we consider a dynamic environment that evolves through systematic addition or deletion of blocks of data. We introduce a new dimension, called the data span dimension, which allows user-defined selections of a temporal subset of the database. Taking this new degree of freedom into account, we describe efficient model maintenance algorithms for frequent itemsets and clusters. We then describe a generic algorithm that takes any traditional incremental model maintenance algorithm and transforms it into an algorithm that allows restrictions on the data span dimension. We also develop an algorithm for automatically discovering a specific class of interesting block selection sequences. In a detailed experimental study, we examine the validity and performance of our ideas on synthetic and real datasets.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA; Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Ganti, V (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.						Agrawal R., 1994, P 20 INT C VER LARG; AGRAWAL R, 1998, P ACM SIGMOD C MAN D; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; CHAUDHURI S, 1997, ACM SIGMOD RECOR MAR; CHEUNG D, 1996, P 2 INT C KNOWL DISC; CHEUNG D, 1997, P 5 DAT SYST ADV APP; Cheung D., 1996, P 12 INT C DAT ENG I; Duda R., 1973, PATTERN CLASSIFICATI; Dunkel B, 1999, PROC INT CONF DATA, P522, DOI 10.1109/ICDE.1999.754968; Ester M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FELDMAN R, 1997, P WORKSH RES ISS DAT; Fukunaga K., 1990, INTRO STAT PATTERN R; GANTI V, 1999, P 18 S PRINC DAT SYS; Gehrke J., 1999, P ACM SIGMOD INT C M; GUHA S, 1998, P ACM SIGMOD C MAN D; GUPTA H, 1997, P INT C DAT THEOR JA; Jain A.K., 1988, ALGORITHMS CLUSTERIN; MOGUL J, DIGITALS WEB PROXY T; MUELLER A, 1995, FAST SEQUENTIAL PARA; PUDI V, 2000, INCREMENTAL MINING A; Ramaswamy S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; SARAWAGI S, 1995, P ACM SIGMOD C MAN D, P343; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; THOMAS S, 1997, P 3 INT C KNOWL DISC; Utgoff P. E., 1988, P 5 INT C MACH LEARN, P107; WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1; Xu X., 1995, P 1 INT C KNOWL DISC; Zaki M.J., 1997, P 3 INT C KNOWL DISC; Zhang T., 1996, P ACM SIGMOD C MAN D	30	39	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN-FEB	2001	13	1					50	63		10.1109/69.908980		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	400RU	WOS:000166886100006	
J	Lin, TY				Lin, TY			Data mining and machine oriented modeling: A granular computing approach	APPLIED INTELLIGENCE			English	Article						binary relation; data mining; granulation; machine-oriented modeling; nighborhood system; partition		From the processing point of view, data mining is machine derivation of interesting properties (to human) from the stored data. Hence, the notion of machine oriented data modeling is explored: An attribute value, in a relational model, is a meaningful label (a property) of a set of entities (granule). A model using these granules themselves as attribute values (their bit patterns or lists of members) is called a machine oriented data model. The model provides a good database compaction and data mining environment. For moderate size databases, finding association rules, decision rules, and etc., can be reduced to easy computation of set theoretical operations of granules. In the second part, these notions are extended to real world objects, where the universe is granulated (clustered) into granules by binary relations. Data modeling and mining with such additional semantics are formulated and investigated. In such models, data mining is essentially a machine "calculus" of granules-granular computing.	San Jose State Univ, Dept Math & Comp Sci, San Jose, CA 95192 USA; Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley Initiat Soft Comp, Berkeley, CA 94720 USA	Lin, TY (reprint author), San Jose State Univ, Dept Math & Comp Sci, San Jose, CA 95192 USA.	tylin@cs.sjsu.edu					AGRAWAL R, 1994, P 20 VLDB C SAN CHIL; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; BAIRAMIAN S, 1989, THESIS CALIFORNIA ST; Cai Y., 1991, Knowledge discovery in databases; CHU W, 1992, J INTELL INF SYST, V1, P355, DOI 10.1007/BF00962924; DATE CJ, 1996, INTRO DATABASE SYSTE; Lin T. Y., 1992, DECISION SUPPORT EXP, P287; Lin T. Y., 1998, ROUGH SETS KNOWLEDGE, P107; LIN TY, 1989, P 1989 ACM 17 ANN CO, P453; Lin T.Y., 1998, ROUGH SETS KNOWLEDGE, P121; LIN TY, 1996, COMPUTATIONAL ENG SY, V2, P1095; Lin TY, 1988, P 1988 ACM 16 ANN CO, P725, DOI 10.1145/322609.323183; Lin TY, 1989, P 4 INT S METH INT S, P75; LIN TY, 1996, COMPUTATIONAL ENG SY, V2, P936; Lin T.Y., 1997, ADV MACHINE INTELLIG, VIV, P132; LIN TY, 1996, P 4 INT WORKSH ROUGH, P404; LOUIE E, 2000, IN PRESS LECT NOTES; MEYER D, 1983, THEORY RELATIONAL DA; MICHAEL B, 1997, ROUGH SETS DATA MINI, P229; Pawlak Z., 1991, ROUGH SETS THEORETIC; SIERPENSKI W, 1952, GEN TOPOLOGY; ZADEH L, 1996, P 1996 IEEE INT C FU, P1; ZADEH LA, IN PRESS GRANULAR CO; ZIARKO W, 1993, P AAAI 93 WORKSH KNO	24	39	41	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0924-669X		APPL INTELL	Appl. Intell.	SEP	2000	13	2					113	124		10.1023/A:1008384328214		12	Computer Science, Artificial Intelligence	Computer Science	345WG	WOS:000088837700003	
J	Feelders, A; Daniels, H; Holsheimer, M				Feelders, A; Daniels, H; Holsheimer, M			Methodological and practical aspects of data mining	INFORMATION & MANAGEMENT			English	Article						data mining; knowledge discovery in databases; data quality		We describe the different stages in the data mining process and discuss some pitfalls and guidelines to circumvent them. Despite the predominant attention on analysis, data selection and pre-processing are the most time-consuming activities, and have a substantial influence on ultimate success. Successful data mining projects require the involvement of expertise in data mining, company data, and the subject area concerned. Despite the attractive suggestion of 'fully automatic' data analysis, knowledge of the processes behind the data remains indispensable in avoiding the many pitfalls of data mining. (C) 2000 Elsevier Science B.V. All rights reserved.	Tilburg Univ, Dept Econ & Business Adm, NL-5000 LE Tilburg, Netherlands; Rotterdam Sch Management, Inst Adv Management Studies, NL-3000 DR Rotterdam, Netherlands; Data Distilleries, NL-1098 VA Amsterdam, Netherlands	Feelders, A (reprint author), Tilburg Univ, Dept Econ & Business Adm, POB 90153, NL-5000 LE Tilburg, Netherlands.						BRATKO I, 1995, COMMUN ACM, V38, P65, DOI 10.1145/219717.219771; Breiman L, 1984, CLASSIFICATION REGRE; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Fayyad U, 1996, AI MAG, V17, P37; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; Glymour C, 1997, DATA MIN KNOWL DISC, V1, P11, DOI 10.1023/A:1009773905005; Hand DJ, 1998, AM STAT, V52, P112, DOI 10.2307/2685468; Heckerman D., 1996, ADV KNOWLEDGE DISCOV, P273; HOLSHEIMER M, 1994, CSR9406 CWI; HOLSHEIMER M, 1996, ADV KNOWLEDGE DISCOV, P447; Laudon KC, 1996, COMMUN ACM, V39, P92, DOI 10.1145/234215.234476; Little RJA, 1987, STAT ANAL MISSING DA; O'Leary D., 1993, Journal of Management Information Systems, V9; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rubin DB, 1996, J AM STAT ASSOC, V91, P473, DOI 10.2307/2291635; Schafer J.L., 1997, ANAL INCOMPLETE MULT; Subramanian A, 1997, INFORM MANAGE, V33, P99, DOI 10.1016/S0378-7206(97)00040-2; Wang R. Y., 1996, Journal of Management Information Systems, V12	19	39	44	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-7206		INFORM MANAGE	Inf. Manage.	AUG	2000	37	5					271	281		10.1016/S0378-7206(99)00051-8		11	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	329ZB	WOS:000087937400005	
B	Liu, B; Hsu, W			AMER ASSOC ARTIFICIAL INTELLIGENCE; AMER ASSOC ARTIFICIAL INTELLIGENCE	Liu, B; Hsu, W			Post-analysis of learned rules	PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2			English	Proceedings Paper	13th National Conference on Artificial Intelligence (AAAI 96) / 8th Conference on Innovative Applications of Artificial Intelligence (IAAI 96)	AUG 04-08, 1996	PORTLAND, OR	Amer Assoc Artificial Intelligence				Rule induction research implicitly assumes that after producing the rules from a dataset, these rules will be used directly by an expert system or a human user. In real-life applications, the situation may not be as simple as that, particularly, when the user of the rules is a human being. The human user almost always has some previous concepts or knowledge about the domain represented by the dataset. Naturally, he/she wishes to know how the new rules compare with his/her existing knowledge. In dynamic domains where the rules may change over time, it is important to know what the changes are. These aspects of research have largely been ignored in the past. With the increasing use of machine learning techniques in practical applications such as data mining, this issue of post analysis of rules warrants greater emphasis and attention. In this paper, we propose a technique to deal with this problem. A system has been implemented to perform the post analysis of classification rules generated by systems such as C4.5. The proposed technique is general and highly interactive. It will be particularly useful in data mining and data analysis.	Natl Univ Singapore, Dept Informat Syst & Comp Sci, Singapore 119260, Singapore	Liu, B (reprint author), Natl Univ Singapore, Dept Informat Syst & Comp Sci, Lower Kent Ridge Rd, Singapore 119260, Singapore.						Breiman L, 1984, CLASSIFICATION REGRE; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Clark P, 1993, P 10 INT MACH LEARN, P49; LIU B, 1995, FINDING INTERESTING; MAJOR J, 1993, P AAAI 93 WORKSH KDD; Matheus C, 1994, AAAI WORKSH KNOWL DI, P25; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349; ORTEGA J, 1995, IJCAI 95; PAZZANI M, 1992, MACHINE LEARNING, V9; Quinlan J.R., 1992, C4 5 PROGRAM MACHINE; SILBERSCHATZ A, 1995, P 1 INT C KNOWL DISC; Zimmermann HJ, 1991, FUZZY SET THEORY ITS	12	39	44	AMER ASSOC ARTIFICIAL INTELLIGENCE	MENLO PK	445 BURGESS DR, MENLO PK, CA 94025 USA		0-262-51091-X				1996							828	834				7	Computer Science, Artificial Intelligence	Computer Science	BN59H	WOS:000082323300123	
J	Niu, DX; Wang, YL; Wu, DD				Niu, Dongxiao; Wang, Yongli; Wu, Desheng Dash			Power load forecasting using support vector machine and ant colony optimization	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Ant colony optimization; Feature selection; Support vector machine; Power load forecasting	GENETIC ALGORITHM; SYSTEM	This paper creates a system for power load forecasting using support vector machine and ant colony optimization. The method of colony optimization is employed to process large amount of data and eliminate redundant information. The system mines the historical daily loading which has the same meteorological category as the forecasting day in order to compose data sequence with highly similar meteorological features. With this method, we reduced SVM training data and overcame the disadvantage of very large data and slow processing speed when constructing SVM model. This paper proposes a new feature selection mechanism based on ant colony optimization in an attempt to combat the aforemention difficulties. The method is then applied to find optimal feature subsets in the fuzzy-rough data reduction process. The present work is applied to complex systems monitoring, the ant colony optimization can mine the data more overall and accurate than the original fuzzy-rough method, an entropy-based feature selector, and a transformation-based reduction method, PCA. Comparing with single SVM and BP neural network in short-term load forecasting, this new method can achieve greater forecasting accuracy. It denotes that the SVM-learning system has advantage when the information preprocessing is based on data mining technology. (C) 2009 Elsevier Ltd. All rights reserved.	[Niu, Dongxiao; Wang, Yongli; Wu, Desheng Dash] N China Elect Power Univ, Sch Business Adm, Beijing 102206, Peoples R China; [Wu, Desheng Dash] Univ Toronto, RiskLab, Toronto, ON M5S 3G8, Canada; [Wu, Desheng Dash] Reykjavik Univ, Sch Sci & Engn, IS-103 Reykjavik, Iceland	Wu, DD (reprint author), N China Elect Power Univ, Sch Business Adm, Beijing 102206, Peoples R China.	DWu@Rotman.Utoronto.Ca	Wu, Desheng/I-6230-2012		Natural Science Foundation of China [70671039]; Ministry of Education [NCET-07-0281]	Natural Science Foundation of China (70671039), The Ministry of Education to support the new century talents plan (NCET-07-0281).	Bonabeau E., 1999, SWARM INTELLIGENCE N; Brown R. G., 1983, INTRO RANDOM SIGNAL; CHRISTIA.WR, 1971, IEEE T POWER AP SYST, VPA90, P900, DOI 10.1109/TPAS.1971.293123; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; Douglas AP, 1998, IEEE T POWER SYST, V13, P1507, DOI 10.1109/59.736298; MBAMALU GAN, 1993, IEEE T POWER SYST, V8, P343, DOI 10.1109/59.221222; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Glover JA, 1989, EDUC PSYCHOL REV, V1, P1, DOI 10.1007/BF01326547; Goldberg D. E., 1997, GENETIC ALGORITHMS S; Jensen R, 2005, FUZZY SET SYST, V149, P5, DOI 10.1016/j.fss.2004.07.014; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Lin CM, 2007, APPL MATH COMPUT, V187, P574, DOI 10.1016/j.amc.2006.08.170; Maniezzo V, 1999, IEEE T KNOWL DATA EN, V11, P769, DOI 10.1109/69.806935; MOGHRAM I, 1989, IEEE T POWER SYST, V4, P1484, DOI 10.1109/59.41700; Osman MS, 2005, APPL MATH COMPUT, V163, P755, DOI 10.1016/j.amc.2003.10.057; Pai PF, 2005, ENERG CONVERS MANAGE, V46, P2669, DOI 10.1016/j.enconman.2005.02.004; PARK JH, 1991, IEEE T POWER SYST, V6, P450, DOI 10.1109/59.76686; Sadownik R, 1999, J FORECASTING, V18, P215, DOI 10.1002/(SICI)1099-131X(199905)18:3<215::AID-FOR719>3.0.CO;2-B; Wu DS, 2009, EXPERT SYST APPL, V36, P9105, DOI 10.1016/j.eswa.2008.12.039; Wu DSD, 2009, EUR J OPER RES, V194, P227, DOI 10.1016/j.ejor.2007.10.009	21	38	40	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAR 15	2010	37	3					2531	2539		10.1016/j.eswa.2009.08.019		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	533SY	WOS:000272846500081	
J	Cortez, P; Cerdeira, A; Almeida, F; Matos, T; Reis, J				Cortez, Paulo; Cerdeira, Antonio; Almeida, Fernando; Matos, Telmo; Reis, Jose			Modeling wine preferences by data mining from physicochemical properties	DECISION SUPPORT SYSTEMS			English	Article						Sensory preferences; Regression; Variable selection; Model selection; Support vector machines; Neural networks	SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; CLASSIFICATION; REGRESSION; DISCRIMINATION; PARAMETERS; ALGORITHMS	We propose a data mining approach to predict human wine taste preferences that is based on easily available analytical tests at the certification step. A large dataset (when compared to other studies in this domain) is considered, with white and red vinho verde samples (from Portugal). Three regression techniques were applied, under a computationally efficient procedure that performs simultaneous variable and model selection. The support vector machine achieved promising results, Outperforming the multiple regression and neural network methods. Such model is useful to support the oenologist wine tasting evaluations and improve wine production. Furthermore, similar techniques can help in target marketing by modeling consumer tastes from niche markets. (C) 2009 Elsevier B.V. All rights reserved.	[Cortez, Paulo; Reis, Jose] Univ Minho, Dept Informat Syst, R&D Ctr Algoritmi, P-4800058 Guimaraes, Portugal; [Cerdeira, Antonio; Almeida, Fernando; Matos, Telmo; Reis, Jose] CVRVV, P-4050501 Oporto, Portugal	Cortez, P (reprint author), Univ Minho, Dept Informat Syst, R&D Ctr Algoritmi, P-4800058 Guimaraes, Portugal.	pcortez@dsi.uminho.pt	Cortez, Paulo/A-2674-2008	Cortez, Paulo/0000-0002-7991-2090	FCT [PTDC/EIA/64541/2006]	We would like to thank Cristina Lagido and the anonymous reviewers for their helpful comments. The work of P. Cortez is supported by the FCT project PTDC/EIA/64541/2006.	ASUNCION A., 2007, UCI MACHINE LEARNING; Bi J, 2003, P 20 INT C MACH LEAR; Bishop CM, 1995, NEURAL NETWORKS PATT; Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2; Cortez P, 2006, NEURAL PROCESS LETT, V24, P41, DOI 10.1007/s11063-006-9009-6; CORTEZ P, INTRO ADV S IN PRESS; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Ebeler SE, 1999, FLAVOR CHEMISTRY, P409; Ferrer JC, 2008, INT J PROD ECON, V112, P985, DOI 10.1016/j.ijpe.2007.05.020; Flexer A., 1996, P 13 EUR M CYB SYST, V2, P1005; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Hastie T., 2001, ELEMENTS STAT LEARNI; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; Kewley RH, 2000, IEEE T NEURAL NETWOR, V11, P668, DOI 10.1109/72.846738; Kiang MY, 2003, DECIS SUPPORT SYST, V35, P441, DOI 10.1016/S0167-9236(02)00110-0; Legin A, 2003, ANAL CHIM ACTA, V484, P33, DOI 10.1016/S0003-2670(03)00301-5; Moreno IM, 2007, TALANTA, V72, P263, DOI 10.1016/j.talanta.2006.10.029; R Development Core Team, 2008, R LANG ENV STAT COMP; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; Shaw MJ, 2001, DECIS SUPPORT SYST, V31, P127, DOI 10.1016/S0167-9236(00)00123-8; Smith PJ, 2006, SIGHT SOUND, V16, P84; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Sun LX, 1997, FRESEN J ANAL CHEM, V359, P143, DOI 10.1007/s002160050551; Turban E., 2007, BUSINESS INTELLIGENC; Vapnik V., 1992, COMPUTATIONAL LEARNI, P144; Venables WN, 2003, MODERN APPL STAT; VLASSIDES S, 2001, BIOTECHNOLOGY BIOENG, V73; Wang WJ, 2003, NEUROCOMPUTING, V55, P643, DOI 10.1016/S0925-2312(02)00632-X; Werbos P. J., 1974, THESIS HARVARD U CAM; Witten IH, 2005, DATA MINING PRACTICA; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Yu HY, 2008, J AGR FOOD CHEM, V56, P307, DOI 10.1021/jf0725575; YU M, 2008, DECIS SUPPORT SYST, V44, P899; *CVRVV, 2008, PORT WIN VINH VERD; *FAO FAOSTAT, 2008, FOOD AGR ORG AGR TRA	36	38	38	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	NOV	2009	47	4					547	553		10.1016/j.dss.2009.05.016		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	516NQ	WOS:000271549600027	
J	Garcia, S; Cano, JR; Herrera, F				Garcia, Salvador; Cano, Jose Ramon; Herrera, Francisco			A memetic algorithm for evolutionary prototype selection: A scaling up approach	PATTERN RECOGNITION			English	Article						data reduction; evolutionary algorithms; memetic algorithms; prototype selection; scaling up; nearest neighbour rule; data mining	NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; INSTANCE SELECTION; GENETIC ALGORITHM; CLASSIFICATION; REDUCTION; CLASSIFIERS; DESIGN; SEARCH; ISSUES	Prototype selection problem consists of reducing the size of databases by removing samples that are considered noisy or not influential on nearest neighbour classification tasks. Evolutionary algorithms have been used recently for prototype selection showing good results. However, due to the complexity of this problem when the size of the databases increases, the behaviour of evolutionary algorithms could deteriorate considerably because of a lack of convergence. This additional problem is known as the scaling up problem. Memetic algorithms are approaches for heuristic searches in optimization problems that combine a population-based algorithm with a local search. In this paper, we propose a model of memetic algorithm that incorporates an ad hoc local search specifically designed for optimizing the properties of prototype selection problem with the aim of tackling the scaling up problem. In order to check its performance, we have carried out an empirical study including a comparison between our proposal and previous evolutionary and non-evolutionary approaches studied in the literature. The results have been contrasted with the use of non-parametric statistical procedures and show that our approach outperforms previously studied methods, especially when the database scales up. (c) 2008 Elsevier Ltd. All rights reserved.	[Garcia, Salvador; Herrera, Francisco] Univ Granada, Dept Comp Sci & Arificial Intelligence, E-18071 Granada, Spain; [Cano, Jose Ramon] Univ Jaen, Dept Comp Sci, Jaen 23700, Spain	Garcia, S (reprint author), Univ Granada, Dept Comp Sci & Arificial Intelligence, E-18071 Granada, Spain.	salvagl@decsai.ugr.es; jrcano@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ASUNCION A, 2007, UCI REPOSITORY MACH; Baluja S., 1994, CMUCS94163; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; Cano JR, 2005, PATTERN RECOGN LETT, V26, P953, DOI 10.1016/j.patrec.2004.09.043; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Chen JH, 2005, INT J APPROX REASON, V40, P3, DOI 10.1016/j.ijar.2004.11.009; Dawkins R., 1976, SELFISH GENE; Demsar J, 2006, J MACH LEARN RES, V7, P1; Eiben AE, 2003, INTRO EVOLUTIONARY C; Eshelman L., 1991, FDN GENETIC ALGORITH, P265; Freitas A.A., 2002, DATA MINING KNOWLEDG; Garcia-Pedrajas N, 2007, PATTERN RECOGN, V40, P80, DOI 10.1016/j.patcog.2006.06.024; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Ghosh A, 2005, EVOLUTIONARY COMPUTA; Goldberg D.E., 1991, FDN GENETIC ALGORITH, P69; Gomez-Ballester E, 2006, PATTERN RECOGN, V39, P171, DOI 10.1016/j.patcog.2005.06.007; Grochowski M, 2004, LECT NOTES ARTIF INT, V3070, P580; Hart W. E., 1994, THESIS U CALIFORNIA; Hart W.E., 2005, RECENT ADV MEMETIC A; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904; Ishibuchi H, 1999, LECT NOTES ARTIF INT, V1585, P82; Kim SW, 2007, PATTERN RECOGN, V40, P2946, DOI 10.1016/j.patcog.2007.03.006; Krasnogor N, 2005, IEEE T EVOLUT COMPUT, V9, P474, DOI 10.1109/TEVC.2005.850260; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Land M., 1998, THESIS U CALIFORNIA; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Lozano M, 2006, PATTERN RECOGN, V39, P1827, DOI 10.1016/j.patcog.2006.04.005; Lozano M, 2004, EVOL COMPUT, V12, P273, DOI 10.1162/1063656041774983; Moscato P., 1989, 826 C3P, V826; Papadopoulos A. N., 2004, NEAREST NEIGHBOR SEA; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Shakhnarovich G., 2006, NEAREST NEIGHBOR MET; Sheskin D., 2003, HDB PARAMETRIC NONPA; Sierra B, 2001, P 8 ART INT MED EUR, P20; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WETTSCHERECK D, 1995, 1 INT C CAS BAS REAS, P347; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhao KP, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P94	47	38	38	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	AUG	2008	41	8					2693	2709		10.1016/j.patcog.2008.02.006		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	310FU	WOS:000256515100021	
J	Kim, S; Whitehead, EJ; Zhang, Y				Kim, Sunghun; Whitehead, E. James, Jr.; Zhang, Yi			Classifying software changes: Clean or buggy?	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						maintenance; software metrics; software fault diagnosis; configuration management; classification; association rules; data mining; machine learning	HISTORY; SYSTEM; FAULTS	This paper introduces a new technique for predicting latent software bugs, called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using features ( in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent buggy change recall on average. Change classification has several desirable qualities: 1) The prediction granularity is small ( a change to a single file), 2) predictions do not require semantic information about the source code, 3) the technique works for a broad array of project types and programming languages, and 4) predictions can be made immediately upon the completion of a change. Contributions of this paper include a description of the change classification approach, techniques for extracting features from the source code and change histories, a characterization of the performance of change classification across 12 open source projects, and an evaluation of the predictive power of different groups of features.	[Kim, Sunghun] MIT, Cambridge, MA 02139 USA; [Whitehead, E. James, Jr.; Zhang, Yi] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA	Kim, S (reprint author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	hunkim@csail.mit.edu; ejw@cs.ucsc.edu; yiz@soe.ucsc.edu					Alpaydin E., 2004, INTRO MACHINE LEARNI; ANTONIOL G, 2000, P 7 WORK C REV ENG, P247; Anvik J., 2006, P 28 INT C SOFTW ENG, P361, DOI DOI 10.1145/1134285.1134336; Brun Y, 2004, PROC INT CONF SOFTW, P480, DOI 10.1109/ICSE.2004.1317470; Cubranic D, 2003, PROC INT CONF SOFTW, P408, DOI 10.1109/ICSE.2003.1201219; Di Lucca GA, 2002, PROC IEEE INT CONF S, P93, DOI 10.1109/ICSM.2002.1167756; EESSAN AE, 2005, P 21 INT C SOFTW MAI, P263; FISCHER M, 2003, P 19 INT C SOFTW MAI, P19; Flanagan C, 2002, P ACM SIGPLAN 2002 C, P234; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Graves TL, 2000, IEEE T SOFTWARE ENG, V26, P653, DOI 10.1109/32.859533; Gyimothy T, 2005, IEEE T SOFTWARE ENG, V31, P897, DOI 10.1109/TSE.2005.112; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Khoshgoftaar T. M., 1998, Proceedings Ninth International Symposium on Software Reliability Engineering (Cat. No.98TB100257), DOI 10.1109/ISSRE.1998.730899; Khoshgoftaar TM, 2003, SOFTWARE QUAL J, V11, P19, DOI 10.1023/A:1023632027907; Kim MH, 2006, J INTEL MAT SYST STR, V17, P35, DOI 10.1177/1045389X06056064; Kim S, 2007, PROC INT CONF SOFTW, P489; Kim S., 2005, P 2005 EUR SOFTW ENG, P177, DOI DOI 10.1145/1081706.1081736; KROVETZ R, 2003, P 26 ANN INT ACM SIG, P425; KUHN A, 2005, P 12 WORK C REV ENG, P133, DOI DOI 10.1109/WCRE.2005.16; KUMAR R, 1998, P A REL MAI, P155; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; LEWIS DD, 2004, J MACH LEARN RES, V5, P397; Li Z., 2005, P 10 EUR SOFTW ENG C, P306, DOI DOI 10.1145/1081706.1081755; Livshits B., 2005, P INT S FDN SOFTW EN, P296, DOI 10.1145/1081706.1081754; Lyle J. R., 1987, P 2 INT C COMP APPL, P877; MADHAVAN J, 2007, P ECL TECHN EXCH WOR; Maletic J.I., 1999, P 14 IEEE INT C AUT, P251; Marchal D, 2003, J STRUCT GEOL, V25, P135, DOI 10.1016/S0191-8141(02)00011-1; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P2, DOI 10.1109/TSE.2007.256941; Mizuno O, 2007, P 6 JOINT M EUR SOFT, P405, DOI 10.1145/1287624.1287683; Mockus A, 2000, PROC IEEE INT CONF S, P120, DOI 10.1109/ICSM.2000.883028; Mockus A, 2000, BELL LABS TECH J, V5, P169, DOI 10.1002/bltj.2229; Montgomery D. C., 2001, ENG STAT; MOORE AW, 2005, CROSS VALIDATION; Nagappan N, 2005, PROC INT CONF SOFTW, P284, DOI 10.1145/1062455.1062514; NEWMAN DJ, 1988, UCI REPOSITORY MACHI; Ostrand TJ, 2005, IEEE T SOFTWARE ENG, V31, P340, DOI 10.1109/TSE.2005.49; Ostrand T.J., 2002, P ACM INT S SOFTW TE, P55; Ostrand T.J.T., 2004, P 2004 ACM SIGSOFT I, P86, DOI 10.1145/1007512.1007524; Pan K., 2006, P 6 IEEE INT WORKSH; PENTA MD, 2002, P 10 IEEE INT WORKSH, P207; RASKUTTI B, 2001, P 12 EUR C MACH LEAR, P419; Scott S, 1999, P 16 INT C MACH LEAR, P379; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Sliwerski J., 2005, P INT WORKSH MIN SOF, P24; SPOHRER JC, 1985, P ACM C HUM FACT COM, P47, DOI 10.1145/317456.317465; Vapnik V.N., 1995, NATURE STAT LEARNING; Williams CC, 2005, IEEE T SOFTWARE ENG, V31, P466, DOI 10.1109/TSE.2005.63; Witten IH, 2005, DATA MINING PRACTICA; Zhang L., 2004, ACM T ASIAN LANGUAGE, V3, P243, DOI 10.1145/1039621.1039625; Zheng Z., 2004, ACM SIGKDD EXPLORATI, V6, P80, DOI DOI 10.1145/1007730.1007741; Zimmermann T., 2004, P 1 INT WORKSH MIN S, P2; Zimmermann T, 2005, IEEE T SOFTWARE ENG, V31, P429, DOI 10.1109/TSE.2005.72; *SCH TOOLWORKS, 2005, MAIN UND METR DOC TO	55	38	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	MAR-APR	2008	34	2					181	196		10.1109/TSE.2007.70773		16	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	276SC	WOS:000254161500002	
J	Cano, JR; Herrera, F; Lozano, M				Cano, Jose Ramon; Herrera, Francisco; Lozano, Manuel			Evolutionary stratified training set selection for extracting classification rules with trade off precision-interpretability	DATA & KNOWLEDGE ENGINEERING			English	Article						training set selection; interpretability; precision; evolutionary algorithms; rule classification; decision trees	DECISION TREES; INSTANCE SELECTION; LEARNING ALGORITHMS; REDUCTION	The generation of predictive models is a frequent task in data mining with the objective of generating highly precise and interpretable models. The data reduction is an interesting preprocessing approach that can allow us to obtain predictive models with these characteristics in large size data sets. In this paper, we analyze the rule classification model based on decision trees using a training selected set via evolutionary stratified instance selection. This method faces the scaling problem that appears in the evaluation of large size data sets, and the trade off interpretability-precision of the generated models. (c) 2006 Elsevier B.V. All rights reserved.	Univ Jaen, Dept Comp Sci, Linares 23700, Jaen, Spain; Univ Granada, Dept Comp Sci & Artificial Intelligence, Granada 18071, Spain	Cano, JR (reprint author), Univ Jaen, Dept Comp Sci, Linares 23700, Jaen, Spain.	jrcano@ujaen.es; herrera@decsai.ugr.es; lozano@decsai.ugr.es	Herrera, Francisco/C-6856-2008; Lozano Marquez, Manuel/B-1848-2012	Herrera, Francisco/0000-0002-7283-312X; 			Aguilar J. S., 2001, Intelligent Data Analysis, V5; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Anderson T. W., 1984, INTRO MULTIVARIATE S; Back T., 1996, EVOLUTIONARY ALGORIT; BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1007/BF00993345; Breslow LA, 1997, KNOWL ENG REV, V12, P1, DOI 10.1017/S0269888997000015; Cano JR, 2005, PATTERN RECOGN LETT, V26, P953, DOI 10.1016/j.patrec.2004.09.043; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; ESHELMAN L. J., 1991, FDN GENETIC ALGORITH, V1, P265; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOLDBERG D, 2002, DESIGN COMPETENT GEN; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GROCHOWSKI M, 2004, LNAI, P580; GROCHOWSKI M, 2004, LECT NOTES COMPUTER, V3070, P598; HALL LO, 2002, INT C TOOLS ART INT, P233; HART PE, 1968, IEEE T INFORM THEORY, V18, P431; John G. H., 1995, P 1 INT C KNOWL DISC, P174; Kibbler D., 1987, P 4 INT WORKSH MACH, P24; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Last M, 2004, IEEE T KNOWL DATA EN, V16, P203, DOI 10.1109/TKDE.2004.1269598; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; NEWMAN CGD, 1998, UCI RESPOSITORY MACH; Oates T, 1997, P 14 INT C MACH LEAR, P254; Oates T., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Osei-Bryson KM, 2004, COMPUT OPER RES, V31, P1933, DOI 10.1016/S0305-0548(03)00156-4; Pedreira CE, 2006, IEEE T PATTERN ANAL, V28, P157, DOI 10.1109/TPAMI.2006.14; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Sebban M., 2000, International Journal of Computers, Systems and Signals, V1; Reeves C. R., 2001, INSTANCE SELECTION C, P339; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SCHAFFER C, 1991, P EUR WORK SESS LEAR, P192; Sebban M., 2000, P 17 INT C MACH LEAR, P855; Shinn-Ying Ho, 2002, Pattern Recognition Letters, V23, DOI 10.1016/S0167-8655(02)00109-5; SIERRA B, 2001, LECT NOTES COMPUTER, P20; VALLS JM, 2003, APPL INFORMATICS, P275; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten IH, 2000, DATA MINING PRACTICA; Zhou ZH, 2003, IEEE T INF TECHNOL B, V7, P37, DOI 10.1109/TITB.2003.808498; *SPSS INC, 1999, SPPSS 11 0 ADV MOD	41	38	38	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	JAN	2007	60	1					90	108		10.1016/j.datak.2006.01.008		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	115GA	WOS:000242721600006	
S	Nguyen, HS		Peters, JF; Skowron, A		Nguyen, Hung Son			Approximate Boolean reasoning: Foundations and applications in data mining	TRANSACTIONS ON ROUGH SETS V	Lecture Notes in Computer Science		English	Article						rough sets; data mining; Boolean reasoning; feature selection and extraction; decision rule construction; discretization; decision tree induction; association rules; large data tables	ROUGH SET-THEORY; CONTINUOUS ATTRIBUTES; DISCRETIZATION; CLASSIFICATION; REDUCTS; IMPLICANTS; COMPLEXITY; SYSTEMS; RULES; DNF	Since its introduction by George Boole during the mid-1800s, Boolean algebra has become an important part of the lingua franca of mathematics, science, engineering, and research in artificial intelligence, machine learning and data mining. The Boolean reasoning approach has manifestly become a powerful tool for designing effective and accurate solutions for many problems in decision-making and approximate reasoning optimization. In recent years, Boolean reasoning has become a recognized technique for developing many interesting concept approximation methods in rough set theory. The problem considered in this paper is the creation of a general framework for concept approximation. The need for such a general framework arises in machine learning and data mining. This paper presents a solution to this problem by introducing a general framework for concept approximation which combines rough set theory, Boolean reasoning methodology and data mining. This general framework for approximate reasoning is called Rough Sets and Approximate Boolean Reasoning (RSABR). The contribution of this paper is the presentation of the theoretical foundation of RSABR as well as its application in solving many data mining problems and knowledge discovery in databases (KDD) such as feature selection, feature extraction, data preprocessing, classification of decision rules and decision trees, association analysis.	Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland	Nguyen, HS (reprint author), Warsaw Univ, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.	son@mimuw.edu.pl	Nguyen, Hung Son /I-7452-2012				Agrawal R., 1993, ACM SIGMOD INT C MAN, P207; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Alsabti K., 1998, KNOWLEDGE DISCOVERY, P2; ANDRADE H, 2000, CSTR4203 UMIACS U MA; ANTHONY M, 1992, CAMBRIDGE TRACTS THE, V30; Bazan J, 2003, LECT NOTES ARTIF INT, V2639, P181; Bazan J. G., 1994, LECT NOTES ARTIF INT, V869, P346; Bazan J.G., 2001, LECT NOTES ARTIF INT, V2005, P106; Blake A., 1937, THESIS U CHICAGO; Boole G., 1847, MATH ANAL LOGIC; BOOLE G, 1854, LAW THOUGHT; Breiman L, 1984, CLASSIFICATION REGRE; Brown F. M., 1990, BOOLEAN REASONING; CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164; CHANDRA AK, 1978, DISCRETE MATH, V24, P7, DOI 10.1016/0012-365X(78)90168-1; Chang C.-L., 1973, SYMBOLIC LOGIC MECH; CHLEBUS BS, 1 INT C ROUGH SETS S, P537; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cohen WW, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P709; DAVIS M, 1962, COMMUN ACM, V5, P394, DOI 10.1145/368273.368557; DAVIS M, 1960, J ACM, V7, P201, DOI 10.1145/321033.321034; Dougherty J, 1995, INT C MACH LEARN, P194; DUENTSCH I, 2000, P 8 INT C IPMU 2000, P220; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Fayyad U, 1996, P 2 INT C KNOWL DISC, P367; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FRIEDMAN JH, 1996, 13 NAT C ART INT 8 I, V1, P717; Gallaire H., 1978, LOGIC DATABASES; Garey M. R., 1979, COMPUTERS INTRACTABI; Goldberg E., 2002, Proceedings 2002 Design, Automation and Test in Europe Conference and Exhibition, DOI 10.1109/DATE.2002.998262; Goldsmith J, 2005, LECT NOTES COMPUT SC, V3618, P410; Greco S., 2002, HDB DATA MINING KNOW, P318; Grzymala-Busse JW, 2000, COMMUN ACM, V43, P108, DOI 10.1145/332051.332082; Han J., 2000, 2000 ACM SIGMOD INT, P1; Han J., 2000, DATA MINING CONCEPTS; Hand D. J., 2001, PRINCIPLES DATA MINI; HAYESROTH F, 1983, BUILDING EXPERT SYST, P3; HEATH D, 1993, IJCAI-93, VOLS 1 AND 2, P1002; Hoa Nguyen S., 1996, P C INF PROC MAN UNC, P1451; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; HUNTINGTON Edward V., 1933, T AM MATH SOC, V35, P557, DOI 10.2307/1989783; Jensen R, 2005, LECT NOTES ARTIF INT, V3641, P194; JEROSLOW RG, 1988, LOGIC BASED DECISION; Kautz H A, 1992, P 10 EUR C ART INT E, P359; Kautz H, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1194; Keefe R., 2000, CAMBRIDGE STUDIES PH; Kerber R., 1992, P 10 NAT C ART INT, P123; KLOESGEN W, 2002, HDB KNOWLEDGE DISCOV; Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; Kowalski R. A., 1980, LOGIC PROBLEM SOLVIN; KRYSZKIEWICZ M, 1997, ROUGH SETS DATA MINI, P355; KRYSZKIEWICZ M, 2004, LECT NOTES COMPUTER, V3135, P120; LIU H, 1999, FEATURE SELECTION KN; LIU H, 1995, TAI 95 P 7 INT C TOO, P88; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; LOVELAND DW, 1978, FUNDAMENTAL STUDIES, V6; Maimon O., 2005, DATA MINING KNOWLEDG; Manquinho VM, 1997, PROC INT C TOOLS ART, P232, DOI 10.1109/TAI.1997.632261; Marques-Silva J. P., 1996, P IEEE ACM INT C COM, P220, DOI 10.1109/ICCAD.1996.569607; Mehta M., 1995, P 1 INT C KNOWL DISC, P216; Mehta M., 1996, EXTENDING DATABASE T, P18; Michalewicz Z., 1994, GENETIC ALGORITHMS D; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHALSKI RS, 1973, P 3 INT JOINT C ART, P162; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; Mitchell TM, 1998, MACHINE LEARNING; MOSKEWICZ YZM, 2001, P 38 DES AUT C DAC20; Murthy S, 1994, J ARTIFICIAL INTELLI, V2, P1; Nguyen H. S., 1997, THESIS WARSAW U WARS; Nguyen H. S., 1998, Fundamenta Informaticae, V34; Nguyen H. S., 2005, INT J HYBRID INTELLI, V2, P149; Nguyen H. S., 1995, P 2 JOINT ANN C INF, P34; Nguyen H.S., 1998, LECT NOTES ARTIF INT, V1424, P545; NGUYEN HS, 1997, P 3 JOINT C INF SCI, V3, P81; NGUYEN HS, 1999, P 16 INT JOINT C ART, P806; NGUYEN HS, 2003, ELECT NOTES THEORETI, V82; NGUYEN HS, 2005, 2005 IEEE WIC ACM IN; Nguyen HS, 2002, LECT NOTES ARTIF INT, V2475, P433; NGUYEN HS, 1996, P 4 INT WORKSH ROUGH, P82; Nguyen HS, 2002, ADV SOFT COMP, P57; Nguyen HS, 1999, LECT NOTES ARTIF INT, V1711, P137; Nguyen HS, 2005, LECT NOTES ARTIF INT, V3642, P12; NGUYEN HS, 2003, COGNITIVE TECHNOLOGI, P333; NGUYEN HS, 2005, 9 PAC AS C KNOWL DIS; Nguyen H.S., 2001, FUNDAMENTA INFORM, V48, P61; Nguyen H.S., 1998, ROUGH SETS KNOWLEDGE, P451; NGUYEN HS, 2002, ROUGH NEUROCOMPUTING, P333; Nguyen S. H., 1998, Fundamenta Informaticae, V34; Nguyen S. H., 1998, STUDIES FUZZINESS SO, V19, P55; Nguyen S.H., 1998, P C INF PROC MAN UNC, P1346; NGUYEN SH, 1996, 6 INT C INF PROC MAN, V3, P1451; NGUYEN SH, 2000, THESIS WARSAW U WARS; Nguyen SH, 2004, LECT NOTES COMPUT SC, V3100, P187; Nguyen SH, 2000, STUD FUZZ SOFT COMP, V56, P289; Ohm A, 1998, STUDIES FUZZINESS SO, V19, P572; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1981, 429 PAS I COMP SCI; PAWLAK Z, 1984, INT J MAN MACH STUD, V20, P469, DOI 10.1016/S0020-7373(84)80022-X; Pawlak Z., 1991, SYSTEM THEORY KNOWLE, V9; PAWLAK Z, 1990, MACHINE LEARNING UNC, V3, P227; PAWLAK Z, 1981, INFORM SYST, V6, P205, DOI 10.1016/0306-4379(81)90023-5; PAWLAK Z, 2004, T ROUGH SETS, V1, P1; Pfahringer B, 1995, P 12 INT C MACH LEAR, P456; Pizzuti C, 1996, PROC INT C TOOLS ART, P332, DOI 10.1109/TAI.1996.560473; Polkowski, 1998, STUDIES FUZZINESS SO, V18, P321; Polkowski L., 2000, STUDIES FUZZINESS SO, V56; Polkowski L, 1998, STUDIES FUZZINESS SO, V19; Prosser P., 1993, COMPUT INTELL, V9, P268, DOI 10.1111/j.1467-8640.1993.tb00310.x; Provost F.J., 1997, KNOWLEDGE DISCOVERY, P43; Quafafou M, 2000, INFORM SCIENCES, V124, P301, DOI 10.1016/S0020-0255(99)00075-4; QUINE WV, 1961, MATH LOGIC; Quine W.V.O., 1959, AM MATH MONTHLY, V66, P755, DOI 10.2307/2310460; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Quinlan R., 1986, MACH LEARN, V1, P81; Ramakrishnan S., 1994, 20 INT C VER LARG DA, P487; Richeldi M, 1995, LECT NOTES ARTIF INT, V912, P335; RISSANEN J, 1985, MINIMUM DESCRIPTION, P523; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rudeanu S., 1974, BOOLEAN FUNCTIONS EQ; RYAN L, 2004, THESIS S FRASER U BU; Sarle W. S., 1995, P 27 S INT; SELMAN B, 1997, P 15 INT JOINT C ART, P50; Selman B., 1992, P 10 NAT C ART INT A, P459; SEN S, 1993, SAC 93 P 1993 ACM SI, P157; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; Shannon C.E., 1938, Transactions of the American Institute of Electrical Engineers, V57; SHANNON CE, 1940, SYMBOLIC ANAL RELAY; Skowron A., 2002, HDB KDD, P134; Skowron A., 1996, Fundamenta Informaticae, V27; SKOWRON A, 2003, SPECIAL VOLUME ROUGH, V24; Skowron A, 1999, LECT NOTES ARTIF INT, V1704, P107; Skowron A., 1993, LECT NOTES ARTIF INT, V689, P295; Skowron A., 2000, 16th World Computer Congress 2000. Proceedings of Conference on Intelligent Information Processing; Slezak D, 2002, FUND INFORM, V53, P365; Slowinski R., 1997, ADV MACHINE INTELLIG, VIV, P17; Slowinski R., 1992, INTELLIGENT DECISION; STEFANOWSKI J, 2001, INT J COMPUTATIONAL, V17, P545; STOLORZ P, 1998, SCALABLE HIGH PERFOR; Stone MH, 1936, T AM MATH SOC, V40, P37, DOI 10.2307/1989664; Taylor C.C., 1994, MACHINE LEARNING NEU; Umans C, 2001, J COMPUT SYST SCI, V63, P597, DOI 10.1006/jcss.2001.1775; Vapnik V. N., 1998, STAT LEARNING THEORY; Witten IH, 2005, DATA MINING PRACTICA; WNEK J, 1994, MACH LEARN, V14, P139, DOI 10.1023/A:1022622132310; Wroblewski J., 1996, Fundamenta Informaticae, V28; WROBLEWSKI J, 2002, THESIS WARSAW U WARS; ZADEH L, 1999, COMPUT MATH APPL, V37; ZAKI MJ, 1998, 7 INT C INF KNOWL MA, P68; Ziarko W., 1994, ROUGH SETS FUZZY SET; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2; Ziarko W., 1991, Knowledge discovery in databases; SKOWRON A, 1995, FR ART INT, V28, P220	156	38	42	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-39382-X	LECT NOTES COMPUT SC			2006	4100						334	506				173	Computer Science, Theory & Methods	Computer Science	BFJ88	WOS:000242418100016	
J	Li, J; Narayanan, RM				Li, J; Narayanan, RM			Integrated spectral and spatial information mining in remote sensing imagery	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						classifcation; clustering; image information mining; remote sensing; texture	SUPPORT VECTOR MACHINES; NEURAL NETWORKS; SENSED DATA; RETRIEVAL; CLASSIFICATION; TRANSFORMS; ALGORITHM	Most existing remote sensing image retrieval systems allow only simple queries based on sensor, location, and date of image capture. This approach does not permit the efficient retrieval of useful hidden information from large image databases. This paper presents an integrated approach to retrieving spectral and spatial patterns from remotely sensed imagery using state-of-the-art data mining and advanced database technologies. Land cover information corresponding to spectral characteristics is identified by supervised classification based on support vector machines with automatic model selection, while textural features characterizing spatial information are extracted using Gabor wavelet coefficients. Within identified land cover categories, textural features are clustered to acquire search-efficicnt space in an object-oriented database with associated images in an image database. Interesting patterns are then retrieved using a query-by-example approach. The evaluation of the study results using coverage and novelty measures validates the effectiveness of the proposed remote sensing image information mining framework, which is potentially useful for applications such as agricultural and environmental monitoring.	Austin Peay State Univ, Dept Comp Sci & Informat Technol, Clarksville, TN 37044 USA; Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA	Li, J (reprint author), Austin Peay State Univ, Dept Comp Sci & Informat Technol, Clarksville, TN 37044 USA.	ram@ee.psu.edu					Albuz E, 2001, IEEE T KNOWL DATA EN, V13, P851, DOI 10.1109/69.956109; AZIMISADJADI MR, 2000, P IEEE GEOSC REM SEN, V2, P669; BAEZAYATES R, 1999, INFORMATION RETRIEVA; BAUMANN P, 1999, P 25 VLDB C ED UK; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Burl MC, 1999, P SOC PHOTO-OPT INS, V3695, P197, DOI 10.1117/12.339982; BURL MC, 1999, P C SYST CYB INF INF; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chapelle O, 2000, ADV NEUR IN, V12, P230; CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B; Cortes C, 1995, MACH LEARN, V20, P1; Cristianini N., 2000, INTRO SUPPORT VECTOR; CROMP RF, 1993, P 2 INT C INF KNOWL, P471, DOI 10.1145/170088.170397; Datcu M., 2000, P IEEE AER C BIG SKY, V3, P253; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FUKUDA S, 2001, P IGARSS SYDN AUSTR, V1, P187; GUALTIERI J. A., 1999, JPL PUB, V99-17, P217; Jensen J. R., 1996, INTRO DIGITAL IMAGE; Ji CY, 2000, PHOTOGRAMM ENG REM S, V66, P1451; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Koperski K., 2002, P IGARSS TOR ON CAN, V3, P1810; KORFHAGE R, 1997, INFORMATION STORAGE; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; MARCHISIO G, 1999, P IGARSS 99, V1, P290; PELLEG D, 2000, P 17 INT C MACH LEAR, P727; Pena JM, 1999, PATTERN RECOGN LETT, V20, P1027, DOI 10.1016/S0167-8655(99)00069-0; Pichler O, 1996, PATTERN RECOGN, V29, P733, DOI 10.1016/0031-3203(95)00127-1; Ramachandran R, 2000, P SOC PHOTO-OPT INS, V4057, P259, DOI 10.1117/12.381740; Ray S, 1999, P 4 INT C ADV PATT R, P137; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/cviu.1993.1024; SCHAALE M, 2000, P ASPRS RTI ANN C WA; SCHOLKOPF B, 1996, 1599 MIT AI; Shekhar S, 2002, IEEE T MULTIMEDIA, V4, P174, DOI 10.1109/TMM.2002.1017732; SOH LK, 1998, P IGARSS SEATTL WA J, V2, P798; Sohn Y, 2002, PHOTOGRAMM ENG REM S, V68, P1271; SRIVASTAVA A, 2003, P 12 INT C MACH LEAR; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; VELLAIKAL A, 1995, P SOC PHOTO-OPT INS, V2488, P178, DOI 10.1117/12.211973; Zhang J., 2001, P 2 INT WORKSH MULT, P13	42	38	42	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	MAR	2004	42	3					673	685		10.1109/TGRS.2004.824221		13	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	813KM	WOS:000220906000020	
J	Li, YJ; Ning, P; Wang, XS; Jajodia, S				Li, YJ; Ning, P; Wang, XS; Jajodia, S			Discovering calendar-based temporal association rules	DATA & KNOWLEDGE ENGINEERING			English	Article						knowledge discovery; temporal data mining; association rule; time granularity	PATTERNS	We study the problem of mining association rules and related time intervals, where an association rule holds either in all or some of the intervals. To restrict to meaningful time intervals, we use calendar schemas and their calendar-based patterns. A calendar schema example is (year, month, day) and a calendar-based pattern within the schema is ((*), 3, 15), which represents the set of time intervals each corresponding to the 15th day of a March. Our focus is finding efficient algorithms for this mining problem by extending the well-known Apriori algorithm with effective pruning techniques. We evaluate our techniques via experiments. (C) 2002 Published by Elsevier Science B.V.	George Mason Univ, Ctr Secure Informat Syst, Fairfax, VA 22030 USA; N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA	Li, YJ (reprint author), George Mason Univ, Ctr Secure Informat Syst, Fairfax, VA 22030 USA.	yli@ise.gmu.edu; ning@csc.ncsu.edu; xywang@gmu.edu; jajodia@gmu.edu					Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1994, 9839 RJ IBM ALM RES; Ale J.M., 2000, P 2000 ACM S APPL CO, P294, DOI 10.1145/335603.335770; Bayardo RJ, 1999, PROC INT CONF DATA, P188, DOI 10.1109/ICDE.1999.754924; Bettini C, 1998, IEEE T KNOWL DATA EN, V10, P222, DOI 10.1109/69.683754; Bettini C, 2000, TIME GRANULARITIES D; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; CHEN X, 1998, P 9 INT C DAT EXP SY, P796; Chen XD, 1999, LECT NOTES ARTIF INT, V1704, P295; HAN EH, 1997, P ACM SIGMOD INT C M, P277, DOI 10.1145/253260.253330; HAN J, 1995, P 15 INT C DAT ENG, P106; Han J, 1995, P 21 INT C VER LARG, P420; KOHAVI R., 2000, SIGKDD EXPLORATIONS, V2, P86; Leban B., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; LI Y, 2001, P ACM SIGKDD 2001 WO, P97; LI Y, 2001, P 8 INT S TEMP REPR, P111; LI Y, 2000, LECT NOTES ARTIF INT, V2007, P5; LU H, 1998, P ACM SIGMOD 1998 WO; Mannila H., 1995, P 1 INT C KNOWL DISC, P210; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; NG R, 1999, P ACM SIGMOD C MAN D, P556, DOI 10.1145/304182.304575; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; Rainsford CP, 1999, LECT NOTES ARTIF INT, V1704, P504; Ramaswamy S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; RODDICK JF, 2001, ACM SIGKDD 2001 WORK, P167; Savasere A, 1995, P 21 INT C VER LARG, P432; SHINTANI T, 1998, P ACM SIGMOD INT C M, P25, DOI 10.1145/276304.276308; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; Srikant R., 1995, P 21 INT C VER LARG, P407; Wang W, 2001, PROC INT CONF DATA, P283; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining	34	38	45	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	FEB	2003	44	2					193	218		10.1016/S0169-023X(02)00135-0		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634UN	WOS:000180359900004	
J	Aggarwal, CC; Yu, PS				Aggarwal, CC; Yu, PS			A new approach to online generation of association rules	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						OLAP; association rules; data mining; knowledge discovery		We discuss the problem of online mining of association rules in a large database of sales transactions. The online mining is performed by preprocessing the data effectively in order to make it suitable for repeated online queries. We store the preprocessed data in such a way that online processing may be done by applying a graph theoretic search algorithm whose complexity is proportional to the size of the output. The result is an online algorithm which is independent of the size of the transactional data and the size of the preprocessed data. The algorithm is almost instantaneous in the size of the output. The algorithm also supports techniques for quickly discovering association rules from large itemsets. The algorithm is capable of finding rules with specific items in the antecedent or consequent. These association rules are presented in a compact form, eliminating redundancy. The use of nonredundant association rules helps significantly in the reduction of irrelevant noise in the data mining process.	IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Aggarwal, CC (reprint author), IBM Corp, TJ Watson Res Ctr, 30 Saw Mill River Rd, Hawthorne, NY 10532 USA.	charu@us.ibm.com; psyu@us.ibm.com	Yu, Philip/A-2815-2012				AGGARWAL CC, 1998, P KDD C; AGGARWAL CC, 1998, ICDE C; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P478; AGRAWAL S, P 22 INT C VER LARG, P506; CHEN MS, 20556 IBM; Dyreson C, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P532; GUPTA A, 1995, P 21 C VER LARG DAT; Han J, 1995, P 21 INT C VER LARG, P420; HARINARAYAN V, 1995, P 1996 ACM SIGMOD C, P205; Kaufman L., 1990, FINDING GROUPS DATA; KLEMENTTINEN M, 1994, P C INF KNOWL MAN; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Ng R, 1994, P 20 INT C VER LARG, P144; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; PIATATSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Savasere A, 1995, P 21 INT C VER LARG, P432; Shukla A, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P522; SRIKANT R, 1996, P 1996 ACM SIGMOD C; Srikant R., 1995, P 21 INT C VER LARG, P407; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; ZIARKO W, 1991, KNOWLEDGE DISCOVERY	25	38	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL-AUG	2001	13	4					527	540		10.1109/69.940730		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	460AK	WOS:000170283500001	
J	Wang, CZ; Wu, CX; Chen, DG				Wang, Changzhong; Wu, Congxin; Chen, Degang			A systematic study on attribute reduction with rough sets based on general binary relations	INFORMATION SCIENCES			English	Article						attribute reduction; discernibility matrix; rough sets based on general binary relations; relation information systems; relation decision systems	INCOMPLETE INFORMATION-SYSTEMS; KNOWLEDGE REDUCTION; FEATURE-SELECTION; MODEL; RULES	Attribute reduction is considered as an important preprocessing step for pattern recognition, machine learning, and data mining. This paper provides a systematic study on attribute reduction with rough sets based on general binary relations. We define a relation information system, a consistent relation decision system, and a relation decision system and their attribute reductions. Furthermore, we present a judgment theorem and a discernibility matrix associated with attribute reduction in each type of system; based on the discernibility matrix, we can compute all the reducts. Finally, the experimental results with UCI data sets show that the proposed reduction methods are an effective technique to deal with complex data sets. (c) 2008 Elsevier Inc. All rights reserved.	[Wang, Changzhong; Wu, Congxin] Harbin Inst Technol, Dept Math, Harbin 150001, Heilongjiang, Peoples R China; [Chen, Degang] N China Elect Power Univ, Dept Math & Phys, Beijing 102206, Peoples R China	Wang, CZ (reprint author), Harbin Inst Technol, Dept Math, Harbin 150001, Heilongjiang, Peoples R China.	changzhongwang@126.com; chengdedang@263.net					Bazan J., 1998, ROUGH SETS KNOWLEDGE, P321; Beynon M, 2001, EUR J OPER RES, V134, P592, DOI 10.1016/S0377-2217(00)00280-0; Bonikowski Z., 1994, ROUGH SETS FUZZY SET, P243; Bonikowski Z, 1998, INFORM SCIENCES, V107, P149, DOI 10.1016/S0020-0255(97)10046-9; Bryniarski E., 1989, B POL ACAD SCI, V16, P71; Cattaneo G., 1998, ROUGH SETS KNOWLEDGE, V1, P59; Chen D., 2006, INFORM SCI, V176, P1829; Chen DG, 2007, INFORM SCIENCES, V177, P3500, DOI 10.1016/j.ins.2007.02.041; Chen DG, 2004, LECT NOTES ARTIF INT, V3066, P477; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; Greco S, 2002, EUR J OPER RES, V138, P247, DOI 10.1016/S0377-2217(01)00244-2; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; Hall M. A., 2000, P 17 INT C MACH LEAR, P359; HU Q, 2006, EXPERT SYSTEMS APPL; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; Hu QH, 2004, INT J UNCERTAIN FUZZ, V12, P575, DOI 10.1142/S0218488504003089; Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086; Kryszkiewicz M, 2001, INT J INTELL SYST, V16, P105, DOI 10.1002/1098-111X(200101)16:1<105::AID-INT8>3.0.CO;2-S; Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1; Kryszkiewicz M, 1999, INFORM SCIENCES, V113, P271, DOI 10.1016/S0020-0255(98)10065-8; Mi JS, 2004, INFORM SCIENCES, V159, P255, DOI 10.1016/j.ins.2003.07.004; Mordeson JN, 2001, FUZZY SET SYST, V121, P315, DOI 10.1016/S0165-0114(00)00023-3; NEWMAN DJ, 1998, UCI REPOSITORY MACH; NGUYEN HS, 1985, LNCS, V4100, P334; Nguyen HS, 1999, LECT NOTES ARTIF INT, V1711, P137; Nguyen SH, 2000, STUD FUZZ SOFT COMP, V56, P289; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 2006, INFORM SCI, V177, P41; Pawlak Z, 1998, CYBERNET SYST, V29, P661, DOI 10.1080/019697298125470; PAWLAK Z, 2006, INFORM SCI, V177, P28; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pawlak Z., 2006, INFORM SCI, V177, P3; Polkowski L., 1995, SOFT COMPUTING ROUGH, P55; Polkowski L., 1994, P RSSC 94 3 WORKSH R, P142; Pomykata J., 1987, B POLISH ACAD SCI MA, V35, P653; Quafafou M, 2000, INFORM SCIENCES, V124, P301, DOI 10.1016/S0020-0255(99)00075-4; Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A., 1992, INTELLIGENT DECISION, P331; Slezak D., 1998, P IPMU 98 PAR FRANC, V2, P1362; Slezak D, 1996, P IPMU 96 GRAN SPAIN, V3, P1159; Slowinski R, 2000, IEEE T KNOWL DATA EN, V12, P331, DOI 10.1109/69.842271; Stefanowski J., 1998, ROUGH SETS KNOWLEDGE, V1, P500; Wu WZ, 2005, INFORM SCIENCES, V174, P143, DOI 10.1016/j.ins.2004.09.002; Wybraniec-Skardowska U., 1989, B POLISH ACAD SCI MA, V37, P51; Yao YY, 1998, INFORM SCIENCES, V109, P21, DOI 10.1016/S0020-0255(98)00012-7; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Yeung DS, 2005, IEEE T FUZZY SYST, V13, P343, DOI 10.1109/TFUZZ.2004.841734; Yu Da-ren, 2004, Proceedings of the CSEE, V24; Yu L, 2004, J MACH LEARN RES, V5, P1205; Zakowski W., 1983, DEMONSTRATIO MATH, V16, P761; Zhang W.X., 2001, THEORY METHODS ROUGH; Zhu W., 2007, INFORM SCI, V177, P1892; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	55	37	44	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	MAY 1	2008	178	9					2237	2261		10.1016/j.ins.2008.01.007		25	Computer Science, Information Systems	Computer Science	289QJ	WOS:000255068700010	
J	Prinzie, A; Van den Poel, D				Prinzie, Anita; Van den Poel, Dirk			Random forests for multiclass classification: Random MultiNomial Logit	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						multiclass classifier design and evaluation; feature evaluation and selection; data mining methods and algorithms; customer relationship management (CRM)	SUPPORT VECTOR MACHINES; MODEL; OPTIMIZATION; CLASSIFIERS; ANNOTATION; ALGORITHMS; STRATEGIES; SELECTION	Several supervised learning algorithms are suited to classify instances into a multiclass value space. MultiNomial Logit (MNL) is recognized as a robust classifier and is commonly applied within the CRM (Customer Relationship Management) domain. Unfortunately, to date, it is unable to handle huge feature spaces typical of CRM applications. Hence, the analyst is forced to immerse himself into feature selection. Surprisingly, in sharp contrast with binary logit, current software packages lack any feature-selection algorithm for MultiNomial Logit. Conversely, Random Forests, another algorithm learning multiclass problems, is just like MNL robust but unlike MNL it easily handles high-dimensional feature spaces. This paper investigates the potential of applying the Random Forests principles to the MNL framework. We propose the Random MultiNomial Logit (RMNL), i.e. a random forest of MNLs, and compare its predictive performance to that of (a) MNL with expert feature selection, (b) Random Forests of classification trees. We illustrate the Random MultiNomial Logit on a cross-sell CRM problem within the home-appliances industry. The results indicate a substantial increase in model accuracy of the RMNL model to that of the MNL model with expert feature selection. (C) 2007 Elsevier Ltd. All rights reserved.	[Prinzie, Anita; Van den Poel, Dirk] Univ Ghent, Dept Mkt, B-9000 Ghent, Belgium	Prinzie, A (reprint author), Univ Ghent, Dept Mkt, B-9000 Ghent, Belgium.	Anita.Prinzie@UGent.be; Dirk.VandenPoel@UGent.be					Agrawal D, 1996, J RETAILING, V72, P383, DOI 10.1016/S0022-4359(96)90020-2; ANAS A, 1983, TRANSPORT RES B-METH, V17, P13, DOI 10.1016/0191-2615(83)90023-1; Baltas G, 2001, J BUS RES, V51, P115, DOI 10.1016/S0148-2963(99)00058-2; Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Barsalou L. W., 1991, PSYCHOL LEARN MOTIV, P1; Ben-Akiva M., 1985, DISCRETE CHOICE ANAL; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, WADSWORTH STAT PROBA, P358; Buchtala O, 2005, IEEE T SYST MAN CY B, V35, P928, DOI 10.1109/TSMCB.2005.847743; Buckinx W, 2005, EUR J OPER RES, V164, P252, DOI 10.1016/j.ejor.2003.12.010; Chetouani M, 2005, LECT NOTES ARTIF INT, V3445, P344; CORFMAN KP, 1991, J MARKETING RES, V28, P368, DOI 10.2307/3172873; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007; Dietterich T.G., 2000, MACH LEARN, V40, P1; Dietterich TG, 1997, AI MAG, V18, P97; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170; GREEN DM, 1966, SIGNAL DETECTION THE; Huang XH, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-205; Jain A. K., 2000, IEEE T PATTERN ANAL, V22; JOHNSON MD, 1984, J CONSUM RES, V11, P741, DOI 10.1086/209010; Knott A., 2002, J INTERACT MARK, V16, P59, DOI 10.1002/dir.10038; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Lunetta KL, 2004, BMC GENET, V5, DOI 10.1186/1471-2156-5-32; Luo T, 2004, IEEE T SYST MAN CY B, V34, P1753, DOI 10.1109/TSMCB.2004.830340; MORRISON DG, 1969, J MARKETING RES, V6, P156, DOI 10.2307/3149666; Novovicova J, 2003, LECT NOTES COMPUT SC, V2652, P646; Peng SH, 2003, FEBS LETT, V555, P358, DOI 10.1016/S0014-5793(03)01275-4; PRINZIE A, IN PRESS DECISION SU; Prinzie A, 2005, EXPERT SYST APPL, V29, P630, DOI 10.1016/j.eswa.2005.04.022; Schwender H, 2004, TOXICOL LETT, V151, P291, DOI 10.1016/j.toxlet.2004.02.021; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Xing E. P., 2001, P 18 INT C MACH LEAR, P601	39	37	38	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2008	34	3					1721	1732		10.1016/j.eswa.2007.01.029		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	262YB	WOS:000253183700014	
J	Uncu, O; Turksen, IB				Uncu, Oezge; Tuerksen, I. B.			A novel feature selection approach: Combining feature wrappers and filters	INFORMATION SCIENCES			English	Article						feature wrappers; feature filters; approximate functional dependency; fuzzy discretization; cluster validity index		Feature selection is one of the most important issues in the research fields such as system modelling, data mining and pattern recognition. In this study, a new feature selection algorithm that combines feature wrapper and feature filter approaches is proposed in order to identify the significant input variables in systems with continuous domains. The proposed method utilizes functional dependency concept, correlation coefficients and K-nearest neighbourhood (KNN) method to implement the feature filter and feature wrappers. Four feature selection methods independently select the significant input variables and the input variable combination, which yields best result with respect to their corresponding evaluation function, is selected as the winner. This is similar to the basic information fusion notion of integrating the information collected from different sources. All of the four feature selection methods are performed in two stages: (i) pre-selection, (ii) selection. Two of the four feature selection methods utilize KNN method for evaluating the candidates. These two methods use sequential forward and sequential backward search mechanism, respectively, in pre-selection stage. Whereas, the third feature selection method uses correlation coefficients in the pre-selection stage. It is common to have outliers and noise in real-life data. In order to make the proposed feature selection algorithm noise and outlier resistant, approximate functional dependencies are used by utilizing membership values that inherently cope with uncertainty in the data. Thus, the fourth feature selection method makes use of approximate functional dependencies to evaluate candidates in pre-selection stage. All of these four methods apply KNN method with exhaustive search strategy in order to find the most suitable input variable combination with respect to a performance measure. (C) 2006 Elsevier Inc. All rights reserved.	Simon Fraser Univ, Sch Engn Sci, Burnaby, BC 06531, Canada; Univ Toronto, Dept Mech & Ind Engn, Toronto, ON M5S 3G8, Canada	Uncu, O (reprint author), Simon Fraser Univ, Sch Engn Sci, Burnaby, BC 06531, Canada.	ozge.uncu@utoronto.ca; turksen@mie.utoronto.ca					AHA DW, 1975, P 5 INT WORKSH ART I, P1; ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; Bezdek J., 1973, THESIS CORNELL U; Chen MS, 1999, FUZZY SET SYST, V103, P239, DOI 10.1016/S0165-0114(98)00224-3; COHEN WW, 1994, COMPUTATIONAL LEARNI, V2, P171; Doak J., 1992, THESIS U CALIFORNIA; EMAMI MR, 1997, THESIS U TORONTO TOR; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Hall M., 1998, THESIS WAIKATO U; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Jang J.-S. R., 1996, Proceedings of the Fifth IEEE International Conference on Fuzzy Systems. FUZZ-IEEE '96 (Cat. No.96CH35998), DOI 10.1109/FUZZY.1996.552396; Kim DJ, 2001, IEICE T INF SYST, VE84D, P281; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kittler J., 1978, Pattern Recognition and Signal Processing; LAST M, 2000, LECT NOTES COMPUTER, P532; Liu H, 1996, P 13 INT C MACH LEAR, P319; Nakashima T, 1997, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I - III, P1457, DOI 10.1109/FUZZY.1997.619758; NARENDRA PM, 1997, IEEE T COMPUT, V26, P917; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Setiono R, 1995, P 7 IEEE INT C TOOLS, P388; Sproule BA, 1997, CLIN PHARMACOL THER, V62, P29, DOI 10.1016/S0009-9236(97)90149-1; Sridhar DV, 1998, COMPUT CHEM ENG, V22, P613, DOI 10.1016/S0098-1354(97)00227-5; Sugeno M., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390281; Thawonmas R, 1997, IEEE T SYST MAN CY B, V27, P196, DOI 10.1109/3477.558798	26	37	43	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JAN 15	2007	177	2					449	466		10.1016/j.ins.2006.03.022		18	Computer Science, Information Systems	Computer Science	112EV	WOS:000242509400008	
J	Menzies, T; Chen, ZH; Hihn, J; Lum, K				Menzies, Tim; Chen, Zhihao; Hihn, Jairus; Lum, Karen			Selecting best practices for effort estimation	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						model-based effort estimation; COCOMO; deviation; data mining		Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently underconstrained problem. Hence, the learned effort models can exhibit large deviations that prevent standard statistical methods (e.g., t-tests) from distinguishing the performance of alternative effort-estimation methods. The COSEEKMO effort-modeling workbench applies a set of heuristic rejection rules to comparatively assess results from alternative models. Using these rules, and despite the presence of large deviations, COSEEKMO can rank alternative methods for generating effort models. Based on our experiments with COSEEKMO, we advise a new view on supposed "best practices" in model-based effort estimation: 1) Each such practice should be viewed as a candidate technique which may or may not be useful in a particular domain, and 2) tools like COSEEKMO should be used to help analysts explore and select the best method for a particular domain.	W Virginia Univ, Dept Comp Sci, Morgantown, WV 26506 USA; CALTECH, Jet Prop Lab, Pasadena, CA 91109 USA	Menzies, T (reprint author), W Virginia Univ, Dept Comp Sci, Morgantown, WV 26506 USA.	tim@menzies.us; chenscott@gmail.com; jhihn@mail.jpl.nasa.gov; ktlum@mail.jpl.nasa.gov	Chen, Zhihao/A-2208-2010				BASILI V, 2002, P 24 INT C SOFTW ENG; Boehm B. W, 1981, SOFTWARE ENG EC; Boehm B. W., 2000, SOFTWARE COST ESTIMA; Brieman L, 1996, MACH LEARN, V24, P123; CHEN Z, 2005, P PROMISE WORKSH INT; CHEN Z, 2005, IEEE SOFTWARE    NOV; CHULANI BBS, 1998, P C INT SOC PAR AN I; CHULANI S, 1999, IEEE T SOFTWARE  JUL, V25; CHULANI S, 1999, J PARAMETRICS, V15, P175; Cohen P., 1995, EMPIRICAL METHODS AR; Ferens D., 1998, J PARAMETRICS, V18, P55; HABIBAGAHI H, 1998, J PARAMETRICS NOV, P59; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; JENSEN R, 1983, P 5 ISPA C, P88; Jones T. C., 1998, ESTIMATING SOFTWARE; Jorgensen M, 2004, J SYST SOFTWARE, V70, P37, DOI 10.1016/S0164-1212(02)00156-5; Jorgensen Magne, 2004, IEEE T SOFTWARE ENG, V30; KEMERER CF, 1987, COMMUN ACM, V30, P416, DOI 10.1145/22899.22906; KIRSOPP C, 2002, P 22 SGAI INT C KNOW; Kliijnen J, 1997, J STAT COMPUT SIM, V57, P111; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LUM K, 2002, P C INT SOC PAR AN I; MENZIES T, 2005, P INT C SOFTW ENG IC; Miller A. J, 2002, SUBSET SELECTION REG; PARK R, 1988, P 4 COCOMO US GROUP; Provost F. J., 2001, MACHINE LEARNING, V42; PUTNAM LH, 1992, YOURDON PRESS COMPUT; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Shepperd M., 1997, IEEE T SOFTWARE ENG, V23; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; STRUTZKE R, 2005, ESTIMATING SOFTWARE; STUKES S, 1998, J PARAMETRICS, V18, P77; STUKES S, 1991, TR90075491 MAN CONS; Witten I. H., 2005, DATA MINING; Witten I.H., 1999, DATA MINING PRACTICA; Yildiz OT, 2006, IEEE T PATTERN ANAL, V28, P392, DOI 10.1109/TPAMI.2006.61; *ISPA, 2006, P 2006 INT C INT SOC	37	37	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	NOV	2006	32	11					883	895		10.1109/TSE.2006.114		13	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	101EE	WOS:000241720900003	
J	Arshadi, N; Jurisica, I				Arshadi, N; Jurisica, I			Data mining for case-based reasoning in high-dimensional biological domains	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						machine learning; data mining; clustering; feature selection; case-based reasoning classifiers; microarray data analysis; mass spectrometry data analysis; biomarker discovery	OVARIAN-CANCER; GENE-EXPRESSION; SERUM; CLASSIFICATION; PATTERNS; REPRODUCIBILITY; PREDICTION; KNOWLEDGE; SELECTION; SUPPORT	Case-based reasoning (CBR) is a suitable paradigm for class discovery in molecular biology, where the rules that define the domain knowledge are difficult to obtain and the number and the complexity of the rules affecting the problem are too large for formal knowledge representation. To extend the capabilities of CBR, we propose the mixture of experts for case-based reasoning (MOE4CBR), a method that combines an ensemble of CBR classifiers with spectral clustering and logistic regression. Our approach not only achieves higher prediction accuracy, but also leads to the selection of a subset of features that have meaningful relationships with their class labels. We evaluate MOE4CBR by applying the method to a CBR system called TA3-a computational framework for CBR systems. For two ovarian mass spectrometry data sets, the prediction accuracy improves from 80 percent to 93 percent and from 90 percent to 98.4 percent, respectively. We also apply the method to leukemia and lung microarray data sets with prediction accuracy improving from 65 percent to 74 percent and from 60 percent to 70 percent, respectively. Finally, we compare our list of discovered biomarkers with the lists of selected biomarkers from other studies for the mass spectrometry data sets.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; Princess Margaret Hosp, Ontario Canc Inst, Univ Hlth Network, Div Canc Informat, Toronto, ON M5G 2M9, Canada	Arshadi, N (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	niloofar@cs.toronto.edu; juris@ai.utoronto.ca					AHA D, 1998, CAS BAS REAS INT PAP; Aha D.W., 1994, P AAAI 94 WORKSH CAS, P106; ANDRITSOS P., 2004, P INT C EXT DAT TECH, P123; ARSHADI N, 2004, CSRG490 U TOR DEP CO; Arshadi N, 2004, LECT NOTES COMPUT SC, V3155, P17; BAEZA- YATES R., 1999, MODERN INFORMATION R; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; Devore J. L., 1995, PROBABILITY STAT ENG; Dunn J. C., 1974, Journal of Cybernetics, V4; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Han J., 2000, DATA MINING CONCEPTS; Hastie T., 2001, ELEMENTS STAT LEARNI; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jaeger J, 2003, Pac Symp Biocomput, P53; JONES L, 2003, CRITICAL ASSESSMENT, P38; Jurisica I, 1998, ARTIF INTELL MED, V12, P1, DOI 10.1016/S0933-3657(97)00037-7; Jurisica I, 2004, AI MAG, V25, P85; Jurisica I, 2001, IBM SYST J, V40, P394; Jurisica I., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S0218213097000268; JURISICA I, 2000, INT J APPL INTELLIGE, V12, P251; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen Teuvo, 1995, SELF ORG MAPS; Le Cun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Leake D.B, 1996, CASE BASED REASONING; Lenz Mario, 1998, CASE BASED REASONING; Marling C, 2002, AI MAG, V23, P69; Mitchell T. M, 1997, MACHINE LEARNING; Mukherjee S, 2003, PRACTICAL APPROACH M, P166, DOI 10.1007/0-306-47815-3_9; MYLOPOULOS J, 1990, ACM T INFORM SYST, V8, P325, DOI 10.1145/102675.102676; NG AY, 2002, ADV NEURAL INFORMATI, V14; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Xing E. P., 2001, P 18 INT C MACH LEAR, P601; Yang Q, 2000, LECT NOTES ARTIF INT, V1822, P102; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100	41	37	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	AUG	2005	17	8					1127	1137		10.1109/TKDE.2005.124		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	935UP	WOS:000229809200010	
J	Kaya, M; Alhajj, R				Kaya, M; Alhajj, R			Genetic algorithm based framework for mining fuzzy association rules	FUZZY SETS AND SYSTEMS			English	Article						CURE clustering algorithm; fuzzy sets; data mining; genetic algorithms; quantitative attributes; association rules		It is not an easy task to know a priori the most appropriate fuzzy sets that cover the domains of quantitative attributes for fuzzy association rules mining, simply because characteristics of quantitative data are in general unknown. Besides, it is unrealistic that the most appropriate fuzzy sets can always be provided by domain experts. Motivated by this, in this paper we propose an automated method for mining fuzzy association rules. For this purpose, we first present a genetic algorithm (GA) based clustering method that adjusts centroids of the clusters, which are to be handled later as midpoints of triangular membership functions. Next, we give a different method for generating the membership functions by using Clustering Using Representatives (CURE) clustering algorithm, which is known as one of the most efficient clustering algorithms described in the literature. Finally, we compared the proposed GA-based approach with other approaches from the literature. Experiments conducted on 100K transactions from the US census in the year 2000 show that the proposed method exhibits a good performance in terms of execution time and interesting fuzzy association rules. &COPY; 2004 Elsevier B.V. All rights reserved.	Univ Calgary, Dept Comp Sci, Adv Database Syst, Calgary, AB T2N 1N4, Canada; Firat Univ, Dept Comp Engn, TR-23119 Elazig, Turkey	Alhajj, R (reprint author), Univ Calgary, Dept Comp Sci, Adv Database Syst, 2500 Univ Dr, Calgary, AB T2N 1N4, Canada.	alhajj@cpsc.ucalgary.ca					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Au W.H., 1998, P 7 IEEE INT C FUZZ, P1314; Cai C. H., 1998, Proceedings. IDEAS'98. International Database Engineering and Applications Symposium (Cat. No.98EX156), DOI 10.1109/IDEAS.1998.694360; Chien BC, 2001, P IFSA WORLD C NAFIP, V3, P1306; Fu A. W. C., 1998, P INT S INT DAT ENG, P263; Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4; GYENESEI A., 2000, 336 TUCS; GYENESEI A., 2000, 346 TUCS; Hirota K, 1996, P IEEE INT C FUZZ SY, V2, P1448; Hong T. P., 1999, INTELL DATA ANAL, V3, P363, DOI 10.1016/S1088-467X(99)00028-1; Hong T.-P., 1999, P INT C KNOWL BAS IN, P480; Ishibuchi H., 2001, P IEEE INT S IND EL, P118; KAYA M, 2002, P INT C DAT EXP SYST; KAYA M., 2003, P IEEE INT C DAT MIN; Kuok C. M., 1998, SIGMOD REC, P41, DOI DOI 10.1145/273244.273257; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; Michalewicz Z., 1992, GENETIC ALGORITHMS D; Miller R, 1997, P ACM SIGMOD INT C M, P452, DOI 10.1145/253260.253361; NG R., 1994, P INT C VER LARG DAT; Pedrycz W, 1998, FUZZY SET SYST, V98, P279, DOI 10.1016/S0165-0114(96)00377-6; Srikant R., 1996, P ACM SIGMOD INT C M, P1, DOI 10.1145/233269.233311; YAGER RR, 1995, PR CONF ART INT APPL, P265, DOI 10.1109/CAIA.1995.378813; Yue S., 2000, P IEEE INT C SYST MA, P1906; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zhang W., 1999, P IEEE ICTAI, P99	26	37	41	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JUN 16	2005	152	3					587	601		10.1016/j.fss.2004.09.014		15	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	925OX	WOS:000229063500011	
J	Su, CT; Hsu, JH				Su, CT; Hsu, JH			An extended Chi2 algorithm for discretization of real value attributes	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						VPRS model; RST; data mining; discretization	RULES; MODEL	The Variable Precision Rough Sets (VPRS) model is a powerful tool for data mining, as it has been widely applied to acquire knowledge. Despite its diverse applications in many domains, the VPRS model unfortunately cannot be applied to real-world classification tasks involving continuous attributes. This requires a discretization method to preprocess the data. Discretization is an effective technique to deal with continuous attributes for data mining, especially for the classification problem. The modified Chi2 algorithm is one of the modifications to the Chi2 algorithm, replacing the inconsistency check in the Chi2 algorithm by using the quality of approximation, coined from the Rough Sets Theory (RST), in which it takes into account the effect of degrees of freedom. However, the classification with a controlled degree of uncertainty, or a misclassification error, is outside the realm of RST. This algorithm also ignores the effect of variance in the two merged intervals. In this study, we propose a new algorithm, named the extended Chi2 algorithm, to overcome these two drawbacks. By running the software of See5, our proposed algorithm possesses a better performance than the original and modified Chi2 algorithms.	Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, Hsinchu 300, Taiwan; Natl Chiao Tung Univ, Dept Ind Engn & Management, Hsinchu, Taiwan	Su, CT (reprint author), Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, Kuang Fu Rd,Sec 2, Hsinchu 300, Taiwan.	ctsu@mx.nthu.edu.tw; d9033809.iem90g@nctu.edu.tw					An AJ, 1996, ENG APPL ARTIF INTEL, V9, P645, DOI 10.1016/S0952-1976(96)00059-0; BEYNON M, 2002, P 3 INT C ROUGH SETS, P530; Beynon M, 2001, EUR J OPER RES, V134, P592, DOI 10.1016/S0377-2217(00)00280-0; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; Dougherty J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Kattan MW, 1998, OMEGA-INT J MANAGE S, V26, P467, DOI 10.1016/S0305-0483(97)00081-9; Kerber R., 1992, P 10 NAT C ART INT, P123; Li R.-P., 2002, P 1 C MACH LEARN CYB, P243; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; Montgomery D.C., 1999, APPL STAT PROBABILIT; NGUYEN H S, 1998, P 1 INT C ROUGH SETS, P545; NGUYEN HS, 1998, ROUGH SETS KNOWLEDGE, P451; NGUYEN HS, 1997, THESIS WARSAW U; NGUYEN HS, 1997, B INT ROUGH SET SOC, V1, P5; Shen L, 2001, INTELL DATA ANAL, V5, P431; Tay E. H., 2002, IEEE T KNOWL DATA EN, V14, P666, DOI DOI 10.1109/TKDE.2002.1000349; ZIARKO W, 2002, P 3 INT C ROUGH SETS, P514; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	19	37	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2005	17	3					437	441				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	888EY	WOS:000226358200011	
J	Albert, TC; Goes, PB; Gupta, A				Albert, TC; Goes, PB; Gupta, A			GIST: A model for design and management of content and interactivity of customer-centric Web sites	MIS QUARTERLY			English	Article						Web site analysis and design; customer segmentation; personalization	USER PARTICIPATION; SYSTEMS	Customer-centric Web-based systems, such as e-commerce Web sites, or sites that support customer relationship management (CRM) activities, are themselves information systems, but their design and maintenance need to follow vastly different approaches from the traditional systems lifecycle approach. Based on marketing frameworks that are applicable to the online world, and following design science principles, we develop a model to guide the design and the continuous management of such sites. The model makes extensive use of current technologies for tracking the customers and their behaviors, and combines elements of data mining and statistical analyses. A case study based on a financial services Web site is used to provide a preliminary validation and design evaluation of our approach. The case study showed considerable measured improvement in the effectiveness of the company's Web site. In addition, it also highlighted an important benefit of the our approach: the identification of previously unknown or unexpected segments of visitors. This finding can lead to promising new business opportunities.	Univ Hartford, Sch Business, Hartford, CT 06117 USA; Univ Connecticut, Sch Business, Storrs, CT 06269 USA; Univ Minnesota, Carlson Sch Management, Minneapolis, MN 55455 USA	Albert, TC (reprint author), Univ Hartford, Sch Business, 2000 Bloomfield Ave, Hartford, CT 06117 USA.	talbert@hartford.edu; paulo.goes@business.uconn.edu; agupta@csom.umn.edu					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; ALBERT TC, 2003, E BUSINESS MARKETING; BARKI H, 1994, MIS QUART, V18, P59, DOI 10.2307/249610; CSIKSZENTMIHALY.M, 1977, BOREDOM ANXIETY; DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008; Donoghue K., 2002, BUILT USE DRIVING PR; El Sawy OA, 1999, MIS QUART, V23, P305; GREEN GI, 1986, J MANAGEMENT INFORMA, V3, P81; GREENSPAN R, 2002, AM SURFERS KEEP IT S; Hevner AR, 2004, MIS QUART, V28, P75; Hoffman DL, 1996, J MARKETING, V60, P50, DOI 10.2307/1251841; Hoffman D.L., 1995, J COMPUTER MEDIATED, V1; HOLLAND JH, 1986, PHYSICA D, V22, P307; HONG W, 2002, E SERVICE NEW DIRECT, P108; Inmon W.H., 2002, BUILDING DATA WAREHO; KAUL A, 1995, E COMMUNICATION U TA; Kotler P., 2003, MARKETING MANAGEMENT; Lee SH, 2002, SKULL BASE-INTERD AP, V12, P189, DOI 10.1055/s-2002-35750-1; Levin N., 2001, J INTERACTIVE MARKET, V15, P2, DOI 10.1002/dir.1007; MCKEEN JD, 1994, MIS QUART, V18, P427, DOI 10.2307/249523; Nielsen J., 2000, DESIGNING WEB USABIL; PARSONS A, 1998, J INTERACT MARK, V12, P31, DOI 10.1002/(SICI)1520-6653(199824)12:1<31::AID-DIR4>3.0.CO;2-X; PELTIER JW, 1997, J DIRECT MARKETING, V11, P53, DOI 10.1002/(SICI)1522-7138(199723)11:4<53::AID-DIR8>3.0.CO;2-V; PEPPERS D, 1997, ENTERPRISE ONE ONE; PEPPERS D, 1996, ONE ONE FUTURE; RUST RT, 2002, E SERVICE NEW DIRECT, P3; Stafford TE, 2003, COMMUN ACM, V46, P26, DOI 10.1145/777313.777333; WEINSTEIN A, 1993, MARKET SEGMENTATION; WIND J, 2001, J INTERACTIVE MARKET, V15, P13, DOI 10.1002/1520-6653(200124)15:1<13::AID-DIR1001>3.0.CO;2-#; XUE M, 2003, INCORPORATING DUAL C; ZEITHAMAL V, 2000, 00115 MSI	31	37	37	SOC INFORM MANAGE-MIS RES CENT	MINNEAPOLIS	UNIV MINNESOTA-SCH MANAGEMENT 271 19TH AVE SOUTH, MINNEAPOLIS, MN 55455 USA	0276-7783		MIS QUART	MIS Q.	JUN	2004	28	2					161	182				22	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	826XF	WOS:000221862100003	
S	Alves, RT; Delgado, MR; Lopes, HS; Freitas, AA		Yao, X; Burke, E; Lozano, JA; Smith, J; MereloGuervos, JJ; Bullinaria, JA; Rowe, J; Tino, P; Kaban, A; Schwefel, HP		Alves, RT; Delgado, MR; Lopes, HS; Freitas, AA			An artificial immune system for fuzzy-rule induction in data mining	PARALLEL PROBLEM SOLVING FROM NATURE - PPSN VIII	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Parallel Problem Solving from Nature (PPSN VIII)	SEP 18-22, 2004	Birmingham, ENGLAND	CERCIA, Honda Res Inst Europe, Thales Res & Technol, HP Labs Bristol	Univ Birmingham, Sch Comp Sci			This work proposes a classification-rule discovery algorithm integrating artificial immune systems and fuzzy systems. The algorithm consists of two parts: a sequential covering procedure and a rule evolution procedure. Each antibody (candidate solution) corresponds to a classification rule. The classification of new examples (antigens) considers not only the fitness of a fuzzy rule based on the entire training set, but also the affinity between the rule and the new example. This affinity must be greater than a threshold in order for the fuzzy rule to be activated, and it is proposed an adaptive procedure for computing this threshold for each rule. This paper reports results for the proposed algorithm in several data sets. Results are analyzed with respect to both predictive accuracy and rule set simplicity, and are compared with C4.5rules, a very popular data mining algorithm.	CEFET PR, CPGEI, BR-80230901 Curitiba, Parana, Brazil; Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England	Alves, RT (reprint author), CEFET PR, CPGEI, Av Sete Stembro 3165, BR-80230901 Curitiba, Parana, Brazil.	roberto_alves@msn.com; myriam@dainf.cefetpr.br; hslopes@cpgei.cefetpr.br; A.A.Freitas@kent.ac.uk					Back T., 2000, EVOLUTIONARY COMPUTA; CARVALHO DR, 2002, P GEN EV COMP C GECC, P1035; CASTRO LN, 2002, ARTIFICAL IMMUNE SYS; DASGUPTA D, 1999, ARTIFICAL IMMUNE SYS; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FREITAS AA, 2003, P INT C ART IMM SYST, V2787, P229; Gonzalez Fabio A., 2002, P GEN EV COMP C GECC, P1081; Ishibuchi H, 2001, IEEE T FUZZY SYST, V9, P506, DOI 10.1109/91.940964; LOPES HS, 1997, GENETIC ALGORITHMS F, P193; Nasaroui O, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P711; Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452; Pedrycz W., 1998, INTRO FUZZY SETS ANA; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Watkins A. B., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1007049; Witten IH, 2000, DATA MINING PRACTICA; Zadeh L.A, 1965, FUZZY SETS INFORM CO, V8, P338, DOI DOI 10.1016/S0019-9958(65)90241-X	16	37	39	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-23092-0	LECT NOTES COMPUT SC			2004	3242						1011	1020				10	Computer Science, Theory & Methods	Computer Science	BAX55	WOS:000224103300102	
J	Zhang, M; Xu, LD; Zhang, WX; Li, HZ				Zhang, M; Xu, LD; Zhang, WX; Li, HZ			A rough set approach to knowledge reduction based on inclusion degree and evidence reasoning theory	EXPERT SYSTEMS			English	Article						intelligent systems; rough sets; database and knowledge base systems; data mining; machine learning; inclusion degree		The theory of rough sets is an extension of set theory for studying intelligent systems characterized by insufficient and incomplete information. We discuss the basic concept and properties of knowledge reduction based on inclusion degree and evidence reasoning theory, and propose a knowledge discovery approach based on inclusion degree and evidence reasoning theory.	Xian Jiaotong Univ, Grad Sch, Xian 710049, Peoples R China; Xian Jiaotong Univ, Natl Key Lab Mfg Syst Engn, Xian 710049, Peoples R China; Xian Jiaotong Univ, Sch Management, Xian 710049, Peoples R China; Old Dominion Univ, Dept Informat Technol & Decis Sci, Norfolk, VA 23529 USA	Zhang, M (reprint author), Xian Jiaotong Univ, Grad Sch, Xian 710049, Peoples R China.						Guan JW, 1998, ARTIF INTELL, V105, P77, DOI 10.1016/S0004-3702(98)00090-3; Kumar A, 1998, J INTELL INF SYST, V10, P31, DOI 10.1023/A:1008633406999; Li HX, 2001, KNOWL-BASED SYST, V14, P253, DOI 10.1016/S0950-7051(01)00103-4; Pawlak Z, 1997, EUR J OPER RES, V99, P48, DOI 10.1016/S0377-2217(96)00382-7; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1991, ROUGH SETS THEORETIC; Komorowski J., 1997, Studia Logica, V58, DOI 10.1023/A:1004900200790; Shafer G, 1976, MATH THEORY EVIDENCE; Starzyk J. A., 2000, Knowledge and Information Systems, V2, DOI 10.1007/s101150050007; Walczak B, 1999, CHEMOMETR INTELL LAB, V47, P1, DOI 10.1016/S0169-7439(98)00200-7; Yao YY, 1996, INT J APPROX REASON, V15, P291, DOI 10.1016/S0888-613X(96)00071-0; Yao YY, 1998, INFORM SCIENCES, V104, P81, DOI 10.1016/S0020-0255(97)00076-5; Zhang DJ, 2000, MULTIBODY SYST DYN, V4, P1, DOI 10.1023/A:1009849313860; Zhang HY, 2001, CHINESE CHEM LETT, V12, P75; ZHANG W, 2001, J XIAN JIAOTONG U, V35, P425; Zhang W.X., 2001, THEORY METHODS ROUGH; ZHANG WX, 1996, UNCERTAINTY REASONIN	17	37	42	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	0266-4720		EXPERT SYST	Expert Syst.	NOV	2003	20	5					298	304		10.1111/1468-0394.00254		7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	735MC	WOS:000186118300007	
J	Thang, KF; Aggarwal, RK; McGrail, AJ; Esp, DG				Thang, KF; Aggarwal, RK; McGrail, AJ; Esp, DG			Analysis of power transformer dissolved gas data using the self-organizing map	IEEE TRANSACTIONS ON POWER DELIVERY			English	Article						condition monitoring; data mining; dissolved gases; incipient faults; power transformers; self-organizing map	FAULT-DIAGNOSIS; EXPERT-SYSTEM	Incipient faults in power transformers can degrade the oil and cellulose insulation, leading to the formation of dissolved gases. Even though established approaches that relate these dissolved gas information to the condition of power transformers are already developed, it is discussed in this paper that they still contain some limitations. In view of that, this paper introduces an alternative approach for the analysis of dissolved gas data, which can produce more convincing interpretation and fault diagnosis. The proposed approach, which is based on the data mining methodology and the self-organizing map, has been compared and validated using conventional interpretation schemes and real fault-cases, thereby proven to be capable of enhancing the condition monitoring of power transformers.	Univ Bath, Sch Elect & Elect Engn, Bath BA2 7AY, Avon, England; Natl Grid Co Plc, Leatherhead KT22 7ST, Surrey, England; Natl Grid Co Plc, Wokingham RG31 5BN, England	Thang, KF (reprint author), Univ Bath, Sch Elect & Elect Engn, Bath BA2 7AY, Avon, England.						Bhattacharyya S. K., 1993, Proceedings 1993 North American Power Symposium; DORNENBU.E, 1974, BROWN BOVERI REV, V61, P238; DUVAL M, P IEEE POW ENG SOC C; ESP DG, 1998, P C REC IEEE INT S E, V1, P12; ESP DG, 2000, P C REC IEEE INT S E, P456; Fayyad Usama, 1996, DATA MINING KNOWLEDG; Huang YC, 1997, IEEE T POWER DELIVER, V12, P761; Kohonen T., 1997, SELF ORGANIZING MAPS; LIN CE, 1993, IEEE T POWER DELIVER, V8, P231, DOI 10.1109/61.180341; ROGERS RR, 1978, IEEE T ELECTR INSUL, V13, P349, DOI 10.1109/TEI.1978.298141; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; TOMSOVIC K, 1993, IEEE T POWER DELIVER, V8, P1638, DOI 10.1109/61.252690; TU YM, 1997, P 5 INT C PROP APPL, V1, P263, DOI 10.1109/ICPADM.1997.617578; Ultsch A., 1993, INFORM CLASSIFICATIO, P307; VENEGAS O, 1997, IEEE T POWER DELIVER, V4, P290; WANG Z, P AM POWER C, V428, P97; Wang ZY, 1998, IEEE T POWER DELIVER, V13, P1224; Zhang Y, 1996, IEEE T POWER DELIVER, V11, P1836, DOI 10.1109/61.544265; *HELS U TECH NEUR, DOC SOM PAK; *IEC STD, PUBLICATION IEC STD, V567; *IEC STD, 60599 IEC STD	21	37	41	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0885-8977		IEEE T POWER DELIVER	IEEE Trans. Power Deliv.	OCT	2003	18	4					1241	1248		10.1109/TPWRD.2003.817733		8	Engineering, Electrical & Electronic	Engineering	727LJ	WOS:000185659500021	
J	Srivastava, A; Han, EH; Kumar, V; Singh, V				Srivastava, A; Han, EH; Kumar, V; Singh, V			Parallel formulations of decision-tree classification algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data mining; parallel processing; classification; scalability; decision trees		Classification decision tree algorithms are used extensively for data mining in many domains such as retail target marketing, fraud detection, etc. Highly parallel algorithms for constructing classification decision trees are desirable for dealing with large data sets in reasonable amount of time. Algorithms for building classification decision trees have a natural concurrency, but are difficult to parallelize due to the inherent dynamic nature of the computation. In this paper, we present parallel formulations of classification decision tree learning algorithm based on induction. We describe two basic parallel formulations. One is based on Synchronous Tree Construction Approach and the other is based on Partitioned Tree Construction Approach. We discuss the advantages and disadvantages of using these methods and propose a hybrid method that employs the good features of these methods. We also provide the analysis of the cost of computation and communication of the proposed hybrid method. Moreover, experimental results on an IBM SP-2 demonstrate excellent speedups and scalability.	Univ Minnesota, Dept Comp Sci & Engn, Army HPC Res Ctr, Minneapolis, MN 55455 USA; Hitachi Amer Inc, Informat Technol Lab, Tarrytown, NY 10591 USA							AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; ALSABTI K, 1997, P 23 VLDB C; ALSABTI K, 1998, CLOUDS CLASSIFICATIO; ANURAG S, 1997, TR97010 U MINN DEP C; Breiman L, 1984, CLASSIFICATION REGRE; Catlett J., 1991, THESIS U SYDNEY; Chan P., 1993, P 2 INT C INF KNOWL, P314; Chan P. K., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); CHATTRATICHAT J, P 3 INT C KNOWL DISC; GEORGE D, 1994, EXP HEMATOL, V22, P379; GOIL S, 1996, P S PAR DISTR COMP S; GOLDBERG DE, 1989, GENETIC AOGORITHMS S; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; JOSHI MV, 1998, P INT PAR PROC S; KUFRIN R, 1997, PARALLEL PROCESSING, V3; Kumar V., 1994, INTRO PARALLEL COMPU; LIPPMANN RP, 1987, IEEE ASSP MAGAZINE, V4, P22; Mehta M., 1996, P 5 INT C EXT DAT TE; PEARSON RA, 1994, PARALLEL PROCESSING, V2, P207; QUINLAN JR, 1993, C4 5 PROGRMAS MACHIN; SHAFER JC, 1996, P 22 VLDB C; SHANKAR R, 1995, FRONTIERS 95; Spiegelhalter D.J., 1994, MACHINE LEARNING NEU; WIRTH J, 1988, 5 INT C MACH LEARN	24	37	39	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1999	3	3					237	261		10.1023/A:1009832825273		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	260RH	WOS:000083963300002	
B	Ultsch, A		Oja, E; Kaski, S		Ultsch, A			Data mining and knowledge discovery with emergent self-organizing feature maps for multivariate time series	KOHONEN MAPS			English	Proceedings Paper	High-Level Workshop on the Theory of Methodology and Applications of the SOM	JUL, 1999	FINLAND	Acad Finland				Self-Organizing Feature Maps, when used appropriately, can exhibit emergent phenomena. SOFM with only few neurons limit this ability, therefore Emergent Feature Maps need to have thousands of neurons. The structures of Emergent Feature Maps can be visualized using U-Matrix Methods. U-Matrices lead to the construction of self-organizing classifiers possessing the ability to classify new datapoints. This subsymbolic knowledge can be converted to a symbolic form which is understandable for humans. All these steps were combined into a system for Neuronal Data Mining. This system has been applied successfully for knowledge Discovery in multivariate time series.	Univ Marburg, Dept Comp Sci, D-35032 Marburg, Germany	Ultsch, A (reprint author), Univ Marburg, Dept Comp Sci, Hans Meerwein Str, D-35032 Marburg, Germany.						ALLEN J, 1984, ARTIF INTELL, V23, pS123; DEGEN R, 1991, EPILEPSY RES S2, V2, pS177; GAUL WG, 1998, HER INF DAT WISS 22; GUIMARAES G, 1996, 20 ANN C SOC CLASS F, P105; GUIMARAESS G, 1999, IN PRESS METHOD TEMP; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; REUTTERER T, 1998, P ANN C SIC CLASS DR, P92; Ultsch A., 1999, DATA MINING KNOWLEDG; ULTSCH A, 1998, P 11 IEEE SMC 98 INT; ULTSCH A, 1994, NEW APPROACHES CLASS, P445; ULTSCH A, 1987, CONTROL KNOWLEDGE BA; ULTSCH A, 1995, GESELLSCHAFTE KLASSI; ULTSCH A, 1999, UNIFIKATIONSBASIERTE; WOODS E, 1997, DATA MINING	14	37	39	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS		0-444-50270-X				1999							33	45		10.1016/B978-044450270-4/50003-6		13	Computer Science, Artificial Intelligence	Computer Science	BP21Z	WOS:000084436200003	
J	Chen, CY; Shyue, SW; Chang, CJ				Chen, Chen-Yuan; Shyue, Shiahn-Wern; Chang, Chin-Jui			ASSOCIATION RULE MINING FOR EVALUATION OF REGIONAL ENVIRONMENTS: CASE STUDY OF DAPENG BAY, TAIWAN	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL			English	Article						Data mining; Association rule (AR); Decision tree (DT); Cluster analysis (CA)	LOGISTIC-REGRESSION MODELS; ALGORITHM; PATTERNS	Data mining is commonly used in a wide range of different fields. It is an important tool for analyzing information in research areas where there is a huge collection of data. The aim of this study is to determine the various patterns that characterize multidimensional marine environments. In particular, we wish to determine the association patterns, the characterize Taiwan's Dapeng Bay. The processes of association rule (AR) mining and decision tree (DT) analysis are the main methodologies used in this study. We also utilize Weka, a comprehensive suite of Java class libraries for implementing many machine learning algorithms and the Clementine 10.1 software package for data mining analysis. Applications constructed from the AR model and decision tree model can be applied in other scientific domains. This paper describes the data mining process for Dapeng Bay, which is located in the south of Taiwan.	[Shyue, Shiahn-Wern] Natl Sun Yat Sen Univ, Dept Marine Environm & Engn, Kaohsiung 80424, Taiwan; [Chen, Chen-Yuan] Natl Pingtung Univ Educ, Dept Comp Sci, Pingtung 90003, Taiwan; [Chang, Chin-Jui] Transworld Inst Technol, Dept Informat Management, Touliu 64063, Yunlin, Taiwan	Shyue, SW (reprint author), Natl Sun Yat Sen Univ, Dept Marine Environm & Engn, 70 Lianhai Rd, Kaohsiung 80424, Taiwan.	cyc@mail.npue.edu.tw; swshyue@mail.nsysu.edu.tw			National Sun Yat-Sen University; Department of Information Management of the Transworld institute of Technology; National Science Council [NSC 98-2221-E-153-004, NSC 90-2621-Z-110-012, NSC 91-2621-Z-110-004, NSC 92-2621-Z-110-004]	This study was initiated during the LOICZ project under the auspices of the government, Taiwan. The research was supported by the Marine GIS research team of the National Sun Yat-Sen University and the Department of Information Management of the Transworld institute of Technology. The authors are also grateful for the research grants given to CYC from the National Science Council under Grant No. NSC 98-2221-E-153-004 as well as given to SWS under Grant Nos. NSC 90-2621-Z-110-012, NSC 91-2621-Z-110-004, and NSC 92-2621-Z-110-004.	Agrawal R., 1994, P 20 INT C VER LARG, P487; Cai JH, 2008, INT J INNOV COMPUT I, V4, P2263; CHEN CH, 2010, EXPERT SYSTEMS APPL, V37, P993; Chen CW, 2008, CHINA OCEAN ENG, V22, P43; Chen CY, 2008, ENG COMPUTATION, V25, P121, DOI [10.1108/02644400810855940, 10.1108/02644400810&55940]; Chen TH, 2008, MATH PROBL ENG, DOI 10.1155/2008/186372; Chu CJ, 2008, INT J INNOV COMPUT I, V4, P2775; Han J., 2001, DATA MINING CONCEPTS; Han SW, 2008, INT J INNOV COMPUT I, V4, P2749; Hong TP, 2008, INT J INNOV COMPUT I, V4, P2875; Jea KF, 2009, INT J INNOV COMPUT I, V5, P2351; LAN GC, 2009, ICIC EXPRESS LETT, V3, P1327; Lyubartsev VG, 2004, J MARINE SYST, V47, P3, DOI 10.1016/j.jmarsys.2003.12.004; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Raju GT, 2008, INT J INNOV COMPUT I, V4, P381; Vega M, 1998, WATER RES, V32, P3581, DOI 10.1016/S0043-1354(98)00138-9; Witten I.H., 1999, DATA MINING PRACTICA; Wright DJ, 1997, INT J GEOGR INF SCI, V11, P523, DOI 10.1080/136588197242176; XI YJ, 2009, ICIC EXPRESS LETT, V3, P1365	20	36	36	ICIC INT	KUMAMOTO	TOKAI UNIV, 9-1-1, TOROKU, KUMAMOTO, 862-8652, JAPAN	1349-4198		INT J INNOV COMPUT I	Int. J. Innov. Comp. Inf. Control	AUG	2010	6	8					3425	3436				12	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	640SK	WOS:000281072400008	
J	Fung, BCM; Wang, K; Chen, R; Yu, PS				Fung, Benjamin C. M.; Wang, Ke; Chen, Rui; Yu, Philip S.			Privacy-Preserving Data Publishing: A Survey of Recent Developments	ACM COMPUTING SURVEYS			English	Article						Performance; Security; Information sharing; privacy protection; anonymity; sensitive information; data mining	ACHIEVING K-ANONYMITY; DATABASES; ANONYMIZATION; SUPPRESSION; MODELS	The collection of digital information by governments, corporations, and individuals has created tremendous opportunities for knowledge- and information-based decision making. Driven by mutual benefits, or by regulations that require certain data to be published, there is a demand for the exchange and publication of data among various parties. Data in its original form, however, typically contains sensitive information about individuals, and publishing such data will violate individual privacy. The current practice in data publishing relies mainly on policies and guidelines as to what types of data can be published and on agreements on the use of published data. This approach alone may lead to excessive data distortion or insufficient protection. Privacy-preserving data publishing (PPDP) provides methods and tools for publishing useful information while preserving data privacy. Recently, PPDP has received considerable attention in research communities, and many approaches have been proposed for different data publishing scenarios. In this survey, we will systematically summarize and evaluate different approaches to PPDP, study the challenges in practical data publishing, clarify the differences and requirements that distinguish PPDP from other related problems, and propose future research directions.	[Fung, Benjamin C. M.] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 1M8, Canada; [Wang, Ke] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada; [Yu, Philip S.] Univ Illinois, Chicago, IL USA	Fung, BCM (reprint author), Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 1M8, Canada.	fung@ciise.concordia.ca	WANG, Ke/H-6830-2013		NSERC [356065-2008]	The research is supported in part by NSERC Discovery Grants (356065-2008).	Abul O, 2008, PROC INT CONF DATA, P376, DOI 10.1109/ICDE.2008.4497446; ADAM NR, 1989, ACM COMPUT SURV, V21, P515, DOI 10.1145/76894.76895; Aggarwal CC, 2008, ADV DATABASE SYST, V34, P1, DOI 10.1007/978-0-387-70992-5; Aggarwal Charu C, 2008, ACM Transactions on Database Systems, V33, DOI 10.1145/1331904.1331906; Aggarwal CC, 2005, P 31 INT C VER LARG, P901; AGGARWAL CC, 2007, P SIAM INT C DAT MIN; AGGARWAL CC, 2006, P 12 ACM SIGKDD; AGGARWAL G, 2005, P 10 INT C DAT THEOR, P247; AGGARWAL G, 2006, P 25 ACM SIGMOD SIGA; Aggarwal V, 2008, NETW HETEROG MEDIA, V3, P251, DOI 10.3934/nhm.2008.3.251; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; Agrawal S, 2005, PROC INT CONF DATA, P193; Alon N, 1999, J COMPUT SYST SCI, V58, P137, DOI 10.1006/jcss.1997.1545; ATZORI M, 2007, P INT WORKSH PRIV AW, P283; Atzori M, 2008, VLDB J, V17, P703, DOI 10.1007/s00778-006-0034-x; Barak B, 2007, P 26 S PRINC DAT SYS, P273, DOI 10.1145/1265530.1265569; Barbaro Michael, 2006, NY TIMES        0809; Bayardo RJ, 2005, PROC INT CONF DATA, P217; BEINAT E, 2001, GEOINFORMATICS; Blum A., 2005, PODS, P128, DOI 10.1145/1065167.1065184; BLUM A, 2008, P 40 ANN ACM S THEOR, P609, DOI 10.1145/1374376.1374464; Brand R., 2002, Inference Control in Statistical Databases. From Theory to Practice. Revised Papers from Seminar `Statistical Disclosure Control: From Theory to Practice' (Lecture Notes in Computer Science Vol.2316); Bu Y, 2008, P VLDB ENDOWMENT, V1, P845; Burnett Leslie, 2003, J Law Med, V10, P506; BYUN JW, 2006, P VLDB WORKSH SEC DA; CARLISLE DM, 2007, CALIFORNIA INPATIENT; CHAKARAVARTHY VT, 2008, P 17 ACM C INF KNOWL; CHAUM D., 1981, COMMUN ACM, V24, P2; CHAWLA S, 2005, P UNC ART INT C UAI; Chawla S, 2005, P 2 THEOR CRYPT C; Clifton C., 2002, ACM SIGKDD EXPLORATI, V4, P28, DOI 10.1145/772862.772867; Clifton C., 2000, Journal of Computer Security, V8; COX LH, 1980, J AM STAT ASSOC, V75, P377, DOI 10.2307/2287463; Dalenius T., 1986, J OFF STAT, V2, P329; Dalenius T., 1977, STAT TIDSKRIFT, V15, P429; DENNING DE, 1985, P IEEE S SEC PRIV; Deutsch A., 2005, P 10 INT C DAT THEOR, P230; Dinur I., 2003, P 22 ACM SIGACT SIGM, P202, DOI DOI 10.1145/773153.773173; Domingo-Ferrer J, 2008, ADV DATABASE SYST, V34, P53; DOMINGOFERRER J, 2008, P 3 INT C AV REL SEC, P990; DOMINGOFERRER J, 2002, THEORY PRACTICAL APP, P113; DU W, 2003, P 9 ACM SIGKDD; DUNCAN G, 1998, STAT DATA PROTECTION, P351; Dwork C, 2008, LECT NOTES COMPUT SC, V4890, P1; DWORK C., 2006, P 3 THEOR CRYPT C, P265; DWORK C, 2007, P ICDT INT C DAT THE, P18; DWORK C, 2004, PRIVACY PRESERVING D, P528; Dworsky A, 2006, J SOC SERV RES, V33, P1, DOI 10.1300/J079v33n02_01; EMAM KE, 2006, DATA ANONYMIZATION P; Evfimievski A., 2008, PODS 2008, P171, DOI 10.1145/1376916.1376941; Evfimievski A., 2002, P 8 ACM SIGKDD INT C, P217; FARKAS C, 2003, ACM SIGKDD EXPLORATI, V4, P6; Fuller W.A., 1993, J OFF STAT, V9, P383; Fung B.C.M., 2008, P 11 INT C EXT DAT T, P264; Fung BCM, 2009, DATA KNOWL ENG, V68, P552, DOI 10.1016/j.datak.2008.12.001; FUNG BCM, 2009, P 24 ACM SIGAPP S AP; Fung BCM, 2007, IEEE T KNOWL DATA EN, V19, P711, DOI 10.1109/TKDE.2007.1015; Fung BCM, 2005, PROC INT CONF DATA, P205; FUNG BCM, 2008, P 2008 IEEE INT C IN, P46; GEHRKE J, 2006, 12 ACM SIGKDD; Goguen J.A., 1984, P IEEE S SEC PRIV; Hegland M, 1999, COMPUT STAT DATA AN, V31, P377, DOI 10.1016/S0167-9473(99)00038-9; HENGARTNER U, 2007, P INT WORKSH PRIV AW, P268; HINKE T, 1995, J COMPUT SECURITY; Hinke T. H., 1988, Proceedings of the 1988 IEEE Symposium on Security and Privacy (Cat. No.88CH2558-5), DOI 10.1109/SECPRI.1988.8101; Huang Z., 2005, P 2005 ACM SIGMOD C, P37, DOI 10.1145/1066157.1066163; Hundepool A., 1996, P 3 INT SEM STAT CON; Iyengar V.S., 2002, P 8 ACM SIGKDD INT C, P279; Jajodia S., 1995, INFORMATION SECURITY, P570; Jakobsson M., 2002, Proceedings of the 11th USENIX Security Symposium; JIANG W, 2005, P 19 ANN IFIP WG 11, P166; Jiang W, 2006, VLDB J, V15, P316, DOI 10.1007/s00778-006-0008-z; Kantarcioglu M, 2008, ADV DATABASE SYST, V34, P313; Kantarcioglu M., 2004, P 10 ACM SIGKDD INT, P599; Kargupta H., 2003, P 3 IEEE INT C DAT M, P99; Kenthapadi K., 2005, PODS, P118, DOI 10.1145/1065167.1065183; KIFER D, 2006, P ACM SIGMOD; Kim J, 1995, P SECT SURV RES METH, P114; KOKKINAKIS D, 2007, P 11 C ART INT MED A, P237; KUMAR R, 2007, P 16 WORLD WID WEB C, P628; Le Fevre K., 2006, P 22 IEEE INT C DAT; Lefevre K., 2005, P ACM SIGMOD INT C M, P49, DOI 10.1145/1066157.1066164; LEFEVRE K, 2006, P 12 ACM SIGKDD; LI J, 2008, P ACM C MAN DAT SIGM, P437; LI N, 2007, P 21 IEEE INT C DAT; Machanavajjhala A, 2006, P 22 IEEE INT C DAT; Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, P1; Malin B, 2006, LECT NOTES COMPUT SC, V4258, P413; Martin D., 2007, P 23 IEEE INT C DAT; MATLOFF NS, 1988, DATABASE SECURITY ST, P159; Meyerson A., 2004, P 23 ACM SIGMOD SIGA, P223, DOI 10.1145/1055558.1055591; MIKLAU G., 2004, P ACM SIGMOD INT C M, P575, DOI 10.1145/1007568.1007633; MOHAMMED N, 2009, P 12 INT C EXT DAT T; MOORE RA, 1996, 9604 US BUR CENS; MOTWANI R, 2007, P C VER LARG DAT BAS; Nergiz ME, 2007, DATA KNOWL ENG, V63, P622, DOI 10.1016/j.datak.2007.03.009; Nergiz M.E, 2007, P 23 INT C DAT ENG I, P1417; Nergiz ME, 2007, P ACM SIGMOD INT C M, P665, DOI 10.1145/1247480.1247554; Ohrn A, 1999, ARTIF INTELL MED, V15, P235, DOI 10.1016/S0933-3657(98)00056-6; OZSOYOGLU G, 1990, J COMPUT SYST SCI, V40, P405, DOI 10.1016/0022-0000(90)90005-6; Papadimitriou S, 2007, ELE COM ENG, P459; Pinkas B., 2002, ACM SIGKDD EXPLORATI, V4, P12, DOI 10.1145/772862.772865; POHLIG SC, 1978, IEEE T INFORM THEORY, V24, P106, DOI 10.1109/TIT.1978.1055817; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Rastogi V., 2007, P INT C VER LARG DAT, P531; REISS SP, 1984, ACM T DATABASE SYST, V9, P20, DOI 10.1145/348.349; REISS SP, 1982, P ACM S PRINC DAT SY, P139; ROSEN BE, 1992, J PROCESS CONTR, V67, P419; RUBIN DB, J OFFICIAL STAT, V9, P2; Samarati P., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275508; Samarati P., 1998, PROTECTING PRIVACY D; Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193; SAYGIN Y, 2006, WEB INFORM SECURITY, P133; Shannon E., 1948, BELL SYST TECH J, V27, P623; Skowron A., 1992, HDB APPL ADV ROUGH S; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P571, DOI 10.1142/S021848850200165X; SWEENEY L, 1998, DATABASE SECURITY, V11, P356; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Terrovitis M., 2008, P VLDB ENDOW, V1, P115; Terrovitis M, 2008, P 9 INT C MOB DAT MA, P65; THURAISINGHAM BM, 1987, COMPUT SECUR, V6, P479; Torra V., 2001, CONFIDENTIALITY DISC, P91; Truta T., 2006, P INT WORKSH PRIV DA, P94; Vaidya J, 2008, ADV DATABASE SYST, V34, P337; Verykios VS, 2004, IEEE T KNOWL DATA EN, V16, P434, DOI 10.1109/TKDE.2004.1269668; Vinterbo SA, 2004, IEEE T KNOWL DATA EN, V16, P939, DOI 10.1109/TKDE.2004.31; WANG K, 2005, P 2005 IEEE INT C IN, P171; WANG K, 2009, P 25 IEEE INT C DAT; WANG K, 2006, P 12 ACM SIGKDD C; Wang K., 2005, P 5 IEEE INT C DAT M, P466; WANG K, 2004, P 4 IEEE INT C DAT M; Wang K, 2007, KNOWL INF SYST, V11, P345, DOI 10.1007/s10115-006-0035-5; Wang S.-W., 2006, P 39 HAW INT C SYST; WARNER SL, 1965, J AM STAT ASSOC, V60, P63, DOI 10.2307/2283137; Wong RCW, 2007, P INT C VER LARG DAT, P543; Wong RC-W, 2006, P 12 ACM SIGKDD INT, P754; WRIGHT RN, 2005, P SEC MOB AD HOC NET; Xiao X., 2006, P ACM SIGMOD C; XIAO X, 2007, P ACM SIGMOD C; XIAO X, 2006, P 32 C VER LARG DAT; XU J, 2006, P 12 ACM SIGKDD C; XU Y, 2008, P 14 ACM SIGKDD C; XU Y, 2008, P 8 IEEE INT C DAT M; Yang Z., 2005, P 11 ACM SIGKDD INT, P334, DOI 10.1145/1081870.1081909; Yao C., 2005, P 31 INT C VER LARG, P910; You T. H., 2007, P INT WORKSH PRIV AW, P278; Zayatz L., 2007, J OFF STAT, V23, P253; Zhang P., 2005, LECT NOTES COMPUTER, V3584; ZHANG Q, 2007, P 23 IEEE INT C DAT; *PRES INF TECHN AD, 2004, REV HLTH CAR INF TEC	150	36	49	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0360-0300		ACM COMPUT SURV	ACM Comput. Surv.	JUN	2010	42	4							14	10.1145/1749603.1749605		53	Computer Science, Theory & Methods	Computer Science	618LX	WOS:000279357800002	
J	Wu, DS				Wu, Desheng			Supplier selection: A hybrid model using DEA, decision tree and neural network	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Supplier selection; Data envelopment analysis (DEA); Decision tree (DT); Neural networks (NNs); Data mining (DM); Classification; Prediction	DATA ENVELOPMENT ANALYSIS; EFFICIENCY; SAMPLE	As the most important responsibility of purchasing management, the problem of vendor evaluation and selection has always received a great deal of attention from practitioners and researchers. This management decision is a challenge due to the complexity and various criteria involved. This paper presents a hybrid model using data envelopment analysis (DEA), decision trees (DT) and neural networks (NNs) to assess supplier performance, The model consists of two modules: Module 1 applies DEA and classifies suppliers into efficient and inefficient clusters based on the resulting efficiency scores. Module 2 utilizes firm performance-related data to train DT. NNs model and apply the trained decision tree model to new suppliers. Our results yield a favorable classification and prediction accuracy rate. (C) 2008 Elsevier Ltd. All rights reserved.	[Wu, Desheng] Reykjav Univ, IS-103 Reykjavik, Iceland; [Wu, Desheng] Univ Toronto, RiskLab, Toronto, ON M5S 3G3, Canada	Wu, DS (reprint author), Reykjav Univ, Kringlunni 1, IS-103 Reykjavik, Iceland.	dash@ru.is	Wu, Desheng/I-6230-2012				Albino V, 1998, INT J PROJ MANAG, V16, P9, DOI 10.1016/S0263-7863(97)00007-0; ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; BREIMAN L, 1984, CLASSIFICATON REGRES; CHARNES A, 1978, EUR J OPER RES, V2, P429, DOI 10.1016/0377-2217(78)90138-8; de Boer L, 2001, EUROPEAN J PURCHASIN, V7, P75, DOI 10.1016/S0969-7012(00)00028-9; Dickson G., 1966, J PURCHASING, V2, P5; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; GELDERMAN K, 2003, INT J PURCHASING SUP, V9, P207; Khoo L.P., 1998, INT J PURCHASING MAT, V34, P46; Kim YS, 2008, EXPERT SYST APPL, V34, P1227, DOI 10.1016/j.eswa.2006.12.017; KLEINSORGE IK, 1992, J ACCOUNT PUBLIC POL, V11, P357, DOI 10.1016/0278-4254(92)90004-H; Kumar M, 2006, INT J PROD ECON, V101, P273, DOI 10.1016/j.ijpe.2005.01.005; Lall V., 2000, SUPPLY CHAIN MANAG, V5, P143, DOI 10.1108/13598540010338893; Li XB, 1999, EUR J OPER RES, V115, P507, DOI 10.1016/S0377-2217(98)00130-1; Liang L, 2005, COMPUT OPER RES, V32, P1115, DOI 10.1016/j.cor.2003.09.015; Nassimbeni G, 2006, INT J PROD ECON, V103, P694, DOI 10.1016/j.ijpe.2006.01.003; Olsen RF, 1997, IND MARKET MANAG, V26, P101, DOI 10.1016/S0019-8501(96)00089-2; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Talluri S, 2005, IEEE T ENG MANAGE, V52, P130, DOI 10.1109/TEM.2004.839960; Volkovich V, 2007, EUR J OPER RES, V183, P1097, DOI 10.1016/j.ejor.2005.12.045; Weber C. A., 1993, International Journal of Physical Distribution & Logistics Management, V23, DOI 10.1108/09600039310038161; Weber CA, 1996, EUR J OPER RES, V90, P142, DOI 10.1016/0377-2217(94)00336-X; Witten IH, 2000, DATA MINING PRACTICA; WU D, 2008, INT J PROD RES, P2313; WU D, 2008, EXPERT SYST IN PRESS; WU DS, 2006, INT J INFORM TECHNOL, V5, P162; Wu DS, 2006, EXPERT SYST APPL, V31, P108, DOI 10.1016/j.eswa.2005.09.034; Wu DSD, 2009, EUR J OPER RES, V194, P227, DOI 10.1016/j.ejor.2007.10.009	28	36	40	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2009	36	5					9105	9112		10.1016/j.eswa.2008.12.039		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	427MG	WOS:000264782800044	
J	Aggarwal, CC; Yu, PS				Aggarwal, Charu C.; Yu, Philip S.			A Survey of Uncertain Data Algorithms and Applications	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Mining methods and algorithms; database applications; database management; information technology and systems	IMPRECISE DATA	In recent years, a number of indirect data collection methodologies have led to the proliferation of uncertain data. Such databases are much more complex because of the additional challenges of representing the probabilistic information. In this paper, we provide a survey of uncertain data mining and management applications. We will explore the various models utilized for uncertain data representation. In the field of uncertain data management, we will examine traditional database management methods such as join processing, query processing, selectivity estimation, OLAP queries, and indexing. In the field of uncertain data mining, we will examine traditional mining problems such as frequent pattern mining, outlier detection, classification, and clustering. We discuss different methodologies to process and mine uncertain data in a variety of forms.	[Aggarwal, Charu C.] IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA; [Yu, Philip S.] Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA	Aggarwal, CC (reprint author), IBM Corp, TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.	charu@us.ibm.com; psyu@cs.uic.edu			US Army Research laboratory; UK Ministry of Defense [W911NF-06-3-0001]	The research of Charu C. Aggarwal was sponsored in part by the US Army Research laboratory and the UK Ministry of Defense under Agreement W911NF-06-3-0001. The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies of the US Government, the US Army Research Laboratory, the UK Ministry of Defense, or the UK Government. The US and UK governments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notice hereon.	ABITEBOUL S, 1987, P ACM SIGMOD; AGGARWAL CC, 2008, P 24 IEEE INT C DAT; Aggarwal CC, 2009, ADV DATABASE SYST, V35, P1, DOI 10.1007/978-0-387-09690-2; Aggarwal C.C., 2008, P SIAM INT C DAT MIN; AGGARWAL CC, 2007, P 23 IEEE INT C DAT; Aggarwal CC, 2003, P 29 INT C VER LARG; ANDRITSOS P, 2006, P 22 IEEE INT C DAT; ANKERST M, 1992, P ACM SIGMOD; Antoine C, 2007, CLIMACTERIC, V10, P23, DOI 10.1080/13697130601176734; ANTOVA L, 2008, P 24 IEEE INT C DAT; ANTOVA L, 2007, P ACM SIGMOD; ARENAS M, 1999, P 18 ACM S PRINC DAT; BARBARA D, 1992, IEEE T KNOWL DATA EN, V4, P487, DOI 10.1109/69.166990; BELL D, 1996, DATA KNOWLEDGE ENG, V18; BENJELLOUN O., 2006, P 32 INT C VER LARG; Bi J, 2004, P ADV NEUR INF PROC; BOHM C, 2007, P 10 INT S SPAT TEMP; BOHM C, 2006, P 22 IEEE INT C DAT; Burdick D., 2005, P INT C VER LARG DAT, P970; BURDICK D, 2007, P 33 INT C VER LARG; CAVELLO R, 1987, P 13 INT C VER LARG; Chen ALP, 1996, IEEE T KNOWL DATA EN, V8, P273, DOI 10.1109/69.494166; Cheng R, 2004, IEEE T KNOWL DATA EN, V16, P1112, DOI 10.1109/TKDE.2004.46; Cheng R, 2003, P ACM SIGMOD; CHENG R, 2006, P 15 ACM INT C INF K; CHENG R, 2005, 05004 CSD PURD U DEP; CHENG R, 2004, P 30 INT C VER LARG; CHUI CK, 2008, P 12 PAC AS C KNOWL; CHUI CK, 2007, P 11 PAC AS C KNOWL; CORMODE G, 2008, P 27 ACM SIGMOD SIGA; DALVI N, 2005, P 31 INT C VER LARG; DALVI N, 2004, P 30 INT C VER LARG; DASSARMA A, 2006, P 22 IEEE INT C DAT; Deshpande A, 2004, P 30 INT C VER LARG; Dey D, 1998, DATA KNOWL ENG, V28, P107, DOI 10.1016/S0169-023X(98)00015-9; Dong X. L., 2007, P 33 INT C VER LARG; Ester M., 1996, P 2 INT C KNOWL DISC; FLORESCU D, 1997, P 23 INT C VER LARG; Friedman N., 1999, P 16 INT JOINT C ART; Fuhr N, 1997, ACM T INFORM SYSTEMS; FUXMAN A, 2005, P ACM SIGMOD; GAROFALAKIS M, 2006, IEEE DATA ENG B; GENEST C., 1986, STAT SCI, V1, P114, DOI 10.1214/ss/1177013825; GRAHNE G., 1991, PROBLEM INCOMPLETE I; GREEN T, 2006, DATA ENG B, V29; HUNG E, 2003, P 19 IEEE INT C DAT; HUNG E, 2002, PROBSEM PROBABILISTI; IMIELINSKI T, 1984, J ACM; KEULEN M, 2005, P 21 IEEE INT C DAT; Kriegel HP, 2005, P 11 ACM SIGKDD INT; Kriegel H-P, 2005, P 5 IEEE INT C DAT M; KRIEGEL HP, 2006, P 11 INT C DAT SYST; Lakshmanan LVS, 1997, ACM T DATABASE SYST, V22, P419, DOI 10.1145/261124.261131; LEE SK, 1992, P 18 INT C VER LARG; Little RJA, 1987, STAT ANAL MISSING DA; LJOSA V, 2007, P 23 IEEE INT C DAT; LJOSA V, 2008, P 24 IEEE INT C DAT; McClean S, 2001, IEEE T KNOWL DATA EN, V13, P902, DOI 10.1109/69.971186; MOTRO A, 1990, SIGMOD RECORD, V19; MOTRO A, 1996, UNCERTAINTY MANAGEME, P9; Mutsuzaki M., 2007, P 3 BIENN C INN DAT; NGAI W, 2006, P 6 IEEE INT C DAT M; Nierman A., 2002, P 28 INT C VER LARG; PEDERSEN T, 1999, P 11 INT C VER LARG; Pei J., 2007, P 33 INT C VER LARG; PFOZER D, 1999, P INT C SOL STAT DEV; PRADE H, 1984, INFORM SCI; ROSS R, 2005, J ACM, V52; Rundensteiner E. A., 1992, Data & Knowledge Engineering, V7, DOI 10.1016/0169-023X(92)90040-I; SADRI F, 1991, P 7 IEEE INT C DAT E; SEN P, 2007, P 23 IEEE INT C DAT; Silverman B. W., 1986, DENSITY ESTIMATION S; SINGH S, 2007, P 23 IEEE INT C DAT; SINGH S, 2006, P 22 IEEE INT C DAT; SOLIMAN M, 2007, P 23 IEEE INT C DAT; TAO Y, 2005, P 31 INT C VER LARG; Zhang Q, 2008, P ACM SIGMOD; ZHAO W, 2004, J INTELL INF SYST, P1; ZIMANYI E, 1997, THEORETICAL COMPUTER, V171	79	36	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2009	21	5					609	623		10.1109/TKDE.2008.190		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	420PB	WOS:000264300600001	
J	Lucchese, C; Orlando, S; Perego, R				Lucchese, C; Orlando, S; Perego, R			Fast and memory efficient mining of frequent closed itemsets	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; association rules; frequent itemsets; condensed representations; closed itemsets; high-performance algorithms	ASSOCIATION RULES	This paper presents a new scalable algorithm for discovering closed frequent itemsets, a lossless and condensed representation of all the frequent itemsets that can be mined from a transactional database. Our algorithm exploits a divide-and-conquer approach and a bitwise vertical representation of the database and adopts a particular visit and partitioning strategy of the search space based on an original theoretical framework, which formalizes the problem of closed itemsets mining in detail. The algorithm adopts several optimizations aimed to save both space and time in computing itemset closures and their supports. In particular, since one of the main problems in this type of algorithms is the multiple generation of the same closed itemset, we propose a new effective and memory-efficient pruning technique, which, unlike other previous proposals, does not require the whole set of closed patterns mined so far to be kept in the main memory. This technique also permits each visited partition of the search space to be mined independently in any order and, thus, also in parallel. The tests conducted on many publicly available data sets show that our algorithm is scalable and outperforms other state-of-the-art algorithms like CLOSET+ and FP-CLOSE, in some cases by more than one order of magnitude. More importantly, the performance improvements become more and more significant as the support threshold is decreased.	Univ Ca Foscari Venezia, Dipartimento Informat, I-30172 Venice, Italy; CNR, ISTI, High Performance Comp Lab, Area Ric Pisa, I-56126 Pisa, PI, Italy	Lucchese, C (reprint author), Univ Ca Foscari Venezia, Dipartimento Informat, Via Torino 155, I-30172 Venice, Italy.	clucches@dsi.unive.it; orlando@dsi.unive.it; raffaele.perego@isti.cnr.it	Lucchese, Claudio/G-3947-2012				Agrawal R., 1994, P 20 INT C VER LARG; BOULICAUT JF, 2000, P 4 EUR C PRINC PRAC; BRIN S, 1997, P ACM SIGMOD INT C M; BYKOWSKI A, 2001, P 20 ACM S PRINC DAT; CALDERS T, 2002, P 6 EUR C PRINC PRAC; Goethals B, 2004, SIGKDD EXPLORATIONS, V6, P109; Grahne G., 2003, P ICDM WORKSH FREQ I; HAN JW, 2000, P 2000 ACM SIGMOD IN; KRYSZKIEWICZ M, 2001, P IEEE INT C DAT MIN; KRYSZKIEWICZ M, 2002, P 6 PAC AS C KNOWL D; LIU J, 2002, P 9 ACM INT C KNOWL; LUCCHESE C, 2003, P 2003 WORKSH FREQ I; MANNILA H, 1996, P ACM INT C KNOWL DI; ORLANDO S, 2002, P IEEE INT C DAT MIN; PARK JS, 1995, P ACM INT C MAN DAT; PASQUIER N, 1999, P 7 INT C DAT THEOR; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; PEI J, 2003, P 9 ACM SIGKDD INT C; PEI J, 2000, P ACM SIGMOD INT WOR; PEI J, 2001, P IEEE INT C DAT MIN; TAOUIL R, 2000, SIGKDD EXPLORATIONS, V2; Zaki M.J., 2003, P 9 ACM SIGKDD INT C; Zaki MJ, 2004, DATA MIN KNOWL DISC, V9, P223, DOI 10.1023/B:DAMI.0000040429.96086.c7; Zaki M.J., 2002, P 2 SIAM INT C DAT M	24	36	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JAN	2006	18	1					21	36		10.1109/TKDE.2006.10		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	993EU	WOS:000233938200002	
J	Yoon, H; Yang, KY; Shahabi, C				Yoon, H; Yang, KY; Shahabi, C			Feature subset selection and feature ranking for multivariate time series	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article; Proceedings Paper	1st International Workshop on Data Cleaning and Preprocessing	DEC   09, 2002	Maebashi City, JAPAN	Univ Technol Sydney, Hong Kong Univ Sci & Technol		data mining; feature evaluation and selection; feature extraction or construction; time series analysis; feature representation		Feature subset selection (FSS) is a known technique to preprocess the data before performing any data mining tasks, e.g., classification and clustering. FSS provides both cost-effective predictors and a better understanding of the underlying process that generated the data. We propose a family of novel unsupervised methods for feature subset selection from Multivariate Time Series (MTS) based on Common Principal Component Analysis, termed CLeVer. Traditional FSS techniques, such as Recursive Feature Elimination (RFE) and Fisher Criterion (FC), have been applied to MTS data sets, e.g., Brain Computer Interface (BCI) data sets. However, these techniques may lose the correlation information among features, while our proposed techniques utilize the properties of the principal component analysis to retain that information. In order to evaluate the effectiveness of our selected subset of features, we employ classification as the target data mining task. Our exhaustive experiments show that CLeVer outperforms RFE, FC, and random selection by up to a factor of two in terms of the classification accuracy, while taking up to 2 orders of magnitude less processing time than RFE and FC.	Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA	Yoon, H (reprint author), Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.	hjy@usc.edu; kiyoungy@usc.edu; shahabi@usc.edu					Bishop C., 1996, NEURAL NETWORKS PATT; Chang Chin-Chung, 2004, LIBSVM LIB SUPPORT; Cohen I., 2002, FEATURE SELECTION US; FLURY BN, 1984, J AM STAT ASSOC, V79, P892, DOI 10.2307/2288721; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HAN J, 2000, DATA MINING CONCEPTS, P121; Hettich S., 1999, UCI KDD ARCH; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kadous M. W., 2002, THESIS U NEW S WALES; KOHAVI R, 1995, P INT JOINT C ART IN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KRZANOWSKI W, 1979, J AM STAT ASS, V74; KRZANOWSKI W, 2002, STAT TRANSITION, V5, P759; Lal T. Navin, 2004, IEEE T BIOMEDICAL EN, V51; LEIBOVICI D, 1998, LINEAR ALGEBRA ITS A; LIU H, 2003, P PAC AS C KNOWL DIS; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; MOON T.K., 2000, MATH METHODS ALGORIT; Pal S.K., 2004, PATTERN RECOGNITION; Sakoe H., 1978, IEEE T ACOUSTICS SPE, V26; SCHOTT JR, 1991, BIOMETRIKA, V78, P771, DOI 10.1093/biomet/78.4.771; SHAH M, 1997, MOTION BASED RECOGNI, pCH15; SHAHABI C, 2003, P VER LARG DAT BAS B; TANAWONGSUWAN R, 2003, P 4 INT C AUD VID BA; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; TUCKER A, 2001, IEEE T SYSTEMS MAN C, V31; Vapnik V. N., 1998, STAT LEARNING THEORY; Weston J., 2005, SPIDER OBJECT ORIENT; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; WINSTEIN C, 2004, SOC NEUROSCIENCE OCT; YANG K, 2004, P 2 ACM INT WORKSH M; ZHANG XL, 1995, BRAIN RES B, V38; ZHONG S, 2002, P INT JOINT C NEUR N; 2003, MARKER CONFIGURATION	35	36	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP	2005	17	9					1186	1198		10.1109/TKDE.2005.144		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	953SW	WOS:000231101800004	
J	Elfeky, MG; Aref, WG; Elmagarmid, AK				Elfeky, MG; Aref, WG; Elmagarmid, AK			Periodicity detection in time series databases	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						periodic patterns mining; temporal data mining; time series forecasting; time series analysis	PATTERNS	Periodicity mining is used for predicting trends in time series data. Discovering the rate at which the time series is periodic has always been an obstacle for fully automated periodicity mining. Existing periodicity mining algorithms assume that the periodicity rate ( or simply the period) is user- specified. This assumption is a considerable limitation, especially in time series data where the period is not known a priori. In this paper, we address the problem of detecting the periodicity rate of a time series database. Two types of periodicities are defined, and a scalable, computationally efficient algorithm is proposed for each type. The algorithms perform in O(n log n) time for a time series of length n. Moreover, the proposed algorithms are extended in order to discover the periodic patterns of unknown periods at the same time without affecting the time complexity. Experimental results show that the proposed algorithms are highly accurate with respect to the discovered periodicity rates and periodic patterns. Real- data experiments demonstrate the practicality of the discovered periodic patterns.	Google Inc, Mountain View, CA 94043 USA; Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Elfeky, MG (reprint author), Google Inc, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.	mgelfeky@google.com; aref@cs.purdue.edu; ake@cs.purdue.edu					ABRAHAMSON K, 1987, SIAM J COMPUT, V16, P1039, DOI 10.1137/0216067; AGRAWAL R, 1995, P 11 INT C DAT ENG M; Agrawal R., 1994, P 20 INT C VER LARG; Aref WG, 2004, IEEE T KNOWL DATA EN, V16, P332; Atallah MJ, 2001, ALGORITHMICA, V29, P468, DOI 10.1007/s004530010062; AYRES J, 2002, P 8 INT C KNOWL DISC; BERBERIDIS W, 2002, P 15 EUR C ART INT J; Bettini C, 1998, IEEE T KNOWL DATA EN, V10, P222, DOI 10.1109/69.683754; Cormen T.H., 1990, INTRO ALGORITHMS; Daw CS, 2003, REV SCI INSTRUM, V74, P915, DOI 10.1063/1.1531823; ELFEKY M, 2004, P 9 INT C EXT DAT BA; GAROFALAKIS MN, 1999, P 25 INT C VER LARG; Han J., 1998, P 4 INT C KNOWL DISC; HAN J, 1999, P 15 INT C DAT ENG M; INDYK P, 2000, P 26 INT C VER LARG; KEOGH E, 2002, P 8 INT C KNOWL DISC; Keogh E., 2004, DATA MINING TIME SER; KNUTH DE, 1981, SERIES COMPUTER SCI, V2; MA S., 2001, P 17 INT C DAT ENG; OZDEN B, 1998, P 14 INT C DAT ENG F; SRIKANT R, 1996, P 5 INT C EXT DAT BA; Vitter JS, 2001, ACM COMPUT SURV, V33, P209, DOI 10.1145/384192.384193; Weigend A, 1994, TIME SERIES PREDICTI; YANG J, 2000, P 6 INT C KNOWL DISC; YANG J, 2002, P 2 INT C DAT MIN DE	25	36	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL	2005	17	7					875	887		10.1109/TKDE.2005.114		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	925SY	WOS:000229074800001	
B	Ratanamahatana, CA; Keogh, E		Kargupta, H; Srivastava, J; Kamath, C; Goodman, A		Ratanamahatana, Chotirat Ann; Keogh, Eamonn			Three Myths about Dynamic Time Warping Data Mining	PROCEEDINGS OF THE FIFTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING	SIAM Proceedings Series		English	Proceedings Paper	5th SIAM International Conference on Data Mining	APR 21-23, 2005	Newport Beach, CA	SIAM, Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Amer Stat Assoc		Dynamic Time Warping; Data Mining; Experimentation	WORD RECOGNITION; ALGORITHMS; SERIES	The Dynamic Time Warping (DTW) distance measure is a technique that has long been known in speech recognition community. It allows a non-linear mapping of one signal to another by minimizing the distance between the two. A decade ago, DTW was introduced into Data Mining community as a utility for various tasks for time series problems including classification, clustering, and anomaly detection. The technique has flourished, particularly in the last three years, and has been applied to a variety of problems in various disciplines. In spite of DTW's great success, there are still several persistent "myths" about it. These myths have caused confusion and led to much wasted research effort. In this work, we will dispel these myths with the most comprehensive set of time series experiments ever conducted.	[Ratanamahatana, Chotirat Ann; Keogh, Eamonn] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA	Ratanamahatana, CA (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	ratana@cs.ucr.edu; eamonn@cs.ucr.edu					Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; Berndt D., 1994, AAAI 94 WORKSH KNOWL, P229; BOZKAYA T, 1997, CIKM; CAIANI EG, 1998, IEEE COMPUTERS CARDI, P73; CARDLE M, 2003, THESIS CAMBRIDGE U; KEOGH E, 2001, SIGMOD, P151; Keogh E., 2002, VLDB, P406, DOI 10.1016/B978-155860869-6/50043-3; Keogh E., 2002, UCR TIME SERIES DATA; Keogh E.J., 2002, 8 ACM SIGKDD INT C K, P102; Kim SW, 2004, INFORM SYST, V29, P405, DOI 10.1016/S0306-4379(03)00037-1; Kornfield EM, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P195, DOI 10.1109/DIAL.2004.1263249; LAAKSONEN J, 1998, P INT C ART NEUR NET, P245; RABINER LR, 1978, IEEE T ACOUST SPEECH, V26, P575, DOI 10.1109/TASSP.1978.1163164; PARK S, 2000, ICDE 00; Ratanamahatana CA, 2004, SIAM PROC S, P11; RATANAMAHATANA CA, 2004, SIGKDD WORKSH MIN TE; RATH TM, 2003, COMPUTER VISION PATT, V2, P521; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SHOU Y, 2001, TR200401 HKU CSIS; TOMASI G, 2004, J CHEMOMETRICS; WONG TSF, 2003, IDEAS; Zhu Y., 2003, SIGMOD C, P181	22	36	38	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA		978-0-89871-593-4	SIAM PROC S			2005							506	510				5	Computer Science, Artificial Intelligence	Computer Science	BUJ08	WOS:000289491000050	
J	Evfimievski, A; Srikant, R; Agrawal, R; Gehrke, J				Evfimievski, A; Srikant, R; Agrawal, R; Gehrke, J			Privacy preserving mining of association rules	INFORMATION SYSTEMS			English	Article; Proceedings Paper	8th International Conference on Knowledge Discovery and Data Mining (KDD 2002)	JUL 23-26, 2002	EDMONTON, CANADA	ACM, SIGKDD		data mining; privacy; association rule; privacy breach		We present a framework for mining association rules from transactions consisting of categorical items where the data has been randomized to preserve privacy of individual transactions. While it is feasible to recover association rules and preserve privacy using a straightforward "uniform" randomization, the discovered rules can unfortunately be exploited to find privacy breaches. We analyze the nature of privacy breaches and propose a class of randomization operators that are much more effective than uniform randomization in limiting the breaches. We derive formulae for an unbiased support estimator and its variance, which allow us to recover itemset supports from randomized datasets, and show how to incorporate these formulae into mining algorithms. Finally, we present experimental results that validate the algorithm by applying it on real datasets. (C) 2003 Published by Elsevier Ltd.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; IBM Almaden Res Ctr, San Jose, CA 95120 USA	Gehrke, J (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.	aevf@cs.cornell.edu; srikant@almaden.ibm.com; ragrawal@almaden.ibm.com; johannes@cs.cornell.edu					ADAM NR, 1989, COMPUT SURV, V21, P515; Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R, 2000, ACM SIGMOD C MAN DAT, P439; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGRAWAL R, 1999, 5 INT C KNOWL DISC D; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Agrawal R., 1994, 9839 RJ IBM ALM RES; BAYARDO R, 1998, P ACM SIGMOD C MAN D; Breiman L, 1984, CLASSIFICATION REGRE; Clifton C., 1996, ACM SIGMOD WORKSH RE, P15; Conway R, 1976, P ACM ANN C, P85, DOI 10.1145/800191.805537; CRANOR L, 1999, 9943 TR ATT LABS RES; CRANOR LF, 1999, COMMUN ACM, V42; Estivill-Castro V., 1999, LECT NOTES COMPUTER, V1676, P389; Evfimievski A., 2002, P 8 ACM SIGKDD INT C, P217; Evfimievski A., 2003, P 22 ACM SIGMOD SIGA, P211, DOI 10.1145/773153.773174; Lindell Y., 2000, CRYPTO, P36; Mitchell T., 1997, MACH LEARN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rizvi S., 2002, P 28 INT C VER LARG; Shoshani A., 1982, Proceedings of Very Large Data Bases. Eighth International Conference on Very Large Data Bases; THEARLING K, DATA MINING PRIVACY; Vaidya J., 2002, P 8 ACM SIGKDD INT C; WARNER SL, 1965, J AM STAT ASSOC, V60, P63, DOI 10.2307/2283137; Westin A., 1998, ECOMMERCE PRIVACY WH; Westin A., 1999, FREEBIES PRIVACY WHA; WESTIN A, 1998, PRIVACY CONCERNS CON; *EUR UN, 1998, DIR PRIV PROT; *OFF INF PRIV COMM, 1998, DAT MIN STAK CLAIM Y; 1999, ECONOMIST        MAY; 1997, TIME             AUG; 2000, BUSINESS WEEK    MAR	32	36	37	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	JUN	2004	29	4					343	364		10.1016/j.is.2003.09.001		22	Computer Science, Information Systems	Computer Science	802KI	WOS:000220162000006	
J	Boulle, M				Boulle, M			Khiops: A statistical discretization method of continuous attributes	MACHINE LEARNING			English	Article						data mining; machine learning; discretization; data analysis		In supervised machine learning, some algorithms are restricted to discrete data and have to discretize continuous attributes. Many discretization methods, based on statistical criteria, information content, or other specialized criteria, have been studied in the past. In this paper, we propose the discretization method Khiops,(1) based on the chi-square statistic. In contrast with related methods ChiMerge and ChiSplit, this method optimizes the chi-square criterion in a global manner on the whole discretization domain and does not require any stopping criterion. A theoretical study followed by experiments demonstrates the robustness and the good predictive performance of the method.	France Telecom R&D, F-22300 Lannion, France	Boulle, M (reprint author), France Telecom R&D, 2 Ave Pierre Marzin, F-22300 Lannion, France.	marc.boulle@francetelecom.com					BERTELSEN R, 1994, P 7 FLOR ART INT RES, P122; BERTIER P., 1981, ANAL DONNEES MULTIDI; Blake C, 1998, UCI REPOSITORY MACHI; BOULLE M, 2001, NTFTRD7339; Breiman L, 1984, CLASSIFICATION REGRE; BURDSALL B, 1997, P 2 INT ICSC S FUZZ, P217; CATLETT J, 1991, P EUR WORK SESS LEAR, P87; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; KERBER R, 1991, P 10 INT C ART INT, P123; Langley P, 1992, P 10 NAT C ART INT, P223; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; ZIGHED DA, 2000, GRAPHES INDUCTION, P327; Zighed DA, 1998, INT J UNCERTAIN FUZZ, V6, P307, DOI 10.1142/S0218488598000264	16	36	41	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	APR	2004	55	1					53	69		10.1023/B:MACH.0000019804.29836.05		17	Computer Science, Artificial Intelligence	Computer Science	803AH	WOS:000220203500003	
S	Lee, YC; Hong, TP; Lin, WY		Negoita, MG; Howlett, RJ; Jain, LC		Lee, YC; Hong, TP; Lin, WY			Mining fuzzy association rules with multiple minimum supports using maximum constraints	KNOWLEDGE-BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 2, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	8th International Conference on Knowledge-Based Intelligent Information and Engineering Systems	SEP, 2004	Wellington, NEW ZEALAND	Royal Soc New Zealand, IPENZ, New Zealand Trade & Enterprise, Telecom, Allied Telesyn, Positively Wellington Business	Wellington Inst Technol			Data mining is the process of extracting desirable knowledge or interesting patterns from existing databases for specific purposes. Most of the previous approaches set a single minimum support threshold for all the items or itemsets and identify the relationships among transactions using binary values. But in real applications, different items may have different criteria to judge its importance and quantitative data may exist. In this paper, we thus propose a fuzzy mining algorithm for discovering useful fuzzy association rules under the maximum support constraints. Items may have different minimum supports and the minimum support for an itemset is set as the maximum of the minimum supports of the items contained in the itemset. Under the constraint, the characteristic of level-by-level processing is kept, such that the original Apriori algorithm can be easily extended to find the large itemsets. An example is also given to illustrate the proposed algorithm.	Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan		d9003007@stmail.isu.edu.tw; tphong@nuk.edu.tw; wylin@isu.edu.tw					Agrawal R., 1993, ACM SIGMOD INT C MAN, P207; Cai CH, 1998, IDEAS 98 - INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P68; Fukuda T., 1996, ACM SIGACT SIGMOD SI, P182; Hong T. P., 1999, INTELL DATA ANAL, V3, P363, DOI 10.1016/S1088-467X(99)00028-1; LEE YC, 2002, WORKSH FDN DAT MIN D, P171; Ma Y., 1999, P 5 ACM SIGKDD INT C, P337, DOI 10.1145/312129.312274; Rastogi R, 1998, PROC INT CONF DATA, P503, DOI 10.1109/ICDE.1998.655813; Srikant R., 1996, 1996 ACM SIGMOD INT, P1; Wang K., 2000, P 26 INT C VER LARG, P43; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z; Yue S., 2000, IEEE INT C SYST MAN, P1906	11	36	37	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-23206-0	LECT NOTES COMPUT SC			2004	3214						1283	1290				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBB76	WOS:000224585400171	
J	Aumann, Y; Lindell, Y				Aumann, Y; Lindell, Y			A statistical theory for quantitative association rules	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						data mining; knowledge discovery in data bases; quantitative association rules; statistical inference theory		Association rules are a key data-mining tool and as such have been well researched. So far, this research has focused predominantly on databases containing categorical data only. However, many real-world databases contain quantitative attributes and current solutions for this case are so far inadequate. In this paper we introduce a new definition of quantitative association rules based on statistical inference theory. Our definition reflects the intuition that the goal of association rules is to find extraordinary and therefore interesting phenomena in databases. We also introduce the concept of sub-rules which can be applied to any type of association rule. Rigorous experimental evaluation on real-world datasets is presented, demonstrating the usefulness and characteristics of rules mined according to our definition.	IBM TJ Watson Res, Hawthorne, NY 10532 USA; Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel	Lindell, Y (reprint author), IBM TJ Watson Res, 19 Skyline Dr, Hawthorne, NY 10532 USA.	aumann@cs.biu.ac.il; lindell@us.ibm.com					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R, 1994, P 20 INT C VLDB; Brin S., 1997, P 1997 ACM SIGMOD C; FUKUDA T, 1996, P 1996 ACM SIGMOD C; Fukuda T, 1999, J COMPUT SYST SCI, V58, P1, DOI 10.1006/jcss.1998.1595; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; KLOESGEN W, 1994, P KDD 94 WORKSH AAAI; Lindgren B.W., 1976, STAT THEORY; Mannila H., 1994, KNOWLEDGE DISCOVERY, P181; Morimoto Y, 2001, MACH LEARN, V45, P235, DOI 10.1023/A:1017980905332; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Srikant R, 1996, P ACM SIGMOD C MAN D; TOIVONEN H, 1996, P 22 VLDB C; YODA K, P KDD 97; ZHANG Z, 1997, P 1 PAC AS C KNOWL D	15	36	38	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	MAY	2003	20	3					255	283		10.1023/A:1022812808206		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	657XD	WOS:000181690900002	
J	Chan, FKP; Fu, AWC; Yu, C				Chan, FKP; Fu, AWC; Yu, C			Haar wavelets for efficient similarity search of time-series: With and without time warping	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						similarity search; time warping; wavelets; dimension reduction; multidimensional index; time series database; data mining		We address the handling of time series search based on two important distance definitions: Euclidean distance and time warping distance. Conventional method reduces the dimensionality by means of Discrete Fourier Transform. We apply the Haar Wavelet Transform technique and propose the use of a proper normalization so that the method can guarantee no false dismissal for Euclidean distance. We found that this method has competitive performance from our experiments,. Euclidean distance measurement cannot handle the time shifts of patterns. It fails to match the same rise and fall patterns of sequences with different scales. A distance measure that handles this problem is the time warping distance. However, the complexity of computing the time warping distance function is high. Also, as time warping distance is not a metric, most indexing techniques would not guarantee any false dismissal. We propose efficient strategies to mitigate the problems of time warping. We suggest a Haar wavelet-based approximation function for time warping distance, called Low Resolution Time Warping, which results in less computation by trading off a small amount of accuracy. We apply our approximation function to similarity search in time series databases, and show by experiment that it is highly effective in suppressing the number of false-alarms in similarity search.	Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China; Univ Illinois, Dept Elect Engn & Comp Sci, Chicago, IL 60612 USA	Chan, FKP (reprint author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	fkpchan@alumni.cuhk.net; adafu@cse.cuhk.edu.hk; yu@eecs.uic.edu					AGBINYA JI, 1996, P IEEE TENCON DIGITA, P514; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; AGRAWAL R, 1993, P 4 INT C FDN DAT OR; Akansu A. N., 1992, MULTIRESOLUTION SIGN; Benedetto JJ, 1994, WAVELETS MATH APPL; BERNDT DJ, 1995, ADV KNOWLEDGE DISCOV; Burrus C. S., 1997, INTRO WAVELETS WAVEL; Chan K. P., 1999, P INT C DAT ENG; Chatfield C., 1984, ANAL TIME SERIES INT; Edwards T., 1991, DISCRETE WAVELET TRA; Faloutsos C., 1994, P ACM SIGMOD INT C M, P419, DOI 10.1145/191839.191925; FORAN J, 1991, FUNDAMENTALS REAL AN; Gonzalez R. C., 1992, DIGITAL IMAGE PROCES; GROCHENIG K, 1992, IEEE T INFORM THEORY, V38, P556, DOI 10.1109/18.119723; KANTH KVR, 1998, P ACM SIGMOD C MAN D; KEOGH EJ, 2000, P ACM SIGKDD C KNOWL; KORN F, 1997, P ACM SIGMOD C MAN D; LI CS, 1996, P INT C DAT ENG; MYERS CS, 1981, IEEE T ACOUSTICS SPE, V29; NATSEV A, 1999, P ACM SIGMOD INT C M, P395, DOI 10.1145/304182.304217; Oppenheim A. V., 1975, DIGITAL SIGNAL PROCE; Rabiner L., 1993, FUNDAMENTALS SPEECH; Rafiei D., 1997, P ACM SIGMOD INT C M, P13, DOI 10.1145/253260.253264; Roussopoulos N, 1995, P ACM SIGMOD INT C M, P71, DOI DOI 10.1145/223784.223794; SAKOE H, 1979, IEEE T ACOUSTICS SPE, V27; SAKOE H, 1990, READING SPEECH RECOG; SANGHYUN P, 2000, P INT C DAT ENG; SASHA D, TIME SERIES FINANCE; Stollnitz E., 1996, WAVELETS COMPUTER GR; WU D, 1996, P C INF KNOWL MAN; Yi B.-K., 1998, P INT C DAT ENG; Yi B.K., 2000, P 26 INT C VER LARG, P385	32	36	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY-JUN	2003	15	3					686	705		10.1109/TKDE.2003.1198399		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	674PG	WOS:000182644700014	
J	Burl, MC; Asker, L; Smyth, P; Fayyad, U; Perona, P; Crumpler, L; Aubele, J				Burl, MC; Asker, L; Smyth, P; Fayyad, U; Perona, P; Crumpler, L; Aubele, J			Learning to recognize volcanoes on Venus	MACHINE LEARNING			English	Article						machine learning; pattern recognition; learning from examples; large image databases; data mining; automatic cataloging; detection of natural objects; Magellan SAR; JARtool; volcanoes; Venus; principal components analysis; trainable	IMAGE; METHODOLOGY; PERFORMANCE; RETRIEVAL; MAGELLAN; SYSTEM	Dramatic improvements in sensor and image acquisition technology have created a demand for automated tools that can aid in the analysis of large image databases. We describe the development of JARtool, a trainable software system that learns to recognize volcanoes in a large data set of Venusian imagery. A machine learning approach is used because it is much easier for geologists to identify examples of volcanoes in the imagery than it is to specify domain knowledge as a set of pixel-level constraints. This approach can also provide portability to other domains without the need for explicit reprogramming; the user simply supplies the system with a new set of training examples. We show how the development of such a system requires a completely different set of skills than are required for applying machine learning to "toy world" domains. This paper discusses important aspects of the application process not commonly encountered in the "toy world" including obtaining labeled training data, the difficulties of working with pixel data, and the automatic extraction of higher-level features.	CALTECH, Jet Prop Lab, Pasadena, CA 91109 USA; Univ Stockholm, S-10691 Stockholm, Sweden; Univ Calif Irvine, Irvine, CA 92717 USA; Univ Padua, I-35100 Padua, Italy; Brown Univ, Providence, RI 02912 USA; New Mexico Museum Nat Hist & Sci, Albuquerque, NM USA; Microsoft Res, Redmond, WA USA	Burl, MC (reprint author), CALTECH, Jet Prop Lab, MS 525-3660,4800 Oak Grove Dr, Pasadena, CA 91109 USA.						ASKER L, 1997, 15 INT JOINT C ART I; ASKER L, 1997, 14 INT C MACH LEARN; AUBELE JC, 1990, EARTH MOON PLANETS, V50-1, P493, DOI 10.1007/BF00142404; BALDI P, 1994, COMMUNICATION; BRODLEY CE, 1997, STAT COMPUTING; BUNCH PC, 1978, J APPL PHOTOGR ENG, V4, P166; BURL MC, 1996, CNSTR9601 CALTECH; Burl M. C., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), DOI 10.1109/CVPR.1994.323844; BURL MC, 1994, IEEE INT C IM PROC, V3, P236; CHAKRABORTY DP, 1990, RADIOLOGY, V174, P873; CHERKAUER K, 1996, COMMUNICATION; CHESTERS MS, 1992, PHYS MED BIOL, V37, P1433, DOI 10.1088/0031-9155/37/7/001; Cooke RM, 1991, EXPERTS UNCERTAINTY; CROSS AM, 1988, INT J REMOTE SENS, V9, P1519; CRUMPLER LS, 1997, VENUS, V2; Duda R., 1973, PATTERN CLASSIFICATI; FAYYAD UM, 1996, EARLY VISUAL LEARNIN; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; Fukunaga K., 1990, INTRO STAT PATTERN R; GREEN DM, 1966, SIGNAL DETECTION THE; GUEST JE, 1992, J GEOPHYS RES-PLANET, V97, P15949; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; LANGLEY P, 1995, COMMUN ACM, V38, P55; MACMILLAN NA, 1991, SIGNAL DETECTION THE; MENDEL E, 1997, SAOIMAGE NEXT GENERA; MOGHADDAM B, 1995, INT WORKSH AUT FAC G, P122; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; PETTENGILL GH, 1991, SCIENCE, V252, P260, DOI 10.1126/science.252.5003.260; Picard RW, 1996, IEEE T PATTERN ANAL, V18, P769, DOI 10.1109/TPAMI.1996.531797; Poulton E. C., 1994, BEHAV DECISION THEOR; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Richards J. A., 1986, REMOTE SENSING DIGIT; SAUNDERS RS, 1992, J GEOPHYS RES-PLANET, V97, P13067; SIMARD P, 1993, ADV NEURAL INFORMATI, V5, P50; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; SKINGLEY J, 1987, PATTERN RECOGN LETT, V6, P61, DOI 10.1016/0167-8655(87)90050-X; Spackman K.A., 1989, P 6 INT WORKSH MACH, P160; STOFAN ER, 1992, J GEOPHYS RES-PLANET, V97, P13347; STONEBRAKER M, 1991, COMMUN ACM, V34, P78, DOI 10.1145/125223.125262; Stough T. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TREITEL S, 1971, IEEE T GEOSCI ELECT, VGE 9, P10, DOI 10.1109/TGE.1971.271457; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; TURMON M, 1996, COMMUNICATION; WILES CR, 1993, IMAGE VISION COMPUT, V11, P188, DOI 10.1016/0262-8856(93)90035-F	45	36	36	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	FEB-MAR	1998	30	2-3					165	194		10.1023/A:1007400206189		30	Computer Science, Artificial Intelligence	Computer Science	ZK607	WOS:000073342100003	
J	Zhang, CS; Ouyang, DT; Ning, JX				Zhang, Changsheng; Ouyang, Dantong; Ning, Jiaxu			An artificial bee colony approach for clustering	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Clustering; Meta-heuristic algorithm; Artificial bee colony; K-means	K-MEANS ALGORITHM; SEARCH	Clustering is a popular data analysis and data mining technique. In this paper, an artificial bee colony clustering algorithm is presented to optimally partition N objects into K clusters. The Deb's rules are used to direct the search direction of each candidate. This algorithm has been tested on several well-known real datasets and compared with other popular heuristics algorithm in clustering, such as GA, SA, TS, ACO and the recently proposed K-NM-PSO algorithm. The computational simulations reveal very encouraging results in terms of the quality of solution and the processing time required. (C) 2009 Elsevier Ltd. All rights reserved.	[Zhang, Changsheng] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China; [Ouyang, Dantong] Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China; [Ning, Jiaxu] NE Normal Univ, Inst Grassland Sci, Changchun, Peoples R China	Zhang, CS (reprint author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.	zcs820@yahoo.com.cn			NSFC [60973089, 60903009]; Open Research Fund of the Symbol Computation and Knowledge Engineer of Education Ministry [93K-17-2009-K02]; Special Fund for Fundamental Research of Central Universities of Northeastern University [90404015]; National High Technology Research and Development Program of China [2009AA012122]	This work was supported by NSFC Major Research Program under Grants 60973089 and 60903009, Open Research Fund of the Symbol Computation and Knowledge Engineer of Education Ministry (93K-17-2009-K02) and the Special Fund for Fundamental Research of Central Universities of Northeastern University (90404015), and the National High Technology Research and Development Program of China (863 Program) (2009AA012122).	ALSULTAN KS, 1995, PATTERN RECOGN, V28, P1443, DOI 10.1016/0031-3203(95)00022-R; Bandyopadhyay S, 2002, INFORM SCIENCES, V146, P221, DOI 10.1016/S0020-0255(02)00208-6; Basturk B, 2006, IEEE SWARM INT S 200; Blake C, 1998, UCI REPOSITORY MACHI; Brucker P., 1978, LECTURE NOTES EC MAT, V157, P45; FORGY EW, 1965, BIOMETRICS, V21, P768; Goldberg D.E., 1991, FDN GENETIC ALGORITH, P69; Gungor Z, 2007, APPL MATH COMPUT, V184, P199, DOI 10.1016/j.amc.2006.05.166; Kao YT, 2008, EXPERT SYST APPL, V34, P1754, DOI 10.1016/j.eswa.2007.01.028; Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007; Karaboga D., 2005, TR06 ERC U COMP ENG; Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879; Mualik U., 2002, PATTERN RECOGN, V33, P1455; Murthy CA, 1996, PATTERN RECOGN LETT, V17, P825, DOI 10.1016/0167-8655(96)00043-8; Sander J., 2003, COURSE HOMEPAGE PRIN; SEELEY TD, 1988, BEHAV ECOL SOCIOBIOL, V22, P229, DOI 10.1007/BF00299837; SELIM SZ, 1991, PATTERN RECOGN, V24, P1003, DOI 10.1016/0031-3203(91)90097-O; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; Shelokar PS, 2004, ANAL CHIM ACTA, V509, P187, DOI 10.1016/j.aca.2003.12.032; Sung CS, 2000, PATTERN RECOGN, V33, P849, DOI 10.1016/S0031-3203(99)00090-4; Teodorovic D, 2006, NEUREL 2006: Eight Seminar on Neural Network Applications in Electrical Engineering, Proceedings, P151	21	35	38	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2010	37	7					4761	4767		10.1016/j.eswa.2009.11.003		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	597AB	WOS:000277726300005	
J	Alcala-Fdez, J; Alcala, R; Gacto, MJ; Herrera, F				Alcala-Fdez, Jesus; Alcala, Rafael; Jose Gacto, Maria; Herrera, Francisco			Learning the membership function contexts for mining fuzzy association rules by using genetic algorithms	FUZZY SETS AND SYSTEMS			English	Article						Data mining; Fuzzy association rules; Genetic algorithms; Genetic fuzzy systems; 2-Tuples linguistic representation	MULTIPLE MINIMUM SUPPORTS; TRADE-OFF; DATA-BASE; REPRESENTATION; FRAMEWORK; SELECTION; SYSTEMS; NUMBER; MODEL	Different studies have proposed methods for mining fuzzy association rules from quantitative data, where the membership functions were assumed to be known in advance. However, it is not an easy task to know a priori the most appropriate fuzzy sets that cover the domains of quantitative attributes for mining fuzzy association rules. This paper thus presents a new fuzzy data-mining algorithm for extracting both fuzzy association rules and membership functions by means of a genetic learning of the membership functions and a basic method for mining fuzzy association rules. It is based on the 2-tuples linguistic representation model allowing us to adjust the context associated to the linguistic term membership functions. Experimental results show the effectiveness of the framework. (C) 2008 Elsevier B.V. All rights reserved.	[Alcala-Fdez, Jesus; Alcala, Rafael; Jose Gacto, Maria; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Alcala-Fdez, J (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, C Daniel Saucedo Aranda, E-18071 Granada, Spain.	jalcala@decsai.ugr.es; alcala@decsai.ugr.es; mjgacto@ugr.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008; Alcala, Rafael/B-1843-2012; Alcala Fernandez, Jesus/C-6795-2012	Herrera, Francisco/0000-0002-7283-312X; 	Spanish Ministry of Science and Technology [TIN2005-08386-C05-01]; Andalusian Government [P05-TIC-00531]	This paper has been supported by the Spanish Ministry of Science and Technology under Project TIN2005-08386-C05-01 and the Andalusian Government under Project P05-TIC-00531.	Agrawal R., 1994, INT C VER LARG DAT B, P487; Agrawal R., 1993, SIGMOD, P207; Alcala R, 2007, IEEE T FUZZY SYST, V15, P616, DOI 10.1109/TFUZZ.2006.889880; Cano JR, 2007, DATA KNOWL ENG, V60, P90, DOI 10.1016/j.datak.2006.01.008; Cordon O, 2004, FUZZY SET SYST, V141, P5, DOI 10.1016/S0165-0114(03)00111-8; Cordon O, 2001, INFORM SCIENCES, V136, P85, DOI 10.1016/S0020-0255(01)00143-8; Cordon O., 2001, ADV FUZZY SYSTEMS AP; Cordon O, 2001, IEEE T FUZZY SYST, V9, P667, DOI 10.1109/91.940977; Delgado M, 2003, IEEE T FUZZY SYST, V11, P214, DOI 10.1109/TFUZZ.2003.809896; Dubois D, 2006, DATA MIN KNOWL DISC, V13, P167, DOI 10.1007/s10618-005-0032-4; Dubois D, 2005, IEEE T FUZZY SYST, V13, P250, DOI 10.1109/TFUZZ.2004.840130; ESHELMAN L. J., 1991, FDN GENETIC ALGORITH, V1, P265; Eshelman L.J., 1993, FDN GENETIC ALGORITH, V2, P187; Fu A, 1998, IDEAL 98 1 INT S INT, P263; Han J, 2006, DATA MINING CONCEPTS; Herrera F, 2000, IEEE T FUZZY SYST, V8, P746, DOI 10.1109/91.890332; Herrera Francisco, 2008, Evolutionary Intelligence, V1, DOI 10.1007/s12065-007-0001-5; Hong T., 2008, STUDIES FUZZINESS SO, V220, P397; Hong TP, 2004, IEEE SYMP COMP COMMU, P116; Hong TP, 2006, SOFT COMPUT, V10, P1091, DOI 10.1007/s00500-006-0046-x; Hong TP, 2001, INT J UNCERTAIN FUZZ, V9, P587, DOI 10.1142/S0218488501001071; Hullermeier E, 2007, IEEE T SYST MAN CY B, V37, P1039, DOI 10.1109/TSMCB.2007.895332; Ishibuchi H., 2004, CLASSIFICATION MODEL; Ishibuchi H, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P118, DOI 10.1109/ISIE.2001.931767; Kaya M, 2006, SOFT COMPUT, V10, P578, DOI 10.1007/s00500-005-0509-5; Kaya M, 2005, FUZZY SET SYST, V152, P587, DOI 10.1016/j.fss.2004.09.014; Kaya M, 2006, APPL INTELL, V24, P7, DOI 10.1007/s10489-006-6925-0; KUOK C, 1998, SIGMOD REC, V17, P41; Lee YC, 2004, LECT NOTES COMPUT SC, V3214, P1283; Lee YC, 2008, EXPERT SYST APPL, V34, P459, DOI 10.1016/j.eswa.2006.09.011; Lozano M, 2004, EVOL COMPUT, V12, P273, DOI 10.1162/1063656041774983; NOJIMA Y, 2007, INT C FUZZ SYST LOND, P23; SHUYUE J, 2000, IEEE INT C SYST MAN, P1906; Sudkamp T, 2005, FUZZY SET SYST, V149, P57, DOI 10.1016/j.fss.2004.07.017; Wang W, 2000, INT JOINT C INF SYST, P1; Zhang C., 2002, LECT NOTES ARTIFICIA, V2307	36	35	37	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	APR 1	2009	160	7					905	921		10.1016/j.fss.2008.05.012		17	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	421MJ	WOS:000264362700003	
J	Duan, L; Xu, L; Guo, F; Lee, J; Yan, BP				Duan, Lian; Xu, Lida; Guo, Feng; Lee, Jun; Yan, Baopin			A local-density based spatial clustering algorithm with noise	INFORMATION SYSTEMS			English	Article; Proceedings Paper	2nd International Conference on Intelligent Information Processing	OCT 21-23, 2004	Beijing, PEOPLES R CHINA	IFIP TC12, WG12 3		data mining; local outlier factor; local reachability density; local-density-based clustering	FEATURE SPACE THEORY	Density-based clustering algorithms are attractive for the task of class identification in spatial database. However, in many cases, very different local-density clusters exist in different regions of data space, therefore, DBSCAN method [M. Ester, H.-P. Kriegel, J. Sander, X. Xu, A density-based algorithm for discovering clusters in large spatial databases with noise, in: E. Simoudis, J. Han, U.M. Fayyad (Eds.), Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, Portland, OR, AAAI, Menlo Park, CA, 1996, pp. 226-231] using a global density parameter is not suitable. Although OPTICS [M. Ankerst, M.M. Breunig, H.-P. Kriegel, J. Sander, OPTICS: ordering points to identify the clustering structure, in: A. Delis, C. Faloutsos, S. Ghandeharizadeh (Eds.), Proceedings of ACM SIGMOD International Conference on Management of Data Philadelphia, PA, ACM, New York, 1999, pp. 49-60] provides an augmented ordering of the database to represent its density-based clustering structure, it only generates the clusters with local-density exceeds certain thresholds but not the cluster of similar local-density; in addition, it does not produce clusters of a data set explicitly. Furthermore, the parameters required by almost all the major clustering algorithms are hard to determine although they significantly impact on the clustering result. In this paper, a new clustering algorithm LDBSCAN relying on a local-density-based notion of clusters is proposed. In this technique, the selection of appropriate parameters is not difficult, it also takes the advantage of the LOF [M.M. Breunig, H.-P. Kriegel, R.T. Ng, J. Sander, LOF: identifying density-based local outliers, in: W. Chen, J.F. Naughton, P.A. Bernstein (Eds.), Proceedings of ACM SIGMOD International Conference on Management of Data, Dalles, TX, ACM, New York, 2000, pp. 93-104] to detect the noises comparing with other density-based clustering algorithms. The proposed algorithm has potential applications in business intelligence. (c) 2006 Elsevier B.V. All rights reserved.	Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China; Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; Zhejiang Univ, Hangzhou 310027, Peoples R China; Old Dominion Univ, Norfolk, VA 23529 USA	Duan, L (reprint author), Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.	duanlian@cstnet.cn					Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Ankerst M, 1999, P ACM SIGMOD INT C M, P49, DOI 10.1145/304182.304187; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Breuning M.M., 2000, P ACM SIGMOD INT C M, P93, DOI DOI 10.1145/342009.335388; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Li HX, 2003, EXPERT SYST, V20, P60, DOI 10.1111/1468-0394.00226; Li HX, 2001, KNOWL-BASED SYST, V14, P253, DOI 10.1016/S0950-7051(01)00103-4; Ma S, 2003, LECT NOTES COMPUT SC, V2762, P214; Ma W.M., 2004, PATTERN RECOGN, V37, P503; SHEIKHOLESLAMI G, 1988, P 24 INT C VER LARG, P428; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases	13	35	39	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	NOV	2007	32	7			SI		978	986		10.1016/j.is.2006.10.006		9	Computer Science, Information Systems	Computer Science	200NC	WOS:000248769100004	
J	Kazius, J; Nijssen, S; Kok, J; Back, T; Ijzerman, AP				Kazius, J; Nijssen, S; Kok, J; Back, T; Ijzerman, AP			Substructure mining using elaborate chemical representation	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	7th International Conference on Chemical Structures	JUN 05-09, 2005	Noordwijkerhout, NETHERLANDS	ASC, CINF, CSA Trust, CSJ, GDCh, KNCV			POSSIBLE TOXIC ACTION; ARTIFICIAL-INTELLIGENCE; COMPUTER-PREDICTION; BIOLOGICAL-ACTIVITY; MUTAGENICITY DATA; DEREK SYSTEM; CARCINOGENICITY; GENOTOXICITY; PROGRAM; CONNECTIVITY	Substructure mining algorithms are important drug discovery tools since they can find substructures that affect physicochemical and biological properties. Current methods, however, only consider a part of all chemical information that is present within a data set of compounds. Therefore, the overall aim of our study was to enable more exhaustive data mining by designing methods that detect all substructures of any size. shape, and level of chemical detail. A means of chemical representation was developed that uses atomic hierarchies, thus enabling substructure mining to consider general and/or highly specific features. As a proof-of-concept, the efficient, multipurpose graph mining system Gaston learned substructures of any size and shape from it mutagenicity data set that was represented in this manner. From these substructures. we extracted a set of only six nonredundant, discriminative substructures that represent relevant biochemical knowledge. Our results demonstrate the individual and synergistic importance of elaborate chemical representation and mining for nonlinear substructures. We conclude that the combination of elaborate chemical representation and Gaston provides an excellent method for 2D substructure mining as this recipe systematically explores all substructures in different levels of chemical detail.	Leiden Univ, Div Med Chem, Leiden Amsterdam Ctr Drug Res, NL-2300 RA Leiden, Netherlands; Leiden Univ, Leiden Inst Adv Comp Sci, NL-2333 CA Leiden, Netherlands	Kazius, J (reprint author), Leiden Univ, Div Med Chem, Leiden Amsterdam Ctr Drug Res, POB 9502,Einsteinweg 55, NL-2300 RA Leiden, Netherlands.	j.kazius@lacdr.leidenuniv.nl					Agrawal R., 1994, P 20 INT C VER LARG, P487; ASHBY J, 1985, ENVIRON MUTAGEN, V7, P919, DOI 10.1002/em.2860070613; ASHBY J, 1991, MUTAT RES, V257, P229, DOI 10.1016/0165-1110(91)90003-E; Bacha PA, 2002, J CHEM INF COMP SCI, V42, P1104, DOI 10.1021/ci020366q; BEMIGNI R, 1988, J TOXICOL ENV HLTH, V25, P135; Borgelt C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183885; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Contrera JF, 2005, REGUL TOXICOL PHARM, V43, P313, DOI 10.1016/j.yrtph.2005.09.001; Dearden JC, 1997, ATLA-ALTERN LAB ANIM, V25, P223; ENSLEIN K, 1994, MUTAT RES, V305, P47, DOI 10.1016/0027-5107(94)90125-2; Helma C, 2004, J CHEM INF COMP SCI, V44, P1402, DOI 10.1021/ci034254q; HELMA C, 2002, P BEILST WORKSH 2002; HOFER H, 2003, ADV INTELLIGENT DATA, V5, P380; IHLENFELDT WD, 1994, J CHEM INF COMP SCI, V34, P109, DOI 10.1021/ci00017a013; Inokuchi A., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Inokuchi A., 2001, J COMPUT AIDED CHEM, V2, P87, DOI 10.2751/jcac.2.87; JUDSON PN, 1994, J CHEM INF COMP SCI, V34, P148, DOI 10.1021/ci00017a018; Kazius J, 2005, J MED CHEM, V48, P312, DOI 10.1021/jm040835a; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; KLOPMAN G, 1992, MUTAT RES, V272, P59, DOI 10.1016/0165-1161(92)90008-A; Klopman G, 2004, SAR QSAR ENVIRON RES, V15, P251, DOI 10.1080/10629360410001724897; KLOPMAN G, 1984, J AM CHEM SOC, V106, P7315, DOI 10.1021/ja00336a004; KLOPMAN G, 1992, QSAR, V11, P172; Kuramochi M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989534; Li H, 2005, CHEM RES TOXICOL, V18, P1071, DOI 10.1021/tx049652h; Llorens O, 2001, J MED CHEM, V44, P2793, DOI 10.1021/jm004594; Mahe P, 2005, J CHEM INF MODEL, V45, P939, DOI 10.1021/ci050039t; MALACARNE D, 1993, ENVIRON HEALTH PERSP, V101, P332, DOI 10.2307/3431444; Nijssen S, 2004, P 10 ACM SIGKDD INT, P647, DOI 10.1145/1014052.1014134; Pearl Greg M., 2001, Current Topics in Medicinal Chemistry, V1, P247, DOI 10.2174/1568026013395074; Perrotta A, 1996, ENVIRON MOL MUTAGEN, V28, P31, DOI 10.1002/(SICI)1098-2280(1996)28:1<31::AID-EM7>3.0.CO;2-H; Piegorsch W.W., 1991, LECT NOTES MED INFOR, P35; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; Ridings JE, 1996, TOXICOLOGY, V106, P267, DOI 10.1016/0300-483X(95)03190-Q; SANDERSON DM, 1991, HUM EXP TOXICOL, V10, P261; SMITHING MP, 1992, FOOD SAFETY ASSESSME, P192; Snyder RD, 2004, ENVIRON MOL MUTAGEN, V43, P143, DOI 10.1002/em.20013; Votano JR, 2004, MUTAGENESIS, V19, P365, DOI 10.1093/mutage/geh043; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; White AC, 2003, MUTAT RES-GEN TOX EN, V539, P77, DOI 10.1016/S1383-5718(03)00135-9; WOO YT, 1995, TOXICOL LETT, V79, P219, DOI 10.1016/0378-4274(95)03373-S; WORLEIN M, 2005, P 4 EUR C PRINC KNOW; Yan X., 2002, P 2002 IEEE INT C DA, P721; Young SS, 2002, CHEMOMETR INTELL LAB, V60, P5, DOI 10.1016/S0169-7439(01)00181-2; Zeiger E, 1996, MUTAGENESIS, V11, P471, DOI 10.1093/mutage/11.5.471	45	35	36	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	MAR-APR	2006	46	2					597	605		10.1021/ci0503715		9	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	028XT	WOS:000236522800018	
J	Kuo, RJ; Liao, JL; Tu, C				Kuo, RJ; Liao, JL; Tu, C			Integration of ART2 neural network and genetic K-means algorithm for analyzing Web browsing paths in electronic commerce	DECISION SUPPORT SYSTEMS			English	Article						clustering analysis; data mining; ART2; genetic K-means algorithm; recommendation agent system	MARKET-SEGMENTATION; CLUSTERS	Neural networks and genetic algorithms are useful for clustering analysis in data mining. Artificial neural networks (ANNs) and genetic algorithms (GAs) have been applied in many areas with very promising results. Thus, this study uses adaptive resonance theory 2 (ART2) neural network to determine an initial solution, and then applies genetic K-means algorithm (GKA) to find the final solution for analyzing Web browsing paths in electronic commerce (EC). The proposed method is compared with ART2 followed by K-means. In order to verify the proposed method, data from a Monte Carlo Simulation are used. The simulation results show that the ART2 + GKA is significantly better than the ART2 + K-means, both for mean within cluster variations and misclassification rate. A real-world problem, a recommendation agent system for a Web PDA company, is investigated. In this system, the browsing paths are used for clustering in order to analyze the browsing preferences of customers. These results also show that, based on the mean within-cluster variations, ART2 + GKA is much more effective. (c) 2004 Elsevier B.V. All rights reserved.	Natl Taipei Univ Technol, Dept Ind Engn & Management, Taipei 106, Taiwan	Kuo, RJ (reprint author), Natl Taipei Univ Technol, Dept Ind Engn & Management, 1,Sect 3,Chung Hsiao E Rd, Taipei 106, Taiwan.	rjkuo@ntut.edu.tw					BALAKRISHNAN PV, 1994, PSYCHOMETRIKA, V59, P409; Balakrishnan PV, 1996, EUR J OPER RES, V93, P346, DOI 10.1016/0377-2217(96)00046-X; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; Hertz J, 1991, INTRO THEORY NEURAL; Holland JH, 1975, ADAPTATION NEURAL AR; Jones D., 1991, P 4 INT C GEN ALG, P442; KOHONEN T, 1991, ARTIFICIAL NEURAL NETWORKS, VOLS 1 AND 2, P981; Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879; Kuo RJ, 2004, J ORG COMP ELECT COM, V14, P43, DOI 10.1207/s15327744joce1401_3; KUO RJ, 2002, P 30 INT C COMP IND, P509; Kuo RJ, 2002, COMPUT OPER RES, V29, P1475, DOI 10.1016/S0305-0548(01)00043-0; LAURENCE F, 1996, FUNDAMENTAL NEURAL N, P350; Mannila H., 1996, Proceedings. Eighth International Conference on Scientific and Statistical Database Management (Cat. No.96TB100051), DOI 10.1109/SSDM.1996.505910; Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5; MILLIGAN GW, 1980, PSYCHOMETRIKA, V45, P325, DOI 10.1007/BF02293907; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P123, DOI 10.1007/BF02294153; Murthy CA, 1996, PATTERN RECOGN LETT, V17, P825, DOI 10.1016/0167-8655(96)00043-8; PEPER F, 1993, P 1993 INT JOINT C N, V2, P1425, DOI 10.1109/IJCNN.1993.716812; PIETER Z, 1996, DATA MINING; PROCTOR RA, 1992, MARKETING INTELLIGEN, V10, P21, DOI 10.1108/02634509210007830; SCOTT A, 1990, AI EXPERT, V4, P49; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; SRINIVAS M, 1994, IEEE COMPUTER    JUN, P17; THOMAS F, 1998, IEEE T NEURAL NETWOR, V9, P544; Venugopal V., 1994, Journal of Systems Management, V45; YAMAMAOTO K, 1996, AIAA J, V33, P1990	27	35	39	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	AUG	2005	40	2					355	374		10.1016/j.dss.2004.04.010		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	973LM	WOS:000232524100014	
J	Liu, DR; Shih, YY				Liu, DR; Shih, YY			Hybrid approaches to product recommendation based on customer lifetime value and purchase preferences	JOURNAL OF SYSTEMS AND SOFTWARE			English	Article						recommender system; data mining; product recommendation; customer lifetime value (CLV); collaborative filtering	MINING ASSOCIATION RULES; SUPPORT	Recommending products to attract customers and meet their needs is important in fiercely competitive environments. Recommender systems have emerged in e-commerce applications to Support the recommendation of products. Recently, a weighted RFM-based method (WRFM-based method) has been proposed to provide recommendations based on customer lifetime value, including Recency, Frequency and Monetary. Preference-based collaborative filtering (CF) typically makes recommendations based on the similarities of customer preferences. This study proposes two hybrid methods that exploit the merits of the WRFM-based method and the preference-based CF method to improve the quality of recommendations. Experiments are conducted to evaluate the quality of recommendations provided by the proposed methods, using a data set concerning the hardware retail marketing. The experimental results indicate that the proposed hybrid methods outperform the WRFM-based method and the preference-based CF method. (c) 2004 Elsevier Inc. All rights reserved.	Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan; Minghsin Univ Sci & Technol, Dept Informat Management, Hsinchu, Taiwan	Liu, DR (reprint author), Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan.	dliu@iim.nctu.edu.tw					Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P INT C VER LARG DAT, P407; BERGER PD, 1998, J INTERACT MARK, V12, P17, DOI 10.1002/(SICI)1520-6653(199824)12:1<17::AID-DIR3>3.0.CO;2-K; Bult JR, 1995, MARKET SCI, V14, P378, DOI 10.1287/mksc.14.4.378; Changchien SW, 2001, EXPERT SYST APPL, V20, P325, DOI 10.1016/S0957-4174(01)00017-3; Chen H C, 2001, P ACM C INF KNOWL MA, P231; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; HEARST M, 1998, K MEANS CLUSTERING U; Hill W, 1995, P ACM CHI 95 C HUM F, P194, DOI 10.1145/223904.223929; Hughes A. M., 1994, STRATEGIC DATABASE M; IRVIN S, 1994, CREDIT WORLD, V82, P37; Kahan R., 1998, J CONSUMER MARKETING, V15, P491, DOI 10.1108/07363769810235965; Konstan J., 2000, P 2 ACM C EL COMM, P158, DOI DOI 10.1145/352871.352887; Lang K., 1995, P 12 INT C MACH LEAR, P331; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; LIU DR, UNPUB INFORMATION MA; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Miglautsch J. R., 2000, J DATABASE MARKETING, V8, P67, DOI 10.1057/palgrave.jdm.3240019; PEPPERS D, 1997, ONE ONE FUTURE BUILD; PUNJ G, 1983, J MARKETING RES, V20, P134, DOI 10.2307/3151680; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Rucker J, 1997, COMMUN ACM, V40, P73, DOI 10.1145/245108.245125; SAATY TL, 1994, RWS PUBLICATIONS; SALTON G, 1983, INTRO MODERN INFORMA; Schafer J.B., 2001, J DATA MINING KNOWLE, V5, P115; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Srikant R., 1995, P 21 INT C VER LARG, P407; Stone B., 1995, SUCCESSFUL DIRECT MA; van Rijsbergen C. J., 1979, INFORMATION RETRIEVA; Yun HY, 2003, J SYST SOFTWARE, V67, P181, DOI 10.1016/S0164-1212(02)00128-0	30	35	40	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0164-1212		J SYST SOFTWARE	J. Syst. Softw.	AUG	2005	77	2					181	191		10.1016/j.jss.2004.08.031		11	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	931MI	WOS:000229489000009	
J	He, J; Liu, XT; Shi, Y; Xu, WX; Yan, N				He, J; Liu, XT; Shi, Y; Xu, WX; Yan, N			Classifications of credit cardholder behavior by using fuzzy linear programming	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING			English	Article						data mining; classification; fuzzy linear programming; satisfying solution; credit card bankruptcy	MULTIPLE CRITERIA; MODELS; MULTICRITERIA; DUALITY	Behavior analysis of credit cardholders is one of the main research topics in credit card portfolio management. Usually, the cardholder's behavior, especially bankruptcy, is measured by a score of aggregate attributes that describe cardholder's spending history. In real-life practice, statistics and neural networks are the major players to calculate such a score system for prediction. Recently, various multiple linear programming-based classification methods have been promoted for analyzing credit cardholders' behaviors. As a continuation of this research direction, this paper proposes a heuristic classification method by using the fuzzy linear programming (FLP) to discover the bankruptcy patterns of credit cardholders. Instead of identifying a compromise solution for the separation of credit cardholder behaviors, this approach classifies the credit cardholder behaviors by seeking a fuzzy (satisfying) solution obtained from a fuzzy linear program.In this paper, a real-life credit database from a major US bank is used for empirical study which is compared with the results of known multiple linear programming approaches.	Univ Nebraska, Coll Informat Sci & Technol, Omaha, NE 68182 USA; Chinese Acad Sci, Acad Math & Syst Sci, Inst Syst Sci, Beijing 100080, Peoples R China; SW Petr Inst, Sch Business Adm, Chengdu 610500, Sichuan, Peoples R China; Chinese Acad Sci, Inst Policy & Management, Beijing 100080, Peoples R China; Univ Nebraska, Coll Informat Sci & Technol, Omaha, NE 68182 USA	Shi, Y (reprint author), Univ Nebraska, Coll Informat Sci & Technol, Omaha, NE 68182 USA.	hejing@amss.ac.cn; liuxiaotao11@sina.com; yshi@unomaha.edu; wxu@mail.casipm.ac.cn; nyan@mail.unomaha.edu					ALI H, 2002, BIOL CHARACTERISTIC; CHARNES A, 1961, MANAGEMENT MODELS IN, V1; Conover WJ, 1999, PRACTICAL NONPARAMET; FREED N, 1981, EUR J OPER RES, V7, P44, DOI 10.1016/0377-2217(81)90048-5; FREED N, 1986, DECISION SCI, V17, P151, DOI 10.1111/j.1540-5915.1986.tb00218.x; GLOVER F, 1990, DECISION SCI, V21, P771, DOI 10.1111/j.1540-5915.1990.tb01249.x; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; Han J., 2001, DATA MINING CONCEPTS; Kou G, 2003, OPTIM METHOD SOFTW, V18, P453, DOI 10.1080/10556780310001600953; KOU G, 2002, 68182 NE U NEBR COLL; Lee S.M, 1972, GOAL PROGRAMMING DEC; LEE TH, 2003, INT J INFORMATION TE, V2, P299, DOI 10.1142/S0219622003000665; LIN Y, 2002, INT J INFORMATION TE, V1, P153, DOI 10.1142/S0219622002000105; LINDSAY PH, 1972, HUMAN INFORMATION PR; LIU YH, 1994, FUZZY SET SYST, V65, P117, DOI 10.1016/0165-0114(94)90252-6; LIU YJ, 1995, J MATH ANAL APPL, V194, P389, DOI 10.1006/jmaa.1995.1307; OUELLETTE BFF, 1998, BIOINFORMATICS PRACT, P16; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rodder W., 1980, EXTREMAL METHODS SYS, P415; SCHWALB O, 2003, INT J INFORMATION TE, V2, P93, DOI 10.1142/S0219622003000513; SHI Y, 1989, MULTIPLE CRITERIA DE, P165; SHI Y, 1993, FUZZY SET SYST, V60, P163, DOI 10.1016/0165-0114(93)90344-H; Shi Y., 2001, MULTIPLE CRITERIA MU; SHI Y, 2001, MULTIPLE CRITERIA DE, P421; Shi Yong, 2002, INT J INFORM TECHNOL, V131, P145; YAN N, 2003, 68182 NE U NEBR COLL; YU PL, 1985, MULTIPLE CRITERIA DE; ZHENG J, 2003, P 36 ANN HAW INT C S; Zhong YH, 2002, FUZZY SET SYST, V132, P335, DOI 10.1016/S0165-0114(02)00116-1; Zimmermann H.-J., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90031-3	30	35	35	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-6220		INT J INF TECH DECIS	Int. J. Inf. Technol. Decis. Mak.	DEC	2004	3	4					633	650		10.1142/S021962200400129X		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	881DD	WOS:000225842700008	
J	Spiegler, I				Spiegler, I			Technology and knowledge: bridging a "generating" gap	INFORMATION & MANAGEMENT			English	Article						knowledge; technology; knowledge management; data mining; knowledge life cycle	MANAGEMENT	Refuting the notion of technology as a replacement of knowledge, this paper focuses on a gap between them that needs to be bridged. The idea is that technology represents the means, and knowledge the end of a process that includes many explicit and implicit methods for generating knowledge by using technology. Among these methods is data mining (DM), the leading thrust in the effort to gain actionable information from operational databases of organizations; this is particularly evident in direct marketing, customer relationship management (CRM), user profiling, and e-commerce applications. Two models of knowledge are reviewed. The first follows a conventional hierarchy of data, information and knowledge with a spiral and recursive way of generating knowledge. The other presents a reverse hierarchy where knowledge precedes the data-to-information process. The models are compared and discussed in the context of knowledge management (KM), using DM as an example. (C) 2002 Elsevier Science B.V. All rights reserved.	Tel Aviv Univ, Technol & Informat Syst Dept, Leon Recanati Grad Sch Business Adm, IL-69978 Tel Aviv, Israel	Spiegler, I (reprint author), Tel Aviv Univ, Technol & Informat Syst Dept, Leon Recanati Grad Sch Business Adm, IL-69978 Tel Aviv, Israel.		Wang, Charles/B-5565-2011				Alavi M, 2001, MIS QUART, V25, P107, DOI 10.2307/3250961; Bose I, 2001, INFORM MANAGE-AMSTER, V39, P211, DOI 10.1016/S0378-7206(01)00091-X; BOURDREAU A, 1999, INFORMATION SYST FAL, P24; CHEN L, 2000, INFORMATION SYST WIN, P65; Chung H. M., 1999, J MANAGE INFORM SYST, V16, P11; DAVENPORT TH, 1998, WORKING KNOWLEDGE; DAVIS S, 1994, HARVARD BUSINESS SEP; DREYFUS H, 1997, WHAT COMPUTERS STILL; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Holsapple CW, 2002, INFORM MANAGE-AMSTER, V39, P477, DOI 10.1016/S0378-7206(01)00109-4; KANTER J, 1999, INFORMATION SYST FAL, P7; Nonaka I, 1996, TECHNOL SOC, V18, P203, DOI 10.1016/0160-791X(96)00001-2; Nonaka I., 1995, KNOWLEDGE CREATING C; POLANYI M, 1962, PERSONAL KNOWLEDGE; RAMAKRISHNAN N, 1999, IEEE COMPUTER    AUG; SHANON CE, 1962, MATH THEORY COMMUNIC; SPIEGLER I, 1995, IEEE T SYST MAN CYB, V25, P1121, DOI 10.1109/21.391292; Spiegler I., 2000, COMMUNICATIONS AIS, V3, P1; Tuomi I, 1999, J MANAGE INFORM SYST, V16, P103; VAIL EF, 1999, INFORMATION SYST FAL, P16; WEBBER AM, 1993, HARVARD BUSINESS JAN; WINOGRAD T, 1997, CALCULATIONS NEXT 50; *ACM, 1971, CODASYL FEAT AN GEN	23	35	37	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-7206		INFORM MANAGE-AMSTER	Inf. Manage.	JUL	2003	40	6					533	539		10.1016/S0378-7206(02)00069-1		7	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	683RL	WOS:000183163300005	
J	Wang, Y; Wong, AKC				Wang, Y; Wong, AKC			From association to classification: Inference using weight of evidence	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						classification; data mining; event association; pattern discovery; weight of evidence		Association and classification are two important tasks in data mining and knowledge discovery. Intensive studies have been carried out in both areas. But, how to apply discovered event associations to classification is still seldom found in current publications. Trying to bridge this gap, this paper extends our previous paper on significant event association discovery to classification. We propose to use weight of evidence to evaluate the evidence of a significant event association in support of, or against, a certain class membership. Traditional weight of evidence in information theory is extended here to measure the event associations of different orders with respect to, a certain class. After the discovery of significant event associations inherent in a data set, it is easy and efficient to apply the weight of evidence measure for classifying an observation according to any attribute. With this approach, we achieve flexible prediction.	Pattern Discovery Software Syst Ltd, Waterloo, ON N2L 5V4, Canada; Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada	Wang, Y (reprint author), Pattern Discovery Software Syst Ltd, 550 Parkside Dr,Unit B9, Waterloo, ON N2L 5V4, Canada.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; BAYARDO RJ, 1997, P 3 INT C KNOWL DISC, P115; Breiman L, 1984, CLASSIFICATION REGRE; Brin S., 1997, P ACM SIGMOD INT C M, P265, DOI 10.1145/253260.253327; Chan K. C. C., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00129.x; FISHER DH, 1989, P 11 INT JOINT C ART, V1, P788; IBA W, 1988, P 5 INT C MACH LEARN, P73; Liu B, 1998, P 4 INT C KNOWL DISC, P80; MURPH PM, 1991, UCI REPOSITORY MACHI; OSTEYEE DB, 1974, INFORMATION WEIGHT E; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1992, C4 5 PROGRAM MACHINE; SCHLIMMER JC, 1987, THESIS U CALIFORNIA; Wong AKC, 1997, IEEE T KNOWL DATA EN, V9, P877, DOI 10.1109/69.649314	16	35	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY-JUN	2003	15	3					764	767				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	674PG	WOS:000182644700020	
J	Leigh, W; Modani, N; Purvis, R; Roberts, T				Leigh, W; Modani, N; Purvis, R; Roberts, T			Stock market trading rule discovery using technical charting heuristics	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						stock market; technical analysis; financial expert system	KNOWLEDGE	In this case study in knowledge engineering and data mining, we implement a recognizer for two variations of the 'bull flag' technical charting heuristic and use this recognizer to discover trading rules on the NYSE Composite Index. Out-of-sample results indicate that these rules are effective. (C) 2002 Elsevier Science Ltd. All rights reserved.	Univ Cent Florida, Coll Business Adm, Dept Management Informat Syst, Orlando, FL 32816 USA; Univ Cent Florida, Coll Business Adm, Dept Finance, Orlando, FL 32816 USA; Clemson Univ, Coll Business & Publ Affairs, Dept Management, Clemson, SC 29634 USA; Univ Kansas, Sch Business, Dept Accounting & Informat Syst, Lawrence, KS 66045 USA	Leigh, W (reprint author), Univ Cent Florida, Coll Business Adm, Dept Management Informat Syst, POB 161400, Orlando, FL 32816 USA.						ARMSTRONG JS, 1993, J FORECASTING, V12, P103; DOWNES J, 1998, DICT FINANCE INVESTM; Duda R., 1973, PATTERN CLASSIFICATI; EDWARDS R., 1997, TECHNICAL ANAL STOCK; Gencay R., 1998, J EMPIR FINANC, V5, P347, DOI 10.1016/S0927-5398(97)00022-4; Haugen R. A., 1997, MODERN INVESTMENT TH; Kim KJ, 2001, EXPERT SYST, V18, P194, DOI 10.1111/1468-0394.00174; Kohara K., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<11::AID-ISAF115>3.3.CO;2-V; Koopmans TC, 1947, REV ECON STATISTICS, V29, P161, DOI 10.2307/1928627; Last M, 2001, IEEE T SYST MAN CY B, V31, P160, DOI 10.1109/3477.907576; Lee KC, 1995, EXPERT SYST, V12, P331, DOI 10.1111/j.1468-0394.1995.tb00270.x; MARTINELLI R, 1998, TECHNICAL ANAL STOCK, V16, P63; Poh K. L., 2000, Knowledge and Information Systems, V2, DOI 10.1007/PL00011646; ROBERTS T, 1995, BOUNDED RATIONALITY; SAMUELSON PA, 1965, IMR-IND MANAG REV, V6, P41; Skouras S, 2001, J ECON DYN CONTROL, V25, P213, DOI 10.1016/S0165-1889(99)00074-3; WANG Y, 2001, EXPERT SYSTEMS APPL, V22, P33	17	35	37	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2002	23	2					155	159		10.1016/S0957-4174(02)00034-9		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	585WG	WOS:000177547100007	
J	Cody, WF; Kreulen, JT; Krishna, V; Spangler, WS				Cody, WF; Kreulen, JT; Krishna, V; Spangler, WS			The integration of business intelligence and knowledge management	IBM SYSTEMS JOURNAL			English	Article							SYSTEM	Enterprise executives understand that timely, accurate knowledge can mean improved business performance. Two technologies have been central in improving the quantitative and qualitative value of the knowledge available to decision makers: business intelligence and knowledge management. Business intelligence has applied the functionality, scalability, and reliability of modern database management systems to build ever-larger data warehouses, and to utilize data mining techniques to extract business advantage from the vast amount of available enterprise data. Knowledge management technologies, while less mature than business intelligence technologies, are now capable of combining today's content management systems and the Web with vastly improved searching and text mining capabilities to derive more value from the explosion of textual information. We believe that these systems will blend over time, borrowing techniques from each other and inspiring new approaches that can analyze data and text together, seamlessly. We call this blended technology BIKM. In this paper, we describe some of the current business problems that require analysis of both text and data, and some of the technical challenges posed by these problems. We describe a particular approach based on an OLAP (on-line analytical processing) model enhanced with text analysis, and describe two tools that we have developed to explore this approach-eClassifier performs text analysis, and Sapient integrates data and text through an OLAP-style interaction model. Finally, we discuss some new research that we are pursuing to enhance this approach.	IBM Corp, Almaden Res Ctr, Div Res, San Jose, CA 95120 USA	Cody, WF (reprint author), IBM Corp, Almaden Res Ctr, Div Res, 650 Harry Rd, San Jose, CA 95120 USA.						DHILLON I, 1998, P 30 C INT COMP SCI; Duda R., 1973, PATTERN CLASSIFICATI; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HERNARDEZ M, 2001, P SPEC INT GROUP MAN; Kimball Ralph, 1996, DATA WAREHOUSE TOOLK; Kwok C., 2001, P 10 INT WORLD WID W; Nasukawa T, 2001, IBM SYST J, V40, P967; Pohs W, 2001, IBM SYST J, V40, P956; POHS W, 2001, PRACTICAL KNOWLEDGE; Rasmussen E., 1992, INFORMATION RETRIEVA, P419; Salton G., 1983, INTRO MODERN RETRIEV; SALTON G, 1988, INFORMATION PROCESSI, V4, P512; SARAWAGI S, 1998, P INT C EXT DAT TECH, P168; Sullivan D, 2001, DOCUMENT WAREHOUSING; VAITHYANATHAN S, MODEL BASED HIERARCH	15	35	36	IBM CORP	ARMONK	OLD ORCHARD RD, ARMONK, NY 10504 USA	0018-8670		IBM SYST J	IBM Syst. J.		2002	41	4					697	713				17	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	615AM	WOS:000179223700011	
J	Bohanec, M; Zupan, B; Rajkovic, V				Bohanec, M; Zupan, B; Rajkovic, V			Applications of qualitative multi-attribute decision models in health care	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article; Proceedings Paper	15th Medical Informatics Europe Conference (MIE 99)	AUG, 1999	LJUBLJANA, SLOVENIA	European Federat Med Informat, World Congress Med Informat, Int Med Informat Assoc		multi-attribute decision-making; decision support; hierarchical models; qualitative models		Hierarchical decision models are a general decision support methodology aimed at the classification or evaluation of options that occur in decision-making processes. They are also important for the analysis, simulation and explanation of options. Decision models are typically developed through the decomposition of complex decision problems into smaller and less complex subproblems; the result of such decomposition is a hierarchical structure that consists of attributes and utility functions. This article presents an approach to the development and application of qualitative hierarchical decision models that is based on DEX, an expert system shell for multi-attribute decision support. The distinguishing characteristics of DEX are the use of qualitative (symbolic) attributes, and 'if-then' decision rules. Also, DEX provides a number of methods for the analysis of models and options, such as selective explanation and what-if analysis. We demonstrate the applicability and flexibility of the approach presenting four real-life applications of DEX in health care: assessment of breast cancer risk, assessment of basic living activities in community nursing, risk assessment in diabetic foot care, acid technical analysis of radiogram errors. In particular, we highlight and justify the importance of knowledge presentation and option analysis methods for practical decision-making. We further show that, using a recently developed data mining method called HINT, such hierarchical decision models can be discovered from retrospective patient data. (C) 2000 Elsevier Science Ireland Ltd. All rights reserved.	Jozef Stefan Inst, SI-1000 Ljubljana, Slovenia; Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana, Slovenia; Univ Maribor, Fac Org Sci, SLO-2000 Maribor, Slovenia	Bohanec, M (reprint author), Jozef Stefan Inst, Jamova 39, SI-1000 Ljubljana, Slovenia.	marko.bohanec@ijs.si					Bohanec M., 1998, Context Sensitive Decision Support Systems. IFIP TC8/WG8.3 International Conference on Context-Sensitive Decision Support Systems; Bohanec M., 1999, Informatica, V23; Bohanec M., 1990, SISTEMICA, V1, P145; Chankong V., 1983, MULTIOBJECTIVE DECIS; Henderson V., 1997, BASIC PRINCIPLES NUR; Lavrac N, 1997, INTELLIGENT DATA ANA; Leskovar R, 1999, ST HEAL T, V68, P930; Lucas PJF, 1999, ARTIF INTELL MED, V15, P105, DOI 10.1016/S0933-3657(98)00047-5; Mingers J., 1989, Machine Learning, V3, DOI 10.1007/BF00116837; MORTENSEN RA, 1996, INT CLASSIFICATION N; NAGEL S, 1993, COMPUTER AIDED DECIS; Plaper G, 1999, ST HEAL T, V68, P970; PRIMICZAKELJ M, 1995, INT J CANCER, V62, P414, DOI 10.1002/ijc.2910620410; Quinlan R.J., 1993, C4 5 PROGRAMS MACHIN; RAJKOVIC V, 1991, DECISION SUPPORT KNO, P47; SIMON AH, 1977, NEW SCI MANAGEMENT D; SUSTERSIC O, 1998, 2 EUR TEL C SES; URBANCIC T, 1991, DP6218 I J STEF; Vincke P, 1992, MULTICRITERIA DECISI; Zupan B, 1999, ARTIF INTELL, V109, P211, DOI 10.1016/S0004-3702(99)00008-9; Zupan B, 1998, IEEE INTELL SYST APP, V13, P38, DOI 10.1109/5254.671090; Zupan B, 1997, KLUWER INT SER ENG C, V414, P261; ZUPAN B, UNPUB PREDICTING PAT	23	35	35	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056		INT J MED INFORM	Int. J. Med. Inform.	SEP	2000	58				SI		191	205		10.1016/S1386-5056(00)00087-3		15	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	351RG	WOS:000089171500019	
J	Xu, XW; Jager, J; Kriegel, HP				Xu, XW; Jager, J; Kriegel, HP			A fast parallel clustering algorithm for large spatial databases	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						clustering algorithms; parallel algorithms; distributed algorithms; scalable data mining; distributed index structures; spatial databases		The clustering algorithm DBSCAN relies on a density-based notion of clusters and is designed to discover clusters of arbitrary shape as well as to distinguish noise. In this paper, we present PDBSCAN, a parallel version of this algorithm. We use the 'shared-nothing' architecture with multiple computers interconnected through a network. A fundamental component of a shared-nothing system is its distributed data structure. We introduce the dR*-tree, a distributed spatial index structure in which the data is spread among multiple computers and the indexes of the data are replicated on every computer. We implemented our method using a number of workstations connected via Ethernet (10 Mbit). A performance evaluation shows that PDBSCAN offers nearly linear speedup and has excellent scaleup and sizeup behavior.	Siemens AG, D-81730 Munich, Germany; Univ Munich, Inst Comp Sci, D-80538 Munich, Germany	Xu, XW (reprint author), Siemens AG, Otto Hahn Ring 6, D-81730 Munich, Germany.	Xiaowei.Xu@mchp.siemens.de; jaeger@informatik.uni-muenchen.de; kriegel@informatik.uni-munchen.de					AGRAWAL R, 1996, PARALLEL MINING ASS; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; BIALLY T, 1969, IEEE T INFORM THEORY, V15, P658, DOI 10.1109/TIT.1969.1054385; CHEUNG DW, 1996, P INT C PAR DISTR IN; Ester M., 1995, P 1 INT C KNOWL DISC, P94; Ester M, 1996, P 2 INT C KNOWL DISC, P226; Faloutsos C., 1989, Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, DOI 10.1145/73721.73746; GEIST A, 1996, PVM PARALLEL VIRTUAL; GUETING RH, 1994, VLDB J, V3, P357, DOI 10.1007/BF01231602; JAJA J, 1992, INTRO PARALLEL ALGOR, P61; Kamel I., 1993, P 2 INT C INF KNOWL; LI X, 1989, PARALLEL COMPUT, V11, P275, DOI 10.1016/0167-8191(89)90036-7; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; Mehta M., 1997, VLDB Journal, V6, DOI 10.1007/s007780050033; OLSON CF, 1995, PARALLEL COMPUT, V21, P1313, DOI 10.1016/0167-8191(95)00017-I; Park J. S., 1995, P ACM SIGMOD INT C M, P175, DOI 10.1145/223784.223813; PFITZNER DW, 1998, DATA MIN KNOWL DISC, V2, P419; RICHARDS AJ, 1983, REMOTE SENSING DIGIT; SANDER J, 1998, DENSITY BASED CLUSTE, V2, P1; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; Stonebraker M, 1993, P ACM SIGMOD INT C M, P2, DOI 10.1145/170035.170038; Stonebraker M., 1986, DATABASE ENG, V9; RASMUSSEN EM, 1989, J DOC, V45, P1, DOI 10.1108/eb026836; XU X, 1999, EFFICIENT CLUSTERING; XU XW, 1998, 14 INT C DAT ENG ICD; ZHANG T, 1998, BIRCH NEW DATA CLUST, P1	27	35	41	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	1999	3	3					263	290		10.1023/A:1009884809343		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	260RH	WOS:000083963300003	
J	Flach, PA; Savnik, I				Flach, PA; Savnik, I			Database dependency discovery: a machine learning approach	AI COMMUNICATIONS			English	Article						induction; attribute dependency; database reverse engineering; data mining	FUNCTIONAL-DEPENDENCIES	Database dependencies, such as functional and multivalued dependencies, express the presence of structure in database relations, that can be utilised in the database design process. The discovery of database dependencies can be viewed as an induction problem, in which general rules (dependencies) are obtained from specific facts (the relation). This viewpoint has the advantage of abstracting away as much as possible from the particulars of the dependencies. The algorithms in this paper are designed such that they can easily be generalised to other kinds of dependencies. Like in current approaches to computational induction such as inductive logic programming, we distinguish between top-down algorithms and bottom-up algorithms. In a top-down approach, hypotheses are generated in a systematic way and then tested against the given relation. In a bottom-up approach, the relation is inspected in order to see what dependencies it may satisfy or violate. We give a simple (but inefficient) top-down algorithm, a bi-directional algorithm, and a bottom-up algorithm. In the case of functional dependencies, these algorithms have been implemented in the FDEP system and evaluated experimentally. The bottom-up algorithm is the most efficient of the three, and also outperforms other algorithms from the literature.	Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England; Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia	Flach, PA (reprint author), Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.						Beeri C., 1980, ACM Transactions on Database Systems, V5, DOI 10.1145/320613.320614; De Raedt L., 1996, ADV INDUCTIVE LOGIC; DeRaedt L, 1997, ARTIF INTELL, V95, P187, DOI 10.1016/S0004-3702(97)00041-6; DIETTERICH T, 1982, HDB ARTIFICIAL INTEL, V3; FAGIN R, 1982, J ACM, V29, P952, DOI 10.1145/322344.322347; Flach P, 1993, LECT NOTES ARTIF INT, P83; FLACH PA, P 5 INT S METH INT S, P371; FLACH PA, 1997, LECT NOTES ARTIF INT, V1297, P149; FLACH PA, 1995, THESIS TILBURG U; GALLAIRE H, 1984, COMPUT SURV, V16, P153; GOTTLOB G, 1987, INFORM PROCESS LETT, V24, P109, DOI 10.1016/0020-0190(87)90103-7; Gottlob G., 1990, Acta Cybernetica, V9; HUHTALA Y, 1997, C199779 U HELS DEP C; KANTOLA M, 1992, INT J INTELL SYST, V7, P591, DOI 10.1002/int.4550070703; KIVINEN J, 1995, THEOR COMPUT SCI, V149, P129, DOI 10.1016/0304-3975(95)00028-U; LOVELAND DW, 1998, HDB LOGIC ARTIFICIAL, V5, P163; Maier D., 1983, THEORY RELATIONAL DA; Mannila H., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; MANNILA H, 1996, P CYB SYST 96, P973; MANNILA H, 1997, C19978 U HELS DEP CO; Mannila H., 1992, DESIGN RELATIONAL DA; MANNILA H, 1994, DATA KNOWL ENG, V12, P83, DOI 10.1016/0169-023X(94)90023-X; Merz C. J., 1996, UCI REPOSITORY MACHI; MUGGLETON S., 1992, INDUCTIVE LOGIC PROG; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; Plotkin G., 1971, MACH INTELL, V6, P101; Plotkin G.D., 1970, MACH INTELL, V5, P153; Reiter R., 1984, CONCEPTUAL MODELLING, P191; SAVNIK I, 1993, 6681 IJS J STEF I; Savnik I., 1993, P AAAI 93 WORKSH KNO, P174; SAVNIK I, UNPUB DISCOVERY MULT; Ullman J. D., 1988, PRINCIPLES DATABASE, VI	32	35	36	IOS PRESS	AMSTERDAM	VAN DIEMENSTRAAT 94, 1013 CN AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		1999	12	3					139	160				22	Computer Science, Artificial Intelligence	Computer Science	261HP	WOS:000084004000002	
S	Keogh, EJ; Pazzani, MJ		Zytkow, JM; Rauch, J		Keogh, EJ; Pazzani, MJ			Scaling up dynamic time warping to massive dataset	PRINCIPLES OF DATA MINING AND KNOWLEDGE DISCOVERY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	3rd European Conference on Principles of Data Mining and Knowledge Discovery in Databases (PKDD 99)	SEP 15-18, 1999	PRAGUE, CZECH REPUBLIC	Komercni Banka	UNIV ECON, LAB INTELLIGENT SYST			There has been much recent interest in adapting data mining algorithms t time series databases. Many of these algorithms need to compare time series Typically some variation or extension of Euclidean distance is used. However, as w demonstrate in this paper, Euclidean distance can be an extremely brittle distance measure. Dynamic time warping (DTW) has been suggested as a technique to allow more robust distance calculations, however it is computationally expensive. In thi paper we introduce a modification of DTW which operates on a higher level abstraction of the data, in particular, a piecewise linear representation. We demonstrate that our approach allows us to outperform DTW by one to three orders o magnitude. We experimentally evaluate our approach on medical, astronomical and sign language data.	Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA	Keogh, EJ (reprint author), Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA.						Agrawal R., 1995, VLDB; BAY S, 1999, UCI REPOSITORY KDD D; Berndt D, 1994, AAAI 94 WORKSH KNOWL; CAIANI EG, 1998, IEEE COMPUTERS CARDI, V25; Das G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Debregeas A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DERRIERE S, 1998, DENLS STRIP 3792; FALOUTSOS C, 1994, P ACM SIGMOD C MINN; GAVRRILA K, 1995, DETECTION DISTORTED; HAGIT S, 1996, P 12 IEEE INT C DAT, P546; Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; KEOGH E, 1999, IN PRESS P 11 INT C; Keogh E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Kruskall J. B., 1983, TIME WARPS STRING ED; PAVLIDIS T, 1974, IEEE T COMPUTER C, V23; Rabiner L., 1993, FUNDAMENTALS SPEECH; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Schmill M, 1999, 7 INT WORKSH ART INT	18	35	39	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-66490-4	LECT NOTES ARTIF INT			1999	1704						1	11				11	Computer Science, Artificial Intelligence	Computer Science	BS61Q	WOS:000170570600001	
J	Duan, L; Street, WN; Xu, E				Duan, L.; Street, W. N.; Xu, E.			Healthcare information systems: data mining methods in the creation of a clinical recommender system	ENTERPRISE INFORMATION SYSTEMS			English	Article						nursing care plan; recommender system; data mining; correlation; information value; medical informatics; healthcare integrated information systems; healthcare enterprise-wide systems	DECISION-SUPPORT-SYSTEM; INTERVENTION; PREVENTION; RESILIENCE; AIDS	Recommender systems have been extensively studied to present items, such as movies, music and books that are likely of interest to the user. Researchers have indicated that integrated medical information systems are becoming an essential part of the modern healthcare systems. Such systems have evolved to an integrated enterprise-wide system. In particular, such systems are considered as a type of enterprise information systems or ERP system addressing healthcare industry sector needs. As part of efforts, nursing care plan recommender systems can provide clinical decision support, nursing education, clinical quality control, and serve as a complement to existing practice guidelines. We propose to use correlations among nursing diagnoses, outcomes and interventions to create a recommender system for constructing nursing care plans. In the current study, we used nursing diagnosis data to develop the methodology. Our system utilises a prefix-tree structure common in itemset mining to construct a ranked list of suggested care plan items based on previously-entered items. Unlike common commercial systems, our system makes sequential recommendations based on user interaction, modifying a ranked list of suggested items at each step in care plan construction. We rank items based on traditional association-rule measures such as support and confidence, as well as a novel measure that anticipates which selections might improve the quality of future rankings. Since the multi-step nature of our recommendations presents problems for traditional evaluation measures, we also present a new evaluation method based on average ranking position and use it to test the effectiveness of different recommendation strategies.	[Duan, L.; Street, W. N.] Univ Iowa, Henry B Tippie Coll Business, Dept Management Sci, Iowa City, IA 52242 USA; [Xu, E.] Univ Calif Berkeley, Coll Nat Resources, Berkeley, CA 94720 USA; [Xu, E.] Univ Virginia, Coll Arts & Sci, Charlottesville, VA 22904 USA	Duan, L (reprint author), Univ Iowa, Henry B Tippie Coll Business, Dept Management Sci, Iowa City, IA 52242 USA.	lian-duan@uiowa.edu					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Bellika JG, 2005, INT J MED INFORM, V74, P587, DOI 10.1016/j.ijmedinf.2005.06.001; Billsus D, 2002, COMMUN ACM, V45, P34; Borgelt C., 2003, P IEEE ICDM WORKSH F, P90; Dochterman J.M., 2003, NURS INT CLASS; Erol O, 2010, ENTERP INF SYST-UK, V4, P111, DOI 10.1080/17517570903474304; Han J., 2005, DATA MINING CONCEPTS; Hardiker NR, 2002, J BIOMED INFORM, V35, P298, DOI 10.1016/S1532-0464(03)00002-9; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; HILL W, 1995, CHI 95 C P HUM FACT, P194; Iglesias A., 2003, ERR IS HUMAN BUILDIN, V5; Kakousis K, 2010, ENTERP INF SYST-UK, V4, P355, DOI 10.1080/17517575.2010.509814; Keenan G.M., 2006, 9 INT C NURS INF SEO, P580; Koren Y., 2008, RECSYS 08, P333; Li L, 2008, INFORM SYST FRONT, V10, P531, DOI 10.1007/s10796-008-9108-1; LI LX, 1991, INT J BIOMED COMPUT, V29, P191, DOI 10.1016/0020-7101(91)90037-F; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; Luo J, 2007, ENTERP INFORM SYST, V1, P49, DOI 10.1080/17517570601092184; MacKinnon W., 2009, SYSTEM SCI 2009, P1; McNee S.M., 2006, CHI 06, P1097, DOI DOI 10.1145/1125451.1125659; Miller BM, 2003, IFAC WORK S, P263; Moorhead S., 2005, NURSING OUTCOMES CLA; Nanda, 2005, NANDA NURSING DIAGNO; Puustjarvi Juha, 2010, Proceedings 6th International Conference on Web Information Systems and Technologies, WEBIST 2010; Resnick P, 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Ryan S A, 1985, J Med Syst, V9, P29, DOI 10.1007/BF00992520; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Wang JW, 2010, ENTERP INFORM SYST, V4, P215, DOI 10.1080/17517571003754561; XU LD, 1994, INT J BIOMED COMPUT, V36, P281, DOI 10.1016/0020-7101(94)90082-5; Yoo SK, 2008, 7TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE IN CONJUNCTION WITH 2ND IEEE/ACIS INTERNATIONAL WORKSHOP ON E-ACTIVITY, PROCEEDINGS, P255, DOI 10.1109/ICIS.2008.12	32	34	34	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1751-7575		ENTERP INF SYST-UK	Enterp. Inf. Syst.		2011	5	2					169	181		10.1080/17517575.2010.541287		13	Computer Science, Information Systems	Computer Science	750TC	WOS:000289569900001	
J	Tasdemir, K; Merenyi, E				Tasdemir, Kadim; Merenyi, Erzsebet			Exploiting Data Topology in Visualization and Clustering Self-Organizing Maps	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Clustering; data mining; self-organizing map (SOM); topology preservation; visualization	DATA PROJECTION; NETWORKS	The self-organizing map (SOM) is a powerful method for visualization, cluster extraction, and data mining. It has been used successfully for data of high dimensionality and complexity where traditional methods may often be insufficient. In order to analyze data structure and capture cluster boundaries from the SOM, one common approach is to represent the SOM's knowledge by visualization methods. Different aspects of the information learned by the SOM are presented by existing methods, but data topology, which is present in the SOM's knowledge, is greatly underutilized. We show in this paper that data topology can be integrated into the visualization of the SOM and thereby provide a more elaborate view of the cluster structure than existing schemes. We achieve this by introducing a weighted Delaunay triangulation (a connectivity matrix) and draping it over the SOM. This new visualization, CONNvis, also shows both forward and backward topology violations along with the severity of forward ones, which indicate the quality of the SOM learning and the data complexity. CONNvis greatly assists in detailed identification of cluster boundaries. We demonstrate the capabilities on synthetic data sets and on a real 8-D remote sensing spectral image.	[Tasdemir, Kadim; Merenyi, Erzsebet] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA	Tasdemir, K (reprint author), Yasar Univ, Dept Comp Engn, TR-35100 Izmir, Turkey.	kadim.tasdemir@yasar.edu.tr; erzsebet@rice.edu					Aupetit M., 2006, ADV NEURAL INFORM PR, V18, P83; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Blackmore J., 1995, P 12 INT C MACH LEAR, P55; Cottrell M., 1996, P 4 EUR S ART NEUR N, P103; CSATHO B, 1998, INT ARCH PHOTOGRAMM, P26; Dougherty J, 1995, P 12 INT C MACH LEAR, P194; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; HAKKINEN E, 1997, P 1 WORKSH SELF ORG, P69; HIMBERG J, 2000, INT J C NEUR NETWKS, V3, P587; KASKI S, 1998, VISUAL EXPLORATIONS; Kaski S., 2000, Australian Journal of Intelligent Information Processing Systems, V6; Kohonen T., 1997, SELF ORG MAPS; KRAAIJVELD MA, 1995, IEEE T NEURAL NETWOR, V6, P548, DOI 10.1109/72.377962; Marsland S, 2002, NEURAL NETWORKS, V15, P1041, DOI 10.1016/S0893-6080(02)00078-3; MARTINETZ T, 1994, NEURAL NETWORKS, V7, P507, DOI 10.1016/0893-6080(94)90109-0; Merenyi E, 2007, IEEE T NEURAL NETWOR, V18, P786, DOI 10.1109/TNN.2007.895833; Merenyi E., 2000, STUDIES FUZZINESS SO, V54; Merkl D., 1997, P WORKSH SELF ORG MA, P106; PAMPALK E, 2002, P INT C ART NEUR NET, P871; Polzlbauer G., 2005, P 2 INT S NEUR NETW, P75; Ressom H, 2003, NEURAL NETWORKS, V16, P633, DOI 10.1016/S0893-6080(03)00102-3; Su MC, 2001, IEEE T NEURAL NETWOR, V12, P153, DOI 10.1109/72.896805; Tenenbaum J. B., 2000, SCIENCE, V290, P5500; Ultsch A., 1993, INFORM CLASSIFICATIO, P307; Ultsch A., 2003, P 4 WORKSH SELF ORG, V3, P225; Venna J, 2001, LECT NOTES COMPUT SC, V2130, P485; Vesanto J., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00013-X; Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731; Villmann T, 2001, SELF ORG MAPS RECENT, P121; Yin HJ, 2002, IEEE T NEURAL NETWOR, V13, P237, DOI 10.1109/72.977314	30	34	34	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	APR	2009	20	4					549	562		10.1109/TNN.2008.2005409		14	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	435XI	WOS:000265376200001	
J	Peng, Y; Kou, G; Shi, Y; Chen, ZX				Peng, Yi; Kou, Gang; Shi, Yong; Chen, Zhengxin			A Multi-criteria Convex Quadratic Programming model for credit data analysis	DECISION SUPPORT SYSTEMS			English	Article						data mining; classification; mathematical programming; multiple criteria decision making; multi-criteria convex quadric programming (MCQP)	SUPPORT VECTOR MACHINES; CLASSIFICATION; SEPARATION; BEHAVIOR	Speed and scalability are two essential issues in data mining and knowledge discovery. This paper proposed a mathematical programming model that addresses these two issues and applied the model to Credit Classification Problems. The proposed Multicriteria Convex Quadric Programming (MCQP) model is highly efficient (computing time complexity O(n(1.5-2))) and scalable to massive problems (size of O(10(9))) because it only needs to solve linear equations to find the global optimal solution. Kernel functions were introduced to the model to solve nonlinear problems. In addition, the theoretical relationship between the proposed MCQP model and SVM was discussed. (c) 2007 Elsevier B.V. All rights reserved.	[Peng, Yi] Univ Elect Sci & Technol China, Sch Management & Econ, Chengdu 610054, Peoples R China; [Kou, Gang] Thomson Corp R&D, Eagan, MN 55123 USA; [Peng, Yi; Kou, Gang; Shi, Yong; Chen, Zhengxin] Univ Nebraska, Coll Informat Sci & Technol, Omaha, NE 68182 USA; [Shi, Yong] CAS Res Ctr Fictitious Econ & Data Sci, Beijing 100080, Peoples R China	Kou, G (reprint author), Univ Nebraska, Coll Informat Sci & Technol, Omaha, NE 68182 USA.	kougang@yahoo.com					Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Bradley PS, 1999, INFORMS J COMPUT, V11, P217, DOI 10.1287/ijoc.11.3.217; BURGES CJC, 1998, KNOWLEDGE DISCOVERY, V2, P121; Caruana R., 2004, P 10 ACM SIGKDD INT, P69, DOI 10.1145/1014052.1014063; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cristianini N., 2000, INTRO SUPPORT VECTOR; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FREED N, 1981, EUR J OPER RES, V7, P44, DOI 10.1016/0377-2217(81)90048-5; FUNG G, 2003, THESIS U WISCONSIN; Fung G., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347105; Fung G., 2002, J MACHINE LEARNING R, V3, P303; Fung GM, 2005, MACH LEARN, V59, P77, DOI 10.1007/s10994-005-0463-6; Golub G.H., 1989, MATRIX COMPUTATIONS; Hand D. J., 1981, DISCRIMINATION CLASS; JOAHIMS T, 2002, LEARNING CLASSIFY TE; JOAHIMS T, 2004, SVMLIGHT SUPPORT VEC; JOAHIMS T, 1999, ADV KERNEL METHODS S; KOLESAR P, 1985, MANAGE SCI, V31, P123, DOI 10.1287/mnsc.31.2.123; Kou G, 2006, LECT NOTES COMPUT SC, V3994, P476; Kou G, 2005, ANN OPER RES, V135, P261, DOI 10.1007/s10479-005-6245-5; Kwak W., 2006, International Journal of Business Intelligence and Data Mining, V1, DOI 10.1504/IJBIDM.2006.010782; Mangasarian OL, 1999, IEEE T NEURAL NETWOR, V10, P1032, DOI 10.1109/72.788643; Mangasarian OL, 2000, ADV NEUR IN, P135; Mangasarian OL, 2004, J MACH LEARN RES, V5, P1127; Mangasarian OL, 2005, OPTIM METHOD SOFTW, V20, P115, DOI 10.1080/10556780410001715117; MANGASAR.OL, 1968, IEEE T INFORM THEORY, V14, P801, DOI 10.1109/TIT.1968.1054229; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; Murphy PM, 1992, UCI REPOSITORY MACHI; Musicant DR, 1998, NDC NORMALLY DISTRIB; Olson D., 2005, INTRO BUSINESS DATA; Peng Y, 2004, LECT NOTES COMPUT SC, V3039, P931; Peng Y, 2005, LECT NOTES COMPUT SC, V3516, P548; QUINLAN J, 2004, SEE 5 0; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; ROSENBERG E, 1994, OPER RES, V42, P589, DOI 10.1287/opre.42.4.589; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Scholkopf B, 1999, ADV KERNEL METHODS S; SCHOLKOPF B, 1996, SPRINGER LECT NOTES, V1112, P47; Scholkopf B., 2002, LEARNING KEMELS; SHI Y, 2005, TECHNOLOGY DECISION, V4, P1; SHI Y, 2001, MULTICRITERIA MULTIC; SHOWERS JL, 1981, INTERFACES, V11, P21, DOI 10.1287/inte.11.6.21; TONY VG, 2006, DECIS SUPPORT SYST, V42, P1131; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; Vapnik V.N., 1963, Avtomatika i Telemekhanika, V24; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V. N., 2000, NATURE STAT LEARNING; Vapnik V. N., 1964, AUTOMAT REM CONTROL, V25, P821; Vapnik V.N., 1995, NATURE STAT LEARNING; Wolfe P., 1961, Q APPL MATH, V19, P239; Zhao HM, 2007, DECIS SUPPORT SYST, V43, P809, DOI 10.1016/j.dss.2006.12.011; Zheng JL, 2004, NEUROINFORMATICS, V2, P303, DOI 10.1385/NI:2:3:303; [Anonymous], 2001, SPSS WIND REL 11 0 1	53	34	34	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	MAR	2008	44	4					1016	1030		10.1016/j.dss.2007.12.001		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	270WF	WOS:000253750200018	
J	El-Arroudi, K; Joos, G; Kamwa, I; McGillis, DT				El-Arroudi, Khalil; Joos, Geza; Kamwa, Innocent; McGillis, Donald T.			Intelligent-based approach to islanding detection in distributed generation	IEEE TRANSACTIONS ON POWER DELIVERY			English	Article						artificial intelligence; data mining; distributed generation; power system protection; power systems	METHODOLOGY; RELAYS	This paper introduces a new intelligent-based approach for detecting islanding in distributed generation (DG). This approach utilizes and combines various system parameter indices in order to secure the detection of islanding for any possible network topology, penetration level and operating condition of the DG under study. Hence, every parameter index displays characteristics for a given set of events. The proposed technique uses the data-mining technology to extract information from the large data sets of these indices after they are screened off-line via massive event analyses using network simulations. The technique is tested on a typical DG with multiple distributed resources and the results indicate that this technique can successfully detect islanding operations. In addition, this technique can also overcome the problem of setting the detection thresholds inherent in the existing techniques by optimizing their settings.	McGill Univ, Dept Elect & Comp Engn, Montreal, PQ H3A 2A7, Canada; Inst Rech Hydro Quebec, Varennes, PQ J3X 1S1, Canada	El-Arroudi, K (reprint author), McGill Univ, Dept Elect & Comp Engn, Montreal, PQ H3A 2A7, Canada.	khalil.elarroudi@mail.mcgill.ca; geza.joos@mcgill.ca; kamwa.innocent@ireq.ca; donmcgillis@videotron.ca					Affonso CM, 2005, IEE P-GENER TRANSM D, V152, P109, DOI 10.1049/ip-gtd:20041079; El-Arroudi K, 2003, P INT C POW SYST TRA; Ernst D, 2004, IEEE T POWER SYST, V19, P427, DOI 10.1109/TPWRS.2003.821457; Freitas W, 2005, IEEE T POWER DELIVER, V20, P57, DOI 10.1109/TPWRD.2004.838637; Funabashi T., 2003, P IEEE BOL POW TECH, V2, P23; HARTMANN WG, 2003, P IEEE RUR EL POW C; HUANG JA, 2005, CIGRE, P1; Hung GK, 2003, IEEE T ENERGY CONVER, V18, P169, DOI 10.1109/TEC.2002.808412; OGARMAN R, 2003, P IEEE POW ENG SOC S, V3, P1466; REDFERN MA, 1995, IEEE T POWER DELIVER, V10, P1249, DOI 10.1109/61.400903; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; Salman S.K., 2001, P DEV POW SYST PROT, P82; Sheng Y, 2004, IEEE T POWER DELIVER, V19, P533, DOI 10.1109/TPWRD.2003.820418; Sumner M, 2002, IEEE T POWER ELECTR, V17, P207, DOI 10.1109/63.988831; Villenueve P. L., 2004, IEEE Power & Energy Magazine, V2, DOI 10.1109/MPAE.2004.1293600; WALLERSTEIN I, 1992, THEOR SOC, V21, P1, DOI 10.1007/BF00993461; Wehenkel L, 1997, IEEE EXPERT, V12, P60, DOI 10.1109/64.621229; Yin Jun, 2004, P LARG ENG SYST C PO, P124; 2005, CART USERS MANUAL	19	34	37	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0885-8977		IEEE T POWER DELIVER	IEEE Trans. Power Deliv.	APR	2007	22	2					828	835		10.1109/TPWRD.2007.893592		8	Engineering, Electrical & Electronic	Engineering	155TA	WOS:000245599900011	
J	Bandyopadhyay, S; Giannella, C; Maulik, U; Kargupta, H; Liu, K; Datta, S				Bandyopadhyay, S; Giannella, C; Maulik, U; Kargupta, H; Liu, K; Datta, S			Clustering distributed data streams in peer-to-peer environments	INFORMATION SCIENCES			English	Article						data mining; data streams; cluster analysis; peer-to-peer	WIRELESS SENSOR NETWORKS; ALGORITHMS	This paper describes a technique for clustering homogeneously distributed data in a peer-to-peer environment like sensor networks. The proposed technique is based on the principles of the K-Means algorithm. It works in a localized asynchronous manner by communicating with the neighboring nodes. The paper offers extensive theoretical analysis of the algorithm that bounds the error in the distributed clustering process compared to the centralized approach that requires downloading all the observed data to a single site. Experimental results show that, in contrast to the case when all the data is transmitted to a central location for application of the conventional clustering algorithm, the communication cost (an important consideration in sensor networks which are typically equipped with limited battery power) of the proposed approach significantly smaller. At the same time, the accuracy of the obtained centroids is high and the number of samples which are incorrectly labeled is also small. (C) 2005 Elsevier Inc. All rights reserved.	Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA	Kargupta, H (reprint author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, 1000 Hilltop Circle, Baltimore, MD 21250 USA.	sanghami@isical.ac.in; hillol@cs.umbc.edu					Aggarwal C., 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1; Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4; Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422; BABCOCK B, 2003, ACM SIGMOD PRINC DAT; Cerpa A., 2002, P 21 INT ANN JOINT C; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Chen WP, 2004, IEEE T MOBILE COMPUT, V3, P258; Cochran W.G., 1977, SAMPLING TECHNIQUES; Dhillon I., 1999, P KDD 99 WORKSH HIGH, P245; Domingos P., 2001, P 7 INT C KNOWL DISC, P97; DOMINGOS P, 2001, P 6 INT C KNOWL DISC, P71; Domingos P, 2001, P 18 INT C MACH LEAR, P106; EISENHARDT M, 2003, GI LECT NOTES INFORM; Estrin D., 1999, P 5 ANN ACM IEEE INT, P263, DOI DOI 10.1145/313451.313556; ESTRIN D, 1999, 99692 U SO CAL; Forman G, 2000, SIGKDD EXPLORATIONS, V2, P34; Fred A. L. N., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1047450; GHARAVI H, 2003, P IEEE SPECIAL ISSUE, V91; Ghiasi S, 2002, SENSORS, V2, P258, DOI 10.3390/s20700258; Guha S, 2000, P ANN S FDN COMP SCI; Han J., 2000, DATA MINING CONCEPTS; Heinzelman W., 2000, P HAW C SYST SCI JAN; Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190; Hill J., 2000, INT C ARCH SUPP PROG; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Intanagonwiwat C., 2000, P 6 ANN INT C MOB CO, P56, DOI DOI 10.1145/345910.345920; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Januzaj E, 2004, LECT NOTES COMPUT SC, V2992, P88; Jelasity M, 2003, P 15 BELG DUTCH C AR, P203; Johnson E., 1999, LECT NOTES COMPUTER, V1759, P221; Kargupta H., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011677; JOUVE P, 2003, P WORKSH PAR DISTR C; KARGUPTA H, 2004, P 2004 SIAM INT C DA; Keogh E., 2003, P 3 IEEE INT C DAT M, P115; Klusch M., 2003, P JOINT INT C AI IJC; Krishnamachari B, 2004, IEEE T COMPUT, V53, P241, DOI 10.1109/TC.2004.1261832; LAZAREVIC A, 2000, P 8 EUR S ART NEUR N, P129; LIN J, 2004, P 9 C EXT DAT TECHN; Lindsey S, 2002, IEEE T PARALL DISTR, V13, P924, DOI 10.1109/TPDS.2002.1036066; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Mainwaring A., 2002, ACM INT WORKSH WIR S; MERUGU S, 2003, P IEEE C DAT MIN ICD; Palpanas T, 2003, SIGMOD REC, V32, P77; Pottie G.J., 2000, COMMUN ACM, V43, P551; RADIVOJAC P, 2003, 58 IEEE SEM C VEH TE, V5, P3030; Samatova NF, 2002, DISTRIB PARALLEL DAT, V11, P157; SINHA A, 2000, P INT S LOW POW EL D; Sohrabi K, 2000, IEEE PERS COMMUN, V7, P16, DOI 10.1109/98.878532; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Tou J.T., 1974, PATTERN RECOGNITION; WOLFF R, 2004, IEEE T SYST MAN CY B; Younis Ossama, 2004, IEEE T MOBILE COMPUT, V3; Zhao F, 2003, P IEEE, V91, P1199, DOI 10.1109/JPROC.2003.814921	54	34	37	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JUL 22	2006	176	14					1952	1985		10.1016/j.ins.2005.11.007		34	Computer Science, Information Systems	Computer Science	050RI	WOS:000238105200002	
J	Kargupta, H; Datta, S; Wang, Q; Sivakumar, K				Kargupta, H; Datta, S; Wang, Q; Sivakumar, K			Random-data perturbation techniques and privacy-preserving data mining	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article; Proceedings Paper	3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	MELBOURNE, FL	IEEE Comp Soc TCCI, IEEE Comp Soc TCPAMI		data mining; privacy; random perturbation; security	SAMPLE COVARIANCE-MATRIX; LARGEST EIGENVALUE; LIMIT; SECURITY	Privacy is becoming an increasingly important issue in many data-mining applications. This has triggered the development of many privacy-preserving data-mining techniques. A large fraction of them use randomized data-distortion techniques to mask the data for preserving the privacy of sensitive data. This methodology attempts to hide the sensitive data by randomly modifying the data values often using additive noise. This paper questions the utility of the random-value distortion technique in privacy preservation. The paper first notes that random matrices have predictable structures in the spectral domain and then it develops a random matrix-based spectral-filtering technique to retrieve original data from the dataset distorted by adding random values. The proposed method works by comparing the spectrum generated from the observed data with that of random matrices. This paper presents the theoretical foundation and extensive experimental results to demonstrate that, in many cases, random-data distortion preserves very little data privacy. The analytical framework presented in this paper also points out several possible avenues for the development of new privacy-preserving data-mining techniques. Examples include algorithms that explicitly guard against privacy breaches through linear transformations, exploiting multiplicative and colored noise for preserving privacy in data mining applications.	Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA; Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA	Kargupta, H (reprint author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.	hillol@cs.umbc.edu					Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; BAI ZD, 1988, J MULTIVARIATE ANAL, V26, P166, DOI 10.1016/0047-259X(88)90078-4; BRAND R, 2002, MICRODATA PROTECTION, P97; Du W.-L., 2001, NEW SEC PAR WORKSH C, P11; EVFIMEVSKI A, 2002, P ACM SIKDD C EDM CA; EVFIMEVSKI A, 2003, P ACM SIMOD PODS C C; EVFIMEVSKI S, 2002, SIGKDD EXPLORATIONS, V4; GEMAN S, 1980, ANN PROBAB, V8, P252, DOI 10.1214/aop/1176994775; GRENANDER U, 1977, SIAM J APPL MATH, V32, P499, DOI 10.1137/0132041; HAM F, 1999, 21 SEIS RES S; Iyengar V.S., 2002, P 8 ACM SIGKDD INT C, P279; Jackson J., 1991, USERS GUIDE PRINCIPA; Janson S., 2000, RANDOM GRAPHS; JOHNSON K, LECT NOTES COMPUTER; JONSSON D, 1982, J MULTIVARIATE ANAL, V12, P1, DOI 10.1016/0047-259X(82)90080-X; KANTARCIOGLU M, 2002, SIGMOD WORKSHOP DMKD; Kargupta H., 2000, ADV DISTRIBUTED PARA; Kargupta H., 2002, ACM SIGKDD EXPLORATI, V3, P37, DOI 10.1145/507515.507521; Kargupta H., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); LIEW CK, 1985, ACM T DATABASE SYST, V10, P395, DOI 10.1145/3979.4017; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; LIU K, 2003, TRCS0324 U MAR COMP; Manolakis D. G., 2000, STAT ADAPTIVE SIGNAL; Marcenko V.A., 1967, MATH USSR SB, V1, P457, DOI 10.1070/SM1967v001n04ABEH001994; Mehta M L, 1991, RANDOM MATRICES; Muralidhar K, 1999, ACM T DATABASE SYST, V24, P487, DOI 10.1145/331983.331986; Papoulis A., 2002, PROBABILITY RANDOM V; PARK B, 2001, P 1 SIAM INT C DAT M; Park BH, 2003, HUM FAC ER, P341; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RIZVI S, 2002, P 28 VLDB C HONG KON; Schneier B., 1995, APPL CRYPTOGRAPHY; SILVERSTEIN JW, 1989, J MULTIVARIATE ANAL, V30, P307, DOI 10.1016/0047-259X(89)90042-0; SILVERSTEIN JW, 1992, IEEE T SIGNAL PROCES, V40, P2100, DOI 10.1109/78.149981; STEWART GW, 1973, SIAM REV, V15, P727, DOI 10.1137/1015095; Stolfo S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; TRAUB JF, 1984, ACM T DATABASE SYST, V9, P672, DOI 10.1145/1994.383392; VAIDYA J, 2002, 8 ACM SIGKDD INT C K; WEYL H, 1949, P NATL ACAD SCI USA, V35, P408, DOI 10.1073/pnas.35.7.408; WIGNER EP, 1951, P CAMB PHILOS SOC, V47, P790; YIN YQ, 1988, PROBAB THEORY REL, V78, P509, DOI 10.1007/BF00353874; *UML, REP	43	34	36	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	MAY	2005	7	4					387	414		10.1007/s10115-004-0173-6		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	931CZ	WOS:000229464700001	
J	Zhu, XQ; Wu, XD; Elmagarmid, AK; Feng, Z; Wu, LD				Zhu, XQ; Wu, XD; Elmagarmid, AK; Feng, Z; Wu, LD			Video data mining: Semantic indexing and event detection from the association perspective	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						video mining; multimedia systems; database management; knowledge-based systems		Advances in the media and entertainment industries, including streaming audio and digital TV, present new challenges for managing and accessing large audio-visual collections. Current content management systems support retrieval using low-level features, such as motion, color, and texture. However, low-level features often have little meaning for naive users, who much prefer to identify content using high-level semantics or concepts. This creates a gap between systems and their users that must be bridged for these systems to be used effectively. To this end, in this paper, we first present a knowledge-based video indexing and content management framework for domain specific videos (using basketball video as an example). We will provide a solution to explore video knowledge by mining associations from video data. The explicit definitions and evaluation measures (e.g., temporal support and confidence) for video associations are proposed by integrating the distinct feature of video data. Our approach uses video processing techniques to find visual and audio cues (e.g., court field, camera motion activities, and applause), introduces multilevel sequential association mining to explore associations among the audio and visual cues, classifies the associations by assigning each of them with a class label, and uses their appearances in the video to construct video indices. Our experimental results demonstrate the performance of the proposed approach.	Univ Vermont, Dept Comp Sci, Burlington, VT 05401 USA; Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA; Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China	Zhu, XQ (reprint author), Univ Vermont, Dept Comp Sci, 33 Colchester Ave,Votey 377, Burlington, VT 05401 USA.	xqzhu@cs.uvm.edu; xwu@cs.uvm.edu; ake@purdue.edu; zhfeng@fudan.edu.cn; ldwu@fudan.edu.cn					Agrawal R., 1995, P 11 INT C DAT ENG; Agrawal R., 1994, P 20 INT C VER LARG, P487; Cormen T. H., 2001, INTRO ALGORITHMS; Cui B, 2003, P 2003 ACM SIGMOD IN, P479; Duan L, 2003, P 11 ACM INT C MULT, P33; FAN J, 2002, MULTIMEDIA DATA MINI; Fan JP, 2001, J ELECTRON IMAGING, V10, P895, DOI 10.1117/1.1406944; Guttman A., 1984, P ACM SIGMOD INT C M, P47; Gwadera R, 2003, P 3 IEEE INT C DAT M, P67; Han J., 2000, DATA MINING CONCEPTS; Han JW, 1999, PROC INT CONF DATA, P106; Horowitz S. L., 1974, P 2 INT JOINT C PATT, P424; Hsu W., 2003, P 9 ACM SIGKDD INT C, P553; Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3; Jiang HT, 1998, IEEE T KNOWL DATA EN, V10, P947, DOI 10.1109/69.738359; Katayama N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Kokkoras F, 2002, MULTIMEDIA SYST, V8, P328, DOI 10.1007/s005300200054; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; MATSUO Y, 2003, P INT WORKSH MULT DA; NEPAL S., 2001, P ACM MULT, P261; NEWSAM S, 2002, P DIMACS WORKSH VID; Oates T, 1996, P 13 INT C MACH LEAR, P346; OH J, 2002, P INT WORKSH MULT DA; Pan J.-Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; PAN J, 2002, P INT C AS DIG LIB I, P194; SNOEK C, 2005, IN PRESS MULTIMEDIA; Srikant R., 1996, P 5 INT C EXT DAT TE; SRIKANT R, 1995, P 21 VER LARG DAT BA; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; THURAISINGHAM B, 2001, MANAGING MINING MULT; WANG RR, 2002, P DIMACS WORKSH VID; WIJESEKERA D, 2000, P INT WORKSH MULT DA; WINDHOUWER M, 2002, P INT C DAT ENG, P494; Wolf W, 1996, P IEEE INT C AC SPEE, V2, P1228; Xie L., 2002, P IEEE INT C AC SPEE; Xie L., 2003, VIDEO MINING; YOSHIDA K, 1993, P 12 IFAC WORLD C SY, V1, P81; Zaiane O. R., 1998, P ACM SIGMOD INT C M, P581, DOI 10.1145/276304.276388; Zhang H. J., 1993, ACM MULTIMEDIA SYSTE, V1, P10; Zhou W., 2000, P ACM MULT 2000 WORK, P213, DOI 10.1145/357744.357941; ZHU X, 2003, P INT JOINT C ART IN, P1422; ZHU X, 2003, P IEEE INT C MULT EX, V3, P333; ZHU X, 2004, IEEE T MULTIMEDIA; ZHU X, 2002, P ACM SIGMOD WORKSH, P9; Zhu XQ, 2003, PROC INT CONF DATA, P569, DOI 10.1109/ICDE.2003.1260822; *SOCAR, 2004, WOCAR ENG 2 5	46	34	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2005	17	5					665	677				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	908BU	WOS:000227763000007	
S	Verleysen, M; Francois, D		Cabestany, J; Prieto, A; Sandoval, F		Verleysen, M; Francois, D			The curse of dimensionality in data mining and time series prediction	COMPUTATIONAL INTELLIGENCE AND BIOINSPIRED SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Work-Conference on Artificial Neural Networks	JUN 08-10, 2005	Barcelona, SPAIN				PRINCIPAL COMPONENT ANALYSIS; NEURAL-NETWORKS; REDUCTION	Modern data analysis tools have to work on high-dimensional data, whose components are not independently distributed. High-dimensional spaces show surprising, counter-intuitive geometrical properties that have a large influence on the performances of data analysis tools. Among these properties, the concentration of the norm phenomenon results in the fact that Euclidean norms and Gaussian kernels, both commonly used in models, become inappropriate in high-dimensional spaces. This papers presents alternative distance measures and kernels, together with geometrical methods to decrease the dimension of the space. The methodology is applied to a typical time series prediction example.		Verleysen, M (reprint author), Pl Levant,3, B-1380 Louvain La Neuve, Belgium.	verleysen@dice.ucl.ac.be; francois@auto.ucl.ac.be					Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Bellmann R, 1961, ADAPTIVE CONTROL PRO; BEYER KS, 1999, 7 INT C JER ISR JAN, V1540, P217; BORGGAARD C, 1992, ANAL CHEM, V64, P545, DOI 10.1021/ac00029a018; Demartines P., 1994, THESIS I NATL POLYTE; Demartines P., 1997, IEEE T NEURAL NETWOR; FRANCOIS D, 2005, ESANN2005 EUR S ART; FRANCOIS D, 2005, UNPUB ASMDA2005 APPL; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; Hinneburg A., 2000, VLDB J, P506; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; Kohonen Teuvo, 1995, SELF ORG MAPS; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Lee J., 2002, EUR S ART NEUR NETW; LENDASSE A, 2001, EUROPEAN J EC SOCIAL, V15; Ramsay JO, 1997, FUNCTIONAL DATA ANAL; Refenes APN, 1997, IEEE T NEURAL NETWOR, V8, P1222, DOI 10.1109/72.641449; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SCHULLER KR, 1998, NEURAL COMPUT, V10, P1299; Silverman B. W., 1986, DENSITY ESTIMATION S; TAKENS F, 1985, LECT NOTES MATH, V1125, P99; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319	22	34	35	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26208-3	LECT NOTES COMPUT SC			2005	3512						758	770				13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCO15	WOS:000230384000093	
J	Wong, ML; Leung, KS				Wong, ML; Leung, KS			An efficient data mining method for learning Bayesian networks using an evolutionary algorithm-based hybrid approach	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						Bayesian networks; data mining; evolutionary computation; evolutionary programming (EP)	DESCRIPTION LENGTH PRINCIPLE; EQUIVALENCE CLASSES; GENETIC ALGORITHMS; BELIEF NETWORKS; NEURAL NETWORKS; KNOWLEDGE; DATABASES; DISCOVERY	Given the explosive growth of data collected from current business environment, data mining can potentially discover new knowledge to improve managerial decision making. This paper proposes a novel data mining approach that employs an evolutionary algorithm to discover knowledge represented in Bayesian networks. The approach is applied successfully to handle the business problem of finding response models from direct marketing data. Learning Bayesian networks from data is a difficult problem. There are two different approaches to the network learning problem. The first one uses dependency analysis, while the second one searches good network structures according to a metric. Unfortunately, both approaches have their own drawbacks. Thus, we,propose a novel hybrid algorithm of the two approaches, which consists of two phases, namely, the conditional independence (CI) test and the search phases. In the Cl test phase, dependency analysis is conducted to reduce the size of the search space. In the search phase, good Bayesian network models are generated by using an evolutionary algorithm. A new operator is introduced to further enhance the search effectiveness and efficiency. In a number of experiments and comparisons, the hybrid algorithm outperforms MDLEP, our previous algorithm which uses evolutionary programming (EP) for network learning, and other network learning algorithms. We then apply the approach to two data sets of direct marketing and compare the performance of the evolved Bayesian networks obtained by the new algorithm with those by MDLEP, the logistic regression models, the naive Bayesian classifiers, and the tree-augmented naive Bayesian network classifiers (TAN). In the comparison, the new algorithm outperforms the others.	Lingnan Univ, Dept Informat Syst, Tuen Mun, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Wong, ML (reprint author), Lingnan Univ, Dept Informat Syst, Tuen Mun, Hong Kong, Peoples R China.	mlwong@ln.edu.hk; ksleung@cse.cuhk.edu.hk					ACID S, 1996, P IPMU 96 C, P979; Agresti A., 2002, CATEGORICAL DATA ANA; Andersson SA, 1997, ANN STAT, V25, P505; Atkinson-Abutridy J, 2003, IEEE T EVOLUT COMPUT, V7, P546, DOI 10.1109/TEVC.2003.819262; Au WH, 2003, IEEE T EVOLUT COMPUT, V7, P532, DOI 10.1109/TEVC.2003.819264; Back T, 2000, EVOLUTIONARY COMPUTA, V2; Back T., 2000, EVOLUTIONARY COMPUTA; Beaumont GP, 1996, STAT TESTS INTRO MIN; Beinlich IA, 1989, P 2 EUR C ART INT ME, P247; Bhattacharyya S., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347186; Bhattacharyya S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Bhattacharyya S, 2002, IEEE T EVOLUT COMPUT, V6, P169, DOI 10.1109/4235.996016; Bouckaert R., 1995, THESIS UTRECHT U UTR; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; Cabena P., 1997, DISCOVERING DATA MIN; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; CHICKERING DM, 1994, MSRTR9417 MICR RES; CHICKERING DM, 2002, MSRTR2002103 MICR RE; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cooper GF, 1997, DATA MIN KNOWL DISC, V1, P203, DOI 10.1023/A:1009787925236; COTTA C, 2001, COMPUT INTELL, V2206, P739, DOI 10.1007/3-540-45493-4_72; Cotta C., 2002, Parallel Problem Solving from Nature - PPSN VII. 7th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2439); Dash D, 1999, P 15 C UNC ART INT, P142; DECAMPOS LM, 1999, APPROXIMATING CAUSAL; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FOGEL DB, 2000, ARTIFICIAL INTELLIGE; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FUNG RM, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P762; Goldberg D.E., 1989, GENETIC ALGORITHMS S; HECKERMAN D, 1995, COMMUN ACM, V38, P27, DOI 10.1145/203330.203336; Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752; Heckerman D., 1998, P 14 C UNC ART INT, P230; HECKERMAN D, 1995, MSRTR9506 ADV TECHN; Henrion M, 1988, P 2 C UNC ART INT, P149; HOFFEN KU, 1993, ACM COLT, P77; HOLLAND JH, 1975, ADAPTATION NATURAL A; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Keogh E. J., 1999, P 7 INT WORKSH ART I, P225; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Langley P., 1994, P 10 C UNC ART INT, P399; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; Laskey KB, 2003, MACH LEARN, V50, P175, DOI 10.1023/A:1020206129842; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LEE SY, 2001, P LAT BREAK PAP 2001, P252; Levin N., 1997, J DIRECT MARKETING, V11, P76, DOI 10.1002/(SICI)1522-7138(199723)11:4<76::AID-DIR10>3.0.CO;2-D; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Myers J. W., 1999, P GEN EV COMP C, V1, P458; MYERS JW, 1999, P 15 C UNC ART INT S, V1, P476; Neapolitan R. E., 1990, PROBABILISTIC REASON; Parr Rud O, 2001, DATA MINING COOKBOOK; Pearl J., 1988, PROBABILISTIC REASON; PETRISON LA, 1997, J DIRECT MARKETING, V11, P109, DOI 10.1002/(SICI)1522-7138(199723)11:4<109::AID-DIR12>3.0.CO;2-G; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Silverstein C, 2000, DATA MIN KNOWL DISC, V4, P163, DOI 10.1023/A:1009891813863; Singh M., 1993, P 9 C UNC ART INT, P259; SINGH M, 1998, THESIS U PENNSYLVANI; SPATZ C, 1981, BASIC STAT TALES DIS; Spirtes P., 2000, CAUSATION PREDICTION; Suzuki J, 1999, IEICE T FUND ELECTR, VE82A, P2237; Tian J., 2000, P 16 C UNC ART INT, P580; Tucker A, 2001, INT J INTELL SYST, V16, P621, DOI 10.1002/int.1027; VANDIJK S, 2003, P 2003 GEN EV COMP 1, V2723, P886; WONG ML, 2002, P 2002 C EV COMP, P1314; Wong ML, 1999, IEEE T PATTERN ANAL, V21, P174; WONG ML, 2002, P 2002 IEEE INT C DA, P498; WONG ML, 2002, P GEN EV COMP C, P214; Wong ML, 2000, IEEE ENG MED BIOL, V19, P45; Xiang Y, 1999, DATA MIN KNOWL DISC, V3, P315, DOI 10.1023/A:1009888910252; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; Zahavi J., 1997, J DIRECT MARKETING, V11, P63, DOI 10.1002/(SICI)1522-7138(199723)11:4<63::AID-DIR9>3.0.CO;2-U; Zhou C, 2003, IEEE T EVOLUT COMPUT, V7, P519, DOI 10.1109/TEVC.2003.819261	76	34	46	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	AUG	2004	8	4					378	404		10.1109/TEVC.2004.830334		27	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	848CP	WOS:000223445100006	
J	Zhang, YF; Bhattacharyya, S				Zhang, YF; Bhattacharyya, S			Genetic programming in classifying large-scale data: an ensemble method	INFORMATION SCIENCES			English	Article						genetic programming; ensemble; classification; large-scale data	ALGORITHMS; CLASSIFICATION; COMBINATION; FORECASTS	This study demonstrated potential of genetic programming (GP) as a base classifier algorithm in building ensembles in the context of large-scale data classification. All ensemble built upon base classifiers that were trained with GP was found to significantly outperform its counterparts built upon base classifiers that were trained with decision tree and logistic regression. The superiority of GP ensemble was partly attributed to the higher diversity, both in terms of the functional form of as well as with respect to the variables defining the models, among the base classifiers upon which it was built on. Implications of GP as a useful tool in other data mining problems, such as feature selection, were also discussed. (C) 2003 Elsevier Inc. All rights reserved.	Univ Illinois, Coll Business Adm, Chicago, IL 60607 USA	Zhang, YF (reprint author), Univ Illinois, Coll Business Adm, 601 S Morgan St,MC 294, Chicago, IL 60607 USA.	yzhang14@uic.edu; sidb@uic.edu					ALTENBERG L, 1994, EVOLUTIONARY PROGRAM, P233; ANGELINE P, 1998, P 3 ANN GEN PROGR C, P745; BATES JM, 1969, OPER RES QUART, V20, P451, DOI 10.2307/3008764; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bhattacharyya S, 1999, INFORMS J COMPUT, V11, P248, DOI 10.1287/ijoc.11.3.248; Bhattacharyya S, 1998, DECISION SCI, V29, P871, DOI 10.1111/j.1540-5915.1998.tb00880.x; BHATTACHARYYA S, 1998, P 4 INT C KNOWL DIS; BHATTACHARYYA S, 2000, P GECCO 2000 WORKSH; BHATTACHARYYA S, 2000, P 6 ACM SIGKDD INT C; Bradley PS, 1999, INFORMS J COMPUT, V11, P217, DOI 10.1287/ijoc.11.3.217; Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008640732416; CLEMEN RT, 1989, INT J FORECASTING, V5, P559, DOI 10.1016/0169-2070(89)90012-5; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DOMINGOS P, 2000, P 6 INT C KNOW DIS D; EGGERMONT J, 1999, ADV INTELLIGENT DATA; EVETT M, 1998, P 3 ANN GEN PROGR C; FAYYAD U, 1996, ADV KNOWL DISC DAT M; Fisher RA, 1936, ANN EUGENIC, V7, P179; Freed N., 1981, Decision Sciences, V12, DOI 10.1111/j.1540-5915.1981.tb00061.x; Frei K, 1997, MOL PSYCHIATR, V2, P96, DOI 10.1038/sj.mp.4000217; GEHRKE J, 1999, P 1999 SIGMOD C PHIL; GREENE DP, 1987, GENETIC ALGORITHMS A; HALL L, 2000, P 6 ACM SIGKDD INT C; Hand D. J., 1981, DISCRIMINATION CLASS; JACOBS RA, 1995, NEURAL COMPUT, V7, P867, DOI 10.1162/neco.1995.7.5.867; KAUFMANN M, P GEN EV COMP C 1999, P1053; Kim Y., 2000, P 6 ACM SIGKDD INT C, P365, DOI 10.1145/347090.347169; KIM Y, 2001, CONGRESS EVOLUTIONAR, P759; Koehler G. J., 1991, ORSA Journal on Computing, V3; Koza J. R., 1992, GENETIC PROGRAMMING; Krogh A., 1995, ADV NEURAL INFORMATI, V7, P231; Langdon W. B., 2000, Genetic Programming and Evolvable Machines, V1, DOI 10.1023/A:1010024515191; Michalewicz Z., 1994, GENETIC ALGORITHMS D; Mitchell M., 1996, INTRO GENETIC ALGORI; Montana DJ, 1995, EVOL COMPUT, V3, P199, DOI 10.1162/evco.1995.3.2.199; Optiz D., 1999, J ARTIFICIAL INTELLI, V11, P169; Optiz D.W., 1999, P 16 INT C ART INT, P379; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SOLLICH P, 1996, ADV NEURAL INFORMATI, V8; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; WINKLER RL, 1983, J ROY STAT SOC A STA, V146, P150, DOI 10.2307/2982011	43	34	34	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JUN 14	2004	163	1-3					85	101		10.1016/j.ins.2003.03.028		17	Computer Science, Information Systems	Computer Science	829TY	WOS:000222074100005	
J	Thawornwong, S; Enke, D				Thawornwong, S; Enke, D			The adaptive selection of financial and economic variables for use with artificial neural networks	NEUROCOMPUTING			English	Article						neural networks; variable relevance analysis; financial and economic variables; stock market prediction	EFFICIENT CAPITAL-MARKETS; STOCK RETURNS; PREDICTING RETURNS; INDEXES; PREDICTABILITY; BUSINESS; SYSTEM; MODELS; LEVEL	It has been widely accepted that predicting stock returns is not a simple task since many market factors are involved and their structural relationships are not perfectly linear. Recently, a promising data mining technique in machine learning has been proposed to uncover the predictive relationships of numerous financial and economic variables. Inspired by the fact that the determinant between these variables and their interrelationships over stock returns changes over time, we explore this issue further by using data mining to uncover the recent relevant variables with the greatest predictive ability. The objective is to examine whether using the recent relevant variables leads to additional improvements in stock return forecasting. Given evidence of non-linearity in the financial market, the resulting variables are then provided to neural networks, including probabilistic and feed-forward neural networks, for predicting the directions of future excess stock return. The results show that redeveloped neural network models that use the recent relevant variables generate higher profits with lower risks than the buy-and-hold strategy, conventional linear regression, and the random walk model, as well as the neural network models that use constant relevant variables. (C) 2003 Elsevier B.V. All rights reserved.	Univ Missouri, Intelligent Syst Ctr, Rolla, MO 65409 USA	Enke, D (reprint author), Univ Missouri, Intelligent Syst Ctr, 1870 Miner Circle 204, Rolla, MO 65409 USA.	enke@umr.edu					Abhyankar A, 1997, J BUS ECON STAT, V15, P1, DOI 10.2307/1392068; Austin M., 1997, New Review of Applied Expert Systems, V3; BALVERS RJ, 1990, J FINANC, V45, P1109, DOI 10.2307/2328717; BREEN W, 1989, J FINANC, V44, P1177, DOI 10.2307/2328638; Burrell PR, 1997, NEURAL COMPUT APPL, V6, P193, DOI 10.1007/BF01501506; CAMPBELL JY, 1987, J FINANC ECON, V18, P373, DOI 10.1016/0304-405X(87)90045-6; Chenoweth T, 1996, APPL ARTIF INTELL, V10, P523, DOI 10.1080/088395196118416; Chenoweth T, 1996, NEUROCOMPUTING, V10, P275, DOI 10.1016/0925-2312(95)00109-3; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Demuth H., 1998, NEURAL NETWORK TOOLB; Desai VS, 1998, DECISION SCI, V29, P405, DOI 10.1111/j.1540-5915.1998.tb01582.x; Duda R.O., 2001, PATTERN CLASSIFICATI; ELTON EJ, 1991, MODERN PORTFOLIO THE; FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486; FAMA EF, 1977, J FINANC ECON, V5, P115, DOI 10.1016/0304-405X(77)90014-9; FAMA EF, 1989, J FINANC ECON, V25, P23, DOI 10.1016/0304-405X(89)90095-0; FAMA EF, 1991, J FINANC, V46, P1575, DOI 10.2307/2328565; FAMA EF, 1988, J FINANC ECON, V22, P3, DOI 10.1016/0304-405X(88)90020-7; FERSON WE, 1989, J FINANC, V44, P1191, DOI 10.2307/2328639; Hagen M.T., 1996, NEURAL NETWORK DESIG; Han J., 2000, DATA MINING CONCEPTS; KEIM DB, 1986, J FINANC ECON, V17, P357, DOI 10.1016/0304-405X(86)90070-X; JENSEN MC, 1978, J FINANC ECON, V6, P95, DOI 10.1016/0304-405X(78)90025-9; LEITCH G, 1991, AM ECON REV, V81, P580; Leung MT, 2000, INT J FORECASTING, V16, P173, DOI 10.1016/S0169-2070(99)00048-5; Lo A. W., 1988, REV FINANC STUD, VI, P41, DOI DOI 10.1093/RFS/1.1.41; MALKIEL BG, 1995, RANDOM WALK WALL; MALLIARIS M, 1993, APPL INTELL, V3, P193, DOI 10.1007/BF00871937; MILLS TC, 1991, J EC SURVEYS, V5, P215, DOI 10.1111/j.1467-6419.1991.tb00133.x; Motiwalla L, 2000, COMPUT OPER RES, V27, P1111, DOI 10.1016/S0305-0548(99)00148-3; Nelson M, 1999, J FORECASTING, V18, P359, DOI 10.1002/(SICI)1099-131X(199909)18:5<359::AID-FOR746>3.0.CO;2-P; Pantazopoulos KN, 1998, IEEE T SYST MAN CY B, V28, P520, DOI 10.1109/3477.704291; PESARAN MH, 1995, J FINANC, V50, P1201, DOI 10.2307/2329349; PETERSON GE, 1995, IEEE T NEURAL NETWOR, V6, P949, DOI 10.1109/72.392257; Poddig T, 1996, NEUROCOMPUTING, V10, P251, DOI 10.1016/0925-2312(96)00049-5; Priestley M.B., 1988, NONLINEAR NONSTATION; Qi M, 1999, J BUS ECON STAT, V17, P419, DOI 10.2307/1392399; Qi M, 1999, J FORECASTING, V18, P151, DOI 10.1002/(SICI)1099-131X(199905)18:3<151::AID-FOR716>3.3.CO;2-M; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; REFENES AN, 1994, NEURAL NETWORKS, V7, P375; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318; SCHWERT GW, 1990, J FINANC, V45, P1237, DOI 10.2307/2328722; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Swales G. S.  Jr., 1992, Financial Analysts Journal, V48, DOI 10.2469/faj.v48.n5.78; THAWORNWONG S, 2003, NEURAL NETWORKS BUSI, P47; THAWRONWONG S, 2001, P INT ICSC C COMP IN, P329; THAWRONWONG S, 2001, P 32 ANN M DEC SCI I, P1079; Tsaih R, 1998, DECIS SUPPORT SYST, V23, P161, DOI 10.1016/S0167-9236(98)00028-1; Vellido A, 1999, EXPERT SYST APPL, V17, P51, DOI 10.1016/S0957-4174(99)00016-0; Wasserman P.D., 1993, ADV METHODS NEURAL C	50	34	35	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	JAN	2004	56						205	232		10.1016/j.neucom.2003.05.001		28	Computer Science, Artificial Intelligence	Computer Science	768XX	WOS:000188597300010	
S	Valtchev, P; Missaoui, R; Godin, R		Eklund, P		Valtchev, P; Missaoui, R; Godin, R			Formal concept analysis for knowledge discovery and data mining: The new challenges	CONCEPT LATTICES, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	2nd International Conference on Formal Concept Analysis (ICFCA 2004)	FEB 23-26, 2004	Sydney, AUSTRALIA				GALOIS CONCEPT LATTICES; ASSOCIATION RULES; ALGORITHMS; DATABASES	Data mining (DM) is the extraction of regularities from raw data, which are further transformed within the wider process of knowledge discovery in databases (KDD) into non-trivial facts intended to support decision making. Formal concept analysis (FCA) offers an appropriate framework for KDD, whereby our focus here is on its potential for DM support. A variety of mining methods powered by FCA have been published and the figures grow steadily, especially in the association rule mining (ARM) field. However, an analysis of current ARM practices suggests the impact of FCA has not reached its limits, i.e., appropriate FCA-based techniques could successfully apply in a larger set of situations. As a first step in the projected FCA expansion, we discuss the existing ARM methods, provide a set of guidelines for the design of novel ones, and list some open algorithmic issues on the FCA side. As an illustration, we propose two on-line methods computing the minimal generators of a closure system.	Univ Montreal, DIRO, Montreal, PQ, Canada; UQO, Dept Informat & Ingn, Gatineau, PQ, Canada; Univ Quebec Montreal, Dept Informat, Montreal, PQ, Canada	Valtchev, P (reprint author), Univ Montreal, DIRO, Montreal, PQ, Canada.						Agrawal R., 1994, P 20 INT C VER LARG, P487; AYAN NF, 1999, P 5 ACM SIGKDD INT C, P287, DOI 10.1145/312129.312252; Barbut M., 1970, ORDRE CLASSIFICATION; Birkhoff G., 1967, LATTICE THEORY, V25; Bordat J. P., 1986, MATH SCI HUMAINES, V96, P31; Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094; DAVEY BA, 1992, INTRO LATTICES ORDER; Feldman R., 1997, P ACM SIGMOD WORKSH, P59; GANTER B, 1984, 831 TECHN HOCHSCH; Ganter B., 1999, FORMAL CONCEPT ANAL; GODIN R, 1994, THEORETICAL COMPUTER, V133, P378; GODIN R, 1995, COMPUT INTELL, V11, P246, DOI 10.1111/j.1467-8640.1995.tb00031.x; Guigues J.-L, 1986, MATH SCI HUMAINES, V95, P5; Han J., 2001, DATA MINING CONCEPTS; Kryszkiewicz M., 2002, Pattern Detection and Discovery. ESF Exploratory Workshop Proceedings (Lecture Notes in Artificial Intelligence Vol. 2447); Kuznetsov SO, 2002, J EXP THEOR ARTIF IN, V14, P189, DOI 10.1080/09528130210164170; Luxenburger M., 1991, MATH INFORMATIQUE SC, V29, P35; Maier D., 1983, THEORY RELATIONAL DA; Mannila H., 1994, P AAAI WORKSH KNOWL, P181; Nourine L, 1999, INFORM PROCESS LETT, V71, P199, DOI 10.1016/S0020-0190(99)00108-8; Ore O, 1944, T AM MATH SOC, V55, P493, DOI 10.2307/1990305; PAN F, 2003, P 9 INT C KNOWL DISC; PASQUIER N, 2000, P 18 INFORSID 2000 L, P56; Pasquier N, 1999, INFORM SYST, V24, P25, DOI 10.1016/S0306-4379(99)00003-4; Pasquier N., 1999, P 7 INT C DAT THEOR, P398; Pei J., 2000, P ACM SIGMOD WORKSH, P21; Pfaltz J. L., 2002, P 1 INT WORKSH DISCR, P65; Stumme G, 2002, DATA KNOWL ENG, V42, P189, DOI 10.1016/S0169-023X(02)00057-5; Thomas S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Valtchev P, 2003, LECT NOTES ARTIF INT, V2746, P282; Valtchev P, 2002, DISCRETE MATH, V256, P801, DOI 10.1016/S0012-365X(02)00349-7; VALTCHEV P, 2003, P 4 INT C JOURN INF, P3; Valtchev P, 2001, LECT NOTES ARTIF INT, V2120, P290; Valtchev P, 2002, J EXP THEOR ARTIF IN, V14, P115, DOI 10.1080/09528130210164198; Wang J., 2003, P 9 ACM SIGKDD INT C; Wille R, 2002, J EXP THEOR ARTIF IN, V14, P81, DOI 10.1080/09528130210164161; Wille R., 1982, ORDERED SETS, P445; WILLE R, 2002, ORDERED SETS, V14, P81; Yan X., 2003, P 3 SIAM INT C DAT M; Yan X., 2003, P 9 INT C KNOWL DISC; Zaki M. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347101; Zaki MJ, 1999, IEEE CONCURR, V7, P14, DOI 10.1109/4434.806975; Zaki M.J., 2002, P 2 SIAM INT C DAT M	43	34	34	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-21043-1	LECT NOTES ARTIF INT			2004	2961						352	371				20	Computer Science, Artificial Intelligence	Computer Science	BY62F	WOS:000189423400030	
J	Masseglia, F; Poncelet, P; Teisseire, M				Masseglia, F; Poncelet, P; Teisseire, M			Incremental mining of sequential patterns in large databases	DATA & KNOWLEDGE ENGINEERING			English	Article						sequential patterns; incremental mining; data mining		In this paper, we consider the problem of the incremental mining of sequential patterns when new transactions or new customers are added to an original database. We present a new algorithm for mining frequent sequences that uses information collected during an earlier mining process to cut down the cost of finding new sequential patterns in the updated database. Our test shows that the algorithm performs significantly faster than the naive approach of mining the whole updated database from scratch. The difference is so pronounced that this algorithm could also be useful for mining sequential patterns, since in many cases it is faster to apply our algorithm than to mine sequential patterns using a standard algorithm, by breaking down the database into an original database plus an increment. (C) 2003 Elsevier Science B.V. All rights reserved.	INRIA Sophia Antipolis, FR-06902 Sophia Antipolis, France; LIRMM, F-34392 Montpellier 5, France; Ecole Mines Ales, Lab LGI2P, F-30035 Nimes 1, France	Masseglia, F (reprint author), INRIA Sophia Antipolis, 2004 Route des Lucioles,BP 93, FR-06902 Sophia Antipolis, France.		Teisseire, Maguelonne/A-6576-2011				AGRAWAL R, 1995, P 1 INT C KNOWL DISC; Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R, 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1995, P 11 INT C DAT ENG I; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; Cheung D., 1996, P 12 INT C DAT ENG I; CHEUNG DW, 1997, P 5 INT C DAT SYST A; Fayad U., 1996, ADV KNOWLEDGE DISCOV; FELDMAN R, 1997, P DMKD WORKSH, P414; GARDARIN G, 1998, JOURN BAS DONN AV BD; Lee SD, 1998, DATA MIN KNOWL DISC, V2, P233, DOI 10.1023/A:1009703019684; Lin MY, 1998, PROC INT C TOOLS ART, P24; MASSEGLIA F, 1999, JOURNES BASES DONNES; Masseglia F., 1999, NETWORKING INFORMATI, V2, P571; Parthasarathy S, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P251, DOI 10.1145/319950.320010; PASQUIER N, 1998, INFORMATION SYSTEMS, V19, P33; Pudi V, 2000, INFORM SYST, V25, P323, DOI 10.1016/S0306-4379(00)00021-1; RAINSFORD CP, 1996, P INT S COOP DAT SYS, P302; RAINSFORD CP, 1997, P 8 INT DAT WORKSH, P78; SARDA N, 1998, P 9 INT WORKSH DAT E; Savasere A, 1995, P 21 INT C VER LARG, P432; Srikant R., 1996, P 5 INT C EXT DAT TE, P3; THOMAS S, 1997, P 3 INT C KNOWL DISC; TOIVONEN H, 1996, P 22 INT C VER LARG; WANG K, 1997, J INTELL INF SYST, P8; Wang K., 1996, P ACM SIGMOD 96 DAT, P95; ZAKI M, 1998, THESIS U ROCHESTER N; ZAKI MJ, 1999, FAST MINING SEQUENTI	28	34	41	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	JUL	2003	46	1					97	121		10.1016/S0169-023X(02)00209-4		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	686XK	WOS:000183346100004	
J	Widmer, G				Widmer, G			Discovering simple rules in complex data: A meta-learning algorithm and some surprising musical discoveries	ARTIFICIAL INTELLIGENCE			English	Article						machine learning; data mining; rule discovery; ensemble methods; meta-learning; partial models; expressive music performance	MACHINE DISCOVERY; PREDICTION; PRINCIPLES; KNOWLEDGE	This article presents a new rule discovery algorithm named PLCG that can find simple, robust partial rule models (sets of classification rules) in complex data where it is difficult or impossible to find models that completely account for all the phenomena of interest. Technically speaking, PLCG is an ensemble learning method that learns multiple models via some standard rule learning algorithm, and then combines these into one final rule set via clustering, generalization, and heuristic rule selection. The algorithm was developed in the context of an interdisciplinary research project that aims at discovering fundamental principles of expressive music performance from large amounts of complex real-world data (specifically, measurements of actual performances by concert pianists). It will be shown that PLCG succeeds in finding some surprisingly simple and robust performance principles, some of which represent truly novel and musically meaningful discoveries. A set of more systematic experiments shows that PLCG usually discovers significantly simpler theories than more direct approaches to rule learning (including the state-of-the-art learning algorithm RIPPER), While striking a compromise between coverage and precision. The experiments also show how easy it is to use PLCG as a meta-learning strategy to explore different parts of the space of rule models. (C) 2003 Elsevier Science B.V. All rights reserved.	Univ Vienna, Dept Med Cybernet & Artificial Intelligence, Vienna, Austria; Austrian Res Inst Artificial Intelligence, Vienna, Austria	Widmer, G (reprint author), Univ Vienna, Dept Med Cybernet & Artificial Intelligence, Vienna, Austria.						CAMBOUROPOULOS E, 2000, P AAAI 2000 WORKSH A, P19; CAMBOUROPOULOS E, 2001, P 8 BRAZ S COMP MUS; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cohen W. W., 1993, P 13 INT JOINT C ART, P988; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Dixon S, 2001, J NEW MUSIC RES, V30, P39, DOI 10.1076/jnmr.30.1.39.7119; Dixon S, 2000, P 14 EUR C ART INT E, P626; Domingos P., 1998, INTELL DATA ANAL, V2, P187, DOI 10.1016/S1088-467X(98)00023-7; Domingos P, 1996, MACH LEARN, V24, P141; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hunter L., 1993, ARTIFICIAL INTELLIGE; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; KING RD, 1992, P NATL ACAD SCI USA, V89, P11322, DOI 10.1073/pnas.89.23.11322; MUGGLETON S, 1992, PROTEIN ENG, V5, P647, DOI 10.1093/protein/5.7.647; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan JR, 1993, C4 5 PROGRAMS MACHIN; SHAVLIK JW, 1992, INT J GENOME RES, V1, P81; SUNDBERG J, 1993, SPEECH COMMUN, V13, P239, DOI 10.1016/0167-6393(93)90075-V; VALDESPEREZ RE, 1995, ARTIF INTELL, V74, P191, DOI 10.1016/0004-3702(94)00073-A; ValdesPerez RE, 1996, ARTIF INTELL, V82, P331, DOI 10.1016/0004-3702(95)00128-X; Valdes-Perez RE, 1999, ARTIF INTELL, V107, P335, DOI 10.1016/S0004-3702(98)00116-7; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; Widmer G, 2001, AI COMMUN, V14, P149; WIDMER G, 1993, INFORMATICA, V17, P371; Widmer G, 2002, J NEW MUSIC RES, V31, P37, DOI 10.1076/jnmr.31.1.37.8103; WIDMER G, 2001, P 12 EUR C MACH LEAR; WIDMER G, 2000, P INT COMP MUS C ICM; WIDMER G, 2002, P 5 INT C DISC SCI D	32	34	34	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	JUN	2003	146	2					129	148		10.1016/S0004-3702(03)00016-X		20	Computer Science, Artificial Intelligence	Computer Science	679MP	WOS:000182926600001	
J	Breault, JL; Goodall, CR; Fos, PJ				Breault, JL; Goodall, CR; Fos, PJ			Data mining a diabetic data warehouse	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						data mining; diabetes; data mining software CART		Diabetes is a major health problem in the United States. There is a long history of diabetic registries and databases with systematically collected patient information. We examine one such diabetic data warehouse, showing a method of applying data mining techniques, and some of the data issues, analysis problems, and results. The diabetic data warehouse is from a large integrated health care system in the New Orleans area with 30,383 diabetic patients. Methods for translating a complex relational database with time series and sequencing information to a flat file suitable for data mining are challenging. We discuss two variables in detail, a comorbidity index and the HgbA1c, a measure of glycemic control related to outcomes. We used the classification tree approach in Classification and Regression Trees (CART((R))) with a binary target variable of HgbA1c >9.5 and 10 predictors: age, sex, emergency department visits, office visits, comorbidity index, dyslipidemia, hypertension, cardiovascular disease, retinopathy, end-stage renal disease. Unexpectedly, the most important variable associated with bad glycemic control is younger age, not the comorbiditity index or whether patients have related diseases. If we want to target diabetics with bad HgbA1c values, the odds of finding them is 3.2 times as high in those <6.5 years of age than those older. Data mining can discover novel associations that are useful to clinicians and administrators. (C) 2002 Elsevier Science B.V. All rights reserved.	Alton Ochsner Med Fdn & Ochsner Clin, New Orleans, LA 70121 USA; Tulane Univ, New Orleans, LA 70112 USA; AT&T Corp, Shannon Res & Technol Lab, Middletown, NJ 07748 USA; Tulane Univ, New Orleans, LA 70112 USA; Univ Nevada, Sch Dent, Las Vegas, NV 89154 USA	Breault, JL (reprint author), Alton Ochsner Med Fdn & Ochsner Clin, 1516 Jefferson Highway, New Orleans, LA 70121 USA.		Breault, Joseph/D-4142-2011				Adams PF, 1999, CURRENT ESTIMATES NA; Bellazzi R, 2000, ARTIF INTELL MED, V20, P37, DOI 10.1016/S0933-3657(00)00052-X; Bellazzi R, 1998, Proc AMIA Symp, P160; BJORVAND AT, 1996, TIME SERIES ROUGH SE, P75; Blonde L, 2001, Ochsner J, V3, P126; BLUM RL, 1982, COMPUTERS BIOMEDICAL, V15, P165; BRAGG R, 1997, NY TIMES        0118, P6; BRAGG R, 1997, NY TIMES        0315, P8; BRAGG R, 1997, NY TIMES        0315, pV146; BREAULT JL, 2002, P C MATH CHALL SCI D; BREAULT JL, IN PRESS P 33 S INT; BREIMAN L, 1984, CLASSIFICATION REGRE, P307; DUMOUCHEL W, IN PRESS P 33 S INT; DUMOUCHEL W, 1999, KDD 99 P 5 ACM SIGKD, P6; Dzeroski S., 2001, RELATIONAL DATA MINI; Fos P, 2000, DESIGNING HLTH CARE; GOODALL C, 1995, P MASS DAT SETS COMM; Goodall CR, 1999, J COMPUT GRAPH STAT, V8, P620, DOI 10.2307/1390880; GUNOPULOS D, 2000, KDD 2000 TUTORIALS, P243; HAND D, 2001, PRINCIPLES DATA MINI, P343; HE H, 2000, PRICAI 2000, P799; HOOD D, 2001, LOUISIANA HLTH REPOR; HSU W, 2000, KDD 2000, P430; HUANG YW, 1999, KDD 99, P282; Klabunde CN, 2000, J CLIN EPIDEMIOL, V53, P1258, DOI 10.1016/S0895-4356(00)00256-0; RIVA A, 1995, ADV INTELLIGENT DATA, P144; Sakamoto N, 1996, J Med Syst, V20, P183, DOI 10.1007/BF02263390; SONGER TJ, 1995, P C DIAB AM, P259; STEPANIUK J, 1999, P 11 INT S METH INT, P457; Tafeit E, 2000, AM J HUM BIOL, V12, P388, DOI 10.1002/(SICI)1520-6300(200005/06)12:3<388::AID-AJHB9>3.0.CO;2-1; Tsien C L, 2000, Proc AMIA Symp, P858; Weng C, 1997, DIABETIC MED, V14, P877, DOI 10.1002/(SICI)1096-9136(199710)14:10<877::AID-DIA473>3.0.CO;2-Q; *AMA JCAHO NCQA, 2001, COORD PERF MEAS MAN; *CDC, 2001, DIAB SER PUBL HLTH P; *CDC, 1998, NAT DIAB FACT SHEET; *CDC, 1996, MMWR-MORBID MORTAL W, V45, P937; *TIMB CONS, 2001, CART FREQ ASK QUEST; 1999, LADHH	38	34	35	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	SEP-OCT	2002	26	1-2					37	54		10.1016/S0933-3657(02)00051-9		18	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	597BJ	WOS:000178201900003	
J	Ros, F; Pintore, M; Chretien, JR				Ros, F; Pintore, M; Chretien, JR			Molecular descriptor selection combining genetic algorithms and fuzzy logic: application to database mining procedures	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article; Proceedings Paper	4th Congress of Chemometrics	DEC 06-07, 2000	PARIS, FRANCE	Soc Ind Chem, French Grp Chemometr, French Soc Chem, French Grp Chemometr, CNRS, Conservat Natl Arts Metiers, Ecole Europenne Chimie Analyt, Cercle Sci Analyt		molecular descriptor selection; genetic algorithm; stepwise approach; fuzzy clustering	COMBINATORIAL CHEMISTRY; NEURAL NETWORKS; RECOGNITION; SYSTEMS	A new algorithm, devoted to molecular descriptor selection in the context of Data Mining problems, has been developed. This algorithm is based on the concepts of genetic algorithms (GA) for descriptor hyperspace exploration and combined with a stepwise approach to get local convergence. Its selection power was evaluated by a fitness function derived from a fuzzy clustering method. Different training and test sets were randomly generated at each GA generation. The fitness score was derived by combining the scores of the training and test sets. The ability of the proposed algorithm to select relevant subsets of descriptors was tested on two data sets. The first one, an academic example, corresponded to the artificial problem of Bullseye, the second was a real data set including 114 olfactory compounds divided into three odor categories. In both cases, the proposed method allowed to improve the separation between the different data set classes. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Orleans, Lab Chemometr & BioInformat, F-45067 Orleans 2, France	Chretien, JR (reprint author), Univ Orleans, Lab Chemometr & BioInformat, BP 6759, F-45067 Orleans 2, France.	Jacques.Chretien@univ-orleans.fr					Altenberg L., 1994, ADV GENETIC PROGRAMM, P47; Audouze K, 2000, ANALUSIS, V28, P625; BERTRAND D, 1992, J CHEMOMETR, V3, P413; COLLINS RJ, 1991, P 4 INT C GEN ALG, P244; DEARDEN JC, 1990, EURO CH ENV, V1, P25; Fauchere JL, 1998, CHEMOMETR INTELL LAB, V43, P43, DOI 10.1016/S0169-7439(98)00082-3; Fukunaga K., 1972, INTRO STAT PATTERN R; GEMPERLINE PJ, 1991, ANAL CHEM, V63, P2313, DOI 10.1021/ac00020a022; Goldberg D.E., 1989, GENETIC ALGORITHMS S; GREFENSTETTE JJ, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P183; HATHAWAY RJ, 1994, PATTERN RECOGN, V27, P429, DOI 10.1016/0031-3203(94)90119-8; HOLLAND JH, 1992, ADAPTATION NATURAL A; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kinnear K. E., 1994, ADV GENETIC PROGRAMM; Kohonen T, 2001, SELF ORGANIZING MAPS; Leitch D, 1998, IEEE T SYST MAN CY C, V28, P112, DOI 10.1109/5326.661094; Lin YH, 1997, IEEE T FUZZY SYST, V5, P614; MARENGO E, 1993, CHEMOMETR INTELL LAB, V19, P43, DOI 10.1016/0169-7439(93)80081-R; PEDRYCZ W, 1990, PATTERN RECOGN, V23, P121, DOI 10.1016/0031-3203(90)90054-O; Ripley B. D., 1993, NETWORKS CHAOS STAT, P40; ROS F, 1995, FOOD CONTROL, V6, P37, DOI 10.1016/0956-7135(95)91452-Q; Ros F, 1997, J CHEMOMETR, V11, P469, DOI 10.1002/(SICI)1099-128X(199711/12)11:6<469::AID-CEM491>3.3.CO;2-H; Ros F, 2000, SAR QSAR ENVIRON RES, V11, P281, DOI 10.1080/10629360008033236; SABLJIC A, 1990, EURO CH ENV, V1, P61; SINFORT N, 1993, THESIS U MONTPELLIER; TAKAGI H, 1993, P 8 AUSTR ART INT C, P68; Warr WA, 1997, J CHEM INF COMP SCI, V37, P134, DOI 10.1021/ci9601426; ZADEH LA, 1977, CLASSIFICATION CLUST, P251	29	34	34	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	AUG 28	2002	63	1					15	26		10.1016/S0169-7439(02)00033-3		12	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	581UC	WOS:000177311000005	
J	Apte, C; Liu, B; Pednault, E; Smyth, P				Apte, C; Liu, B; Pednault, E; Smyth, P			Business applications of data mining	COMMUNICATIONS OF THE ACM			English	Article									IBM Corp, Thomas J Watson Res Ctr, Data Abstract Res Grp, Yorktown Hts, NY 10598 USA; Univ Illinois, Dept Comp Sci, Chicago, IL USA; Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92717 USA	Apte, C (reprint author), IBM Corp, Thomas J Watson Res Ctr, Data Abstract Res Grp, Yorktown Hts, NY 10598 USA.						Apte C., 2001, P 7 ACM SIGKDD INT C, P408, DOI 10.1145/502512.502573; Apte C, 1999, IEEE INTELL SYST APP, V14, P49, DOI 10.1109/5254.809568; Cadez I., 2001, P 7 ACM SIGKDD INT C, P37, DOI 10.1145/502512.502523; Hsu W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347180; LIU B, 2000, P 6 ACM SIGKDD INT C, P208, DOI 10.1145/347090.347128	5	34	35	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0001-0782		COMMUN ACM	Commun. ACM	AUG	2002	45	8					49	53				5	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	577XC	WOS:000177087200014	
J	Hong, TH; Han, I				Hong, TH; Han, I			Knowledge-based data mining of news information on the Internet using cognitive maps and neural networks	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; Internet; cognitive maps; neural networks	FORECASTING METHODS; SYSTEM	In this paper, we investigate ways to apply news information on the Internet to the prediction of interest rates. We developed the Knowledge-Based News Miner (KBNMiner), which is designed to represent the knowledge of interest rate experts with cognitive maps (CMs), to search and retrieve news information on the Internet according to prior knowledge, and to apply the information, which is retrieved from news information, to a neural network model for the prediction of interest rates. This paper focuses on improving the performance of data mining by using prior knowledge. Real-world interest rate prediction data is used to illustrate the performance of the KBNMiner. Our integrated approach, which utilizes CMs and neural networks, has been shown to be effective in experiments. While the 10-fold cross validation is used to test our research model, the experimental results of the paired t-test have been found to be statistically significant. (C) 2002 Elsevier Science Ltd. All rights reserved.	Korea Adv Inst Sci & Technol, Grad Sch Management, Dongdaemun Gu, Seoul 130012, South Korea	Hong, TH (reprint author), Korea Adv Inst Sci & Technol, Grad Sch Management, Dongdaemun Gu, 207-43 Cheongryangri Dong, Seoul 130012, South Korea.		Han, Ingoo/C-2031-2011				ALLEN LE, 1996, MORTGAGE BANKING, V56, P99; ARMSTRONG JS, 1992, INT J FORECASTING, V8, P69, DOI 10.1016/0169-2070(92)90008-W; AXELROD R, 1976, STRUCTURE DECISON CO; Berry M. R. J., 1997, DATA MINING TECHNIQU; Bidarkota PV, 1998, INT J FORECASTING, V14, P457, DOI 10.1016/S0169-2070(98)00036-3; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; CARBONE R, 1982, J FORECASTING, V1, P215, DOI 10.1002/for.3980010207; Changchien SW, 2001, EXPERT SYST APPL, V20, P325, DOI 10.1016/S0957-4174(01)00017-3; Chiang DA, 2000, FUZZY SET SYST, V112, P419, DOI 10.1016/S0165-0114(98)00003-7; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; FRASCONI O, 1991, P INT JOINT C NEUR N; Frawley W. J., 1991, Knowledge discovery in databases; GILES CL, 1993, P IEEE INT C NEUR NE, P801; HONG TH, 1996, P 1 A PAC C DEC SCI, P975; Kim SH, 1997, EXPERT SYST APPL, V13, P85, DOI 10.1016/S0957-4174(97)00010-9; Kohara K., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<11::AID-ISAF115>3.3.CO;2-V; KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2; Padmanabhan B, 1999, DECIS SUPPORT SYST, V27, P303, DOI 10.1016/S0167-9236(99)00053-6; PARK KS, 1995, INT J HUM-COMPUT ST, V42, P157, DOI 10.1006/ijhc.1995.1007; Park SC, 2001, DECIS SUPPORT SYST, V31, P205, DOI 10.1016/S0167-9236(00)00132-9; TABER R, 1991, EXPERT SYST APPL, V2, P83, DOI 10.1016/0957-4174(91)90136-3; TOWELL GG, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P861; ZHANG WR, 1992, IEEE T SYST MAN CYB, V22, P103, DOI 10.1109/21.141315; ZHANG WR, 1989, IEEE T SYST MAN CYB, V19, P31, DOI 10.1109/21.24529	24	34	35	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2002	23	1					1	8		10.1016/S0957-4174(02)00022-2		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	572TR	WOS:000176791500001	
J	Shekhar, S; Schrater, PR; Vatsavai, RR; Wu, WL; Chawla, S				Shekhar, S; Schrater, PR; Vatsavai, RR; Wu, WL; Chawla, S			Spatial contextual classification and prediction models for mining geospatial data	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						Markov random fields (MRIF); spatial autoregression (SAR); spatial context; spatial data mining	MARKOV RANDOM-FIELDS; STATISTICAL-ANALYSIS; IMAGES	Modeling spatial context (e.g., autocorrelation) is a key challenge in classification problems that arise in geospatial domains. Markov random fields (MRF) is a popular model for incorporating spatial context into image segmentation and land-use classification problems. The spatial autoregression (SAR) model, which is an extension of the classical regression model for incorporating spatial dependence, is popular for prediction and classification of spatial data in regional economics, natural resources, and ecological studies. There is little literature comparing these alternative approaches to facilitate the exchange of ideas (e.g., solution procedures). We argue that the SAR model makes more restrictive assumptions about the distribution of feature values and class boundaries than MRF. The relationship between SAR and MRF is analogous to the relationship between regression and Bayesian classifiers. This paper provides comparisons between the two models using a probabilistic and an experimental framework.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA; Univ Minnesota, Dept Psychol, Minneapolis, MN 55455 USA; Vignette Corp, Boston, MA 02167 USA	Shekhar, S (reprint author), Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.		Vatsavai, Ranga/A-6961-2008				Agrawal R., 1994, Proceedings of the Thirteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1994, DOI 10.1145/182591.182600; Anselin L., 1988, SPATIAL ECONOMETRICS; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J ROY STAT SOC B MET, V48, P259; BOYKOV Y, 1999, P INT C COMP VIS SEP; CHOU PB, 1993, MARKOV RANDOM FIELD; Cressie N.A.C., 1993, STAT SPATIAL DATA; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; GREENMAN C, 2000, NY TIMES         JAN; Haykin S., 1994, NEURAL NETWORKS COMP; Hosmer Jr D.W., 1989, APPL LOGISTIC REGRES; Jhung YH, 1996, IEEE T GEOSCI REMOTE, V34, P67; Koperski K., 1996, P SIGMOD WORKSH RES, P1; Lesage James.P, 1997, J REGIONAL ANAL POLI, V27, P83; LESAGE JP, 2001, DATA MINING SCI ENG; LeSage JP, 1997, INT REGIONAL SCI REV, V20, P113, DOI 10.1177/016001769702000107; LI S, 1995, COMPUTER VISION; MARK D, 1999, NSF WORKSH FEB; MELTON J, 2001, SIGMOD REC DEC, V30; Ozesmi SL, 1999, ECOL MODEL, V116, P15, DOI 10.1016/S0304-3800(98)00149-5; Ozesmi U, 1997, ECOL MODEL, V101, P139, DOI 10.1016/S0304-3800(97)01983-2; PACE R, 1997, STAT PROBABILITY LET, P291; PACE R, 1997, GEOGRAPH ANAL; RIBEIRONETO B, 1999, MODERN INFORMATION R; RODDICK JF, 1999, ACM SPEC INT GROUP K; SARLE WS, 1994, 9 ANN SAS US GROUP C; Shekhar S., 2002, TOUR SPATIAL DATABAS; SHEKHAR S, 1999, IEEE T KNOWLEDGE DAT, V11; Solberg AHS, 1996, IEEE T GEOSCI REMOTE, V34, P100, DOI 10.1109/36.481897; Tobler WR, 1979, CELLULAR GEOGRAPHY P; Warrender CE, 1999, INT J REMOTE SENS, V20, P1987, DOI 10.1080/014311699212308	32	34	36	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1520-9210		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	JUN	2002	4	2					174	188		10.1109/TMM.2002.1017732		15	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	576JN	WOS:000177000800004	
J	Garcke, J; Griebel, M; Thess, M				Garcke, J; Griebel, M; Thess, M			Data mining with sparse grids	COMPUTING			English	Article						data mining; classification; approximation; sparse grids; combination technique	SUPPORT VECTOR MACHINES; COMBINATION TECHNIQUE; NEURAL NETWORKS; INTEGRAL-EQUATIONS; CLASSIFICATION; APPROXIMATION; SPACES; COMPLEXITY; PARAMETER; PDES	We present a new approach to the classification problem arising in data mining. It is based on the regularization network approach but, in contrast to other methods which employ ansatz functions associated to data points, we use basis functions coming from a grid in the usually high-dimensional feature space for the minimization process. To cope with the curse of dimensionality we employ sparse grids [78]. Thus, only O(h(n)(-1) n(d-1)) instead of O(h(n)(-d)) grid points and unknowns are involved. Here d denotes the dimension of the feature space and h(n) = 2(-n) gives the mesh size. To be precise, we suggest to use the sparse grid combination technique [42] where the classification problem is discretized and solved on a certain sequence of conventional grids with uniform mesh sizes in each coordinate direction. The sparse grid solution is then obtained from the solutions on these different grids by linear combination. In contrast to other sparse grid techniques, the combination method is simpler to use and can be parallelized in a natural and straightforward way. We describe the sparse grid combination technique for the classification problem in terms of the regularization network approach. We then give implementational details and discuss the complexity of the algorithm. It turns out that the method scales only linearly with the number of instances, i.e. the amount of data to be classified. Finally we report on the quality of the classifier built by our new method. Here we consider standard test problems from the UCI repository and problems with huge synthetical data sets in up to 9 dimensions. It turns out that our new method achieves correctness rates which are competitive to that of the best existing methods.	Univ Bonn, Inst Angew Math, D-53115 Bonn, Germany; Prudential Syst Software GmbH, Technol Zentrum Chemnitz, D-09125 Chemnitz, Germany	Garcke, J (reprint author), Univ Bonn, Inst Angew Math, Wegelerstr 6, D-53115 Bonn, Germany.						ALLEN A, 1972, REGRESSION MOORE PEN; ARGE E, 1995, J COMPUT APPL MATH, V59, P191, DOI 10.1016/0377-0427(94)00033-W; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; Balder R., 1994, THESIS TU MUNCHEN; BASZENSKI G, 1985, ISNM, V75, P35; Bennett K.P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Berry MJA, 2000, MASTERING DATA MININ; BLAKE CL, 1998, UCI RESP MACHINE LEA; BRADLEY PS, 1998, ICML, V98, P82; BUNGARTZ H, 1994, COMPUT METHOD APPL M, V116, P243, DOI 10.1016/S0045-7825(94)80029-4; BUNGARTZ HJ, 1998, LECT NOTES COMPUTATI, V3, P45; Bungartz HJ, 1999, J COMPLEXITY, V15, P167, DOI 10.1006/jcom.1999.0499; Bungartz H.-J., 1992, THESIS TU MUNCHEN; BUNGARTZ HJ, 1994, E W J NUMER MATH, V1, P21; BUNGARTZ HJ, 1992, ITERATIVE METHODS IN LINEAR ALGEBRA, P293; Cherkassky V., 1998, LEARNING DATA CONCEP; Cios K., 1998, DATA MINING METHODS; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Faber G, 1909, MATH ANN, V66, P81; Frank K, 1996, J COMPLEXITY, V12, P17, DOI 10.1006/jcom.1996.0004; Fung G., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347105; GARCKE J, 2000, CLASSIFICATION SPARS; Garcke J, 2000, J COMPUT PHYS, V165, P694, DOI 10.1006/jcph.2000.6627; GARCKE J, 256 SFB U BONN; GARCKE J, 2001, IN PRESS P 7 ACM SIG; Gerstner T, 1998, NUMER ALGORITHMS, V18, P209, DOI 10.1023/A:1019129717644; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; GIROSI F, 1993, 1430 AI MIT ART INT; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; GRIEBEL M, 1993, LECT NOTES COMPUTER, V732, P276; GRIEBEL M, 1995, COMPUTING, V50, P127; Griebel M, 1998, COMPUTING, V61, P151, DOI 10.1007/BF02684411; GRIEBEL M, 1992, LECT NOTES COMPUT SC, V634, P217; Griebel M., 1992, Parallel Processing Letters, V2, DOI 10.1142/S0129626492000180; Griebel M, 2000, CONSTR APPROX, V16, P525, DOI 10.1007/s003650010010; GRIEBEL M, 1995, INT J NUMER METHOD H, V5, P251, DOI 10.1108/EUM0000000004119; GRIEBEL M, 1994, MULTILEVELNETHODEN A; GRIEBEL M., 1995, ADV COMPUT MATH, V4, P171, DOI 10.1007/BF02123478; GRIEBEL M, 1992, ITERATIVE METHODS IN LINEAR ALGEBRA, P263; GRIEBEL M, 1991, NOTE NUM FL, V31, P94; Griebel M, 1999, NUMER MATH, V83, P279, DOI 10.1007/s002110050450; HEGLAND N, 2000, HIGH DIMENSIONAL SMO; Ho T. K., 1996, CHECKERBOARD DATASET; Hoschek Josef, 1992, GRUNDLAGEN GEOMETRIS; KAUFMAN L, 1999, ADV KERNEL METHODS S, P146; KNAPEK S, 2000, THESIS U BONN; LEE YJ, 2001, COMPUT OPTIM APPL, V20; Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218; Mangasarian OL, 2001, ADV NEUR IN, V13, P577; MELLI G, DATGEN PROGRAM CREAT; OLSHANSKII MA, 2000, 192 RWTH I GEOM PRAK; OSWALD P, 1991, 1191 FSU; Penny WD, 1999, NEURAL NETWORKS, V12, P877, DOI 10.1016/S0893-6080(99)00040-4; Pflaum C, 1999, NUMER MATH, V84, P327, DOI 10.1007/s002119900119; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Schiekofer T., 1998, THESIS U BONN; Sickel W., 1999, J COMPUT ANAL APPL, V1, P263, DOI 10.1023/A:1021901515213; Singh S, 1998, PATTERN RECOGN LETT, V19, P141, DOI 10.1016/S0167-8655(97)00163-3; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Smolyak S.A., 1963, DOKL AKAD NAUK SSSR, V4, P240; STONE M, 1974, J R STAT SOC B, V36, P111; Stuben K., 1999, 53 GMD; Taylor C.C., 1994, MACHINE LEARNING NEU; TEMLYAKOV VN, 1989, P STEKL I MATH, V1; Tikhonov AN, 1977, SOLUTIONS ILL POSED; UTERAS F, 1979, SMOOTHING TECHNIQUES, P196; VAPNIAK VN, 1982, ESTIMATION DEPENDENC; Vapnik V.N., 1995, NATURE STAT LEARNING; WAHBA G, 1985, ANN STAT, V13, P1378, DOI 10.1214/aos/1176349743; Wahba G., 1990, SERIES APPL MATH, V59; WIELAND A, SPIRAL DATA SET; YSERENTANT H, 1993, P ICIAM 91 WASH 1991; YSERENTANT H, 1986, NUMER MATH, V49, P379, DOI 10.1007/BF01389538; ZENGER C, 1991, NOTES NUM FLUID MECH, V31	77	34	34	SPRINGER-VERLAG WIEN	VIENNA	SACHSENPLATZ 4-6, PO BOX 89, A-1201 VIENNA, AUSTRIA	0010-485X		COMPUTING	Computing		2001	67	3					225	253		10.1007/s006070170007		29	Computer Science, Theory & Methods	Computer Science	507EM	WOS:000173014100003	
