PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT	PM
J	Koulman, A; Tapper, BA; Fraser, K; Cao, MS; Lane, GA; Rasmussen, S				Koulman, Albert; Tapper, Brian A.; Fraser, Karl; Cao, Mingshu; Lane, Geoffrey A.; Rasmussen, Susanne			High-throughput direct-infusion ion trap mass spectrometry: a new method for metabolomics	RAPID COMMUNICATIONS IN MASS SPECTROMETRY			English	Article							ERGOT ALKALOIDS; GRASS; FESCUE	A fast method was developed to directly infuse raw plant extracts into a linear ion trap mass spectrometer, using the ion trap to isolate and fragment as many ions as possible from the extract. The full mass spectra can be analysed by multivariate statistics to determine discriminating ions, and the fragmentation data allows rapid classification or identification of these ions. The methodology was used to screen a wide range of strains of endophytic fungi in perennial ryegrass seeds for differences in metabolic profiles. The results show that this newly developed methodology is able to determine discriminating ions that can be present in very low concentrations. It also yielded sufficient fragmentation data to classify or identify the discriminating ions. Copyright (c) 2007 John Wiley & Sons, Ltd.	AgRes Grasslands Res Ctr, Palmerston North, New Zealand	Koulman, A (reprint author), AgRes Grasslands Res Ctr, Private Bag 11008, Palmerston North, New Zealand.	albert.koulman@agresearch.co.nz	Koulman, Albert/B-2967-2009; Koulman, Albert/	Koulman, Albert/0000-0001-9998-051X			BACON CW, 1995, J ANIM SCI, V73, P861; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUSH LP, 1993, AGR ECOSYST ENVIRON, V44, P81, DOI 10.1016/0167-8809(93)90040-V; Enot DP, 2006, P NATL ACAD SCI USA, V103, P14865, DOI 10.1073/pnas.0605152103; Koulman A, 2007, PHYTOCHEMISTRY, V68, P355, DOI 10.1016/j.phvtochem.2006.10.012; LANE GA, 2000, MICROBIAL ENDOPHYTES, P34; Lehner AF, 2005, J MASS SPECTROM, V40, P1484, DOI 10.1002/jms.933; Lehner AF, 2004, J MASS SPECTROM, V39, P1275, DOI 10.1002/jms.678; ROWAN DD, 1986, J CHEM ECOL, V12, P647, DOI 10.1007/BF01012099; Schardl CL, 2004, ANNU REV PLANT BIOL, V55, P315, DOI 10.1146/annurev.arplant.55.031903.141735; Smedsgaard J, 2004, STUD MYCOL, P243; Smedsgaard J, 2005, J EXP BOT, V56, P273, DOI 10.1093/jxb/eri068; Tor-Agbidye J, 2001, VET HUM TOXICOL, V43, P140; Wilkinson HH, 2000, MOL PLANT MICROBE IN, V13, P1027, DOI 10.1094/MPMI.2000.13.10.1027; Woodfield DR, 2004, NEW ZEAL VET J, V52, P300	15	39	39	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0951-4198			RAPID COMMUN MASS SP	Rapid Commun. Mass Spectrom.		2007	21	3					421	428		10.1002/rcm.2854		8	Biochemical Research Methods; Chemistry, Analytical; Spectroscopy	Biochemistry & Molecular Biology; Chemistry; Spectroscopy	135WS	WOS:000244185200019	17206744	
J	Li, S; Fedorowicz, A; Andrew, ME				Li, S.; Fedorowicz, A.; Andrew, M. E.			A new descriptor selection scheme for SVM in unbalanced class problem: a case study using skin sensitisation dataset	SAR AND QSAR IN ENVIRONMENTAL RESEARCH			English	Article						support vector machine; variable selection; unbalanced data; Fisher's linear; discriminant analysis; skin sensitisation		A novel descriptor selection scheme for Support Vector Machine (SVM) classification method has been proposed and its utility demonstrated using a skin sensitisation dataset as an example. A backward elimination procedure, guided by mean accuracy (the average of specificity and sensitivity) of a leave-one-out cross validation, is devised for the SVM. Subsets of descriptors were first selected using a sequential t-test filter or a Random Forest filter, before backward elimination was applied. Different kernels for SVM were compared using this descriptor selection scheme. The Radial Basis Function (RBF) kernel worked best when a sequential t-test filter was adopted. The highest mean accuracy, 84.9%, was obtained using SVM with 23 descriptors. The sensitivity and the specificity were as high as 93.1% and 76.6%, respectively. A linear kernel was found to be optimal when a Random Forest filter was used. The performance using 24 descriptors was comparable with a RBF kernel with a sequential t-test filter. As a comparison, Fisher's linear discriminant analysis (LDA) under the same descriptor selection scheme was carried out. SVM was shown to outperform the LDA.	NIOSH, Div Effects Lab Div, Morgantown, WV 26505 USA; W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA	Li, S (reprint author), NIOSH, Div Effects Lab Div, Morgantown, WV 26505 USA.	swl4@cdc.gov					BASKETTER DA, 2001, CONTACT DERMATITIS, V45, P2; Bennett K. P., 2000, SIGKDD EXPLORATIONS, V2, P1; Biesiada J., 2005, P 4 INT C COMP REC S; BREIMAN L., 2001, MACH LEARN, V45, P1, DOI DOI 10.1023/A:1010933404324; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P2, DOI DOI 10.1023/A:1009715923555; Canu S, 2003, ADV NEURAL INFORM PR, V15; Chapelle O., 2000, ADV NEURAL INFORM PR, V12; CHAWLA NA, 2002, J ARTIF INTELL RES J, V16, P1; CHEN JJ, 2005, SAR QSAR ENVIRON RES, V16, P6; Cortes C., 1995, MACH LEARN, V20, P3; Cristianini N., 2000, INTRO SUPPORT VECTOR; FEDOROWICZ A, 2005, CHEM RES TOXICOL, V18, P6; FROHLICH H, 2004, 2004 IEEE INT JOINT; Guyon I, 2002, MACH LEARN, V46, P1; Hall M. A., 1999, THESIS U WAIKATO; HANEKE KE, 2001, REGUL TOXICOL PHARM, V34, P3; Japkowicz N., 2000, P 2000 INT C ART INT; Kohavi R., 1997, ARTIF INTELL, V97, P1; Lee J. H., 2000, AUTOMATIC MODEL SELE; LI S, 2005, J CHEM INF MODEL, V45, P4; NICKERSON A, 2001, P 8 INT WORKSH AI ST; NIH, 1999, NIH PUBLICATION, V99-4494; SMITH CK, 2001, ALLERGIC CONTACT DER; Smola A., 1998, THESIS TU BERLIN; Vapnik V., 1998, STAT LEARNING THEORY; Venables WN, 1999, MODERN APPL STAT S S; Weston J, 2001, ADV NEUR IN, V13, P668; WHITLEY DC, 2000, J CHEM INF COMP SCI, V40, P5	28	7	7	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1062-936X			SAR QSAR ENVIRON RES	SAR QSAR Environ. Res.		2007	18	5-6					423	441		10.1080/10629360701428474		19	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications; Environmental Sciences; Mathematical & Computational Biology; Toxicology	Chemistry; Computer Science; Environmental Sciences & Ecology; Mathematical & Computational Biology; Toxicology	208BE	WOS:000249294000001	17654333	
S	Kouzani, AZ; Nahavandi, S; Khoshmanesh, K			IEEE	Kouzani, A. Z.; Nahavandi, S.; Khoshmanesh, K.			Face classification by a random forest	TENCON 2007 - 2007 IEEE REGION 10 CONFERENCE, VOLS 1-3	TENCON-IEEE Region 10 Conference Proceedings		English	Proceedings Paper	IEEE Region 10 Conference ( TENCON 2007)	OCT 30-NOV 02, 2007	Taipei, TAIWAN	IEEE			RECOGNITION	This paper presents a random forest-based face image classification method. The random forest is an ensemble learning method that grows many classification trees. Each tree gives a classification. The forest selects the classification that has the most votes. Three experiments are performed. The random forest-based method together with several existing approaches are trained and evaluated. The experimental results are presented and discussed.	[Kouzani, A. Z.; Nahavandi, S.; Khoshmanesh, K.] Deakin Univ, Sch Engn & IT, Geelong, Vic 3217, Australia	Kouzani, AZ (reprint author), Deakin Univ, Sch Engn & IT, Geelong, Vic 3217, Australia.						Basak J, 2006, NEURAL COMPUT, V18, P2062, DOI 10.1162/neco.2006.18.9.2062; BOWYER KW, 2004, P INT C PATT REC, V1, P358; Breiman L., RANDOM FORESTS; Breiman L., 1996, MACHINE LEARNING, V24; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; KIM H, 2002, PATT REC SUPP VECT M; LIAW A, 2002, R NEWS, V2, P1820; Lu JW, 2006, IEEE T NEURAL NETWOR, V17, P166, DOI 10.1109/TNN.2005.860853; Tolba A.S., 2006, INT J SIGNAL PROCESS, V2, P88; Vapnik V.N., 1999, NATURE STAT LEARNING; WANG T, RANDOM FORESTS; *WIK, RAND FOR; YAN R, MATLABARSENAL; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; AT T FACE DATABASE	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0886-1420		978-1-4244-1271-6	TENCON IEEE REGION			2007							652	655				4	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BHW51	WOS:000257059800167		
B	Folleco, A; Khoshgoftaar, TM; Van Hulse, J		Pham, H; Pham, H; Yamada, S		Folleco, Andres; Khoshgoftaar, Taghi M.; Van Hulse, Jason			Software quality classification with imbalanced and noisy data	Thirteenth ISSAT International Conference on Reliability and Quality in Design, Proceedings			English	Proceedings Paper	13th ISSAT International Conference on Reliabitity and Quality in Design	AUG 02-04, 2007	Seattle, WA	Int Soc Sci & Appl Technol		class noise; class imbalance; software quality; noisy class labels; quality prediction performance	TRAINING DATA	The objective of this study is to evaluate the impact of poor data quality on the analysis of software quality prediction models. The reliability and performance analysis of high assurance and mission critical software systems can be significantly affected by the quality of the data. The experimental results in this study demonstrate the dramatic effect of using incorrect class labels on the analysis of software quality classification performance models.	Florida Atlantic Univ, Boca Raton, FL 33431 USA	Khoshgoftaar, TM (reprint author), Florida Atlantic Univ, Boca Raton, FL 33431 USA.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Gamberger D., 1999, P 16 INT C MACH LEAR, P143; Khoshgoftaar TM, 2005, INTELL DATA ANAL, V9, P3; KHOSHGOFTAAR TM, 2003, LECT NOTES ARTIF INT, V1689, P216; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; TAGHI M, 1998, EMPIR SOFTW ENG, V3, P275; TAGHI M, 2004, P 10 INT SOFTW METR, P119; TAGHI M, 2006, P 18 IEEE INT C TOOL, P713; Teng C.M., 1999, P 16 INT C MACH LEAR, P239; Van Hulse J, 2006, INTELL DATA ANAL, V10, P487; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Witten Ian H., 2005, DATA MINING PRACTICA, V2nd; Wohlin C., 2000, EXPT SOFTWARE ENG, pRuneson; YANG Y, 2004, P 8 EUR C PRINC PRAC; Zhu XQ, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P297; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8	17	0	0	INT SOC SCI APPL TECHNOL	PISCATAWAY	36 CARRIAGE DR, PISCATAWAY, NJ 08854 USA			978-0-9763486-2-7				2007							191	195				5	Computer Science, Software Engineering; Engineering, Multidisciplinary; Engineering, Industrial; Engineering, Electrical & Electronic	Computer Science; Engineering	BGU12	WOS:000250541900036		
S	Stiglic, G; Kokol, P		Kokol, P; Podgorelec, V; MiceticTurk, D; Zorman, M; Verlic, M		Stiglic, Gregor; Kokol, Peter			Effectiveness of rotation forest in meta-learning based gene expression classification	Twentieth IEEE International Symposium on Computer-Based Medical Systems, Proceedings	COMPUTER-BASED MEDICAL SYSTEMS : PROCEEDINGS OF THE ANNUAL IEEE SYMPOSIUM		English	Proceedings Paper	20th IEEE International Symposium on Computer-Based Medical Systems	JUN 20-22, 2007	Maribor, SLOVENIA	IEEE Comp Soc TCCM, Fac Elect Engn & Comp Sci, Fac Hlth Sci			SELECTION	A lot of research has been done in the field of assembling classifiers in ensembles and on the other hand selecting the most appropriate single classifiers for a given problem which was solved by ineta-learning techniques. This paper presents application of recently proposed ensemble of classifiers called Rotation Forest to Grading ineta-learning scheme, where it is used as one of the base classifiers and meta-level classifier at the same time. Our proposed Grading variation is compared to four widely used classifiers on 14 datasets from the domain of gene expression classification problems. Experimental evaluations show that using Rotation Forest at meta-level most significantly impacts the accuracy of Grading scheme and confirms that it can be used for estimation of classifiers regions of strong and weak classification.	Univ Maribor, Maribor, Slovenia	Stiglic, G (reprint author), Univ Maribor, Maribor, Slovenia.		Stiglic, Gregor/E-5286-2011				Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; BAY SD, 2000, 17 INT C MACH LEARN, P49; Blake C. L., UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Frank E., 2005, DATA MINING PRACTICA; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings; LEE J, COMPUTATIONAL STAT D, V48, P869; LI J, P IEEE ICDM 2003 C, P585; Liu Huiqing, 2002, Genome Inform, V13, P51; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; SEEWALD AK, 2001, 4 INT C IDA 2001 P S, P115; SYMONS S, MACHINE LEARNING ALG; Vapnik VN, 1998, STAT LEARN THEORY; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; WU W, 2005, BMC BIOINFORMATICS, V6, P1	20	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-7125		978-0-7695-2905-9	COMP MED SY			2007							243	248		10.1109/CBMS.2007.43		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems; Engineering, Biomedical	Computer Science; Engineering	BGL02	WOS:000248094800041		
S	Rigas, G; Katsis, CD; Ganiatsas, G; Fotiadis, DI		Conati, C; McCoy, K; Paliouras, G		Rigas, G.; Katsis, C. D.; Ganiatsas, G.; Fotiadis, D. I.			A user independent, biosignal based, emotion recognition method	User Modeling 2007, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	11th International Conference on User Modeling	JUN 25-29, 2007	Corfu, GREECE	Natl Ctr Sci Res Demokritos, Ionian Univ, User Modeling Inc		emotion recognition; biosignals; classification		A physiological signal based emotion recognition method, for the assessment of three emotional classes: happiness, disgust and fear, is presented. Our approach consists of four steps: (i) biosignal acquisition, (ii) biosignal preprocessing and feature extraction, (iii) feature selection and (iv) classification. The input signals are facial electromyograms, the electrocardiogram, the respiration and the electrodermal skin response. We have constructed a dataset which consists of 9 healthy subjects. Moreover we present preliminary results which indicate on average, accuracy rates of 0.48, 0.68 and 0.69 for recognition of happiness, disgust and fear emotions, respectively.	Univ Ioannina, Dept Comp Sci, Unit Med Technol & Intelligent Informat Syst, GR-45110 Ioannina, Greece	Rigas, G (reprint author), Univ Ioannina, Dept Comp Sci, Unit Med Technol & Intelligent Informat Syst, GR-45110 Ioannina, Greece.						BANG SW, 2004, MED BIOL ENG COMPUTE, V42, P419; BRADLEY M, 1991, VALENCE SPECIFIC HYP; Breiman L., 2001, MACHINE LEARNING, V45; COHEN MH, 1999, IEEE INTELL SYST APP, V14, P8; Darrell T, 2005, NEAREST NEIGHBOR MET; DRYER DC, 1999, 8 INT C HUM COMP INT, P818; FRANK E, 2006, DATA MINING PRACTICA; FUJITA M, 2001, ETHNOLOGICAL MODELIN, P453; GHMAN A, 1988, INT AFFECTIVE PICTUR; GORONZY S, 2004, RECOGNITION USING BI, P36; GREENWALD MK, 1993, LOOKING PICTURES EVA; Katsis C. D., 2006, DIAGNOSTIC PATHOLOGY, V1, P1; Lapatki BG, 2004, J APPL PHYSIOL, V96, P327, DOI 10.1152/japplphysiol.00521.2003; NAVOT A, 2005, 21 INT C MACH LEARN; Pearson K, 1901, PHILOS MAG, V2, P559; Picard R.W., 1995, AFFECTIVE COMPUTING; Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607; SCHELL AM, 2000, HDB PSYCHOPHYSIOLOGY	18	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-73077-4	LECT NOTES ARTIF INT			2007	4511						314	318				5	Computer Science, Artificial Intelligence	Computer Science	BGJ92	WOS:000247845600036		
B	Yun, S; Guo-Ying, M; Yong, Y			IEEE	Yun, Sha; Guo-Ying, Mang; Yong, Yang			A road detection algorithm by boosting using feature combination	2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3			English	Proceedings Paper	IEEE Intelligent Vehicles Symposium	JUN 13-15, 2007	Istanbul, TURKEY	IEEE				Road detection is one of the most important branches of road following. In this paper we propose a classification-based road detection algorithm by boosting. To fully utilize potential region feature correlations and improve the accuracy of classification, this algorithm introduces the feature combination method into road detection. First, an over-completed feature set is constructed on several linear and non-linear combined functions. Second, a correlation feature set is selected from the over-completed feature set by feature selection algorithm. Then, the boosting, the support vector machine and the random forest classifiers are used to evaluate the correlation feature set and the raw feature set. The results of the experiment shows the performance of boosting classifier based on the correlation feature set provides the best outcome.								Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; Bekkerman R., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753625; BERTOZZI M, 2000, ROBOTICS AUTONOMOUS, V32; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang C.C., LIBSVM LIB SUPPORT V; CHEM MY, 2003, 16 IPPR C COMP VIS G; Foedisch M., 2004, P 7 INT IEEE C INT T; FOEDISCH M, 2005, APPROACH KNOWLEDGE B; GUYON I, 2000, BIOWULF TECHNICAL RE; Schafft HA, 1997, MICROELECTRON RELIAB, V37, P3, DOI 10.1016/0026-2714(96)00235-1; Vapnik V., 1998, STAT LEARNING THEORY; VIOLA P, 2001, ICCV WORKSH STAT COM; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; XIAO R, FEATURE SELECTION CO; YING ZG, 2004, J BEIJING I TECHNOLO, V47, P234	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-1067-5				2007							327	331				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Engineering, Mechanical	Computer Science; Engineering	BHC37	WOS:000252173600055		
B	Lee, SM; Kim, DS; Park, JS		Wang, Y; Cheung, YM; Zhang, Q; Wang, PSP		Lee, Sang Min; Kim, Dong Seong; Park, Jong Sou			A hybrid approach for real-time network intrusion detection systems	CIS: 2007 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PROCEEDINGS			English	Proceedings Paper	International Conference on Computational Intelligence and Security	DEC 15-19, 2007	Harbin, PEOPLES R CHINA	Harbin Inst Technol, Guangdong Univ Technol, IEEE Hong Kong, Computat Intelligence Chapter, Hong Kong Baptist Univ, Xidian Univ, IEEE Comp Soc Press				This paper proposes a hybrid approach for real-time Network Intrusion Detection Systems (NIDS). We adopt Random Forest (RF) for feature selection and Minimax Probability Machine (MPM) for intrusion detection. RF provides the variable importance by numeric values so that the irrelevant features can be eliminated However, the NIDS based on RF is slow to build intrusion detection model. We employ MPM, since MPM has been shown a better performance, compared with RF in terms of model building time. To validate the feasibility, we carry out several times of experiments with KDD 1999 intrusion detection dataset. The experimental results show the proposed approach is faster and more lightweight than the previous approaches while guaranteeing high detection rates so that it is suitable for real-time NIDS.								Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; Kim DS, 2005, LECT NOTES COMPUT SC, V3498, P415; Kim DS, 2006, LECT NOTES ARTIF INT, V4293, P632; Kruegel C, 2002, P IEEE S SECUR PRIV, P285, DOI 10.1109/SECPRI.2002.1004378; Park JS, 2005, LECT NOTES COMPUT SC, V3822, P279; SABHNANI M, 2004, J INTELIGENT DATA AN; TAO D, 2005, P 5 IEEE INT C DAT M	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3072-7				2007							712	715				4	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BHI03	WOS:000253372500149		
J	Kelemen, JZ; Kertesz-Farkas, A; Kocsor, A; Puskas, LG				Kelemen, Janos Z.; Kertesz-Farkas, Attila; Kocsor, Andras; Puskas, Laszlo G.			Kalman filtering for disease-state estimation from microarray data	BIOINFORMATICS			English	Article							GENE-EXPRESSION DATA; ARTIFICIAL NEURAL NETWORKS; SUPPORT VECTOR MACHINES; CLASSIFICATION; CANCER; PREDICTION; TRANSLATION; DISCOVERY; LEUKEMIA	Motivation: In this paper, we propose using the Kalman filter (KF) as a pre-processing step in microarray-based molecular diagnosis. Incorporating the expression covariance between genes is important in such classification problems, since this represents the functional relationships that govern tissue state. Failing to fulfil such requirements may result in biologically implausible class prediction models. Here, we show that employing the KF to remove noise (while retaining meaningful covariance and thus being able to estimate the underlying biological state from microarray measurements) yields linearly separable data suitable for most classification algorithms. Results: We demonstrate the utility and performance of the KF as a robust disease-state estimator on publicly available binary and multi-class microarray datasets in combination with the most widely used classification methods to date. Moreover, using popular graphical representation schemes we show that our filtered datasets also have an improved visualization capability. Contact: kelli@nucleus.szbk.u-szeged.hu. Supplementary information: www.inf.u-szeged.hu/similar to kfa/kalman06/	Hungarian Acad Sci, Lab Funct Genom, Biol Res Ctr, H-6726 Szeged, Hungary; Hungarian Acad Sci, Res Grp Artificial Intelligence, H-6720 Szeged, Hungary; Univ Szeged, H-6720 Szeged, Hungary	Kelemen, JZ (reprint author), Hungarian Acad Sci, Lab Funct Genom, Biol Res Ctr, H-6726 Szeged, Hungary.	kelli@nucleus.szbk.u-szeged.hu					Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Baldi P., 2001, BIOINFORMATICS MACHI; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Brunsdon C., 1998, CASE STUDIES VISUALI, P55; Cui QH, 2005, BIOINFORMATICS, V21, P1538, DOI 10.1093/bioinformatics/bti197; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; Grewal M. S., 2001, KALMAN FILTERING; Gribskov M, 1996, COMPUT CHEM, V20, P25, DOI 10.1016/S0097-8485(96)80004-0; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hertz J., 1991, INTRO THEORY NEURAL; Hodges Jr J, 1951, DISCRIMINATORY ANAL; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; Joachims T., 1999, ADV KERNEL METHODS S; Kalman R.E., 1960, T ASME D, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Liao L, 2003, J COMPUT BIOL, V10, P857, DOI 10.1089/106652703322756113; Murvai J, 2001, GENOME RES, V11, P1410, DOI 10.1101/gr.168701; Noble W. S., 2004, KERNEL METHODS COMPU, P71; PIATETSKYSHAPIR.G, 2000, ACM SIGKDD EXPLORATI, V2, P76, DOI 10.1145/380995.381018; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; REMLINGER SK, 2003, INTRO APPL RANDOM FO; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Shi T, 2005, MODERN PATHOL, V18, P547, DOI 10.1038/modpathol.3800322; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1998, STAT LEARNING THEORY; WELCH G, 1995, TR95041 U N CAROLINA; Weston J., 2006, SPIDER; Witten I. H., 1999, DATA MINING PRACTICA; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	37	3	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	DEC 15	2006	22	24					3047	3053		10.1093/bioinformatics/btl545		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	115DO	WOS:000242715200012	17065158	
J	Keefer, CE; Woody, NA				Keefer, Christopher E.; Woody, Nathaniel A.			Rejecting unclassiflable samples with decision forests	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article; Proceedings Paper	9th Scandinavian Symposium on Chemometrics (SSC9)	AUG 21-25, 2005	Reykjavik, ICELAND			decision forest (DF) method; proximity matrix; k-nearest neighbor; "no-class"		Validation of empirical models is designed to produce statistics related to the average error rate of the model. These statistics can be used to minimize errors arising from extrapolation in the Y-values, but pay no attention to the X-block of predicted samples and cannot provide sample specific prediction confidences. In this manuscript, a novel method for identifying potentially poorly classified samples is described that is universal to any Decision Forest method. The samples identified as unclassifiable are assigned a "no-class" assignment and it is shown that these samples have a much higher error rate than samples assigned to a class. These samples are identified by creating a proximity matrix that calculates the similarity of each test sample to each training sample. This similarity is defined in terms of the path samples took through the tree and can be used as a transformed descriptor set for a k-nearest neighbor classifier. The Decision Forest prediction and the k-nearest neighbor prediction can then be combined to assign the sample prediction in such a way that the expected error of the prediction is more accurate. The method is purely automatic and does not require any parameters beyond the determination of k. (c) 2006 Published by Elsevier B.V.	GlaxoSmithKline Inc, Res Triangle Pk, NC 27709 USA	Woody, NA (reprint author), GlaxoSmithKline Inc, 5 Moore Dr, Res Triangle Pk, NC 27709 USA.	Nathaniel.X.Woody@gsk.com					Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 1996, MACH LEARN, V24, P132; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich T.G., 1999, MACH LEARN, P1; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hollenberg PF, 2002, DRUG METAB REV, V34, P17, DOI 10.1081/DMR-120001387; KONG EB, 1996, P 12 NAT C ART INT; Mingers J., 1989, Machine Learning, V3, DOI 10.1007/BF00116837; Pelkonen O, 2002, DRUG METAB REV, V34, P37, DOI 10.1081/DMR-120001388; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; TSYMBAL A, 2003, DIVERSITY ENSEMBLE F; Utgoff PE, 1997, MACH LEARN, V29, P5, DOI 10.1023/A:1007413323501	13	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	DEC 1	2006	84	1-2					40	45		10.1016/j.chemolab.2006.04.013		6	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	115XX	WOS:000242768200007		
J	Willse, A; Kwak, J; Yamazaki, K; Preti, G; Wahl, JH; Beauchamp, GK				Willse, Alan; Kwak, Jae; Yamazaki, Kunio; Preti, George; Wahl, Jon H.; Beauchamp, Gary K.			Individual odortypes: interaction of MHC and background genes	IMMUNOGENETICS			English	Article						MHC; odors; gas chromatography; mass spectrometry; heterozygosity	MAJOR HISTOCOMPATIBILITY COMPLEX; CHEMOSENSORY IDENTITY; URINARY PROTEINS; MOUSE URINE; MICE; IDENTIFICATION; RECOGNITION; DISCRIMINATION; SPECTROMETRY; PHEROMONES	Genes of the major histocompatibility complex (MHC) influence the urinary odors of mice. Behavioral studies have shown (1) that mice differing only at MHC have distinct urinary odors, suggesting an MHC odor phenotype or odortype; (2) that the MHC odortype can be recognized across different background strains; and (3) that the MHC odortype is not an additive trait. Very little is known about the odorants underlying this behavioral phenotype. We compared urinary volatile profiles of two MHC haplotypes (H2(b) and H2(k)) and their heterozygous cross (H2(b) x H2(k)) for two different background strains (C57BL/6J and BALB/c) using solid phase micro-extraction (SPME) headspace analysis and gas chromatography/mass spectrometry (GC/MS). Both MHC and background genes substantially influence the volatile profile. Of 148 compounds screened, 108 of them significantly differ between the six genotypes. Surprisingly, for numerous compounds, their MHC associations are moderated by background genes (i.e., there is a significant MHC x background interaction effect in the statistical model relating genotype to relative compound concentration). These interactions account for nearly 30% of the total genetic effect on the volatile profile. MHC heterozygosity further extends the odortype diversity. For many compounds, the volatile expression for the heterozygote is more extreme than the expression for either homozygote, suggesting a heterozygous-specific odortype. The remarkable breadth of effects of MHC variation on concentrations of metabolites and the interaction between MHC and other genetic variation implies the existence of as yet unknown processes by which variation in MHC genes gives rise to variation in volatile molecules in body fluids.	Pacific NW Natl Lab, Richland, WA 99354 USA; Monell Chem Senses Ctr, Philadelphia, PA 19104 USA; Univ Penn, Sch Med, Dept Dermatol, Philadelphia, PA 19104 USA	Willse, A (reprint author), Pacific NW Natl Lab, 902 Battelle Blvd,POB 999, Richland, WA 99354 USA.	Alan.Willse@pnl.gov	Kwak, Jae/E-5781-2011	Kwak, Jae/0000-0003-4216-2019			ALTMAN PL, 1979, BIOL HDB, V3, P124; Bard J, 2000, IMMUNOGENETICS, V51, P514, DOI 10.1007/s002510000165; BEAUCHAMP GK, 1990, CHEM SIGNAL, V5, P244; Beauchamp GK, 2003, BIOCHEM SOC T, V31, P147; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BENYON RJ, 2003, BIOCHEM SOC T, V31, P142; Boehm T, 2006, TRENDS NEUROSCI, V29, P100, DOI 10.1016/j.tins.2005.11.006; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Culverhouse R, 2004, GENET EPIDEMIOL, V27, P141, DOI 10.1002/gepi.20006; Eggert Frank, 1996, Physiology and Behavior, V59, P57, DOI 10.1016/0031-9384(95)02029-2; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLLEY A, 1974, ANN NY ACAD SCI, V237, P102, DOI 10.1111/j.1749-6632.1974.tb49847.x; Hurst JL, 2001, NATURE, V414, P631, DOI 10.1038/414631a; Kayali-Sayadi MN, 2003, J CHROMATOGR B, V796, P55, DOI 10.1016/j.jchromb.2003.08.001; Legendre P., 1998, NUMERICAL ECOLOGY; Leinders-Zufall T, 2004, SCIENCE, V306, P1033, DOI 10.1126/science.1102818; LIEBICH HM, 1977, BIOMED MASS SPECTROM, V4, P69, DOI 10.1002/bms.1200040202; Malnic B, 1999, CELL, V96, P713, DOI 10.1016/S0092-8674(00)80581-4; McClelland Erin E, 2004, BMC Immunol, V5, P14, DOI 10.1186/1471-2172-5-14; MCLACHLAN G, 2000, FINITE MIXTURE METHO; Novotny MV, 2003, BIOCHEM SOC T, V31, P117; Penn DJ, 2002, P NATL ACAD SCI USA, V99, P11260, DOI 10.1073/pnas.162006499; POTTS WK, 1991, NATURE, V352, P619, DOI 10.1038/352619a0; R Development Core Team, 2004, R LANG ENV STAT COMP; RESTREPO D, 2006, IN PRESS TRENDS NEUR; Robertson DHL, 1996, BIOCHEM J, V316, P265; Singer AG, 1997, P NATL ACAD SCI USA, V94, P2210, DOI 10.1073/pnas.94.6.2210; Thomas DC., 2004, STAT METHODS GENETIC; Thomas L, 1975, 4 INT C IMM, P2; Willse A, 2005, ANAL CHEM, V77, P2348, DOI 10.1021/ac048711t; YAMAGUCHI M, 1981, P NATL ACAD SCI-BIOL, V78, P5817, DOI 10.1073/pnas.78.9.5817; Yamazaki K, 2000, P NATL ACAD SCI USA, V97, P10500, DOI 10.1073/pnas.180320997; YAMAZAKI K, 1994, P NATL ACAD SCI USA, V91, P3735, DOI 10.1073/pnas.91.9.3735; YAMAZAKI K, 1986, P NATL ACAD SCI USA, V83, P4438, DOI 10.1073/pnas.83.12.4438; YAMAZAKI K, 1983, P NATL ACAD SCI-BIOL, V80, P5685, DOI 10.1073/pnas.80.18.5685; YAMAZAKI K, 1979, J EXP MED, V150, P755, DOI 10.1084/jem.150.4.755; YAMAZAKI K, 1984, J MOL CELL IMMUNOL, V1, P79; Yamazaki K., 1981, BIOCH TASTE OLFACTIO, P85; YAMAZAKI K, 1976, J EXP MED, V144, P1324, DOI 10.1084/jem.144.5.1324	39	32	33	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0093-7711			IMMUNOGENETICS	Immunogenetics	DEC	2006	58	12					967	982		10.1007/s00251-006-0162-x		16	Genetics & Heredity; Immunology	Genetics & Heredity; Immunology	120GQ	WOS:000243072900004	17089117	
J	Wang, LY; Comaniciu, D; Fasulo, D				Wang, Lu-Yong; Comaniciu, Dorin; Fasulo, Daniel			Exploiting interactions among polymorphisms contributing to complex disease traits with boosted generative modeling	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						genotype; complex traits; genetic heterogeneity; boosting; generative model	MULTIFACTOR-DIMENSIONALITY REDUCTION; GENE-GENE INTERACTIONS; RANDOM FORESTS; ASSOCIATION; FUTURE	Although there has been great success in identifying disease genes for simple, monogenic Mendelian traits, deciphering the genetic mechanisms involved in complex diseases remains challenging. One major approach is to identify configurations of interacting factors such as single nucleotide polymorphisms (SNPs) that confer susceptibility to disease. Traditional methods, such as the multiple dimensional reduction method and the combinatorial partitioning method, provide good tools to decipher such interactions amid a disease population with a single genetic cause. However, these traditional methods have not managed to resolve the issue of genetic heterogeneity, which is believed to be a very common phenomenon in complex diseases. There is rarely prior knowledge of the genetic heterogeneity of a disease, and traditional methods based on estimation over the entire population are unlikely to succeed in the presence of heterogeneity. We present a novel Boosted Generative Modeling (BGM) approach for structure-model the interactions leading to diseases in the context of genetic heterogeneity. Our BGM method bridges the ensemble and generative modeling approaches to genetic association studies under a case-control design. Generative modeling is employed to model the interaction network configuration and the causal relationships, while boosting is used to address the genetic heterogeneity problem. We perform our method on simulation data of complex diseases. The results indicate that our method is capable of modeling the structure of interaction networks among disease-susceptible loci and of addressing genetic heterogeneity issues where the traditional methods, such as multiple dimensional reduction method, fail to apply. Our BGM method provides an exploratory tool that identifies the variables (e.g., disease-susceptible loci) that are likely to correlate and contribute to the disease.	Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA	Wang, LY (reprint author), Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA.	luyong.wang@siemens.com					Botstein D, 2003, NAT GENET, V33, P228, DOI 10.1038/ng1090; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brem RB, 2005, NATURE, V436, P701, DOI 10.1038/nature03865; Bureau A, 2005, GENET EPIDEMIOL, V28, P171, DOI 10.1002/gepi.20041; Carlson CS, 2004, NATURE, V429, P446, DOI 10.1038/nature02623; Frankel WN, 1996, NAT GENET, V14, P371, DOI 10.1038/ng1296-371; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; Heckerman D., 1995, MSRTR9506; JENSEN F, 2001, BAYESIAN NETWORKS DE; Li WT, 2000, HUM HERED, V50, P334, DOI 10.1159/000022939; Lunetta KL, 2004, BMC GENET, V5, DOI 10.1186/1471-2156-5-32; MOORE J, 2003, HUM HERED, V56, P74; Moore JH, 2002, ANN MED, V34, P88, DOI 10.1080/07853890252953473; NELSON M, 2001, GENOME RES, V11, P2115; Nothnagel M, 2002, AM J HUM GENET S, V71, pA2363; OTT J, 2003, NAT REV, V4, P701; Phillips PC, 1998, GENETICS, V149, P1167; PROVINCE M, 2001, ADV GENET, P273; Risch N, 1996, SCIENCE, V273, P1516, DOI 10.1126/science.273.5281.1516; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Rodin A, 2005, J COMPUT BIOL, V12, P1, DOI 10.1089/cmb.2005.12.1; Ruczinski I, 2004, J MULTIVARIATE ANAL, V90, P178, DOI 10.1016/j.jmva.2004.02.010; Templeton A.R., 2000, EPISTASIS COMPLEX TR; Weiss KM, 2002, TRENDS GENET, V18, P19, DOI 10.1016/S0168-9525(01)02550-1	28	4	4	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277			J COMPUT BIOL	J. Comput. Biol.	DEC	2006	13	10					1673	1684		10.1089/cmb.2006.13.1673		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	131CV	WOS:000243846600002	17238838	
J	Han, PF; Zhang, XZ; Norton, RS; Feng, ZP				Han, Pengfei; Zhang, Xiuzhen; Norton, Raymond S.; Feng, Zhi-Ping			Predicting disordered regions in proteins based on decision trees of reduced amino acid composition	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						intrinsically unstructured proteins; disordered region; decision tree; reduced amino acid composition	FUNCTION NEURAL-NETWORK; INTRINSIC DISORDER; STRUCTURAL PROTEOMICS; SEQUENCE	Intrinsically unstructured proteins (IUPs) are proteins lacking a fixed three dimensional structure or containing long disordered regions. IUPs play an important role in biology and disease. Identifying disordered regions in protein sequences can provide useful information on protein structure and function, and can assist high-throughput protein structure determination. In this paper we present a system for predicting disordered regions in proteins based on decision trees and reduced amino acid composition. Concise rules based on biochemical properties of amino acid side chains are generated for prediction. Coarser information extracted from the composition of amino acids can not only improve the prediction accuracy but also increase the learning efficiency. In cross-validation tests, with four groups of reduced amino acid composition, our system can achieve a recall of 80% at a 13% false positive rate for predicting disordered regions, and the overall accuracy can reach 83.4%. This prediction accuracy is comparable to most, and better than some, existing predictors. Advantages of our approach are high prediction accuracy for long disordered regions and efficiency for large-scale sequence analysis. Our software is freely available for academic use upon request.	Walter & Eliza Hall Inst Med Res, Parkville, Vic 3050, Australia; RMIT Univ, Sch Comp Sci & IT, Melbourne, Vic, Australia	Feng, ZP (reprint author), Walter & Eliza Hall Inst Med Res, Parkville, Vic 3050, Australia.	feng@wehi.edu.au					Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cheng JL, 2005, DATA MIN KNOWL DISC, V11, P213, DOI 10.1007/s10618-005-0001-y; Coeytaux K, 2005, BIOINFORMATICS, V21, P1891, DOI 10.1093/bioinformatics/bti266; DAILY KM, 2005, 2005 IEEE S COMPUT I, P475; Dayhoff M.O., 1978, ATLAS PROTEIN SEQ S3, P345; Dunker AK, 2001, J MOL GRAPH MODEL, V19, P26, DOI 10.1016/S1093-3263(00)00138-8; DUNKER AK, 2002, ADV PROTEIN CHEM, V62, P26; HAN P, 2005, P AUSDM05, P131; Hansen JC, 2006, J BIOL CHEM, V281, P1853, DOI 10.1074/jbc.R500022200; Haynes C, 2006, NUCLEIC ACIDS RES, V34, P305, DOI 10.1093/nar/gkj424; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Jones DT, 2003, PROTEINS, V53, P573, DOI 10.1002/prot.10528; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; Li X, 1999, GENOME INFORMATICS, V10, P30; Linding R, 2003, STRUCTURE, V11, P1453, DOI 10.1016/j.str.2003.10.002; Liu JF, 2002, J MOL BIOL, V322, P53, DOI 10.1016/S0022-2836(02)00736-2; Liu JF, 2003, NUCLEIC ACIDS RES, V31, P3833, DOI 10.1093/nar/gkg515; MADIA KV, 1979, MULTIVARIATE ANAL; Michell T.M., 1997, MACHINE LEARNING; Obradovic Z, 2003, PROTEINS, V53, P566, DOI 10.1002/prot.10532; OBRADOVIC Z, 2005, PROTEIN-STRUCT FUNCT, V7, P176; Oldfield CJ, 2005, PROTEINS, V59, P444, DOI 10.1002/prot.20446; Peng Kang, 2005, Journal of Bioinformatics and Computational Biology, V3, P35, DOI 10.1142/S0219720005000886; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Radivojac Predrag, 2003, Pac Symp Biocomput, P216; Romero P, 1998, Pac Symp Biocomput, P437; Romero P, 2001, PROTEINS, V42, P38, DOI 10.1002/1097-0134(20010101)42:1<38::AID-PROT50>3.0.CO;2-3; Thomson R, 2004, LECT NOTES COMPUT SC, V3177, P108; Thomson R, 2003, BIOINFORMATICS, V19, P1741, DOI 10.1093/bioinformatics/btg237; Uversky VN, 2002, EUR J BIOCHEM, V269, P2, DOI 10.1046/j.0014-2956.2001.02649.x; Uversky VN, 2000, PROTEINS, V41, P415, DOI 10.1002/1097-0134(20001115)41:3<415::AID-PROT130>3.0.CO;2-7; Uversky VN, 2005, J MOL RECOGNIT, V18, P343, DOI 10.1002/jmr.747; Vucetic S, 2003, PROTEINS, V52, P573, DOI 10.1002/prot.10437; Vucetic S, 2005, BIOINFORMATICS, V21, P137, DOI 10.1093/bioinformatics/bth476; Ward JJ, 2004, BIOINFORMATICS, V20, P2138, DOI 10.1093/bioinformatics/bth195; Ward JJ, 2004, J MOL BIOL, V337, P635, DOI 10.1016/j.jmb.2004.02.002; Weathers EA, 2004, FEBS LETT, V576, P348, DOI 10.1016/j.febslet.2004.09.036; Yang ZR, 2005, BIOINFORMATICS, V21, P3369, DOI 10.1093/bioinformatics/bti534	39	6	6	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277			J COMPUT BIOL	J. Comput. Biol.	DEC	2006	13	10					1723	1734		10.1089/cmb.2006.13.1723		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	131CV	WOS:000243846600005	17238841	
J	Klema, J; Almonayyes, A				Klema, Jiri; Almonayyes, Ahmad			Automatic categorization of fanatic text using random forests	KUWAIT JOURNAL OF SCIENCE & ENGINEERING			English	Article						data mining; machine learning; random forest; text classification		This paper presents a study of the task of classification and analysis of fanatic texts. The analyzed set of texts stems from an Arabic environment in Kuwait, where teachers and students were asked questions regarding various terrorist tendencies. The responses were assigned by a domain expert into one of three classes with respect to degree of fanaticism of their content. The main task was to grasp the implicit expert's knowledge and distinguish the documents according to their content. The paper deals with the bag-of-words representation of the documents. It applies learning algorithms that proved to work well in the field of text classification (TFIDF classifier, multinomial probabilistic model) as well as the random forest classifier that is well-known to cope with domains described by a large number of features. The associated task is to discover any knowledge helping to understand the domain. For this reason, the final models were also analyzed and used to reveal inherent structure inside the set of documents (a sub-class structure) or to identify important words and their possible relations.	Kuwait Univ, Dept Math & Comp Sci, Safat, Kuwait; Czech Tech Univ, Dept Cybernet, Prague 16627, Czech Republic	Almonayyes, A (reprint author), Kuwait Univ, Dept Math & Comp Sci, Safat, Kuwait.	klema@labe.felk.cvut.cz; sami@mcs.sci.kuniv.edu.kw					Branting L.K., 2003, P 9 INT C ART INT IC, P224, DOI 10.1145/1047788.1047837; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREMAN L, 1984, CLAASSIFICATION REGR; Cohen W, 1996, P 19 ANN INT ACM SIG, P307, DOI 10.1145/243199.243278; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Frasconi P, 2002, J INTELL INF SYST, V18, P195, DOI 10.1023/A:1013681528748; Hastie T., 2001, ELEMENTS STAT LEARNI; Joachims T, 1997, P 14 INT C MACH LEAR, P143; Joachims T., 1998, P ECML 98 10 EUR C M; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Manning Christopher D., 2001, FDN STAT NATURAL LAN; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Salton G., 1975, J AM SOC INFORM SCI, V18, P613; Vapnik VN, 1995, NATURE STAT LEARNING; Witten I., 2000, DATA MINING PRACTICA; Xia YQ, 2005, LECT NOTES COMPUT SC, V3406, P723; Zelikovitz S., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management	18	0	0	ACADEMIC PUBLICATION COUNCIL	KHALDIYA	PO BOX 17225, KHALDIYA 72453, KUWAIT	1024-8684			KUWAIT J SCI ENG	Kuwait J. Sci. Eng.	DEC	2006	33	2					1	18				18	Multidisciplinary Sciences	Science & Technology - Other Topics	128BL	WOS:000243630600001		
J	Kurgan, LA; Homaeian, L				Kurgan, Lukasz A.; Homaeian, Leila			Prediction of structural classes for protein sequences and domains - Impact of prediction algorithms, sequence representation and homology, and test procedures on accuracy	PATTERN RECOGNITION			English	Article						protein structural class; SCOP; machine learning; homology; prediction; secondary protein structure	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; SECONDARY STRUCTURE; GLOBULAR-PROTEINS; HELIX/STRAND CONTENT; NEURAL-NETWORKS; FOLDING TYPES; RECOGNITION; CLASSIFICATION; DATABASES	This paper addresses computational prediction of protein structural classes. Although in recent years progress in this field was made, the main drawback of the published prediction methods is a limited scope of comparison procedures, which in same cases were also improperly performed. Two examples include using protein datasets of varying homology, which has significant impact on the prediction accuracy, and comparing methods in pairs using different datasets. Based on extensive experimental work, the main aim of this paper is to revisit and reevaluate state of the art in this field. To this end, this paper performs a first-of-its-kind comprehensive and multi-goal study, which includes investigation of eight prediction algorithms, three protein sequence representations, three datasets with different homologies and finally three test procedures. Quality of several previously unused prediction algorithms, newly proposed sequence representation, and a new-to-the-field testing procedure is evaluated. Several important conclusions and findings are made. First, the logistic regression classifier, which was not previously used, is shown to perform better than other prediction algorithms, and high quality of previously used support vector machines is confirmed. The results also show that the proposed new sequence representation improves accuracy of the high quality prediction algorithms, while it does not improve results of the lower quality classifiers. The study shows that commonly used jackknife test is computationally expensive, and therefore computationally less demanding 10-fold cross-validation procedure is proposed. The results show that there is no statistically significant difference between these two procedures. The experiments show that sequence homology has very significant impact on the prediction accuracy, i.e. using highly homologous datasets results in higher accuracies. Thus, results of several past studies that use homologous datasets should not be perceived as reliable. The best achieved prediction accuracy for low homology datasets is about 57% and confirms results reported by Wang and Yuan [How good is the prediction of protein structural class by the component-coupled method?. Proteins 2000;38:165-175]. For a highly homologous dataset instance based classification is shown to be better than the previously reported results. It achieved 97% prediction accuracy demonstrating that homology is a major factor that can result in the overestimated prediction accuracy. (0 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2M7, Canada	Kurgan, LA (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2M7, Canada.	lkurgan@ece.ualberta.ca	Kurgan, Lukasz/B-5721-2009	Kurgan, Lukasz/0000-0002-7749-0314			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, P226; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bu WS, 1999, EUR J BIOCHEM, V266, P1043, DOI 10.1046/j.1432-1327.1999.00947.x; Cai YD, 2003, J THEOR BIOL, V221, P115, DOI 10.1006/jtbi.2003.3179; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1993, J PROTEIN CHEM, V12, P169, DOI 10.1007/BF01026038; Chou KC, 1998, PROTEINS, V31, P97, DOI 10.1002/(SICI)1097-0134(19980401)31:1<97::AID-PROT8>3.0.CO;2-E; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU PY, 1974, BIOCHEMISTRY-US, V13, P211, DOI 10.1021/bi00699a001; Cohens W, 1995, P 12 INT C MACH LEAR, P115; CORNETTE JL, 1987, J MOL BIOL, V195, P659, DOI 10.1016/0022-2836(87)90189-6; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.3.CO;2-B; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Eisenhaber F, 1996, PROTEINS, V25, P157, DOI 10.1002/(SICI)1097-0134(199606)25:2<157::AID-PROT2>3.0.CO;2-F; Eisenhaber F, 1996, PROTEINS, V25, P169, DOI 10.1002/(SICI)1097-0134(199606)25:2<169::AID-PROT3>3.3.CO;2-5; FILKENSTEIN AV, 1971, J MOL BIOL, V62, P613; GANAPATHIRAJU M, 2004, IEEE SIGNAL PROC MAY, P78; Grassmann J, 1999, Proc Int Conf Intell Syst Mol Biol, P106; Grigoriev IV, 1999, P NATL ACAD SCI USA, V96, P14318, DOI 10.1073/pnas.96.25.14318; Gromiha MM, 1998, PROTEIN ENG, V11, P249, DOI 10.1093/protein/11.4.249; Hall M. A., 1999, THESIS U WAIKATO HAM; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Jin LX, 2003, COMPUT BIOL CHEM, V27, P373, DOI 10.1016/S1476-9271(02)00087-7; John G.H., 1995, P 11 C UNC ART INT, P338; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KURGAN LA, 2005, LECT NOTES ARTIF INT, V4587, P334; Leslie C, 2002, PAC S BIOC, P566; LEVITT M, 1976, NATURE, V261, P552, DOI 10.1038/261552a0; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; Lin Z, 2001, J PROTEIN CHEM, V20, P217, DOI 10.1023/A:1010967008838; Liu H., 1996, P 13 INT C MACH LEAR, P319; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Markowetz F, 2003, BIOMETRICAL J, V45, P377, DOI 10.1002/bimj.200390019; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; MUSKAL SM, 1992, J MOL BIOL, V225, P713, DOI 10.1016/0022-2836(92)90396-2; NAKASHIMA H, 1986, J BIOCHEM-TOKYO, V99, P153; OOBATAKE M, 1977, J THEOR BIOL, V67, P567, DOI 10.1016/0022-5193(77)90058-3; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; ROST B, 2000, PROTEIN STRUCTURE PR, P71; Ruan JS, 2005, ARTIF INTELL MED, V35, P19, DOI 10.1016/j.artmed.2005.02.006; SAHA A, 1993, IEEE T COMPUT, V42, P1222, DOI 10.1109/12.257708; Wang ZX, 2000, PROTEINS, V38, P165, DOI 10.1002/(SICI)1097-0134(20000201)38:2<165::AID-PROT5>3.0.CO;2-V; WANG ZX, 2001, PROTEINS, V443, P339; Witten I. H., 1999, DATA MINING PRACTICA; ZHANG CT, 1995, PROTEIN ENG, V8, P425, DOI 10.1093/protein/8.5.425; Zhang CT, 1998, PROTEIN ENG, V11, P971, DOI 10.1093/protein/11.11.971; ZHANG CT, 1992, PROTEIN SCI, V1, P401; Zhang ZD, 2001, J THEOR BIOL, V208, P65, DOI 10.1006/jtbi.2000.2201; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	64	92	95	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	DEC	2006	39	12					2323	2343		10.1016/j.patcog.2006.02.014		21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	095OX	WOS:000241318400007		
J	Lee, JG; Zhang, CS				Lee, Jianguo; Zhang, Changshui			Classification of gene-expression data: The manifold-based metric learning way	PATTERN RECOGNITION			English	Article						gene expression; metric learning; manifold learning; nearest neighbor	SMALL SAMPLES; MICROARRAY; CANCER; PREDICTION; VALIDATION; ALGORITHMS; ERROR	Classification of microarray gene-expression data can potentially help medical diagnosis, and becomes an important topic in bioinformatics. However, microarray data sets are usually of small sample size relative to an overwhelming number of genes. This makes the classification problem fairly challenging. Instance-based learning (IBL) algorithms, such as nearest neighbor (k-NN), are usually the baseline algorithm due to their simplicity. However, practices show that k-NN performs not very well in this field. This paper introduces manifold-based metric learning to improve the performance of IBL methods. A novel metric learning algorithm is proposed by utilizing both local manifold structural information and local discriminant information. In addition, a random subspace extension is also presented. We apply the proposed algorithm to the gene-classification problem in three ways: one in the original feature space, another in the reduced feature space, and the third via the random subspace extension. Statistical evaluation shows that the proposed algorithm can achieve promising results, and gain significant performance improvement over traditional IBL algorithms. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Tsinghua Univ, Dept Automat, Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Lee, JG (reprint author), Tsinghua Univ, Dept Automat, Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	lijg01@mails.tsinghua.edu.cn; zcs@mail.tsinghua.edu.cn					Alon A., 1999, P NATL ACAD SCI USA, V96, P6745; Bar-Hillel A., 2003, P 20 INT C MACH LEAR, P11; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang C. -C., 2004, LIBSVM LIB SUPPORT V; Cover T., 1967, IEEE T INFORM THEORY, V13, P57; Dougherty ER, 2001, COMPAR FUNCT GENOM, V2, P28, DOI 10.1002/cfg.62; Efron B., 1982, JACKKNIFE BOOTSTRAP; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Girolami M, 1998, NEURAL COMPUT, V10, P2103, DOI 10.1162/089976698300016981; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gray A., 1993, MODERN DIFFERENTIAL; Hall M, 2003, IEEE T KNOWL DATA EN, V15, P1; HASTIE T, 1996, IEEE T PATTERN ANAL, V18, P409; Hastie T., 1995, V7, P999; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HSU JC, 1996, MULTIPLE COMPARISON; Iizuka N, 2003, LANCET, V361, P923, DOI 10.1016/S0140-6736(03)12775-4; KIRA K, 1994, P 9 INT C MACH LEARN, P249; LEE J, 2004, P 21 INT C MACH LEAR, P528; LI S, 2000, IEEE T PATTERN ANAL, V22, P135; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Liu H., 1998, FEATURE SELECTION KN; Mackay DJC, 1998, NATO ADV SCI I D-BEH, V89, P175; Mitchell T. M., 1997, MACHINE LEARNING; Nutt CL, 2003, CANCER RES, V63, P1602; Okun O., 2004, P 2 EUR WORKSH DAT M, P51; Pochet N, 2004, BIOINFORMATICS, V20, P3185, DOI 10.1093/bioinformatics/bth383; Salzberg S., 1991, LNCS, V542, P399; Schapire RE, 1998, ANN STAT, V26, P1651; Schultz M, 2004, ADV NEUR IN, V16, P41; Sima C, 2005, BIOINFORMATICS, V21, P1046, DOI 10.1093/bioinformatics/bti081; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; Simard P.Y., 2001, INT J IMAGING SYSTEM, V11, p[181, 194]; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Theilhaber J, 2002, GENOME RES, V12, P165, DOI 10.1101/gr.182601; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1997, NATURE STAT LEARNING; Vincent P, 2002, ADV NEUR IN, V14, P985; Wolfe DA, 1999, NONPARAMETRIC STAT M, V2nd; WU W, 2005, MC BIOINFORMATICS, V6, P1; Yandell B.S., 1997, PRACTICAL DATA ANAL; Zhang Zhihua, 2003, P 18 INT JOINT C ART, P1450	44	17	19	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	DEC	2006	39	12					2450	2463		10.1016/j.patcog.2006.05.026		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	095OX	WOS:000241318400017		
J	Martinez-Otzeta, JM; Sierra, B; Lazkano, E; Astigarraga, A				Martinez-Otzeta, J. M.; Sierra, B.; Lazkano, E.; Astigarraga, A.			Classifier hierarchy learning by means of genetic algorithms	PATTERN RECOGNITION LETTERS			English	Article						data mining; classifier combination; genetic algorithms	COMBINATION	Classifier combination falls in the so called data mining area. Its aim is to combine some paradigms from the supervised classification - sometimes with a previous non-supervised data division phase - in order to improve the individual accuracy of the component classifiers. Formation of classifier hierarchies is an alternative among the several methods of classifier combination. In this paper we present a novel method to find good hierarchies of classifiers for given databases. In this new proposal, a search is performed by means of genetic algorithms, returning the best individual according to the classification accuracy over the dataset, estimated through 10-fold cross-validation. Experiments have been carried out over 14 databases from the UCI repository, showing an improvement in the performance compared to the single classifiers. Moreover, similar or better results than other approaches, such as decision tree bagging and boosting, have been obtained. (c) 2006 Elsevier B.V. All rights reserved.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, San Sebastian 20018, Basque Country, Spain	Martinez-Otzeta, JM (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, P Manuel Lardizabal 1, San Sebastian 20018, Basque Country, Spain.	ccbmaotj@si.ehu.es	Martinez-Otzeta, Jose Maria/K-6464-2014	Martinez-Otzeta, Jose Maria/0000-0001-5015-1315			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Freitas A.A., 2002, DATA MINING KNOWLEDG; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; GAMA JM, 2002, THESIS U PORTO; Goldberg D, 1989, GENETIC ALGORITHMS S; Gunes V, 2003, INT J PATTERN RECOGN, V17, P1303, DOI 10.1142/S0218001403002897; HEISELE B, 2001, INT C COMP VIS PATT, P18; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; Lu Y, 1996, APPL INTELL, V6, P75, DOI 10.1007/BF00117809; MINSKY M, 1961, P IRE, V49, P8, DOI 10.1109/JRPROC.1961.287775; Mitchell T. M., 1997, MACHINE LEARNING; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sierra B, 1998, ARTIF INTELL MED, V14, P215, DOI 10.1016/S0933-3657(98)00024-4; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	21	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC	2006	27	16					1998	2004		10.1016/j.patrec.2006.06.001		7	Computer Science, Artificial Intelligence	Computer Science	101DH	WOS:000241718600015		
J	Hettick, JM; Kashon, ML; Slaven, JE; Ma, Y; Simpson, JP; Siegel, PD; Mazurek, GN; Weissman, DN				Hettick, Justin M.; Kashon, Michael L.; Slaven, James E.; Ma, Yan; Simpson, Janet P.; Siegel, Paul D.; Mazurek, Gerald N.; Weissman, David N.			Discrimination of intact mycobacteria at the strain level: A combined MALDI-TOF MS and biostatistical analysis	PROTEOMICS			English	Article						linear discriminant analysis; MALDI; MS; mycobacteria; random forests	TIME-OF-FLIGHT; LASER-DESORPTION/IONIZATION-TIME; PERFORMANCE LIQUID-CHROMATOGRAPHY; TRANSFORM MASS-SPECTROMETRY; DESORPTION IONIZATION; SAMPLE PREPARATION; MYCOLIC ACIDS; BACTERIA; REPRODUCIBILITY; TUBERCULOSIS	New methodologies for surveillance and identification of Mycobacterium tuberculosis are required to stem the spread of disease worldwide. In addition, the ability to discriminate mycobacteria at the strain level may be important to contact or source case investigations. To this end, we are developing MALDI-TOF MS methods for the identification of M. tuberculosis in culture. In this report, we describe the application of MALDI-TOF MS, as well as statistical analysis including linear discriminant and random forest analysis, to 16 medically relevant strains from four species of mycobacteria, M. tuberculosis, M. avium, M. intracellulare, and M. kansasii. Although species discrimination can be accomplished on the basis of unique m/z values observed in the MS fingerprint spectrum, discrimination at the strain level is predicted on the relative abundance of shared m/z values among strains within a species. For the 16 mycobacterial strains investigated in the present study, it is possible to unambiguously identify strains within a species on the basis of MALDI-TOF MS data. The error rate for classification of individual strains using linear discriminant analysis was 0.053 using 37 m/z variables, whereas the error rate for classification of individual strains using random forest analysis was 0.023 using only 18 m/z variables. In addition, using random forest analysis of MALDI-TOF MS data, it was possible to correctly classify bacterial strains as either M. tuberculosis or non-tuberculous with 100% accuracy.	Ctr Dis Control & Prevent, HELD, ACIB, NIOSH, Morgantown, WV 26505 USA; Ctr Dis Control & Prevent, Natl Ctr HIV STD & TB Prevent, Div TB Eliminat, Atlanta, GA USA; Ctr Dis Control & Prevent, NIOSH, Div Resp Dis Studies, Morgantown, WV 26505 USA; W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA	Hettick, JM (reprint author), Ctr Dis Control & Prevent, HELD, ACIB, NIOSH, 1095 Willowdale Rd, Morgantown, WV 26505 USA.	jhettick@cdc.gov	Hettick, Justin/E-9955-2010				Barry CE, 1998, PROG LIPID RES, V37, P143, DOI 10.1016/S0163-7827(98)00008-3; BEAVIS RC, 1988, CHEM PHYS LETT, V146, P310, DOI 10.1016/0009-2614(88)87450-5; Benson Constance A., 2004, Morbidity and Mortality Weekly Report, V53, P1; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUTLER WR, 1991, J CLIN MICROBIOL, V29, P2468; CASTORO JA, 1993, ANAL CHEM, V65, P2621, DOI 10.1021/ac00067a013; Cotter RJ, 1999, ANAL CHEM, V71, p445A, DOI 10.1021/ac9904617; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Domin MA, 1999, RAPID COMMUN MASS SP, V13, P222, DOI 10.1002/(SICI)1097-0231(19990228)13:4<222::AID-RCM440>3.0.CO;2-Y; Dye C, 1999, JAMA-J AM MED ASSOC, V282, P677, DOI 10.1001/jama.282.7.677; EISENACH KD, 1990, J INFECT DIS, V161, P977; Fenselau C, 2001, MASS SPECTROM REV, V20, P157, DOI 10.1002/mas.10004; Gantt SL, 1999, J AM SOC MASS SPECTR, V10, P1131, DOI 10.1016/S1044-0305(99)00086-0; Gentleman R, 2005, BIOINFORMATICS COMPU; HAGEN SR, 1995, J CHROMATOGR A, V692, P167, DOI 10.1016/0021-9673(94)00743-S; Hettick JM, 2001, ANAL CHEM, V73, P5378, DOI 10.1021/ac0102157; Hettick JM, 2004, ANAL CHEM, V76, P5769, DOI 10.1021/ac049410m; HUTCHENS TW, 1993, RAPID COMMUN MASS SP, V7, P576, DOI 10.1002/rcm.1290070703; Iademarco Michael F, 2003, Semin Respir Infect, V18, P225; KARAS M, 1988, ANAL CHEM, V60, P2299, DOI 10.1021/ac00171a028; KARAS M, 1987, INT J MASS SPECTROM, V78, P53, DOI 10.1016/0168-1176(87)87041-6; Kilinc O, 2002, RESP MED, V96, P506, DOI 10.1053/rmed.2002.1315; Koomen JM, 2000, ANAL CHEM, V72, P3860, DOI 10.1021/ac0001941; KOSTER C, 1992, J AM CHEM SOC, V114, P7572, DOI 10.1021/ja00045a045; Lay JO, 2001, MASS SPECTROM REV, V20, P172, DOI 10.1002/mas.10003; Merchant M, 2000, ELECTROPHORESIS, V21, P1164, DOI 10.1002/(SICI)1522-2683(20000401)21:6<1164::AID-ELPS1164>3.3.CO;2-S; Ramirez J, 2001, J MASS SPECTROM, V36, P929, DOI 10.1002/jms.196; Saenz AJ, 1999, RAPID COMMUN MASS SP, V13, P1580, DOI 10.1002/(SICI)1097-0231(19990815)13:15<1580::AID-RCM679>3.0.CO;2-V; Smole SC, 2002, J MICROBIOL METH, V48, P107, DOI 10.1016/S0167-7012(01)00315-3; Steenland K, 1997, AM J PUBLIC HEALTH, V87, P2012, DOI 10.2105/AJPH.87.12.2012; van Baar BLM, 2000, FEMS MICROBIOL REV, V24, P193, DOI 10.1016/S0168-6445(99)00036-4; Wang ZP, 1998, RAPID COMMUN MASS SP, V12, P456, DOI 10.1002/(SICI)1097-0231(19980430)12:8<456::AID-RCM177>3.0.CO;2-U; Williams TL, 2003, J AM SOC MASS SPECTR, V14, P342, DOI 10.1016/S1044-0305(03)00065-5; 2005, MMWR MORB MORTL WKLY, V54, P245	35	65	68	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853			PROTEOMICS	Proteomics	DEC	2006	6	24					6416	6425		10.1002/pmic.200600335		10	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	123DW	WOS:000243277500005	17109381	
J	Zhang, QY; Aires-de-Sousa, J				Zhang, Qing-You; Aires-de-Sousa, Joao			Physicochemical stereodescriptors of atomic chiral centers	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							MOLECULAR CHIRALITY; MODEL BUILDERS; PREDICTION; DESCRIPTORS; CLASSIFICATION; SELECTIVITY; REVISION; CODES	Physicochemical atomic stereodescriptors (PAS) were implemented that represent the chirality of an atomic chiral center on the basis of empirical physicochemical properties of the ligands. The ligands are ranked according to a specific property, and the chiral center takes an S/R-like descriptor relative to that property. The procedure is performed for a series of properties, yielding a chirality profile. Application of the PAS descriptors to the prediction of enantioselectivity in chemical reactions, from the molecular structures, is illustrated here. The relationship between the molecular structures, represented by the PAS descriptors, and the enantioselectivity was learned by neural networks, decision trees, or random forests. In a first application, a data set was employed with chiral amino alcohols that enantioselectively catalyze the addition of diethylzinc to benzaldehyde. Prediction of the major enantiomer obtained in the reaction, from the molecular structure of the catalyst, was achieved with accuracy up to 90%. The second application investigated the enantiopreference of Pseudomonas cepacia lipase (PCL) toward primary alcohols. The learned models could make correct predictions about the preferred enantiomer, from the molecular structure of the substrate, in up to 93% of the cases. These included substrates with and without O-atoms bonded to the chiral center. The properties automatically selected to build the models can give indications on the relevant factors guiding the observed chemical behavior.	Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Quim, CQFB & REQUIMTE, P-2829516 Caparica, Portugal	Aires-de-Sousa, J (reprint author), Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Quim, CQFB & REQUIMTE, P-2829516 Caparica, Portugal.	jas@fct.unl.pt	Aires-de-Sousa, Joao/C-7826-2013; REQUIMTE, AL/H-9106-2013; REQUIMTE, ORG/M-4578-2013; REQUIMTE, LAQV/N-9835-2013	Aires-de-Sousa, Joao/0000-0002-5887-2966; 			Aires-de-Sousa J, 2001, J CHEM INF COMP SCI, V41, P369, DOI 10.1021/ci000125n; Aires-de-Sousa J, 2002, J MOL GRAPH MODEL, V20, P373, DOI 10.1016/S1093-3263(01)00136-X; Aires-de-Sousa J, 2005, J COMB CHEM, V7, P298, DOI 10.1021/cc049961q; Aires-De-Sousa J, 2004, J CHEM INF COMP SCI, V44, P831, DOI 10.1021/ci030410h; Aires-de-Sousa J., 2003, HDB CHEMOINFORMATICS, V3, P1062; Breiman L., 2000, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Caetano S, 2005, ANAL CHIM ACTA, V544, P315, DOI 10.1016/j.aca.2004.12.012; CAHN RS, 1966, ANGEW CHEM INT EDIT, V5, P385, DOI 10.1002/anie.196603851; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; Gasteiger J, 1988, PHYSICAL PROPERTY PR, P119; Gasteiger J., 1990, TETRAHEDRON COMPUT M, V3, P537, DOI DOI 10.1016/0898-5529(90)90156-3; Golbraikh A, 2001, J CHEM INF COMP SCI, V41, P147, DOI 10.1021/ci000082a; Julian-Ortiz JV, 1998, J MOL GRAPH MODEL, V16, P14; Kohonen T., 1989, SELF ORG ASSOCIATIVE; Kovatcheva A, 2005, SAR QSAR ENVIRON RES, V16, P93, DOI 10.1080/10629360412331319844; Lukovits I, 2001, J CHEM INF COMP SCI, V41, P1517, DOI 10.1021/ci0100346; MATA P, 1993, TETRAHEDRON-ASYMMETR, V4, P657, DOI 10.1016/S0957-4166(00)80173-1; MOSIER PD, 1998, 1 IND US WORKSH MATH; PRELOG V, 1982, ANGEW CHEM INT EDIT, V21, P567, DOI 10.1002/anie.198205671; R Development Core Team R, LANG ENV STAT COMP; SADOWSKI J, 1994, J CHEM INF COMP SCI, V34, P1000, DOI 10.1021/ci00020a039; SADOWSKI J, 1993, CHEM REV, V93, P2567, DOI 10.1021/cr00023a012; SADOWSKI J, 1992, ANAL CHIM ACTA, V265, P233, DOI 10.1016/0003-2670(92)85029-6; SCHULTZ HP, 1995, J CHEM INF COMP SCI, V35, P864, DOI 10.1021/ci00027a011; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; WEISSFLOCH ANE, 1995, J ORG CHEM, V60, P6959, DOI 10.1021/jo00126a056; Zhang QY, 2005, J ORG CHEM, V70, P2120, DOI 10.1021/jo048029z; Zupan J., 1999, NEURAL NETWORKS CHEM	29	14	17	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	NOV 27	2006	46	6					2278	2287		10.1021/ci600235w		10	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	109HF	WOS:000242298100008	17125170	
J	Cannon, EO; Bender, A; Palmer, DS; Mitchell, JBO				Cannon, Edward O.; Bender, Andreas; Palmer, David S.; Mitchell, John B. O.			Chemoinformatics-based classification of prohibited substances employed for doping in sport	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							MOLECULAR SIMILARITY; CHEMICAL-STRUCTURE; DRUG DISCOVERY; DESCRIPTORS; DATABASES; 2D	Representative molecules from 10 classes of prohibited substances were taken from the World Anti-Doping Agency (WADA) list, augmented by molecules from corresponding activity classes found in the MDDR database. Together with some explicitly allowed compounds, these formed a set of 5245 molecules. Five types of fingerprints were calculated for these substances. The random forest classification method was used to predict membership of each prohibited class on the basis of each type of fingerprint, using 5-fold cross-validation. We also used a k-nearest neighbors (kNN) approach, which worked well for the smallest values of k. The most successful classifiers are based on Unity 2D fingerprints and give very similar Matthews correlation coefficients of 0.836 (kNN) and 0.829 (random forest). The kNN classifiers tend to give a higher recall of positives at the expense of lower precision. A naive Bayesian classifier, however, lies much further toward the extreme of high recall and low precision. Our results suggest that it will be possible to produce a reliable and quantitative assignment of membership or otherwise of each class of prohibited substances. This should aid the fight against the use of bioactive novel compounds as doping agents, while also protecting athletes against unjust disqualification.	Univ Cambridge, Dept Chem, Unilever Ctr Mol Sci Informat, Cambridge CB2 1EW, England	Mitchell, JBO (reprint author), Univ Cambridge, Dept Chem, Unilever Ctr Mol Sci Informat, Lensfield Rd, Cambridge CB2 1EW, England.	jbom1@cam.ac.uk	Bender, Andreas/C-6942-2009; Mitchell, John/F-9863-2010	Bender, Andreas/0000-0002-6683-7546; Mitchell, John/0000-0002-0379-6097			Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; BENDER A, 2006, ANN REP COMPUT CHEM, V2, P145; BENDER A, 2005, THESIS U CAMBRIDGE U; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brooks R V, 1975, Br J Sports Med, V9, P89; BURBRIDGE R, 2001, INTRO SUPPORT VECTOR; Burset M, 1996, GENOMICS, V34, P353, DOI 10.1006/geno.1996.0298; Death AK, 2004, J CLIN ENDOCR METAB, V89, P2498, DOI 10.1210/jc.2004-0033; DOWNS GM, 1994, J CHEM INF COMP SCI, V34, P1094, DOI 10.1021/ci00021a011; Duckworth FC, 1998, J OPER RES SOC, V49, P220; Estrada E, 2001, CURR MED CHEM, V8, P1573; FAULON JL, 1994, J CHEM INF COMP SCI, V34, P1204, DOI 10.1021/ci00021a031; Itskowitz P, 2005, J CHEM INF MODEL, V45, P777, DOI 10.1021/ci049628+; KONTAXAKIS SG, 2002, P 4 INT C TECHN AUT; Leach A.R., 2003, INTRO CHEMOINFORMATI; Mason JS, 2001, CURR PHARM DESIGN, V7, P567, DOI 10.2174/1381612013397843; McGregor MJ, 1997, J CHEM INF COMP SCI, V37, P443, DOI 10.1021/ci960151e; Mitchell T. M., 1997, MACHINE LEARNING; *R DEV COR TEAM R, 2005, LANG ENV STAT COMP R; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Todd Jan, 2001, DOPING ELITE SPORT P, P65; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Zhang Q, 2006, J MED CHEM, V49, P1536, DOI 10.1021/jm050468i	27	23	23	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	NOV 27	2006	46	6					2369	2380		10.1021/ci0601160		12	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	109HF	WOS:000242298100018	17125180	
J	Edwards, TC; Cutler, DR; Zimmermann, NE; Geiser, L; Moisen, GG				Edwards, Thomas C., Jr.; Cutler, D. Richard; Zimmermann, Niklaus E.; Geiser, Linda; Moisen, Gretchen G.			Effects of sample survey design on the accuracy of classification tree models in species distribution models	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	2nd Workshop on Advances in Predictive Species Distribution Models	2004	Riederalp, SWITZERLAND			model accuracy; sample survey; study design; classification trees; lichens; accuracy assessment; probability samples; non-probability samples	GENERALIZED ADDITIVE-MODELS; NEW-SOUTH-WALES; NATURAL-RESOURCES; SIERRA-NEVADA; HABITAT; RARE; CONSERVATION; INFORMATION; CALIFORNIA; INFERENCE	We evaluated the effects of probabilistic (hereafter DESIGN) and non-probabilistic (PURPOSIVE) sample surveys on resultant classification tree models for predicting the presence of four lichen species in the Pacific Northwest, USA. Models derived from both survey forms were assessed using an independent data set (EVALUATION). Measures of accuracy as gauged by resubstitution rates were similar for each lichen species irrespective of the underlying sample survey form. Cross-validation estimates of prediction accuracies were lower than resubstitution accuracies for all species and both design types, and in all cases were closer to the true prediction accuracies based on the EVALUATION data set. We argue that greater emphasis should be placed on calculating and reporting cross-validation accuracy rates rather than simple resubstitution accuracy rates. Evaluation of the DESIGN and PURPOSIVE tree models on the EVALUATION data set shows significantly lower prediction accuracy for the PURPOSIVE tree models relative to the DESIGN models, indicating that non-probabilistic sample surveys may generate models with limited predictive capability. These differences were consistent across all four lichen species, with 11 of the 12 possible species and sample survey type comparisons having significantly lower accuracy rates. Some differences in accuracy were as large as 50%. The classification tree structures also differed considerably both among and within the modelled species, depending on the sample survey form. Overlap in the predictor variables selected by the DESIGN and PURPOSIVE tree models ranged from only 20% to 38%, indicating the classification trees fit the two evaluated survey forms on different sets of predictor variables. The magnitude of these differences in predictor variables throws doubt on ecological interpretation derived from prediction models based on non-probabilistic sample surveys. (c) 2006 Elsevier B.V. All rights reserved.	Utah State Univ, USGS Utah Cooperat Res Unit, Coll Nat Resources, Logan, UT 84322 USA; Utah State Univ, Dept Math & Stat, Logan, UT 84322 USA; Swiss Fed Res Inst WSL, Dept Landscape Res, CH-8903 Birmensdorf, Switzerland; USDA Forest Serv, Siuslaw Natl Forest, Corvallis, OR 97339 USA; USDA Forest Serv, Rocky Mt Res Stn, Ogden, UT 84401 USA	Edwards, TC (reprint author), Utah State Univ, USGS Utah Cooperat Res Unit, Coll Nat Resources, 5290 Old Main Hill, Logan, UT 84322 USA.	tce@nr.usu.edu	Zimmermann, Niklaus/A-4276-2008	Zimmermann, Niklaus/0000-0003-3099-9604			AUSTIN MP, 1990, ECOL MONOGR, V60, P161, DOI 10.2307/1943043; AUSTIN MP, 1989, BIOL CONSERV, V50, P13, DOI 10.1016/0006-3207(89)90003-7; AUSTIN MP, 1983, AUST J ECOL, V8, P169, DOI 10.1111/j.1442-9993.1983.tb01604.x; Best L.B., 1986, P209; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CALL DR, 1992, CONDOR, V94, P880, DOI 10.2307/1369285; CHATFIELD C, 1995, J ROY STAT SOC A STA, V158, P419, DOI 10.2307/2983440; Cochran W, 1977, SAMPLING TECHNIQUES; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; Dreisbach TA, 2002, PREDICTING SPECIES OCCURRENCES: ISSUES OF ACCURACY AND SCALE, P475; Edwards TC, 2005, ECOLOGY, V86, P1081, DOI 10.1890/04-0608; Edwards TC, 2004, ECOL APPL, V14, P414, DOI 10.1890/02-5236; Edwards TC, 1996, CONSERV BIOL, V10, P263, DOI 10.1046/j.1523-1739.1996.10010263.x; Engler R, 2004, J APPL ECOL, V41, P263, DOI 10.1111/j.0021-8901.2004.00881.x; Fielding AH, 1995, CONSERV BIOL, V9, P1466, DOI 10.1046/j.1523-1739.1995.09061466.x; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; FREDERICK GP, 1992, CONDOR, V94, P889, DOI 10.2307/1369286; Frescino TS, 2001, J VEG SCI, V12, P15, DOI 10.2307/3236670; GEISER LH, 2004, R6NRAQTP104 USDA FOR; Gesch D, 2002, PHOTOGRAMM ENG REM S, V68, P5; Glover C.J.M., 1989, P89; Gregoire TG, 1998, CAN J FOREST RES, V28, P1429, DOI 10.1139/cjfr-28-10-1429; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T. J., 1990, GEN ADDITIVE MODELS; Hosmer D. W., 2000, APPL LOGISTICS REGRE; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Jaberg C, 2001, J APPL ECOL, V38, P1169, DOI 10.1046/j.0021-8901.2001.00668.x; KODRICBROWN A, 1993, ECOL APPL, V3, P736, DOI 10.2307/1942104; Lawler JJ, 2002, LANDSCAPE ECOL, V17, P233, DOI 10.1023/A:1020219914926; LEVINS R, 1966, AM SCI, V54, P421; Manly BFJ, 1997, RANDOMIZATION BOOTST, V2nd; Martin JA, 1999, CONDOR, V101, P272, DOI 10.2307/1369990; MAX TA, 1996, PNWRP493 USDA FOR SE; McCullagh P., 1989, GEN LINEAR MODELS, Vsecond; McNoleg O., 1996, COMPUT GEOSCI, V22, P585, DOI 10.1016/0098-3004(95)00131-X; Munoz J, 2004, J VEG SCI, V15, P285, DOI 10.1658/1100-9233(2004)015[0285:COSMCU]2.0.CO;2; Nusser SM, 1998, ECOL APPL, V8, P234, DOI 10.2307/2641063; Olsen AR, 1997, ENVIRON ECOL STAT, V4, P167, DOI 10.1023/A:1018522428238; Olsen AR, 1999, ENVIRON MONIT ASSESS, V54, P1, DOI 10.1023/A:1005823911258; Scott J. M., 2002, PREDICTING SPECIES O; Steele BM, 2000, REMOTE SENS ENVIRON, V74, P545, DOI 10.1016/S0034-4257(00)00145-0; Thornton PE, 1997, J HYDROL, V190, P214, DOI 10.1016/S0022-1694(96)03128-9; Thornton PE, 1999, AGR FOREST METEOROL, V93, P211, DOI 10.1016/S0168-1923(98)00126-9; VANHORNE B, 1991, 8 US DEP INT US FISH; Welch NE, 2005, CONSERV BIOL, V19, P473, DOI 10.1111/j.1523-1739.2005.00384.x; YEE TW, 1991, J VEG SCI, V2, P587, DOI 10.2307/3236170; Zimmermann NE, 1999, J VEG SCI, V10, P469, DOI 10.2307/3237182	48	50	51	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800			ECOL MODEL	Ecol. Model.	NOV 16	2006	199	2					132	141		10.1016/j.ecolmodel.2006.05.016		10	Ecology	Environmental Sciences & Ecology	104XV	WOS:000241994800002		
J	Shi, Q; Harris, LN; Lu, X; Li, XC; Hwang, J; Gentleman, R; Iglehart, JD; Miron, A				Shi, Qian; Harris, Lyndsay N.; Lu, Xin; Li, Xiaochun; Hwang, Justin; Gentleman, Robert; Iglehart, J. Dirk; Miron, Alexander			Declining plasma fibrinogen alpha fragment identifies HER2-positive breast cancer patients and reverts to normal levels after surgery	JOURNAL OF PROTEOME RESEARCH			English	Article						breast cancer; proteomics; HER2; fibrinogen; plasma	LASER DESORPTION/IONIZATION-TIME; ARTIFICIAL NEURAL-NETWORKS; SELDI MASS-SPECTROMETRY; SERUM-PROTEIN PROFILES; GENE-EXPRESSION DATA; LYMPH-NODE STATUS; OVARIAN-CANCER; BIOMARKER DISCOVERY; PROTEOMIC PATTERNS; PROSTATE-CANCER	Breast cancer is the most common nonskin malignancy affecting women. Currently, no simple, blood-based diagnostic test exists to complement radiological screening and increase sensitivity of detection. To screen plasma specimens and identify biomarkers that detect HER2-positive breast cancer, automated robotic sample processing followed by surface-enhanced laser desorption ionization time-of-flight (SELDI-TOF) mass spectroscopy was used. Multiple statistical algorithms were used to select biomarkers that segregate cancer patients versus controls and produced average CV rates ranging from 20% to 29%. A set of seven biomarkers were validated on an independent test data set and achieved the best error rate of 19.1%. A permutation test indicateded a p-value for CV error less than 0.002. Moreover, a ROC curve using these biomarkers achieved an area-under-the-curve value of 0.95 on an independent test data set. The marker responsible for most of the resolving power was identified as a fragment of Fibrinogen Alpha (FGA) encompassing residues 605-629. This marker was present at lower levels in cancer patients as compared to controls. The importance of this biomarker was validated in a longitudinal study comparing pre- and post-operative levels and was shown to revert to normal levels after surgery. This fragment may serve as a useful diagnostic and treatment-monitoring marker.	Dana Farber Canc Inst, Dept Canc Biol, Boston, MA 02115 USA; Dana Farber Canc Inst, Dept Biostat, Boston, MA 02115 USA; Fudan Univ, Inst Prote & Syst Biol, Inst Biomed Sci, Shanghai 200433, Peoples R China; Univ Calif San Diego, Dept Family & Prevent Med, San Diego, CA 92103 USA; Harvard Univ, Sch Publ Hlth, Dept Biostat, Boston, MA 02115 USA; Fred Hutchinson Canc Res Ctr, Program Computat Biol, Seattle, WA 98104 USA; Harvard Univ, Sch Med, Brigham & Womens Hosp, Dept Surg, Boston, MA 02115 USA	Miron, A (reprint author), Dana Farber Canc Inst, Dept Canc Biol, 44 Binney St, Boston, MA 02115 USA.	alexander_miron@dfci.harvard.edu					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Becker S, 2004, ANN SURG ONCOL, V11, P907, DOI 10.1245/ASO.2004.03.557; Blackwell K, 2000, J CLIN ONCOL, V18, P600; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARTER CL, 1989, CANCER, V63, P181, DOI 10.1002/1097-0142(19890101)63:1<181::AID-CNCR2820630129>3.0.CO;2-H; Chen YD, 2004, CLIN CANCER RES, V10, P8380, DOI 10.1158/1078-0432.CCR-1162-03; Coombes KR, 2003, CLIN CHEM, V49, P1615, DOI 10.1373/49.10.1615; Duda R. O., 1973, PATTERN CLASSIFICATI; FRANCIS CW, 1993, BLOOD CELLS, V19, P306; FRANCIS CW, 1993, BLOOD CELLS, V19, P291; Gillette MA, 2005, J PROTEOME RES, V4, P1143, DOI 10.1021/pr0500962; GRAY AJ, 1995, J BIOL CHEM, V270, P26602; Greiling D, 1997, J CELL SCI, V110, P861; Grizzle WE, 2004, UROL ONCOL-SEMIN ORI, V22, P337, DOI 10.1016/j.urolonc.2004.04.008; Heer K, 2001, CLIN CANCER RES, V7, P3491; Karande AA, 2001, INT J CANCER, V95, P277, DOI 10.1002/1097-0215(20010920)95:5<277::AID-IJC1047>3.0.CO;2-Y; Liotta LA, 2006, J CLIN INVEST, V116, P26, DOI 10.1172/JCI27467; Liu Jian, 2005, J Zhejiang Univ Sci B, V6, P4, DOI 10.1631/jzus.2005.B0004; MANI DR, 2005, NEXT GENERATION DATA; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; MILLER AB, 1992, CAN MED ASSOC J, V147, P1459; *NAT CTR HLTH STAT, 1998, SEER CANC STAT REV 1; OReilly MS, 1997, CELL, V88, P277, DOI 10.1016/S0092-8674(00)81848-6; Paweletz CP, 2001, DIS MARKERS, V17, P301; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pusztai L, 2004, CANCER, V100, P1814, DOI 10.1002/cncr.20203; Qu YS, 2002, CLIN CHEM, V48, P1835; Schnitt S J, 2001, J Natl Cancer Inst Monogr, P22; Seibert V, 2004, PATHOL RES PRACT, V200, P83, DOI 10.1016/j.prp.2004.01.010; Seregni E, 2004, EUR J NUCL MED MOL I, V31, pS15, DOI 10.1007/s00259-004-1523-z; Simpson-Haidaris PJ, 2001, ANN NY ACAD SCI, V936, P406; SKOGEN WF, 1988, BLOOD, V71, P1475; Soltys SG, 2004, CLIN CANCER RES, V10, P4806, DOI 10.1158/1078-0432.CCR-03-0469; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Sorlie T, 2003, P NATL ACAD SCI USA, V100, P8418, DOI 10.1073/pnas.0932692100; Tang N, 2004, MASS SPECTROM REV, V23, P34, DOI 10.1002/mas.10066; THOMPSON WD, 1993, BLOOD COAGUL FIBRIN, V4, P113, DOI 10.1097/00001721-199304010-00019; Tolson J, 2004, LAB INVEST, V84, P845, DOI 10.1038/labinvest.3700097; VALAGUSSA P, 1978, CANCER, V41, P1170, DOI 10.1002/1097-0142(197803)41:3<1170::AID-CNCR2820410355>3.0.CO;2-I; Villanueva J, 2004, ANAL CHEM, V76, P1560, DOI 10.1021/ac0352171; Villanueva J, 2006, J CLIN INVEST, V116, P271, DOI 10.1172/JCI26022; Vlahou Antonia, 2003, Clin Breast Cancer, V4, P203, DOI 10.3816/CBC.2003.n.026; Wadsworth JT, 2004, CLIN CANCER RES, V10, P1625, DOI 10.1158/1078-0432.CCR-0297-3; Wang Z, 2004, CLIN CHEM, V50, P1939, DOI 10.1373/clinchem.2004.036871; Wang ZGC, 2004, CANCER RES, V64, P64, DOI 10.1158/0008-5472.CAN-03-2570; Wilson LL, 2004, ANN NY ACAD SCI, V1022, P317, DOI 10.1196/annals.1318.047; Xiao XY, 2004, SCI CHINA SER C, V47, P219, DOI 10.1360/03yc0105; Yarden Y, 2001, NAT REV MOL CELL BIO, V2, P127, DOI 10.1038/35052073; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Ye B, 2003, CLIN CANCER RES, V9, P2904; Yu JK, 2004, WORLD J GASTROENTERO, V10, P3127; ZHANG XG, 2006, UNPUB; Zhang Z, 2004, CANCER RES, V64, P5882, DOI 10.1158/0008-5472.CAN-04-0746	56	20	23	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893			J PROTEOME RES	J. Proteome Res.	NOV 3	2006	5	11					2947	2955		10.1021/pr060099u		9	Biochemical Research Methods	Biochemistry & Molecular Biology	101QL	WOS:000241755400008	17081046	
J	Falk, TH; Chan, WY				Falk, Tiago H.; Chan, Wai-Yip			Single-ended speech quality measurement using machine learning methods	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						mean opinion score (MOS); objective quality measurement; quality model; single-ended measurement; speech communication; speech distortions; speech enhancement; speech quality; subjective quality	NORMALIZING BLOCK TECHNIQUE; OBJECTIVE ESTIMATION; MODELS	We describe a novel single-ended algorithm constructed from models of speech signals, including clean and degraded speech, and speech corrupted by multiplicative noise and temporal discontinuities. Machine learning methods are used to design the models, including Gaussian mixture models, support vector machines, and random forest classifiers. Estimates of the subjective mean opinion score (MOS) generated by the models are combined using hard or soft decisions generated by a classifier which has learned to match the input signal with the models. Test results show the algorithm outperforming ITU-T P.563, the current "state-of-art" standard single-ended algorithm. Employed in a distributed double-ended measurement configuration, the proposed algorithm is found to be more effective than P.563 in assessing the quality of noise reduction systems and can provide a functionality not available with P.862 PESQ, the current double-ended standard algorithm.	Queens Univ, Dept Elect & Comp Engn, Kingston, ON K7L 3N6, Canada	Falk, TH (reprint author), Queens Univ, Dept Elect & Comp Engn, Kingston, ON K7L 3N6, Canada.	tiago.falk@ece.queensu.ca; geoffrey.chan@queensu.ca					*3GPP2, 2004, 26094 3GPP2 TS; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Canny J., 1983, 720 MIT ART INT LAB; FALK TH, 2006, P INT C AC SPEECH SI, V1, P837; Falk TH, 2006, IEEE SIGNAL PROC LET, V13, P108, DOI 10.1109/LSP.2005.861598; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gray P, 2000, IEE P-VIS IMAGE SIGN, V147, P493, DOI 10.1049/ip-vis:20000539; Hansen M, 1999, J ACOUST SOC AM, V106, P2888, DOI 10.1121/1.428136; HERMANSKY H, 1999, P ROB METH SPEECH RE; HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423; Hu Y, 2006, P IEEE INT C AC SPEE, V1, P153; HU Y, 2006, IN PRESS P INT C SPO; HU Y, 2006, UNPUB SPEECH COMMUN; Huang X., 2001, SPOKEN LANGUAGE PROC, V1st; Jayant N. S., 1984, DIGITAL CODING WAVEF; JAYANT NS, 1974, P IEEE, V62, P611, DOI 10.1109/PROC.1974.9484; Kim DS, 2005, IEEE T SPEECH AUDI P, V13, P821, DOI 10.1109/TSA.2005.851924; KLEIJN WB, 1995, SPEECH CODING SYNTHE, P495; KUBICHEK R, 1991, P IEEE GLOBECOM C, P1765; LIANG J, 1994, P IEEE VEH TECHN C J, V3, P1719; PAAJANEN E, 2000, P IEEE SPEECH COD WO, P23; QUACKENBUSH SR, 1988, OBJECTIVES MEASURES; Thorpe L., 1999, P IEEE WORKSH SPEECH, P144; Vapnik VN, 1995, NATURE STAT LEARNING; VORAN S, 1992, SQ1392 CCITT SG12; Voran S, 1999, IEEE T SPEECH AUDI P, V7, P383, DOI 10.1109/89.771260; Voran S, 1999, IEEE T SPEECH AUDI P, V7, P371, DOI 10.1109/89.771259; Voran SD, 2005, P INT C MEAS SPEECH; Voran Stephen, 2003, P INT C MEAS SPEECH; WANG EB, 1992, J RARE EARTH, V10, P5; ZHA W, 2005, EURASIP J APPL SIG P, P1410	32	20	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	NOV	2006	14	6					1935	1947		10.1109/TASL.2006.883253		13	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	099BJ	WOS:000241567200006		
J	Lin, SY; Horng, SC				Lin, Shin-Yeu; Horng, Shih-Cheng			A classification-based fault detection and isolation scheme for the ion implanter	IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING			English	Article						classification; classification and regression tree (CART); clustering algorithm; fault detection and isolation; ion implanter	DYNAMIC-SYSTEMS; DIAGNOSIS	We propose a classification-based fault detection and isolation scheme for the ion implanter. The proposed scheme consists of two parts: 1) the classification part and 2) the fault detection and isolation part. In the classification part, we propose a hybrid classification tree (HCT) with learning capability to classify the recipe of a working wafer in the ion implanter, and a k-fold cross-validation error is treated as the accuracy of the classification result. In the fault detection and isolation part, we propose a warning signal generation criteria based on the classification accuracy to detect and fault isolation scheme based on the HCT to isolate the actual fault of an ion implanter. We have compared the proposed classifier with the existing classification software and tested the validity of the proposed fault detection and isolation scheme for real cases to obtain successful results.	Natl Chiao Tung Univ, Dept Elect & Control Engn, Hsinchu 300, Taiwan	Lin, SY (reprint author), Natl Chiao Tung Univ, Dept Elect & Control Engn, Hsinchu 300, Taiwan.	sylin@cc.nctu.edu.tw; schong.ece90g@nctu.edu.tw					BARSCHODORFF D, 1987, VDI BER, V644, P241; Basseville M., 1985, DETECTION ABRUPT CHA, V77; BORISOV A, 2003, UNPUB NIPS 2003 WORK; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bruzzone L, 2001, IEEE T GEOSCI REMOTE, V39, P456, DOI 10.1109/36.905255; CHANG X, 2004, IEEE T SYST MAN CY B, V34, P1031; Cordon O, 1999, INT J APPROX REASON, V20, P21, DOI 10.1016/S0888-613X(00)88942-2; Denoeux T, 2000, IEEE T SYST MAN CY A, V30, P131, DOI 10.1109/3468.833094; Dunham M. H, 2002, DATA MINING INTRO AD; Ediriwickrema J, 1997, IEEE T GEOSCI REMOTE, V35, P810, DOI 10.1109/36.602523; FRANK PM, 1990, AUTOMATICA, V26, P459, DOI 10.1016/0005-1098(90)90018-D; FRIEDMAN JH, 2002, COMPUTATIONAL STAT D, V34, P367; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Gertler J., 1998, FAULT DETECTION DIAG; Grimmett G. R., 2001, PROBABILITY RANDOM P; HAWKINS DM, 1982, TOPICS APPL MULTIVAR, P267; Himmelblau D.M., 1978, FAULT DETECTION DIAG; ISERMANN R, 1984, AUTOMATICA, V20, P387, DOI 10.1016/0005-1098(84)90098-0; ISERMANN R, 1993, AUTOMATICA, V29, P815, DOI 10.1016/0005-1098(93)90088-B; Isermann R., 2004, 16 S AUT CONTR AER S; Isermann R, 1997, CONTROL ENG PRACT, V5, P639, DOI 10.1016/S0967-0661(97)00046-4; Ishibuchi H, 2001, IEEE T FUZZY SYST, V9, P506, DOI 10.1109/91.940964; Lawrence RL, 2001, PHOTOGRAMM ENG REM S, V67, P1137; Marin-Blazquez JG, 2002, IEEE T FUZZY SYST, V10, P484, DOI 10.1109/TFUZZ.2002.800687; McKenna C. M., 2000, P 2000 INT C ION IMP, P1; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; NEUMANN D, 1991, P IFAC S SAFEPROCESS, V1, P73; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 2003, DATA MINING TOOLS SE; Smith G. M., 2003, STAT PROCESS CONTROL; Stearns S. D., 1990, DIGITAL SIGNAL ANAL; WILLSKY AS, 1976, AUTOMATICA, V12, P601, DOI 10.1016/0005-1098(76)90041-8; Yue HH, 2000, IEEE T SEMICONDUCT M, V13, P374, DOI 10.1109/66.857948; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	35	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0894-6507			IEEE T SEMICONDUCT M	IEEE Trans. Semicond. Manuf.	NOV	2006	19	4					411	424		10.1109/TSM.2006.883594		14	Engineering, Manufacturing; Engineering, Electrical & Electronic; Physics, Applied; Physics, Condensed Matter	Engineering; Physics	105XG	WOS:000242065000007		
J	Rehfeldt, GE; Crookston, NL; Warwell, MV; Evans, JS				Rehfeldt, Gerald E.; Crookston, Nicholas L.; Warwell, Marcus V.; Evans, Jeffrey S.			Empirical analyses of plant-climate relationships for the western United States	INTERNATIONAL JOURNAL OF PLANT SCIENCES			English	Article						bioclimatic models; Random Forests multiple-regression tree; climatic distributions; climatic niche; response to climate change; global warming	VEGETATION DISTRIBUTION; SPECIES DISTRIBUTIONS; GLOBAL CHANGE; ADAPTIVE EVOLUTION; CONTINENTAL-SCALE; CHANGING CLIMATE; PINUS-SYLVESTRIS; MIGRATION RATES; POLLEN SPECTRA; WATER-BALANCE	The Random Forests multiple-regression tree was used to model climate profiles of 25 biotic communities of the western United States and nine of their constituent species. Analyses of the communities were based on a gridded sample of ca. 140,000 points, while those for the species used presence-absence data from ca. 120,000 locations. Independent variables included 35 simple expressions of temperature and precipitation and their interactions. Classification errors for community models averaged 19%, but the errors were reduced by half when adjusted for misalignment between geographic data sets. Errors of omission for species-specific models approached 0, while errors of commission were less than 9%. Mapped climate profiles of the species were in solid agreement with range maps. Climate variables of most importance for segregating the communities were those that generally differentiate maritime, continental, and monsoonal climates, while those of importance for predicting the occurrence of species varied among species but consistently implicated the periodicity of precipitation and temperature-precipitation interactions. Projections showed that unmitigated global warming should increase the abundance primarily of the montane forest and grassland community profiles at the expense largely of those of the subalpine, alpine, and tundra communities but also that of the arid woodlands. However, the climate of 47% of the future landscape may be extramural to contemporary community profiles. Effects projected on the spatial distribution of species-specific profiles were varied, but shifts in space and attitude would be extensive. Species-specific projections were not necessarily consistent with those of their communities.	USDA, Rocky Mt Res Stn, Forest Serv, Forestry Sci Lab, Moscow, ID 83843 USA	Rehfeldt, GE (reprint author), USDA, Rocky Mt Res Stn, Forest Serv, Forestry Sci Lab, 1221 S Main, Moscow, ID 83843 USA.	grehfeldt@fs.fed.us	Evans, Jeffrey/	Evans, Jeffrey/0000-0002-5533-7044			Ackerly DD, 2003, INT J PLANT SCI, V164, pS165, DOI 10.1086/368401; ALERICH CA, 2004, FOREST INVENTORY ANL; Bachelet D, 2001, ECOSYSTEMS, V4, P164, DOI 10.1007/s10021-001-0002-7; Baker Frederick S., 1944, ECOL MONOGR, V14, P223, DOI 10.2307/1943534; Bakkenes M, 2002, GLOBAL CHANGE BIOL, V8, P390, DOI 10.1046/j.1354-1013.2001.00467.x; Beaumont LJ, 2005, ECOL MODEL, V186, P250, DOI 10.1016/j.ecolmodel.2005.01.030; BECHTOLD WA, 2005, SRS80 USDA FOR SERV; Berry PM, 2002, GLOBAL ECOL BIOGEOGR, V11, P453, DOI 10.1046/j.1466-822x.2002.00304.x; BOOTH TH, 1990, FOREST ECOL MANAG, V36, P47, DOI 10.1016/0378-1127(90)90063-H; BOX EO, 1993, J BIOGEOGR, V20, P629, DOI 10.2307/2845519; Box EO, 1999, CLIMATIC CHANGE, V41, P213, DOI 10.1023/A:1005483507351; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Broadmeadow MSJ, 2005, FORESTRY, V78, P145, DOI 10.1093/forestry/cpi014; Brown D. E., 1998, CLASSIFICATION N AM; Burns R.M., 1990, USDA FOREST SERVICE, V654; Chuine I, 2004, NATURE, V432, P289, DOI 10.1038/432289a; Chuine I, 2001, ECOL LETT, V4, P500, DOI 10.1046/j.1461-0248.2001.00261.x; Clark JS, 1998, BIOSCIENCE, V48, P13, DOI 10.2307/1313224; Thomas CD, 2001, NATURE, V411, P577, DOI 10.1038/35079066; Cumming SG, 1996, CLIMATIC CHANGE, V34, P213; Daubenmire R., 1968, WASHINGTON AGR EXPT, V60; DAUBENMIRE R, 1956, ECOL MONOGR, V26, P131, DOI 10.2307/1943287; DAVIS MB, 1989, CLIMATIC CHANGE, V15, P75, DOI 10.1007/BF00138846; Davis MB, 2005, ECOLOGY, V86, P1704, DOI 10.1890/03-0788; Etterson JR, 2001, SCIENCE, V294, P151, DOI 10.1126/science.1063656; Flato GM, 2001, GEOPHYS RES LETT, V28, P195, DOI 10.1029/2000GL012121; *GLOBE TASK TEAM, 1999, GLOB LAND ON KIL BAS; Gordon C, 2000, CLIM DYNAM, V16, P147, DOI 10.1007/s003820050010; Graham MH, 2003, ECOLOGY, V84, P2809, DOI 10.1890/02-3114; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; HAIG IT, 1941, USDA TECHNICAL B, V767; Hansen AJ, 2001, BIOSCIENCE, V51, P765, DOI 10.1641/0006-3568(2001)051[0765:GCIFRO]2.0.CO;2; Hastie T., 2001, ELEMENTS STAT LEARNI; Higgins SI, 2003, J ECOL, V91, P341, DOI 10.1046/j.1365-2745.2003.00781.x; HOLDRIDGE LR, 1947, SCIENCE, V105, P367, DOI 10.1126/science.105.2727.367; HUNTLEY B, 1990, QUATERNARY RES, V33, P360, DOI 10.1016/0033-5894(90)90062-P; HUNTLEY B, 1991, ANN BOT-LONDON, V67, P15; HUTCHINSON MF, 2000, ANUSPLIN USERS GUIDE; HUTCHINSON M.F., 1991, DATA ASSIMILATION SY, P104; IPCC, 2001, CLIM CHANG 2001 SCI; Iverson LR, 1998, ECOL MONOGR, V68, P465, DOI 10.2307/2657150; Jackson ST, 2000, PALEOBIOLOGY, V26, P194, DOI 10.1666/0094-8373(2000)26[194:ROPPAC]2.0.CO;2; Jump AS, 2005, ECOL LETT, V8, P1010, DOI 10.1111/j.1461-0248.2005.00796.x; Larsen JA, 1930, ECOLOGY, V11, P631, DOI 10.2307/1932327; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; LITTLE EL, 1971, USDA MISCELLANEOUS P, V1446; Little Jr E.L., 1976, USDA MISCELLANEOUS P, V1314, P13; Loustau D, 2005, TREE PHYSIOL, V25, P813; McKenzie D, 2003, J BIOGEOGR, V30, P1093; MELILLO JM, 1995, GLOBAL BIOGEOCHEM CY, V9, P407; Moisen GG, 2002, ECOL MODEL, V157, P209, DOI 10.1016/S0304-3800(02)00197-7; MONSERUD RA, 1993, CLIMATIC CHANGE, V25, P59, DOI 10.1007/BF01094084; Monserud RA, 1998, PALAEOGEOGR PALAEOCL, V139, P15, DOI 10.1016/S0031-0182(97)00127-2; Neilson RP, 2005, BIOSCIENCE, V55, P749, DOI 10.1641/0006-3568(2005)055[0749:FRTGPM]2.0.CO;2; NEILSON RP, 1995, ECOL APPL, V5, P362, DOI 10.2307/1942028; Noss RF, 2001, CONSERV BIOL, V15, P578, DOI 10.1046/j.1523-1739.2001.015003578.x; OVERPECK JT, 1985, QUATERNARY RES, V23, P87, DOI 10.1016/0033-5894(85)90074-2; Parmesan C, 2003, NATURE, V421, P37, DOI 10.1038/nature01286; Pearson RG, 2003, GLOBAL ECOL BIOGEOGR, V12, P361, DOI 10.1046/j.1466-822X.2003.00042.x; Petit RJ, 2004, FOREST ECOL MANAG, V197, P117, DOI 10.1016/j.foreco.2004.05.009; PRENTICE IC, 1992, J BIOGEOGR, V19, P117, DOI 10.2307/2845499; R Development Core Team, 2004, R LANG ENV STAT COMP; Rehfeldt G. E., 2004, RECENT RES DEV GENET, V1, P113; Rehfeldt GE, 2001, CLIMATIC CHANGE, V50, P355, DOI 10.1023/A:1010614216256; Rehfeldt GE, 1999, AM J BOT, V86, P741, DOI 10.2307/2656584; REHFELDT GE, 2004, 134 USDA FOR SERV RO; Rehfeldt GE, 1999, ECOL MONOGR, V69, P375, DOI 10.1890/0012-9615(1999)069[0375:GRTCIP]2.0.CO;2; REHFELDT GE, 2006, 165 USDA FOR SERV RO; Rehfeldt GE, 2002, GLOBAL CHANGE BIOL, V8, P912, DOI 10.1046/j.1365-2486.2002.00516.x; Rice KJ, 2003, FRONT ECOL ENVIRON, V1, P469, DOI 10.2307/3868114; Root TL, 2003, NATURE, V421, P57, DOI 10.1038/nature01333; Savolainen O, 2004, FOREST ECOL MANAG, V197, P79, DOI 10.1016/j.foreco.2004.05.006; Shafer SL, 2001, ECOSYSTEMS, V4, P200, DOI 10.1007/s10021-001-0004-5; Shaw JD, 2005, J FOREST, V103, P280; STEENBERGH WF, 1977, NATL PARK SERVICES S, V8; STEPHENSON NL, 1990, AM NAT, V135, P649, DOI 10.1086/285067; Stephenson NL, 1998, J BIOGEOGR, V25, P855, DOI 10.1046/j.1365-2699.1998.00233.x; Tchebakova N. M., 2005, MITIG ADAPT STRAT GL, V11, P861; Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121; THOMPSON RS, 2002, 1153 US GEOL SURV; Thuiller W, 2003, J VEG SCI, V14, P669, DOI 10.1658/1100-9233(2003)014[0669:GMVCTA]2.0.CO;2; Thuiller W, 2003, GLOBAL CHANGE BIOL, V9, P1353, DOI 10.1046/j.1365-2486.2003.00666.x; TURNER RM, 1995, SORORAN DESERT PLANT; *USGS, 2005, DIG REPR TREE SPEC R; Walther GR, 2002, NATURE, V416, P389, DOI 10.1038/416389a	85	153	160	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	1058-5893			INT J PLANT SCI	Int. J. Plant Sci.	NOV	2006	167	6					1123	1150		10.1086/507711		28	Plant Sciences	Plant Sciences	117YD	WOS:000242908300005		
J	Gruters, U; Janze, S; Kammann, C; Jager, HJ				Grueters, U.; Janze, S.; Kammann, C.; Jaeger, H.-J.			Plant functional types and elevated CO2: A method of scanning for causes of community alteration	JOURNAL OF APPLIED BOTANY AND FOOD QUALITY-ANGEWANDTE BOTANIK			English	Article							ATMOSPHERIC CO2; INTERSPECIFIC VARIATION; ENRICHMENT; GRASSLAND; RESPONSES; PASTURE; TRAITS; GROWTH; FLORA; PRODUCTIVITY	In this paper, a general method for an a posteriori plant functional type (PFT) analysis of global change effects on community composition is developed. We apply the method to a case study, specifically the Giessen-FACE experiment. This experiment involves a Central European meadow that has been exposed to moderate CO2-enrichmerit since May 1998.	Univ Giessen, Inst Pflanzenokol, D-35392 Giessen, Germany	Gruters, U (reprint author), Univ Giessen, Inst Pflanzenokol, Heinrich Buff Ring 26-32, D-35392 Giessen, Germany.	Uwe.Grueters@bot2.bio.uni-giessen.de	Kammann, Claudia/B-1533-2013				Ainsworth EA, 2005, NEW PHYTOL, V165, P351, DOI 10.1111/j.1469-8137.2004.01224.x; BassiriRad H, 2003, GLOBAL CHANGE BIOL, V9, P1582, DOI 10.1046/j.1365-2486.2003.00679.x; BREIMAN L, 2006, RANDOM FORESTS; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CALDWELL BD, 1996, CARBON DIOXIDE POPUL, P301; Campbell BD, 2000, AGR ECOSYST ENVIRON, V82, P39, DOI 10.1016/S0167-8809(00)00215-2; Chapin FS, 2003, ANN BOT-LONDON, V91, P455, DOI 10.1093/aob/mcg041; Chapin FS, 2000, NATURE, V405, P234, DOI 10.1038/35012241; Chapin III FS, 2002, PRINCIPLES TERRESTRI; Chen C, 2004, 666 U BERK DEP STAT; De Bello F, 2005, J APPL ECOL, V42, P824, DOI 10.1111/j.1365-2664.2005.01079.x; Diaz S, 2002, GLOBAL RANGELANDS: PROGRESS AND PROSPECTS, P81, DOI 10.1079/9780851995236.0081; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Edwards GR, 2001, OECOLOGIA, V127, P383, DOI 10.1007/s004420000602; EHLERINGER J, 1977, PLANT PHYSIOL, V59, P86, DOI 10.1104/pp.59.1.86; FITTER AH, 1994, J ECOL, V82, P415, DOI 10.2307/2261309; Grime J. P., 2001, PLANT STRATEGIES VEG; Hattenschwiler S, 2001, OECOLOGIA, V129, P31, DOI 10.1007/s004420100699; Hodgson JG, 1999, OIKOS, V85, P282, DOI 10.2307/3546494; Hodgson J.G., 1995, ELECT COMP PLANT ECO; Houghton JT, 2001, CLIMATE CHANGE 2001; HUNT R, 1993, FUNCT ECOL, V7, P661, DOI 10.2307/2390186; Jager HJ, 2003, J APPL BOT-ANGEW BOT, V77, P117; Kammann C, 2005, BASIC APPL ECOL, V6, P351, DOI 10.1016/j.baae.2005.01.011; KLEYER M, 1995, BIOL TRAITS VASC PLA; Knevel IC, 2003, J VEG SCI, V14, P611, DOI 10.1658/1100-9233(2003)014[0611:LTOTNE]2.0.CO;2; Korner C, 2000, ECOL APPL, V10, P1590, DOI 10.2307/2641226; Lavorel S, 2002, FUNCT ECOL, V16, P545, DOI 10.1046/j.1365-2435.2002.00664.x; Lavorel S, 1998, ACTA OECOL, V19, P227, DOI 10.1016/S1146-609X(98)80027-1; Leps J, 2003, MULTIVARIATE ANAL EC; Leuschner C, 1996, VEGETATION MITTELEUR; LIAW A, 2006, DOCUMENTATION PACKAG; Lososova Z, 2004, J VEG SCI, V15, P415, DOI 10.1658/1100-9233(2004)015[0415:WVOALI]2.0.CO;2; LUSCHER A, 1996, CARBON DIOXIDE POPUL, P286; Luscher A, 1998, OECOLOGIA, V113, P37; Marissink M, 2002, J VEG SCI, V13, P733, DOI 10.1658/1100-9233(2002)013[0733:FCOASS]2.0.CO;2; Morgan JA, 2004, OECOLOGIA, V140, P11, DOI 10.1007/s00442-004-1550-2; Nowak RS, 2004, NEW PHYTOL, V162, P253, DOI 10.1111/j.1469-8137.2004.01033.x; Oberdorfer E, 1990, PFLANZENSOZIOLOGISCH; Petraitis PS, 1996, FUNCT ECOL, V10, P421, DOI 10.2307/2389934; Pillar VD, 2003, J VEG SCI, V14, P323, DOI 10.1111/j.1654-1103.2003.tb02158.x; POORTER H, 1993, VEGETATIO, V104, P77, DOI 10.1007/BF00048146; Poorter H, 1996, CARBON DIOXIDE POPUL, P375, DOI 10.1016/B978-012420870-4/50057-8; Poorter H, 2003, NEW PHYTOL, V157, P175, DOI 10.1046/j.1469-8137.2003.00680.x; PUGESEK BH, 2002, STRUCTURAL EQUATION; RODWELL J.S., 1992, BRIT PLANT COMMUNITI, V3; Roiger R. J., 2003, DATA MINING TUTORIAL; Schubert R, 1990, EXKURSIONSFLORA DEUT, V4; Shipley B., 2004, CAUSE CORRELATION BI; Stocklin J, 1998, OECOLOGIA, V116, P50, DOI 10.1007/s004420050562; ter Braak CJF, 1998, CANOCO REFERENCE MAN; Teyssonneyre F, 2002, GLOBAL CHANGE BIOL, V8, P1034, DOI 10.1046/j.1365-2486.2002.00543.x; Thompson K, 1997, NEW PHYTOL, V136, P679, DOI 10.1046/j.1469-8137.1997.00787.x; Truong Y, 2004, P 10 ACM SIGKDD INT, P835, DOI 10.1145/1014052.1016923; Vasseur L, 1998, PLANT ECOL, V135, P31, DOI 10.1023/A:1009753403246; VERDONSCHOT PFM, 1994, HYDROBIOLOGIA, V278, P251, DOI 10.1007/BF00142333; Wright IJ, 2004, NATURE, V428, P821, DOI 10.1038/nature02403	58	4	5	DRUCKEREI LIDDY HALM	GOTTINGEN	BACKHAUSSTRASSE 9B, 37081 GOTTINGEN, GERMANY	1613-9216			J APPL BOT FOOD QUAL	J. Appl. Bot. Food Qual.-Angew. Bot.	NOV	2006	80	2					116	128				13	Plant Sciences	Plant Sciences	125RX	WOS:000243461200004		
J	Han, PF; Zhang, XZ; Norton, RS; Feng, ZP				Han, Pengfei; Zhang, Xiuzhen; Norton, Raymond S.; Feng, Zhi-Ping			Predicting disordered regions in proteins based on decision trees of reduced amino acid composition	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						disordered region; decision tree; intrinsically unstructured proteins; reduced amino acid composition	FUNCTION NEURAL-NETWORK; INTRINSIC DISORDER; STRUCTURAL PROTEOMICS; SEQUENCE	Intrinsically unstructured proteins (IUPs) are proteins lacking a fixed three-dimensional structure or containing long disordered regions. IUPs play an important role in biology and disease. Identifying disordered regions in protein sequences can provide useful information on protein structure and function, and can assist high-throughput protein structure determination. In this paper, we present a system for predicting disordered regions in proteins based on decision trees and reduced amino acid composition. Concise rules based on biochemical properties of amino acid side chains are generated for prediction. Coarser information extracted from the composition of amino acids cannot only improve the prediction accuracy, but can also increase the learning efficiency. In cross-validation tests, with four groups of reduced amino acid composition, our system can achieve a recall of 80% at a 13% false positive rate for predicting disordered regions, and the overall accuracy can reach 83.4%. This prediction accuracy is comparable to most, and better than some, existing predictors. Advantages of our approach are high prediction accuracy for long disordered regions and efficiency for large-scale sequence analysis. Our software is freely available for academic use upon request.	Walter & Eliza Hall Inst Med Res, Div Biol Struct, Parkville, Vic 3050, Australia; RMIT Univ, Sch Comp Sci & IT, Melbourne, Vic, Australia	Feng, ZP (reprint author), Walter & Eliza Hall Inst Med Res, Div Biol Struct, Parkville, Vic 3050, Australia.	feng@wehi.edu.au					Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHENG J, 2005, DATA MIN KNOWL DISC, P213; Coeytaux K, 2005, BIOINFORMATICS, V21, P1891, DOI 10.1093/bioinformatics/bti266; DAILY KM, 2005, 2005 IEEE S COMPUT I, P475; Dayhoff M.O., 1978, ATLAS PROTEIN SEQ S3, P345; Dunker AK, 2001, J MOL GRAPH MODEL, V19, P26, DOI 10.1016/S1093-3263(00)00138-8; DUNKER AK, 2002, ADV PROTEIN CHEM, V62, P26; HAN P, 2005, P AUSDM05, P131; Hansen JC, 2006, J BIOL CHEM, V281, P1853, DOI 10.1074/jbc.R500022200; HAYNES C, 2006, NUCLEIC ACIDS RES, V1, P305; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Jones DT, 2003, PROTEINS, V53, P573, DOI 10.1002/prot.10528; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; Li X, 1999, GENOME INFORMATICS, V10, P30; Linding R, 2003, STRUCTURE, V11, P1453, DOI 10.1016/j.str.2003.10.002; LIU J, 2002, J MOL BIOL, V332, P53; Liu JF, 2003, NUCLEIC ACIDS RES, V31, P3833, DOI 10.1093/nar/gkg515; MADIA KV, 1979, MULTIVARIATE ANAL; Mitchell T. M., 1997, MACHINE LEARNING; Obradovic Z, 2003, PROTEINS, V53, P566, DOI 10.1002/prot.10532; OBRADOVIC Z, 2005, PROTEIN-STRUCT FUNCT, V7, P176; Oldfield CJ, 2005, PROTEINS, V59, P444, DOI 10.1002/prot.20446; Peng Kang, 2005, Journal of Bioinformatics and Computational Biology, V3, P35, DOI 10.1142/S0219720005000886; Quinlan J., 1993, C 4 5 PROGRAMS MACHI; Radivojac Predrag, 2003, Pac Symp Biocomput, P216; Romero P, 1998, PAC S BIOCOMP, V3, P437; Romero P, 2001, PROTEINS, V42, P38, DOI 10.1002/1097-0134(20010101)42:1<38::AID-PROT50>3.0.CO;2-3; Thomson R, 2004, LECT NOTES COMPUT SC, V3177, P108; Thomson R, 2003, BIOINFORMATICS, V19, P1741, DOI 10.1093/bioinformatics/btg237; Uversky VN, 2002, EUR J BIOCHEM, V269, P2, DOI 10.1046/j.0014-2956.2001.02649.x; Uversky VN, 2000, PROTEINS, V41, P415, DOI 10.1002/1097-0134(20001115)41:3<415::AID-PROT130>3.0.CO;2-7; Uversky VN, 2005, J MOL RECOGNIT, V18, P343, DOI 10.1002/jmr.747; Vucetic S, 2003, PROTEINS, V52, P573, DOI 10.1002/prot.10437; Vucetic S, 2005, BIOINFORMATICS, V21, P137, DOI 10.1093/bioinformatics/bth476; Ward JJ, 2004, BIOINFORMATICS, V20, P2138, DOI 10.1093/bioinformatics/bth195; Ward JJ, 2004, J MOL BIOL, V337, P635, DOI 10.1016/j.jmb.2004.02.002; Weathers EA, 2004, FEBS LETT, V576, P348, DOI 10.1016/j.febslet.2004.09.036; Yang ZR, 2005, BIOINFORMATICS, V21, P3369, DOI 10.1093/bioinformatics/bti534	39	2	2	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277			J COMPUT BIOL	J. Comput. Biol.	NOV	2006	13	9					1579	1590		10.1089/cmb.2006.13.1579		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	115YT	WOS:000242770400007		
J	Jahnukainen, T; Malehorn, D; Sun, M; Lyons-Weiler, J; Bigbee, W; Gupta, G; Shapiro, R; Randhawa, PS; Pelikan, R; Hauskrecht, M; Vats, A				Jahnukainen, Timo; Malehorn, David; Sun, Mai; Lyons-Weiler, James; Bigbee, William; Gupta, Gaurav; Shapiro, Ron; Randhawa, Parmjeet Singh; Pelikan, Richard; Hauskrecht, Milos; Vats, Abhay			Proteomic analysis of urine in kidney transplant patients with BK virus nephropathy	JOURNAL OF THE AMERICAN SOCIETY OF NEPHROLOGY			English	Article; Proceedings Paper	World Transplant Congress	JUL 22-27, 2006	Boston, MA				RENAL-ALLOGRAFT REJECTION; POLYOMAVIRUS TYPE BK; RECIPIENTS; CANCER; IDENTIFICATION; BIOMARKERS; INFECTION; NEPHRITIS; PROTEINS; PATTERNS	The differentiation of BK virus-associated renal allograft nephropathy (BKVAN) from acute allograft rejection (AR) in renal transplant recipients is an important clinical problem because the treatment can be diametrically opposite for the two conditions. The aim of this discovery-phase biomarker development study was to examine feasibility of developing a noninvasive method to differentiate BKVAN from AR. Surface-enhanced laser desorption/ionization (SELDI) time-of-flight mass spectrometry analysis was used to compare proteomic profiles of urine samples of 21 patients with BKVAN, 28 patients with AR (Banff Ia to IIb), and 29 patients with stable graft function. SELDI analysis showed proteomic profiles that were significantly different in the BKVAN group versus the AR and stable transplant groups. Peaks that corresponded to m/z values of 5.872, 11.311, 11.929, 12.727, and 13.349 kD were significantly higher in patients with BKVAN. Bioinformatics analyses allowed distinction of profiles of patients with BKVAN from patients with AR and stable patients. SELDI profiles also showed a high degree of reproducibility. Proteomic analysis of urine may offer a noninvasive way to differentiate BKVAN from AR in clinical practice. The identification of individual proteomic peaks can improve further the clinical utility of this screening method.	Univ Pittsburgh, Childrens Hosp Pittsburgh, Div Pediat Nephrol, Dept Pediat, Pittsburgh, PA 15213 USA; Univ Pittsburgh, Clin Prote Facil, Pittsburgh, PA 15213 USA; Univ Pittsburgh, Inst Canc, Pittsburgh, PA 15213 USA; Univ Pittsburgh, Sch Med, Dept Surg, Pittsburgh, PA USA; Univ Pittsburgh, Med Ctr, Dept Pathol, Pittsburgh, PA USA; Univ Pittsburgh, Benedum Oncol Informat Ctr, Ctr Pathol Informat, Canc Biomarkers Lab,Dept Comp Sci, Pittsburgh, PA USA; Univ Pittsburgh, Benedum Oncol Informat Ctr, Ctr Pathol Informat, Canc Biomarkers Lab,Dept Pathol, Pittsburgh, PA USA	Vats, A (reprint author), Univ Pittsburgh, Childrens Hosp Pittsburgh, Div Pediat Nephrol, Dept Pediat, 3705 5th Ave, Pittsburgh, PA 15213 USA.	abhay.vats@chp.edu	Pelikan, Richard/I-4109-2013				Baldi P, 2001, BIOINFORMATICS, V17, P509, DOI 10.1093/bioinformatics/17.6.509; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Carbone M, 2003, CANCER RES, V63, P6125; Clarke W, 2003, ANN SURG, V237, P660, DOI 10.1097/00000658-200305000-00008; GARDNER SD, 1984, J CLIN PATHOL, V37, P578, DOI 10.1136/jcp.37.5.578; Good P, 2000, PERMUTATION TESTS PR; Hariharan S, 2006, KIDNEY INT, V69, P655, DOI 10.1038/sj.ki.5000040; Haubitz M, 2005, KIDNEY INT, V67, P2313, DOI 10.1111/j.1523-1755.2005.00335.x; Hauskrecht Milos, 2005, Appl Bioinformatics, V4, P227, DOI 10.2165/00822942-200504040-00003; Hirsch HH, 2002, NEW ENGL J MED, V347, P488, DOI 10.1056/NEJMoa020439; Hirsch HH, 2005, TRANSPLANTATION, V79, P1277, DOI 10.1097/01.TP.0000156165.83160.09; Lyons-Weiler James, 2005, Cancer Inform, V1, P53; Mannon RB, 2005, AM J TRANSPLANT, V5, P2883, DOI 10.1111/j.1600-6143.2005.01096.x; Nguyen MT, 2005, AM J NEPHROL, V25, P318, DOI 10.1159/000086476; O'Riordan E, 2004, J AM SOC NEPHROL, V15, P3240, DOI 10.1097/01.ASN.0000145241.83482.68; Pappo O, 1996, MODERN PATHOL, V9, P105; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; Racusen LC, 1999, KIDNEY INT, V55, P713, DOI 10.1046/j.1523-1755.1999.00299.x; Randhawa PS, 2000, NEW ENGL J MED, V342, P1361, DOI 10.1056/NEJM200005043421809; Randhawa PS, 1999, TRANSPLANTATION, V67, P103, DOI 10.1097/00007890-199901150-00018; Rogers MA, 2003, CANCER RES, V63, P6971; Schaub S, 2005, AM J TRANSPLANT, V5, P729, DOI 10.1111/j.1600-6143.2005.00766.x; Schaub S, 2004, J AM SOC NEPHROL, V15, P219, DOI 10.1097/01.ASN.0000101031.52826.BE; Vapnik V. N., 1995, NATURE STAT LEARN TH; Vats A, 2003, TRANSPLANTATION, V75, P105, DOI 10.1097/01.TP.0000039842.75916.BF; VLAHOU A, 2005, J BIOMED BIOTECHNOL, V5, P308; Vlahou A, 2001, AM J PATHOL, V158, P1491, DOI 10.1016/S0002-9440(10)64100-4; Vlahou A, 2005, J CHROMATOGR B, V814, P11, DOI 10.1016/j.jchromb.2004.10.024; Voshol H, 2005, J PROTEOME RES, V4, P1192, DOI 10.1021/pr050060+; Weiss S. M., 1990, COMPUTER SYSTEMS LEA; Wittke S, 2005, AM J TRANSPLANT, V5, P2479, DOI 10.1111/j.1600-6143.2005.01053.x	33	24	26	AMERICAN SOCIETY NEPHROLOGY	WASHINGTON	1725 I ST, NW STE 510, WASHINGTON, DC 20006 USA	1046-6673			J AM SOC NEPHROL	J. Am. Soc. Nephrol.	NOV	2006	17	11					3248	3256		10.1681/ASN.2006050437		9	Urology & Nephrology	Urology & Nephrology	103UL	WOS:000241912100039	17035609	
J	Hamady, M; Betterton, MD; Knight, R				Hamady, Micah; Betterton, M. D.; Knight, Rob			Using the nucleotide substitution rate matrix to detect horizontal gene transfer	BMC BIOINFORMATICS			English	Article							DNA-BASE COMPOSITION; MOLECULAR EVOLUTION; THERMOTOGA-MARITIMA; BACTERIAL GENOMES; SURROGATE METHODS; TRANSFER EVENTS; RIBOSOMAL-RNA; IDENTIFICATION; SEQUENCE; PROTEIN	Background: Horizontal gene transfer (HGT) has allowed bacteria to evolve many new capabilities. Because transferred genes perform many medically important functions, such as conferring antibiotic resistance, improved detection of horizontally transferred genes from sequence data would be an important advance. Existing sequence-based methods for detecting HGT focus on changes in nucleotide composition or on differences between gene and genome phylogenies; these methods have high error rates. Results: First, we introduce a new class of methods for detecting HGT based on the changes in nucleotide substitution rates that occur when a gene is transferred to a new organism. Our new methods discriminate simulated HGT events with an error rate up to 10 times lower than does GC content. Use of models that are not time-reversible is crucial for detecting HGT. Second, we show that using combinations of multiple predictors of HGT offers substantial improvements over using any single predictor, yielding as much as a factor of 18 improvement in performance (a maximum reduction in error rate from 38% to about 3%). Multiple predictors were combined by using the random forests machine learning algorithm to identify optimal classifiers that separate HGT from non-HGT trees. Conclusion: The new class of HGT-detection methods introduced here combines advantages of phylogenetic and compositional HGT-detection techniques. These new techniques offer order-of-magnitude improvements over compositional methods because they are better able to discriminate HGT from non-HGT trees under a wide range of simulated conditions. We also found that combining multiple measures of HGT is essential for detecting a wide range of HGT events. These novel indicators of horizontal transfer will be widely useful in detecting HGT events linked to the evolution of important bacterial traits, such as antibiotic resistance and pathogenicity.	Univ Colorado, Dept Chem & Biochem, Boulder, CO 80309 USA; Univ Colorado, Dept Phys, Boulder, CO 80309 USA; Univ Colorado, Dept Comp Sci, Boulder, CO 80309 USA	Knight, R (reprint author), Univ Colorado, Dept Chem & Biochem, Boulder, CO 80309 USA.	hamady@colorado.edu; mdb@colorado.edu; rob@spot.colorado.edu					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Andersson JO, 2005, CELL MOL LIFE SCI, V62, P1182, DOI 10.1007/s00018-005-4539-z; Barlow RS, 2004, ANTIMICROB AGENTS CH, V48, P838, DOI 10.1128/AAC.48.3.838-842.2004; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bushman F, 2002, LATERAL DNA TRANSFER; Campbell A, 1999, P NATL ACAD SCI USA, V96, P9184, DOI 10.1073/pnas.96.16.9184; COFFEY TJ, 1991, MOL MICROBIOL, V5, P2255, DOI 10.1111/j.1365-2958.1991.tb02155.x; COX EC, 1967, P NATL ACAD SCI USA, V58, P1895, DOI 10.1073/pnas.58.5.1895; Deng WY, 2001, INFECT IMMUN, V69, P6323, DOI 10.1128/IAI.69.10.6323-6335.2001; Devauchelle C, 2001, J COMPUT BIOL, V8, P381, DOI 10.1089/106652701752236205; DiRuggiero J, 2000, MOL MICROBIOL, V38, P684, DOI 10.1046/j.1365-2958.2000.02161.x; Droge M, 1998, J BIOTECHNOL, V64, P75, DOI 10.1016/S0168-1656(98)00105-9; Dzidic S, 2003, ACTA PHARMACOL SIN, V24, P519; Edgar RC, 2004, BMC BIOINFORMATICS, V5, P1, DOI 10.1186/1471-2105-5-113; EDWARDS AR, 1994, MOL BIOL EVOL, V11, P911; FELSENSTEIN J, 1981, J MOL EVOL, V17, P368, DOI 10.1007/BF01734359; FREEDMAN D, 1967, MARKOV CHAINS; Garcia-Vallve S, 2000, GENOME RES, V10, P1719, DOI 10.1101/gr.130000; Ge F, 2005, PLOS BIOL, V3, P1709, DOI 10.1371/journal.pbio.0030316; Gophna U, 2003, GENE, V312, P151, DOI 10.1016/S0378-1119(03)00612-7; GROISMAN EA, 1993, P NATL ACAD SCI USA, V90, P1033, DOI 10.1073/pnas.90.3.1033; Hastings PJ, 2004, TRENDS MICROBIOL, V12, P401, DOI 10.1016/j.tim.2004.07.003; Hayes WS, 1998, GENOME RES, V8, P1154; HIGGINS DG, 1988, GENE, V73, P237, DOI 10.1016/0378-1119(88)90330-7; HILL T, 1996, STAT METHODS APPL; Hsiao WWL, 2005, PLOS GENET, V1, P540, DOI 10.1371/journal.pgen.0010062; Huynen MA, 1999, TRENDS MICROBIOL, V7, P281, DOI 10.1016/S0966-842X(99)01539-5; Kanehisa M., 2004, NUCLEIC ACIDS RES, V32, P277; Karlin S, 2001, TRENDS MICROBIOL, V9, P335, DOI 10.1016/S0966-842X(01)02079-0; Katz LA, 2002, INT J SYST EVOL MICR, V52, P1893, DOI 10.1099/ijs.0.02113-0; Kent WJ, 2000, GENOME RES, V10, P1115, DOI 10.1101/gr.10.8.1115; KIMURA M, 1968, NATURE, V217, P624, DOI 10.1038/217624a0; Kimura M, 1983, NEUTRAL THEORY MOL E; Kingman J. F. C., 1962, Z WAHRSCHEINLICHKEIT, V1, P14, DOI 10.1007/BF00531768; Knight RD, 2001, GENOME BIOL, V2; Koonin EV, 2003, MOL MICROBIOL, V50, P725, DOI 10.1046/j.1365-2958.2003.03808.x; Koski LB, 2001, MOL BIOL EVOL, V18, P404; Krzanowski W. J., 2000, PRINCIPLES MULTIVARI; Kurland CG, 2003, P NATL ACAD SCI USA, V100, P9658, DOI 10.1073/pnas.1632870100; Lake JA, 1997, MOL BIOL EVOL, V14, P213; LANAVE C, 1984, J MOL EVOL, V20, P86, DOI 10.1007/BF02101990; Lawrence JG, 1997, J MOL EVOL, V44, P383, DOI 10.1007/PL00006158; Lawrence JG, 2002, TRENDS MICROBIOL, V10, P1, DOI 10.1016/S0966-842X(01)02282-X; Lio P, 1998, GENOME RES, V8, P1233; Lobry JR, 1999, MOL BIOL EVOL, V16, P719; Lobry JR, 1996, BIOCHIMIE, V78, P323, DOI 10.1016/0300-9084(96)84764-X; Lobry J.R., 2002, GENOME BIOL, V3; Marquez R, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-11-r91; MOHDZAIN Z, 2004, J BACTERIOL, V186, P81114; MUTO A, 1987, P NATL ACAD SCI USA, V84, P166, DOI 10.1073/pnas.84.1.166; Nakamura Y, 2000, NUCLEIC ACIDS RES, V28, P292, DOI 10.1093/nar/28.1.292; Nakamura Y, 2004, NAT GENET, V36, P760, DOI 10.1038/ng1381; Nelson KE, 1999, NATURE, V399, P323; Nesbo CL, 2001, MOL BIOL EVOL, V18, P362; Ochman H, 2005, P NATL ACAD SCI USA, V102, P6595, DOI 10.1073/pnas.0502035102; OCHMAN H, 2001, CURR OPIN GENE DEV, V11, P619; Ochman H, 2000, NATURE, V405, P299, DOI 10.1038/35012500; Ochman H, 1996, P NATL ACAD SCI USA, V93, P7800, DOI 10.1073/pnas.93.15.7800; OTA R, 2003, J MOL EVOL S1, V57, P233; Ragan MA, 2001, FEMS MICROBIOL LETT, V201, P187, DOI 10.1111/j.1574-6968.2001.tb10755.x; Ragan MA, 2006, TRENDS MICROBIOL, V14, P4, DOI 10.1016/j.tim.2005.11.004; RODRIGUEZ F, 1990, J THEOR BIOL, V142, P485, DOI 10.1016/S0022-5193(05)80104-3; SALMOND GPC, 1993, TRENDS BIOCHEM SCI, V18, P7, DOI 10.1016/0968-0004(93)90080-7; Schultes E, 1997, RNA, V3, P792; Shea JE, 1996, P NATL ACAD SCI USA, V93, P2593, DOI 10.1073/pnas.93.6.2593; Shoemaker NB, 2001, APPL ENVIRON MICROB, V67, P561, DOI 10.1128/AEM.67.2.561-568.2001; Simonson AB, 2005, P NATL ACAD SCI USA, V102, P6608, DOI 10.1073/pnas.0501996102; Smit S, 2006, RNA, V12, P1, DOI 10.1261/rna.2183806; Smith AD, 2004, MOL BIOL EVOL, V21, P419; Snel B, 2002, GENOME RES, V12, P17, DOI 10.1101/gr.176501; SUEOKA N, 1961, COLD SPRING HARB SYM, V26, P35; SUEOKA N, 1988, P NATL ACAD SCI USA, V85, P2653, DOI 10.1073/pnas.85.8.2653; Sueoka N, 2002, GENE, V300, P141, DOI 10.1016/S0378-1119(02)01046-6; SUEOKA N, 1962, P NATL ACAD SCI USA, V48, P582, DOI 10.1073/pnas.48.4.582; SUEOKA N, 1995, J MOL EVOL, V42, P323; SYVANEN M, 1994, ANNU REV GENET, V28, P237; Weiss G, 2003, MOL BIOL EVOL, V20, P572, DOI 10.1093/molbev/msg073; Woese CR, 2000, MICROBIOL MOL BIOL R, V64, P202, DOI 10.1128/MMBR.64.1.202-236.2000; Zhang R, 2003, PHYSIOL GENOMICS, V16, P19, DOI 10.1152/physiolgenomics.00170.2003	80	11	13	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	OCT 26	2006	7								476	10.1186/1471-2105-7-476		21	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	107QU	WOS:000242186900001	17067382	
J	Rothfuss, A; Steger-Hartmann, T; Heinrich, N; Wichard, J				Rothfuss, Andreas; Steger-Hartmann, Thomas; Heinrich, Nikolaus; Wichard, Joerg			Computational prediction of the chromosome-damaging potential of chemicals	CHEMICAL RESEARCH IN TOXICOLOGY			English	Article							PROGRAMS DEREK; GENOTOXICITY; ABERRATIONS; MUTAGENICITY; SENSITIVITY; TOPKAT; ASSAY; SAR	We report on the generation of computer- based models for the prediction of the chromosome-damaging potential of chemicals as assessed in the in Vitro chromosome aberration (CA) test. On the basis of publicly available CA-test results of more than 650 chemical substances, half of which are drug-like compounds, we generated two different computational models. The first model was realized using the (Q) SAR tool MCASE. Results obtained with this model indicate a limited performance (53%) for the assessment of a chromosome-damaging potential (sensitivity), whereas CA- test negative compounds were correctly predicted with a specificity of 75%. The low sensitivity of this model might be explained by the fact that the underlying 2D-structural descriptors only describe part of the molecular mechanism leading to the induction of chromosome aberrations, that is, direct drug-DNA interactions. The second model was constructed with a more sophisticated machine learning approach and generated a classification model based on 14 molecular descriptors, which were obtained after feature selection. The performance of this model was superior to the MCASE model, primarily because of an improved sensitivity, suggesting that the more complex molecular descriptors in combination with statistical learning approaches are better suited to model the complex nature of mechanisms leading to a positive effect in the CA- test. An analysis of misclassified pharmaceuticals by this model showed that a large part of the false-negative predicted compounds were uniquely positive in the CA- test but lacked a genotoxic potential in other mutagenicity tests of the regulatory testing battery, suggesting that biologically nonsignificant mechanisms could be responsible for the observed positive CA- test result. Since such mechanisms are not amenable to modeling approaches it is suggested that a positive prediction made by the model reflects a biologically significant genotoxic potential. An integration of the machine-learning model as a screening tool in early discovery phases of drug development is proposed.	Schering AG, Expt Toxicol, D-13342 Berlin, Germany; Schering AG, Computat Chem, D-13342 Berlin, Germany; FMP, Mol Modeling Grp, D-13125 Berlin, Germany	Rothfuss, A (reprint author), Schering AG, Expt Toxicol, D-13342 Berlin, Germany.	andreas.rothfuss@schering.de					ASHBY J, 1978, NATURE, V271, P452, DOI 10.1038/271452a0; Breiman L., 1993, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cariello NF, 2002, MUTAGENESIS, V17, P321, DOI 10.1093/mutage/17.4.321; Chang CC, 2001, LIBSVM LIB SUPPORT V; Degrassi Francesca, 2004, Current Medicinal Chemistry - Anti-Cancer Agents, V4, P317, DOI 10.2174/1568011043352920; Diehl MS, 2000, ENVIRON MOL MUTAGEN, V35, P72; Greene N, 2002, ADV DRUG DELIVER REV, V54, P417, DOI 10.1016/S0169-409X(02)00012-1; Hastie T., 2001, SPRINGER SERIES STAT; HE L, 2003, CHEM RES TOXICOL, V16, P1576; *ICH 2SB, CPMPICH17495 ICH 2SB; Kirkland D, 2005, MUTAT RES-GEN TOX EN, V584, P1, DOI 10.1016/j.mrgentox.2005.02.004; Kirkland DJ, 2000, MUTAT RES-GEN TOX EN, V464, P137, DOI 10.1016/S1383-5718(99)00175-8; KLOPMAN G, 1994, MUTAT RES, V305, P33, DOI 10.1016/0027-5107(94)90124-4; Li H, 2005, CHEM RES TOXICOL, V18, P1071, DOI 10.1021/tx049652h; MERKWIRTH C, 2002, ENTOOL MATLAB TOOLBO; Miller B, 1998, MUTAT RES-REV MUTAT, V410, P81, DOI 10.1016/S1383-5742(97)00030-6; Obe G, 2002, MUTAT RES-FUND MOL M, V504, P17, DOI 10.1016/S0027-5107(02)00076-3; Parry EM, 2002, MUTAGENESIS, V17, P509, DOI 10.1093/mutage/17.6.509; RICHARD AM, 2001, SAR QSAR ENVIRON RES, V13, P1; Rosenkranz HS, 2004, MUTAT RES-GEN TOX EN, V559, P67, DOI 10.1016/j.mrgentox.2003.12.010; ROSENKRANZ HS, 1990, ENVIRON MOL MUTAGEN, V16, P149, DOI 10.1002/em.2850160304; Rosenkranz HS, 1999, SAR QSAR ENVIRON RES, V10, P277, DOI 10.1080/10629369908039181; Sadowski J, 1998, J MED CHEM, V41, P3325, DOI 10.1021/jm9706776; Serra JR, 2003, CHEM RES TOXICOL, V16, P153, DOI 10.1021/tx020077w; Simon-Hettich B, 2006, TOXICOLOGY, V224, P156, DOI 10.1016/j.tox.2006.04.032; Snyder RD, 2004, ENVIRON MOL MUTAGEN, V43, P143, DOI 10.1002/em.20013; Snyder RD, 2001, MUTAT RES-REV MUTAT, V488, P151, DOI 10.1016/S1383-5742(01)00055-2; Sofuni T., 1998, DATA BOOK CHROMOSOMA; TODESCHINI R, 2000, SERIES METHODS PRINC, V11; White AC, 2003, MUTAT RES-GEN TOX EN, V539, P77, DOI 10.1016/S1383-5718(03)00135-9; WICHARD J, 2006, IN PRESS NEUROCOMPUT; Zhao CY, 2006, TOXICOLOGY, V217, P105, DOI 10.1016/j.tox.2005.08.019	35	12	12	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0893-228X			CHEM RES TOXICOL	Chem. Res. Toxicol.	OCT 16	2006	19	10					1313	1319		10.1021/tx060136w		7	Chemistry, Medicinal; Chemistry, Multidisciplinary; Toxicology	Pharmacology & Pharmacy; Chemistry; Toxicology	094IK	WOS:000241232900007	17040100	
J	Enot, DP; Beckmann, M; Overy, D; Draper, J				Enot, David P.; Beckmann, Manfred; Overy, David; Draper, John			Predicting interpretability of metabolome models based on behavior, putative identity, and biological relevance of explanatory signals	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						mass spectral fingerprinting; phenotyping; random forest data analysis	FUNCTIONAL GENOMICS; CLASSIFICATION; PHENOTYPES; STRATEGY; MUTANTS; SAMPLES	Powerful algorithms are required to deal with the dimensionality of metabolomics data. Although many achieve high classification accuracy, the models they generate have limited value unless it can be demonstrated that they are reproducible and statistically relevant to the biological problem under investigation. Random forest (RF) generates models, without any requirement for dimensionality reduction or feature selection, in which individual variables are ranked for significance and displayed in an explicit manner. In metabolome fingerprinting by mass spectrometry, each metabolite can be represented by signals at several m/z. Exploiting a prior understanding of expected biochemical differences between sample classes, we aimed to develop meaningful metrics relevant to the significance both of the overall RF model and individual, potentially explanatory, signals. Pair-wise comparison of related plant genotypes with strong phenotypic differences demonstrated that robust models are not only reproducible but also logically structured, highlighting correlated m/z derived from just a small number of explanatory metabolites reflecting the biological differences between sample classes. RF models were also generated by using groupings of samples known to be increasingly phenotypically similar. Although classification accuracy was often reasonable, we demonstrated reproducibly in both Arabidopsis and potato a performance threshold based on margin statistics beyond which such models showed little structure indicative of either generalizibility or further biological interpretability. In a multiclass problem using 25 Arabidopsis genotypes, despite the complicating effects of ecotype background and secondary metabolome perturbations common to several mutations, the ranking of metabolome signals by RF provided scope for deeper interpretability.	Univ Wales, Inst Biol Sci, Aberystwyth SY23 3DA, Dyfed, Wales	Draper, J (reprint author), Univ Wales, Inst Biol Sci, Aberystwyth SY23 3DA, Dyfed, Wales.	jhd@aber.ac.uk					Aharoni Asaph, 2002, OMICS A Journal of Integrative Biology, V6, P217, DOI 10.1089/15362310260256882; Allen J, 2003, NAT BIOTECHNOL, V21, P692, DOI 10.1038/nbt823; Baumgartner C, 2004, BIOINFORMATICS, V20, P2985, DOI 10.1093/bioinformatics/bth343; Baumgartner C, 2005, J BIOMED INFORM, V38, P89, DOI 10.1016/j.jbi.2004.08.009; Bijlsma S, 2006, ANAL CHEM, V78, P567, DOI 10.1021/ac051495j; Bino RJ, 2004, TRENDS PLANT SCI, V9, P418, DOI 10.1016/j.tplants.2004.07.004; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Catchpole GS, 2005, P NATL ACAD SCI USA, V102, P14458, DOI 10.1073/pnas.0503955102; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dunn WB, 2005, METABOLOMICS, V1, P137, DOI 10.1007/s11306-005-4433-6; Dunn WB, 2005, ANALYST, V130, P606, DOI 10.1039/b418288j; Ein-Dor L, 2006, P NATL ACAD SCI USA, V103, P5923, DOI 10.1073/pnas.0601231103; Fiehn O, 2002, PLANT MOL BIOL, V48, P155, DOI 10.1023/A:1013713905833; Fiehn O, 2000, NAT BIOTECHNOL, V18, P1157, DOI 10.1038/81137; Good P, 2000, PERMUTATION TESTS PR; GOODACRE R, 2004, TRENDS BIOTECHNOL, V22, P439; Hastie T., 2001, ELEMENTS STAT LEARNI; Hellwege EM, 2000, P NATL ACAD SCI USA, V97, P8699, DOI 10.1073/pnas.150043797; Jonsson P, 2004, ANAL CHEM, V76, P1738, DOI 10.1021/ac0352427; Kell DB, 2001, PLANT PHYSIOL, V126, P943, DOI 10.1104/pp.126.3.943; Keurentjes JJB, 2006, NAT GENET, V38, P842, DOI 10.1038/ng1815; Lee K, 2004, BIOINFORMATICS, V20, P959, DOI 10.1093/bioinformatics/bth015; Lunetta KL, 2004, BMC GENET, V5, DOI 10.1186/1471-2156-5-32; Lyons-Weiler James, 2005, Cancer Inform, V1, P53; Manley B.F.J., 1994, MULTIVARIATE STAT ME; Mouille G, 2003, PLANT J, V35, P393, DOI 10.1046/j.1365-313X.2003.01807.x; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Roessner U, 2001, PLANT CELL, V13, P11, DOI 10.1105/tpc.13.1.11; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Schapire RE, 1998, ANN STAT, V26, P1651; Scholze J, 2000, CLIN DRUG INVEST, V20, P1, DOI 10.2165/00044011-200020010-00001; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; SOMORJAI RL, 2003, BIOINGORMATICS, V12, P1484; Vapnik V., 1998, STAT LEARNING THEORY; Ward JL, 2003, PHYTOCHEMISTRY, V62, P949, DOI 10.1016/S0031-9422(02)00705-7; Weckwerth W, 2004, P NATL ACAD SCI USA, V101, P7809, DOI 10.1073/pnas.0303415101; Weiss SM, 1991, COMPUTER SYSTEMS LEA; WU B, 2004, BIOINFORMATICS, V19, P1636	39	26	26	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	OCT 3	2006	103	40					14865	14870		10.1073/pnas.0605152103		6	Multidisciplinary Sciences	Science & Technology - Other Topics	092AL	WOS:000241069300041	16990432	
J	Rodriguez, JJ; Kuncheva, LI				Rodriguez, Juan J.; Kuncheva, Ludmila I.			Rotation forest: A new classifier ensemble method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classifier ensembles; AdaBoost; bagging; random forest; feature extraction; PCA; kappa-error diagrams	KARHUNEN-LOEVE EXPANSION; FEATURE SELECTION	We propose a method for generating classifier ensembles based on feature extraction. To create the training data for a base classifier, the feature set is randomly split into K subsets (K is a parameter of the algorithm) and Principal Component Analysis (PCA) is applied to each subset. All principal components are retained in order to preserve the variability information in the data. Thus, K axis rotations take place to form the new features for a base classifier. The idea of the rotation approach is to encourage simultaneously individual accuracy and diversity within the ensemble. Diversity is promoted through the feature extraction for each base classifier. Decision trees were chosen here because they are sensitive to rotation of the feature axes, hence the name "forest." Accuracy is sought by keeping all principal components and also using the whole data set to train each base classifier. Using WEKA, we examined the Rotation Forest ensemble on a random selection of 33 benchmark data sets from the UCI repository and compared it with Bagging, AdaBoost, and Random Forest. The results were favorable to Rotation Forest and prompted an investigation into diversity-accuracy landscape of the ensemble models. Diversity-error diagrams revealed that Rotation Forest ensembles construct individual classifiers which are more accurate than these in AdaBoost and Random Forest, and more diverse than these in Bagging, sometimes more accurate as well.	Univ Burgos, Escuela Politecn Super, Burgos 09006, Spain; Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales; Univ Valladolid, Dept Informat, Escuela Tecn Super Ingn Informat, E-47011 Valladolid, Spain	Rodriguez, JJ (reprint author), Univ Burgos, Escuela Politecn Super, Edificio C,C Francisco de Vitoria S-N, Burgos 09006, Spain.	jjrodriguez@ubu.es; calonso@infor.uva.es	Rodriguez, Juan/B-1014-2008	Rodriguez, Juan/0000-0002-3291-2739			Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Banfield R.E., 2004, P 5 INT WORKSH MULT; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich T.G., 2000, P 1 INT WORKSH MULT, P1; Fern X.Z., 2003, P 20 INT C MACH LEAR, P186, DOI Proc. 20th Int. Conf. Machine Learning; Fleiss J.L., 1981, STAT METHODS RATES P; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; Frank E., 2005, DATA MINING PRACTICA; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; Han J., 2001, DATA MINING CONCEPTS; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; KITTLER J, 1973, PATTERN RECOGN, V5, P335, DOI 10.1016/0031-3203(73)90025-3; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; KOLENIKOV S, 2004, P 2004 JOINT STAT M; KUNCHEVA LI, 2000, P 15 INT C PATT REC, V2, P169; KUNCHEVA LI, 2004, COMBINING PATTERN CL; KUNCHEVA LI, 2004, INFORM FUSION, V6, P3; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Long PM, 2003, MACH LEARN, V52, P31, DOI 10.1023/A:1023937123600; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; Mason L, 2000, MACH LEARN, V38, P243, DOI 10.1023/A:1007697429651; Melville P., 2004, P 5 INT WORKSH MULT, P293; NADEAU C, 2003, MACH LEARN, V62, P239; OZA NC, 2005, P 6 INT WORKSH MCS 2; OZA NC, 2003, P 4 INT WORKSH MULT; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; ROLI F, 2001, P 2 INT WORKSH MULT; ROLI F, 2004, P 5 INT WORKSH MULT; ROLI F, 2001, P 1 INT WORKSH MULT; ROLI F, 2002, P 3 INT WORKSH MULT; Schapire R. E., 1999, MACH LEARN, V37, P1; SCHAPIRE RE, 1999, MACH LEARN, V37, P397; Schapire R.E., 2002, P MSRI WORKSH NONL E; Schapire RE, 1998, ANN STAT, V26, P1651; SKURICHINA M, 2005, P 6 INT WORKSH MULT, P165; Tumer K, 2003, PATTERN ANAL APPL, V6, P65, DOI 10.1007/s10044-002-0181-7; van der Heijden F., 2004, CLASSIFICATION PARAM; Webb A., 1999, STAT PATTERN RECOGNI; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; WINDEATT T, 2003, P 4 INT WORKSH MULT	47	310	336	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1619	1630		10.1109/TPAMI.2006.211		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	071ME	WOS:000239605500006	16986543	
J	Donaldson, AE; Larsen, GY; Fullerton-Gleason, L; Olson, LM				Donaldson, A. E.; Larsen, G. Y.; Fullerton-Gleason, L.; Olson, L. M.			Classifying undetermined poisoning deaths	INJURY PREVENTION			English	Article							SUICIDE MORTALITY DATA; MISCLASSIFICATION; EPIDEMIOLOGY; STATISTICS; ACCIDENT; ADEQUACY; MANNER	Objective: To classify poisoning deaths of undetermined intent as either suicide or unintentional and to estimate the extent of underreported poisoning suicides. Methods: Based on 2002 statewide death certificate and medical examiner data in Utah, the authors randomly selected one half of undetermined and unintentional poisoning deaths for data abstraction and included all suicides. Bivariate analyses assessed differences in demographics, death characteristics, forensic toxicology results, mental health history, and other potentially contributing factors. Classification and regression tree (CART) analysis used information from unintentional and suicide poisoning deaths to create a classification tree that was applied to undetermined poisoning deaths. Results: The authors analyzed 41 unintentional, 87 suicide, and 84 undetermined poisonings. Undetermined and unintentional decedents were similar in the presence of opiates, physical health problems, and drug abuse. Although none of the undetermined decedents left a suicide note, previous attempt or intent to commit suicide was reported for 11 (13%) of these cases. CART analysis identified suicidal behavior, drug abuse, physical health problems, depressed mood, and age as discriminating between suicide and unintentional poisoning. It is estimated that suicide rates related to poisoning are underreported by approximately 30% and overall suicide rates by 10%. Unintentional poisoning death rates were underreported by 61%. Conclusions: This study suggests that manner of death determination relies on circumstance dependent variables that may not be consistently captured by medical examiners. Underreporting of suicide rates has important implications in policy development, research funding, and evaluation of prevention programs.	Univ Utah, Intermt Injury Control Res Ctr, Dept Pediat, Sch Med, Salt Lake City, UT 84158 USA; Univ New Mexico, Sch Med, Dept Emergency Med, Albuquerque, NM 87131 USA	Donaldson, AE (reprint author), Univ Utah, Intermt Injury Control Res Ctr, Dept Pediat, Sch Med, POB 581289, Salt Lake City, UT 84158 USA.	donaldson@hsc.utah.edu					HOLDING TA, 1978, BRIT J PSYCHIAT, V133, P542, DOI 10.1192/bjp.133.6.542; Breiman L., 1993, CLASSIFICATION REGRE; Breiman L., RANDOM FORESTS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Camidge DR, 2003, BRIT J CLIN PHARMACO, V56, P613, DOI 10.1046/j.1365-2125.2003.01910.x; Cantor C, 2001, PSYCHOPATHOLOGY, V34, P140, DOI 10.1159/000049297; Centers for Disease Control and Prevention, 2004, MMWR-MORBID MORTAL W, V53, P233; Centers for Disease Control and Prevention National Center for Injury Prevention and Control, WEB BAS INJ STAT QUE; Goldsmith SK, 2002, REDUCING SUICIDE NAT; HANZLICK R, NATL ASS MED EXAMINE; Hanzlick R, 1997, AM J FOREN MED PATH, V18, P228, DOI 10.1097/00000433-199709000-00003; *HARV INJ CONTR RE, UN DAT EL NAT VIOL I; Jougla E, 2002, REV EPIDEMIOL SANTE, V50, P49; KLECK G, 1988, SUICIDE LIFE-THREAT, V18, P219; Lewis RJ, INTRO CLASSIFICATION; Lindqvist P, 2002, FORENSIC SCI INT, V128, P136, DOI 10.1016/S0379-0738(02)00188-3; Linsley KR, 2001, BRIT J PSYCHIAT, V178, P465, DOI 10.1192/bjp.178.5.465; Mohler B, 2001, AM J PUBLIC HEALTH, V91, P150; OCARROLL PW, 1989, SUICIDE LIFE-THREAT, V19, P1; Ohberg A, 1998, ACTA PSYCHIAT SCAND, V98, P214, DOI 10.1111/j.1600-0447.1998.tb10069.x; Paulozzi LJ, 2004, INJURY PREV, V10, P47, DOI 10.1136/ip.2003.003434; PHILLIPS DP, 1993, SUICIDE LIFE-THREAT, V23, P307; SILVERMAN MM, 2001, NATL STRATEGY SUICID; SPEECHLEY M, 1991, CAN J PUBLIC HEALTH, V82, P38; Stanistreet D, 2001, MED SCI LAW, V41, P111	25	31	32	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1353-8047			INJURY PREV	Inj. Prev.	OCT	2006	12	5					338	343		10.1136/ip.2005.011171		6	Public, Environmental & Occupational Health	Public, Environmental & Occupational Health	091KI	WOS:000241025800015	17018678	
J	Stamatatos, E				Stamatatos, Efstathios			Authorship attribution based on feature set subspacing ensembles	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						text categorization; authorship attribution; classifier ensembles	TEXT CATEGORIZATION; CLASSIFIERS; ACCURACY	Authorship attribution can assist the criminal investigation procedure as well as cybercrime analysis. This task can be viewed as a single-label multi-class text categorization problem. Given that the style of a text can be represented as mere word frequencies selected in a language-independent method, suitable machine learning techniques able to deal with high dimensional feature spaces and sparse data can be directly applied to solve this problem. This paper focuses on classifier ensembles based on feature set subspacing. It is shown that an effective ensemble can be constructed using, exhaustive disjoint subspacing, a simple method producing many poor but diverse base classifiers. The simple model can be enhanced by a variation of the technique of cross-validated committees applied to the feature set. Experiments on two benchmark text corpora demonstrate the effectiveness of the presented method improving previously reported results and compare it to support vector machines, an alternative suitable machine learning approach to authorship attribution.	Univ Aegean, Dept Informat & Commun Syst Engn, Samos 83200, Greece	Stamatatos, E (reprint author), Univ Aegean, Dept Informat & Commun Syst Engn, Samos 83200, Greece.	stamatatos@aegean.gr	Stamatatos, Efstathios/F-2927-2012				Abbasi A, 2005, IEEE INTELL SYST, V20, P67, DOI 10.1109/MIS.2005.81; Argamon S., 2003, P 9 ACM SIGKDD INT C, P475; Baayen H., 1996, Literary & Linguistic Computing, V11, DOI 10.1093/llc/11.3.121; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burrows J. F., 1987, Literary & Linguistic Computing, V2, DOI 10.1093/llc/2.2.61; Chaski C. E., 2001, FORENSIC LINGUIST, V8, P1, DOI 10.1558/sll.2001.8.1.1; de Vel O, 2001, SIGMOD RECORD, V30, P55; Diederich J, 2003, APPL INTELL, V19, P109, DOI 10.1023/A:1023824908771; Holmen BA, 1998, TRANSPORT RES D-TR E, V3, P117, DOI 10.1016/S1361-9209(97)00032-1; Joachims T., 1998, P EUR C MACH LEARN; Juola P, 2004, P JOINT C ASS COMP H, P175; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KOPPEL M, 2003, P IJCAI 03 WORKSH CO; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Labbe C., 2001, J QUANT LINGUIST, V8, P213, DOI 10.1076/jqul.8.3.213.4100; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; MORTON AQ, 1965, J R STAT SOC SER A-G, V128, P169, DOI 10.2307/2344178; Mosteller F., 1984, APPL BAYESIAN CLASSI; OPITZ D, 1999, COMBINING ARTIFICIAL, P79; Parmanto B, 1996, ADV NEUR IN, V8, P882; Peng F., 2005, P 10 C EUR CHAPT ASS; Peng F., 2003, P C PAC ASS COMP LIN; Peng FC, 2004, INFORM RETRIEVAL, V7, P317, DOI 10.1023/B:INRT.0000011209.19643.e2; RUDMAN J, 1998, COMPUT HUMANITIES, V31, P351; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SICHEL HS, 1975, J AM STAT ASSOC, V70, P542, DOI 10.2307/2285930; Stamatatos E, 2000, COMPUT LINGUIST, V26, P471, DOI 10.1162/089120100750105920; Stamatatos E, 2001, COMPUT HUMANITIES, V35, P193, DOI 10.1023/A:1002681919510; Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7; van Halteren H., 2004, P 42 ANN M ASS COMP, DOI 10.3115/1218955.1218981; Vapnik VN, 1995, NATURE STAT LEARNING; Witten I., 2000, DATA MINING PRACTICA; Zenobi G., 2001, P 12 EUR C MACH LEAR, P576	33	7	9	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130			INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	OCT	2006	15	5					823	838		10.1142/S0218213006002965		16	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	098DZ	WOS:000241502500010		
J	Culp, M; Johnson, K; Michailidis, G				Culp, Mark; Johnson, Kjell; Michailidis, George			ada: an R package for stochastic boosting	JOURNAL OF STATISTICAL SOFTWARE			English	Article						boosting algorithms; R; machine learning; classification; implementation of statistical algorithms	CLASSIFICATION; MACHINE	Boosting is an iterative algorithm that combines simple classification rules with 'mediocre' performance in terms of misclassification error rate to produce a highly accurate classification rule. Stochastic gradient boosting provides an enhancement which incorporates a random mechanism at each boosting step showing an improvement in performance and speed in generating the ensemble. ada is an R package that implements three popular variants of boosting, together with a version of stochastic gradient boosting. In addition, useful plots for data analytic purposes are provided along with an extension to the multi-class case. The algorithms are illustrated with synthetic and real data sets.	Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA; Pfizer Global Res & Dev, Ann Arbor, MI 48105 USA	Culp, M (reprint author), Univ Michigan, Dept Stat, 436 W Hall,550 E Univ, Ann Arbor, MI 48109 USA.	culpm@umich.edu; Kjell.Johnson@pfizer.com; gmichail@umich.edu					Becker RA, 1988, NEW S LANGUAGE PROGR; BOONYANUNTA N, 2003, P 16 INT C DEV APPL, P674; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, INT C MACH LEARN, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hastie T., 2001, ELEMENTS STAT LEARNI; HOTHORN T, 2006, MBOOST MODEL BASED B; HOTHORN T, 2006, IN PRESS BIOINFORMAT, DOI DOI 10.1093/BIOINFORMATICS/BT1462; Huang K, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-78; KAWAKITA M, 2005, FISH RES, V76, P323; LEMMENS A, 2005, J MARKETING RES, V43, P276; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; *R DEV COR TEAM, 2006, R LANG ENV STAT COMP, pO6410; Ridgeway G, 2006, GBM GEN BOOSTED REGR; Rosset S, 2004, J MACH LEARN RES, V5, P941; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Segal MR, 2004, MACHINE LEARNING BEN; SUGATA S, 2001, J CHEM SOFTWARE, V7; Therneau T. M., 2005, RPART RECURSIVE PART; Ulintz PJ, 2006, MOL CELL PROTEOMICS, V5, P497, DOI 10.1074/mcp.M500233-MCP200; Valiant L. G., 1984, P 16 ANN ACM S THEOR, P436, DOI DOI 10.1145/800057.808710	28	13	13	JOURNAL OF STATISTICAL SOFTWARE	LOS ANGELES	UCLA DEPT STATISTICS, 8130 MATH SCIENCES BLDG, BOX 951554, LOS ANGELES, CA 90095-1554 USA	1548-7660			J STAT SOFTW	J. Stat. Softw.	OCT	2006	17	2					1	27				27	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	102JW	WOS:000241808000001		
J	Tang, EK; Suganthan, PN; Yao, X				Tang, E. K.; Suganthan, P. N.; Yao, X.			An analysis of diversity measures	MACHINE LEARNING			English	Article						classifier ensemble; diversity measures; margin distribution; majority vote; disagreement measure; double fault measure; KW variance; interrater agreement; generalized diversity; measure of difficulty; entropy measure; coincident failure diversity	NEURAL-NETWORK ENSEMBLES; CLASSIFIER ENSEMBLES; MARGINS	Diversity among the base classifiers is deemed to be important when constructing a classifier ensemble. Numerous algorithms have been proposed to construct a good classifier ensemble by seeking both the accuracy of the base classifiers and the diversity among them. However, there is no generally accepted definition of diversity, and measuring the diversity explicitly is very difficult. Although researchers have designed several experimental studies to compare different diversity measures, usually confusing results were observed. In this paper, we present a theoretical analysis on six existing diversity measures (namely disagreement measure, double fault measure, KW variance, inter-rater agreement, generalized diversity and measure of difficulty), show underlying relationships between them, and relate them to the concept of margin, which is more explicitly related to the success of ensemble learning algorithms. We illustrate why confusing experimental results were observed and show that the discussed diversity measures are naturally ineffective. Our analysis provides a deeper understanding of the concept of diversity, and hence can help design better ensemble learning algorithms.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England	Suganthan, PN (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	tangke@pmail.ntu.edu.sg; epnsugan@ntu.edu.sg; X.Yao@cs.bham.ac.uk	 Suganthan, .Ponnuthurai /A-5023-2011; Tang, Ke/E-5656-2015				Atukorale AS, 2003, NEUROCOMPUTING, V51, P75, DOI 10.1016/S0925-2312(02)00603-3; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown G., 2004, INFORM FUSION, V6, P5; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Dietterich T.G., 2000, MACH LEARN, V40, P1; Fleiss J.L., 1981, STAT METHODS RATES P; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Kuncheva LI, 2003, LECT NOTES COMPUT SC, V2652, P1126; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; LIU JY, 1997, TOOL ENG, V4, P3; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; Mason L, 2000, MACH LEARN, V38, P243, DOI 10.1023/A:1007697429651; PATRIDGE D, 1997, INFORMATION SOFTWARE, V39, P707; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Schapire R., 1999, P 4 EUR C COMP LEARN, P1; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Skalak D., 1996, P AM ASS ART INT AAA; Suganthan PN, 1999, IEEE T NEURAL NETWOR, V10, P193, DOI 10.1109/72.737507; Suykens JaK, 2002, LEAST SQUARES SUPPOR; Tamon C, 2000, LECT NOTES ARTIF INT, V1810, P404; Vapnik VN, 1995, NATURE STAT LEARNING	30	86	98	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	OCT	2006	65	1					247	271		10.1007/s10994-006-9449-2		25	Computer Science, Artificial Intelligence	Computer Science	088FN	WOS:000240797500009		
J	Lopez, F; Granjeaud, S; Ara, T; Ghattas, B; Gautheret, D				Lopez, Fabrice; Granjeaud, Samuel; Ara, Takeshi; Ghattas, Badih; Gautheret, Daniel			The disparate nature of "intergenic" polyadenylation sites	RNA-A PUBLICATION OF THE RNA SOCIETY			English	Article						polyadenylation; 3 ' UTR; transcript isoforms; genome annotation	HUMAN MESSENGER-RNAS; LARGE-SCALE ANALYSIS; ALTERNATIVE POLYADENYLATION; FULL-LENGTH; HUMAN GENES; GENOME; SEQUENCE; COMPLEX; MOUSE; TRANSCRIPTOME	The termination of mature eukaryotic mRNAs occurs at specific polyadenylation sites located downstream from stop codons in the 3'-untranslated region (UTR). An accurate delineation of these sites is essential for the study of 3'-UTR-based gene regulation and for the design of pertinent probes for transcriptome analysis. Although typical poly(A) sites are located between 0 and 2 kb from the stop codon, EST sequence analyses have identified sites located at unexpectedly long ranges (5-10 kb) in a number of genes. Here we perform a complete mapping of EST and full-length cDNA sequences on the mouse and human genome to observe putative poly(A) sites extending beyond annotated 3'-ends and into the intergenic regions. We introduce several quality parameters for poly(A) site prediction and train a classification tree to associate P-values to predicted sites. We observe a higher than background level of high-scoring sites up to 12-15 kb past the stop codon, both in human and mouse. This leads to an estimate of about 5000 human genes having unreported 3'-end extensions and about 3500 novel polyadenylated transcripts lying in present "intergenic'' regions. These high-scoring, long-range poly(A) sites corresponding to novel transcripts and gene extensions should be incorporated into current human and mouse gene repositories.	Univ Aix Marseille 2, INSERM, ERM 206, F-13288 Marseille 09, France; Univ Aix Marseille 2, CNRS, UMR 6206, Inst Math Luminy, F-13288 Marseille, France	Gautheret, D (reprint author), Univ Aix Marseille 2, INSERM, ERM 206, Luminy Case 906, F-13288 Marseille 09, France.	gautheret@esil.univ-mrs.fr					Ara T, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-189; Ashurst JL, 2005, NUCLEIC ACIDS RES, V33, pD459, DOI 10.1093/nar/gki135; Beaudoing E, 2001, GENOME RES, V11, P1520, DOI 10.1101/gr.190501; Beaudoing E, 2000, GENOME RES, V10, P1001, DOI 10.1101/gr.10.7.1001; Birney E, 2004, GENOME RES, V14, P925, DOI 10.1101/gr.1860604; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Carninci P, 2005, SCIENCE, V309, P1559, DOI 10.1126/science.1112014; Carninci P, 2001, GENOMICS, V77, P79, DOI 10.1006/geno.2001.6601; Carninci P, 2003, GENOME RES, V13, P1273, DOI 10.1101/gr.1119703; EdwaldsGilbert G, 1997, NUCLEIC ACIDS RES, V25, P2547, DOI 10.1093/nar/25.13.2547; Gautheret D, 1998, GENOME RES, V8, P524; Imanishi T, 2004, PLOS BIOL, V2, P856, DOI 10.1371/journal.pbio.0020162; Iseli C, 2002, GENOME RES, V12, P1068, DOI 10.1101/gr.62002; John B, 2004, PLOS BIOL, V2, P1862, DOI 10.1371/journal.pbio.0020363; Johnson JM, 2005, TRENDS GENET, V21, P93, DOI 10.1016/j.tig.2004.12.008; Kampa D, 2004, GENOME RES, V14, P331, DOI 10.1011/gr.2094104; LaCava J, 2005, CELL, V121, P713, DOI 10.1016/j.cell.2005.04.029; Legendre M, 2003, BMC GENOMICS, V4, DOI 10.1186/1471-2164-4-7; Le Texier V, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-169; Lewis BP, 2005, CELL, V120, P15, DOI 10.1016/j.cell.2004.12.035; McGinnis S, 2004, NUCLEIC ACIDS RES, V32, P20; MIGNONE F, 2002, GENOME BIOL, V3, P3; *NCBI, 2002, NCBI HDB, pCH17; Pruitt KD, 2005, NUCLEIC ACIDS RES, V33, pD501, DOI 10.1093/nar/gki025; STRATCHAN T, 1999, HUMAN MOL GENETICS, V2; Tian B, 2005, NUCLEIC ACIDS RES, V33, P201, DOI 10.1093/nar/gki158; Touriol C, 2000, J BIOL CHEM, V275, P19361, DOI 10.1074/jbc.M908431199; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Wyers F, 2005, CELL, V121, P725, DOI 10.1016/j.cell.2005.04.030; Yan J, 2005, GENOME RES, V15, P369, DOI 10.1101/gr.3109605	31	16	16	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1355-8382			RNA	RNA-Publ. RNA Soc.	OCT	2006	12	10					1794	1801		10.1261/rna.136206		8	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	089DV	WOS:000240861400004	16931874	
J	Koike, A				Koike, A.			Comparison of methods for chemical-compound affinity prediction	SAR AND QSAR IN ENVIRONMENTAL RESEARCH			English	Article						structure activity relationship; boosting; bagging; support vector machine	RESISTANCE REVERSAL AGENTS; SUPPORT VECTOR MACHINES; RECEPTOR-ACTIVITY; CYTOCHROME-P450 3A4; GENETIC ALGORITHM; 5-HT1A; CLASSIFICATION; DERIVATIVES; INHIBITORS; PHARMACOPHORE	The selection of effective features from various descriptors of chemical compounds and the exploitation of the most appropriate classifier is a momentous issue in improving overall accuracies of virtual screening of chemical compounds. In this article, the performance of various feature-selection methods and various classifiers of chemical compound- protein binding affinities are compared by using six series of compounds: cytochrome P450 2C9 inhibitors, multi-drug-resistance reversal compounds, estrogen receptor ligands, inhibitors of human ether-a-go-go-related genes, and ligands of serotonin receptor 5HT1A and 5HT2A. As a result, it was found that the genetic algorithm was superior to the other feature-selection methods, and its combination with Random Forests and Adaboosts or Baggings gave almost the same performance as support-vector machines and was superior to the other classifiers. The precision and recall of these methods were almost the same or ascendant to those of previous work. The automatically selected descriptors for each protein-compound affinity prediction were plausible and would be informative to interpret the resulting model.	Hitachi Ltd, Cent Res Lab, Kokubunji, Tokyo 1858601, Japan; Reverse Proteom Res Inst, Chiba 2920818, Japan	Koike, A (reprint author), Hitachi Ltd, Cent Res Lab, 1-280 Higashi Koigakubo, Kokubunji, Tokyo 1858601, Japan.	asako.koike.ea@hitachi.com					Bakken GA, 2000, J MED CHEM, V43, P4534, DOI 10.1021/jm000244u; Boksa J, 2001, POL J PHARMACOL, V53, P501; Boksa J, 2003, POL J PHARMACOL, V55, P1013; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1992, INT STAT REV, V3, P291; Byrtus H, 2001, POL J PHARMACOL, V53, P395; Cavalli A, 2002, J MED CHEM, V45, P3844, DOI 10.1021/jm0208875; Chlon G, 2001, POL J PHARMACOL, V53, P359; Cho SJ, 2002, J CHEM INF COMP SCI, V42, P927, DOI 10.1021/ci010247v; CHOWDHURY S, 2005, CURR MED RES OPIN, V12, P1985; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Dukat M, 2004, BIOORGAN MED CHEM, V12, P2545, DOI 10.1016/j.bmc.2004.03.026; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Keseru GM, 2003, BIOORG MED CHEM LETT, V13, P2773, DOI 10.1016/S0960-894X(03)00492-X; Klopman G, 1997, MOL PHARMACOL, V52, P323; Kriegl JM, 2005, EUR J PHARM SCI, V24, P451, DOI 10.1016/j.ejps.2004.12.009; Leopoldo M, 2004, J MED CHEM, V47, P6616, DOI 10.1021/jm049702f; Lewis DFV, 2002, DRUG METAB REV, V34, P69, DOI 10.1081/DMR-120001391; Li H, 2005, CHEM RES TOXICOL, V18, P1071, DOI 10.1021/tx049652h; MCCALLUM A, 1998, P AAAI ICML 98 WORKS, V41; MITCHELL M, 1996, INTRO GENETIC ALGOIR; Mitchell T. M., 1997, MACHINE LEARNING; OBNISKA J, 2003, POL J PHARMACOL, V55, P556; Paluchowska MH, 2002, POL J PHARMACOL, V54, P641; Paluchowska MH, 2001, POL J PHARMACOL, V53, P369; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Sabb AL, 2001, BIOORG MED CHEM LETT, V11, P1069, DOI 10.1016/S0960-894X(01)00151-2; Schalkoff R. J., 1991, PATTERN RECOGNITION; SHAPIRE R, 1999, P 10 INT C ALG LEARN; Smith DA, 1997, DRUG DISCOV TODAY, V2, P479, DOI 10.1016/S1359-6446(97)01085-4; Song MH, 2006, J CHEM INF MODEL, V46, P392, DOI 10.1021/ci050308f; Sutherland JJ, 2003, J CHEM INF COMP SCI, V43, P1906, DOI 10.1021/ci034143r; Tobita M, 2005, BIOORG MED CHEM LETT, V15, P2886, DOI 10.1016/j.bmcl.2005.03.080; Vapnick V., 1995, NATURE STAT LEARNING; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Yang JM, 2005, PROTEINS, V59, P205, DOI 10.1002/prot.20387; Yang Y. M., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536	38	4	4	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1062-936X			SAR QSAR ENVIRON RES	SAR QSAR Environ. Res.	OCT	2006	17	5					497	514		10.1080/10629360600934168		18	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications; Environmental Sciences; Mathematical & Computational Biology; Toxicology	Chemistry; Computer Science; Environmental Sciences & Ecology; Mathematical & Computational Biology; Toxicology	090LW	WOS:000240953800004	17018425	
J	Rossi, A; Sandri, M; Bianco, M; Marsilio, A; Tansella, M; Amaddeo, F				Rossi, Alberto; Sandri, Marco; Bianco, Maria; Marsilio, Alessandra; Tansella, Michele; Amaddeo, Francesco			Factors associated with clinicians' dispositions in an out-patient psychiatric department	SOCIAL PSYCHIATRY AND PSYCHIATRIC EPIDEMIOLOGY			English	Article						out-patient care; decision-making; psychiatric care; service evaluation; patient selection; mental health service	EMERGENCY ROOM; PATIENTS WANT; SERVICES; DECISIONS; ADMISSION; CARE; HOSPITALIZATION; DETERMINANTS; INPATIENT; DIAGNOSIS	This cross-sectional study attempted to identify factors associated with clinicians' dispositions of patients after the first visit in an out-patient psychiatric department. Over a 33-month period, all new episodes of care with the department were included in the study. For each patient, socio-demographic, clinical information and contact characteristics were prospectively collected in relation to the first visit, as was information on case disposition. Factors associated with clinicians' disposition were analysed. Of the 1,138 patients who met the study criteria, 848 (75%) were followed up by the department, 150 (13%) were referred to other services and 140 (12%) were discharged. Suffering from a major psychiatric disorder, being younger and not living in an institution influenced clinicians' disposition to follow-up patients. Older age increased the chances of being referred to other services rather than discharged. Examining decision-making behaviour in out-patient psychiatric departments is a worthwhile endeavour because this setting represents the main entry point of modern and accessible community-based systems of care. The findings confirmed the importance of psychiatric determinants in the dispositional process and contribute to make clinicians more aware of other factors related to their decision-making.	Policlin GB Rossi, Sect Psychiat & Clin Psychol, Dept Med & Publ Hlth, I-37134 Verona, Italy; Univ Verona, Sect Psychiat & Clin Psychol, Dept Med & Publ Hlth, I-37100 Verona, Italy	Rossi, A (reprint author), Policlin GB Rossi, Sect Psychiat & Clin Psychol, Dept Med & Publ Hlth, Piazzale LA Scuro 10, I-37134 Verona, Italy.	alberto.rossi@medicina.univr.it	Rossi, Alberto/B-4219-2010; Amaddeo, Francesco/B-4144-2010; Tansella, Michele/B-4106-2010; Sandri, Marco/L-2875-2013	Sandri, Marco/0000-0002-1422-5695			Agresti A., 1996, INTRO CATEGORICAL DA; APSLER R, 1983, ARCH GEN PSYCHIAT, V40, P1133; Austin PC, 2004, AM STAT, V58, P131, DOI 10.1198/0003130043277; Bass C, 2002, ACTA PSYCHIAT SCAND, V105, P117, DOI 10.1034/j.1600-0447.2002.00275.x; Becker T, 2006, ACTA PSYCHIAT SCAND, V113, P9, DOI 10.1111/j.1600-0447.2005.00711.x; Blenkiron P, 1998, Int J Health Care Qual Assur Inc Leadersh Health Serv, V11, P188, DOI 10.1108/09526869810231550; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chamberlin J, 2005, EPIDEMIOL PSICHIAT S, V14, P10; DERKSEN S, 1992, BRIT J MATH STAT PSY, V45, P265; FRIEDMAN S, 1983, J NERV MENT DIS, V171, P155, DOI 10.1097/00005053-198303000-00004; GERSON S, 1980, AM J PSYCHIAT, V137, P1; Scandinavica AP, 1999, ACTA PSYCHIAT SCAND, V100, P319; Hosmer D.W., 2000, APPL LOGISTIC REGRES; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; JOHNSON JH, 1979, J CLIN PSYCHOL, V35, P844, DOI 10.1002/1097-4679(197910)35:4<844::AID-JCLP2270350433>3.0.CO;2-G; Khanna R, 1992, Int J Soc Psychiatry, V38, P293, DOI 10.1177/002076409203800408; KHURI R, 1984, HOSP COMMUNITY PSYCH, V35, P715; LIAW A, 2002, RANDOM FOREST R CLAS; LINCOLN CV, 1995, PSYCHIATR SERV, V46, P1166; MARSON DC, 1988, AM J PSYCHIAT, V145, P918; MENDEL WM, 1969, ARCH GEN PSYCHIAT, V20, P321; NEUMANN M, 1990, ISRAEL J PSYCHIAT, V27, P199; Noble LM, 1999, ACTA PSYCHIAT SCAND, V100, P321; RABINOWITZ J, 1995, PSYCHIATR SERV, V46, P712; RABINOWITZ J, 1994, J PSYCHIAT RES, V28, P475, DOI 10.1016/0022-3956(94)90005-1; Rossi A, 2005, SOC PSYCH PSYCH EPID, V40, P50, DOI 10.1007/s00127-005-0845-x; Rossi A, 2005, AUST NZ J PSYCHIAT, V39, P414, DOI 10.1080/j.1440-1614.2005.01590.x; Rossi A, 2002, BRIT J PSYCHIAT, V181, P331, DOI 10.1192/bjp.181.4.331; Schaefer BA, 2003, ACTA PSYCHIAT SCAND, V107, P188, DOI 10.1034/j.1600-0447.2003.01453.x; Schnyder U, 1999, ACTA PSYCHIAT SCAND, V99, P179, DOI 10.1111/j.1600-0447.1999.tb00974.x; SLAGG NB, 1993, HOSP COMMUNITY PSYCH, V44, P252; Statacorp, 2001, STAT STAT SOFTW REL; Tansella M, 1991, PSYCHOL MED        S, V19, P5; TANSELLA M, 1987, PSYCHOL MED, V17, P283; Viinamaki H, 1998, ACTA PSYCHIAT SCAND, V97, P47, DOI 10.1111/j.1600-0447.1998.tb09962.x; Way BB, 2001, PSYCHIATR SERV, V52, P214, DOI 10.1176/appi.ps.52.2.214; WAY BB, 1992, HOSP COMMUNITY PSYCH, V43, P703	37	2	2	DR DIETRICH STEINKOPFF VERLAG	DARMSTADT	PO BOX 10 04 62, D-64204 DARMSTADT, GERMANY	0933-7954			SOC PSYCH PSYCH EPID	Soc. Psychiatry Psychiatr. Epidemiol.	OCT	2006	41	10					832	840		10.1007/s00127-006-0105-8		9	Psychiatry	Psychiatry	089WW	WOS:000240913600012	16865635	
J	Kedarisetti, KD; Kurgan, L; Dick, S				Kedarisetti, Kanaka Durga; Kurgan, Lukasz; Dick, Scott			Classifier ensembles for protein structural class prediction with varying homology	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						SCOP structural class; sequence homology; protein primary sequence; feature selection; classifier ensemble	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; SECONDARY STRUCTURE; GLOBULAR-PROTEINS; FOLDING TYPES; RECOGNITION; SEQUENCE; PARADOX; SCOP	Structural class characterizes the overall folding type of a protein or its domain. A number of computational methods have been proposed to predict structural class based on primary sequences; however, the accuracy of these methods is strongly affected by sequence homology. This paper proposes, an ensemble classification method and a compact feature-based sequence representation. This method improves prediction accuracy for the four main structural classes compared to competing methods, and provides highly accurate predictions for sequences of widely varying homologies. The experimental evaluation of the proposed method shows superior results across sequences that are characterized by entire homology spectrum, ranging from 25% to 90% homology. The error rates were reduced by over 20% when compared with using individual prediction methods and most commonly used composition vector representation of protein sequences. Comparisons with competing methods on three large benchmark datasets consistently show the superiority of the proposed method. (c) 2006 Elsevier Inc. All rights reserved.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2M7, Canada	Kurgan, L (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2M7, Canada.	lkurgan@ece.ualberta.ca	Kurgan, Lukasz/B-5721-2009	Kurgan, Lukasz/0000-0002-7749-0314			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, P226; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BLACK SD, 1991, ANAL BIOCHEM, V193, P72, DOI 10.1016/0003-2697(91)90045-U; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bu WS, 1999, EUR J BIOCHEM, V266, P1043, DOI 10.1046/j.1432-1327.1999.00947.x; Cai YD, 2003, J THEOR BIOL, V221, P115, DOI 10.1006/jtbi.2003.3179; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; Camoglu Orhan, 2005, Journal of Bioinformatics and Computational Biology, V3, P717, DOI 10.1142/S0219720005001259; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1993, J PROTEIN CHEM, V12, P169, DOI 10.1007/BF01026038; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CORNETTE JL, 1987, J MOL BIOL, V195, P659, DOI 10.1016/0022-2836(87)90189-6; Diplarisa S., 2005, P 10 PANH C INF PCI, P448; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.3.CO;2-B; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Eisenhaber F, 1996, PROTEINS, V25, P169, DOI 10.1002/(SICI)1097-0134(199606)25:2<169::AID-PROT3>3.3.CO;2-5; Feng KY, 2005, BIOCHEM BIOPH RES CO, V334, P213, DOI 10.1016/j.bbrc.2005.06.075; Frank E., 2005, DATA MINING PRACTICA; Gromiha MM, 1998, PROTEIN ENG, V11, P249, DOI 10.1093/protein/11.4.249; Hall M. A., 1999, THESIS U WAIKATO HAM; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Jin LX, 2003, COMPUT BIOL CHEM, V27, P373, DOI 10.1016/S1476-9271(02)00087-7; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; KEDARISETTI K, 2006, IN PRESS COMPUTATION; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KURGAN L, 2006, PREDICTION STRUCTURA; LEVITT M, 1976, NATURE, V261, P552, DOI 10.1038/261552a0; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; Lin Z, 2001, J PROTEIN CHEM, V20, P217, DOI 10.1023/A:1010967008838; Liu H., 1996, P 13 INT C MACH LEAR, P319; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; NAKASHIMA H, 1986, J BIOCHEM-TOKYO, V99, P153; Platt J., 1998, ADV KERNEL METHODS S; Seewald A.K., 2002, P 19 INT C MACH LEAR, P554; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P577, DOI 10.1016/j.bbrc.2005.06.128; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Tan Aik Choon, 2003, Genome Inform, V14, P206; Wang ZX, 2000, PROTEINS, V38, P165, DOI 10.1002/(SICI)1097-0134(20000201)38:2<165::AID-PROT5>3.0.CO;2-V; ZHANG CT, 1995, PROTEIN ENG, V8, P425, DOI 10.1093/protein/8.5.425; ZHANG CT, 1992, PROTEIN SCI, V1, P401; Zhang ZD, 2001, J THEOR BIOL, V208, P65, DOI 10.1006/jtbi.2000.2201	50	119	121	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	SEP 29	2006	348	3					981	988		10.1016/j.bbrc.2006.07.141		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	079HM	WOS:000240166500028	16904630	
J	Jiang, R; Yang, H; Sun, FZ; Chen, T				Jiang, Rui; Yang, Hua; Sun, Fengzhu; Chen, Ting			Searching for interpretable rules for disease mutations: a simulated annealing bump hunting strategy	BMC BIOINFORMATICS			English	Article							SINGLE NUCLEOTIDE POLYMORPHISMS; AMINO-ACID SUBSTITUTIONS; SECONDARY STRUCTURE; LAC REPRESSOR; PROTEIN; PREDICTION; INFORMATION; SEQUENCE	Background: Understanding how amino acid substitutions affect protein functions is critical for the study of proteins and their implications in diseases. Although methods have been developed for predicting potential effects of amino acid substitutions using sequence, three-dimensional structural, and evolutionary properties of proteins, the applications are limited by the complication of the features and the availability of protein structural information. Another limitation is that the prediction results are hard to be interpreted with physicochemical principles and biological knowledge. Results: To overcome these limitations, we proposed a novel feature set using physicochemical properties of amino acids, evolutionary profiles of proteins, and protein sequence information. We applied the support vector machine and the random forest with the feature set to experimental amino acid substitutions occurring in the E. coli lac repressor and the bacteriophage T4 lysozyme, as well as to annotated amino acid substitutions occurring in a wide range of human proteins. The results showed that the proposed feature set was superior to the existing ones. To explore physicochemical principles behind amino acid substitutions, we designed a simulated annealing bump hunting strategy to automatically extract interpretable rules for amino acid substitutions. We applied the strategy to annotated human amino acid substitutions and successfully extracted several rules which were either consistent with current biological knowledge or providing new insights for the understanding of amino acid substitutions. When applied to unclassified data, these rules could cover a large portion of samples, and most of the covered samples showed good agreement with predictions made by either the support vector machine or the random forest. Conclusion: The prediction methods using the proposed feature set can achieve larger AUC ( the area under the ROC curve), smaller BER ( the balanced error rate), and larger MCC ( the Matthews' correlation coefficient) than those using the published feature sets, suggesting that our feature set is superior to the existing ones. The rules extracted by the simulated annealing bump hunting strategy have comparable coverage and accuracy but much better interpretability as those extracted by the patient rule induction method ( PRIM), revealing that the strategy is more effective in inducing interpretable rules.	Univ So Calif, Los Angeles, CA 90089 USA	Chen, T (reprint author), Univ So Calif, MCB201,1050 Childs Way, Los Angeles, CA 90089 USA.	ruijiang@usc.edu; huayang@usc.edu; fsun@usc.edu; tingchen@usc.edu	Sun, Fengzhu /G-4373-2010; Jiang, Rui/B-1345-2012	Jiang, Rui/0000-0002-7533-3753			Bairoch A., 2007, NUCLEIC ACIDS RES, V33, P154; Bao L, 2005, BIOINFORMATICS, V21, P2185, DOI 10.1093/bioinformatics/bti365; Berg J.M., 2002, BIOCHEMISTRY; BOWIE JU, 1991, SCIENCE, V253, P164, DOI 10.1126/science.1853201; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chasman D, 2001, J MOL BIOL, V307, P683, DOI 10.1006/jmbi.2001.4510; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Durbin R., 1998, BIOL SEQUENCE ANAL P; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Ferrer-Costa C, 2004, PROTEINS, V57, P811, DOI 10.1002/prot.20252; Ferrer-Costa C, 2002, J MOL BIOL, V315, P771, DOI 10.1006/jmbi.2001.5255; FINN RD, 2006, NUCLEIC ACIDS RES, pD247; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Krawczak M, 2000, HUM MUTAT, V15, P45, DOI 10.1002/(SICI)1098-1004(200001)15:1<45::AID-HUMU10>3.0.CO;2-T; Krishnan VG, 2003, BIOINFORMATICS, V19, P2199, DOI 10.1093/bioinformatics/btg297; MARKIEWICZ P, 1994, J MOL BIOL, V240, P421, DOI 10.1006/jmbi.1994.1458; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; McKusick V., 1998, MENDELIAN INHERITANC; Mitchell T. M., 1997, MACHINE LEARNING; Ng PC, 2001, GENOME RES, V11, P863, DOI 10.1101/gr.176601; Ramensky V, 2002, NUCLEIC ACIDS RES, V30, P3894, DOI 10.1093/nar/gkf493; RENELL D, 1991, J MOL BIOL, V222, P67; Saunders CT, 2002, J MOL BIOL, V322, P891, DOI 10.1016/S0022-2836(02)00813-6; Suckow J, 1996, J MOL BIOL, V261, P509, DOI 10.1006/jmbi.1996.0479; Sunyaev S, 2001, HUM MOL GENET, V10, P591, DOI 10.1093/hmg/10.6.591; Terp BN, 2002, HUM MUTAT, V20, P98, DOI 10.1002/humu.10095; Vapnik NV, 1998, STAT LEARNING THEORY	28	13	14	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 19	2006	7								417	10.1186/1471-2105-7-417		18	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	097SE	WOS:000241468000001	16984653	
J	Granitto, PM; Furlanello, C; Biasioli, F; Gasperi, F				Granitto, Pablo M.; Furlanello, Cesare; Biasioli, Franco; Gasperi, Flavia			Recursive feature elimination with random forest for PTR-MS analysis of agroindustrial products	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						PTR-MS; feature selection; Support Vector Machines; random forest	REACTION-MASS-SPECTROMETRY; VARIABLE SELECTION; CANCER-DIAGNOSIS; CLASSIFICATION; PREDICTION; BIAS; GC	In this paper we apply the recently introduced Random Forest-Recursive Feature Elimination (RF-RFE) algorithm to the identification of relevant features in the spectra produced by Proton Transfer Reaction-Mass Spectrometry (PTR-MS) analysis of agroindustrial products. The method is compared with the more traditional Support Vector Machine-Recursive Feature Elimination (SVM-RFE), extended to allow multiclass problems, and with a baseline method based on the Kruskal-Wallis statistic (KWS). In particular, we apply all selection methods to the discrimination of nine varieties of strawberries and six varieties of typical cheeses from Trentino Province, North Italy. Using replicated experiments we estimate unbiased generalization errors. Our results show that RF-RFE outperforms SVM-RFE and KWS on the task of finding small subsets of features with high discrimination levels on PTR-MS data sets. We also show how selection probabilities and features co-occurrence can be used to highlight the most relevant features for discrimination. (c) 2006 Elsevier B.V All rights reserved.	Ist Agrario S Michele Adige, I-38010 Michele Adige, Italy; ITC, IRST, Ctr Ric Sci & Tecnol, I-38050 Trento, Italy	Granitto, PM (reprint author), Ist Agrario S Michele Adige, Via E Mach 1, I-38010 Michele Adige, Italy.	pablo.granitto@iasma.it; furlan@itc.it; franco.biasioli@iasma.it; flavia.gasperi@iasma.it	Gasperi, Flavia/B-8104-2011; Granitto, Pablo/A-3645-2013; Biasioli, Franco/A-3278-2012; Furlanello, Cesare/	Furlanello, Cesare/0000-0002-5384-3605			Alexandridis A, 2005, CHEMOMETR INTELL LAB, V75, P149, DOI 10.1016/j.chemolab.2004.06.004; Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Biasioli F, 2003, J AGR FOOD CHEM, V51, P7227, DOI 10.1021/jf030248i; Biasioli F, 2003, INT J MASS SPECTROM, V223, P343, DOI 10.1016/S1387-3806(02)00870-9; Boscaini E, 2003, J AGR FOOD CHEM, V51, P1782, DOI 10.1021/jf020922g; BOSCAINI F, 2006, FOOD QUAL PERFER, V17, P63; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; Gasperi F., 2004, Scienza e Tecnica Lattiero-Casearia, V55, P345; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GRANITTO PM, 2005, ARG S ART INT 2005 2, P191; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HANSEL A, 1995, INT J MASS SPECTROM, V149, P609, DOI 10.1016/0168-1176(95)04294-U; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Johnson KJ, 2002, CHEMOMETR INTELL LAB, V60, P225, DOI 10.1016/S0169-7439(01)00198-8; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kruskal W, 1952, J AM STAT ASSOC, V47; Li H, 2005, CHEM RES TOXICOL, V18, P1071, DOI 10.1021/tx049652h; Lindinger W, 1998, INT J MASS SPECTROM, V173, P191, DOI 10.1016/S0168-1176(97)00281-4; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Scholkopf B, 2002, LEARNING KERNELS; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; SUTTER JM, 1993, MICROCHEM J, V47, P60, DOI 10.1006/mchj.1993.1012; Vapnik VN, 1995, NATURE STAT LEARNING; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1630, DOI 10.1021/ci049869h	29	31	31	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	SEP 15	2006	83	2					83	90		10.1016/j.chemolab.2006.01.007		8	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	092KJ	WOS:000241095100001		
J	Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartko, H; Bastieri, D; Becker, J; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bordas, P; Bosch-Ramon, V; Bretz, T; Britvitch, I; Camara, M; Carmona, E; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Danielyan, V; Dazzi, F; De Angelis, A; de los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Fuchs, M; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Hsu, CC; Jacon, P; Kalekin, O; Kosyra, R; Kranich, D; Laatiaoui, M; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Lombardi, S; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Majumdar, P; Maneva, G; Mannheim, K; Mansutti, O; Mariotti, M; Martinez, M; Mazin, D; Merck, C; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ninkovic, J; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Paredes, JM; Pasanen, M; Pascoli, D; Pauss, F; Pegna, R; Persic, M; Peruzzo, L; Piccioli, A; Poller, M; Prandini, E; Raymers, A; Rhode, W; Ribo, M; Rico, J; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Scapin, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, SN; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zanin, R; Zapatero, J				Albert, J.; Aliu, E.; Anderhub, H.; Antoranz, P.; Armada, A.; Asensio, M.; Baixeras, C.; Barrio, J. A.; Bartko, H.; Bastieri, D.; Becker, J.; Bednarek, W.; Berger, K.; Bigongiari, C.; Biland, A.; Bisesi, E.; Bock, R. K.; Bordas, P.; Bosch-Ramon, V.; Bretz, T.; Britvitch, I.; Camara, M.; Carmona, E.; Chilingarian, A.; Ciprini, S.; Coarasa, J. A.; Commichau, S.; Contreras, J. L.; Cortina, J.; Curtef, V.; Danielyan, V.; Dazzi, F.; De Angelis, A.; de los Reyes, R.; De Lotto, B.; Domingo-Santamaria, E.; Dorner, D.; Doro, M.; Errando, M.; Fagiolini, M.; Ferenc, D.; Fernandez, E.; Firpo, R.; Flix, J.; Fonseca, M. V.; Font, L.; Fuchs, M.; Galante, N.; Garczarczyk, M.; Gaug, M.; Giller, M.; Goebel, F.; Hakobyan, D.; Hayashida, M.; Hengstebeck, T.; Hoehne, D.; Hose, J.; Hsu, C. C.; Jacon, P.; Kalekin, O.; Kosyra, R.; Kranich, D.; Laatiaoui, M.; Laille, A.; Lenisa, T.; Liebing, P.; Lindfors, E.; Lombardi, S.; Longo, F.; Lopez, J.; Lopez, M.; Lorenz, E.; Majumdar, P.; Maneva, G.; Mannheim, K.; Mansutti, O.; Mariotti, M.; Martinez, M.; Mazin, D.; Merck, C.; Meucci, M.; Meyer, M.; Miranda, J. M.; Mirzoyan, R.; Mizobuchi, S.; Moralejo, A.; Nilsson, K.; Ninkovic, J.; Ona-Wilhelmi, E.; Orduna, R.; Otte, N.; Oya, I.; Paneque, D.; Paoletti, R.; Paredes, J. M.; Pasanen, M.; Pascoli, D.; Pauss, F.; Pegna, R.; Persic, M.; Peruzzo, L.; Piccioli, A.; Poller, M.; Prandini, E.; Raymers, A.; Rhode, W.; Ribo, M.; Rico, J.; Riegel, B.; Rissi, M.; Robert, A.; Ruegamer, S.; Saggion, A.; Sanchez, A.; Sartori, P.; Scalzotto, V.; Scapin, V.; Schmitt, R.; Schweizer, T.; Shayduk, M.; Shinozaki, K.; Shore, S. N.; Sidro, N.; Sillanpaa, A.; Sobczynska, D.; Stamerra, A.; Stark, L. S.; Takalo, L.; Temnikov, P.; Tescaro, D.; Teshima, M.; Tonello, N.; Torres, A.; Torres, D. F.; Turini, N.; Vankov, H.; Vitale, V.; Wagner, R. M.; Wibig, T.; Wittek, W.; Zanin, R.; Zapatero, J.			Discovery of very high energy gamma-rays from Markarian 180 triggered by an optical outburst	ASTROPHYSICAL JOURNAL			English	Article						BL Lacertae objects : individual (Markarian 180); gamma rays : observations	BL LACERTAE OBJECTS; EXTRAGALACTIC BACKGROUND LIGHT; X-RAY; MAGIC TELESCOPE; EMISSION; BLAZARS; SPECTRA; CONSTRAINTS; CATALOG; 1ES-1959+650	The high-frequency-peaked BL Lacertae object Markarian 180 (Mrk 180) was observed to have an optical outburst in 2006 March, triggering a Target of Opportunity observation with the MAGIC telescope. The source was observed for 12.4 hr, and very high energy gamma-ray emission was detected with a significance of 5.5 sigma. An integral flux above 200 GeV of (2.3 +/- 0.7) x 10(-11) cm(-2) s(-1) was measured, corresponding to 11% of the Crab Nebula flux. A rather soft spectrum with a photon index of has been determined. No significant flux -3.3 x 0.7 variation was found.	Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany; Inst Fis Altes Energies, E-08193 Bellaterra, Spain; Swiss Fed Inst Technol, CH-8093 Zurich, Switzerland; Univ Complutense, E-28040 Madrid, Spain; Univ Autonoma Barcelona, E-08193 Barcelona, Spain; Univ Wurzburg, D-97074 Wurzburg, Germany; Univ Lodz, PL-90236 Lodz, Poland; Univ Udine, I-33100 Udine, Italy; Univ Barcelona, E-08028 Barcelona, Spain; Yerevan Phys Inst, Yerevan 375036, Armenia; Tuorla Observ, FI-21500 Piikkio, Finland; Univ Siena, I-53100 Siena, Italy; Univ Calif Davis, Davis, CA 95616 USA; Humboldt Univ, D-12489 Berlin, Germany; Univ Trieste, I-34100 Trieste, Italy; Inst Nucl Energy Res, BG-1784 Sofia, Bulgaria; INAF, I-34131 Trieste, Italy; Univ Pisa, I-56126 Pisa, Italy; CSIC, IEEC, Inst Ciencies Espai, E-08193 Barcelona, Spain; Univ Padua, I-35131 Padua, Italy; Ist Nazl Fis Nucl, I-35131 Padua, Italy; INFN Trieste, I-33100 Udine, Italy; INFN Pisa, I-53100 Siena, Italy; INFN Trieste, I-34100 Trieste, Italy; INFN Triesta, I-34131 Trieste, Italy; INFN Pisa, I-56126 Pisa, Italy; Univ Dortmund, D-44227 Dortmund, Germany	Mazin, D (reprint author), Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany.	elilin@utu.fi; mazin@mppmu.mpg.de	Fernandez, Enrique/L-5387-2014; De Angelis, Alessandro/B-5372-2009; Mannheim, Karl/F-6705-2012; Flix, Josep/G-5414-2012; Tjus, Julia/G-8145-2012; Doro, Michele/F-9458-2012; chilingarian, ashot/B-1901-2014; Contreras Gonzalez, Jose Luis/K-7255-2014; Rico, Javier/K-8004-2014; Fernandez, Ester/K-9734-2014; lopez, marcos/L-2304-2014; GAug, Markus/L-2340-2014; Font, Lluis/L-4197-2014; Tonello, Nadia/L-8065-2014; Moralejo Olaizola, Abelardo/M-2916-2014; Ribo, Marc/B-3579-2015; Torres, Diego/F-3009-2015; Antoranz, Pedro/H-5095-2015; Miranda, Jose Miguel/F-2913-2013; Barrio, Juan/L-3227-2014	Fernandez, Enrique/0000-0002-6405-9488; Doro, Michele/0000-0001-9104-3214; chilingarian, ashot/0000-0002-2018-9715; Contreras Gonzalez, Jose Luis/0000-0001-7282-2394; Rico, Javier/0000-0003-4137-1134; lopez, marcos/0000-0002-8791-7908; GAug, Markus/0000-0001-8442-7877; Font, Lluis/0000-0003-2109-5961; Tonello, Nadia/0000-0003-0550-1667; Moralejo Olaizola, Abelardo/0000-0002-1344-9080; Torres, Diego/0000-0002-1522-9065; Antoranz, Pedro/0000-0002-3015-3601; Miranda, Jose Miguel/0000-0002-1472-9690; Barrio, Juan/0000-0002-0965-0259			Aharonian F, 2004, ASTRON ASTROPHYS, V421, P529, DOI 10.1051/0004-6361:20035764; Aharonian F, 2006, NATURE, V440, P1018, DOI 10.1038/nature04680; ALBERT J, 2006, UNPUB APJL; Albert J, 2006, ASTROPHYS J, V642, pL119, DOI 10.1086/504845; Albert J, 2006, ASTROPHYS J, V639, P761, DOI 10.1086/499421; ALBERT J, 2006, UNPUB APJ; ANYKEYEV VB, 1991, NUCL INSTRUM METH A, V303, P350, DOI 10.1016/0168-9002(91)90802-W; Bock RK, 2004, NUCL INSTRUM METH A, V516, P511, DOI 10.1016/j.nima.2003.08.157; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bretz T, 2005, AIP CONF PROC, V745, P730; CORTINA J, 2005, P 29 INT COSM RAY C, V5, P359; Costamante L, 2002, ASTRON ASTROPHYS, V384, P56, DOI 10.1051/0004-6361:20011749; Daum A, 1997, ASTROPART PHYS, V8, P1, DOI 10.1016/S0927-6505(97)00031-5; DERMER CD, 1993, ASTROPHYS J, V416, P458, DOI 10.1086/173251; Domingo-Santamaria E., 2005, P 29 INT COSM RAY C, V5, P363; Donato D, 2005, ASTRON ASTROPHYS, V433, P1163, DOI 10.1051/0004-6361:20034555; Donato D, 2001, ASTRON ASTROPHYS, V375, P739, DOI 10.1051/0004-6361:20010675; Dwek E, 2005, ASTROPHYS J, V618, P657, DOI 10.1086/426010; Falco EE, 1999, PUBL ASTRON SOC PAC, V111, P438, DOI 10.1086/316343; Fichtel CE, 1994, APJS, V93, P125; Fomin VP, 1994, ASTROPART PHYS, V2, P137, DOI 10.1016/0927-6505(94)90036-1; Fossati G, 2004, NEW ASTRON REV, V48, P419, DOI 10.1016/j.newar.2003.12.020; Fossati G, 2000, ASTROPHYS J, V541, P166, DOI 10.1086/309430; Gaug M., 2005, P 29 INT COSM RAY C, V5, P375; GIOMMI P, 2002, BLAZAR ASTROPHYSICS, P63; GOULD RJ, 1966, PHYS REV LETT, V16, P252, DOI 10.1103/PhysRevLett.16.252; Hartman RC, 1999, ASTROPHYS J SUPPL S, V123, P79, DOI 10.1086/313231; Hartman RC, 2001, ASTROPHYS J, V558, P583, DOI 10.1086/322462; Hauser MG, 2001, ANNU REV ASTRON ASTR, V39, P249, DOI 10.1146/annurev.astro.39.1.249; Hillas A M, 1985, 19TH P INT COSM RAY, V3, P445; Holder J, 2003, ASTROPHYS J, V583, pL9, DOI 10.1086/367816; Horan D, 2004, ASTROPHYS J, V603, P51, DOI 10.1086/381430; KNAPP J, 2004, EAS SIMULATION CORSI; Kneiske TM, 2004, ASTRON ASTROPHYS, V413, P807, DOI 10.1051/0004-6361:20031542; KRAWCZYNSKI H, 2003, AAS HEAD M, V7, DOI UNSP 49.01; Lessard RW, 2001, ASTROPART PHYS, V15, P1, DOI 10.1016/S0927-6505(00)00133-X; LI TP, 1983, ASTROPHYS J, V272, P317, DOI 10.1086/161295; Lorenz E, 2004, NEW ASTRON REV, V48, P339, DOI 10.1016/j.newar.2003.12.059; Majumdar P, 2005, P 29 INT COSM RAY C, V5, P203; MANNHEIM K, 1991, ASTRON ASTROPHYS, V251, P723; Maraschi L., 1992, APJ, V397, P5, DOI DOI 10.1086/186531; Massaro E, 2004, ASTRON ASTROPHYS, V422, P103, DOI 10.1051/0004-6361:20047148; MAZIN M, 2006, IN PRESS AP SS; MUFSON SL, 1981, ASTROPHYS J, V248, pL61, DOI 10.1086/183624; NIKISHOV AI, 1962, SOV PHYS JETP-USSR, V14, P393; Nilsson K, 2003, ASTRON ASTROPHYS, V400, P95, DOI 10.1051/0004-6361:20021861; Perlman ES, 2005, ASTROPHYS J, V625, P727, DOI 10.1086/429688; REBILLOT P, 2003, P 28 INT COSM RAY C, V5, P2599; STECKER F. W., 1992, APJ, V390, P49; Wagner R, 2005, P 29 INT COSM RAY C, V4, P163	50	61	61	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X			ASTROPHYS J	Astrophys. J.	SEP 10	2006	648	2	2				L105	L108		10.1086/508020		4	Astronomy & Astrophysics	Astronomy & Astrophysics	082RB	WOS:000240403800006		
J	Moore, LE; Fung, ET; McGuire, M; Rabkin, CC; Molinaro, A; Wang, Z; Zhang, FJ; Wang, J; Yip, C; Meng, XY; Pfeiffer, RM				Moore, Lee E.; Fung, Eric T.; McGuire, Marielena; Rabkin, Charles C.; Molinaro, Annette; Wang, Zheng; Zhang, Fujun; Wang, Jing; Yip, Christine; Meng, Xiao-Ying; Pfeiffer, Ruth M.			Evaluation of apolipoprotein A1 and posttranslationally modified forms of transthyretin as biomarkers for ovarian cancer detection in an independent study population	CANCER EPIDEMIOLOGY BIOMARKERS & PREVENTION			English	Article							PROTEOMIC PATTERNS; SERUM PROTEOMICS; CLASSIFICATION; PLASMA; HEALTH	Background: Although overall 5-year survival rates for ovarian cancer are poor (10-30%), stage I/Ila patients have a 95% 5-year survival. New biomarkers that improve the diagnostic performance of existing tumor markers are critically needed. A previous study by Zhang et al. reported identification and validation of three biomarkers using proteomic profiling that together improved early-stage ovarian cancer detection. Methods: To evaluate these markers in an independent study population, postdiagnostic/pretreatment serum samples were collected from women hospitalized at the Mayo Clinic from 1980 to 1989 as part of the National Cancer Institute Immunodiagnostic Serum Bank. Sera from 42 women with ovarian cancer, 65 with benign tumors, and 76 with digestive diseases were included in this study. Levels of various posttranslationally forms of transthyretin and apolipoprotein A1 were measured in addition to CA125. Results: Mean levels of five of the six forms of transthyretin were significantly lower in cases than in controls. The specificity of a model including transthyretin and apolipoprotein A1 alone was high [96.5%; 95% confidence interval (95% CI), 91.9-98.8%] but sensitivity was low (52.4%; 95% CI, 36.4-68.0%). A class prediction algorithm using all seven markers, CA125, and age maintained high specificity (94.3%; 95% CI, 89.1-97.5%) but had higher sensitivity (78.6%; 95% CI, 63.2-89.7%). Conclusions: We were able to replicate the findings reported by Zhang et al. in an independently conducted blinded study. These results provide some evidence that including age of patient and these markers in a model may improve specificity, especially when CA125 levels are >= 35 units/mL. Influences of sample handling, subject characteristics, and other covariates on biomarker levels require further consideration in discovery and replication or validation studies.	NCI, Div Canc Epidemiol & Genet, Occupat & Environm Epidemiol Branch, Dept Hlth & Human Serv,NIH, Rockville, MD 20852 USA; Ciphergen Biosyst Inc, Fremont, CA USA	Moore, LE (reprint author), NCI, Div Canc Epidemiol & Genet, Occupat & Environm Epidemiol Branch, Dept Hlth & Human Serv,NIH, 6120 Execut Blvd,EPS 8118, Rockville, MD 20852 USA.	moorele@mail.nih.gov	Pfeiffer, Ruth /F-4748-2011				Bachorik PS, 1997, CLIN CHEM, V43, P2364; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; Bernstein LH, 2002, CLIN CHEM LAB MED, V40, P1344, DOI 10.1515/CCLM.2002.232; BREIMAN L, 1992, INT STAT REV, V60, P291, DOI 10.2307/1403680; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cannistra SA, 2004, NEW ENGL J MED, V351, P2519, DOI 10.1056/NEJMra041842; Coombes KR, 2005, NAT BIOTECHNOL, V23, P291, DOI 10.1038/nbt0305-291; Diamandis EP, 2004, EXPERT REV MOL DIAGN, V4, P575, DOI 10.1586/14737159.4.5.575; DIMAGNO EP, 1989, MAYO CLIN PROC, V64, P1226; DUDOIT S, 2003, 126 UC BERK DIV BIOS; Fung ET, 2005, INT J CANCER, V115, P783, DOI 10.1002/ijc.20928; Hu Jianhua, 2005, Briefings in Functional Genomics & Proteomics, V3, P322, DOI 10.1093/bfgp/3.4.322; Jungner I, 1998, CLIN CHEM, V44, P1641; Kohavi R., 1995, INT JOINT C ART INT; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; KUESEL AC, 1992, INT J CANCER, V52, P341, DOI 10.1002/ijc.2910520302; MAHLCK CG, 1994, GYNECOL OBSTET INVES, V37, P135; Mor G, 2005, P NATL ACAD SCI USA, V102, P7677, DOI 10.1073/pnas.0502178102; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Ransohoff DF, 2005, J NATL CANCER I, V97, P315, DOI 10.1093/jnci/dji054; *SAS I, 1999, SAS US GUID VERS 9; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; YE B, HAPTOGLOBIN ALPHA SU; Zhang Z, 2004, CANCER RES, V64, P5882, DOI 10.1158/0008-5472.CAN-04-0746	24	49	51	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1055-9965			CANCER EPIDEM BIOMAR	Cancer Epidemiol. Biomarkers Prev.	SEP	2006	15	9					1641	1646		10.1158/1055-9965.EPI-05-0980		6	Oncology; Public, Environmental & Occupational Health	Oncology; Public, Environmental & Occupational Health	085FB	WOS:000240587800015	16985025	
J	Lin, WQ; Jiang, JH; Wu, HL; Shen, GL; Yu, RQ				Lin, Wei-Qi; Jiang, Jian-Hui; Wu, Hai-Long; Shen, Guo-Li; Yu, Ru-Qin			Recent Advances in Chemometric Methodologies for QSAR Studies	CURRENT COMPUTER-AIDED DRUG DESIGN			English	Article						Computer-aided drug design; QSAR; chemometrics; variable selection; artificial neural networks; genetic algorithm; particle swarm optimization; support vector machine	SUPPORT VECTOR MACHINES; ARTIFICIAL NEURAL-NETWORKS; K-NEAREST-NEIGHBOR; PARTICLE SWARM OPTIMIZATION; STRUCTURE-PROPERTY RELATIONSHIPS; CHROMATOGRAPHIC RETENTION TIMES; CHANNEL ANTAGONIST ACTIVITY; MULTIPLE LINEAR-REGRESSION; ANGIOTENSIN-II ANTAGONISTS; MOLECULAR-FIELD ANALYSIS	In recent years chemometrics has been undergoing an exciting development both in the applied areas and in the theoretical and methodological aspects. This review is focused on recent advances in chemometric methodologies for quantitative structure-activity relationship (QSAR) studies, and it covers multiple applications. QSAR is one of the tools for the computer-aided drug design; it is also an important branch of chemometrics. The feature or variable selection is an important aspect in QSAR studies. Basic requirements and different algorithms for feature or variable selection are briefly discussed. Moreover, an overview of the state-of-the-art chemometric methods developed to combat the shortcomings of conventional algorithms and their applications in QSAR is given. A survey of innovative chemometric approaches in QSAR model construction is also presented. Some remarks and outlook about QSAR studies applied to the computer-aided drug design have also been discussed.	[Lin, Wei-Qi; Jiang, Jian-Hui; Wu, Hai-Long; Shen, Guo-Li; Yu, Ru-Qin] Hunan Univ, Coll Chem & Chem Engn, State Key Lab Chemo Biosensing & Chemometr, Changsha 410082, Hunan, Peoples R China	Yu, RQ (reprint author), Hunan Univ, Coll Chem & Chem Engn, State Key Lab Chemo Biosensing & Chemometr, Changsha 410082, Hunan, Peoples R China.	rqyu@hnu.cn	Jiang, Jian-Hui/K-2054-2012		National Natural Science Foundation of China [20375012, 20105007, 20205005, 20435010]	The work was financially supported by the National Natural Science Foundation of China (Grant No. 20375012, 20105007, 20205005, 20435010).	AARTS E, 1989, SIMULATED ANNEALING, P13; *ACC, 2003, CER 2; Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; Agrafiotis DK, 2002, J MED CHEM, V45, P1098, DOI 10.1021/jm0104668; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500; ALLEN DM, 1971, TECHNOMETRICS, V13, P469, DOI 10.2307/1267161; Baumann K, 2002, J CHEMOMETR, V16, P339, DOI 10.1002/cem.730; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOHACHEVSKY IO, 1986, TECHNOMETRICS, V28, P209, DOI DOI 10.2307/1269076]; Bonabeau E, 2000, NATURE, V406, P39, DOI 10.1038/35017500; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burden FR, 1997, CHEMOMETR INTELL LAB, V38, P127, DOI 10.1016/S0169-7439(97)00052-X; Burden FR, 1999, J MED CHEM, V42, P3183, DOI 10.1021/jm980697n; Burges C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; BURNS JA, 1993, CHEM REV, V93, P2583, DOI 10.1021/cr00024a001; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; CAMILLERI P, 1993, J COMPUT AID MOL DES, V7, P61, DOI 10.1007/BF00141575; CERNY V, 1985, J OPTIMIZ THEORY APP, V45, P41, DOI 10.1007/BF00940812; Chiu Ting-Lan, 2004, J Chem Inf Comput Sci, V44, P154, DOI 10.1021/ci030294i; Cho SJ, 2002, J CHEM INF COMP SCI, V42, P927, DOI 10.1021/ci010247v; COHEN NC, 1990, J MED CHEM, V33, P883, DOI 10.1021/jm00165a001; Colomi A, 1991, P 1 EUR C ART LIF, P134; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; Deogun JS, 1998, J AM SOC INFORM SCI, V49, P423, DOI 10.1002/(SICI)1097-4571(19980415)49:5<423::AID-ASI5>3.3.CO;2-S; Dixon S, 2005, J COMPUT CHEM, V26, P23, DOI 10.1002/jcc.20142; Draper N. R., 1998, APPL REGRESSION ANAL; Du YP, 2002, J CHEM INF COMP SCI, V42, P993, DOI 10.1021/ci020283+; Efron B., 1982, JACKKNIFE BOOTSTRAP; EMBRECHTS MJ, 2002, NEUR NETW 2002 IJCNN, V1, P305; EMBRECHTS MJ, 2001, NEUR NETW 2001 IJCNN, V4, P2478; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Frohlich H, 2004, QSAR COMB SCI, V23, P311, DOI 10.1002/qsar.200410011; Gao H, 2001, J CHEM INF COMP SCI, V41, P402, DOI 10.1021/ci000306p; Gini G, 2004, J CHEM INF COMP SCI, V44, P1897, DOI 10.1021/ci0401219; Godden JW, 2001, J CHEM INF COMP SCI, V41, P1060, DOI 10.1021/ci0102867; Goldberg D, 1989, GENETIC ALGORITHMS S; Gramatica P, 2004, J CHEM INF COMP SCI, V44, P1794, DOI 10.1021/ci049923u; Grover Manish, 2000, Pharmaceutical Science and Technology Today, V3, P28, DOI 10.1016/S1461-5347(99)00214-X; Guha R, 2004, J CHEM INF COMP SCI, V44, P1440, DOI 10.1021/ci0499469; Guha R, 2005, J CHEM INF MODEL, V45, P800, DOI 10.1021/ci050022a; Guha R, 2004, J CHEM INF COMP SCI, V44, P2179, DOI 10.1021/ci049849f; Gunn SR, 1997, LECT NOTES COMPUT SC, V1280, P313; Gupta MK, 2006, J CHEM INF MODEL, V46, P93, DOI 10.1021/ci0501140; Han YQ, 2004, J CHEM INF COMP SCI, V44, P489, DOI 10.1021/ci034132y; HANSEN LK, 1994, NEURAL COMPUT, V6, P1223, DOI 10.1162/neco.1994.6.6.1223; Hasegawa K, 1999, J CHEM INF COMP SCI, V39, P112, DOI 10.1021/ci980088o; Hasegawa K, 1997, J CHEM INF COMP SCI, V37, P306, DOI 10.1021/ci960047x; Hasegawa K., 1998, THEOCHEM, V425, DOI 10.1016/S0166-1280(97)00205-4; HASSIBI B, 1993, NIPS 5, P164; Hawkins DM, 1997, QUANT STRUCT-ACT REL, V16, P296, DOI 10.1002/qsar.19970160404; Hemmateenejad B, 2002, CHEMOMETR INTELL LAB, V64, P91, DOI 10.1016/S0169-7439(02)00068-0; Hemmateenejad B, 2005, J CHEM INF MODEL, V45, P190, DOI 10.1021/ci049766z; Hemmateenejad B, 2004, J COMPUT CHEM, V25, P1495, DOI 10.1002/jcc.20066; Hemmateenejad B, 2003, J CHEM INF COMP SCI, V43, P1328, DOI 10.1021/ci025661p; Hoffman B, 1999, J MED CHEM, V42, P3217, DOI 10.1021/jm980415j; Hoffman BT, 2000, J MED CHEM, V43, P4151, DOI 10.1021/jm990472s; Holland J. H., 1992, GENETIC ALGORITHMS, P66; Itskowitz P, 2005, J CHEM INF MODEL, V45, P777, DOI 10.1021/ci049628+; Izrailev S, 2002, SAR QSAR ENVIRON RES, V13, P417, DOI 10.1080/10629360290014296; Izrailev S, 2001, J CHEM INF COMP SCI, V41, P176, DOI 10.1021/ci000036s; Jiang JH, 1996, J CHEMOMETR, V10, P253, DOI 10.1002/(SICI)1099-128X(199605)10:3<253::AID-CEM420>3.3.CO;2-Q; Kalivas JH, 1995, ADAPTATION SIMULATED; KALIVAS JH, 1989, ANAL CHEM, V61, P2024, DOI 10.1021/ac00193a006; Karelson M, 1996, CHEM REV, V96, P1027, DOI 10.1021/cr950202r; KATRITZKY AR, 1995, CHEM SOC REV, V24, P279, DOI 10.1039/cs9952400279; KATRITZKY AR, 1994, ANAL CHEM, V66, P1799, DOI 10.1021/ac00083a005; KENNEDY J, 1995, P IEEE INT C NEUR NE, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kier L., 1986, MOL CONNECTIVITY STR; Kimura T, 1998, J CHEM INF COMP SCI, V38, P276, DOI 10.1021/ci970237n; Kirkpatrick S., 1982, 9355 IBM RC; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kovalishyn VV, 1998, J CHEM INF COMP SCI, V38, P651, DOI 10.1021/ci980325n; Kovesdi I, 1999, MED RES REV, V19, P249, DOI 10.1002/(SICI)1098-1128(199905)19:3<249::AID-MED4>3.0.CO;2-0; Krieger MJB, 2000, NATURE, V406, P992; KUBINYI H, 1994, QUANT STRUCT-ACT REL, V13, P285, DOI 10.1002/qsar.19940130306; Kubinyi H, 1997, DRUG DISCOV TODAY, V2, P538, DOI 10.1016/S1359-6446(97)01084-2; Kubinyi H, 1996, J CHEMOMETR, V10, P119; KUBINYI H, 1994, QUANT STRUCT-ACT REL, V13, P393, DOI 10.1002/qsar.19940130403; LEARDI R, 1992, J CHEMOMETR, V6, P267, DOI 10.1002/cem.1180060506; LeCun Y., 1990, NEURAL INFORMATION P, P598; Li SQ, 2005, J CHEM INF MODEL, V45, P952, DOI 10.1021/ci050049u; Lin TH, 2004, J CHEM INF COMP SCI, V44, P76, DOI 10.1021/ci030295a; Lin WQ, 2005, J CHEM INF MODEL, V45, P486, DOI 10.1021/ci049890i; Lin WQ, 2005, J CHEM INF MODEL, V45, P535, DOI 10.1021/ci049642m; Liu HX, 2004, J CHEM INF COMP SCI, V44, P161, DOI 10.1021/ci034173u; Liu HX, 2003, J CHEM INF COMP SCI, V43, P1288, DOI 10.1021/ci03040355; Liu SS, 2003, J CHEM INF COMP SCI, V43, P964, DOI 10.1021/ci020377j; Liu SS, 2002, J CHEM INF COMP SCI, V42, P749, DOI 10.1021/ci010245a; Lu QZ, 2003, J CHEM INF COMP SCI, V43, P1132, DOI 10.1021/ci020068t; Lu QZ, 2002, J COMPUT CHEM, V23, P1357, DOI 10.1002/jcc.10149; LUCASIUS CB, 1994, CHEMOMETR INTELL LAB, V25, P99, DOI 10.1016/0169-7439(94)85038-0; LUCASIUS CB, 1993, CHEMOMETR INTELL LAB, V19, P1, DOI 10.1016/0169-7439(93)80079-W; Lucic B, 1999, J CHEM INF COMP SCI, V39, P610, DOI 10.1021/ci980161a; Lucic B, 1999, J CHEM INF COMP SCI, V39, P121, DOI 10.1021/ci980090f; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; MALLOWS CL, 1964, CENTR REG M IMA MAHH; Matsui K., 1999, Systems and Computers in Japan, V30, DOI 10.1002/(SICI)1520-684X(19990630)30:7<69::AID-SCJ8>3.0.CO;2-U; MAZZATORTA P, J CHEM INF MODEL; McNeany TJ, 2005, J CHEM INF MODEL, V45, P768, DOI 10.1021/cit049631t; Micheli A, 2001, J CHEM INF COMP SCI, V41, P202, DOI 10.1021/ci0000399; Mosier PD, 2002, J CHEM INF COMP SCI, V42, P1460, DOI 10.1021/ci020039i; Nas T., 1989, MULTIVARIATE CALIBRA; Netzeva TI, 2004, J CHEM INF COMP SCI, V44, P258, DOI 10.1021/ci034195g; Nicolotti O, 2002, J MED CHEM, V45, P5069, DOI 10.1021/jm020919o; Niculescu SP, 2003, J MOL STRUC-THEOCHEM, V622, P71, DOI 10.1016/S0166-1280(02)00619-X; Norinder U, 2003, NEUROCOMPUTING, V55, P337, DOI 10.1016/S0925-2312(03)00374-6; OZDEMIR M, 2001, IEEE MOUNT WORKSH SO, P53; Papa E, 2005, J CHEM INF MODEL, V45, P1256, DOI 10.1021/ci050212l; Patankar SJ, 2002, J CHEM INF COMP SCI, V42, P1053, DOI 10.1021/ci010114+; Prabhakar YS, 2003, QSAR COMB SCI, V22, P583, DOI 10.1002/qsar.200330814; Rajko R, 2001, CHEMOMETR INTELL LAB, V57, P1, DOI 10.1016/S0169-7439(01)00101-0; RANDIC M, 1995, NEW J CHEM, V19, P781; RASSOKHIN DN, 2000, J MOL GRAPH MODEL, V18, P370; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P854, DOI 10.1021/ci00020a020; Roy K, 2004, BIOORGAN MED CHEM, V12, P745, DOI 10.1016/j.bmc.2003.11.009; Schefzick S, 2004, J COMPUT AID MOL DES, V18, P511, DOI 10.1007/s10822-004-5322-1; SCHNEIDER G, DRUG DESIGN, P203; Schneider G, 1998, PROG BIOPHYS MOL BIO, V70, P175, DOI 10.1016/S0079-6107(98)00026-1; Senese CL, 2003, J CHEM INF COMP SCI, V43, P2180, DOI 10.1021/ci034168q; Serra JR, 2001, CHEM RES TOXICOL, V14, P1535, DOI 10.1021/tx010101q; Shannon C. E., 1963, MATH THEORY COMMUNIC; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; Shen M, 2002, J MED CHEM, V45, P2811, DOI 10.1021/jm010488u; Shen M, 2003, J MED CHEM, V46, P3013, DOI 10.1021/jm020491t; Shen Q, 2005, J CHEM INF MODEL, V45, P1024, DOI 10.1021/ci049610z; Shen Q, 2004, J COMPUT CHEM, V25, P1726, DOI 10.1002/jcc.20094; Shen Q, 2004, J CHEM INF COMP SCI, V44, P2027, DOI 10.1021/ci034292+; Shen Q, 2004, EUR J PHARM SCI, V22, P145, DOI 10.1016/j.ejps.2004.03.002; Shen Q, 2003, ANAL BIOANAL CHEM, V375, P248, DOI 10.1007/s00216-002-1668-1; SHERIDAN RP, 1987, ACCOUNTS CHEM RES, V20, P322, DOI 10.1021/ar00141a002; Smith PA, 2003, J MED CHEM, V46, P1617, DOI 10.1021/jm020397c; Smola A. J., 1998, TECHNICAL REPORT SER, VNC2-TR-1998-030; Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Swierenga H, 1998, CHEMOMETR INTELL LAB, V41, P237, DOI 10.1016/S0169-7439(98)00055-0; Swierenga H, 1999, J CHEMOMETR, V13, P237, DOI 10.1002/(SICI)1099-128X(199905/08)13:3/4<237::AID-CEM541>3.0.CO;2-F; Tetko IV, 1996, J CHEM INF COMP SCI, V36, P794, DOI 10.1021/ci950204c; TOPLISS JG, 1972, J MED CHEM, V15, P1066, DOI 10.1021/jm00280a017; Trinajstic N., 1992, CHEM GRAPH THEORY; Turner JV, 2003, J COMPUT CHEM, V24, P891, DOI 10.1002/jcc.10148; VANDERBILT D, 1984, J COMPUT PHYS, V56, P259, DOI 10.1016/0021-9991(84)90095-0; Vapnik VN, 1995, NATURE STAT LEARNING; Vapnik V.N., 1982, ESTIMATION DEPENDENC; Venkatraman V, 2004, J CHEM INF COMP SCI, V44, P1686, DOI 10.1021/ci049933v; Waller CL, 1999, J CHEM INF COMP SCI, V39, P345, DOI 10.1021/ci980405r; WANG Z, 2004, IEEE PAR DISTR PROC, P194; Wehrens R, 2000, CHEMOMETR INTELL LAB, V54, P35, DOI 10.1016/S0169-7439(00)00102-7; Whitley DC, 2000, J CHEM INF COMP SCI, V40, P1160, DOI 10.1021/ci000384c; WIKEL JH, 1993, BIOORG MED CHEM LETT, V3, P645, DOI 10.1016/S0960-894X(01)81246-4; Winkler David A., 2004, Biosilico, V2, P104; Xiao ZY, 2002, J MED CHEM, V45, P2294, DOI 10.1021/jm0105427; Xie HP, 2002, COMPUT CHEM, V26, P591, DOI 10.1016/S0097-8485(02)00022-0; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1267, DOI 10.1021/ci049934n; Xue CX, 2004, J CHEM INF COMP SCI, V44, P950, DOI 10.1021/ci034280o; Xue CX, 2004, J CHEM INF COMP SCI, V44, P669, DOI 10.1021/ci034248u; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1693, DOI 10.1021/ci049820b; Yao XJ, 2004, J CHEM INF COMP SCI, V44, P1257, DOI 10.1021/ci049965i; Yasri A, 2001, J CHEM INF COMP SCI, V41, P1218, DOI 10.1021/ci010291a; Zernov VV, 2003, J CHEM INF COMP SCI, V43, P2048, DOI 10.1021/ci0340916; Zhang L, 1997, ANAL CHIM ACTA, V344, P29, DOI 10.1016/S0003-2670(96)00628-9; Zheng WF, 2000, J CHEM INF COMP SCI, V40, P185, DOI 10.1021/ci980033m; Zupan J., 1993, NEURAL NETWORKS CHEM	171	4	4	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4099	1875-6697		CURR COMPUT-AID DRUG	Curr. Comput.-Aided Drug Des.	SEP	2006	2	3					255	266				12	Chemistry, Medicinal; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Computer Science	V17TI	WOS:000207959100004		
J	Seringhaus, M; Paccanaro, A; Borneman, A; Snyder, M; Gerstein, M				Seringhaus, Michael; Paccanaro, Alberto; Borneman, Anthony; Snyder, Michael; Gerstein, Mark			Predicting essential genes in fungal genomes	GENOME RESEARCH			English	Article							SACCHAROMYCES-CEREVISIAE GENOME; MICROBIAL COMMUNITIES; EFFECTIVE NUMBER; PROTEIN; YEAST; IDENTIFICATION; BIOINFORMATICS; DELETION; SEARCH	Essential genes are required for an organism's viability, and the ability to identify these genes in pathogens is crucial to directed drug development. Predicting essential genes through computational methods is appealing because it circumvents expensive and difficult experimental screens. Most such prediction is based on homology mapping to experimentally verified essential genes in model organisms. We present here a different approach, one that relies exclusively on sequence features of a gene to estimate essentiality and offers a promising way to identify essential genes in unstudied or uncultured organisms. We identified 14 characteristic sequence features potentially associated with essentiality, such as localization signals, codon adaptation, GC content, and overall hydrophobicity. Using the well- characterized baker's yeast Saccharomyces cerevisiae, we employed a simple Bayesian framework to measure the correlation of each of these features with essentiality. We then employed the 14 features to learn the parameters of a machine learning classifier capable of predicting essential genes. We trained our classifier on known essential genes in S. cerevisiae and applied it to the closely related and relatively unstudied yeast Saccharomyces mikatae. We assessed predictive success in two ways: First, we compared all of our predictions with those generated by homology mapping between these two species. Second, we verified a subset of our predictions with eight in vivo knockouts in S. mikatae, and we present here the first experimentally confirmed essential genes in this species.	Yale Univ, Dept Mol Biophys & Biochem, New Haven, CT 06520 USA; Univ London Royal Holloway & Bedford New Coll, Dept Comp Sci, Egham TW20 0EX, Surrey, England; Yale Univ, Dept Mol Cellular & Dev Biol, New Haven, CT 06520 USA; Yale Univ, Program Computat Biol & Bioinformat, New Haven, CT 06520 USA; Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA	Gerstein, M (reprint author), Yale Univ, Dept Mol Biophys & Biochem, New Haven, CT 06520 USA.	mark.gerstein@yale.edu					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Arigoni F, 1998, NAT BIOTECHNOL, V16, P851, DOI 10.1038/nbt0998-851; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bruccoleri RE, 1998, NUCLEIC ACIDS RES, V26, P4482, DOI 10.1093/nar/26.19.4482; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; Chalker AF, 2002, PHARMACOL THERAPEUT, V95, P1, DOI 10.1016/S0163-7258(02)00222-X; Chen K, 2005, PLOS COMPUT BIOL, V1, P106, DOI 10.1371/journal.pcbi.0010024; Cole S T, 2002, Eur Respir J Suppl, V36, p78s; De Backer MD, 2001, NAT BIOTECHNOL, V19, P235, DOI 10.1038/85677; Decottignies A, 2003, GENOME RES, V13, P399, DOI 10.1101/gr.636103; Dezso Z, 2003, GENOME RES, V13, P2450, DOI 10.1101/gr.1073603; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Drawid A, 2000, J MOL BIOL, V301, P1059, DOI 10.1006/jmbi.2000.3968; Edgington ES, 1995, RANDOMIZATION TESTS; Frank E., 2005, DATA MINING PRACTICA; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Fuglsang A, 2004, BIOCHEM BIOPH RES CO, V317, P957, DOI 10.1016/j.bbrc.2004.03.138; Giaever G, 2002, NATURE, V418, P387, DOI 10.1038/nature00935; Gietz RD, 2002, METHOD ENZYMOL, V350, P87; Hurst LD, 1999, CURR BIOL, V9, P747, DOI 10.1016/S0960-9822(99)80334-0; Jeong Hawoong, 2003, ComPlexUs, V1, P19, DOI 10.1159/000067640; Jordan IK, 2002, GENOME RES, V12, P962, DOI 10.1101/gr.87702; Kellis M, 2003, NATURE, V423, P241, DOI 10.1038/nature01644; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; Lamichhane G, 2003, P NATL ACAD SCI USA, V100, P7213, DOI 10.1073/pnas.1231432100; Longtine MS, 1998, YEAST, V14, P953, DOI 10.1002/(SICI)1097-0061(199807)14:10<953::AID-YEA293>3.3.CO;2-L; LORENZ MC, 1995, GENE, V158, P113, DOI 10.1016/0378-1119(95)00144-U; Lu Z, 2004, BIOINFORMATICS, V20, P547, DOI 10.1093/bioinformatics/btg447; Mushegian AR, 1996, P NATL ACAD SCI USA, V93, P10268, DOI 10.1073/pnas.93.19.10268; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Reich KA, 2000, RES MICROBIOL, V151, P319, DOI 10.1016/S0923-2508(00)00153-4; Riesenfeld CS, 2004, ANNU REV GENET, V38, P525, DOI 10.1146/annurev.genet.38.072902.091216; SHARP PM, 1987, NUCLEIC ACIDS RES, V15, P1281, DOI 10.1093/nar/15.3.1281; Sonnhammer E L, 1998, Proc Int Conf Intell Syst Mol Biol, V6, P175; WILSON AC, 1977, ANNU REV BIOCHEM, V46, P573, DOI 10.1146/annurev.bi.46.070177.003041; Winzeler EA, 1999, SCIENCE, V285, P901, DOI 10.1126/science.285.5429.901; WRIGHT F, 1990, GENE, V87, P23, DOI 10.1016/0378-1119(90)90491-9; Yu HY, 2004, TRENDS GENET, V20, P227, DOI 10.1016/j.tig.2004.04.008	39	44	46	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1088-9051			GENOME RES	Genome Res.	SEP	2006	16	9					1126	1135		10.1101/gr.5144106		10	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	080HN	WOS:000240238600007	16899653	
J	Van Assche, A; Vens, C; Blockeel, H; Dzeroski, S				Van Assche, Anneleen; Vens, Celine; Blockeel, Hendrik; Dzeroski, Saso			First order random forests: Learning relational classifiers with complex aggregates	MACHINE LEARNING			English	Article; Proceedings Paper	13th International Conference on Inductive Logic Programming	SEP 29-OCT 01, 2003	Szeged, HUNGARY	Univ Szeged, Dept Informat, European Knowledge Discovery Network Excellence, Machine Learning, Minist Educ Hungary		relational learning; random forests; aggregation; decision tree learning	MODELS	In relational learning, predictions for an individual are based not only on its own properties but also on the properties of a set of related individuals. Relational classifiers differ with respect to how they handle these sets: some use properties of the set as a whole (using aggregation), some refer to properties of specific individuals of the set, however, most classifiers do not combine both. This imposes an undesirable bias on these learners. This article describes a learning approach that avoids this bias, using first order random forests. Essentially, an ensemble of decision trees is constructed in which tests are first order logic queries. These queries may contain aggregate functions, the argument of which may again be a first order logic query. The introduction of aggregate functions in first order logic, as well as upgrading the forest's uniform feature sampling procedure to the space of first order logic, generates a number of complications. We address these and propose a solution for them. The resulting first order random forest induction algorithm has been implemented and integrated in the ACE-ilProlog system, and experimentally evaluated on a variety of datasets. The results indicate that first order random forests with complex aggregates are an efficient and effective approach towards learning relational classifiers that involve aggregates over complex selections.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium; Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana 1000, Slovenia	Van Assche, A (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Louvain, Belgium.	anneleen.vanassche@cs.kuleuven.be; celine.vens@cs.kuleuven.be; hendrik.blockeel@cs.kuleuven.be; saso.dzeroski@ijs.si					Berka P., 2000, ECML PKDD 2000 DISCO; Blockeel H, 2002, J ARTIF INTELL RES, V16, P135; BLOCKEEL H, 2003, IJCAI 2003 WORKSH LE; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; Blockeel H., 1997, LECT NOTES ARTIF INT, V1297, P77; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; De Raedt L., 1995, LECT NOTES ARTIF INT, V997, P80; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; DUTRA ID, 2002, LECT NOTES COMPUTER, V2583, P48; Dzeroski S, 1998, APPL ARTIF INTELL, V12, P363, DOI 10.1080/088395198117686; EMDE W, 1995, P 1995 WORKSH GI SPE; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HOCHE S, 2001, LECT NOTES ARTIF INT, V2157, P51; Knobbe A.J., 2001, LNCS LNAI, V2168, P277; Knobbe A. J., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Koller D, 1999, LECT NOTES ARTIF INT, V1634, P3; KROGEL MA, 2003, P WORK PROGR TRACK 1, P30; Krogel M.-A., 2001, P 11 INT C IND LOG P, P142; KROGEL MA, 2003, LNCS LNAI, V2835, P194; Lavrac N., 1994, INDUCTIVE LOGIC PROG; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muggleton S.H, 1992, INDUCTIVE LOGIC PROG; NEVILLE J, 2003, P 9 ACM SIGKDD INT C; Perlich Claudia, 2003, P 9 ACM SIGKDD INT C, P167; Plotkin G.D., 1970, MACH INTELL, V5, P153; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Quinlan J. R., 1993, M KAUFMANN SERIES MA; QUINLAN JR, 1996, ALG LEARN THEOR 7 IN; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Srinivasan A., 1995, P 5 INT WORKSH IND L, P199; Srinivasan A., 2003, ALEPH MANUAL; Srinivasan A, 1999, LECT NOTES ARTIF INT, V1634, P291; Uwents W, 2005, LECT NOTES ARTIF INT, V3625, P384	38	17	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	SEP	2006	64	1-3					149	182		10.1007/s10994-006-8713-9		34	Computer Science, Artificial Intelligence	Computer Science	077IC	WOS:000240021500008		
J	Liu, GD; McMillan, L				Liu, Guodong; McMillan, Leonard			Estimation of missing markers in human motion capture	VISUAL COMPUTER			English	Article; Proceedings Paper	14th Pacific Conference on Computer Graphics and Applications	OCT 11-13, 2005	Taipei, TAIWAN			missing markers; motion capture; principle component analysis; piecewise linear modeling	INTERPOLATION	Motion capture is a prevalent technique for capturing and analyzing human articulations. A common problem encountered in motion capture is that some marker positions are often missing due to occlusions or ambiguities. Most methods for completing missing markers may quickly become ineffective and produce unsatisfactory results when a significant portion of the markers are missing for extended periods of time. We propose a data-driven, piecewise linear modeling approach to missing marker estimation that is especially beneficial in this scenario. We model motion sequences of a training set with a hierarchy of low-dimensional local linear models characterized by the principal components. For a new sequence with missing markers, we use a pre-trained classifier to identify the most appropriate local linear model for each frame and then recover the missing markers by finding the least squares solutions based on the available marker positions and the principal components of the associated model. Our experimental results demonstrate that our method is efficient in recovering the full-body motion and is robust to heterogeneous motion data.	Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27515 USA	Liu, GD (reprint author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27515 USA.	liug@cs.unc.edu; mcmillan@cs.unc.edu					Barbic J, 2004, PROC GRAPH INTERF, P185; BREGLER C, 1995, ADV NEURAL INFORMATI, P43; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248; DORFMULLERULHAA.K, 2003, 10 ACM S VIRT REAL S; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; Grochow K., 2004, P ACM SIGGRAPH, P522; GUO S, 1996, COMP AN SIM 96 SPRIN, P95; Herda L, 2000, COMP ANIM CONF PROC, P77; Hinton G. E., 1995, ADV NEURAL INFORMATI, V7, P1015; Hornung A, 2005, P IEEE VIRT REAL ANN, P75; Lawrence ND, 2004, ADV NEUR IN, V16, P329; Liu G., 2006, P 2006 S INT 3D GRAP, P35, DOI 10.1145/1111411.1111418; Press W. H., 1986, NUMERICAL RECIPES AR; Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559; Roweis S, 1998, ADV NEUR IN, V10, P626; SAFONOVA A, 2004, P SIGGRAPH, P514; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; WELCH G, 1999, S VIRT REAL SOFTW TE, P1; Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968	20	12	18	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0178-2789			VISUAL COMPUT	Visual Comput.	SEP	2006	22	9-11					721	728		10.1007/s00371-006-0080-9		8	Computer Science, Software Engineering	Computer Science	082IW	WOS:000240381000015		
J	Garzon, MB; Blazek, R; Neteler, M; de Dios, RS; Ollero, HS; Furlanello, C				Benito Garzon, Marta; Blazek, Radim; Neteler, Markus; Sanchez de Dios, Rut; Sainz Ollero, Helios; Furlanello, Cesare			Predicting habitat suitability with machine learning models: The potential area of Pinus sylvestris L. in the Iberian Peninsula	ECOLOGICAL MODELLING			English	Article						machine learning; random forest; neural networks; classification and regression trees; AUC; kappa; Iberian Peninsula; Pinus sylvestris L.; habitat suitability	ARTIFICIAL NEURAL-NETWORKS; EASTERN UNITED-STATES; SPECIES DISTRIBUTIONS; CLIMATE-CHANGE; CLASSIFICATION TREES; REGRESSION TREES; VEGETATION; PLANT; DISPERSAL; ENVELOPE	We present a modelling framework for predicting forest areas. The framework is obtained by integrating a machine learning software suite within the GRASS Geographical Information System (GIS) and by providing additional methods for predictive habitat modelling. Three machine learning techniques (Tree-Based Classification, Neural Networks and Random Forest) are available in parallel for modelling from climatic and topographic variables. Model evaluation and parameter selection are measured by sensitivity-specificity ROC analysis, while the final presence and absence maps are obtained through maximisation of the kappa statistic. The modelling framework is applied at a resolution of 1km. with Iberian subpopulations of Pinus sylvestris L. forests. For this data set, the most accurate algorithm is Breiman's random forest, an ensemble method which provides automatic combination of tree-classifiers trained on bootstrapped subsamples and randomised variable sets. All models show a potential area of P.syluestris for the Iberian Peninsula which is larger than the present one, a result corroborated by regional pollen analyses. (c) 2006 Elsevier B.V All rights reserved.	Univ Autonoma Madrid, Dept Biol, Bot Unit, E-28049 Madrid, Spain; ITC Irst, Predict Models Biol & Environm Data Anal, I-38050 Trento, Italy	Garzon, MB (reprint author), Univ Autonoma Madrid, Dept Biol, Bot Unit, Carretera Colmenar,Km 15, E-28049 Madrid, Spain.	marta.benito@uam.es	Neteler, Markus/C-6328-2008; Benito Garzon, Marta/E-3622-2013; Sanchez de Dios, Rut/M-3596-2014; Furlanello, Cesare/	Neteler, Markus/0000-0003-1916-1966; Benito Garzon, Marta/0000-0002-3436-123X; Furlanello, Cesare/0000-0002-5384-3605			Anderson RP, 2003, ECOL MODEL, V162, P211, DOI 10.1016/S0304-3800(02)00349-6; ANTON MG, 1997, J BIOGEOGR, V26, P929; Augustin NH, 2001, J APPL ECOL, V38, P991, DOI 10.1046/j.1365-2664.2001.00653.x; Bakkenes M, 2002, GLOBAL CHANGE BIOL, V8, P390, DOI 10.1046/j.1354-1013.2001.00467.x; Beamounts LJ, 2005, ECOL MODEL, V186, P250; BISHP C, 1995, NEURAL NETWORKS PATT; BIVAND RS, 2004, GRASS INTERFACE GRAS; Bivand RS, 2000, COMPUT GEOSCI-UK, V26, P1043, DOI 10.1016/S0098-3004(00)00057-1; BIVAND RS, 2000, P 5 C GEOC U GREENW; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2002, MANUAL SETTING USING; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Busby J.R., 1991, NATURE CONSERVATION, P64; CARPENTER G, 1993, BIODIVERS CONSERV, V2, P667, DOI 10.1007/BF00051966; Caudill M., 1991, AI Expert, V6; Costa Tenorio M, 1990, ECOLOGIA, V1, P31; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; Debeljak M, 2001, ECOL MODEL, V138, P321, DOI 10.1016/S0304-3800(00)00411-7; Dedecker AP, 2004, ECOL MODEL, V174, P161, DOI 10.1016/j.ecolmodel.2004.01.003; Duckworth JC, 2000, GLOBAL ECOL BIOGEOGR, V9, P187, DOI 10.1046/j.1365-2699.2000.00161.x; DUDIK M, 2004, P 21 INT C MACH LEAR; Dzeroski S, 2003, ECOL MODEL, V170, P219, DOI 10.1016/S0304-3800(03)00229-1; Ellison AM, 2004, ECOL LETT, V7, P509, DOI 10.1111/j.1461-0248.2004.00603.x; FARJON A, 1984, DRAWINGS DESCRIPTION, P220; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Fleishman E, 2001, CONSERV BIOL, V15, P1674, DOI 10.1046/j.1523-1739.2001.00053.x; Franco Múgica F., 2001, Holocene, V11, P343, DOI 10.1191/095968301669474913; Franco-Mugica F., 1998, HOLOCENE, V8, P69, DOI 10.1191/095968398675691171; FURLANELLO C, 2003, P DSC 03 INT WORKSH; Garzon M. Benito, 2003, Graellsia, V59, P345; GOMEZ MFS, 1999, HOLOCENE, V9, P39; GOMEZCOMPO C, 1985, PLANT CONSERVATION M; GUILLEN RFI, 1981, VEGETACIO PAISOS CAT; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; Guisan A, 1999, PLANT ECOL, V143, P107, DOI 10.1023/A:1009841519580; Hewitt GM, 1999, BIOL J LINN SOC, V68, P87, DOI 10.1006/bijl.1999.0332; Hirtzel AH, 2002, ECOLOGY, V83, P2027; HOLLAND JH, 1975, ADAPTATION NATURAL A; Iverson LR, 1999, ECOL MODEL, V115, P77, DOI 10.1016/S0304-3800(98)00200-2; Iverson LR, 2004, LANDSCAPE ECOL, V19, P787, DOI 10.1007/s10980-005-3990-5; Iverson LR, 1998, ECOL MONOGR, V68, P465, DOI 10.2307/2657150; Labra FA, 2003, ECOL LETT, V6, P197, DOI 10.1046/j.1461-0248.2003.00413.x; Lehmann A, 2003, ECOL MODEL, V160, P165, DOI 10.1016/S0304-3800(02)00354-X; Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Linderman M, 2004, INT J REMOTE SENS, V25, P1685, DOI 10.1080/01431160310001598971; Liu CR, 2005, ECOGRAPHY, V28, P385, DOI 10.1111/j.0906-7590.2005.03957.x; Luoto M, 2005, GLOBAL ECOL BIOGEOGR, V14, P575, DOI 10.1111/j.1466-822x.2005.00186.x; Manel S, 2001, J APPL ECOL, V38, P921, DOI 10.1046/j.1365-2664.2001.00647.x; McPherson JM, 2004, J APPL ECOL, V41, P811, DOI 10.1111/j.0021-8901.2004.00943.x; Miller J, 2002, ECOL MODEL, V157, P227, DOI 10.1016/S0304-3800(02)00196-5; MITASOVA H, 1993, MATH GEOL, V25, P641, DOI 10.1007/BF00893171; MONSERUD RA, 1992, ECOL MODEL, V62, P275, DOI 10.1016/0304-3800(92)90003-W; MOORE DM, 1991, ENVIRON MANAGE, V15, P59, DOI 10.1007/BF02393838; Neteler M., 2004, OPEN SOURCE GIS GRAS; Ottaviani D, 2004, ECOL MODEL, V179, P417, DOI 10.1016/j.ecolmodel.2004.05.016; Pearson RG, 2002, ECOL MODEL, V154, P289, DOI 10.1016/S0304-3800(02)00056-X; PEARSON RG, 2004, BIOL CONSERV, V123, P389; Pearson RG, 2004, ECOGRAPHY, V27, P285, DOI 10.1111/j.0906-7590.2004.03740.x; Peterson AT, 2002, NATURE, V416, P626, DOI 10.1038/416626a; Phillips SJ, 2006, ECOL MODEL, V190, P231, DOI 10.1016/j.ecolmodel.2005.03.026; Prus-Glowacki W, 2003, PLANT SYST EVOL, V239, P55, DOI 10.1007/s00606-002-0256-3; PRUSGLOWACKI W, 1994, SILVAE GENET, V43, P7; R Development Core Team, 2004, R LANG ENV STAT COMP; Recknagel F, 2001, ECOL MODEL, V146, P303, DOI 10.1016/S0304-3800(01)00316-7; Robertson MP, 2003, ECOL MODEL, V164, P153, DOI 10.1016/S0304-3800(03)00028-0; Rouget M, 2001, J VEG SCI, V12, P491, DOI 10.2307/3237001; RUBY JOHN L., 1967, SILVAE GENET, V16, P50; Sanchez Palomares O., 1999, MODELOS CARTOGRAFIA; Segurado P, 2004, J BIOGEOGR, V31, P1555, DOI 10.1111/j.1365-2699.2004.01076.x; Seoane J, 2005, ECOL MODEL, V185, P299, DOI 10.1016/j.ecolmodel.2004.12.012; Seoane J, 2004, ECOL MODEL, V171, P209, DOI 10.1016/j.ecolmodel.2003.08.006; Soons MB, 2005, DIVERS DISTRIB, V11, P165, DOI 10.1111/j.1366-9516.2005.00148.x; Takahashi K, 2004, J ECOL, V92, P778, DOI 10.1111/j.0022-0477.2004.00927.x; Therneau TM, 1997, INTRO RECURSIVE PART; Thuiller W, 2003, GLOBAL CHANGE BIOL, V9, P1353, DOI 10.1046/j.1365-2486.2003.00666.x; Thuiller W, 2003, GLOBAL ECOL BIOGEOGR, V12, P313, DOI 10.1046/j.1466-822X.2003.00033.x; Vayssieres MP, 2000, J VEG SCI, V11, P679, DOI 10.2307/3236575; Venables WN, 2002, MODERN APPL STAT S, V4th; WALKER PA, 1991, GLOBAL ECOL BIOGEOGR, V1, P108, DOI 10.2307/2997706	81	73	75	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800			ECOL MODEL	Ecol. Model.	AUG 25	2006	197	3-4					383	393		10.1016/j.ecolmodel.2006.03.015		11	Ecology	Environmental Sciences & Ecology	076VH	WOS:000239985700012		
J	Hua, F; Hautaniemi, S; Yokoo, R; Lauffenburger, DA				Hua, Fei; Hautaniemi, Sampsa; Yokoo, Rayka; Lauffenburger, Douglas A.			Integrated mechanistic and data-driven modelling for multivariate analysis of signalling pathways	JOURNAL OF THE ROYAL SOCIETY INTERFACE			English	Article						apoptosis; machine learning; mechanistic modelling; signalling pathways; systems biology	MATHEMATICAL-MODEL; INDUCED APOPTOSIS; RECEPTOR; DEATH; INHIBITION; ACTIVATION; NETWORKS; DYNAMICS; SYSTEM; MODULE	Mathematical models of highly interconnected and multivariate signalling networks provide useful tools to understand these complex systems. However, effective approaches to extracting multivariate regulation information from these models are still lacking. In this study, we propose a data-driven modelling framework to analyse large-scale multivariate datasets generated from mathematical models. We used an ordinary differential equation based model for the Fas apoptotic pathway as an example. The first step in our approach was to cluster simulation outputs generated from models with varied protein initial concentrations. Subsequently, decision tree analysis was applied, in which we used protein concentrations to predict the simulation outcomes. Our results suggest that no single subset of proteins can determine the pathway behaviour. Instead, different subsets of proteins with different concentrations ranges can be important. We also used the resulting decision tree to identify the minimal number of perturbations needed to change pathway behaviours. In conclusion, our framework provides a novel approach to understand the multivariate dependencies among molecules in complex networks, and can potentially be used to identify combinatorial targets for therapeutic interventions.	MIT, Biol Engn Div, Cambridge, MA 02139 USA	Hautaniemi, S (reprint author), MIT, Biol Engn Div, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	sampsa@mit.edu	Hautaniemi, Sampsa/A-3122-2009	Hautaniemi, Sampsa/0000-0002-7749-2694			Adam BL, 2002, CANCER RES, V62, P3609; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Bentele M, 2004, J CELL BIOL, V166, P839, DOI 10.1083/jcb.200404158; Bratton SB, 2002, CELL DEATH DIFFER, V9, P881, DOI 10.1038/sj.cdd.4401069; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; de Pillis LG, 2005, CANCER RES, V65, P7950, DOI 10.1158/0008-5472.CAN-05-0564; Duda R. O., 2001, PATTERN RECOGNITION; Frantz S, 2005, NATURE, V437, P942, DOI 10.1038/437942a; Fussenegger M, 2000, NAT BIOTECHNOL, V18, P768; Gunther EC, 2003, P NATL ACAD SCI USA, V100, P9608, DOI 10.1073/pnas.1632587100; Hautaniemi S, 2005, BIOINFORMATICS, V21, P2027, DOI 10.1093/bioinformatics/bti278; Hoffmann A, 2002, SCIENCE, V298, P1241, DOI 10.1126/science.1071914; Hua F, 2005, J IMMUNOL, V175, P985; Igney FH, 2002, NAT REV CANCER, V2, P277, DOI 10.1038/nrc776; Irmler M, 1997, NATURE, V388, P190; Kholodenko BN, 1999, J BIOL CHEM, V274, P30169, DOI 10.1074/jbc.274.42.30169; Kislinger T, 2005, MOL CELL PROTEOMICS, V4, P887, DOI 10.1074/mcp.M400182-MCP200; Krammer PH, 2000, NATURE, V407, P789, DOI 10.1038/35037728; Landowski TH, 1997, BLOOD, V90, P4266; Lavrik I, 2005, J CELL SCI, V118, P265, DOI 10.1242/jcs.01610; Ma'ayan A, 2005, ANNU REV BIOPH BIOM, V34, P319, DOI 10.1146/annurev.biophys.34.040204.144415; Mencher Simon K, 2005, BMC Clin Pharmacol, V5, P3, DOI 10.1186/1472-6904-5-3; Nagata S, 1999, ANNU REV GENET, V33, P29, DOI 10.1146/annurev.genet.33.1.29; Podgorelec Vili, 2002, J Med Syst, V26, P445, DOI 10.1023/A:1016409317640; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Roth BL, 2004, NAT REV DRUG DISCOV, V3, P353, DOI 10.1038/nrd1346; Scaffidi C, 1998, EMBO J, V17, P1675, DOI 10.1093/emboj/17.6.1675; Schoeberl B, 2002, NAT BIOTECHNOL, V20, P370, DOI 10.1038/nbt0402-370; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Wiley HS, 2003, TRENDS CELL BIOL, V13, P43	32	28	29	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	1742-5689			J R SOC INTERFACE	J. R. Soc. Interface	AUG 22	2006	3	9					515	526		10.1098/rsif.2005.0109		12	Multidisciplinary Sciences	Science & Technology - Other Topics	135PI	WOS:000244165100005	16849248	
J	Pang, H; Lin, AP; Holford, M; Enerson, BE; Lu, B; Lawton, MP; Floyd, E; Zhao, HY				Pang, Herbert; Lin, Aiping; Holford, Matthew; Enerson, Bradley E.; Lu, Bin; Lawton, Michael P.; Floyd, Eugenia; Zhao, Hongyu			Pathway analysis using random forests classification and regression	BIOINFORMATICS			English	Article							GENE-EXPRESSION PROFILES; ENDOTHELIAL-CELLS; CROSS-VALIDATION; BREAST-CANCER; X-INACTIVATION; ADENOCARCINOMA; IDENTIFICATION; PATHOGENESIS; ACTIVATION; PREDICTION	Motivation: Although numerous methods have been developed to better capture biological information from microarray data, commonly used single gene-based methods neglect interactions among genes and leave room for other novel approaches. For example, most classification and regression methods for microarray data are based on the whole set of genes and have not made use of pathway information. Pathway-based analysis in microarray studies may lead to more informative and relevant knowledge for biological researchers. Results: In this paper, we describe a pathway-based classification and regression method using Random Forests to analyze gene expression data. The proposed methods allow researchers to rank important pathways from externally available databases, discover important genes, find pathway-based outlying cases and make full use of a continuous outcome variable in the regression setting. We also compared Random Forests with other machine learning methods using several datasets and found that Random Forests classification error rates were either the lowest or the second-lowest. By combining pathway information and novel statistical methods, this procedure represents a promising computational strategy in dissecting pathways and can provide biological insight into the study of microarray data.	Yale Univ, Sch Med, Dept Epidemiol & Publ Hlth, Div Biostat, New Haven, CT 06520 USA; Yale Univ, Sch Med, WM Keck Biotechnol Resource Lab, New Haven, CT 06520 USA; Yale Univ, Sch Med, Boyer Ctr Mol Med, New Haven, CT 06520 USA; Yale Univ, Sch Med, Dept Genet, New Haven, CT 06520 USA; Pfizer Inc, Groton Labs, Safety Sci, Groton, CT 06340 USA	Zhao, HY (reprint author), Yale Univ, Sch Med, Dept Epidemiol & Publ Hlth, Div Biostat, 333 Cedar St, New Haven, CT 06520 USA.	hongyu.zhao@yale.edu					Appella E, 2001, EUR J BIOCHEM, V268, P2764, DOI 10.1046/j.1432-1327.2001.02225.x; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bolick DT, 2005, ARTERIOSCL THROM VAS, V25, P2301, DOI 10.1161/01.ATV.0000186181.19909.a6; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2003, MANUAL SETTING UP US; Carrel L, 2005, NATURE, V434, P400, DOI 10.1038/nature03479; Charo IF, 2004, CIRC RES, V95, P858, DOI 10.1161/01.RES.0000146672.10582.17; Curtis RK, 2005, TRENDS BIOTECHNOL, V23, P429, DOI 10.1016/j.tibtech.2005.05.011; Desai A, 2003, INFLAMMATION, V27, P213, DOI 10.1023/A:1025036530605; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Disteche CM, 2002, CYTOGENET GENOME RES, V99, P36, DOI 10.1159/000071572; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Enerson BE, 2006, TOXICOL PATHOL, V34, P27, DOI 10.1080/01926230500512068; Erkilic K, 2003, MEDIAT INFLAMM, V12, P107, DOI 10.1080/0962935031000097754; Farmer P, 2005, ONCOGENE, V24, P4660, DOI 10.1038/sj.onc.1208561; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; HARRIS MA, 2004, NUCLEIC ACIDS RES, V32, P258; Hosack DA, 2003, GENOME BIOL, V4, P70; Iida T, 2002, GENES CELLS, V7, P143, DOI 10.1046/j.1356-9597.2001.00512.x; Kanehisa M., 2004, NUCLEIC ACIDS RES, V32, P277; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Maglott D, 2005, NUCLEIC ACIDS RES, V33, pD54, DOI 10.1093/nar/gki031; Mehra R, 2005, CANCER RES, V65, P11259, DOI 10.1158/0008-5472.CAN-05-2495; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; Mootha VK, 2003, NAT GENET, V34, P267, DOI 10.1038/ng1180; Motoyama AB, 2003, BREAST CANCER RES, V5, P27, DOI 10.1186/bcr552; Panzer U, 2006, J AM SOC NEPHROL, V17, P454, DOI 10.1681/ASN.2005040364; Perumal SS, 2005, CANCER CHEMOTH PHARM, V56, P105, DOI 10.1007/s00280-004-0943-6; Qi YJ, 2006, PROTEINS, V63, P490, DOI 10.1002/prot.20865; Rajagopalan D, 2005, BIOINFORMATICS, V21, P788, DOI 10.1093/bioinformatics/bti069; ROTHENBACHER D, 2005, ARTERIOSCLER THROMB, V26, P194; Sato N, 1998, J BIOCHEM-TOKYO, V123, P1119; Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303; Shao WL, 2004, BREAST CANCER RES, V6, P39, DOI 10.1186/bcr742; Sotiriou C, 2003, P NATL ACAD SCI USA, V100, P10393, DOI 10.1073/pnas.1732912100; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Wright G, 2003, P NATL ACAD SCI USA, V100, P9991, DOI 10.1073/pnas.1732008100; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Zhao Y, 2004, J BIOL CHEM, V279, P30844, DOI 10.1074/jbc.M404651200	44	86	94	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	AUG 15	2006	22	16					2028	2036		10.1093/bioinformatics/btl344		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	075QL	WOS:000239900200014	16809386	
J	Ma, Y; Ding, ZY; Qian, Y; Shi, XL; Castranova, V; Harner, EJ; Guo, L				Ma, Yan; Ding, Zhenyu; Qian, Yong; Shi, Xianglin; Castranova, Vince; Harner, E. James; Guo, Lan			Predicting cancer drug response by proteomic profiling	CLINICAL CANCER RESEARCH			English	Article							MOLECULAR PHARMACOLOGY; CLASSIFICATION; SENSITIVITY; MICROARRAYS; SELECTION	Purpose: Accurate prediction of an individual patient's drug response is an important prerequisite of personalized medicine. Recent pharmacogenomics research in chemosensitivity prediction has studied the gene-drug correlation based on transcriptional profiling. However, proteomic profiling will more directly solve the current functional and pharmacologic problems. We sought to determine whether proteomic signatures of untreated cells were sufficient for the prediction of drug response. Experimental Design: In this study, a machine learning model system was developed to classify cell line chemosensitivity exclusively based on proteomic profiling. Using reverse-phase protein lysate microarrays, protein expression levels were measured by 52 antibodies in a panel of 60 human cancer cell (NCI-60) lines. The model system combined several well-known algorithms, including random forests, Relief, and the nearest neighbor methods, to construct the protein expression - based chemosensitivity classifiers. The classifiers were designed to be independent of the tissue origin of the cells. Results: A total of 118 classifiers of the complete range of drug responses (sensitive, intermediate, and resistant) were generated for the evaluated anticancer drugs, one for each agent. The accuracy of chemosensitivity prediction of all the evaluated 118 agents was significantly higher (P < 0.02) than that of random prediction. Furthermore, our study found that the proteomic determinants for chemosensitivity of 5-fluorouracil were also potential diagnostic markers of colon cancer. Conclusions: The results showed that it was feasible to accurately predict chemosensitivity by proteomic approaches. This study provides a basis for the prediction of drug response based on protein markers in the untreated tumors.	W Virginia Univ, Mary Babb Randolph Canc Ctr, Dept Community Med, Morgantown, WV 26506 USA; NIOSH, Pathol & Physiol Res Branch, Hlth Effects Lab Div, Morgantown, WV USA; W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA; W Virginia Univ, Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA	Guo, L (reprint author), W Virginia Univ, Mary Babb Randolph Canc Ctr, Dept Community Med, POB 9300,1814 HSS, Morgantown, WV 26506 USA.	yaq2@cdc.gov; lguo@hsc.wvu.edu	Shi, Xianglin/B-8588-2012				AHA D, 1996, MACH LEARN, V6, P37; BASILI R, 2004, P ISMIR 2004 5 INT C; BENSON AB, 2005, SEMIN ONCOL, V32, P74, DOI 10.1053/j.seminoncol.2005.04.016; Bild AH, 2006, NATURE, V439, P353, DOI 10.1038/nature04296; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Frank E., 2005, DATA MINING PRACTICA; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Munagala K, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-21; Nishizuka S, 2003, CANCER RES, V63, P5243; Nishizuka S, 2003, P NATL ACAD SCI USA, V100, P14229, DOI 10.1073/pnas.2331323100; Paweletz CP, 2001, ONCOGENE, V20, P1981, DOI 10.1038/sj.onc.1204265; Rifkin R, 2003, SIAM REV, V45, P706, DOI 10.1137/S0036144502411986; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Solit DB, 2006, NATURE, V439, P358, DOI 10.1038/nature04304; Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Szakacs G, 2004, CANCER CELL, V6, P129, DOI 10.1016/j.ccr.2004.06.026; Weinstein JN, 1997, SCIENCE, V275, P343, DOI 10.1126/science.275.5298.343	20	42	46	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	AUG 1	2006	12	15					4583	4589		10.1158/1078-0432.CCR-06-0290		7	Oncology	Oncology	073NR	WOS:000239750400018	16899605	
J	Lawler, JJ; White, D; Neilson, RP; Blaustein, AR				Lawler, Joshua J.; White, Denis; Neilson, Ronald P.; Blaustein, Andrew R.			Predicting climate-induced range shifts: model differences and model reliability	GLOBAL CHANGE BIOLOGY			English	Article						climate change; climate-envelope models; extinction; geographic range; model averaging; model prediction; random forest predictors	LAND-COVER DATA; SPECIES DISTRIBUTIONS; VEGETATION DISTRIBUTION; UNITED-STATES; CLASSIFICATION; TREE; VALIDATION; SCENARIOS; ENVELOPE; RESERVES	Predicted changes in the global climate are likely to cause large shifts in the geographic ranges of many plant and animal species. To date, predictions of future range shifts have relied on a variety of modeling approaches with different levels of model accuracy. Using a common data set, we investigated the potential implications of alternative modeling approaches for conclusions about future range shifts and extinctions. Our common data set entailed the current ranges of 100 randomly selected mammal species found in the western hemisphere. Using these range maps, we compared six methods for modeling predicted future ranges. Predicted future distributions differed markedly across the alternative modeling approaches, which in turn resulted in estimates of extinction rates that ranged between 0% and 7%, depending on which model was used. Random forest predictors, a model-averaging approach, consistently outperformed the other techniques (correctly predicting > 99% of current absences and 86% of current presences). We conclude that the types of models used in a study can have dramatic effects on predicted range shifts and extinction rates; and that model-averaging approaches appear to have the greatest potential for predicting range shifts in the face of climate change.	US EPA, Corvallis, OR 97333 USA; Oregon State Univ, Dept Zool, Corvallis, OR 97331 USA; US Forest Serv, Corvallis, OR 97331 USA	Lawler, JJ (reprint author), US EPA, 200 SW 35th St, Corvallis, OR 97333 USA.	lawler.joshua@epa.gov	Neilson, Ronald/A-8588-2009				Anderson RP, 2003, ECOL MODEL, V162, P211, DOI 10.1016/S0304-3800(02)00349-6; Araujo MB, 2005, GLOBAL CHANGE BIOL, V11, P1504, DOI 10.1111/j.1365-2486.2005.001000.x; Araujo MB, 2004, GLOBAL CHANGE BIOL, V10, P1618, DOI 10.1111/j.1365-2486.2004.00828.x; Bachelet D, 2001, ECOSYSTEMS, V4, P164, DOI 10.1007/s10021-001-0002-7; BACHELET D, 2003, GLOBAL BIOGEOCHEMICA, V17, P14, DOI DOI 10.1029/2001GB001508; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chambers JM, 1991, STAT MODELS S; Thomas CD, 2001, NATURE, V411, P577, DOI 10.1038/35079066; Cramer W, 2001, GLOBAL CHANGE BIOL, V7, P357, DOI 10.1046/j.1365-2486.2001.00383.x; Davis AJ, 1998, NATURE, V391, P783, DOI 10.1038/35842; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; Etterson JR, 2001, SCIENCE, V294, P151, DOI 10.1126/science.1063656; Fielding AH, 1995, CONSERV BIOL, V9, P1466, DOI 10.1046/j.1523-1739.1995.09061466.x; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Guisan A, 2002, ECOL MODEL, V157, P89, DOI 10.1016/S0304-3800(02)00204-1; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; Hastie T., 1990, GENERALIZED ADDITIVE; Hoffmann A. A., 1991, EVOLUTIONARY GENETIC; HOLM S, 1979, SCAND J STAT, V6, P65; Houghton JT, 2001, CLIMATE CHANGE 2001; Huntley B, 2004, ECOL LETT, V7, P417, DOI 10.1111/j.1461-0248.2004.00598.x; Iverson LR, 1998, ECOL MONOGR, V68, P465, DOI 10.2307/2657150; Johns TC, 1997, CLIM DYNAM, V13, P103, DOI 10.1007/s003820050155; Kattenberg A, 1996, CLIMATE CHANGE 1995, P285; Koenig WD, 1999, TRENDS ECOL EVOL, V14, P22, DOI 10.1016/S0169-5347(98)01533-X; Leemans R., 1991, RR9118 IIASA; Lomolino M.V., 2005, BIOGEOGRAPHY; Loveland TR, 1999, PHOTOGRAMM ENG REM S, V65, P1021; McCullagh P., 1989, GENERALIZED LINEAR M, VSecond; Meyneeke JO, 2004, ECOL MODEL, V174, P347, DOI 10.1016/j.ecolmodel.2003.07.012; Moisen GG, 2002, ECOL MODEL, V157, P209, DOI 10.1016/S0304-3800(02)00197-7; MONSERUD RA, 1992, ECOL MODEL, V62, P275, DOI 10.1016/0304-3800(92)90003-W; NEILSON RP, 1995, ECOL APPL, V5, P362, DOI 10.2307/1942028; Nix H. A., 1986, ATLAS ELAPID SNAKES, V7, P4; Parmesan C, 2003, NATURE, V421, P37, DOI 10.1038/nature01286; Patterson B. D., 2003, DIGITAL DISTRIBUTION; Pearson RG, 2003, GLOBAL ECOL BIOGEOGR, V12, P361, DOI 10.1046/j.1466-822X.2003.00042.x; Pearson RG, 2002, ECOL MODEL, V154, P289, DOI 10.1016/S0304-3800(02)00056-X; Pearson RG, 2004, ECOGRAPHY, V27, P285, DOI 10.1111/j.0906-7590.2004.03740.x; PETERS RL, 1985, BIOSCIENCE, V35, P707, DOI 10.2307/1310052; Peterson AT, 2002, NATURE, V416, P626, DOI 10.1038/416626a; Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1; Ripley B. D., 1996, PATTERN RECOGNITION; Robertson MP, 2003, ECOL MODEL, V164, P153, DOI 10.1016/S0304-3800(03)00028-0; Root TL, 2003, NATURE, V421, P57, DOI 10.1038/nature01333; Segurado P, 2004, J BIOGEOGR, V31, P1555, DOI 10.1111/j.1365-2699.2004.01076.x; Shafer SL, 2001, ECOSYSTEMS, V4, P200, DOI 10.1007/s10021-001-0004-5; Sitch S, 2003, GLOBAL CHANGE BIOL, V9, P161, DOI 10.1046/j.1365-2486.2003.00569.x; Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7; STOCKWELL DRB, 1992, MATH COMPUT SIMULAT, V33, P385, DOI 10.1016/0378-4754(92)90126-2; Therneau TM, 1997, INTRO RECURSIVE PART; Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121; Thuiller W, 2003, J VEG SCI, V14, P669, DOI 10.1658/1100-9233(2003)014[0669:GMVCTA]2.0.CO;2; Thuiller W, 2003, GLOBAL CHANGE BIOL, V9, P1353, DOI 10.1046/j.1365-2486.2003.00666.x; Thuiller W, 2004, ECOGRAPHY, V27, P165, DOI 10.1111/j.0906-7590.2004.03673.x; Thuiller W, 2004, GLOBAL CHANGE BIOL, V10, P2020, DOI 10.1111/j.1365-2486.2004.00859.x; Thuiller W, 2005, GLOBAL ECOL BIOGEOGR, V14, P347, DOI 10.1111/j.1466-822x.2005.00162.x; Thuiller W, 2004, J BIOGEOGR, V31, P353; Thuiller W, 2005, P NATL ACAD SCI USA, V102, P8245, DOI 10.1073/pnas.0409902102; THUILLER W, 2004, NATURE, V430, DOI DOI 10.1038/nature02716; Venables W., 2002, MODERN APPL STAT S P; Wahba G., 1990, SPLINE MODELS OBSERV; Williams SE, 2003, P ROY SOC B-BIOL SCI, V270, P1887, DOI 10.1098/rspb.2003.2464; Wood SN, 2002, ECOL MODEL, V157, P157, DOI 10.1016/S0304-3800(02)00193-X	65	148	154	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1354-1013			GLOBAL CHANGE BIOL	Glob. Change Biol.	AUG	2006	12	8					1568	1584		10.1111/j.1365-2486.2006.01191.x		17	Biodiversity Conservation; Ecology; Environmental Sciences	Biodiversity & Conservation; Environmental Sciences & Ecology	063FZ	WOS:000239004700018		
J	O'Riordan, E; Gross, SS; Goligorsky, MS				O'Riordan, Edmond; Gross, Steven S.; Goligorsky, Michael S.			Technology Insight: renal proteomics - at the crossroads between promise and problems	NATURE CLINICAL PRACTICE NEPHROLOGY			English	Review						bioinformatics; kidney; mass spectrometry; proteome; urine	SPECTROMETRY-BASED PROTEOMICS; TANDEM MASS-SPECTROMETRY; COMPLEX PROTEIN MIXTURES; HUMAN-URINE; 2-DIMENSIONAL ELECTROPHORESIS; ALLOGRAFT-REJECTION; PROSTATE-CANCER; MULTIDIMENSIONAL SEPARATION; LIQUID-CHROMATOGRAPHY; CLINICAL PROTEOMICS	Knowledge of the human genome has fertilized research in the embryonic field of proteomics. The aim of this Review is to examine the recent application of emerging proteomic technologies to diagnosis of renal disease. We discuss the roles, efficacy and diagnostic potential of different proteomic approaches, focusing on current difficulties and potential solutions. Our rudimentary knowledge of the healthy human urine proteome is described, as are studies that have sought to use the urinary proteome as a tool for diagnosis of renal disease. Vignettes of renal proteome are also presented. The integral role of bioinformatics, and the need for standardized sample preservation and reporting of results, are discussed.	New York Med Coll, Renal Inst, Dept Med, Renal Res Inst, Valhalla, NY 10595 USA; New York Med Coll, Div Nephrol, Valhalla, NY 10595 USA; Cornell Univ, Weill Med Coll, Dept Pharmacol, New York, NY USA	O'Riordan, E (reprint author), New York Med Coll, Renal Inst, Dept Med, Renal Res Inst, Valhalla, NY 10595 USA.	edmond_oriordan@nymc.edu; michael_goligorsky@nymc.edu					Adam BL, 2002, CANCER RES, V62, P3609; Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Anderson NL, 2004, MOL CELL PROTEOMICS, V3, P311, DOI 10.1074/mcp.M300127-MCP200; Arthur JM, 2003, CURR OPIN NEPHROL HY, V12, P423, DOI 10.1097/01.mnh.0000079691.89474.ee; Bagshaw RD, 2005, MOL CELL PROTEOMICS, V4, P133, DOI 10.1074/mcp.M400128-MCP200; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brookes PS, 2002, PROTEOMICS, V2, P969, DOI 10.1002/1615-9861(200208)2:8<969::AID-PROT969>3.0.CO;2-3; Cadieux PA, 2004, J CLIN LAB ANAL, V18, P170, DOI 10.1002/jcla.20018; Campostrini N, 2005, PROTEOMICS, V5, P2385, DOI 10.1002/pmic.200401253; Carr S, 2004, MOL CELL PROTEOMICS, V3, P531, DOI 10.1074/mcp.T400006-MCP200; Celis JE, 1999, ELECTROPHORESIS, V20, P300; Chaurand P, 2004, AM J PATHOL, V165, P1057, DOI 10.1016/S0002-9440(10)63367-6; Cho A, 2002, SCIENCE, V298, P527; Clarke W, 2003, ANN SURG, V237, P660, DOI 10.1097/00000658-200305000-00008; Claverie J. M., 2003, BIOINFORMATICS DUMMI; Cooper JW, 2004, ELECTROPHORESIS, V25, P3913, DOI 10.1002/elps.200406154; Cutillas PR, 2004, AM J PHYSIOL-RENAL, V287, pF353, DOI 10.1152/ajprenal.00018.2004; DeSouza L, 2005, J PROTEOME RES, V4, P377, DOI 10.1021/pr04982lj; EDWARDS JJ, 1982, CLIN CHEM, V28, P941; Elias JE, 2005, NAT METHODS, V2, P667, DOI 10.1038/NMETH785; FUNG E, 2003, RENAL DIS TECHNIQUES, P295; GIDDINGS JC, 1987, J HIGH RES CHROMATOG, V10, P319, DOI 10.1002/jhrc.1240100517; Granger CB, 2004, CIRCULATION, V109, P1697, DOI 10.1161/01.CIR.0000121563.47232.2A; GRIFFITH OW, 1979, J BIOL CHEM, V254, P7558; Gygi SP, 2000, CURR OPIN CHEM BIOL, V4, P489, DOI 10.1016/S1367-5931(00)00121-6; Gygi SP, 1999, NAT BIOTECHNOL, V17, P994, DOI 10.1038/13690; Hachey DL, 2004, J REPROD IMMUNOL, V63, P61, DOI 10.1016/j.jri.2004.01.009; Hampel DJ, 2001, J AM SOC NEPHROL, V12, P1026; Hanash S, 2004, MOL CELL PROTEOMICS, V3, P298, DOI 10.1074/mcp.R400004-MCP200; Hao G, 2006, P NATL ACAD SCI USA, V103, P1012, DOI 10.1073/pnas.0508412103; Haubitz M, 2005, KIDNEY INT, V67, P2313, DOI 10.1111/j.1523-1755.2005.00335.x; Hewitt SM, 2004, J AM SOC NEPHROL, V15, P1677, DOI 10.1097/01.ASN.0000129114.92265.32; Hirsch J, 2004, AM J PHYSIOL-LUNG C, V287, pL1, DOI 10.1152/ajplung.00301.2003; Ibarrola N, 2003, ANAL CHEM, V75, P6043, DOI 10.1021/ac034931f; Issaq HJ, 2001, ELECTROPHORESIS, V22, P3629, DOI 10.1002/1522-2683(200109)22:17<3629::AID-ELPS3629>3.0.CO;2-O; Issaq HJ, 2005, J CHROMATOGR B, V817, P35, DOI 10.1016/j.jchromb.2004.07.042; JACKSON DW, 1993, AM J KIDNEY DIS, V22, P649; Kiernan UA, 2003, J PROTEOME RES, V2, P191, DOI 10.1021/pr025574c; Kwapiszewska G, 2004, BMC BIOTECHNOL, V4, DOI 10.1186/1472-6750-4-30; Lafitte D, 2002, CLIN BIOCHEM, V35, P581, DOI 10.1016/S0009-9120(02)00362-4; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Li JN, 2002, CLIN CHEM, V48, P1296; Liu H., 2002, BIOTECHNIQUES, V32, P900; Liu H., 2002, BIOTECHNIQUES, V32, P902; Liu HB, 2002, BIOTECHNIQUES, V32, P898; Liu T, 2005, J PROTEOME RES, V4, P2070, DOI 10.1021/pr0502065; Mann M, 2002, TRENDS BIOTECHNOL, V20, P261, DOI 10.1016/S0167-7799(02)01944-3; Marouga R, 2005, ANAL BIOANAL CHEM, V382, P669, DOI 10.1007/s00216-005-3126-3; Marshall AG, 1998, MASS SPECTROM REV, V17, P1, DOI 10.1002/(SICI)1098-2787(1998)17:1<1::AID-MAS1>3.0.CO;2-K; MARSHALL T, 1986, CLIN CHEM, V32, P2105; Mischak H, 2004, CLIN SCI, V107, P485, DOI 10.1042/CS20040103; Molina H, 2005, MOL CELL PROTEOMICS, V4, P637, DOI 10.1074/mcp.M500042-MCP200; Norden AGW, 2004, KIDNEY INT, V66, P1994, DOI 10.1111/j.1523-1755.2004.00970.x; OFARRELL PH, 1975, J BIOL CHEM, V250, P4007; Oh J, 2004, PROTEOMICS, V4, P3485, DOI 10.1002/pmic.200401018; Ong SE, 2005, NAT CHEM BIOL, V1, P252, DOI 10.1038/nchembio736; Orchard Sandra, 2005, Proteomics, V5, P337, DOI 10.1002/pmic.200401158; O'Riordan E, 2004, J AM SOC NEPHROL, V15, P3240, DOI 10.1097/01.ASN.0000145241.83482.68; Osicka TM, 2000, DIABETES, V49, P1579, DOI 10.2337/diabetes.49.9.1579; PIEPER R, 2004, PROTEOMICS, V4, P159; Pisitkun T, 2004, P NATL ACAD SCI USA, V101, P13368, DOI 10.1073/pnas.0403453101; Qu YS, 2002, CLIN CHEM, V48, P1835; Rogers MA, 2003, CANCER RES, V63, P6971; Schaub S, 2005, AM J TRANSPLANT, V5, P729, DOI 10.1111/j.1600-6143.2005.00766.x; Schaub S, 2004, KIDNEY INT, V65, P323, DOI 10.1111/j.1523-1755.2004.00352.x; Schaub S, 2004, J AM SOC NEPHROL, V15, P219, DOI 10.1097/01.ASN.0000101031.52826.BE; Serafini-Cessi F, 2003, AM J KIDNEY DIS, V42, P658, DOI 10.1053/S0272-6386(03)00829-1; Smith G, 2005, PROTEOMICS, V5, P2315, DOI 10.1002/pmic.200401267; Spahr CS, 2001, PROTEOMICS, V1, P93, DOI 10.1002/1615-9861(200101)1:1<93::AID-PROT93>3.0.CO;2-3; Taracha E, 2004, ALCOHOL CLIN EXP RES, V28, P729, DOI 10.1097/01.ALC.0000125347.93779.81; TENCER J, 1994, SCAND J CLIN LAB INV, V54, P199, DOI 10.3109/00365519409088425; Thongboonkerd V, 2002, KIDNEY INT, V62, P1461, DOI 10.1046/j.1523-1755.2002.00565.x; Thongboonkerd V, 2004, J AM SOC NEPHROL, V15, P650, DOI 10.1097/01.ASN.0000115334.65095.9B; VANPIK VN, 1995, NATURE STAT LEARNING; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Wagner M, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-26; Wang YJ, 2004, PROTEOMICS, V4, P20, DOI 10.1002/pmic.200300549; Weissinger EM, 2004, NEPHROL DIAL TRANSPL, V19, P3068, DOI 10.1093/ndt/gfh509; Weissinger EM, 2004, KIDNEY INT, V65, P2426, DOI 10.1111/j.1523-1755.2004.00659.x; Woroniecki RP, 2006, AM J NEPHROL, V26, P258, DOI 10.1159/000093814; Yu JK, 2004, WORLD J GASTROENTERO, V10, P3127; Zolotarjova N, 2005, PROTEOMICS, V5, P3304, DOI 10.1002/pmic.200402021	84	20	20	NATURE PUBLISHING GROUP	NEW YORK	75 VARICK ST, 9TH FLR, NEW YORK, NY 10013-1917 USA	1745-8323			NAT CLIN PRACT NEPHR	Nat. Clin. Pract. Nephrol.	AUG	2006	2	8					445	458		10.1038/ncpneph0241		14	Urology & Nephrology	Urology & Nephrology	067ZF	WOS:000239340600011	16932479	
J	Menze, BH; Lichy, MP; Bachert, P; Kelm, BM; Schlemmer, HP; Hamprecht, FA				Menze, B. H.; Lichy, M. P.; Bachert, P.; Kelm, B. M.; Schlemmer, H. -P.; Hamprecht, F. A.			Optimal classification of long echo time in vivo magnetic resonance spectra in the detection of recurrent brain tumors	NMR IN BIOMEDICINE			English	Article						statistical learning; chemometrics; preprocessing; postprocessing; benchmark; magnetic resonance spectroscopy; human brain tumor	MR SPECTROSCOPY QUANTITATION; PATTERN-RECOGNITION; GLIOMATOSIS CEREBRI; COMPONENT ANALYSIS; DOMAIN METHODS; NMR-SPECTRA; LESIONS; QUANTIFICATION; ACCURACY; GRADE	We describe the optimal high-level postprocessing of single-voxel (1)H magnetic resonance spectra and assess the benefits and limitations of automated methods as diagnostic aids in the detection of recurrent brain tumor. In a previous clinical study, 90 long-echo-time single-voxel spectra were obtained from 52 patients and classified during follow-up (30/28/ 32 normal/non-progressive tumor/tumor). Based on these data, a large number of evaluation strategies, including both standard resonance line quantification and algorithms from pattern recognition and machine learning, were compared in a quantitative evaluation. Results from linear and non-linear feature extraction, including ICA, PCA and wavelet transformations, and'also the data from resonance line quantification were combined systematically with different classifiers such as LDA, chemometric methods (PLS, PCR), support vector machines and ensemble methods. Classification accuracy was assessed using a leave-one-out cross-validation scheme and the area under the curve (AUC) of the receiver operator characteristic (ROC). A regularized linear regression on spectra with binned channels reached 91% classification accuracy compared with 83% from quantification. Interpreting the loadings of these regressions, we find that lipid and lactate signals are too unreliable to be used in a simple machine rule. Choline and NAA are the main source of relevant information. Overall, we find that fully automated pattern recognition algorithms perform as well as, or slightly better than, a manually controlled and optimized resonance line quantification. Copyright (C) 2006 John Wiley & Sons, Ltd.	Univ Heidelberg, Interdisciplinary Ctr Sci Comp IWR, D-69120 Heidelberg, Germany; German Canc Res Ctr, Div Radiol, Heidelberg, Germany; German Canc Res Ctr, Div Med Phys Radiol, Heidelberg, Germany	Hamprecht, FA (reprint author), Univ Heidelberg, Interdisciplinary Ctr Sci Comp IWR, D-69120 Heidelberg, Germany.	fred.hamprecht@iwr.uni-heidelberg.de					Bathen TF, 2000, NMR BIOMED, V13, P271, DOI 10.1002/1099-1492(200008)13:5<271::AID-NBM646>3.0.CO;2-7; Bendszus M, 2000, AM J NEURORADIOL, V21, P375; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Butzen J, 2000, AM J NEURORADIOL, V21, P1213; Devos A, 2004, J MAGN RESON, V170, P164, DOI 10.1016/j.jmr.2004.06.010; Duda R., 2000, PATTERN CLASSIFICATI; Dydak U, 2003, MAGNET RESON MED, V50, P196, DOI 10.1002/mrm.10495; ElDeredy W, 1997, NMR BIOMED, V10, P99, DOI 10.1002/(SICI)1099-1492(199705)10:3<99::AID-NBM461>3.0.CO;2-#; Galanaud D, 2003, J NEUROSURG, V98, P269, DOI 10.3171/jns.2003.98.2.0269; Hagberg G, 1998, NMR BIOMED, V11, P148, DOI 10.1002/(SICI)1099-1492(199806/08)11:4/5<148::AID-NBM511>3.0.CO;2-4; Hastie T., 2001, ELEMENTS STAT LEARNI; Herminghaus S, 2003, J NEUROSURG, V98, P74, DOI 10.3171/jns.2003.98.1.0074; Howe FA, 2003, NMR BIOMED, V16, P123, DOI 10.1002/nbm.822; in 't Zandt H, 2001, NMR Biomed, V14, P224, DOI 10.1002/nbm.707; Ladroue C, 2003, MAGNET RESON MED, V50, P697, DOI 10.1002/mrm.10595; Lichy MP, 2005, NEURORADIOLOGY, V47, P826, DOI 10.1007/s00234-005-1434-0; Lisboa PJG, 1998, NMR BIOMED, V11, P225, DOI 10.1002/(SICI)1099-1492(199806/08)11:4/5<225::AID-NBM509>3.0.CO;2-Q; Majos C, 2003, EUR RADIOL, V13, P582, DOI 10.1007/s00330-002-1547-3; MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468; Menze BH, 2005, ST CLASS DAT ANAL, P362, DOI 10.1007/3-540-28084-7_41; Mierisova S, 2001, NMR BIOMED, V14, P247, DOI 10.1002/nbm.697; Moller-Hartmann W, 2002, NEURORADIOLOGY, V44, P371, DOI 10.1007/s00234-001-0760-0; Naressi A, 2001, MAGN RESON MATER PHY, V12, P141, DOI 10.1007/BF02668096; PROVENCHER SW, 1993, MAGNET RESON MED, V30, P672, DOI 10.1002/mrm.1910300604; Schlemmer HP, 2001, AM J NEURORADIOL, V22, P1316; SEEGER U, P ESMRMB 2003 EUR SO, P331; Simonetti AW, 2005, NMR BIOMED, V18, P34, DOI 10.1002/nbm.919; Simonetti AW, 2003, ANAL CHEM, V75, P5352, DOI 10.1021/ac034541t; STADLBAUER A, P ISMRM 2004 INT SOC, P2053; Stoyanova R, 2002, J MAGN RESON, V154, P163, DOI 10.1006/jmre.2001.2486; TATE AR, 1996, THESIS U SUSSEX; Tate AR, 1996, MAGNET RESON MED, V35, P834, DOI 10.1002/mrm.1910350608; Tate AR, 2003, MAGNET RESON MED, V49, P29, DOI 10.1002/mrm.10315; Tzika AA, 2001, NEURORADIOLOGY, V43, P169; Vanhamme L, 1997, J MAGN RESON, V129, P35, DOI 10.1006/jmre.1997.1244; Vanhamme L, 2001, NMR BIOMED, V14, P233, DOI 10.1002/nbm.695; Witjes H, 2000, J MAGN RESON, V144, P35, DOI 10.1006/jmre.2000.2021	37	24	24	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0952-3480			NMR BIOMED	NMR Biomed.	AUG	2006	19	5					599	609		10.1002/nbm.1041		11	Biophysics; Radiology, Nuclear Medicine & Medical Imaging; Spectroscopy	Biophysics; Radiology, Nuclear Medicine & Medical Imaging; Spectroscopy	076DI	WOS:000239936800011	16642460	
J	Hens, N; Aerts, M; Molenberghs, G				Hens, N.; Aerts, M.; Molenberghs, G.			Model selection for incomplete and design-based samples	STATISTICS IN MEDICINE			English	Article						missing data; weighted likelihood; model selection; complex designs; Akaike information criterion	WEIGHTED LIKELIHOOD METHODOLOGY; AKAIKE INFORMATION CRITERION; ESTIMATING EQUATIONS; REGRESSION; 2-STAGE; FIT	The Akaike information criterion, AIC, is one of the most frequently used methods to select one or a few good, optimal regression models from a set of candidate models. In case the sample is incomplete, the naive use of this criterion on the so-called complete cases can lead to the selection of poor or inappropriate models. A similar problem occurs when a sample based on a design with unequal selection probabilities, is treated as a simple random sample. In this paper, we consider a modification of AIC, based on reweighing the sample in analogy with the weighted Horvitz-Thompson estimates. It is shown that this weighted AIC-criterion provides better model choices for both incomplete and design-based samples. The use of the weighted AIC-criterion is illustrated on data from the Belgian Health Interview Survey, which motivated this research. Simulations show its performance in a variety of settings. Copyright (c) 2006 John Wiley & Sons, Ltd.	Univ Hasselt, Ctr Stat, B-3590 Diepenbeek, Belgium	Hens, N (reprint author), Univ Hasselt, Ctr Stat, Campus Diepenbeek,Agoralaan Gebouw D, B-3590 Diepenbeek, Belgium.	niel.hens@uhasselt.be					Aerts M, 1999, J AM STAT ASSOC, V94, P869; Agostinelli C, 2001, STAT SINICA, V11, P499; Agostinelli C, 2002, STAT PROBABIL LETT, V56, P289, DOI 10.1016/S0167-7152(01)00193-6; Akaike H., 1973, 2 INT S INF THEOR, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burnham K. P., 2002, MODEL SELECTION MULT; Cavanaugh JE, 1998, J STAT PLAN INFER, V67, P45, DOI 10.1016/S0378-3758(97)00115-8; FLANDERS WD, 1991, STAT MED, V10, P739, DOI 10.1002/sim.4780100509; HENS N, 2002, ARCH PUBLIC HLTH, V60, P275; HORVITZ DG, 1952, J AM STAT ASSOC, V47, P663, DOI 10.2307/2280784; HURVICH CM, 1989, BIOMETRIKA, V76, P297, DOI 10.1093/biomet/76.2.297; Hurvich CM, 1998, J ROY STAT SOC B, V60, P271, DOI 10.1111/1467-9868.00125; Kish L, 1995, SURVEY SAMPLING; Little R. J. A., 1987, STAT ANAL MISSING DA; LITTLE RJA, 1992, J AM STAT ASSOC, V87, P1227, DOI 10.2307/2290664; NISHII R, 1984, ANN STAT, V12, P758, DOI 10.1214/aos/1176346522; Pan W, 2001, BIOMETRICS, V57, P120, DOI 10.1111/j.0006-341X.2001.00120.x; Pan W, 2001, BIOMETRICS, V57, P529, DOI 10.1111/j.0006-341X.2001.00529.x; *R DEV COR TEA, LANG ENV STAT COMP R; Reilly M, 1997, STAT MED, V16, P5, DOI 10.1002/(SICI)1097-0258(19970115)16:1<5::AID-SIM469>3.0.CO;2-8; Rotnitzky A, 1995, BIOMETRIKA, V82, P805, DOI 10.1093/biomet/82.4.805; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shimodaira H., 1994, LECT NOTES STAT, V89, P21; Simonoff J., 1996, SMOOTHING METHODS ST; Spiegelhalter DJ, 2002, J ROY STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353; TAKEUCHI K., 1976, SURI KAGAKU, V153, P12; Wahba G., 1990, SPLINE MODELS OBSERV; Wood S. N., 2001, R NEWS, V1, P20; Zhao LP, 1996, BIOMETRICS, V52, P1165, DOI 10.2307/2532833; ZHAO LP, 1992, STAT MED, V11, P769, DOI 10.1002/sim.4780110608	30	29	29	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0277-6715			STAT MED	Stat. Med.	JUL 30	2006	25	14					2502	2520		10.1002/sim.2559		19	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Medicine, Research & Experimental; Statistics & Probability	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Research & Experimental Medicine; Mathematics	063XD	WOS:000239052300011	16596577	
J	Pal, M				Pal, M.			Support vector machine-based feature selection for land cover classification: a case study with DAIS hyperspectral data	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article								This paper present the results of a support vector machine (SVM) technique and a genetic algorithm (GA) technique using generalization error bounds derived for SVMs as fitness functions (SVM/GA) for feature selection using hyperspectral data. Results obtained with the SVM/GA-based technique were compared with those produced by random forest-and SVM-based feature selection techniques in terms of classification accuracy and computational cost. The classification accuracy using SVM-based feature selection was 91.89%. The number of features selected was 15. For comparison, the accuracy produced by the use of the full set of 65 features was 91.76%. The level of classification accuracy achieved by the SVM/ GA approach using 15 features varied from 91.87% to 92.44% with different fitness functions but required a large training time. The performance of the random forest- based feature selection approach gave a classification accuracy of 91.89%, which is comparable to the accuracy achieved by using the SVM and SVM/ GA approaches using 15 features. A smaller computational cost is a major advantage associated with the random forest- based feature selection approach. The training time for the SVM-based approach is also very small in comparison to the SVM/ GA approach, thus suggesting the usefulness of random forest- and SVM- based feature selection approaches in comparison to the SVM/ GA approach for land cover classification problems with hyperspectral data. Further, a higher classification accuracy was achieved with a combination of 20 selected features in comparison to the level of accuracy obtained using 15 features, but the difference in accuracy was not significant. To validate the results, SVM-, SVM/ GA- and random forest-based feature selection approaches were compared with a maximum noise transformation based feature extraction technique. Results show an improved performance using these techniques in comparison to the maximum noise transformation-based feature extraction technique.	Natl Inst Technol, Dept Civil Engn, Kurukshetra 136119, Haryana, India	Pal, M (reprint author), Natl Inst Technol, Dept Civil Engn, Kurukshetra 136119, Haryana, India.	mpce_pal@yahoo.co.uk	Pal, Mahesh/P-1136-2014	Pal, Mahesh/0000-0003-1805-2952			Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chapelle O, 2000, ADV NEUR IN, V12, P230; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Eshelman L.J., 1991, CHC ADAPTIVE SEARCH; FROHLICH H, 2002, THESIS TUBINGEN GERM; Goldberg D, 1989, GENETIC ALGORITHMS S; GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; JAAKOLA TS, 1999, P 1999 C M AI STAT; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JIMINEZ L, 1998, IEEE T GEOSCI REMOTE, V37, P2653; Kavzoglu T, 2001, THESIS U NOTTINGHAM; Knerr S., 1990, NEUROCOMPUTING ALGOR; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Mather P., 2004, COMPUTER PROCESSING; PAL M, 2003, SUPPORT VECTOR CLASS; RICHTER R, 1999, 5520599 DLR IB; SCHMID T, 2004, THESIS AUTONOMOUS U; Scholkopf B., 1995, 1 INT C KNOWL DISC D, P252; SERPICO SB, 2001, DIT02027 U TRENTO IT; Strobl P, 1997, P SOC PHOTO-OPT INS, V3071, P225, DOI 10.1117/12.280599; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; Weston J, 2001, ADV NEUR IN, V13, P668	31	35	37	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161			INT J REMOTE SENS	Int. J. Remote Sens.	JUL 20	2006	27	14					2877	2894				18	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	066OL	WOS:000239239100005		
J	Wang, C				Wang, C			Invited commentary: Beyond frequencies and coefficients-toward meaningful descriptions for life course epidemiology	AMERICAN JOURNAL OF EPIDEMIOLOGY			English	Editorial Material							BODY-COMPOSITION; FUNCTIONAL LIMITATION; PHYSICAL-ACTIVITY; HEALTH; RACE; RACISM; POLICY; MODEL		Univ Calif Berkeley, Sch Publ Hlth, Div Epidemiol, Berkeley, CA 94720 USA; Univ Calif Berkeley, Sch Publ Hlth, Div Community Hlth & Human Dev, Berkeley, CA 94720 USA	Wang, C (reprint author), Univ Calif Berkeley, Sch Publ Hlth, Div Epidemiol, 140 Warren Hall,MC 7360, Berkeley, CA 94720 USA.	constancew@berkeley.edu					BERKMAN L, 1989, DEMOGRAPHY, V26, P661, DOI 10.2307/2061264; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DESTAVOLA BL, 2005, AM J EPIDEMIOL, V163, P84, DOI 10.1093/aje/kwj003; Haight T, 2005, AM J EPIDEMIOL, V162, P607, DOI 10.1093/aje/kwi254; Halfon N, 2002, MILBANK Q, V80, P433, DOI 10.1111/1468-0009.00019; Jones CP, 2001, AM J EPIDEMIOL, V154, P299, DOI 10.1093/aje/154.4.299; Kaufman JS, 2001, AM J EPIDEMIOL, V154, P305, DOI 10.1093/aje/154.4.305; Kaufman JS, 2004, EPIDEMIOL PERSPECT I, V1, P4, DOI DOI 10.1186/1742-5573-1-4; Kaufman JS, 1997, EPIDEMIOLOGY, V8, P621, DOI 10.1097/00001648-199710000-00002; Kaufman JS, 2001, EPIDEMIOLOGY, V12, P157, DOI 10.1097/00001648-200103000-00006; Krieger N, 2001, INT J EPIDEMIOL, V30, P668, DOI 10.1093/ije/30.4.668; Kuh D., 2004, LIFE COURSE APPROACH; Palloni A, 2001, ANN NY ACAD SCI, V954, P140; Philippe P, 1998, THEOR MED BIOETH, V19, P591, DOI 10.1023/A:1009979306346; Phillips CV, 2003, EPIDEMIOLOGY, V14, P459, DOI 10.1097/01.ede.0000072106.65262.ae; Robins JM, 2000, EPIDEMIOLOGY, V11, P550, DOI 10.1097/00001648-200009000-00011; SINGER B, 2001, NEW HORIZONS HLTH IN; Smedley BD, 2001, PROMOTING HLTH INTER; Sternfeld B, 2002, AM J EPIDEMIOL, V156, P110, DOI 10.1093/aje/kwf023; Syme S Leonard, 2004, Prev Chronic Dis, V1, pA02; Tager IB, 2004, EPIDEMIOLOGY, V15, P479, DOI 10.1097/01.ede.0000128401.55545.c6; WACHTER KW, 2001, CELLS SURVEYS SHOULD; Wang C, 2005, AM J EPIDEMIOL, V161, pS76; Wang C, 2005, AM J EPIDEMIOL, V161, pS89; Zhang H, 1999, RECURSIVE PARTITIONI	25	6	6	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	0002-9262			AM J EPIDEMIOL	Am. J. Epidemiol.	JUL 15	2006	164	2					122	125		10.1093/aje/kwj194		4	Public, Environmental & Occupational Health	Public, Environmental & Occupational Health	059UY	WOS:000238758900003	16751259	
J	Li, F; Runger, GC; Tuv, E				Li, F; Runger, GC; Tuv, E			Supervised learning for change-point detection	INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH			English	Article						change point; decision tree; statistical process control; randomforest; out-of-bag; variable importance	MAXIMUM-LIKELIHOOD-ESTIMATION; RANDOM-VARIABLES; INFERENCE; TESTS	The detection of changes in the distribution of process variables is referred to as the change-point problem. Existing methods focus on detecting a single (or few) change point in a univariate (or low-dimensional) process. We consider the important high-dimensional multivariate case with multiple change points and without an assumed distribution. In this work the problem is transformed into a supervised learning problem with time as the output response and the process variables as inputs. Our focus is to identify the subset of variables that change. This important, practical scenario is analysed through a supervised learner with a variable importance measure that is used to identify the variables that change among hundreds of variables. Simulated cases are discussed in the paper to verify the proposed method. Moreover, the same data sets are compared with a multivariate exponentially weighted moving average control chart and the advantages of the supervised learner are illustrated.	Arizona State Univ, Dept Ind Engn, Tempe, AZ 85287 USA; Intel Inc, Chandler, AZ USA	Li, F (reprint author), Arizona State Univ, Dept Ind Engn, Tempe, AZ 85287 USA.	fang.li@asu.edu					Belisle P, 1998, BIOMETRICS, V54, P113, DOI 10.2307/2534000; BHATTACHARYA PK, 1987, J MULTIVARIATE ANAL, V23, P183, DOI 10.1016/0047-259X(87)90152-7; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARLSTEIN E, 1988, ANN STAT, V16, P188, DOI 10.1214/aos/1176350699; CSORGO M, 1987, J STAT PLAN INFER, V17, P1, DOI 10.1016/0378-3758(87)90097-8; Davison AC, 1997, BOOTSTRAP METHODS TH; FU YX, 1990, BIOMETRIKA, V77, P563, DOI 10.1093/biomet/77.3.563; HINKLEY DV, 1971, BIOMETRIKA, V58, P509, DOI 10.2307/2334386; HINKLEY DV, 1970, BIOMETRIKA, V57, P1; Hotelling H. H., 1947, TECHNIQUES STAT ANAL; HWANG W, 2004, IN PRESS I IND ENG T; LAVIELLE M, 1993, IEEE T SIGNAL PROCES, V41, P742, DOI 10.1109/78.193214; Lee CB, 1996, STAT PROBABIL LETT, V27, P295, DOI 10.1016/0167-7152(95)00089-5; LOWRY CA, 1992, TECHNOMETRICS, V34, P46, DOI 10.2307/1269551; Pievatolo A, 2000, J ROY STAT SOC C-APP, V49, P543, DOI 10.1111/1467-9876.00211; Runger GC, 2004, QUAL RELIAB ENG INT, V20, P587, DOI 10.1002/qre.571; Taylor AR, 2003, INT J ADAPT CONTROL, V17, P363, DOI 10.1002/acs.753; TUV E, 2005, FEATURE SELECTION US; Xiong YM, 2004, PATTERN RECOGN, V37, P1675, DOI 10.1016/j.patcog.2003.12.018	20	13	13	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0020-7543			INT J PROD RES	Int. J. Prod. Res.	JUL 15	2006	44	14					2853	2868		10.1080/00207540600669846		16	Engineering, Industrial; Engineering, Manufacturing; Operations Research & Management Science	Engineering; Operations Research & Management Science	056DY	WOS:000238502700010		
J	Hothorn, T; Buhlmann, P; Dudoit, S; Molinaro, A; Van der Laan, MJ				Hothorn, Torsten; Buehlmann, Peter; Dudoit, Sandrine; Molinaro, Annette; Van der Laan, Mark J.			Survival ensembles	BIOSTATISTICS			English	Article						censoring; cross-validation; ensemble methods; IPC weights; loss function; prediction; prognostic factors; survival analysis	RIGHT-CENSORED DATA; REGRESSION-MODELS; CLASSIFICATION; MICROARRAYS; PREDICTORS; ACCURACY; SPLINES; TREE	We propose a unified and flexible framework for ensemble learning in the presence of censoring. For right-censored data, we introduce a random forest algorithm and a generic gradient boosting algorithm for the construction of prognostic and diagnostic models. The methodology is utilized for predicting the survival time of patients suffering from acute myeloid leukemia based on clinical and genetic covariates. Furthermore, we compare the diagnostic capabilities of the proposed censored data random forest and boosting methods, applied to the recurrence-free survival time of node-positive breast cancer patients, with previously published findings.	Univ Erlangen Nurnberg, Inst Med Informat Biometrie & Epidemiol, D-91054 Erlangen, Germany; ETH, Seminar Stat, CH-8032 Zurich, Switzerland; Univ Calif Berkeley, Div Biostat, Berkeley, CA 94720 USA; Yale Univ, Sch Med, Div Biostat Epidemiol & Publ Hlth, New Haven, CT 06520 USA	Hothorn, T (reprint author), Univ Erlangen Nurnberg, Inst Med Informat Biometrie & Epidemiol, Waldstr 6, D-91054 Erlangen, Germany.	Torsten.Hothorn@rzmail.uni-erlangen.de	Hothorn, Torsten/A-3639-2010; Buhlmann, Peter/A-2107-2013	Hothorn, Torsten/0000-0001-8301-0471; 			Altman DG, 2000, STAT MED, V19, P453, DOI 10.1002/(SICI)1097-0258(20000229)19:4<453::AID-SIM350>3.3.CO;2-X; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; Bedrick EJ, 2002, BIOSTATISTICS, V3, P331, DOI 10.1093/biostatistics/3.3.331; BENNER A, 2002, P COMP STAT COMPSTAT; Breiman L., 2002, USE SURVIVAL FORESTS; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bryan J, 2004, BIOSTATISTICS, V5, P361, DOI 10.1093/biostatistics/kxg041; BUCKLEY J, 1979, BIOMETRIKA, V66, P429; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; BUHLMANN P, 2006, IN PRESS ANN STAT, V34; Buhlmann P, 2004, HANDBOOK OF COMPUTATIONAL STATISTICS: CONCEPTS AND METHODS, P877; Bullinger L, 2004, NEW ENGL J MED, V350, P1605, DOI 10.1056/NEJMoa031046; COX DR, 1972, J R STAT SOC B, V34, P187; Dudoit S, 2005, STAT METHODOL, V2, P131, DOI 10.1016/j.stamet.2005.02.003; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Garczarek U, 2003, COMPUTATION STAT, V18, P143; Graf E, 1999, STAT MED, V18, P2529; GRAY RJ, 1992, J AM STAT ASSOC, V87, P942, DOI 10.2307/2290630; HASTIE T, 2004, PAMR PREDICTION ANAL; Hastie T, 2004, BIOSTATISTICS, V5, P329, DOI 10.1093/biostatistics/kxh010; Henderson R, 2001, STAT MED, V20, P3083, DOI 10.1002/sim.913; HENDERSON R, 1995, STAT MED, V14, P161, DOI 10.1002/sim.4780140208; Hollander M., 1999, NONPARAMETRIC STAT I; HOTHORN T, 2005, PARTY LAB RECURSIVE; Hothorn T, 2004, STAT MED, V23, P77, DOI 10.1002/sim.1593; Hothorn T, 2005, J COMPUT GRAPH STAT, V14, P675, DOI 10.1198/106186005X59630; Huang J, 2005, BIOMETRICS, V61, P17, DOI 10.1111/j.0006-341X.2005.040304.x; Ishwaran H, 2004, J AM STAT ASSOC, V99, P591, DOI 10.1198/016214504000000638; JAMES I, 1998, ENCY BIOSTATISTICS, P26; Keles S, 2004, BERNOULLI, V10, P1011, DOI 10.3150/bj/1106314848; KOOPERBERG C, 1995, J AM STAT ASSOC, V90, P78, DOI 10.2307/2291132; LeBlanc M, 1999, BIOMETRICS, V55, P204, DOI 10.1111/j.0006-341X.1999.00204.x; Li LX, 2004, BIOINFORMATICS, V20, P3406, DOI 10.1093/bioinformatics/bth415; Molinaro AM, 2004, J MULTIVARIATE ANAL, V90, P154, DOI 10.1016/j.jmva.2004.02.003; Nason M, 2004, J COMPUT GRAPH STAT, V13, P807, DOI 10.1198/106186004X11417; Orbe J, 2003, BIOSTATISTICS, V4, P109, DOI 10.1093/biostatistics/4.1.109; Peters A., 2002, R NEWS, V2, P33; R Development Core Team, 2004, R LANG ENV STAT COMP; Ridgeway G, 1999, COMPUTING SCI STAT, V31, P172; Ripley RM, 2004, STAT MED, V23, P825, DOI 10.1002/sim.1655; Sauerbrei W, 1999, J ROY STAT SOC C-APP, V48, P313, DOI 10.1111/1467-9876.00155; Sauerbrei W, 1999, J ROY STAT SOC A STA, V162, P71, DOI 10.1111/1467-985X.00122; Schemper M, 2003, STAT MED, V22, P2299, DOI 10.1002/sim.1486; SCHUMACHER M, 1994, J CLIN ONCOL, V12, P2086; Sinisi S.E., 2004, STAT APPL GENET MOL, V3, P1, DOI DOI 10.2202/1544-; Stute W, 1999, STAT SINICA, V9, P1089; Therneau T, 1997, 61 MAYO CLIN SECT BI; Therneau TM, 2000, MODELING SURVIVAL DA; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; van der Laan MJ, 2003, UNIFIED METHODS CENS; VANDERLAAN MJ, 2004, 142 U CAL DIV BIOST; VANDERLAAN MJ, 2003, 130 U CAL DIV BIOST	55	89	91	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1465-4644			BIOSTATISTICS	Biostatistics	JUL	2006	7	3					355	373		10.1093/biostatistics/kxj011		19	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	056PG	WOS:000238537000002	16344280	
J	Schwartz, MW; Iverson, LR; Prasad, AM; Matthews, SN; O'Connor, RJ				Schwartz, Mark W.; Iverson, Louis R.; Prasad, Anantha M.; Matthews, Stephen N.; O'Connor, Raymond J.			Predicting extinctions as a result of climate change	ECOLOGY			English	Article						climate and environmental models; climate change; distribution breadth; eastern United States; endemic; extinction; prediction uncertainty; regression tree; vulnerability	BIODIVERSITY; CONSERVATION; SCENARIOS; RESPONSES; ENVELOPE; TREE	Widespread extinction is a predicted ecological consequence of global warming. Extinction risk under climate change scenarios is a function of distribution breadth. Focusing on trees and birds of the eastern United States, we used joint climate and environment models to examine fit and climate change vulnerability as a function of distribution breadth. We found that extinction vulnerability increases with decreasing distribution size. We also found that model fit decreases with decreasing distribution size, resulting in high prediction uncertainty among narrowly distributed species. High prediction uncertainty creates a conservation dilemma in that excluding these species under-predicts extinction risk and favors mistaken inaction on global warming. By contrast, including narrow endemics results in over-predicting extinction risk and promotes mistaken inaction on behalf of individual species prematurely considered doomed to extinction.	Univ Calif Davis, Dept Environm Sci & Policy, Davis, CA 95616 USA; USDA Forest Serv, NE Res Stn, Delaware, OH 43015 USA; Ohio State Univ, Sch Nat Resources, Columbus, OH 43210 USA; Univ Maine, Dept Wildlife Ecol, Orono, ME 04469 USA	Schwartz, MW (reprint author), Univ Calif Davis, Dept Environm Sci & Policy, Davis, CA 95616 USA.	mwschwartz@ucdavis.edu	Schwartz, Mark/G-1066-2011; Matthews, Stephen/D-1050-2012; Iverson, Louis/C-7554-2009	Iverson, Louis/0000-0001-9501-471X			Berry PM, 2002, GLOBAL ECOL BIOGEOGR, V11, P453, DOI 10.1046/j.1466-822x.2002.00304.x; Boer GJ, 2000, CLIM DYNAM, V16, P427, DOI 10.1007/s003820050338; Box EO, 1999, CLIMATIC CHANGE, V41, P213, DOI 10.1023/A:1005483507351; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bush MB, 2002, GLOBAL ECOL BIOGEOGR, V11, P463, DOI 10.1046/j.1466-822X.2002.00305.x; CLARK L. A., 1992, STAT MODELS S, P377; Davis AJ, 1998, NATURE, V391, P783, DOI 10.1038/35842; Guisan A, 2005, ECOL LETT, V8, P993, DOI 10.1111/j.1461-0248.2005.00792.x; Hannah L, 2002, GLOBAL ECOL BIOGEOGR, V11, P485, DOI 10.1046/j.1466-822X.2002.00306.x; Herkert JR, 2003, CONSERV BIOL, V17, P587, DOI 10.1046/j.1523-1739.2003.01418.x; Iverson L.R., 1999, ATLAS CURRENT POTENT; Malanson GP, 1997, J VEG SCI, V8, P307, DOI 10.2307/3237360; MATTHEWS SN, 2004, ATLAS CLIMATE CHANGE; Midgley GF, 2002, GLOBAL ECOL BIOGEOGR, V11, P445, DOI 10.1046/j.1466-822X.2002.00307.x; Millenium Ecosystem Assessment, 2005, MILL EC ASS; MITCHELL JFB, 1995, NATURE, V376, P501, DOI 10.1038/376501a0; O'Connor Raymond J., 1999, Studies in Avian Biology, V19, P45; Pearson RG, 2002, ECOL MODEL, V154, P289, DOI 10.1016/S0304-3800(02)00056-X; Peterson AT, 2002, NATURE, V416, P626, DOI 10.1038/416626a; Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1; Sala OE, 2000, SCIENCE, V287, P1770, DOI 10.1126/science.287.5459.1770; Schwartz MW, 1999, ANNU REV ECOL SYST, V30, P83, DOI 10.1146/annurev.ecolsys.30.1.83; SCHWARTZ MW, 1992, FOREST CHRON, V68, P462; Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121; THUILLER W, 2004, NATURE, V430, DOI DOI 10.1038/nature02716; Weekley CW, 2003, J TORREY BOT SOC, V130, P265, DOI 10.2307/3557545	26	105	111	ECOLOGICAL SOC AMER	WASHINGTON	1990 M STREET NW, STE 700, WASHINGTON, DC 20036 USA	0012-9658			ECOLOGY	Ecology	JUL	2006	87	7					1611	1615		10.1890/0012-9658(2006)87[1611:PEAARO]2.0.CO;2		5	Ecology	Environmental Sciences & Ecology	069OK	WOS:000239457900001	16922312	
J	Pappenberger, F; Iorgulescu, I; Beven, KJ				Pappenberger, F; Iorgulescu, I; Beven, KJ			Sensitivity analysis based on regional splits and regression trees (SARS-RT)	ENVIRONMENTAL MODELLING & SOFTWARE			English	Article						regression tree; sensitivity analysis; Random Forests; uncertainty analysis; calibration; generalized likelihood uncertainty estimation; regional sensitivity analysis	RAINFALL-RUNOFF MODELS; ENVIRONMENTAL-MODELS; DECISION TREES; PARAMETER UNCERTAINTY; GLOBAL OPTIMIZATION; HYDROLOGIC-MODELS; CALIBRATION; SYSTEMS; EUTROPHICATION; INUNDATION	A global sensitivity analysis with regional properties is introduced. This method is demonstrated on two synthetic and one hydraulic example. It can be shown that an uncertainty analysis based on one-dimensional scatter plots and correlation analyses such as the Spearman Rank Correlation coefficient can lead to misinterpretations of any model results. The method which has been proposed in this paper is based on multiple regression trees (so called Random Forests). The splits at each node of the regression tree are sampled from a probability distribution. Several criteria are enforced at each level of splitting to ensure positive information gain and also to distinguish between behavioural and non-behavioural model representations. The latter distinction is applied in the generalized likelihood uncertainty estimation (GLUE) and regional sensitivity analysis (RSA) framework to analyse model results and is used here to derive regression tree (model) structures. Two methods of sensitivity analysis are used: in the first method the total information gain achieved by each parameter is evaluated. In the second method parameters and parameter sets are permuted and an error rate computed. This error rate is compared to values without permutation. This latter method allows the evaluation of the sensitivity of parameter combinations and thus gives an insight into the structure of the response surface. The examples demonstrate the capability of this methodology and stress the importance of the application of sensitivity analysis. (C) 2005 Elsevier Ltd. All rights reserved.	Univ Lancaster, Lancaster LA1 4YQ, England; Ecole Polytech Fed Lausanne, Lausanne, Switzerland	Pappenberger, F (reprint author), Univ Lancaster, Lancaster LA1 4YQ, England.	f.pappenberger@lancaster.ac.uk	Beven, Keith/F-8707-2011; Pappenberger, Florian/A-2839-2009	Pappenberger, Florian/0000-0003-1766-2898			Babendreier JE, 2005, ENVIRON MODELL SOFTW, V20, P1043, DOI 10.1016/j.envsoft.2004.09.013; Beven K, 2003, J HYDRAUL RES, V41, P331; BEVEN K, 1992, HYDROL PROCESS, V6, P279, DOI 10.1002/hyp.3360060305; Beven K, 2002, HYDROL PROCESS, V16, P189, DOI 10.1002/hyp.343; BEVEN K, 2001, J HYDRAUL RES, V39, P339; BEVEN K, IN PRESS J HYDROLOGY; Beven K. J., 2001, RAINFALL RUNOFF MODE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2004, RANDOM FORESTS; CHAN K, 1997, WINT SIM C; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Doherty J, 2002, PEST MODEL INDEPENDE; DUAN QY, 1992, WATER RESOUR RES, V28, P1015, DOI 10.1029/91WR02985; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; Georgakakos KP, 2001, J HYDROL, V249, P1, DOI 10.1016/S0022-1694(01)00455-3; Grieb TM, 1999, ENVIRON INT, V25, P787, DOI 10.1016/S0160-4120(99)00054-9; Gupta HV, 1998, WATER RESOUR RES, V34, P751, DOI 10.1029/97WR03495; HALL JW, 2005, ASCE J HYDRAULIC ENG, V131, P117; Han D, 2002, WATER RESOUR MANAG, V16, P431, DOI 10.1023/A:1022251422280; Helton JC, 2003, RELIAB ENG SYST SAFE, V81, P23, DOI 10.1016/S0951-8320(03)00058-9; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; Hofer E, 1999, COMPUT PHYS COMMUN, V117, P21, DOI 10.1016/S0010-4655(98)00153-2; HORNBERGER GM, 1981, J ENVIRON MANAGE, V12, P7; Horritt MS, 2002, J HYDROL, V268, P87, DOI 10.1016/S0022-1694(02)00121-X; IORGULESCU I, 2004, WATER RESOURCE RES, V40; Jolma A, 2005, ENVIRON MODELL SOFTW, V20, P979, DOI 10.1016/j.envsoft.2004.10.004; KARALIC A, 1991, P ITI 91 CAVT CROAT; KAVETSKI DN, 2003, ADV CALIBRATION WATE, P49; Krzysztofowicz R, 2002, J HYDROL, V268, P16, DOI 10.1016/S0022-1694(02)00106-3; Krzysztofowicz R, 2001, J HYDROL, V249, P46, DOI 10.1016/S0022-1694(01)00412-7; Krzysztofowicz R, 2001, J HYDROL, V249, P2, DOI 10.1016/S0022-1694(01)00420-6; Krzysztofowicz R, 2002, J HYDROL, V268, P41, DOI 10.1016/S0022-1694(02)00107-5; Kuczera G, 1998, J HYDROL, V211, P69, DOI 10.1016/S0022-1694(98)00198-X; MATGEN P, 2004, 20 ISPRS C INT SOC P; MCCUEN RH, 1973, WATER RESOUR RES, V9, P243, DOI 10.1029/WR009i001p00243; McCuen RH, 1973, J HYDROL, V18, P37, DOI 10.1016/0022-1694(73)90024-3; Melching C. S., 1995, COMPUTER MODELS WATE, P69; MURTHY SK, 1995, THESIS J HOPKINS U B; Oakley JE, 2004, J ROY STAT SOC B, V66, P751, DOI 10.1111/j.1467-9868.2004.05304.x; Pallottino S, 2005, ENVIRON MODELL SOFTW, V20, P1031, DOI 10.1016/j.envsoft.2004.09.012; Pappenberger F, 2005, J HYDROL, V302, P46, DOI 10.1016/j.jhydrol.2004.06.036; PAPPENBERGER F, 2004, UNCERTAINTY FLOOD IN; PAPPENBERGER F, 2003, EGS 27 GEN ASS NIC F; PAPPENBERGER F, 2004, INFLUENCE RATING CUR; Pastres R, 2005, ENVIRON MODELL SOFTW, V20, P981, DOI 10.1016/j.envsoft.2004.09.010; Pastres R, 1999, COMPUT PHYS COMMUN, V117, P62, DOI 10.1016/S0010-4655(98)00164-7; Press W. H., 2002, NUMERICAL RECIPES C, V2nd; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Ratto M, 2001, COMPUT PHYS COMMUN, V136, P212, DOI 10.1016/S0010-4655(01)00159-X; RATTO M, IN PRESS IMPROVED AC; Reichert P, 2005, ENVIRON MODELL SOFTW, V20, P991, DOI 10.1016/j.envsoft.2004.10.005; Romanowicz R., 2003, WATER RESOURCES RES, V39; Saltelli A., 2004, SENSITIVITY ANAL PRA; Segal MR, 2004, MACHINE LEARNING BEN; SEIBERT J, 2003, ADV CALIBRATION WATE; Sobol I. M., 1993, MATH MODEL COMPUT EX, V1, P407, DOI DOI 10.2514/1.28511; SPEAR RC, 1994, WATER RESOUR RES, V30, P3159, DOI 10.1029/94WR01732; SPEAR RC, 1980, WATER RES, V14, P43, DOI 10.1016/0043-1354(80)90040-8; Su XG, 2004, J COMPUT GRAPH STAT, V13, P586, DOI 10.1198/106186004X2165; TARANTOLA A, 2004, SIMLAB SOFTWARE PACK; TORGO L, 1999, RELIABLE ERROR ESTIM; Torgo L, 1999, INDUCTIVE LEARNING T; Wagener T, 2003, HYDROL PROCESS, V17, P455, DOI 10.1002/hyp.1135; Wiles JJ, 2002, ENVIRON ENG GEOSCI, V8, P47; Yapo PO, 1998, J HYDROL, V204, P83, DOI 10.1016/S0022-1694(97)00107-8; Yapo PO, 1996, J HYDROL, V181, P23, DOI 10.1016/0022-1694(95)02918-4	72	30	30	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1364-8152			ENVIRON MODELL SOFTW	Environ. Modell. Softw.	JUL	2006	21	7					976	990		10.1016/j.envsoft.2005.04.010		15	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Sciences	Computer Science; Engineering; Environmental Sciences & Ecology	053NH	WOS:000238311300007		
J	Yu, WC; Li, XY; Liu, JF; Wu, BL; Williams, KR; Zhao, HY				Yu, Weichuan; Li, Xiaoye; Liu, Junfeng; Wu, Baolin; Williams, Kenneth R.; Zhao, Hongyu			Multiple peak alignment in sequential data analysis: A scale-space-based approach	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						biomarker discovery; peak identification; multiple peak alignment; scale-space; prior information; energy minimization; parameter optimization	MASS-SPECTROMETRY DATA; OVARIAN-CANCER IDENTIFICATION; TIME; CLASSIFICATION; SERUM; ALGORITHMS; PROFILES; SPECTRA	In this paper, we address the multiple peak alignment problem in sequential data analysis with an approach based on the Gaussian scale-space theory. We assume that multiple sets of detected peaks are the observed samples of a set of common peaks. We also assume that the locations of the observed peaks follow unimodal distributions (e.g., normal distribution) with their means equal to the corresponding locations of the common peaks and variances reflecting the extension of their variations. Under these assumptions, we convert the problem of estimating locations of the unknown number of common peaks from multiple sets of detected peaks into a much simpler problem of searching for local maxima in the scale-space representation. The optimization of the scale parameter is achieved using an energy minimization approach. We compare our approach with a hierarchical clustering method using both simulated data and real mass spectrometry data. We also demonstrate the merit of extending the binary peak detection method (i.e., a candidate is considered either as a peak or as a nonpeak) with a quantitative scoring measure- based approach (i.e., we assign to each candidate a possibility of being a peak).	Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China; Yale Univ, Dept Appl Math, New Haven, CT 06520 USA; W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA; Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA; Yale Univ, Keck Lab, New Haven, CT 06520 USA; Yale Univ, Dept Epidemiol & Publ Hlth, New Haven, CT 06520 USA	Yu, WC (reprint author), Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.	eeyu@ust.hk; xiaoye.li@yale.edu; jfliu@stat.wvu.edu; baolin@biostat.umn.edu; kenneth.williams@yale.edu; hongyu.zhao@yale.edu					Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Anantharaman TS, 1997, J COMPUT BIOL, V4, P91, DOI 10.1089/cmb.1997.4.91; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COOMBES KR, 2004, IMPROVED PEAK DETECT; Coombes KR, 2003, CLIN CHEM, V49, P1615, DOI 10.1373/49.10.1615; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Eilers PHC, 2004, ANAL CHEM, V76, P404, DOI 10.1021/ac034800e; Gryff-Keller A, 2004, MOL PHYS, V102, P1903, DOI 10.1080/00268970412331284226; Johnson KJ, 2003, J CHROMATOGR A, V996, P141, DOI 10.1016/S0021-9673(03)00616-2; LISTGARTEN J, 2004, ADV NEURAL INFORM PR, V17; Nielsen NPV, 1998, J CHROMATOGR A, V805, P17, DOI 10.1016/S0021-9673(98)00021-1; Nomura F, 2004, PROTEOMICS, V4, P1187, DOI 10.1002/pmic.200300674; Papadopoulos MC, 2004, LANCET, V363, P1358, DOI 10.1016/S0140-6736(04)16046-7; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; RANDOLPH TW, 2004, U WASHINGTON BIOSTAT, V230; Satten GA, 2004, BIOINFORMATICS, V20, P3128, DOI 10.1093/bioinformatics/bth372; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Torgrip RJO, 2003, J CHEMOMETR, V17, P573, DOI 10.1002/cem.824; Wadsworth JT, 2004, CLIN CANCER RES, V10, P1625, DOI 10.1158/1078-0432.CCR-0297-3; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Yu JS, 2005, BIOINFORMATICS, V21, pI487, DOI 10.1093/bioinformatics/bti1030; Yu JS, 2005, BIOINFORMATICS, V21, P2200, DOI 10.1093/bioinformatics/bti370; Yu WC, 2006, COMPUT BIOL CHEM, V30, P27, DOI 10.1016/j.compbiolchem.2005.10.006	28	12	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963			IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JUL-SEP	2006	3	3					208	219				12	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	068MM	WOS:000239378400002	17048459	
J	Baca-Garcia, E; Perez-Rodriguez, MM; Basurte-Villamor, I; Saiz-Ruiz, J; Leiva-Murillo, JM; de Prado-Cumplido, M; Santiago-Mozos, R; Artes-Rodriguez, A; de Leon, J				Baca-Garcia, Enrique; Perez-Rodriguez, M. Mercedes; Basurte-Villamor, Ignacio; Saiz-Ruiz, Jeronimo; Leiva-Murillo, Jose M.; de Prado-Cumplido, Mario; Santiago-Mozos, Ricardo; Artes-Rodriguez, Antonio; de Leon, Jose			Using data mining to explore complex clinical decisions: A study of hospitalization after a suicide attempt	JOURNAL OF CLINICAL PSYCHIATRY			English	Article							PREVENTION; CARE	Background: Medical education is moving toward developing guidelines using the evidence-based approach; however, controlled data are missing for answering complex treatment decisions such as those made during suicide attempts. A new set of statistical techniques called data mining (or machine learning) is being used by different industries to explore complex databases and can be used to explore large clinical databases. Method: The study goal was to reanalyze, using data mining techniques a published study, of which variables predicted psychiatrists' decisions to hospitalize in 509 suicide attempters over the age of 18 years who were assessed in the emergency department. Patients were recruited for the study between 1996 and 1998. Traditional multivariate statistics were compared with data mining techniques to determine variables predicting hospitalization. Results: Five analyses done by psychiatric researchers using traditional statistical techniques classified 72% to 88% of patients correctly. The model developed by researchers with no psychiatric knowledge and employing data mining techniques used 5 variables (drug consumption during the attempt, relief that the attempt was not effective, lack of family support, being a housewife, and family history of suicide attempts) and classified 99% of patients correctly (99% sensitivity and 100% specificity). Conclusions: This reanalysis of a published study fundamentally tries to make the point that these new multivariate techniques, called data mining, can be used to study large clinical databases in psychiatry. Data mining techniques may be used to explore important treatment questions and outcomes in large clinical databases and to help develop guidelines for problems where controlled data are difficult to obtain. New opportunities for good clinical research may be developed by using data mining analyses.	Eastern State Hosp, UK Mental Hlth Res Ctr, Lexington, KY 40508 USA; Univ Autonoma Madrid, Dept Psychiat, Fdn Jimenez Diaz, Madrid, Spain; Univ Alcala de Henares, Hosp Ramon y Cajal, Alcala De Henares, Spain; Univ Carlos III Madrid, Dept Signal Theory & Commun, Madrid, Spain	de Leon, J (reprint author), Eastern State Hosp, UK Mental Hlth Res Ctr, 627 W 4th St, Lexington, KY 40508 USA.	jdeleon@uky.edu	de Leon, Jose/F-2709-2013; Santiago-Mozos, Ricardo/M-2572-2014; Perez Rodriguez, Maria/B-9410-2013; Baca-Garcia, Enrique/F-4106-2015; LEIVA MURILLO, JOSE MIGUEL/	de Leon, Jose/0000-0002-7756-2314; Santiago-Mozos, Ricardo/0000-0003-4641-6389; Perez Rodriguez, Maria/0000-0001-5137-1993; Baca-Garcia, Enrique/0000-0002-6963-6555; LEIVA MURILLO, JOSE MIGUEL/0000-0002-3270-9378			American Psychiatric Association (2003), 2003, AM J PSYCHIAT S, V160, P1; Baca-Garcia R, 2004, PSYCHIAT SERV, V55, P792; Beck AT, 1974, PREDICTION SUICIDE, P45; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Choudhry NK, 2005, ANN INTERN MED, V142, P260; Fukunaga F., 1990, INTRO STAT PATTERN R; Gliatto MF, 1999, AM FAM PHYSICIAN, V59, P1500; Goodwin L, 2003, J BIOMED INFORM, V36, P379, DOI 10.1016/j.jbi.2003.09.020; GUNNELL D, 1994, BRIT MED J, V308, P1227; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hamilton NG, 2000, POSTGRAD MED, V108, P81; Hand DJ, 2000, STAT METHODS MED RES, V9, P305, DOI 10.1191/096228000701555172; Hider P., 1998, YOUTH SUICIDE PREVEN; HIRSCHFELD RMA, 1996, PRIM PSYCHIAT, V3, P26; HIRSCHFELD RMA, 1998, HOSP PRACT, V33, P131; Hirschfeld RMA, 1997, NEW ENGL J MED, V337, P910, DOI 10.1056/NEJM199709253371307; HIRSCHFELD RMA, 1998, HOSP PRACT, V33, P127; Hirschfeld RMA, 1998, HOSP PRACT, V33, P119; Hosmer D.W., 2000, APPL LOGISTIC REGRES; Isacsson G, 2001, BRIT MED J, V322, P213, DOI 10.1136/bmj.322.7280.213; KACHUR SP, 1996, GUIDE CLIN PREVENTIV; KIRSTEIN L, 1975, AM J PSYCHIAT, V132, P22; *MAG BEH HTLH CLIN, 2000, CLIN PRACT GUID ASS; MCNAMEE JE, 1996, CANADIAN TASK FORCE; MCNamee JE, 1994, CANADIAN GUIDE CLIN, P456; NHS, 1998, EFFECTIVE HLTH CARE, V4, P1; Nicholas L M, 2001, Clin Cornerstone, V3, P47, DOI 10.1016/S1098-3597(01)90061-4; OCarroll PW, 1996, SUICIDE LIFE-THREAT, V26, P237; Oosterhuis WP, 2004, CLIN CHEM, V50, P806, DOI 10.1373/clinchem.2003.025528; Rihmer Z, 2002, CURR OPIN PSYCHIATR, V15, P83, DOI 10.1097/00001504-200201000-00014; *ROYAL COLL PSYCH, 1992, GEN HOSP MAN AD DEL; *ROYAL NZ COLL GEN, 1998, GUID PRIM CAR PROV D; Shaffer D, 2001, J AM ACAD CHILD PSY, V40, p24S; Smyth P, 2000, STAT METHODS MED RES, V9, P309, DOI 10.1191/096228000701555181; *SUIC RISK ADV COM, 1996, GUID ID ASS TREATM P; Tukey J., 1977, EXPLORATORY DATA ANA; Vapnik V., 1998, STAT LEARNING THEORY; World Health Organization, 2000, MENT BEH DIS; 2000, NAT BIOTECHNOL S, V18, pIT35	39	21	21	PHYSICIANS POSTGRADUATE PRESS	MEMPHIS	P O BOX 240008, MEMPHIS, TN 38124 USA	0160-6689			J CLIN PSYCHIAT	J. Clin. Psychiatry	JUL	2006	67	7					1124	1132				9	Psychology, Clinical; Psychiatry	Psychology; Psychiatry	070TU	WOS:000239548300016	16889457	
J	Zhang, Y; Burer, S; Street, WN				Zhang, Yi; Burer, Samuel; Street, W. Nick			Ensemble pruning via semi-definite programming	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						ensemble pruning; semi-definite programming; heuristics; knowledge sharing	APPROXIMATION ALGORITHMS; CLASSIFIERS	An ensemble is a group of learning models that jointly solve a problem. However, the ensembles generated by existing techniques are sometimes unnecessarily large, which can lead to extra memory usage, computational costs, and occasional decreases in effectiveness. The purpose of ensemble pruning is to search for a good subset of ensemble members that performs as well as, or better than, the original ensemble. This subset selection problem is a combinatorial optimization problem and thus finding the exact optimal solution is computationally prohibitive. Various heuristic methods have been developed to obtain an approximate solution. However, most of the existing heuristics use simple greedy search as the optimization method, which lacks either theoretical or empirical quality guarantees. In this paper, the ensemble subset selection problem is formulated as a quadratic integer programming problem. By applying semi-definite programming (SDP) as a solution technique, we are able to get better approximate solutions. Computational experiments show that this SDP-based pruning algorithm outperforms other heuristics in the literature. Its application in a classifier-sharing study also demonstrates the effectiveness of the method.	Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA	Zhang, Y (reprint author), Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA.	yi-zhang-2@uiowa.edu; samuel-burer@uiowa.edu; nick-street@uiowa.edu					Bennett KP, 2000, P 17 INT C MACH LEAR, P65; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burer S, 2003, MATH PROGRAM, V95, P329, DOI 10.1007/s10107-002-0352-8; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Caruana R., 2004, P 21 INT C MACH LEAR, P18; Chan PK, 1999, IEEE INTELL SYST APP, V14, P67, DOI 10.1109/5254.809570; Chawla NV, 2004, J MACH LEARN RES, V5, P421; d'Aspremont A., 2004, ADV NEURAL INFORM PR, V17; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; FAN W, 2004, P 9 INT C EXT DAT TE, P801; Feige U, 2001, J ALGORITHM, V41, P174, DOI 10.1006/jagm.2001.1183; Fleiss J.L., 1981, STAT METHODS RATES P; Freund Y., 1996, INT C MACH LEARN, P148; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Grove A., 1998, AAAI IAAI, P692; HAN Q, 2002, MATH PROGRAM, P509; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kim Y, 2002, IEEE IJCNN, P2791; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; MARGINEANTU D.D., 1997, 14 INT C MACH LEARN, P211; Mason L, 1999, ADV NEUR IN, V11, P288; McCallum A., 1999, AAAI 99 WORKSH TEXT; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Perrone M. P., 1993, NEURAL NETWORKS SPEE, P126; Prodromidis A., 1998, P 1 NAT C NEW INF TE, P151; Prodromidis A., 2000, ADV DISTRIBUTED DATA; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Rose AK, 2002, J MONEY CREDIT BANK, V34, P1067, DOI 10.1353/mcb.2002.0058; SHEN X, 2004, INT S EL IM SAN JOS; Street W., 2001, 7 ACM SIGKDD INT C K, P377; Wang H., 2003, MINING CONCEPT DRIFT; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019; Zhou Z. H., 2001, 17 INT JOINT C ART I, P797	41	79	84	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2006	7						1315	1338				24	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152UZ	WOS:000245388800007		
J	Montaner, D; Tarraga, J; Huerta-Cepas, J; Burguet, J; Vaquerizas, JM; Conde, L; Minguez, P; Vera, J; Mukherjee, S; Valls, J; Pujana, MAG; Alloza, E; Herrero, J; Al-Shahrour, F; Dopazo, J				Montaner, David; Tarraga, Joaquin; Huerta-Cepas, Jaime; Burguet, Jordi; Vaquerizas, Juan M.; Conde, Lucia; Minguez, Pablo; Vera, Javier; Mukherjee, Sach; Valls, Joan; Pujana, Miguel A. G.; Alloza, Eva; Herrero, Javier; Al-Shahrour, Fatima; Dopazo, Joaquin			Next station in microarray data analysis: GEPAS	NUCLEIC ACIDS RESEARCH			English	Article							GENE-EXPRESSION DATA; GROWING NEURAL-NETWORK; FALSE DISCOVERY RATE; CLUSTER-ANALYSIS; PATTERNS; GENOME; CLASSIFICATION; INFORMATION; DIAGNOSIS; FRAMEWORK	The Gene Expression Profile Analysis Suite ( GEPAS) has been running for more than four years. During this time it has evolved to keep pace with the new interests and trends in the still changing world of microarray data analysis. GEPAS has been designed to provide an intuitive although powerful web- based interface that offers diverse analysis options from the early step of preprocessing ( normalization of Affymetrix and two- colour microarray experiments and other preprocessing options), to the final step of the functional annotation of the experiment ( using Gene Ontology, pathways, PubMed abstracts etc.), and include different possibilities for clustering, gene selection, class prediction and arraycomparative genomic hybridization management. GEPAS is extensively used by researchers of many countries and its records indicate an average usage rate of 400 experiments per day. The web- based pipeline for microarray gene expression data, GEPAS, is available at http://www.gepas.org.	CIPF, Bioinformat Dept, E-46013 Valencia, Spain; CIPF, INB, Funct Genom Node, E-46013 Valencia, Spain; INB, BSC, E-08034 Barcelona, Spain; Univ Oxford, Dept Engn Sci, Pattern Anal & Machine Learning Grp, Oxford OX1 2JD, England; EMBL, EBI, Ensembl Team, Hinxton, Cambs, England; Hosp Barcelona, Inst Invest Biomed Bellvitge, Translat Res Lab, Catalan Inst Oncol, Barcelona 08907, Spain	Dopazo, J (reprint author), CIPF, Bioinformat Dept, Autopista Del Saler 16, E-46013 Valencia, Spain.	jdopazo@cipf.es	Vaquerizas, Juan/F-2676-2011; Vaquerizas, Juan M/; Conde, Lucia/D-9295-2011; Herrero, Javier/; Montaner, David/A-9362-2014; Minguez, Pablo/D-4822-2013; Huerta-Cepas, Jaime/H-5093-2013; Dopazo, Joaquin/A-9270-2014; pujana, Miguel Angel/N-3127-2014	Vaquerizas, Juan M/0000-0002-6583-6541; Herrero, Javier/0000-0001-7313-717X; Montaner, David/0000-0002-2484-3278; Minguez, Pablo/0000-0003-4099-9421; Dopazo, Joaquin/0000-0003-3318-120X; pujana, Miguel Angel/0000-0003-3222-4044			ALBERTSON DG, 2003, HUM MOL GENET, V12, P145; ALSHAHROUR AL, IN PRESS NUCL ACIDS; Al-Shahrour F, 2005, BIOINFORMATICS, V21, P2988, DOI 10.1093/bioinformatics/bti457; Al-Shahrour F, 2005, DATA ANALYSIS AND VISUALIZATION IN GENOMICS AND PROTEOMICS, P99, DOI 10.1002/0470094419.ch7; Al-Shahrour F, 2005, NUCLEIC ACIDS RES, V33, pW460, DOI 10.1093/nar/gki456; Al-Shahrour F, 2004, BIOINFORMATICS, V20, P578, DOI 10.1093/bioinformatics/btg455; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Azuaje F, 2002, BIOINFORMATICS, V18, P319, DOI 10.1093/bioinformatics/18.2.319; Baldi P, 2001, BIOINFORMATICS, V17, P509, DOI 10.1093/bioinformatics/17.6.509; Bammler T, 2005, NAT METHODS, V2, P351; Benjamini Y, 2001, ANN STAT, V29, P1165; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Caron H, 2001, SCIENCE, V291, P1289, DOI 10.1126/science.1056794; CONDE L, 2004, NUCLEIC ACIDS RES, V32, pE242; Conde L, 2005, NUCLEIC ACIDS RES, V33, pW501, DOI 10.1093/nar/gki476; CONDE L, 2006, IN PRESS NUCL ACIDS; CONE L, 2005, NUCLEIC ACIDS RES, V33, pW501; Cui XQ, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-4-210; Dopazo J, 1997, J MOL EVOL, V44, P226, DOI 10.1007/PL00006139; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Gautier L, 2004, BIOINFORMATICS, V20, P307, DOI 10.1093/bioinformatics/btg405; Ge H, 2003, TRENDS GENET, V19, P551, DOI 10.1016/j.tig.2003.08.009; Gentleman RC, 2004, GENOME BIOL, V5, P80; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; HERRERO J, 2004, NUCLEIC ACIDS RES, V32, pE485; Herrero J, 2003, NUCLEIC ACIDS RES, V31, P3461, DOI 10.1093/nar/gkg591; Herrero J, 2003, BIOINFORMATICS, V19, P655, DOI 10.1093/bioinformatics/btg040; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; Herrero J, 2002, J PROTEOME RES, V1, P467, DOI 10.1021/pr025521v; HOLM S, 1979, SCAND J STAT, V6, P65; Kendziorski CM, 2003, STAT MED, V22, P3899, DOI 10.1002/sim.1548; Khatri P, 2005, BIOINFORMATICS, V21, P3587, DOI 10.1093/bioinformatics/bti565; Klein J. P., 2003, SURVIVAL ANAL TECHNI, V2nd; KOHONEN T, 1997, SELFORGANIZING MAPS; Mantripragada KK, 2004, TRENDS GENET, V20, P87, DOI 10.1016/j.tig.2003.12.008; Moreau Y, 2003, TRENDS GENET, V19, P570, DOI 10.1016/j.tig.2003.08.006; Mukherjee S, 2005, BIOINFORMATICS, V21, P108, DOI 10.1093/bioinformatics/bti1119; Perou CM, 1999, P NATL ACAD SCI USA, V96, P9212, DOI 10.1073/pnas.96.16.9212; Ripley B. D., 1996, PATTERN RECOGNITION; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Simon R, 2003, J NATL CANCER I, V95, P14; Simon R, 2005, J CLIN ONCOL, V23, P7332, DOI 10.1200/JCO.2005.02.8712; Smyth Gordon K, 2003, Methods Mol Biol, V224, P111; SNEATH PHA, 1973, NUMERICL TAXONOMY; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V. N., 1995, STAT LEARNING THEORY; Vaquerizas JM, 2004, BIOINFORMATICS, V20, P3656, DOI 10.1093/bioinformatics/bth401; Vaquerizas JM, 2005, NUCLEIC ACIDS RES, V33, pW616, DOI 10.1093/nar/gki500; Wang DG, 1998, SCIENCE, V280, P1077, DOI 10.1126/science.280.5366.1077	56	72	74	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048			NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL 1	2006	34				SI		W486	W491		10.1093/nar/gkl197		6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	156LR	WOS:000245650200099	16845056	
J	Tutz, G; Leitenstorfer, F				Tutz, G; Leitenstorfer, F			Response shrinkage estimators in binary regression	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						logit model; response shrinkage estimator; shrinkage; ridge regression; LASSO; resistant fitting; data sharpening	GENERALIZED LINEAR-MODELS; LOGISTIC-REGRESSION; CLASSIFICATION; DIAGNOSTICS; ROBUSTNESS; SELECTION	A shrinkage type estimator is introduced which has favourable properties in binary regression. The proposed response shrinkage estimator is based on a smoothed version of the observed responses which is obtained by shifting the observation slightly towards the mean of the observations and therefore closer to the underlying probability. Estimates of this type are easily computed by using common program packages. They exist also in cases where the number of variables is large as compared to the number of observations. Comparison to alternative shrinkage methods like ridge regression and LASSO shows that response shrinkage performs rather well. Moreover, a combination of response shrinkage estimators and Pregibon's resistant fitting procedure is considered. The resulting estimate corrects for the overprediction of the resistant fitting in a very simple way. Estimators are compared in simulation studies and applications. (C) 2005 Elsevier B.V. All rights reserved.	Univ Munich, D-80799 Munich, Germany	Tutz, G (reprint author), Univ Munich, Akad Str 1, D-80799 Munich, Germany.	tutz@stat.uni-muenchen.de; leiten@stat.uni-muenchen.de					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; CARROLL RJ, 1993, J ROY STAT SOC B MET, V55, P693; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; Choi E, 1999, BIOMETRIKA, V86, P941, DOI 10.1093/biomet/86.4.941; Christmann A, 2001, COMPUT STAT DATA AN, V37, P65, DOI 10.1016/S0167-9473(00)00063-3; COPAS JB, 1988, J ROY STAT SOC B MET, V50, P225; FOWLKES EB, 1987, BIOMETRIKA, V74, P503, DOI 10.1093/biomet/74.3.503; Hampel F. R., 1986, ROBUST STAT APPROACH; Hurvich CM, 1998, J ROY STAT SOC B, V60, P271, DOI 10.1111/1467-9868.00125; Klinger A, 2001, J ROY STAT SOC B, V63, P377, DOI 10.1111/1467-9868.00291; KUNSCH HR, 1989, J AM STAT ASSOC, V84, P460, DOI 10.2307/2289930; LANDWEHR JM, 1984, J AM STAT ASSOC, V79, P61, DOI 10.2307/2288334; LECESSIE S, 1991, BIOMETRICS, V47, P1267, DOI 10.2307/2532385; Mallows C. L., 1975, SOME TOPICS ROBUSTNE; MARX BD, 1992, STAT MODEL, P227; MCMULLAGH P, 1989, GEN LINEAR MODELS; MEYER D, 2002, 78 U VIENN; NYQUIST H, 1991, APPL STAT-J ROY ST C, V40, P133, DOI 10.2307/2347912; PARZEN A, 2002, J COMPUTATIONAL GRAP, V2, P420; PREGIBON D, 1982, BIOMETRICS, V38, P485, DOI 10.2307/2530463; PREGIBON D, 1981, ANN STAT, V9, P705, DOI 10.1214/aos/1176345513; Rousseeuw PJ, 2003, COMPUT STAT DATA AN, V43, P315, DOI 10.1016/S0167-9473(02)00304-3; Santner T. J., 1989, STAT ANAL DISCRETE D; SEGERSTEDT B, 1992, COMMUN STAT THEORY, V21, P2227, DOI 10.1080/03610929208830909; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tutz G, 2005, STAT COMPUT, V15, P155, DOI 10.1007/s11222-005-1305-x	27	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JUN 20	2006	50	10					2878	2901		10.1016/j.csda.2005.04.009		24	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	047MG	WOS:000237882800023		
J	Kechris, KJ; Lin, JC; Bickel, PJ; Glazer, AN				Kechris, KJ; Lin, JC; Bickel, PJ; Glazer, AN			Quantitative exploration of the occurrence of lateral gene transfer by using nitrogen fixation genes as a case study	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						BLAST; codon usage; horizontal gene transfer; phylogeny	GENOME ANALYSIS; BACTERIA; CLASSIFICATION; PROKARYOTES; EVOLUTION; ALIGNMENT; SEQUENCE; ARCHAEA	Lateral gene transfer (LGT) is now accepted as an important factor in the evolution of prokaryotes. Establishment of the occurrence of LGT is typically attempted by a variety of methods that includes the comparison of reconstructed phylogenetic trees, the search for unusual GC composition or codon usage within a genome, and identification of similarities between distant species as determined by best BLAST hits. We explore quantitative assessments of these strategies to study the prokaryotic trait of nitrogen fixation, the enzyme-catalyzed reduction of N-2 to ammonia. Phylogenies constructed on nitrogen fixation genes are not in agreement with the tree-of-life based on 16S rRNA but do not conclusively distinguish between gene loss and LGT hypotheses. Using a series of analyses on a set of complete genomes, our results distinguish two structurally distinct classes of MoFe nitrogenases whose distribution cuts across lines of vertical inheritance and makes us believe that a conclusive case for LGT has been made.	Univ Calif San Francisco, Dept Biochem & Biophys, San Francisco, CA 94143 USA; Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA; Univ Calif Berkeley, Dept Mol & Cell Biol, Berkeley, CA 94720 USA	Bickel, PJ (reprint author), Univ Colorado, Dept Prevent Med & Biometr, 4200 E 9th Ave,B-119, Denver, CO 80262 USA.	bickel@stat.berkeley.edu; glazer@uclink4.berkeley.edu					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Anbar AD, 2002, SCIENCE, V297, P1137, DOI 10.1126/science.1069651; Archibald JM, 2003, P NATL ACAD SCI USA, V100, P7678, DOI 10.1073/pnas.1230951100; Bickel PJ, 2002, P NATL ACAD SCI USA, V99, P14764, DOI 10.1073/pnas.222508899; Bonnet R, 2004, ANTIMICROB AGENTS CH, V48, P1, DOI 10.1128/AAC.48.1.1-14.2004; Boucher Y, 2003, ANNU REV GENET, V37, P283, DOI 10.1146/annurev.genet.37.050503.084247; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Doolittle WF, 1999, SCIENCE, V284, P2124, DOI 10.1126/science.284.5423.2124; Dzidic S, 2003, ACTA PHARMACOL SIN, V24, P519; Eady RR, 1996, CHEM REV, V96, P3013, DOI 10.1021/cr950057h; Eisen JA, 2000, CURR OPIN GENET DEV, V10, P606, DOI 10.1016/S0959-437X(00)00143-X; Farahi K, 2004, J MOL EVOL, V58, P615, DOI 10.1007/s00239-004-2582-2; Felsenstein J., 1989, CLADISTICS, V5, P164, DOI DOI 10.1111/J.1096-0031.1989.TB00562.X; Genereux DP, 2003, TRENDS GENET, V19, P191, DOI 10.1016/S0168-9525(03)00055-6; Gutell RR, 2002, CURR OPIN STRUC BIOL, V12, P301, DOI 10.1016/S0959-440X(02)00339-1; Howard JB, 1996, CHEM REV, V96, P2965, DOI 10.1021/cr9500545; Jain R, 1999, P NATL ACAD SCI USA, V96, P3801, DOI 10.1073/pnas.96.7.3801; Koonin EV, 2001, ANNU REV MICROBIOL, V55, P709, DOI 10.1146/annurev.micro.55.1.709; Koski LB, 2001, J MOL EVOL, V52, P540; Kurland CG, 2003, P NATL ACAD SCI USA, V100, P9658, DOI 10.1073/pnas.1632870100; Kurland CG, 2005, BIOESSAYS, V27, P741, DOI 10.1002/bies.20258; Leigh J A, 2000, Curr Issues Mol Biol, V2, P125; Miller R. V., 2004, MICROBIAL EVOLUTION; Mrazek J, 1999, ANN NY ACAD SCI, V870, P314, DOI 10.1111/j.1749-6632.1999.tb08893.x; Nelson KE, 1999, NATURE, V399, P323; NEWTON W, 2000, PROKARYOTIC NITROGEN, P3; Peden J, 1999, THESIS U NOTTINGHAM; Raymond J, 2004, MOL BIOL EVOL, V21, P541, DOI 10.1093/molbev.msh047; Raymond J, 2002, SCIENCE, V298, P1616, DOI 10.1126/science.1075558; Rivera MC, 1998, P NATL ACAD SCI USA, V95, P6239, DOI 10.1073/pnas.95.11.6239; Rubio LM, 2005, J BACTERIOL, V187, P405, DOI 10.1128/JB.187.2.405-414.2005; SHARP PM, 1986, NUCLEIC ACIDS RES, V14, P5125, DOI 10.1093/nar/14.13.5125; Syvanen M., 2002, HORIZONTAL GENE TRAN; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; van Berkum P, 2003, J BACTERIOL, V185, P2988, DOI 10.1128/JB.185.10.2988-2998.2003; WOESE CR, 1990, P NATL ACAD SCI USA, V87, P4576, DOI 10.1073/pnas.87.12.4576; WOESE CR, 1990, SCIENCE, V247, P789, DOI 10.1126/science.2305249; Wolf YI, 2001, BMC EVOL BIOL, V1, DOI 10.1186/1471-2148-1-8; YOUNG JPW, 1999, NITROGEN FIXATION MO, P161	39	24	25	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	JUN 20	2006	103	25					9584	9589		10.1073/pnas.0603534103		6	Multidisciplinary Sciences	Science & Technology - Other Topics	058JD	WOS:000238660400037	16769896	
J	Guo, L; Ma, Y; Ward, R; Castranova, V; Shi, XL; Qian, Y				Guo, L; Ma, Y; Ward, R; Castranova, V; Shi, XL; Qian, Y			Constructing molecular classifiers for the accurate prognosis of lung adenocarcinoma	CLINICAL CANCER RESEARCH			English	Article							GENE-EXPRESSION SIGNATURES; SERIAL ANALYSIS; CELLS RESISTANT; MICROARRAY DATA; BREAST-CANCER; ALPHA-TUBULIN; BETA-TUBULIN; SOLID TUMORS; SURVIVAL; CLASSIFICATION	Purpose: Individualized therapy of lung adenocarcinoma depends on the accurate classification of patients into subgroups of poor and good prognosis, which reflects a different probability of disease recurrence and survival following therapy. However, it is currently impossible to reliably identify specific high-risk patients, Here, we propose a computational model system which accurately predicts the clinical outcome of individual patients based on their gene expression profiles. Experimental Design: Gene signatures were selected using feature selection algorithms random forests, correlation-based feature selection, and gain ratio attribute selection. Prediction models were built using random committee and Bayesian belief networks. The prognostic power of the survival predictors was also evaluated using hierarchical cluster analysis and Kaplan-Meier analysis. Results: The predictive accuracy of an identified 37-gene survival signature is 0.96 as measured by the area under the time-dependent receiver operating curves. The cluster analysis, using the 37-gene signature, aggregates the patient samples into three groups with distinct prognoses (Kaplan-Meier analysis, P < 0.0005, log-rank test). All patients in cluster 1 were in stage 1, with No lymph node status (no metastasis) and smaller tumor size (T-1 or T-2). Additionally, a 12-gene signature correctly predicts the stage of 94.2% of patients. Conclusions: Our results show that the prediction models based on the expression levels of a small number of marker genes could accurately predict patient outcome for individualized therapy of lung adenocarcinoma. Such an individualized treatment may significantly increase survival due to the optimization of treatment procedures and improve lung cancer survival every year through the 5-year checkpoint.	W Virginia Univ, Hlth Sci Ctr, Mary Babb Randolph Canc Ctr, Dept Community Med, Morgantown, WV 26506 USA; W Virginia Univ, Hlth Sci Ctr, Mary Babb Randolph Canc Ctr, Dept Stat, Morgantown, WV 26506 USA; W Virginia Univ, Hlth Sci Ctr, Mary Babb Randolph Canc Ctr, Biomed Sci Grad Program, Morgantown, WV 26506 USA; NIOSH, Pathol & Physiol Res Branch, Hlth Effects Lab Div, Morgantown, WV 26505 USA	Guo, L (reprint author), W Virginia Univ, Hlth Sci Ctr, Mary Babb Randolph Canc Ctr, Dept Community Med, 1814 HSS,POB 9300, Morgantown, WV 26506 USA.	lguo@hsc.wvu.edu; yaq2@cdc.gov	Shi, Xianglin/B-8588-2012				AKRITAS MG, 1994, ANN STAT, V22, P1299, DOI 10.1214/aos/1176325630; American Cancer Society, 2005, CANC FACTS FIG 2005; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen GA, 2003, P NATL ACAD SCI USA, V100, P13537, DOI 10.1073/pnas.2233850100; Diesinger I, 2002, INT J CANCER, V102, P372, DOI 10.1002/ijc.10714; Frank E., 2005, DATA MINING PRACTICA; Frankham P, 2003, APPETITE, V41, P1, DOI 10.1016/S0195-6663(03)00024-2; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Gordon GJ, 2002, CANCER RES, V62, P4963; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Heagerty PJ, 2000, BIOMETRICS, V56, P337, DOI 10.1111/j.0006-341X.2000.00337.x; Hsiao LL, 2001, PHYSIOL GENOMICS, V7, P97; Hueso M, 2004, BBA-MOL BASIS DIS, V1689, P58, DOI 10.1016/j.bbadis.2004.01.008; Jiang HY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-81; Kettunen E, 2004, CANCER GENET CYTOGEN, V149, P98, DOI 10.1016/s0165-4608(03)00300-5; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; LAI A, 1999, CANCER RES, V59, P5403; Loganzo F, 2004, MOL CANCER THER, V3, P1319; Malewski T, 2005, CANCER INVEST, V23, P222, DOI 10.1081/CNV-200055958; Matsui K, 2000, ARCH PATHOL LAB MED, V124, P267; Muller-Hagen G, 2004, CURR OPIN DRUG DISC, V7, P290; Nacht M, 1999, CANCER RES, V59, P5464; NARUKE T, 1988, J THORAC CARDIOV SUR, V96, P440; Nedachi T, 2004, DEVELOPMENT, V131, P4987, DOI 10.1242/dev.01368; Nimgaonkar A, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-27; PAIROLERO PC, 1984, ANN THORAC SURG, V38, P331; Poruchynsky MS, 2004, BIOCHEMISTRY-US, V43, P13944, DOI 10.1021/bi049300; Powell CA, 2003, AM J RESP CELL MOL, V29, P157, DOI 10.1165/rcmb.2002-0183RC; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Rhodes DR, 2004, P NATL ACAD SCI USA, V101, P9309, DOI 10.1073/pnas.0401994101; Rhodes DR, 2004, NEOPLASIA, V6, P1; Rifkin R, 2003, SIAM REV, V45, P706, DOI 10.1137/S0036144502411986; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Satoh K, 2004, J MAMMARY GLAND BIOL, V9, P195, DOI 10.1023/B:JOMG.0000037162.84758.b5; Seve P, 2005, CLIN CANCER RES, V11, P5481, DOI 10.1158/1078-0432.CCR-05-0285; Steensma DP, 2005, BLOOD, V105, P443, DOI 10.1182/blood-2004-07-2792; Stein WD, 2004, CANCER RES, V64, P2805, DOI 10.1158/0008-5472.CAN-03-3383; Su AI, 2001, CANCER RES, V61, P7388; Swisher SG, 2002, SEMIN ONCOL, V29, P95, DOI 10.1053/sonc.2002.31530; Velculescu VE, 1999, NAT GENET, V23, P387, DOI 10.1038/70487; VELCULESCU VE, 1995, SCIENCE, V270, P484, DOI 10.1126/science.270.5235.484; Wigle DA, 2002, CANCER RES, V62, P3005; WILLIAMS DE, 1981, J THORAC CARDIOV SUR, V82, P70; Yoon H, 2002, P NATL ACAD SCI USA, V99, P15632, DOI 10.1073/pnas.242597299; Zhang W, 2001, CLIN CANCER RES, V7, P2159; Zhao GH, 2005, EXP CELL RES, V305, P312, DOI 10.1016/j.yexer.2004.12.030	50	55	57	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	JUN 1	2006	12	11	1				3344	3354		10.1158/1078-0432.CCR-05-2336		11	Oncology	Oncology	051OG	WOS:000238169800017	16740756	
J	Fan, H; Ramamohanarao, K				Fan, H; Ramamohanarao, K			Fast discovery and the generalization of strong jumping emerging patterns for building compact and accurate classifiers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; machine learning; emerging patterns; classification; frequent patterns; mining methods and algorithms	GENE-EXPRESSION PROFILES; DATABASES	Classification of large data sets is an important data mining problem that has wide applications. Jumping Emerging Patterns ( JEPs) are those itemsets whose supports increase abruptly from zero in one data set to nonzero in another data set. In this paper, we propose a fast, accurate, and less complex classifier based on a subset of JEPs, called Strong Jumping Emerging Patterns ( SJEPs). The support constraint of SJEP removes potentially less useful JEPs while retaining those with high discriminating power. Previous algorithms based on the manipulation of border [ 1] as well as consEPMiner [ 2] cannot directly mine SJEPs. Here, we present a new tree-based algorithm for their efficient discovery. Experimental results show that: 1) the training of our classifier is typically 10 times faster than earlier approaches, 2) our classifier uses much fewer patterns than the JEP-Classifier [ 3] to achieve a similar ( and, often, improved) accuracy, and 3) in many cases, it is superior to other state-of-the-art classification systems such as Naive Bayes, CBA, C4.5, and bagged and boosted versions of C4.5. We argue that SJEPs are high-quality patterns which possess the most differentiating power. As a consequence, they represent sufficient information for the construction of accurate classifiers. In addition, we generalize these patterns by introducing Noise-tolerant Emerging Patterns (NEPs) and Generalized Noise-tolerant Emerging Patterns ( GNEPs). Our tree-based algorithms can be adopted to easily discover these variations. We experimentally demonstrate that SJEPs, NEPs, and GNEPs are extremely useful for building effective classifiers that can deal well with noise.	Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic 3010, Australia	Fan, H (reprint author), Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic 3010, Australia.	hfan@csse.unimelb.edu.au; rao@csse.unimelb.edu.au					AGRAWAL R, 1992, PROC INT CONF VERY L, P560; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAILEY J, 2002, P 6 EUR C PRINC PRAC; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cheeseman P., 1996, P 2 INT C KNOWL DISC, P153; Christensen R, 1997, LOG LINEAR MODELS LO; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Dong G., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Dong G., 1999, P 2 INT C DISC SCI, P30; Fan H, 2002, P 6 PAC AS C KNOWL D, P456; Fayyad U., 1993, P 13 INT JOINT C ART, P1022; Fayyad U, 1996, AI MAG, V17, P37; Freitas A.A., 2002, DATA MINING KNOWLEDG; Han J., 2000, DATA MINING CONCEPTS; Han J., 2000, P 2000 ACM SIGMOD IN, P1, DOI 10.1145/342009.335372; Jinyan Li, 2001, KNOWL INF SYST, V3, P131, DOI DOI 10.1007/PL00011662; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; Li J, 2003, BIOINFORMATICS S2, V19, pii93; Li J., 2000, P 17 INT C MACH LEAR, P551; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Li JY, 1999, LECT NOTES ARTIF INT, V1704, P406; Liu H, 1998, ELEC SOC S, V98, P86; MITCHELL T, 1982, ARTIFICIAL INTELLIGE, V18; Mitchell T. M., 1997, MACHINE LEARNING; Pei J., 2001, P 2001 INT C DAT MIN; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ripley B. D., 1996, PATTERN RECOGNITION; *RULEQUEST, 2000, SEE5 C5 0 RULEQUEST; Seno M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989558; Witten I. H., 1999, DATA MINING PRACTICA; Yang C, 2001, P 7 ACM SIGKDD INT C, P194, DOI 10.1145/502512.502539; Zhang Xiuzhen, 2000, P 6 INT C KNOWL DISC, P310, DOI 10.1145/347090.347158	39	33	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUN	2006	18	6					721	737		10.1109/TKDE.2006.95		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	033ML	WOS:000236851800001		
J	Su, XG; Tsai, CL; Yan, X				Su, XG; Tsai, CL; Yan, X			Treed variance	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						BIC; heteroscedasticity; regression trees; weighted least squares	HETEROSCEDASTICITY	This article proposes a data-driven tree method, called "treed variance" (TV), to model heteroscedasticity in linear regression. Specifically, we use a score test statistic to recursively bisect data into heterogenous groups, and then adopt the pruning methodology of CART to determine the best tree size. The proposed method provides not only a piecewise constant modeling of the error variance, but also facilitates a natural check of homoscedasticity. We assess the performance of the TV method via simulation studies and illustrate its use with an empirical example.	Univ Cent Florida, Dept Stat & Actuarial Sci, Orlando, FL 32816 USA; Univ Calif Davis, Grad Sch Management, Davis, CA 95616 USA; Peking Univ, Guanghua Sch Management, Beijing 100871, Peoples R China; Merck Res Labs, Clin Biostat, Blue Bell, PA 19422 USA	Su, XG (reprint author), Univ Cent Florida, Dept Stat & Actuarial Sci, Orlando, FL 32816 USA.	xsu@pegasus.cc.ucf.edu					BICKEL PJ, 1978, ANN STAT, V6, P266, DOI 10.1214/aos/1176344124; BOX G, 1988, TECHNOMETRICS, V29, P1; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARMACK CS, 2003, PERMUTATION TESTING; Carroll R., 1988, TRANSFORMATION WEIGH; Cook R. D, 1998, REGRESSION GRAPHICS; Cox DR, 1974, THEORETICAL STAT; Frank E., 1998, P 15 INT C MACH LEAR, P152; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; HARVEY AC, 1976, ECONOMETRICA, V44, P461, DOI 10.2307/1913974; KOENKER R, 1981, J ECONOMETRICS, V17, P107, DOI 10.1016/0304-4076(81)90062-2; LEBLANC M, 1993, J AM STAT ASSOC, V88, P457, DOI 10.2307/2290325; Mendenhall W., 2003, 2 COURSE STAT REGRES; MILLER TW, 1996, 1996 P STAT COMP SEC, P150; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; Rao C. R., 1948, P CAMBRIDGE PHILOS S, V44, P50; RUTEMILL.HC, 1968, J AM STAT ASSOC, V63, P552, DOI 10.2307/2284026; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SIMONOFF JS, 1994, APPL STAT-J ROY ST C, V43, P357, DOI 10.2307/2986026; WHITE H, 1980, ECONOMETRICA, V48, P817, DOI 10.2307/1912934	23	1	1	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	JUN	2006	15	2					356	371		10.1198/106186006X113575		16	Statistics & Probability	Mathematics	049VB	WOS:000238044400005		
J	Meinshausen, N				Meinshausen, Nicolai			Quantile regression forests	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						quantile regression; random forests; adaptive neighborhood regression	TREES	Random forests were introduced as a machine learning tool in Breiman (2001) and have since proven to be very popular and powerful for high-dimensional regression and classification. For regression, random forests give an accurate approximation of the conditional mean of a response variable. It is shown here that random forests provide information about the full conditional distribution of the response variable, not only about the conditional mean. Conditional quantiles can be inferred with quantile regression forests, a generalisation of random forests. Quantile regression forests give a non-parametric and accurate way of estimating conditional quantiles for high-dimensional predictor variables. The algorithm is shown to be consistent. Numerical examples suggest that the algorithm is competitive in terms of predictive power.	ETH, Seminar Stat, CH-8092 Zurich, Switzerland	Meinshausen, N (reprint author), ETH, Seminar Stat, CH-8092 Zurich, Switzerland.	nicolai@stat.math.ethz.ch					Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Barnett V, 1994, OUTLIERS STAT DATA, V3rd; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 2004, 670 U CAL DEP STAT; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chaudhuri P, 2002, BERNOULLI, V8, P561; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; HE X, 1998, J ROYAL STAT SOC B, V3, P537; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9; HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503; Hyndman RJ, 1996, AM STAT, V50, P361, DOI 10.2307/2684934; Koenker R., 2005, QUANTILE REGRESSION; KOENKER R, 1994, BIOMETRIKA, V81, P673; LE QV, 2005, NONPARAMETRIC QUANTI; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lin Y., 2002, 1055 U WISC DEP STAT; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI [10.1016/j.sigpro.2003.07.018, 10.1016/j.sigpro.2003.018]; Portnoy S, 1997, STAT SCI, V12, P279; R Development Core Team, 2005, R LANG ENV STAT COMP; Schapire RE, 1998, ANN STAT, V26, P1651; Steinwart I, 2005, J MACH LEARN RES, V6, P211; Weisberg S., 2005, APPL LINEAR REGRESSI, V3rd	23	66	66	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2006	7						983	999				17	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152UV	WOS:000245388400004		
J	Berk, RA; Kriegler, B; Baek, JH				Berk, RA; Kriegler, B; Baek, JH			Forecasting dangerous inmate misconduct: An application of ensemble statistical procedures	JOURNAL OF QUANTITATIVE CRIMINOLOGY			English	Article						prison; incarceration; misconduct; classification	CLASSIFICATION-SYSTEM	In this paper, we attempt to forecast which prison inmates are likely to engage in very serious misconduct while incarcerated. Such misconduct would usually be a major felony if committed outside of prison: drug trafficking, assault, rape, attempted murder and other crimes. The binary response variable is problematic because it is highly unbalanced. Using data from nearly 10,000 inmates held in facilities operated by the California Department of Corrections, we show that several popular classification procedures do no better than the marginal distribution unless the data are weighted in a fashion that compensates for the lack of balance. Then, random forests performs reasonably well, and better than CART or logistic regression. Although less than 3% of the inmates studied over 24 months were reported for very serious misconduct, we are able to correctly forecast such behavior about half the time.	Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Berk, RA (reprint author), Univ Calif Los Angeles, Dept Stat, 8125 Math Sci Bldg, Los Angeles, CA 90095 USA.	berk@stat.ucla.edu					ALEXANDER J, 1992, HDB EVALUATING PRISO; AUSTIN J, 1993, CLASSIFICATION INTER; AUSTIN J, 1986, CRIME DELINQUENCY, V32, P302, DOI 10.1177/0011128786032003005; BAIRD C, 1993, OBJECTIVE CLASSIFICA; Berk RA, 1999, J AM STAT ASSOC, V94, P1045, DOI 10.2307/2669918; BERK RA, 2003, J CRIMINOLOGY PUBLIC, V2, P215; BERK RA, 2005, IN PRESS SOC METH RE; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 2001, WALD LECT, V1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRENNAN T, 1993, CLASSIFICATION TOOL; BRENNAN T, 1987, CLASSIFICATION OVERV; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Gottfredson M., 1990, GEN THEORY CRIME; HAMILLUKER J, 2003, IN PRESS SOC SCI RES; HARDYMAN PL, 2000, REVALIDATING EXTERNA; HARDYMAN PL, 2001, SEPT 6 7 2000 P; Harer MD, 2001, CRIME DELINQUENCY, V47, P513, DOI 10.1177/0011128701047004002; Harrison PM, 2003, BUREAU JUSTICE STAT; Hastie T., 2001, ELEMENTS STAT LEARNI; KANE TR, 1986, CRIME DELINQUENCY, V32; SAMPSON RJ, 1990, AM SOCIOL REV, V55, P609, DOI 10.2307/2095859	23	26	26	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0748-4518			J QUANT CRIMINOL	J. Quant. Criminol.	JUN	2006	22	2					131	145		10.1007/s-10940-006-9005-z		15	Criminology & Penology	Criminology & Penology	059XR	WOS:000238766000002		
J	Martin, R; Yu, K				Martin, R; Yu, K			Assessing performance of prediction rules in machine learning	PHARMACOGENOMICS			English	Article						bootstrap; machine learning; Monte Carlo simulation; prediction rule; split sample; stochastic gradient boosting; true error	CROSS-VALIDATION; CLASSIFICATION	Introduction: An important goal in machine learning is to assess the degree to which prediction rules are robust and replicable, since these rules are used for decision making and for planning follow-up studies. This requires an estimate of a prediction rule's true error rate, a statistic that can be estimated by resampling data. However, there are many possible approaches depending upon whether we draw observations with or without replacement, or sample once, repeatedly, or not at all, and the pros and cons of each are often unclear. This study illustrates and compares different methods for estimating true error with the aim of providing practical guidance to users of machine learning techniques. Methods: We conducted Monte Carlo simulation studies using four different error estimators: bootstrap, split sample, resubstitution and a direct estimate of true error. Here, 'split sample' refers to a single random partition of the data into a pair of training and test samples, a popular scheme. We used stochastic gradient boosting as a learning algorithm, and considered data from two studies for which the underlying data mechanism was known to be complex: a library of 6000 tripeptide substrates collected for analysis of proteasome inhibition as part of anticancer drug design, and a cardiovascular study involving 600 subjects receiving antiplatelet treatment for acute coronary syndrome. Results: There were important differences in the performance of the various error estimators examined. Error estimators for split sample and resubstitution, while being the most transparent in action and the simplest to apply, did not quantify the performance of prediction rules as accurately as the bootstrap. This was true for both types of study data, despite their highly different nature. Conclusions: The robustness and reliability of decisions based on analysis of genomics data could, in many cases, be improved by following best practices for prediction error estimation. For this, techniques such as bootstrap should be considered.	Millennium Pharmaceut, Cambridge, MA 02139 USA; Washington Univ, St Louis, MO 63110 USA	Martin, R (reprint author), Millennium Pharmaceut, Cambridge, MA 02139 USA.	rory.martin.phd@gmail.com					Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1993, INTRO BOOTSTRAP; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Friedman J., 2000, ANN STAT, V29, P1189; Hastie T., 2001, ELEMENTS STAT LEARNI; HAWKINS D, 2002, J CHEM INF MODEL, V43, P579; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210	13	2	4	FUTURE MEDICINE LTD	LONDON	UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND	1462-2416			PHARMACOGENOMICS	Pharmacogenomics	JUN	2006	7	4					543	550		10.2217/14622416.7.4.543		8	Pharmacology & Pharmacy	Pharmacology & Pharmacy	056WH	WOS:000238555300001	16753002	
J	Nayal, M; Honig, B				Nayal, Murad; Honig, Barry			On the nature of cavities on protein surfaces: Application to the identification of drug-binding sites	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						protein-drug-binding sites; protein-drug; interactions; protein surface cavities; molecular recognition; molecular surface patches; protein function	PATTERN-RECOGNITION STRATEGIES; MOLECULAR-SURFACES; NEURAL-NETWORK; PREDICTION; DESIGN; INHIBITORS; INTERFACES; DISCOVERY; REGIONS; PATCHES	In this article we introduce a new method for the identification and the accurate characterization of protein surface cavities. The method is encoded in the program SCREEN (Surface Cavity REcognition and EvaluatioN). As a first test of the utility of our approach we used SCREEN to locate and analyze the surface cavities of a nonredundant set of 99 proteins cocrystallized with drugs. We find that this set of proteins has on average a-Lout 14 distinct cavities per protein. In all cases, a drug is bound at one (and sometimes more than one) of these cavities. Using cavity size alone as a criterion for predicting drug-binding sites yields a high balanced error rate of 15.7%, with only 71.7% coverage. Here we characterize each surface cavity by computing a comprehensive set of 408 physicochemical, structural, and geometric attributes. By applying modern machine learning techniques (Random Forests) we were able to develop a classifier that can identify drug-binding cavities with a balanced error rate of 7.2% and coverage of 88.9%. Only 18 of the 408 cavity attributes had a statistically significant role in the prediction. Of these 18 important attributes, almost all involved size and shape rather than physicochemical properties of the surface cavity. The implications of these results are discussed. A SCREEN Web server is available at http://interface. bioc.columbia.edu/screen.	Columbia Univ, Howard Hughes Med Inst, Coll Phys & Surg, Dept Biochem & Mol Biophys, New York, NY 10032 USA; Columbia Univ, Howard Hughes Med Inst, Ctr Computat Biol & Bioinformat, New York, NY 10032 USA	Honig, B (reprint author), Columbia Univ, Howard Hughes Med Inst, Coll Phys & Surg, Dept Biochem & Mol Biophys, 1130 St Nicholas Ave,ICRB Mail Box 200, New York, NY 10032 USA.	bh6@columbia.edu					ALKORTA I, 1994, J MOL GRAPHICS, V12, P3, DOI 10.1016/0263-7855(94)80002-2; An JH, 2005, MOL CELL PROTEOMICS, V4, P752, DOI 10.1074/mcp.M400159-MCP200; AQVIST J, 1987, J MOL GRAPHICS, V5, P30, DOI 10.1016/0263-7855(87)80042-5; BADELCHAGNON A, 1994, J MOL GRAPHICS, V12, P193; BADELCHAGNON A, 1994, J MOL GRAPHICS, V12, P162, DOI 10.1016/0263-7855(94)80082-0; Bate P, 2004, J MOL BIOL, V340, P263, DOI 10.1016/j.jmb.2004.04.070; Brady GP, 2000, J COMPUT AID MOL DES, V14, P383, DOI 10.1023/A:1008124202956; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burnham K. P., 2002, MODEL SELECTION MULT; Cochran AG, 2000, CHEM BIOL, V7, pR85, DOI 10.1016/S1074-5521(00)00106-X; CONNOLLY ML, 1986, J MOL GRAPHICS, V4, P3; Cosgrove DA, 2000, J COMPUT AID MOL DES, V14, P573, DOI 10.1023/A:1008167930625; Cover T. M., 1991, ELEMENTS INFORM THEO; DELANEY JS, 1992, J MOL GRAPHICS, V10, P174, DOI 10.1016/0263-7855(92)80052-F; DePristo MA, 2004, STRUCTURE, V12, P831, DOI 10.1016/j.str.2004.02.031; Di L, 2003, CURR OPIN CHEM BIOL, V7, P402, DOI 10.1016/S1367-5931(03)00055-3; DIAMOND R, 1974, J MOL BIOL, V82, P371, DOI 10.1016/0022-2836(74)90598-1; DUNCAN BS, 1993, BIOPOLYMERS, V33, P219, DOI 10.1002/bip.360330204; Edelsbrunner H, 1998, DISCRETE APPL MATH, V88, P83, DOI 10.1016/S0166-218X(98)00067-5; EDELSBRUNNER H, 1995, DISCRETE COMPUT GEOM, V13, P415, DOI 10.1007/BF02574053; EDELSBRUNNER H, 1994, ACM T GRAPHIC, V13, P43, DOI 10.1145/174462.156635; Eisenhaber F, 1996, PROTEIN ENG, V9, P1121, DOI 10.1093/protein/9.12.1121; EISNEBERG D, 1992, PROTEIN SCI, V1, P227; Elcock AH, 2001, J MOL BIOL, V312, P885, DOI 10.1006/jmbi.2001.5009; Exner TE, 2002, J COMPUT CHEM, V23, P1176, DOI 10.1002/jcc.10086; FANNING DW, 1986, BIOPOLYMERS, V25, P863, DOI 10.1002/bip.360250509; Fernandez-Recio J, 2005, PROTEINS, V58, P134, DOI 10.1002/prot.20285; Ferre F., 2004, NUCLEIC ACIDS RES, V32, P240; Glaser F, 2003, BIOINFORMATICS, V19, P163, DOI 10.1093/bioinformatics/19.1.163; HEIDEN W, 1994, J MOL GRAPHICS, V12, P106, DOI 10.1016/0263-7855(94)80075-8; Hendlich M, 1997, J MOL GRAPH MODEL, V15, P359, DOI 10.1016/S1093-3263(98)00002-3; Henry CM, 2001, CHEM ENG NEWS, V79, P69, DOI 10.1021/cen-v079n023.p069; HO CMW, 1990, J COMPUT AID MOL DES, V4, P337, DOI 10.1007/BF00117400; HONIG B, 1995, SCIENCE, V268, P1144, DOI 10.1126/science.7761829; Iversen LF, 2001, BIOCHEMISTRY-US, V40, P14812, DOI 10.1021/bi011389l; Jones S, 1997, J MOL BIOL, V272, P133, DOI 10.1006/jmbi.1997.1233; Jones S, 1996, P NATL ACAD SCI USA, V93, P13, DOI 10.1073/pnas.93.1.13; Jones S, 1997, J MOL BIOL, V272, P121, DOI 10.1006/jmbi.1997.1234; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Keil M, 2004, J COMPUT CHEM, V25, P779, DOI 10.1002/jcc.10361; KLAPPER I, 1986, Proteins Structure Function and Genetics, V1, P47, DOI 10.1002/prot.340010109; KLEYWEGT GJ, 1994, ACTA CRYSTALLOGR D, V50, P178, DOI 10.1107/S0907444993011333; Koenderink J., 1990, SOLID SHAPE; KOROLEV S, 1995, P NATL ACAD SCI USA, V92, P9264, DOI 10.1073/pnas.92.20.9264; KUNTZ ID, 1982, J MOL BIOL, V161, P269, DOI 10.1016/0022-2836(82)90153-X; LASKOWSKI RA, 1995, J MOL GRAPHICS, V13, P323, DOI 10.1016/0263-7855(95)00073-9; Laskowski RA, 1996, PROTEIN SCI, V5, P2438; Laurie ATR, 2005, BIOINFORMATICS, V21, P1908, DOI 10.1093/bioinformatics/bti315; LEVITT DG, 1992, J MOL GRAPHICS, V10, P229, DOI 10.1016/0263-7855(92)80074-N; LEWIS M, 1985, SCIENCE, V230, P1163, DOI 10.1126/science.4071040; LEWIS RA, 1991, METHOD ENZYMOL, V202, P126, DOI 10.1016/0076-6879(91)02010-7; LEWIS RA, 1989, J COMPUT AID MOL DES, V3, P133, DOI 10.1007/BF01557724; Liang J, 1998, PROTEIN SCI, V7, P1884; Liang S, 2004, PROTEINS, V57, P548, DOI 10.1002/prot.20238; Lichtarge O, 1996, J MOL BIOL, V257, P342, DOI 10.1006/jmbi.1996.0167; Lijnzaad P, 1996, PROTEINS, V25, P389, DOI 10.1002/(SICI)1097-0134(199607)25:3<389::AID-PROT10>3.3.CO;2-S; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Lo Conte L, 1999, J MOL BIOL, V285, P2177; Maignan S, 2000, J MED CHEM, V43, P3226, DOI 10.1021/jm000940u; Masuya M, 1995, J MOL GRAPHICS, V13, P331, DOI 10.1016/0263-7855(95)00071-2; Nayal M, 1999, PROTEIN SCI, V8, P676; Nayeem A, 2003, BIOPOLYMERS, V70, P201, DOI 10.1002/bip.10434; Neuvirth H, 2004, J MOL BIOL, V338, P181, DOI 10.1016/j.jmb.2004.02.040; NICHOLLS A, 1991, PROTEINS, V11, P281, DOI 10.1002/prot.340110407; Nissink JWM, 2002, PROTEINS, V49, P457, DOI 10.1002/prot.10232; Ofran Y, 2003, J MOL BIOL, V325, P377, DOI 10.1016/S0022-2836(02)01223-8; Ondrechen MJ, 2001, P NATL ACAD SCI USA, V98, P12473, DOI 10.1073/pnas.211436698; Oprea TI, 2002, J COMPUT AID MOL DES, V16, P325, DOI 10.1023/A:1020877402759; Perola E, 2004, PROTEINS, V56, P235, DOI 10.1002/prot.20088; Peters KP, 1996, J MOL BIOL, V256, P201, DOI 10.1006/jmbi.1996.0077; Pettit FK, 1999, J MOL BIOL, V285, P1377, DOI 10.1006/jmbi.1998.2411; PICKETT SD, 1993, J MOL BIOL, V231, P825, DOI 10.1006/jmbi.1993.1329; Preissner R, 1998, J MOL BIOL, V280, P535, DOI 10.1006/jmbi.1998.1878; Pupko T, 2002, BIOINFORMATICS, V18, pS71; Radzicka A., 1988, BIOCHEMISTRY-US, V27, P1644; Rogers C. A., 1964, PACKING COVERING; Ruppert J, 1997, PROTEIN SCI, V6, P524; Schmitt S, 2002, J MOL BIOL, V323, P387, DOI 10.1016/S0022-2836(02)00811-2; SHARP KA, 1990, DNA PROTEIN COMPLEXE, V2, P211; Shehadi IA, 2002, MOL BIOL REP, V29, P329, DOI 10.1023/A:1021220208562; Sheinerman FB, 2002, J MOL BIOL, V318, P161, DOI 10.1016/S0022-2836(02)00030-X; SMITH GM, 1994, PROTEIN SCI, V3, P118; Stahl M, 2000, PROTEIN ENG, V13, P83, DOI 10.1093/protein/13.2.83; Stawiski EW, 2003, J MOL BIOL, V326, P1065, DOI 10.1016/S0022-2836(03)00031-7; VAJDA S, 1994, BIOCHEMISTRY-US, V33, P13977, DOI 10.1021/bi00251a004; VOORINTHOLT R, 1989, J MOL GRAPHICS, V7, P243, DOI 10.1016/0263-7855(89)80010-4; Voronoi G.F., 1907, J REINE ANGEW MATH, V133, P97; WODAK SJ, 1978, J MOL BIOL, V124, P323, DOI 10.1016/0022-2836(78)90302-9; YOUNG L, 1994, PROTEIN SCI, V3, P717	90	135	143	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585			PROTEINS	Proteins	JUN 1	2006	63	4					892	906		10.1002/prot.20897		15	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	047ER	WOS:000237863100016	16477622	
J	Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartelt, M; Bartko, H; Bastieri, D; Bavikadi, SR; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bordas, P; Bosch-Ramon, V; Bretz, T; Britvitch, I; Camara, M; Carmona, E; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Dame, TM; Danielyan, V; Dazzi, F; De Angelis, A; Reyes, RDL; De Lotto, B; Domingo-Santamari, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Fuchs, M; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Hsu, CC; Isar, PG; Jacon, P; Kalekin, O; Kasyra, R; Kranich, D; Laatiaoui, M; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Lombardi, S; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mansutti, O; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Merck, C; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Paredes, JM; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Persic, M; Peruzzo, L; Piccioli, A; Poller, M; Prandini, E; Raymers, A; Rico, J; Rhode, W; Ribo, M; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Scapin, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, SN; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zanin, R; Zapatero, J				Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartelt, M; Bartko, H; Bastieri, D; Bavikadi, SR; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bordas, P; Bosch-Ramon, V; Bretz, T; Britvitch, I; Camara, M; Carmona, E; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Dame, TM; Danielyan, V; Dazzi, F; De Angelis, A; Reyes, RDL; De Lotto, B; Domingo-Santamari, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Fuchs, M; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Hsu, CC; Isar, PG; Jacon, P; Kalekin, O; Kasyra, R; Kranich, D; Laatiaoui, M; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Lombardi, S; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mansutti, O; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Merck, C; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Paredes, JM; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Persic, M; Peruzzo, L; Piccioli, A; Poller, M; Prandini, E; Raymers, A; Rico, J; Rhode, W; Ribo, M; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Scapin, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, SN; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zanin, R; Zapatero, J			Observation of VHE gamma radiation from HESS J1834-087/W41 with the MAGIC telescope	ASTROPHYSICAL JOURNAL			English	Article						gamma rays : observations; supernova remnants	SUPERNOVA-REMNANTS; RAY SOURCES; MILKY-WAY; EMISSION	Recently, the HESS array has reported the detection of gamma-ray emission above a few hundred GeV from eight new sources located close to the Galactic plane. The source HESS J1834 - 087 is spatially coincident with the supernova remnant G23.3 - 0.3 (W41). Here we present MAGIC observations of this source, resulting in the detection of a differential gamma-ray flux consistent with a power law, described as dN(gamma)/(dA dt dE) = (3.7 +/- 0.6) x 10(-12) (E/TeV)(-2.5 +/- 0.2) cm(-2) s(-1) TeV-1. We confirm the extended character of this flux. We briefly discuss the observational technique used and the procedure implemented for the data analysis, and we put this detection in the perspective of the molecular environment found in the region of W41. We present (CO)-C-13 and (CO)-C-12 emission maps showing the existence of a massive molecular cloud in spatial superposition with the MAGIC detection.	Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany; Inst Fis Altes Energies, E-08193 Barcelona, Spain; ETH, CH-8093 Zurich, Switzerland; Univ Complutense, E-28040 Madrid, Spain; Univ Autonoma Barcelona, E-08193 Bellaterra, Spain; Univ Dortmund, D-44227 Dortmund, Germany; Univ Wurzburg, D-97074 Wurzburg, Germany; Univ Padua, I-35131 Padua, Italy; Ist Nazl Fis Nucl, I-35131 Padua, Italy; Univ Udine, I-33100 Udine, Italy; INFN Trieste, I-33100 Udine, Italy; Univ Lodz, PL-90236 Lodz, Poland; Univ Barcelona, E-08028 Barcelona, Spain; Yerevan Phys Inst, AM-375036 Yerevan, Armenia; Harvard Smithsonian Ctr Astrophys, Cambridge, MA 02138 USA; Univ Siena, I-53100 Siena, Italy; INFN Pisa, I-53100 Siena, Italy; Univ Calif Davis, Davis, CA 95616 USA; Humboldt Univ, D-12489 Berlin, Germany; Tuorla Observ, FI-21500 Piikkio, Finland; Univ Trieste, I-34100 Trieste, Italy; Ist Nazl Fis Nucl, I-34100 Trieste, Italy; Inst Nucl Energy Res, BG-1784 Sofia, Bulgaria; Osserv Astron Trieste, I-34100 Trieste, Italy; Univ Pisa, I-56126 Pisa, Italy; INFN Pisa, I-56126 Pisa, Italy; Inst Ciencies Espai, E-08193 Barcelona, Spain	Albert, J (reprint author), Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany.		Moralejo Olaizola, Abelardo/M-2916-2014; Ribo, Marc/B-3579-2015; Torres, Diego/F-3009-2015; Antoranz, Pedro/H-5095-2015; Miranda, Jose Miguel/F-2913-2013; Fonseca Gonzalez, Maria Victoria/I-2004-2015; Barrio, Juan/L-3227-2014; De Angelis, Alessandro/B-5372-2009; Tonello, Nadia/L-8065-2014; Isar, Paula Gina/B-5808-2011; Mannheim, Karl/F-6705-2012; Flix, Josep/G-5414-2012; Doro, Michele/F-9458-2012; chilingarian, ashot/B-1901-2014; Contreras Gonzalez, Jose Luis/K-7255-2014; Rico, Javier/K-8004-2014; Fernandez, Ester/K-9734-2014; lopez, marcos/L-2304-2014; GAug, Markus/L-2340-2014; Font, Lluis/L-4197-2014; Fernandez, Enrique/L-5387-2014	Moralejo Olaizola, Abelardo/0000-0002-1344-9080; Torres, Diego/0000-0002-1522-9065; Antoranz, Pedro/0000-0002-3015-3601; Miranda, Jose Miguel/0000-0002-1472-9690; Fonseca Gonzalez, Maria Victoria/0000-0003-2235-0725; Barrio, Juan/0000-0002-0965-0259; Tonello, Nadia/0000-0003-0550-1667; Doro, Michele/0000-0001-9104-3214; chilingarian, ashot/0000-0002-2018-9715; Contreras Gonzalez, Jose Luis/0000-0001-7282-2394; Rico, Javier/0000-0003-4137-1134; lopez, marcos/0000-0002-8791-7908; GAug, Markus/0000-0001-8442-7877; Font, Lluis/0000-0003-2109-5961; Fernandez, Enrique/0000-0002-6405-9488			Aharonian F, 2005, SCIENCE, V307, P1938, DOI 10.1126/science.1108643; Aharonian F, 2006, ASTROPHYS J, V636, P777, DOI 10.1086/498013; Albert J, 2006, ASTROPHYS J, V637, pL41, DOI 10.1086/500364; Albert J, 2006, ASTROPHYS J, V638, pL101, DOI 10.1086/501164; Albert J, 2006, ASTROPHYS J, V639, P761, DOI 10.1086/499421; ANYKEYEV VB, 1991, NUCL INSTRUM METH A, V303, P350, DOI 10.1016/0168-9002(91)90802-W; ARISKIN VI, 1970, SOV ASTRON, V13, P883; Baixeras C, 2004, NUCL INSTRUM METH A, V518, P188, DOI 10.1016/j.nima.2003.10.057; Bock RK, 2004, NUCL INSTRUM METH A, V516, P511, DOI 10.1016/j.nima.2003.08.157; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bretl T., 2003, P 28 INT COSM RAY C, P2947; CORTINA J, 2005, P 29 INT COSM RAY C, V5, P359; DAME TM, 1986, ASTROPHYS J, V305, P892, DOI 10.1086/164304; Dame TM, 2001, ASTROPHYS J, V547, P792, DOI 10.1086/318388; Domingo-Santamaria E., 2005, P 29 INT COSM RAY C, V5, P363; Fegan DJ, 1997, J PHYS G NUCL PARTIC, V23, P1013, DOI 10.1088/0954-3899/23/9/004; Fomin VP, 1994, ASTROPART PHYS, V2, P137, DOI 10.1016/0927-6505(94)90036-1; GAENSLER BM, 1995, MON NOT R ASTRON SOC, V275, pL73; Gaug M., 2005, P 29 INT COSM RAY C, V5, P375; Green D. A., 2004, B ASTRON SOC INDIA, V32, P335; Hillas A M, 1985, 19TH P INT COSM RAY, V3, P445; Jackson JM, 2006, ASTROPHYS J SUPPL S, V163, P145, DOI 10.1086/500091; KASSIM NE, 1992, ASTRON J, V103, P943, DOI 10.1086/116116; Lessard RW, 2001, ASTROPART PHYS, V15, P1, DOI 10.1016/S0927-6505(00)00133-X; Majumdar P, 2005, P 29 INT COSM RAY C, V5, P203; MIZOBUCHI S, 2005, P 29 INT COSM RAY C, V5, P323; Rowell GP, 2003, ASTRON ASTROPHYS, V410, P389, DOI 10.1051/0004-6361:20031194; Shaver P. A., 1970, AUSTRAL J PHYS AST S, V14, P133; Torres DF, 2003, PHYS REP, V382, P303, DOI 10.1016/S0370-1573(03)00201-1; Wagner R, 2005, P 29 INT COSM RAY C, V4, P163; White RL, 2005, ASTRON J, V130, P586, DOI 10.1086/431249	31	38	39	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X			ASTROPHYS J	Astrophys. J.	MAY 20	2006	643	1	2				L53	L56		10.1086/504917		4	Astronomy & Astrophysics	Astronomy & Astrophysics	043TQ	WOS:000237625000014		
J	Qi, YJ; Bar-Joseph, Z; Klein-Seetharaman, J				Qi, YJ; Bar-Joseph, Z; Klein-Seetharaman, J			Evaluation of different biological data and computational classification methods for use in protein interaction prediction	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						protein-protein interaction; high-throughput data; joint learning	YEAST; NETWORKS; GENOMES; GENES; TOOL	Protein-protein interactions play a key role in many biological systems. High-throughput methods can directly detect the set of interacting proteins in yeast, but the results are often incomplete and exhibit high false-positive and false-negative rates. Recently, many different research groups independently suggested using supervised learning methods to integrate direct and indirect biological data sources for the protein interaction prediction task. However, the data sources, approaches, and implementations varied. Furthermore, the protein interaction prediction task itself can be subdivided into prediction of (1) physical interaction, (2) co-complex relationship, and (3) pathway co-membership. To investigate systematically the utility of different data sources and the way the data is encoded as features for predicting each of these types of protein interactions, we assembled a large set of biological features and varied their encoding for use in each of the three prediction tasks. Six different classifiers were used to assess the accuracy in predicting interactions, Random Forest (RF), RF similarity-based k-Nearest-Neighbor, Naive Bayes, Decision Tree, Logistic Regression, and Support Vector Machine. For all classifiers, the three prediction tasks had different success rates, and co-complex prediction appears to be an easier task than the other two. Independently of prediction task, however, the RF classifier consistently ranked as one of the top two classifiers for all combinations of feature sets. Therefore, we used this classifier to study the importance of different biological datasets. First, we used the splitting function of the RF tree structure, the Gini index, to estimate feature importance. Second, we determined classification accuracy when only the top-ranking features were used as an input in the classifier. We find that the importance of different features depends on the specific prediction task and the way they are encoded. Strikingly, gene expression is consistently the most important feature for all three prediction tasks, while the protein interactions identified using the yeast-2-hybrid system were not among the top-ranking features under any condition.	Univ Pittsburgh, Sch Med, Dept Biol Struct, Pittsburgh, PA 15260 USA; Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Klein-Seetharaman, J (reprint author), Univ Pittsburgh, Sch Med, Dept Biol Struct, Biomed Sci Tower 3,Room 2051, Pittsburgh, PA 15260 USA.	judithks@cs.cmu.edu					Ashburner M, 2000, NAT GENET, V25, P25; BADER GD, 2003, NAT BIOTECHNOL, V20, P991; Bader JS, 2004, NAT BIOTECHNOL, V22, P78, DOI 10.1038/nbt924; Bar-Joseph Z, 2003, NAT BIOTECHNOL, V21, P1337, DOI 10.1038/nbt890; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Deng MH, 2002, GENOME RES, V12, P1540, DOI 10.1101/gr.153002; DOLINSKI K, SACCHAROMYCES GENOME; FLACH P, 2004, ICML04; Gavin AC, 2002, NATURE, V415, P141, DOI 10.1038/415141a; Ghaemmaghami S, 2003, NATURE, V425, P737, DOI 10.1038/nature02046; Gilchrist MA, 2004, BIOINFORMATICS, V20, P689, DOI 10.1093/bioinformatics/btg469; GUYON I, 2003, J MACHINE LEARN RES, V5, P1157; Harbison CT, 2004, NATURE, V431, P99, DOI 10.1038/nature02800; HO Y, 2002, NATURE, V415, P6868; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; JOACHIMS T, 2002, THESIS NEW YORK; John George H., 1995, P 11 C UNC ART INT, P338; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; Lin N, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-154; Mewes HW, 2004, NUCLEIC ACIDS RES, V32, pD41, DOI 10.1093/nar/gkh092; Qi Y., 2005, PAC S BIOCOMPUT, V10, P531; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Salwinski L, 2003, CURR OPIN STRUC BIOL, V13, P377, DOI 10.1016/S0959-440X(03)00070-8; Sparck Jones K., 1981, INFORM RETRIEVAL EXP, P213; Sprinzak E, 2003, J MOL BIOL, V327, P919, DOI 10.1016/S0022-2836(03)00239-0; Tong AHY, 2004, SCIENCE, V303, P808, DOI 10.1126/science.1091317; Uetz P, 2000, NATURE, V403, P623; von Mering C, 2002, NATURE, V417, P399; Witten I., 2000, DATA MINING PRACTICA; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Yamanishi Y, 2004, BIOINFORMATICS, V20, P363, DOI 10.1093/bioinformatics/bth910; Zhang LV, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-38	34	138	146	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585			PROTEINS	Proteins	MAY 15	2006	63	3					490	500		10.1002/prot.20865		11	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	034QR	WOS:000236946200008	16450363	
J	Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartelt, M; Bartko, H; Bastieri, D; Bavikadi, SR; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bretz, T; Britvitch, I; Camara, M; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Danielyan, V; Dazzi, F; De Angelis, A; de los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Jacon, P; Kalekin, O; Kranich, D; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Persic, M; Peruzzo, L; Piccioli, A; Poller, M; Prandini, E; Rhode, W; Rico, J; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, SN; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vardanyan, A; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zapatero, J				Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartelt, M; Bartko, H; Bastieri, D; Bavikadi, SR; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bretz, T; Britvitch, I; Camara, M; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Danielyan, V; Dazzi, F; De Angelis, A; de los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Jacon, P; Kalekin, O; Kranich, D; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Persic, M; Peruzzo, L; Piccioli, A; Poller, M; Prandini, E; Rhode, W; Rico, J; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, SN; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vardanyan, A; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zapatero, J			Discovery of very high energy gamma rays from 1ES 1218+30.4	ASTROPHYSICAL JOURNAL			English	Article						BL Lacertae objects : individual (1ES 1218+30.4); gamma rays : observations	ACTIVE GALACTIC NUCLEI; BL-LACERTAE OBJECTS; TELESCOPE; CATALOG; BLAZAR	The MAGIC collaboration has studied the high-frequency-peaked BL Lac object 1ES 1218 + 30.4, at a redshift z = 0.182, using the MAGIC imaging air Cerenkov telescope located on the Canary Island of La Palma. A gamma-ray signal was observed with 6.4 sigma significance. The differential energy spectrum for an energy threshold of 120 GeV can be fitted by a simple power law, yielding F-E = (8.1 +/- 2.1) x 10(-7)[E/(250 GeV)](-3.0 +/- 0.4) TeV-1 F (E) m(-2) s(-1). During the 6 days of observation in 2005 January, no time variability on timescales of days was found within the statistical errors. The observed integral flux above 350 GeV is nearly a factor of 2 below the upper limit reported by the Whipple collaboration in 2003.	Univ Wurzburg, Lehrstuhl Astron, D-97074 Wurzburg, Germany; Univ Autonoma Barcelona, Inst Fis Altes Energies, E-08193 Bellaterra, Spain; ETH Honggerberg, Inst Particle Phys, CH-8093 Zurich, Switzerland; Univ Complutense Madrid, Grp Altas Energias, Dept Fis Atom Mol & Nucl, E-28040 Madrid, Spain; Univ Autonoma Barcelona, Dept Fis, Grp Fis Radiac, E-08193 Bellaterra, Spain; Univ Dortmund, Fachbereich Phys, D-44227 Dortmund, Germany; Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany; Univ Padua, Dipartimento Fis, I-35131 Padua, Italy; Ist Nazl Fis Nucl, I-35131 Padua, Italy; Univ Udine, Dipartimento Fis, I-33100 Udine, Italy; Ist Nazl Fis Nucl, I-33100 Udine, Italy; Univ Lodz, Inst Fizyki, PL-90236 Lodz, Poland; Yerevan Phys Inst, Cosm Ray Div, Yerevan 375036, Armenia; Tuorla Observ, FI-21500 Piikkio, Finland; Univ Siena, Dipartimento Fis, I-53100 Siena, Italy; Ist Nazl Fis Nucl, I-53100 Siena, Italy; Univ Calif Davis, Dept Phys, Davis, CA 95616 USA; Humboldt Univ, Inst Phys, D-12489 Berlin, Germany; Univ Trieste, Dipartimento Fis, I-34012 Trieste, Italy; Ist Nazl Fis Nucl, I-34012 Trieste, Italy; Inst Yadreni Izsledvaniya & Yadena Energet, BG-1784 Sofia, Bulgaria; Osserv Astron Trieste, INAF, I-34100 Trieste, Italy; Ist Nazl Fis Nucl, I-34100 Trieste, Italy; Univ Pisa, Dipartimento Fis, I-56126 Pisa, Italy; Ist Nazl Fis Nucl, I-56126 Pisa, Italy; Univ Autonoma Barcelona, Inst Ciencies Espai, E-08193 Bellaterra, Spain	Meyer, M (reprint author), Univ Wurzburg, Lehrstuhl Astron, D-97074 Wurzburg, Germany.	meyer@astro.uni-wuerzburg.de	Fernandez, Enrique/L-5387-2014; Tonello, Nadia/L-8065-2014; Moralejo Olaizola, Abelardo/M-2916-2014; De Angelis, Alessandro/B-5372-2009; Mannheim, Karl/F-6705-2012; Flix, Josep/G-5414-2012; Doro, Michele/F-9458-2012; chilingarian, ashot/B-1901-2014; Contreras Gonzalez, Jose Luis/K-7255-2014; Rico, Javier/K-8004-2014; Fernandez, Ester/K-9734-2014; lopez, marcos/L-2304-2014; GAug, Markus/L-2340-2014; Font, Lluis/L-4197-2014; Torres, Diego/F-3009-2015; Antoranz, Pedro/H-5095-2015; Miranda, Jose Miguel/F-2913-2013; Barrio, Juan/L-3227-2014	Fernandez, Enrique/0000-0002-6405-9488; Tonello, Nadia/0000-0003-0550-1667; Moralejo Olaizola, Abelardo/0000-0002-1344-9080; Doro, Michele/0000-0001-9104-3214; chilingarian, ashot/0000-0002-2018-9715; Contreras Gonzalez, Jose Luis/0000-0001-7282-2394; Rico, Javier/0000-0003-4137-1134; lopez, marcos/0000-0002-8791-7908; GAug, Markus/0000-0001-8442-7877; Font, Lluis/0000-0003-2109-5961; Torres, Diego/0000-0002-1522-9065; Antoranz, Pedro/0000-0002-3015-3601; Miranda, Jose Miguel/0000-0002-1472-9690; Barrio, Juan/0000-0002-0965-0259			Aharonian F, 2004, ASTRON ASTROPHYS, V421, P529, DOI 10.1051/0004-6361:20035764; AHARONIAN FA, 1994, ASTROPHYS J, V423, pL5, DOI 10.1086/187222; Albert J, 2006, ASTROPHYS J, V637, pL41, DOI 10.1086/500364; Baixeras C, 2004, NUCL INSTRUM METH A, V518, P188, DOI 10.1016/j.nima.2003.10.057; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bretz T, 2005, AIP CONF PROC, V745, P730; BRETZ T, 2005, P 29 INT COSM RAY C, V4, P315; CORTINA J, 2005, P 29 INT COSM RAY C, V5, P359; Costamante L, 2002, ASTRON ASTROPHYS, V384, P56, DOI 10.1051/0004-6361:20011749; Donato D, 2001, ASTRON ASTROPHYS, V375, P739, DOI 10.1051/0004-6361:20010675; DORNER D, 2005, P 29 INT COSM RAY C, V5, P175; FAZIO GG, 1970, NATURE, V226, P135, DOI 10.1038/226135a0; Gaug M., 2005, P 29 INT COSM RAY C, V5, P375; Hartman RC, 1999, ASTROPHYS J SUPPL S, V123, P79, DOI 10.1086/313231; Hauser MG, 2001, ANNU REV ASTRON ASTR, V39, P249, DOI 10.1146/annurev.astro.39.1.249; Heck D., 1998, 6019 FZKA; Hillas A M, 1985, 19TH P INT COSM RAY, V3, P445; Horan D, 2004, ASTROPHYS J, V603, P51, DOI 10.1086/381430; Kneiske TM, 2004, ASTRON ASTROPHYS, V413, P807, DOI 10.1051/0004-6361:20031542; KRANICH D, 1997, THESIS TU MUNCHEN; Lessard RW, 2001, ASTROPART PHYS, V15, P1, DOI 10.1016/S0927-6505(00)00133-X; LI TP, 1983, ASTROPHYS J, V272, P317, DOI 10.1086/161295; Majumdar P, 2005, P 29 INT COSM RAY C, V5, P203; MANNHEIM K, 1993, ASTRON ASTROPHYS, V269, P67; Mannheim K, 1996, ASTRON ASTROPHYS, V315, P77; Maraschi L., 1992, APJ, V397, P5, DOI DOI 10.1086/186531; Mucke A, 2001, ASTROPART PHYS, V15, P121, DOI 10.1016/S0927-6505(00)00141-9; PADOVANI P, 1995, ASTROPHYS J, V444, P567, DOI 10.1086/175631; PUNCH M, 1992, NATURE, V358, P477, DOI 10.1038/358477a0; Riegel B., 2005, P 29 INT COSM RAY C, V5, P215; STECKER F. W., 1992, APJ, V390, P49; Veron-Cetty MP, 2003, ASTRON ASTROPHYS, V412, P399, DOI 10.1051/0004-6361:20034225; WHITE N, 2000, WGA CATALOGUE ROSAT	33	74	74	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X			ASTROPHYS J	Astrophys. J.	MAY 10	2006	642	2	2				L119	L122		10.1086/504845		4	Astronomy & Astrophysics	Astronomy & Astrophysics	042UD	WOS:000237554300009		
J	Ma, SG; Song, X; Huang, J				Ma, Shuangge; Song, Xiao; Huang, Jian			Regularized binormal ROC method in disease classification using microarray data	BMC BIOINFORMATICS			English	Article							GENE-EXPRESSION DATA; DIAGNOSTIC-ACCURACY; SELECTION; CANCER; DISCRIMINATION; BIOMARKERS; REGRESSION; MODELS; LASSO; TESTS	Background: An important application of microarrays is to discover genomic biomarkers, among tens of thousands of genes assayed, for disease diagnosis and prognosis. Thus it is of interest to develop efficient statistical methods that can simultaneously identify important biomarkers from such high-throughput genomic data and construct appropriate classification rules. It is also of interest to develop methods for evaluation of classification performance and ranking of identified biomarkers. Results: The ROC (receiver operating characteristic) technique has been widely used in disease classification with low dimensional biomarkers. Compared with the empirical ROC approach, the binormal ROC is computationally more affordable and robust in small sample size cases. We propose using the binormal AUC (area under the ROC curve) as the objective function for two-sample classification, and the scaled threshold gradient directed regularization method for regularized estimation and biomarker selection. Tuning parameter selection is based on V-fold cross validation. We develop Monte Carlo based methods for evaluating the stability of individual biomarkers and overall prediction performance. Extensive simulation studies show that the proposed approach can generate parsimonious models with excellent classification and prediction performance, under most simulated scenarios including model mis-specification. Application of the method to two cancer studies shows that the identified genes are reasonably stable with satisfactory prediction performance and biologically sound implications. The overall classification performance is satisfactory, with small classification errors and large AUCs. Conclusion: In comparison to existing methods, the proposed approach is computationally more affordable without losing the optimality possessed by the standard ROC method.	Univ Washington, Dept Biostat, Seattle, WA 98195 USA; Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA; Univ Iowa, Program Publ Hlth Genet, Iowa City, IA 52242 USA	Ma, SG (reprint author), Univ Washington, Dept Biostat, Seattle, WA 98195 USA.	shuangge@u.washington.edu; songx@u.washington.edu; jian@stat.uiowa.edu					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ben-Dor A., 2000, P 4 ANN INT C COMP M; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cui XG, 2005, BIOSTATISTICS, V6, P59, DOI 10.1093/biostatistics/kxh018; DABNEY AR, 2005, BIOINFORMATICS, V22, P4148; DETTLING M, 2003, BIOINFORMATICS, V9, P1061; DIACONIS P, 1983, SCI AM, V248, P116; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Efron B, 2004, ANN STAT, V32, P407; Friedman JH, 2004, GRADIENT DIRECTED RE; Ghosh D, 2005, J BIOMED BIOTECHNOL, P147, DOI 10.1155/JBB.2005.147; GUI J, 2005, P PSB; HANLEY JA, 1988, MED DECIS MAKING, V8, P197, DOI 10.1177/0272989X8800800308; Hanley JA, 1996, STAT MED, V15, P1575, DOI 10.1002/(SICI)1097-0258(19960730)15:14<1575::AID-SIM283>3.0.CO;2-2; HASTIE T, 2001, ELEMENTS STATISTICAL; KOSOROK MR, IN PRESS ANN STAT; Liu AY, 2005, STAT MED, V24, P37, DOI 10.1002/sim.1922; Ma S, 2006, BIOMETRICS, V62, P202, DOI 10.1111/j.1541-0420.2005.00405.x; Ma SG, 2005, BIOINFORMATICS, V21, P4356, DOI 10.1093/bioinformatics/bti724; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Pepe M. S., 2003, STAT EVALUATION MED; Pepe MS, 2004, AM J EPIDEMIOL, V159, P882, DOI 10.1093/aje/kwh101; Pepe MS, 2006, BIOMETRICS, V62, P221, DOI 10.1111/j.1541-0420.2005.00420.x; POCHET N, 2004, BIOINFORMATICS, V17, P3185; SPANG R, 2001, P GERM C BIOINF; SWETS JA, 1986, PSYCHOL BULL, V99, P100, DOI 10.1037/0033-2909.99.1.100; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; TSAI CA, 2005, J BIOPHARMACEUTICAL, V14, P985; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; WAHBA G, 1990, CBMS NSF REG C SER; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998	33	16	16	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAY 9	2006	7								253	10.1186/1471-2105-7-253		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	067LJ	WOS:000239303600001	16684357	
J	Kim, Y; Street, WN; Menczer, F				Kim, Y; Street, WN; Menczer, F			Optimal ensemble construction via meta-evolutionary ensembles	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						optimal ensemble; evolutionary ensemble; feature selection; neural networks; diversity of ensemble; ensemble size	FEATURE SUBSET-SELECTION; ALGORITHMS	In this paper, we propose a meta-evolutionary approach to improve on the performance of individual classifiers. In the proposed system, individual classifiers evolve, competing to correctly classify test points, and are given extra rewards for getting difficult points right. Ensembles consisting of multiple classifiers also compete for member classifiers, and are rewarded based on their predictive performance. In this way we aim to build small-sized optimal ensembles rather than form large-sized ensembles of individually-optimized classifiers. Experimental results on 15 data sets suggest that our algorithms can generate ensembles that are more effective than single classifiers and traditional ensemble methods. (c) 2005 Elsevier Ltd. All rights reserved.	Utah State Univ, Business Informat Syst, Logan, UT 84322 USA; Univ Iowa, Iowa City, IA 52242 USA; Indiana Univ, Sch Informat, Bloomington, IN 47406 USA	Kim, Y (reprint author), Utah State Univ, Business Informat Syst, Logan, UT 84322 USA.	yong.kim@usu.edu; nick-street@uiowa.edu; fil@indiana.edu	Kim, Yong Seog/B-9421-2013				Blake C. L., 1998, UCI REPOSITORY MACHI; Bradley P. S., 1998, INFORMS Journal on Computing, V10, DOI 10.1287/ijoc.10.2.209; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L., 1996, 460 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, 567 U CAL DEP STAT; Cunningham P, 2000, TCDCS200002 TRIN COL; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Guerra-Salcedo C, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P236; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HO TK, 1998, P 14 INT C PATT REC, P545; Kim Y, 2005, MANAGE SCI, V51, P264, DOI 10.1287/mnsc.1040.0296; KIM Y, 2002, INTELLIGENT DATA ANA, V6, P2; KITTLER J, 1986, HDB PATTERN RECOGNIT, P203; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Menczer F, 2000, EVOL COMPUT, V8, P223, DOI 10.1162/106365600568185; Opitz D. W., 1996, Connection Science, V8, DOI 10.1080/095400996116802; Opitz DW, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P379; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1995, P 14 INT JOINT C ART, P1019; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609	30	18	18	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	MAY	2006	30	4					705	714		10.1016/j.eswa.2005.07.030		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	022IH	WOS:000236048400015		
J	Zhou, XB; Wong, STC				Zhou, XB; Wong, STC			Informatics challenges of high-throughput microscopy	IEEE SIGNAL PROCESSING MAGAZINE			English	Article							CLASSIFICATION; PATTERNS; IMAGES; CELLS		Harvard Univ, Sch Med, Harvard Ctr Neurodegenerat & Repair, Ctr Bioinformat, Cambridge, MA 02138 USA; Brigham & Womens Hosp, Dept Radiol, Boston, MA 02115 USA	Zhou, XB (reprint author), Harvard Univ, Sch Med, Harvard Ctr Neurodegenerat & Repair, Ctr Bioinformat, Cambridge, MA 02138 USA.	zhou@crystal.harvard.edu; stephen-wong@hms.harbard.edu	Magazine, Signal Processing/E-9947-2015				Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213; Boutros M, 2004, SCIENCE, V303, P832, DOI 10.1126/science.1091266; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cheezum MK, 2001, BIOPHYS J, V81, P2378; Chen X, 2005, J BIOMED BIOTECHNOL, P87, DOI 10.1155/JBB.2005.87; CHEN X, IN PRESS IEEE T BIOM; CHRISTOPHE Z, 2002, IEEE T MED IMAGING, V21, P1212; Ehrlich M, 2004, CELL, V118, P591, DOI 10.1016/j.cell.2004.08.017; EILS R, 2004, J CELL BIOL, V161, P477; GALLARDO G, 2004, MEDM IMAGM P SPIE, V5337, P661; Goldberg IG, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-5-r47; Huang K., 2002, P 2002 IEEE INT S BI, P325; Huang K, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-78; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; Kevorkov D, 2005, J BIOMOL SCREEN, V10, P557, DOI 10.1177/1087057105276989; Perlman ZE, 2004, SCIENCE, V306, P1194, DOI 10.1126/science.1100709; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RIPLEY BD, 1976, J APPL PROBAB, V13, P255, DOI 10.2307/3212829; SCHENA M, 2002, GUIDE ANAL DNA MICRO; Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI [10.1117/1.1631315, 10.1117/1.16313161]; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; WONG STC, 1998, MED IMAGE DATABASES; Yarrow JC, 2003, COMB CHEM HIGH T SCR, V6, P279; ZHOU X, IN PRESS LIFE SCI DA; ZHOU X, IN PRESS J BIOMED IN; ZHOU X, IN PRESS IEEE SIGNAL; Zhou XB, 2005, LECT NOTES COMPUT SC, V3749, P885; ZHOU XB, 2005, P IEEE C CIRC SYST K	30	48	50	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-5888			IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	MAY	2006	23	3					63	72				10	Engineering, Electrical & Electronic	Engineering	040FW	WOS:000237365400011		
J	Rokach, L; Maimon, O; Arbel, R				Rokach, L; Maimon, O; Arbel, R			Selective voting - Getting more for less in sensor fusion	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						decision trees; ensemble methods; selective voting; performance measures; information fusion; machine learning	DECISION TREES; CLASSIFIERS	Many real life problems are characterized by the structure of data derived from multiple sensors. The sensors may be independent, yet their information considers the same entities. Thus, there is a need to efficiently use the information rendered by numerous datasets emanating from different sensors. A novel methodology to deal with such problems is suggested in this work. Measures for evaluating probabilistic classification are used in a new efficient voting approach called "selective voting", which is designed to combine the classification of the models (sensor fusion). Using "selective voting", the number of sensors is decreased significantly while the performance of the integrated model's classification is increased. This method is compared to other methods designed for combining multiple models as well as demonstrated on a real-life problem from the field of human resources.	Ben Gurion Univ Negev, Dept Informat Syst Engn, IL-84105 Beer Sheva, Israel; Tel Aviv Univ, Dept Ind Engn, IL-69978 Tel Aviv, Israel	Rokach, L (reprint author), Ben Gurion Univ Negev, Dept Informat Syst Engn, IL-84105 Beer Sheva, Israel.	liorrk@qu.ac.il; maimon@eng.tau.ac.il; rubishag@zalbav.net.il					Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; AN A, 2001, IEEE INT C DAT MIN, P1; Bahler D., 2000, 17 NAT C ART INT AAA; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chan P., 1995, P 12 INT C MACH LEAR, P90; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Levin N, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1261, DOI 10.1007/0-387-25465-X_61; LIU H, 2004, EMPIRICAL STUDY BUIL, P622; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; MCKENDALL R, 1992, DATA FUSION ROBOTICS, P211; MERZ CJ, 1995, P 5 INT WORKSH ART I, P386; ORTEGA J, 1995, AAAI 96 WORKSH INT M; PRODROMODIS L, CUCS01799; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247; Sharkey A.J., 1999, COMBINING ARTIFICIAL, P1; Singhal A, 1997, P SOC PHOTO-OPT INS, V3209, P2, DOI 10.1117/12.287628; Spengler M., 2001, INT WORKSH COMP VIS, P94; TING KM, 1996, 9619 U WAIK DEP COMP; TING KM, 1997, P 9 EUR C MACH LEARN, P250; Torra V, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1005, DOI 10.1007/0-387-25465-X_47; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zhou ZH, 2003, LECT NOTES ARTIF INT, V2639, P476	27	26	27	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAY	2006	20	3					329	350		10.1142/S0218001406004739		22	Computer Science, Artificial Intelligence	Computer Science	052XA	WOS:000238266100001		
J	Plewczynski, D; Spieser, SAH; Koch, U				Plewczynski, D; Spieser, SAH; Koch, U			Assessing different classification methods for virtual screening	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							SUPPORT-VECTOR-MACHINE; LIGAND INTERACTIONS; SCORING FUNCTIONS; LEAD-DISCOVERY; QSAR; SIMILARITY; PREDICTION; INHIBITORS; DESIGN; SET	How well do different classification methods perform in selecting the ligands of a protein target out of large compound collections not used to train the model? Support vector machines, random forest, artificial neural networks, k-nearest-neighbor classification with genetic-algorithm-optimized feature selection, trend vectors, naive Bayesian classification, and decision tree were used to divide databases into molecules predicted to be active and those predicted to be inactive. Training and predicted activities were treated as binary. The database was generated for the ligands of five different biological targets which have been the object of intense drug discovery efforts: HIV-reverse transcriptase, COX2, dihydrofolate reductase, estrogen receptor, and thrombin. We report significant differences in the performance of the methods independent of the biological target and compound class. Different methods can have different applications; some provide particularly high enrichment, others are strong in retrieving the maximum number of actives. We also show that these methods do surprisingly well in predicting recently published ligands of a target on the basis of initial leads and that a combination of the results of different methods in certain cases can improve results compared to the most consistent method.	BioInfoBank Inst, PL-60744 Poznan, Poland; Warsaw Univ, Interdisciplinary Ctr Math & Computat Modeling, Warsaw, Poland; Ist Ric Biol Mol P Angeletti, Merck Res Labs, Dept Chem, I-00040 Pomezia, Italy	Plewczynski, D (reprint author), BioInfoBank Inst, Limanowskiego 24A-16, PL-60744 Poznan, Poland.	darman@bioinfo.pl; uwe_koch@merck.com					Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; Baurin N, 2004, J CHEM INF COMP SCI, V44, P276, DOI 10.1021/ci0341565; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Briem H, 2005, CHEMBIOCHEM, V6, P558, DOI 10.1002/cbic.200400109; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Caron PR, 2001, CURR OPIN CHEM BIOL, V5, P464, DOI 10.1016/S1367-5931(00)00229-5; CHAKRAVORTY SJ, 2004, COMMUNICATION; Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; Evers A, 2005, J MED CHEM, V48, P5448, DOI 10.1021/jm050090o; Ferrara P, 2004, J MED CHEM, V47, P3032, DOI 10.1021/jm030489h; FEUSTON BP, 2004, COMMUNICATION; Guha R, 2005, J CHEM INF MODEL, V45, P800, DOI 10.1021/ci050022a; Guner OF, 2005, IDRUGS, V8, P567; Halperin I, 2002, PROTEINS, V47, P409, DOI 10.1002/prot.10115; Jorissen RN, 2005, J CHEM INF MODEL, V45, P549, DOI 10.1021/ci049641u; Kauffman GW, 2001, J CHEM INF COMP SCI, V41, P1553, DOI 10.1021/ci010073h; Labute P, 1999, Pac Symp Biocomput, P444; LI J, 2005, BIOORGAN MED CHEM, V14, P2209; *MDL INF SYST INC, MACCS DRUG DAT REP; Oprea TI, 2005, J BIOMOL SCREEN, V10, P419, DOI 10.1177/1087057104272660; Oprea TI, 2004, CURR OPIN CHEM BIOL, V8, P349, DOI 10.1016/j.cbpa.2004.06.008; Plewczynski D, 2005, CELL MOL BIOL LETT, V10, P73; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Raymer ML, 1997, J MOL BIOL, V265, P445, DOI 10.1006/jmbi.1996.0746; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Schneider G, 1998, PROG BIOPHYS MOL BIO, V70, P175, DOI 10.1016/S0079-6107(98)00026-1; Sheridan RP, 2000, J CHEM INF COMP SCI, V40, P1456, DOI 10.1021/ci000045j; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P1912, DOI 10.1021/ci049782w; SHERIDAN RP, 1994, J COMPUT AID MOL DES, V8, P323, DOI 10.1007/BF00126749; Sills MA, 2002, J BIOMOL SCREEN, V7, P191, DOI 10.1089/108705702760047709; Stahura FL, 2005, CURR PHARM DESIGN, V11, P1189, DOI 10.2174/1381612053507549; Stahura FL, 2004, COMB CHEM HIGH T SCR, V7, P259; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Wang YH, 2005, J CHEM INF MODEL, V45, P750, DOI 10.1021/ci050041k; Willett P, 2003, BIOCHEM SOC T, V31, P603, DOI 10.1042/BST0310603; Wilton D, 2003, J CHEM INF COMP SCI, V43, P469, DOI 10.1021/ci025586i	36	62	62	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAY	2006	46	3					1098	1106		10.1021/ci050519k		9	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	044FS	WOS:000237658400021	16711730	
J	Hilario, M; Kalousis, A; Pellegrini, C; Muller, M				Hilario, M; Kalousis, A; Pellegrini, C; Muller, M			Processing and classification of protein mass spectra	MASS SPECTROMETRY REVIEWS			English	Review						MS preprocessing; classification; biomarker discovery; data mining; proteomics; machine learning; dimensionality reduction	ENHANCED LASER-DESORPTION; TIME-OF-FLIGHT; SUPPORT VECTOR MACHINES; MALDI-TOF-MS; HIGH-THROUGHPUT PROTEOMICS; MULTIPLY-CHARGED IONS; GENE-EXPRESSION DATA; SPECTROMETRY DATA; OVARIAN-CANCER; ELECTROSPRAY-IONIZATION	Among the many applications of mass spectrometry, biomarker pattern discovery from protein mass spectra has aroused considerable interest in the past few years. While research efforts have raised hopes of early and less invasive diagnosis, they have also brought to light the many issues to be tackled before mass-spectra-based proteomic patterns become routine clinical tools. Known issues cover the entire pipeline leading from sample collection through mass spectrometry analytics to biomorker pattern extraction, validation, and interpretation. This study focuses on the data-analytical phase, which takes as input mass spectra of biological specimens and discovers patterns of peak masses and intensities that discriminate between different pathological states. We survey current work and investigate computational issues concerning the different stages of the knowledge disco very process: exploratory analysis, quality control, and diverse transforms of mass spectra, followed by further dimensionality reduction, classification, and model evaluation. We conclude after a brief discussion of the critical biomedical task of analyzing discovered discriminatory patterns to identify their component proteins as well as interpret and valid ate their biological implications. (c) 2006 Wiley Periodicals, Inc.	Univ Geneva, Dept Comp Sci, Artificial Intelligence Lab, CH-1211 Geneva 4, Switzerland; ETH Honggerberg, Inst Mol Syst Biol, CH-8093 Zurich, Switzerland	Hilario, M (reprint author), Univ Geneva, Dept Comp Sci, Artificial Intelligence Lab, CH-1211 Geneva 4, Switzerland.	Melanie.Hilario@cui.unige.ch	Muller, Markus/B-4974-2011				Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; Adam BL, 2002, CANCER RES, V62, P3609; Adam PJ, 2003, J BIOL CHEM, V278, P6482, DOI 10.1074/jbc.M210184200; Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Alexe G, 2004, PROTEOMICS, V4, P766, DOI 10.1002/pmic.200300574; Allard L, 2004, PROTEOMICS, V4, P2242, DOI 10.1002/pmic.200300809; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Anderle M, 2004, BIOINFORMATICS, V20, P3575, DOI 10.1093/bioinformatics/bth446; Andreev VP, 2003, ANAL CHEM, V75, P6314, DOI 10.1021/ac0301806; ANDREWS R, 1995, SURVEY CRITIQUE TECH; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Bailey T.L., 1993, P 13 INT JOINT C ART, P895; Banez LL, 2003, J UROLOGY, V170, P442, DOI 10.1097/01.ju.0000069431.95404.56; BARAK P, 1995, ANAL CHEM, V67, P2758, DOI 10.1021/ac00113a006; Beer I, 2004, PROTEOMICS, V4, P950, DOI 10.1002/pmic.200300652; Bern Marshall, 2004, Bioinformatics, V20 Suppl 1, pi49, DOI 10.1093/bioinformatics/bth947; BERNDT P, 1999, ELECTROPHORESIS, V20, P2521; Bienvenut WV, 1999, ANAL CHEM, V71, P4800, DOI 10.1021/ac990448m; Binz PA, 1999, ANAL CHEM, V71, P4981, DOI 10.1021/ac990449e; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blueggel M, 2004, CURR PHARM BIOTECHNO, V5, P79, DOI 10.2174/1389201043489648; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; BRAGANETO U, 2003, BIOINFORMATICS, V20, P374; Breen EJ, 2000, ELECTROPHORESIS, V21, P2243, DOI 10.1002/1522-2683(20000601)21:11<2243::AID-ELPS2243>3.0.CO;2-K; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bro R, 1997, CHEMOMETR INTELL LAB, V38, P149, DOI 10.1016/S0169-7439(97)00032-4; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Bylund D, 2002, J CHROMATOGR A, V961, P237, DOI 10.1016/S0021-9673(02)00588-5; Campa MJ, 2003, PROTEOMICS, V3, P1659; Carroll JA, 1996, RAPID COMMUN MASS SP, V10, P1683, DOI 10.1002/(SICI)1097-0231(199610)10:13<1683::AID-RCM716>3.3.CO;2-C; Chamrad DC, 2003, ANAL BIOANAL CHEM, V376, P1014, DOI 10.1007/s00216-003-1995-x; Check E, 2004, NATURE, V429, P496, DOI 10.1038/429496a; Chen Y, 1997, J Biomed Opt, V2, P364, DOI 10.1117/1.429838; Chen YD, 2002, BIOINFORMATICS, V18, P1207, DOI 10.1093/bioinformatics/18.9.1207; Christian NP, 2000, ANAL CHEM, V72, P3327, DOI 10.1021/ac991500h; Clarke W, 2003, ANN SURG, V237, P660, DOI 10.1097/00000658-200305000-00008; Clauser KR, 1999, ANAL CHEM, V71, P2871, DOI 10.1021/ac9810516; CLEAVELAND WS, 1979, J AM STAT ASSOC, V74, P829; Cohens W, 1995, P 12 INT C MACH LEAR, P115; Colinge J, 2003, PROTEOMICS, V3, P1434, DOI 10.1002/pmic.200300489; Coombes KR, 2003, CLIN CHEM, V49, P1615, DOI 10.1373/49.10.1615; COOMBES KR, 2004, UTMDABTR00104; Cover T. M., 1991, ELEMENTS INFORM THEO; Cristianini N., 2000, INTRO SUPPORT VECTOR; Diamandis EP, 2003, CLIN CHEM, V49, P1272, DOI 10.1373/49.8.1272; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Duda R., 2000, PATTERN CLASSIFICATI; Durbin B P, 2002, Bioinformatics, V18 Suppl 1, pS105; Egelhofer V, 2002, ANAL CHEM, V74, P1760, DOI 10.1021/ac011204g; Egelhofer V, 2000, ANAL CHEM, V72, P2741, DOI 10.1021/ac990686h; Eilers PHC, 2004, ANAL CHEM, V76, P404, DOI 10.1021/ac034800e; ERFRON B, 1995, TR477 DEPT STAT U; Fawcett T, 2003, ROC GRAPHS NOTES PRA; FEELDERS A, 1995, P 5 INT WORKSH ART I, P219; Felitsyn N, 2002, INT J MASS SPECTROM, V219, P39, DOI 10.1016/S1387-3806(02)00588-2; FENN JB, 1989, SCIENCE, V246, P64, DOI 10.1126/science.2675315; Fleming CM, 1999, J CHROMATOGR A, V849, P71, DOI 10.1016/S0021-9673(99)00553-1; Forshed J, 2003, ANAL CHIM ACTA, V487, P189, DOI 10.1016/S0003-2670(03)00570-1; Fraga CG, 2001, ANAL CHEM, V73, P675, DOI 10.1021/ac0010025; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fung E. T., 2002, COMPUTATIONAL PROT S, V32, pS34; Gay S, 1999, ELECTROPHORESIS, V20, P3527, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3527::AID-ELPS3527>3.3.CO;2-0; Gentzel M, 2003, PROTEOMICS, V3, P1597, DOI 10.1002/pmic.200300486; Gobom J, 2002, ANAL CHEM, V74, P3915, DOI 10.1021/ac011203o; Graber A, 2004, PROTEOMICS, V4, P474, DOI 10.1002/pmic.200300566; Gras R, 1999, ELECTROPHORESIS, V20, P3535, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3535::AID-ELPS3535>3.3.CO;2-A; Grizzle WE, 2004, UROL ONCOL-SEMIN ORI, V22, P337, DOI 10.1016/j.urolonc.2004.04.008; GRUSHKA E, 1990, ANAL CHEM, V62, P717, DOI 10.1021/ac00206a014; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, P BISC FLINT CIBI 20; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastings CA, 2002, RAPID COMMUN MASS SP, V16, P462, DOI 10.1002/rcm.600; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hilario M, 2003, PROTEOMICS, V3, P1716, DOI 10.1002/pmic.200300523; Huang Xiaohong, 2002, Funct Integr Genomics, V2, P126, DOI 10.1007/s10142-002-0066-2; Huber W, 2002, BIOINFORMATICS, V18, pS96, DOI DOI 10.1093/BI0INF0RMATICS/18.SUPPL_; Izmirlian G, 2004, ANN NY ACAD SCI, V1020, P154, DOI 10.1196/annals.1310.015; Jain N, 2003, BIOINFORMATICS, V19, P1945, DOI 10.1093/bioinformatics/btg264; Jarman KH, 2003, CHEMOMETR INTELL LAB, V69, P61, DOI 10.1016/S0169-7439(03)00113-8; Johnson KJ, 2003, J CHROMATOGR A, V996, P141, DOI 10.1016/S0021-9673(03)00616-2; JONG K, 2004, APPL EVOLUTIONARY CO; JONG K, 2004, IEEE S COMP INT BIOI, P41, DOI 10.1109/CIBCB.2004.1393930; KARAS M, 1988, ANAL CHEM, V60, P2299, DOI 10.1021/ac00171a028; Kiers HAL, 1999, J CHEMOMETR, V13, P275, DOI 10.1002/(SICI)1099-128X(199905/08)13:3/4<275::AID-CEM543>3.0.CO;2-B; King R, 2000, J AM SOC MASS SPECTR, V11, P942, DOI 10.1016/S1044-0305(00)00163-X; Kira K., 1992, P 10 NAT C ART INT, P129; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, P 14 INT JOINT C AI; Kohonen T., 1995, SELF ORG MAPS; KONONEKO I, 2004, P EUR C MACH LEARN; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; Kratzer R, 1998, ELECTROPHORESIS, V19, P1910, DOI 10.1002/elps.1150191109; Kreil DP, 2004, BIOINFORMATICS, V20, P2026, DOI 10.1093/bioinformatics/bth193; Krutchinsky AN, 2002, J AM SOC MASS SPECTR, V13, P129, DOI 10.1016/S1044-0305(01)00336-1; LANGLEY P, 1996, ELEMENTS MACHINGE LE; Lee KR, 2003, PROTEOMICS, V3, P1680, DOI 10.1002/pmic.200300515; LEE TA, 1991, ANAL CHEM, V63, P357, DOI 10.1021/ac00004a011; Li JN, 2002, CLIN CHEM, V48, P1296; Li JW, 1997, ANAL CHEM, V69, P4452, DOI 10.1021/ac970481d; Li JY, 2003, BIOINFORMATICS, V19, pII93, DOI 10.1093/bioinformatics/btg1066; Li LP, 2004, BIOINFORMATICS, V20, P1638, DOI 10.1093/bioinformatics/bth098; Lilien RH, 2003, J COMPUT BIOL, V10, P925, DOI 10.1089/106652703322756159; Liu Huiqing, 2002, Genome Inform, V13, P51; MALMQUIST G, 1994, J CHROMATOGR A, V687, P89, DOI 10.1016/0021-9673(94)00727-6; MANN M, 1989, ANAL CHEM, V61, P1702, DOI 10.1021/ac00190a023; Marchetti N, 2004, ANAL CHEM, V76, P3055, DOI 10.1021/ac035312+; Model Fabian, 2002, Bioinformatics, V18 Suppl 1, pS155; Mohammad-Djafari A, 2002, INT J MASS SPECTROM, V215, P175, DOI 10.1016/S1387-3806(01)00562-0; MUDDIMAN DC, 1995, ANAL CHEM, V67, P4371, DOI 10.1021/ac00119a027; Muller M, 2002, PROTEOMICS, V2, P1413; Muller M, 2002, J AM SOC MASS SPECTR, V13, P221, DOI 10.1016/S1044-0305(01)00358-0; MULLER MJ, 2003, MOL SCANNER DATA ANA; Neville P, 2003, PROTEOMICS, V3, P1710, DOI 10.1002/pmic.200300516; Nielsen NPV, 1998, J CHROMATOGR A, V805, P17, DOI 10.1016/S0021-9673(98)00021-1; Palmblad M, 2001, J AM SOC MASS SPECTR, V12, P1153, DOI 10.1016/S1044-0305(01)00301-4; Papadopoulos MC, 2004, LANCET, V363, P1358, DOI 10.1016/S0140-6736(04)16046-7; Peng WP, 2004, MASS SPECTROM REV, V23, P443, DOI 10.1002/mas.20002; Pepe MS, 2000, J AM STAT ASSOC, V95, P308, DOI 10.2307/2669554; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Petricoin E, 2003, CLIN CHEM, V49, P1276, DOI 10.1373/49.8.1276; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; Powell DA, 2002, J BIOMED OPT, V7, P650, DOI 10.1117/1.1501561; Prados J, 2004, PROTEOMICS, V4, P2320, DOI 10.1002/pmic.200400857; Press W. H., 1995, NUMERICAL RECIPES C; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Purohit PV, 2003, PROTEOMICS, V3, P1699, DOI 10.1002/pmic.200300518; Qu YS, 2002, CLIN CHEM, V48, P1835; Qu YS, 2003, BIOMETRICS, V59, P143, DOI 10.1111/1541-0420.00017; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1994, COMPUTATIONAL LEARNI, V1, P446; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; REINHOLD BB, 1992, J AM SOC MASS SPECTR, V3, P207, DOI 10.1016/1044-0305(92)87004-I; Rockwood AL, 1996, ANAL CHEM, V68, P2027, DOI 10.1021/ac951158i; ROCKWOOD AL, 1995, ANAL CHEM, V67, P2699, DOI 10.1021/ac00111a031; Rogers MA, 2003, CANCER RES, V63, P6971; Sadygov RG, 2002, J PROTEOME RES, V1, P211, DOI 10.1021/pr015514r; Samuelsson J, 2004, BIOINFORMATICS, V20, P3628, DOI 10.1093/bioinformatics/bth460; Satten GA, 2004, BIOINFORMATICS, V20, P3128, DOI 10.1093/bioinformatics/bth372; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; Schmidt F, 2003, J AM SOC MASS SPECTR, V14, P943, DOI 10.1016/S1044-0305(03)00345-3; SCHOLFKOPF B, 2004, KERNEL METHODS COMPU; Scholkopf B, 2003, NATO SC S SS III C S, V183, P1; SENKO MW, 1995, J AM SOC MASS SPECTR, V6, P52, DOI 10.1016/1044-0305(94)00091-D; Shackman JG, 2004, J CHROMATOGR A, V1040, P273, DOI 10.1016/j.chroma.2004.04.004; Shao XG, 2003, ACCOUNTS CHEM RES, V36, P276, DOI 10.1021/ar990163w; Shao XG, 1997, ANAL CHEM, V69, P1722, DOI 10.1021/ac9608679; Shi SDH, 1998, P NATL ACAD SCI USA, V95, P11532, DOI 10.1073/pnas.95.20.11532; Simon R, 2003, J NATL CANCER I, V95, P14; Soille P., 2003, MORPHOLOGICAL IMAGE; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Tammen H, 2004, CLIN CHEM, V50, P545, DOI 10.1373/clinchem.2003.028209; Tang KQ, 2004, J AM SOC MASS SPECTR, V15, P1416, DOI 10.1016/j.jasms.2004.04.034; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; TUKEY JW, 1993, CONTROL CLIN TRIALS, V14, P266, DOI 10.1016/0197-2456(93)90225-3; TURNEY P, 1995, MACH LEARN, V20, P23, DOI 10.1007/BF00993473; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik V., 1998, STAT LEARNING THEORY; Venable JD, 2004, NAT METHODS, V1, P39, DOI 10.1038/NMETH705; Vestal M, 1998, J AM SOC MASS SPECTR, V9, P892, DOI 10.1016/S1044-0305(98)00069-5; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519; WAGNER M, 2004, BMC BIOINFORMATICS, P5; Wallace WE, 2004, ANAL CHEM, V76, P2446, DOI 10.1021/ac0354701; WANG CP, 1987, ANAL CHEM, V59, P649, DOI 10.1021/ac00131a023; Wang MZ, 2003, PROTEOMICS, V3, P1661, DOI 10.1002/pmic.200300513; Washburn MP, 2001, NAT BIOTECHNOL, V19, P242, DOI 10.1038/85686; WATKINS B, 2001, AM LAB, V32, P31; Windig W, 1996, ANAL CHEM, V68, P3602, DOI 10.1021/ac960435y; WOLFKUHLE J, 2003, NATURE REV, V3, P267; WOLPERT DH, 1992, LAUR903460; Won Y, 2003, PROTEOMICS, V3, P2310, DOI 10.1002/pmic.200300590; Wool A, 2002, PROTEOMICS, V2, P1365, DOI 10.1002/1615-9861(200210)2:10<1365::AID-PROT1365>3.0.CO;2-9; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Zhang ZQ, 1997, J AM SOC MASS SPECTR, V8, P659, DOI 10.1016/S1044-0305(97)82982-0; Zhang ZQ, 1998, J AM SOC MASS SPECTR, V9, P225, DOI 10.1016/S1044-0305(97)00284-5; Zhang ZQ, 1999, ANAL CHEM, V71, P39, DOI 10.1021/ac980724h; Zhu HT, 2003, PROTEOMICS, V3, P1673, DOI 10.1002/pmic.200300520; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100; Zien A, 2001, Bioinformatics, V17 Suppl 1, pS323	192	90	94	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0277-7037			MASS SPECTROM REV	Mass Spectrom. Rev.	MAY-JUN	2006	25	3					409	449		10.1002/mas.20072		41	Spectroscopy	Spectroscopy	031GQ	WOS:000236693000003	16463283	
J	Norinder, U; Liden, P; Bostrom, H				Norinder, Ulf; Liden, Per; Bostrom, Henrik			Discrimination between modes of toxic action of phenols using rule based methods	MOLECULAR DIVERSITY			English	Article						2-D descriptors; ensembles; phenols; rule-based modelling; toxic action	PREDICTION; QSAR	Rule-based ensemble modelling has been used to develop a model with high accuracy and predictive capabilities for distinguishing between four different modes of toxic action for a set of 220 phenols. The model not only predicts the majority class (polar narcotics) well but also the other three classes (weak acid respiratory uncouplers, pro-electrophiles and soft electrophiles) of toxic action despite the severely skewed distribution among the four investigated classes. Furthermore, the investigation also highlights the merits of using ensemble (or consensus) modelling as an alternative to the more traditional development of a single model in order to promote robustness and accuracy with respect to the predictive capability for the derived model.	AstraZeneca R&D, SE-15185 Sodertalje, Sweden; Compumine AB, SE-75183 Uppsala, Sweden; Stockholm Univ, SE-16440 Kista, Sweden; Royal Inst Technol, SE-16440 Kista, Sweden	Norinder, U (reprint author), AstraZeneca R&D, SE-15185 Sodertalje, Sweden.	ulf.norinder@astrazeneca.com					Aptula AO, 2002, QUANT STRUCT-ACT REL, V21, P12, DOI 10.1002/1521-3838(200205)21:1<12::AID-QSAR12>3.0.CO;2-M; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CRONIN MTD, 1995, QUANT STRUCT-ACT REL, V14, P1, DOI 10.1002/qsar.19950140102; Dearden JC, 2003, J COMPUT AID MOL DES, V17, P119, DOI 10.1023/A:1025361621494; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Garg R, 2001, CRIT REV TOXICOL, V31, P223, DOI 10.1080/20014091111686; Greene N, 2002, ADV DRUG DELIVER REV, V54, P417, DOI 10.1016/S0169-409X(02)00012-1; Karabunarliev S, 2003, J MOL STRUC-THEOCHEM, V622, P53, DOI 10.1016/S0166-1280(02)00617-6; Michie D., 1995, MACHINE LEARNING NEU; Olsson T., SELMA SYNTHESIS STRU; Pudenz S, 2002, ECOTOXICOLOGY, V11, P337, DOI 10.1023/A:1020501204807; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ren S, 2003, CHEMOSPHERE, V53, P1053, DOI 10.1016/S0045-6535(03)00573-3; Schultz TW, 2003, J MOL STRUC-THEOCHEM, V622, P1, DOI 10.1016/S0166-1280(02)00614-0; SCHULTZ TW, 1990, EURO CH ENV, V1, P241; Zmuidinavicius D, 2003, CURR TOP MED CHEM, V3, P1301, DOI 10.2174/1568026033451989	17	12	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1381-1991			MOL DIVERS	Mol. Divers.	MAY	2006	10	2					207	212		10.1007/s11030-006-9019-3		6	Biochemistry & Molecular Biology; Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	077LR	WOS:000240031400011	16721627	
J	Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartelt, M; Bartko, H; Bastieri, D; Bavikadi, R; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bretz, T; Britvitch, I; Camara, M; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Danielyan, V; Dazzi, F; De Angelis, A; De Los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Jacon, P; Kalekin, O; Kranich, D; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Persic, M; Peruzzo, L; Piccioli, A; Prandini, E; Rhode, W; Rico, J; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, S; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vardanyan, A; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zapatero, J				Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartelt, M; Bartko, H; Bastieri, D; Bavikadi, R; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bretz, T; Britvitch, I; Camara, M; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Danielyan, V; Dazzi, F; De Angelis, A; De Los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Jacon, P; Kalekin, O; Kranich, D; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Persic, M; Peruzzo, L; Piccioli, A; Prandini, E; Rhode, W; Rico, J; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, S; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vardanyan, A; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zapatero, J			Flux upper limit on gamma-ray emission by GRB 050713a from magic telescope observations	ASTROPHYSICAL JOURNAL			English	Article						gamma rays : bursts; gamma rays : observations	ENERGY COSMIC-RAYS; VERY-HIGH-ENERGY; BURSTS; BATSE; GRB-941017; ABSORPTION; COMPONENT; SPECTRA; MODEL	The long-duration gamma-ray burst GRB 050713a was observed by the MAGIC Telescope 40 s after the burst onset and followed up for 37 minutes, until twilight. The observation, triggered by a Swift alert, covered energies above approximate to 175 GeV. Using standard MAGIC analysis, no evidence of a gamma-ray signal was found. As the redshift of the GRB was not measured directly, the flux upper limit estimated by MAGIC is still compatible with the assumption of an unbroken power-law spectrum extending from a few hundred keV to our energy range.	Univ Wurzburg, Lehrstuhl Astron, D-97074 Wurzburg, Germany; Univ Autonoma Barcelona, Inst Fis Altes Energies, E-08193 Barcelona, Spain; ETH Honggerberg, Inst Particle Phys, CH-8093 Zurich, Switzerland; Univ Complutense Madrid, Grp Altas Energias, Dept Fis Atom Mol & Nucl, E-28040 Madrid, Spain; Univ Autonoma Barcelona, Dept Fis, Grp Fis Radiac, E-08193 Barcelona, Spain; Univ Dortmund, Fachbereich Phys, D-44212 Dortmund, Germany; Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany; Univ Padua, Dipartimento Fis, I-35131 Padua, Italy; Ist Nazl Fis Nucl, I-35131 Padua, Italy; Univ Udine, Dipartimento Fis, I-33100 Udine, Italy; Ist Nazl Fis Nucl, I-33100 Udine, Italy; Univ Lodz, Inst Fizyki, PL-90236 Lodz, Poland; Yerevan Phys Inst, Cosm Ray Div, Yerevan 375036, Armenia; Tuorla Observ, FI-21500 Piikkio, Finland; Univ Siena, Dipartimento Fis, I-53100 Siena, Italy; Ist Nazl Fis Nucl, I-53100 Siena, Italy; Univ Calif Davis, Dept Phys, Davis, CA 95616 USA; Humboldt Univ, Inst Phys, D-12489 Berlin, Germany; Osserv Astron Trieste, INAF, I-34131 Trieste, Italy; Ist Nazl Fis Nucl, I-34131 Trieste, Italy; Inst Yadreni Izsledvaniya & Yadena Energet, BG-1784 Sofia, Bulgaria; Univ Pisa, Dipartimento Fis, I-56127 Pisa, Italy; Ist Nazl Fis Nucl, I-56127 Pisa, Italy; Univ Autonoma Barcelona, Inst Ciencies Espai, E-08193 Barcelona, Spain	Albert, J (reprint author), Univ Wurzburg, Lehrstuhl Astron, D-97074 Wurzburg, Germany.		Torres, Diego/F-3009-2015; Antoranz, Pedro/H-5095-2015; Miranda, Jose Miguel/F-2913-2013; Fonseca Gonzalez, Maria Victoria/I-2004-2015; Barrio, Juan/L-3227-2014; Tonello, Nadia/L-8065-2014; De Angelis, Alessandro/B-5372-2009; Moralejo Olaizola, Abelardo/M-2916-2014; Mannheim, Karl/F-6705-2012; Flix, Josep/G-5414-2012; Doro, Michele/F-9458-2012; chilingarian, ashot/B-1901-2014; Contreras Gonzalez, Jose Luis/K-7255-2014; Rico, Javier/K-8004-2014; Fernandez, Ester/K-9734-2014; lopez, marcos/L-2304-2014; GAug, Markus/L-2340-2014; Font, Lluis/L-4197-2014; Fernandez, Enrique/L-5387-2014	Torres, Diego/0000-0002-1522-9065; Antoranz, Pedro/0000-0002-3015-3601; Miranda, Jose Miguel/0000-0002-1472-9690; Fonseca Gonzalez, Maria Victoria/0000-0003-2235-0725; Barrio, Juan/0000-0002-0965-0259; Tonello, Nadia/0000-0003-0550-1667; Moralejo Olaizola, Abelardo/0000-0002-1344-9080; Doro, Michele/0000-0001-9104-3214; chilingarian, ashot/0000-0002-2018-9715; Contreras Gonzalez, Jose Luis/0000-0001-7282-2394; Rico, Javier/0000-0003-4137-1134; lopez, marcos/0000-0002-8791-7908; GAug, Markus/0000-0001-8442-7877; Font, Lluis/0000-0003-2109-5961; Fernandez, Enrique/0000-0002-6405-9488			ALANTE N, 2005, 3747 GCN; Asaoka Y., 2003, P 28 INT COSM RAY C, V5, P2943; Atkins R, 2005, ASTROPHYS J, V630, P996, DOI 10.1086/432501; BAND D, 1993, ASTROPHYS J, V413, P281, DOI 10.1086/172995; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRETZ T, 2005, P 29 INT COSM RAY C, V4, P315; Connaughton V, 1997, ASTROPHYS J, V479, P859, DOI 10.1086/303918; de Jager OC, 2002, ASTROPHYS J, V566, P738, DOI 10.1086/338275; Dermer CD, 2004, ASTRON ASTROPHYS, V418, pL5, DOI 10.1051/0004-6361:20040108; DINGUS BL, 1995, ASTROPHYS SPACE SCI, V231, P187, DOI 10.1007/BF00658613; FALCONE A, 2005, 3581 GCN; Fegan DJ, 1997, J PHYS G NUCL PARTIC, V23, P1013, DOI 10.1088/0954-3899/23/9/004; GALANTE N, 2003, P 28 INT COSM RAY C, V5, P2753; Gaug M., 2005, P 29 INT COSM RAY C, V5, P375; GOLENETSKII S, 2005, 3619 GCN; Gonzalez MM, 2003, NATURE, V424, P749, DOI 10.1038/nature01869; Goodman J., 1986, Astrophysical Journal. Letters to the Editor, V308; GOTTING N, 2003, 1007 GCN; Hillas A M, 1985, 19TH P INT COSM RAY, V3, P445; HURLEY K, 1994, NATURE, V372, P652, DOI 10.1038/372652a0; JARVIS A, 2005, P 29 INT COSM RAY C, V4, P455; Kneiske TM, 2004, ASTRON ASTROPHYS, V413, P807, DOI 10.1051/0004-6361:20031542; Lazzati D, 2004, MON NOT R ASTRON SOC, V347, pL1, DOI 10.1111/j.1365-2966.2004.07387.x; MESZAROS P, 1993, ASTROPHYS J, V418, pL59, DOI 10.1086/187116; MIRZOYAN R, 2005, P 29 INT COSM RAY C, V4, P23; NIKISHOV AI, 1962, PHYS JETP LETT, V41, P392; Paczynski B., 1986, Astrophysical Journal. Letters to the Editor, V308; PALMER TA, 1997, MATH MODELLING WELD, V3, P3; Pe'er A, 2004, ASTROPHYS J, V603, pL1, DOI 10.1086/382872; Preece RD, 2000, ASTROPHYS J SUPPL S, V126, P19, DOI 10.1086/313289; Rolke WA, 2005, NUCL INSTRUM METH A, V551, P493, DOI 10.1016/j.nima.2005.05.068; Ryde F, 2004, ASTROPHYS J, V614, P827, DOI 10.1086/423782; Stern BE, 2004, MON NOT R ASTRON SOC, V352, pL35, DOI 10.1111/j.1365-2966.2004.08163.x; VIETRI M, 1995, ASTROPHYS J, V453, P883, DOI 10.1086/176448; WAXMAN E, 1995, PHYS REV LETT, V75, P386, DOI 10.1103/PhysRevLett.75.386; ZHOU X, 2003, P 28 INT COSM RAY C, V5, P2757	36	36	36	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X			ASTROPHYS J	Astrophys. J.	APR 10	2006	641	1	2				L9	L12		10.1086/503767		4	Astronomy & Astrophysics	Astronomy & Astrophysics	033AK	WOS:000236818100003		
J	Zhang, XG; Lu, X; Shi, Q; Xu, XQ; Leung, HCE; Harris, LN; D Iglehart, J; Miron, A; Liu, JS; Wong, WH				Zhang, XG; Lu, X; Shi, Q; Xu, XQ; Leung, HCE; Harris, LN; D Iglehart, J; Miron, A; Liu, JS; Wong, WH			Recursive SVM feature selection and sample classification for mass-spectrometry and microarray data	BMC BIOINFORMATICS			English	Article							GENE-EXPRESSION PATTERNS; MOLECULAR CLASSIFICATION; PROTEOMIC PATTERNS; BREAST-CANCER; DISCOVERY; SERUM; BIAS	Background: Like microarray-based investigations, high-throughput proteomics techniques require machine learning algorithms to identify biomarkers that are informative for biological classification problems. Feature selection and classification algorithms need to be robust to noise and outliers in the data. Results: We developed a recursive support vector machine (R-SVM) algorithm to select important genes/biomarkers for the classification of noisy data. We compared its performance to a similar, state-of-the-art method (SVM recursive feature elimination or SVM-RFE), paying special attention to the ability of recovering the true informative genes/biomarkers and the robustness to outliers in the data. Simulation experiments show that a 5%-similar to 20% improvement over SVM-RFE can be achieved regard to these properties. The SVM-based methods are also compared with a conventional univariate method and their respective strengths and weaknesses are discussed. R-SVM was applied to two sets of SELDI-TOF-MS proteomics data, one from a human breast cancer study and the other from a study on rat liver cirrhosis. Important biomarkers found by the algorithm were validated by follow-up biological experiments. Conclusion: The proposed R-SVM method is suitable for analyzing noisy high-throughput proteomics and microarray data and it outperforms SVM-RFE in the robustness to noise and in the ability to recover informative features. The multivariate SVM-based method outperforms the univariate method in the classification performance, but univariate methods can reveal more of the differentially expressed features especially when there are correlations between the features.	Tsing Hua Univ, Bioinformat Div, TNLIST, Beijing 100084, Peoples R China; Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China; Harvard Univ, Sch Publ Hlth, Dept Biostat, Boston, MA 02115 USA; Dana Farber Canc Inst, Dept Canc Biol, Boston, MA 02115 USA; Genome Inst Singapore, Med Proteom & Bioanal Sect, Singapore, Singapore; Harvard Univ, Dept Stat, Cambridge, MA 02138 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Zhang, XG (reprint author), Tsing Hua Univ, Bioinformat Div, TNLIST, Beijing 100084, Peoples R China.	xgzhang@tsinghua.edu.cn; xinlu@hsph.harvard.edu; Qian_Shi@dfci.harvard.edu; jxu@escellinternational.com; leunge@gis.a-star.edu.sg; lyndsay_harris@dfci.harvard.edu; JIGLEHART@PARTNERS.ORG; Alexander_Miron@dfci.harvard.edu; jliu@stat.harvard.edu; whwong@stanford.edu					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Barash Y, 2004, BIOINFORMATICS, V20, P839, DOI 10.1093/bioinformatics/btg487; Ben-Dor A., 2000, RECOMB 2000. Proceedings of the Fourth Annual International Conference on Computational Molecular Biology; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Duda R. O., 1973, PATTERN CLASSIFICATI; Fung ET, 2002, BIOTECHNIQUES S, V34-8, P40; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gruvberger S, 2001, CANCER RES, V61, P5979; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hulett MD, 2000, IMMUNOL CELL BIOL, V78, P280, DOI 10.1046/j.1440-1711.2000.00940.x; KOU Z, 2001, P 8 INT C NEUR INF P, V2, P883; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; MUKHERJEE S, 1998, 1677 MIT; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Petricoin EF, 2002, NAT REV DRUG DISCOV, V1, P683, DOI 10.1038/nrd891; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Rai AJ, 2004, ANN NY ACAD SCI, V1022, P286, DOI 10.1196/annals.1318.044; SHI Q, 2005, UNPUB CLIN CANC RES; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Vapnik VN, 1995, NATURE STAT LEARNING; Wu ZJ, 2004, NAT BIOTECHNOL, V22, P656, DOI 10.1038/nbt0604-656b; Xu XQ, 2004, PROTEOMICS, V4, P3235, DOI 10.1002/pmic.200400839; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698; ZHANG X, 2001, RECURSIVE SAMPLE CLA; Zhang X, 1999, NEURAL NETWORKS SIGN, P3	34	106	117	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	APR 10	2006	7								197	10.1186/1471-2105-7-1-197		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	038XT	WOS:000237263600001	16606446	
J	Lombardo, F; Obach, RS; DiCapua, FM; Bakken, GA; Lu, J; Potter, DM; Gao, F; Miller, MD; Zhang, Y				Lombardo, F; Obach, RS; DiCapua, FM; Bakken, GA; Lu, J; Potter, DM; Gao, F; Miller, MD; Zhang, Y			Hybrid mixture discriminant analysis-random forest computational model for the prediction of volume of distribution of drugs in human	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							PLASMA-PROTEIN BINDING; MEAN RESIDENCE TIME; PHARMACOKINETIC PARAMETERS; DISTRIBUTION VALUES; APPARENT VOLUME; BASIC DRUGS; IN-VIVO; RAT	A computational approach is described that can predict the VD,, of new compounds in humans, with an accuracy of within 2-fold of the actual value. A dataset of VD values for 384 drugs in humans was used to train a hybrid mixture discriminant analysis-random forest (MDA-RF) model using 31 computed descriptors. Descriptors included terms describing lipophilicity, ionization, molecular volume, and various molecular fragments. For a test set of 23 proprietary compounds not used in model construction, the geometric mean fold-error (GMFE) was 1.78-fold ( +/- 11.4%). The model was also tested using a leave-class out approach wherein subsets of drugs based on therapeutic class were removed from the training set of 384, the model was recast, and the VD, values for each of the subsets were predicted. GMFE values ranged from 1.46 to 2.94-fold, depending on the subset. Finally, for an additional set of 74 compounds, VD,, predictions made using the computational model were compared to predictions made using previously described methods dependent on animal pharmacokinetic data. Computational VD,, predictions were, on average, 2.13-fold different from the VD,, predictions from animal data. The computational model described can predict human VD, with an accuracy comparable to predictions requiring substantially greater effort and can be applied in place of animal experimentation.	Pfizer Global Res & Dev, Groton Labs, Mol Properties Grp, Groton, CT 06340 USA; Pfizer Global Res & Dev, Groton Labs, Pharmacokinet Grp, Groton, CT 06340 USA; Pfizer Global Res & Dev, Groton Labs, Dynam & Metab Grp, Groton, CT 06340 USA; Pfizer Global Res & Dev, Groton Labs, Computat Chem Grp, Groton, CT 06340 USA; Pfizer Global Res & Dev, Groton Labs, Sci Comp Grp, Groton, CT 06340 USA	Lombardo, F (reprint author), Pfizer Global Res & Dev, Groton Labs, Mol Properties Grp, Groton, CT 06340 USA.	franco.lombardo@novartis.com					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Caldwell GW, 2004, EUR J DRUG METAB PH, V29, P133; Ghafourian T, 2004, J PHARM PHARMACOL, V56, P339, DOI 10.1211/0022357022890; Hastie T., 2001, ELEMENTS STAT LEARNI, P399; HUNT P, 2002, EUROQSAR 2002 BOURN; Lombardo F, 2004, J MED CHEM, V47, P1242, DOI 10.1021/jm030408h; Lombardo F, 2002, J MED CHEM, V45, P2867, DOI 10.1021/jm0200409; LOMBARDO F, 2003, EUROQSAR 2002, P211; Mahmood I, 1998, J PHARM PHARMACOL, V50, P493; Obach RS, 1997, J PHARMACOL EXP THER, V283, P46; OIE S, 1979, J PHARM SCI, V68, P1203, DOI 10.1002/jps.2600680948; Poulin P, 2002, J PHARM SCI, V91, P129, DOI 10.1002/jps.10005; R Development Core Team, 2004, R LANG ENV STAT COMP; SKELL JM, 1988, SAVOL2; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Wajima T, 2003, J PHARM PHARMACOL, V55, P939, DOI 10.1211/0022357021477; Ward KW, 2004, DRUG METAB DISPOS, V32, P612, DOI 10.1124/dmd.32.6.612	18	47	50	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	APR 6	2006	49	7					2262	2267		10.1021/jm050200r		6	Chemistry, Medicinal	Pharmacology & Pharmacy	029VU	WOS:000236593300015	16570922	
J	Pan, W				Pan, W			Incorporating gene functions as priors in model-based clustering of microarray gene expression data	BIOINFORMATICS			English	Article							CLASS PREDICTION; CLASS DISCOVERY; MIXTURE; PATTERNS; CLASSIFICATION; ANNOTATION; PHENOTYPES; PROFILES	Motivation: Cluster analysis of gene expression profiles has been widely applied to clustering genes for gene function discovery. Many approaches have been proposed. The rationale is that the genes with the same biological function or involved in the same biological process are more likely to co-express, hence they are more likely to form a cluster with similar gene expression patterns. However, most existing methods, including model-based clustering, ignore known gene functions in clustering. Results: To take advantage of accumulating gene functional annotations, we propose incorporating known gene functions as prior probabilities in model-based clustering. In contrast to a global mixture model applicable to all the genes in the standard model-based clustering, we use a stratified mixture model: one stratum corresponds to the genes of unknown function while each of the other ones corresponding to the genes sharing the same biological function or pathway; the genes from the same stratum are assumed to have the same prior probability of coming from a cluster while those from different strata are allowed to have different prior probabilities of coming from the same cluster. We derive a simple EM algorithm that can be used to fit the stratified model. A simulation study and an application to gene function prediction demonstrate the advantage of our proposal over the standard method.	Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA	Pan, W (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, MMC 303, Minneapolis, MN 55455 USA.	weip@biostat.umn.edu					Alexandridis R, 2004, BIOINFORMATICS, V20, P2545, DOI 10.1093/bioinformatics/bth281; Al-Shahrour F, 2005, BIOINFORMATICS, V21, P2988, DOI 10.1093/bioinformatics/bti457; Ashburner M, 2000, NAT GENET, V25, P25; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Broet P, 2002, J COMPUT BIOL, V9, P671, DOI 10.1089/106652702760277381; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Carlin B. P., 2000, BAYES EMPIRICAL BAYE, VSecond; Cheng Jill, 2004, J Biopharm Stat, V14, P687, DOI 10.1081/BIP-200025659; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FANG Z, 2006, IN PRESS J BIOMED IN; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Fraley C., 2005, 486 U WASH DEP STAT; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Fraser AG, 2004, NAT GENET, V36, P559, DOI 10.1038/ng1370; Ghosh D, 2002, BIOINFORMATICS, V18, P275, DOI 10.1093/bioinformatics/18.2.275; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Handl J, 2005, BIOINFORMATICS, V21, P3201, DOI 10.1093/bioinformatics/bti517; Hanisch D, 2002, BIOINFORMATICS, V18, P145; HUANG D, 2006, IN PRESS OMICS; HUANG D, 2006, 2006007 U MINN DIV B; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Khatri P, 2005, BIOINFORMATICS, V21, P3587, DOI 10.1093/bioinformatics/bti565; Li H, 2001, GENOME BIOL, V2; Lottaz C, 2005, BIOINFORMATICS, V21, P1971, DOI 10.1093/bioinformatics/bti292; Luan YH, 2003, BIOINFORMATICS, V19, P474, DOI 10.1093/bioinformatics/btg014; McLachlan G, 2002, FINITE MIXTURE MODEL; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; McLachlan GJ, 2003, COMPUT STAT DATA AN, V41, P379, DOI 10.1016/S0167-9473(02)00183-4; Medvedovic M, 2002, BIOINFORMATICS, V18, P1194, DOI 10.1093/bioinformatics/18.9.1194; Mewes HW, 2004, NUCLEIC ACIDS RES, V32, pD41, DOI 10.1093/nar/gkh092; Mootha VK, 2003, NAT GENET, V34, P267, DOI 10.1038/ng1180; Pan W., 2002, GENOME BIOL, V3, pH0009; Pan W, 2005, STAT APPL GENET MO B, V4; Qu Y, 2004, BIOINFORMATICS, V20, P1905, DOI 10.1093/bioinformatics/bth177; Ramoni MF, 2002, P NATL ACAD SCI USA, V99, P9121, DOI 10.1073/pnas.132656399; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tseng GC, 2005, BIOMETRICS, V61, P10, DOI 10.1111/j.0006-341X.2005.031032.x; Vapnik V., 1998, STAT LEARNING THEORY; Wu LF, 2002, NAT GENET, V31, P255, DOI 10.1038/ng906; Xiao Guanghua, 2005, Journal of Bioinformatics and Computational Biology, V3, P1371, DOI 10.1142/S0219720005001612; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977; Zhou XH, 2002, P NATL ACAD SCI USA, V99, P12783, DOI 10.1073/pnas.192159399	46	53	54	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	APR 1	2006	22	7					795	801		10.1093/bioinformatics/btl011		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	025FU	WOS:000236251500004	16434443	
J	Shin, HJ; Markey, MK				Shin, HJ; Markey, MK			A machine learning perspective on the development of clinical decision support systems utilizing mass spectra of blood samples	JOURNAL OF BIOMEDICAL INFORMATICS			English	Review						diagnosis; computer-assisted; spectrum analysis; mass spectrometry; neoplasms; blood; artificial intelligence; signal processing; automatic data processing; pattern recognition; classification	LASER-DESORPTION/IONIZATION-TIME; PROTEOMIC PATTERN DIAGNOSTICS; PROSTATE-SPECIFIC ANTIGEN; OVARIAN-CANCER DETECTION; SERUM-PROTEIN PROFILES; SERVICES TASK-FORCE; CELL LUNG-CANCER; COLORECTAL-CANCER; BREAST-CANCER; PANCREATIC-CANCER	Currently, the best way to reduce the mortality of cancer is to detect and treat it in the earliest stages. Technological advances in genomics and proteomics have opened a new realm of methods for early detection that show potential to overcome the drawbacks of Current strategies. In particular, pattern analysis of mass spectra of blood samples has attracted attention as an approach to early detection of cancer. Mass spectrometry provides rapid and precise measurements of the sizes and relative abundances of the proteins present in a complex biological/chemical mixture. This article presents a review of the development of clinical decision support systems using mass spectrometry from a machine learning perspective. The literature is reviewed in an explicit machine learning framework, the components of which are preprocessing, feature extraction, feature selection, classifier training, and evaluation. (c) 2005 Elsevier Inc. All rights reserved.	Univ Texas, Dept Biomed Engn, Austin, TX 78712 USA; Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA	Markey, MK (reprint author), Univ Texas, Dept Biomed Engn, Austin, TX 78712 USA.	mia.markey@mail.utexas.edu					Abbott A, 1999, NATURE, V402, P715, DOI 10.1038/45350; Adam BL, 2002, CANCER RES, V62, P3609; Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Aebersold R, 2001, CHEM REV, V101, P269, DOI 10.1021/cr990076h; Alexe G, 2004, PROTEOMICS, V4, P766, DOI 10.1002/pmic.200300574; American Cancer Society, 2004, CANC FACTS FIG 2004; ANDERLE M, 2004, BIOINFORMATICS, V446; Anderson NL, 2002, MOL CELL PROTEOMICS, V1, P845, DOI 10.1074/mcp.R200007-MCP200; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Barclay VJ, 1997, ANAL CHEM, V69, P78, DOI 10.1021/ac960638m; Becker S, 2004, ANN SURG ONCOL, V11, P907, DOI 10.1245/ASO.2004.03.557; Bhattacharyya S, 2004, NEOPLASIA, V6, P674, DOI 10.1593/neo.04262; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Boguski MS, 2003, NATURE, V422, P233, DOI 10.1038/nature01515; Brawer MK, 1999, CA-CANCER J CLIN, V49, P264, DOI 10.3322/canjclin.49.5.264; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRODLEY CE, 1996, 13 NAT C ART INT POR, P799; Campa MJ, 2003, CANCER RES, V63, P1652; Cazares LH, 2002, CLIN CANCER RES, V8, P2541; Conrods TP, 2003, EXPERT REV MOL DIAGN, V3, P411, DOI 10.1586/14737159.3.4.411; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; COOMBES KR, 2004, IMPROVED PEAK DETECT; Coombes KR, 2003, CLIN CHEM, V49, P1615, DOI 10.1373/49.10.1615; Cristianini N., 2000, INTRO SUPPORT VECTOR; CRISTIANINI N, 2002, AI MAGAZINE; Dash M., 1997, INTELL DATA ANAL, V1; Diamandis EP, 2003, CLIN CHEM, V49, P1272, DOI 10.1373/49.8.1272; Diamandis EP, 2005, CLIN CANCER RES, V11, P963; Diamandis EP, 2004, MOL CELL PROTEOMICS, V3, P367, DOI 10.1074/mcp.R400007-MCP200; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Dodd LE, 2004, ACAD RADIOL, V11, P462, DOI 10.1016/S1076-6332(03)00814-6; Duda R., 2000, PATTERN CLASSIFICATI; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; EFRON B, 1991, SCIENCE, V253; Efron B, 1993, INTRO BOOTSTRAP; ETZIONI R, 2003, NAT REV, V3; FAHEY MT, 1995, AM J EPIDEMIOL, V141, P680; Feng Z, 2004, PHARMACOGENOMICS, V5, P709, DOI 10.1517/14622416.5.6.709; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; FUNG ET, 2002, BIOTECHNIQUES S; Gamberger D., 1999, INT C MACH LEARN ICM, P143; Green BB, 2003, J AM BOARD FAM PRACT, V16, P233; Grizzle WE, 2003, DIS MARKERS, V19, P185; Grizzle WE, 2004, CLIN CHEM, V50, P1475, DOI 10.1373/clinchem.2004.033456; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Gygi SP, 2000, CURR OPIN CHEM BIOL, V4, P489, DOI 10.1016/S1367-5931(00)00121-6; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Han J., 2001, DATA MINING CONCEPTS; Hastie T., 2002, ELEMENTS STAT LEARNI; Hilario M, 2003, PROTEOMICS, V3, P1716, DOI 10.1002/pmic.200300523; Hu Jianhua, 2005, Briefings in Functional Genomics & Proteomics, V3, P322, DOI 10.1093/bfgp/3.4.322; Humphrey LL, 2002, ANN INTERN MED, V137, P347; HUTCHENS TW, 1993, RAPID COMMUN MASS SP, V7, P576, DOI 10.1002/rcm.1290070703; Issaq HJ, 2002, BIOCHEM BIOPH RES CO, V292, P587, DOI 10.1006/bbrc.2002.6678; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JAPKOWICZ N, 2000, WS0005 MENL PARK; Jeffries NO, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-180; Jemal A, 2004, CA-CANCER J CLIN, V54, P8; Johann DJ, 2003, DIS MARKERS, V19, P197; Keller BO, 2000, J AM SOC MASS SPECTR, V11, P88, DOI 10.1016/S1044-0305(99)00126-9; KNUTZEN AM, 1993, MAYO CLIN PROC, V68, P454; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Koomen JM, 2005, CLIN CANCER RES, V11, P1110; Koomen JM, 2004, RAPID COMMUN MASS SP, V18, P2537, DOI 10.1002/rcm.1657; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; KOPANS DB, 1992, AM J ROENTGENOL, V158, P521; Kotsiantis S.B., 2003, ANN MATH COMPUT TELE, V1, P46; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; Krieg RC, 2002, TECHNOL CANCER RES T, V1, P263; Krutchinsky AN, 2002, J AM SOC MASS SPECTR, V13, P129, DOI 10.1016/S1044-0305(01)00336-1; Kuerer HM, 2004, SURGERY, V136, P1061, DOI 10.1016/j.surg.2004.04.011; Lancashire Lee J., 2005, Current Proteomics, V2, P15, DOI 10.2174/1570164053507808; Lee CH, 2002, RADIOL CLIN N AM, V40, P395, DOI 10.1016/S0033-8389(01)00015-X; Lee KR, 2003, PROTEOMICS, V3, P1680, DOI 10.1002/pmic.200300515; Li J, 2003, BIOINFORMATICS S2, V19, pii93; Li JN, 2002, CLIN CHEM, V48, P1296; Li JN, 2004, J UROLOGY, V171, P1782, DOI 10.1097/01.ju.0000119823.86393.49; Li LH, 2004, ARTIF INTELL MED, V32, P71, DOI 10.1016/j.artmed.2004.03.006; Lilien RH, 2003, J COMPUT BIOL, V10, P925, DOI 10.1089/106652703322756159; Liotta LA, 2003, NATURE, V425, P905, DOI 10.1038/425905a; Liotta LA, 2005, J NATL CANCER I, V97, P310, DOI 10.1093/jnci/dji053; LIU Q, 2003, ASILOMAR C BIOL ASP; Madi A, 2003, ACTA BIOL HUNG, V54, P1, DOI 10.1556/ABiol.54.2003.1.1; Maletic J.I., 2000, INFORM QUALITY IQ200, P200; MALOOF MA, 2003, LEARNING DATA SETS A; Malyarenko DI, 2005, CLIN CHEM, V51, P65, DOI 10.1373/clinchem.2004.037283; Mann M, 2001, ANNU REV BIOCHEM, V70, P437, DOI 10.1146/annurev.biochem.70.1.437; Markey MK, 2003, PROTEOMICS, V3, P1678, DOI 10.1002/pmic.200300521; Mehta AI, 2003, DIS MARKERS, V19, P1; Merchant M, 2000, ELECTROPHORESIS, V21, P1164, DOI 10.1002/(SICI)1522-2683(20000401)21:6<1164::AID-ELPS1164>3.3.CO;2-S; METZ CE, 1986, INVEST RADIOL, V21, P720; MITCHELL TM, 1997, MACNINE LEARING; Neville P, 2003, PROTEOMICS, V3, P1710, DOI 10.1002/pmic.200300516; Ornstein DK, 2004, J UROLOGY, V172, P1302, DOI 10.1097/01.ju.0000139572.88463.39; Orr K, 1998, COMMUN ACM, V41, P66, DOI 10.1145/269012.269023; ORR K, 1998, DATA QUALITY SYSTEMS, P66; Peek ME, 2004, J GEN INTERN MED, V19, P184; Petricoin EF, 2002, J MAMMARY GLAND BIOL, V7, P433, DOI 10.1023/A:1024042200521; Petricoin EF, 2004, PROTEOMICS, V4, P2357, DOI 10.1002/pmic.200400865; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pignone M, 2002, ANN INTERN MED, V137, P132; Pontil M, 1998, NEURAL COMPUT, V10, P955, DOI 10.1162/089976698300017575; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; Prados J, 2004, PROTEOMICS, V4, P2320, DOI 10.1002/pmic.200400857; Purohit PV, 2003, PROTEOMICS, V3, P1699, DOI 10.1002/pmic.200300518; Pusch W, 2003, PHARMACOGENOMICS, V4, P463, DOI 10.1517/phgs.4.4.463.22753; Qu YS, 2002, CLIN CHEM, V48, P1835; Qu YS, 2003, BIOMETRICS, V59, P143, DOI 10.1111/1541-0420.00017; Rai AJ, 2004, ANN NY ACAD SCI, V1022, P286, DOI 10.1196/annals.1318.044; Redman TC, 1998, COMMUN ACM, V41, P79, DOI 10.1145/269012.269025; Rennert G, 2001, CANCER EPIDEM BIOMAR, V10, P1165; Robinson E. A., 1967, STAT COMMUNICATION D; Rodland KD, 2004, CLIN BIOCHEM, V37, P579, DOI 10.1016/j.clinbiochem.2004.05.011; Rosenblatt KP, 2004, ANNU REV MED, V55, P97, DOI 10.1146/annurev.med.55.091902.105237; Satten GA, 2004, BIOINFORMATICS, V20, P3128, DOI 10.1093/bioinformatics/bth372; Semmes OJ, 2005, CLIN CHEM, V51, P102, DOI 10.1373/clinchem.2004.038950; Seraglia R, 2005, J MASS SPECTROM, V40, P123, DOI 10.1002/jms.769; Shamos M., 1985, COMPUTATIONAL GEOMET; Shao XG, 2003, ACCOUNTS CHEM RES, V36, P276, DOI 10.1021/ar990163w; SHIN H, 2004, AM ASS CANC RES AACR; Sidransky D, 2003, J NATL CANCER I, V95, P1711, DOI 10.1093/jnci/djg099; Siuzdak G, 1996, MASS SPECTROMETRY BI; Slotta DJ, 2003, PROTEOMICS, V3, P1687, DOI 10.1002/pmic.200300517; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; SORACE J, 2003, BMC BIOINFORMATICS, V4; Srinivas PR, 2001, CLIN CHEM, V47, P1901; Stone JH, 2005, ARTHRITIS RHEUM, V52, P902, DOI 10.1002/art.20938; TANG N, 2004, MASS SPECTROM REV, V1, P34; Tatay JW, 2003, PROTEOMICS, V3, P1704, DOI 10.1002/pmic.200300512; Valerio A, 2001, RAPID COMMUN MASS SP, V15, P2420, DOI 10.1002/rcm.528; Valerio A, 2004, CLIN CHIM ACTA, V343, P119, DOI 10.1016/j.cccn.2003.12.021; VANDER A, 2001, HUMAN PHYSL; Verma M, 2001, ANN NY ACAD SCI, V945, P103; Vernon SW, 1997, J NATL CANCER I, V89, P1406, DOI 10.1093/jnci/89.19.1406; Vlahou A, 2004, CLIN CHEM, V50, P1438, DOI 10.1373/clinchem.2003.028035; Vlahou A, 2003, ADV EXP MED BIOL, V539, P47; Vlahou A, 2001, AM J PATHOL, V158, P1491, DOI 10.1016/S0002-9440(10)64100-4; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519; Wagner M, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-26; Walsh JME, 2003, JAMA-J AM MED ASSOC, V289, P1297, DOI 10.1001/jama.289.10.1297; Walsh JME, 2003, JAMA-J AM MED ASSOC, V289, P1288, DOI 10.1001/jama.289.10.1288; Wang MZ, 2003, PROTEOMICS, V3, P1661, DOI 10.1002/pmic.200300513; Won Y, 2003, PROTEOMICS, V3, P2310, DOI 10.1002/pmic.200300590; WOOLAS RP, 1993, J NATL CANCER I, V85, P1748, DOI 10.1093/jnci/85.21.1748; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Wu W, 2002, INT J GYNECOL CANCER, V12, P409, DOI 10.1046/j.1525-1438.2002.01200.x; Wulfkuhle JD, 2003, NAT REV CANCER, V3, P267, DOI 10.1038/nrc.1043; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Yates JR, 2000, TRENDS GENET, V16, P5, DOI 10.1016/S0168-9525(99)01879-X; Zhu HT, 2003, PROTEOMICS, V3, P1673, DOI 10.1002/pmic.200300520; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100; Zhukov TA, 2003, LUNG CANCER, V40, P267, DOI 10.1016/S0169-5002(03)00082-5	158	43	48	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	APR	2006	39	2					227	248		10.1016/j.jbi.2005.04.002		22	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	027MQ	WOS:000236420100010	15963765	
J	Geurts, P; Ernst, D; Wehenkel, L				Geurts, P; Ernst, D; Wehenkel, L			Extremely randomized trees	MACHINE LEARNING			English	Article						supervised learning; decision and regression trees; ensemble methods; cut-point randomization; bias/variance tradeoff; kernel-based models	ENSEMBLE METHODS; DECISION TREES; VARIANCE; BIAS; ERROR	This paper proposes anew tree-based ensemble method for supervised classification and regression problems. It essentially consists of randomizing strongly both attribute and cut-point choice while splitting a tree node. In the extreme case, it builds totally randomized trees whose structures are independent of the output values of the learning sample. The strength of the randomization can be tuned to problem specifics by the appropriate choice of a parameter. We evaluate the robustness of the default choice of this parameter, and we also provide insight on how to adjust it in particular situations. Besides accuracy, the main strength of the resulting algorithm is computational efficiency. A bias/variance analysis of the Extra-Trees algorithm is also provided as well as a geometrical and a kernel characterization of the models induced.	Univ Liege, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium	Geurts, P (reprint author), Univ Liege, Dept Elect Engn & Comp Sci, Sart Tilman B-28, B-4000 Liege, Belgium.	P.Geurts@ulg.ac.be; Dernst@ulg.ac.be; L.Wehenkel@ulg.ac.be					Ali K., 1995, LINK ERROR CORRELATI; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1996, ARCING CLASSIFIERS; Breiman L., 2000, 579 U CAL DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Buntine W. L., 1991, Complex Systems, V5; CUTLER A, 2001, COMPUTING SCI STAT, P33; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 1995, MACHINE LEARNING BIA; Ernst D, 2005, J MACH LEARN RES, V6, P503; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; FRIEDMAN C, 2001, BIOINFORMATICS, V1, P1; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GEURTS P, 2000, P 11 EUR C MACH LEAR, P162; Geurts P, 2005, BIOINFORMATICS, V21, P3138, DOI 10.1093/bioinformatics/bti494; Geurts P, 2005, Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology, P194; GEURTS P, 2005, P 9 EUR C PRINC PRAC, P478; GEURTS P, 2002, THESIS U LIEGE; GEURTS P, 2003, EXTREMELY RANDOMIZED; Hastie T., 2001, ELEMENTS STAT LEARNI; HERBRICH R, 2001, J MACHINE LEARNING R, V1, P241; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; KAMATH C, 2002, P 2 SIAM INT C DAT M; Kleinberg E. M., 1990, ANN MATH ARTIFICIAL, V1, P207, DOI 10.1007/BF01531079; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Lin Y., 2002, 1055 U WISC DEP STAT; Maree R., 2004, P 6 AS C COMP VIS, V2, P860; Mingers J., 1989, Machine Learning, V3, DOI 10.1007/BF00116837; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; QUINLAN J, 1986, C4 5 PROGRAMS MACHIN; Torgo L., 1999, THESIS U PORTO; Valentini G, 2004, J MACH LEARN RES, V5, P725; Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; WEHENKEL L, 1997, P INT FUZZ SYST ASS, P381; WEHENKEL L, 1991, AUTOMATICA, V27, P115, DOI 10.1016/0005-1098(91)90010-Y; Wehenkel L., 1996, P INF P MAN UNC, P413; WEHENKEL L, 1998, AUUTOMATIC LEARNING; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; ZHAO G, 2000, THESIS UTAH STATE U; ZHENG Z, 1998, P AUSTR JOINT C ART, P321	49	190	197	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	APR	2006	63	1					3	42		10.1007/s10994-006-6226-1		40	Computer Science, Artificial Intelligence	Computer Science	033LY	WOS:000236850500001		
J	Mas, VR; Maluf, DG; Archer, KJ; Yanek, K; Williams, B; Fisher, RA				Mas, Valeria R.; Maluf, Daniel G.; Archer, Kellie J.; Yanek, Kenneth; Williams, Bridgette; Fisher, Robert A.			Differentially expressed genes between early and advanced hepatocellular carcinoma (HCC) as a potential tool for selecting liver transplant recipients	MOLECULAR MEDICINE			English	Article							TUMOR PROGRESSION; WAITING-LIST; HELICAL CT; CIRRHOSIS; SURVIVAL; CANCER; CHEMOEMBOLIZATION; CLASSIFICATION; MICROARRAYS; RECURRENCE	Hepatocellular carcinoma (HCC) is the fifth most common cancer in the world. Liver transplantation (LT) represents a curative treatment for "small" HCC. Preoperative staging is critical in selecting optimal candidates for LT to optimize the use of this scarce resource. From December 1997 to February 2004, 148 patients diagnosed with cirrhosis and HCC were evaluated at our center. After staging, the patients were listed for LT according to United Network for Organ Sharing (UNOS) criteria. When pretransplant liver MRIs were compared with the findings of the explanted livers, 8 of 35 patients (22.8%) were understaged. Three of the 8 patients (37.5%) had recurrence post-LT. A retrospective gene expression profiling study was done using microarray technology for tumor samples in the pretransplant hepatitis C virus (HCV)-HCC understaged patients and in a contemporaneous group of HCV-HCC patients that were accurately staged. Two sample t tests comparing the early versus advanced HCV-HCCs with respect to gene expression showed an important set of genes differentially expressed among the samples, Hierarchical clustering analysis of the gene expression profiling classified 93.8% of the total tumor samples and 85.7% of the understaged samples in concordance with the explanted pathological staging. We found a distinctive pattern of gene expression between early and advanced HCV-HCCs. These results suggest that gene expression profiling could improve the pre-LT HCC staging to more closely mimic the explant pathology. Whether gene expression profiling of HCC will be refined to the point of predicting potential metastatic biologic behavior to predict post-LT recurrence will require longitudinal prospective study of this gene array technology.	Virginia Commonwealth Univ, Div Transplant Surg, Richmond, VA USA; Virginia Commonwealth Univ, Dept Surg, Richmond, VA USA; Virginia Commonwealth Univ, Dept Pathol, Richmond, VA USA; Virginia Commonwealth Univ, Dept Biostat, Richmond, VA USA	Fisher, RA (reprint author), W Hosp, Dept Surg, Div Transplant, 9th Floor,Room 313,1200 E Broad St,POB 980057, Richmond, VA 23298 USA.	rafisher@vcu.edu					*AM LIV TUM STUD G, 1998, RAND PROSP MULT I TR; Baron RL, 2004, GASTROENTEROLOGY, V127, pS133, DOI 10.1053/j.gastro.2004.09.027; Bolondi L, 2003, ALIMENT PHARM THERAP, V17, P145, DOI 10.1046/j.1365-2036.17.s2.8.x; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bullinger L, 2004, NEW ENGL J MED, V350, P1605, DOI 10.1056/NEJMoa031046; Burrel M, 2003, HEPATOLOGY, V38, P1034, DOI 10.1053/jehp.2003.50409; Child CG, 1964, LIVER PORTAL HYPERTE, P50; DANIELE B, 2004, GASTROENTEROLOGY, V12, pS108; Di Bisceglie AM, 2004, GASTROENTEROLOGY, V127, pS104, DOI 10.1053/j.gastro.2004.09.022; DUMUR CI, 2002, CLIN CHEM, V50, P1994; Dyrskjot L, 2003, NAT GENET, V33, P90, DOI 10.1038/ng1061; El-Serag HB, 1999, NEW ENGL J MED, V340, P745, DOI 10.1056/NEJM199903113401001; Ercolani G, 2003, ANN SURG, V237, P536, DOI 10.1097/00000658-200304000-00016; Fisher RA, 2002, CLIN TRANSPLANT, V16, P52, DOI 10.1034/j.1399-0012.16.s7.8.x; Frederiksen CM, 2003, J CANCER RES CLIN, V129, P263, DOI 10.1007/s00432-003-0434-x; Glanzer JG, 2004, BRIT J CANCER, V90, P1111, DOI 10.1038/sj.bjc.6601668; Graziadei IW, 2003, LIVER TRANSPLANT, V9, P557, DOI 10.1053/jlts.2003.50106; Gross-Goupil M, 2003, INT J CANCER, V104, P745, DOI 10.1002/ijc.11017; Guan XY, 2003, CANCER GENET CYTOGEN, V140, P45, DOI 10.1016/S0165-4608(02)00654-4; Hermanek P, 1992, UICC TNM CLASSIFICAT; Herrero JI, 2001, LIVER TRANSPLANT, V7, P631, DOI 10.1053/jlts.2001.25458; Iizuka N, 2004, INT J ONCOL, V24, P565; IIZUKA N, 2004, CANCER RES, V64, P844; Iizuka N, 2003, ONCOGENE, V22, P3007, DOI 10.1038/sj.onc.1206401; Khakhar A, 2003, TRANSPLANT P, V35, P2438, DOI 10.1016/j.transproceed.2003.08.018; Lee JS, 2004, GASTROENTEROLOGY, V127, pS51, DOI 10.1053/j.gastro.2004.09.015; Li C, 2001, GENOME BIOL, V2, P1; Li C., 2003, ANAL GENE EXPRESSION, P120, DOI 10.1007/0-387-21679-0_5; Liu WC, 2003, EUR RADIOL, V13, P1693, DOI 10.1007/s00330-002-1814-3; Liu WM, 2002, BIOINFORMATICS, V18, P1593, DOI 10.1093/bioinformatics/18.12.1593; Maddala YK, 2004, LIVER TRANSPLANT, V10, P449, DOI 10.1002/lt.20099; Maluf D, 2003, AM J TRANSPLANT, V3, P312, DOI 10.1034/j.1600-6143.2003.00041.x; Marin-Hargreaves G, 2003, CRIT REV ONCOL HEMAT, V47, P13, DOI 10.1016/S1040-8428(02)00213-5; Marsh JW, 2003, LIVER TRANSPLANT, V9, P664, DOI 10.1053/jlts.2003.50144; Mas VR, 2004, LIVER TRANSPLANT, V10, P607, DOI 10.1002/lt.20118; Mazzaferro V, 1996, NEW ENGL J MED, V334, P693, DOI 10.1056/NEJM199603143341104; Nguyen MH, 2002, J CLIN GASTROENTEROL, V35, pS86, DOI 10.1097/00004836-200211002-00004; OKUDA K, 1985, CANCER, V56, P918, DOI 10.1002/1097-0142(19850815)56:4<918::AID-CNCR2820560437>3.0.CO;2-E; OLTHOFF KM, 1998, LIVER TRANSPLANT, V4, P98; Parkin DM, 2001, INT J CANCER, V94, P153, DOI 10.1002/ijc.1440; Schwartz M, 2004, GASTROENTEROLOGY, V127, pS268, DOI 10.1053/j.gastro.2004.09.041; Shimoda M, 2004, LIVER TRANSPLANT, V10, P1478, DOI 10.1012/lt.20303; Shridhar V, 2001, CANCER RES, V61, P5895; Soresi M, 2003, ANTICANCER RES, V23, P1747; Teefey SA, 2003, RADIOLOGY, V226, P533, DOI 10.1148/radiol.2262011980; Hoffman EP, 2004, NAT REV GENET, V5, P229, DOI 10.1038/nrg1297; Tseng TL, 2003, CANCER RES, V63, P647; Valls C, 2004, AM J ROENTGENOL, V182, P1011; Van Thiel DH, 2004, LIVER TRANSPLANT, V10, P631, DOI 10.1002/lt.20120; Zhang L, 2002, J MOL BIOL, V317, P225, DOI 10.1006/jmbi.2001.5350	50	17	19	FEINSTEIN INSTITUTE MED RES	MANHASSET	350 COMMUNITY DRIVE, MANHASSET, NY 11030 USA	1076-1551			MOL MED	Mol. Med.	APR-JUN	2006	12	4-6					97	104		10.2119/2006-00032.Mas		8	Biochemistry & Molecular Biology; Cell Biology; Medicine, Research & Experimental	Biochemistry & Molecular Biology; Cell Biology; Research & Experimental Medicine	085UZ	WOS:000240631200005	16953559	
J	Lin, SM; Devakumar, J; Kibbe, WA				Lin, SM; Devakumar, J; Kibbe, WA			Improved prediction of treatment response using microarrays and existing biological knowledge	PHARMACOGENOMICS			English	Article						classification; knowledge base; microarray; treatment response	ACUTE LYMPHOBLASTIC-LEUKEMIA; GENE-EXPRESSION PROFILES; BREAST-CANCER; REPRODUCIBILITY; SELECTION; SET	A desired application for microarrays in the clinic is to predict treatment response from an often diverse patient population. We present a method for analyzing microarray data that is predicated on biological pathway and function knowledge as opposed to a purely data-driven initial analysis. From an analysis perspective, this methodology takes advantage of information that is available across genes on a single array, as well as differences in those patterns across measurements. By using biological knowledge in the initial analysis, the accuracy and robustness of microarray profile classification is enhanced, especially when low numbers of samples are available. For clinical studies, particularly Phase I or I/II studies, this technique is exceptionally advantageous.	Northwestern Univ, Robert H Lurie Canc Ctr, Chicago, IL 60611 USA; Jubilant Biosys Ltd, Bangalore 560094, Karnataka, India	Kibbe, WA (reprint author), Northwestern Univ, Robert H Lurie Canc Ctr, Chicago, IL 60611 USA.	S-Lin2@northwestern.edu; dr_devakumar@jubilantbiosys.com; wakibbe@northwestern.edu	Kibbe, Warren/B-2106-2010	Kibbe, Warren/0000-0001-5622-7659			Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DePrimo SE, 2003, BMC CANCER, V3, DOI 10.1186/1471-2407-3-3; Downing JR, 2004, NEW ENGL J MED, V351, P528, DOI 10.1056/NEJMp048121; Ein-Dor L, 2005, BIOINFORMATICS, V21, P171, DOI 10.1093/bioinformatics/bth469; Finkelstein D, 2002, PLANT MOL BIOL, V48, P119, DOI 10.1023/A:1013765922672; Gentleman RC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-10-r80; Holleman A, 2004, NEW ENGL J MED, V351, P533, DOI 10.1056/NEJMoa033513; King CL, 2005, J MOL DIAGN, V7, P57, DOI 10.1016/S1525-1578(10)60009-8; Lin SM, 2002, METHODS MICROARRAY D; Ma SG, 2005, BIOINFORMATICS, V21, P4356, DOI 10.1093/bioinformatics/bti724; NowakGottl U, 1996, EUR J HAEMATOL, V56, P35; Piper MDW, 2002, J BIOL CHEM, V277, P37001, DOI 10.1074/jbc.M204490200; SIMON RM, 2003, DESIGN ANAL DNA MICR, P199; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Sullivan R, 1999, J FINANC, V54, P1647, DOI 10.1111/0022-1082.00163; Tian L, 2005, P NATL ACAD SCI USA, V102, P13544, DOI 10.1073/pnas.0506577102; van 't Veer LJ, 2003, BREAST CANCER RES, V5, P57, DOI 10.1186/bcr562; Vapnik V., 1998, STAT LEARNING THEORY; Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Zhu J, 2004, CYTOGENET GENOME RES, V105, P363, DOI 10.1159/000078209	25	5	5	FUTURE MEDICINE LTD	LONDON	UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND	1462-2416			PHARMACOGENOMICS	Pharmacogenomics	APR	2006	7	3					495	501		10.2217/14622416.7.3.495		7	Pharmacology & Pharmacy	Pharmacology & Pharmacy	036LF	WOS:000237071900025	16610959	
J	Paweletz, CP; Wiener, MC; Sachs, JR; Meurer, R; Wu, MS; Wong, KK; Yates, NA; Hendrickson, RC				Paweletz, CP; Wiener, MC; Sachs, JR; Meurer, R; Wu, MS; Wong, KK; Yates, NA; Hendrickson, RC			Surface enhanced laser desorption ionization spectrometry reveals biomarkers for drug treatment but not dose	PROTEOMICS			English	Article						biomarker; proteomic classifier; SELDI	PROTEOMIC PATTERNS; OVARIAN-CANCER; PROTEIN; SERUM; REPRODUCIBILITY	Here we describe the use of SELDI-MS to detect dose-dependent peptide changes in plasma from mice treated with vehicle or rosiglitazone at one of two doses (10 and 30 mg/kg). SELDI features differentiating spectra from the three conditions were found and used to train classifiers. Samples treated with vehicle could be reliably distinguished from samples treated with either dose, but samples treated with the different doses could not be reliably distinguished from one another. We conclude that while SELDI-TOF mass spectra can be used to distinguish treated from untreated samples, the reproducibility and information content of SELDI-TOF are currently not sufficient as a pharmacodynamic readout to distinguish between mice treated with 10 or 30 mg/kg of rosiglitazone. This raises more general questions about whether SELDI's sensitivity is sufficient for detecting dose-dependent changes in plasma.	Merck Res Labs, Dept Mol Profiling Proteom, Rahway, NJ 07065 USA; Merck Res Labs, Dept Comp Sci & Appl Math, Rahway, NJ 07065 USA; Merck Res Labs, Dept Pharmacol, Rahway, NJ 07065 USA; Merck Res Labs, Dept Metab Disorders, Rahway, NJ 07065 USA	Paweletz, CP (reprint author), Merck Res Labs, Dept Mol Profiling Proteom, 126E Lincoln Av, Rahway, NJ 07065 USA.	cloud_paweletz@merck.com					Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; Baker M, 2005, NAT BIOTECHNOL, V23, P297, DOI 10.1038/nbt0305-297; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Combs TP, 2002, ENDOCRINOLOGY, V143, P998, DOI 10.1210/en.143.3.998; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Ebert MPA, 2004, J PROTEOME RES, V3, P1261, DOI 10.1021/pr049865s; MANLEY S, 2003, CLIN CHEM LAB MED, V41, P1259; Paweletz CP, 2000, DRUG DEVELOP RES, V49, P34, DOI 10.1002/(SICI)1098-2299(200001)49:1<34::AID-DDR6>3.0.CO;2-W; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Ripley B. D., 1996, PATTERN RECOGNITION; TONG W, 2004, ENV HLTH PERSPECT, V5, P1622; Wagner JA, 2002, DIS MARKERS, V18, P41; Wiener MC, 2004, ANAL CHEM, V76, P6085, DOI 10.1021/ac0493875; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100	15	7	7	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853			PROTEOMICS	Proteomics	APR	2006	6	7					2101	2107		10.1002/pmic.200500569		7	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	033EL	WOS:000236829300009	16518871	
J	Pan, W; Xiao, GH; Huang, XH				Pan, W; Xiao, GH; Huang, XH			Using input dependent weights for model combination and model selection with multiple sources of data	STATISTICA SINICA			English	Article						classification; microarray data; model mixing; partial least squares; prediction	GENE-EXPRESSION DATA; CROSS-VALIDATION; TUMOR CLASSIFICATION; PREDICTION RULE; HUMAN HEART; ERROR RATE; REGRESSION; SUPPORT	With various sources and large amounts of genomic and proteomic data accumulating, the importance of integrative analyses of multiple sources of data has been increasingly recognized. A natural approach is to combine multiple models, each built on one source of data. A challenge however is to account for different local information contents of different sources of data: the choice of the weight on each candidate model (and thus each source of data) may depend on the input for which a prediction is to be made, suggesting that the constant weights used in most existing approaches may not be optimal. Here we propose an input-dependent weighting (IDW) scheme with the weight being the probability of each model's giving a correct prediction for the given input. The weights can be estimated based on regression using training data. We apply IDW to discriminating human heart failure etiology using two sources of gene expression data, and to gene function prediction by a combined analysis of gene expression and protein-protein interaction data. It is demonstrated that IDW may perform better than some standard approaches. Input-dependent weights can be also adopted as a criterion for model selection.	Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA	Pan, W (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, A460 Mayo, Minneapolis, MN 55455 USA.	weip@biostat.umn.edu; guanghx@biostat.umn.edu; xiaohong@biostat.umn.edu					Akaike H., 1973, P 2 INT S INF THEOR, P267; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Boulesteix A.-L., 2004, STAT APPL GENET MOL, V3, P1, DOI DOI 10.2202/1544-6115.1075; BOX GEP, 1980, J ROY STAT SOC A STA, V143, P383, DOI 10.2307/2982063; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burnham K. P., 2002, MODEL SELECTION MULT; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; GEISSER S, 1975, J AM STAT ASSOC, V70, P320, DOI 10.2307/2285815; George EI, 2000, BIOMETRIKA, V87, P731, DOI 10.1093/biomet/87.4.731; Hall JL, 2004, PHYSIOL GENOMICS, V17, P283, DOI 10.1152/physiolgenomics.00004.2004; Hastie T., 2001, ELEMENTS STAT LEARNI; HAWKINS DM, 2003, EXPLORING BLOOD SPEC; Hoeting JA, 1999, STAT SCI, V14, P382; HUANG X, 2003, BIOINFORMATICS, V9, P2072; Huang XH, 2004, BIOINFORMATICS, V20, P888, DOI 10.1093/bioinformatics/btg499; Huang XH, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-205; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; LeBlanc M, 1996, J AM STAT ASSOC, V91, P1641, DOI 10.2307/2291591; Li HZ, 2004, BIOINFORMATICS, V20, P208, DOI 10.1093/bioinformatics/bth900; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Maclin R., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Paik M., 2004, STAT APPL GENETICS M, V3; *PGA, 2004, NHLBI PROGR GEN APPL; Ripley B. D., 1996, PATTERN RECOGNITION; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHEN X, 2005, UNPUB OPTIMAL MODEL; Shen XT, 2004, TECHNOMETRICS, V46, P306, DOI 10.1198/004017004000000338; Shen XT, 2002, J AM STAT ASSOC, V97, P210, DOI 10.1198/016214502753479356; Shen XT, 2003, J AM STAT ASSOC, V98, P724, DOI 10.1198/016214503000000639; Simon R, 2003, J NATL CANCER I, V95, P14; STONE M, 1974, J R STAT SOC B, V36, P111; Tan YX, 2004, COMPUT BIOL CHEM, V28, P235, DOI 10.1016/j.compbiolchem.2004.05.002; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Vapnik V., 1998, STAT LEARNING THEORY; WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XIAO G, 2005, 2005012 U MINN DIV B; Yang YH, 2003, STAT SINICA, V13, P783; Yang YH, 2001, J AM STAT ASSOC, V96, P574, DOI 10.1198/016214501753168262; YUAN Z, 2003, UNPUB COMBINING LINE; Zhang H, 1999, RECURSIVE PARTITIONI	54	3	3	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405			STAT SINICA	Stat. Sin.	APR	2006	16	2					523	540				18	Statistics & Probability	Mathematics	043GH	WOS:000237587700013		
J	Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartko, H; Bastieri, D; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bretz, T; Britvitch, I; Camara, M; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Danielyan, V; Dazzi, F; De Angelis, A; De los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Galante, N; Garczarczyk, M; Gaug, M; Gebauer, J; Giannitrapani, R; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Jacon, P; Kalekin, O; Kranich, D; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Merck, C; Merck, M; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Peruzzo, L; Piccioli, A; Pin, M; Prandini, E; Rico, J; Rhode, W; Riegel, B; Rissi, M; Robert, A; Rossato, G; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, L; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zapatero, J				Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartko, H; Bastieri, D; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bretz, T; Britvitch, I; Camara, M; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Danielyan, V; Dazzi, F; De Angelis, A; De los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Galante, N; Garczarczyk, M; Gaug, M; Gebauer, J; Giannitrapani, R; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Jacon, P; Kalekin, O; Kranich, D; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Longo, F; Lopez, J; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Merck, C; Merck, M; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Peruzzo, L; Piccioli, A; Pin, M; Prandini, E; Rico, J; Rhode, W; Riegel, B; Rissi, M; Robert, A; Rossato, G; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stark, L; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zapatero, J			Observation of very high energy gamma-ray emission from the active galactic nucleus 1ES 1959+650 using the magic telescope	ASTROPHYSICAL JOURNAL			English	Article						galaxies : active; galaxies : individual (1ES 1959+650); gamma rays : observations	TEV BLAZAR 1ES-1959+650; RADIO-SOURCES; ACCELERATION; SENSITIVITY; NEUTRINOS; SPECTRA; OBJECTS	The MAGIC Cerenkov telescope has observed very high energy (VHE) gamma-ray emission from the active galactic nucleus 1ES 1959+650 during 6 hr in 2004 September and October. The observations were carried out alternating with observations of the Crab Nebula, whose data were used as a reference source for optimizing gamma -ray/hadron separation and for flux comparison. The data analysis shows VHE gamma-ray emission of 1ES 1959+650 with similar to 8 sigma significance, at a time of low activity in both optical and X-ray wavelengths. An integral flux above similar to 180 GeV of about 20% that of the Crab Nebula was obtained. The light curve, sampled over 7 days, shows no significant variations. The differential energy spectrum between 180 GeV and 2 TeV can be fitted with a power-law of index -2.72 +/- 0.14. The spectrum is consistent with the slightly steeper spectrum seen by HEGRA at higher energies, also during periods of low X-ray activity.	Univ Wurzburg, D-97074 Wurzburg, Germany; Inst Fis Altes Energies, E-08193 Bellaterra, Spain; ETH Honggerberg, Inst Particle Phys, HPK, CH-8093 Zurich, Switzerland; Univ Complutense Madrid, E-28040 Madrid, Spain; Univ Autonoma Barcelona, Dept Fis, E-08193 Bellaterra, Spain; Max Planck Inst Phys & Astrophys, D-80895 Munich, Germany; Univ Padua, Dipartimento Fis, I-35131 Padua, Italy; Ist Nazl Fis Nucl, I-35131 Padua, Italy; Univ Lodz, Div Expt Phys, PL-90236 Lodz, Poland; Univ Udine, Dipartimento Fis, I-33100 Udine, Italy; INFN Trieste, I-33100 Udine, Italy; Yerevan Phys Inst, Cosm Ray Div, AM-375036 Yerevan, Armenia; Tuorla Observ, FI-21500 Piikkio, Finland; Univ Calif Davis, Davis, CA 95616 USA; Univ Siena, Dipartimento Fis, I-53100 Siena, Italy; INFN Pisa, I-53100 Siena, Italy; Humboldt Univ, Inst Phys, D-12489 Berlin, Germany; Inst Nucl Energy Res, BG-1784 Sofia, Bulgaria; Univ Dortmund, Fachbereich Phys, D-44227 Dortmund, Germany	Albert, J (reprint author), Univ Wurzburg, Hubland, D-97074 Wurzburg, Germany.		De Angelis, Alessandro/B-5372-2009; Moralejo Olaizola, Abelardo/M-2916-2014; Mannheim, Karl/F-6705-2012; Flix, Josep/G-5414-2012; Doro, Michele/F-9458-2012; chilingarian, ashot/B-1901-2014; Contreras Gonzalez, Jose Luis/K-7255-2014; Rico, Javier/K-8004-2014; Fernandez, Ester/K-9734-2014; lopez, marcos/L-2304-2014; GAug, Markus/L-2340-2014; Font, Lluis/L-4197-2014; Fernandez, Enrique/L-5387-2014; Tonello, Nadia/L-8065-2014; Torres, Diego/F-3009-2015; Antoranz, Pedro/H-5095-2015; Miranda, Jose Miguel/F-2913-2013; Fonseca Gonzalez, Maria Victoria/I-2004-2015; Barrio, Juan/L-3227-2014; Wibig, Tadeusz/; De Angelis, Alessandro/	Moralejo Olaizola, Abelardo/0000-0002-1344-9080; Doro, Michele/0000-0001-9104-3214; chilingarian, ashot/0000-0002-2018-9715; Contreras Gonzalez, Jose Luis/0000-0001-7282-2394; Rico, Javier/0000-0003-4137-1134; lopez, marcos/0000-0002-8791-7908; GAug, Markus/0000-0001-8442-7877; Font, Lluis/0000-0003-2109-5961; Fernandez, Enrique/0000-0002-6405-9488; Tonello, Nadia/0000-0003-0550-1667; Torres, Diego/0000-0002-1522-9065; Antoranz, Pedro/0000-0002-3015-3601; Miranda, Jose Miguel/0000-0002-1472-9690; Fonseca Gonzalez, Maria Victoria/0000-0003-2235-0725; Barrio, Juan/0000-0002-0965-0259; Wibig, Tadeusz/0000-0002-2078-0580; De Angelis, Alessandro/0000-0002-3288-2517			Aharonian F, 2003, ASTRON ASTROPHYS, V406, pL9, DOI 10.1051/0004-6361:20030838; Aharonian FA, 2000, NEW ASTRON, V5, P377, DOI 10.1016/S1384-1076(00)00039-7; Ahrens J, 2004, ASTROPART PHYS, V20, P507, DOI 10.1016/j.astropartphys.2003.09.003; Baixeras C, 2004, NUCL INSTRUM METH A, V518, P188, DOI 10.1016/j.nima.2003.10.057; BERNARDINI E, 2006, IN PRESS NETWORK ATM, V7; Bock RK, 2004, NUCL INSTRUM METH A, V516, P511, DOI 10.1016/j.nima.2003.08.157; BOETTCHER M, 2005, APJ, V621, P176; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CORTINA J, 2005, P 29 INT COSM RAY C; Daniel MK, 2005, ASTROPHYS J, V621, P181, DOI 10.1086/427406; ELVIS M, 1992, ASTROPHYS J SUPPL S, V80, P257, DOI 10.1086/191665; FALOMO R, 2002, APJ, V569, P35; Fegan DJ, 1997, J PHYS G NUCL PARTIC, V23, P1013, DOI 10.1088/0954-3899/23/9/004; Ghisellini G, 1998, MON NOT R ASTRON SOC, V301, P451, DOI 10.1046/j.1365-8711.1998.02032.x; Halzen F, 2005, ASTROPART PHYS, V23, P537, DOI 10.1016/j.astropartphys.2005.03.007; HECK D, 2005, EXTENSIVE AIR SHOWER; Hillas A M, 1985, 19TH P INT COSM RAY, V3, P445; Holder J, 2003, ASTROPHYS J, V583, pL9, DOI 10.1086/367816; HOMS D, 2002, UNIVERSE VIEWED GAMM; Horan D, 2004, ASTROPHYS J, V603, P51, DOI 10.1086/381430; Inoue S, 1996, ASTROPHYS J, V463, P555, DOI 10.1086/177270; KELLERMA.KI, 1969, ASTROPHYS J, V155, pL71, DOI 10.1086/180305; KHELIFI B, 2002, THESIS COLL FRANCE; KRANICH D, 1997, THESIS TU MUNCHEN; Krawczynski H, 2004, ASTROPHYS J, V601, P151, DOI 10.1086/380393; LI TP, 1983, ASTROPHYS J, V272, P317, DOI 10.1086/161295; MANNHEIM K, 1993, ASTRON ASTROPHYS, V269, P67; Massaro E, 2004, ASTRON ASTROPHYS, V422, P103, DOI 10.1051/0004-6361:20047148; Nishiyama T., 2000, AIP C P, V3, P370; PADOVANI P, 1992, ASTROPHYS J, V387, P449, DOI 10.1086/171098; Paneque D, 2004, NUCL INSTRUM METH A, V518, P619, DOI 10.1016/j.nima.2003.11.101; PUNCH M, 1992, NATURE, V358, P477, DOI 10.1038/358477a0; Rachen JP, 1998, PHYS REV D, V58, DOI 10.1103/PhysRevD.58.123005; TONELLO N, 2003, P 28 INT COSM RAY C, P2615; TONELLO N, 2006, THESIS TU MUNCHEN	35	38	38	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X			ASTROPHYS J	Astrophys. J.	MAR 10	2006	639	2	1				761	765		10.1086/499421		5	Astronomy & Astrophysics	Astronomy & Astrophysics	019LK	WOS:000235837100017		
J	Larranaga, P; Calvo, B; Santana, R; Bielza, C; Galdiano, J; Inza, I; Lozano, JA; Armananzas, R; Santafe, G; Perez, A; Robles, V				Larranaga, Pedro; Calvo, Borja; Santana, Roberto; Bielza, Concha; Galdiano, Josu; Inza, Inaki; Lozano, Jose A.; Armananzas, Ruben; Santafe, Guzman; Perez, Aritz; Robles, Victor			Machine learning in bioinformatics	BRIEFINGS IN BIOINFORMATICS			English	Review						machine learning; bioinformatics; supervised classification; clustering; probabilistic graphical models; optimisation; heuristic; genomics; proteomics; microarray; system biology; evolution; text mining	GENE-EXPRESSION DATA; FEATURE SUBSET-SELECTION; PROTEIN SECONDARY STRUCTURE; MULTIPLE SEQUENCE ALIGNMENT; SIDE-CHAIN CONFORMATIONS; SPLICE-SITE PREDICTION; MICROARRAY DATA; MAXIMUM-LIKELIHOOD; BAYESIAN NETWORKS; CROSS-VALIDATION	This article reviews machine learning methods for bioinformatics. It presents modelling methods, such as supervised classification, clustering and probabilistic graphical models for knowledge discovery, as well as deterministic and stochastic heuristics for optimization. Applications in genomics, proteomics, systems biology, evolution and text mining are also shown.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, San Sebastian 20018, Spain; Madrid Tech Univ, Sch Comp Sci, Madrid, Spain; Harvard Univ, Sch Med, Cambridge, MA 02138 USA; Univ Politecn Madrid, Dept Comp Syst Architecture & Technol, E-28040 Madrid, Spain	Larranaga, P (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, Paseo Manuel Lardizabal 1, San Sebastian 20018, Spain.	pedro.larranaga@ehu.es	Lozano, Jose/F-5120-2010; Santana, Roberto/B-2799-2009; Calvo, Borja/D-8814-2012; Armananzas, Ruben/C-2735-2013; Bielza, Concha/F-9277-2013; Larranaga, Pedro/F-9293-2013; Robles, Victor/L-4220-2014	Lozano, Jose/0000-0002-4683-8111; Santana, Roberto/0000-0002-1005-8535; Armananzas, Ruben/0000-0003-4049-0000; Bielza, Concha/0000-0002-7813-1188; Robles, Victor/0000-0003-3937-2269			Aerts S, 2004, BIOINFORMATICS, V20, P1974, DOI 10.1093/bioinformatics/bth179; AJRDINE N, 1971, MAT TAXONOMY; Allen JE, 2004, GENOME RES, V14, P142, DOI 10.1101/gr.1562804; ALLON G, 1999, SODA 99 P 10 ANN ACM, P955; Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; AMTSUURA T, 2005, IN PRESS P 6 MET INT; Ananiadou S, 2006, TEXT MINING BIOL BIO; Ando S., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1006249; Ando S, 2002, INFORM SCIENCES, V145, P237, DOI 10.1016/S0020-0255(02)00235-9; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Baldi P., 2001, BIOINFORMATICS MACHI; Bao L, 2005, BIOINFORMATICS, V21, P2185, DOI 10.1093/bioinformatics/bti365; Barker D, 2004, BIOINFORMATICS, V20, P274, DOI 10.1093/bioinformatics/btg402; Baumgartner C, 2004, BIOINFORMATICS, V20, P2985, DOI 10.1093/bioinformatics/bth343; Ben-Bassat M., 1982, HDB STATISTICS, VII, P773, DOI 10.1016/S0169-7161(82)02038-0; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Bhandarkar S. M., 2002, Proceedings IEEE Computer Society Bioinformatics Conference, DOI 10.1109/CSB.2002.1039330; BLANCO R, 2001, P WORKSH BAY MOD MED, P29; Blazewicz J, 2004, COMPUT BIOL CHEM, V28, P11, DOI 10.1016/j.compbiolchem.2003.12.002; Blazewicz J, 2005, ARTIF INTELL MED, V35, P135, DOI 10.1016/j.artmed.2005.02.001; Blazewicz J, 2005, LECT NOTES COMPUT SC, V3449, P22; Blazewicz J, 2005, BIOINFORMATICS, V21, P2356, DOI 10.1093/bioinformatics/bti351; Bockhorst J, 2003, BIOINFORMATICS, V19, P1227, DOI 10.1093/bioinformatics/btg147; Bohning D, 2003, COMPUT STAT DATA AN, V41, P349, DOI 10.1016/S0167-9473(02)00161-5; Bower J. M., 2004, COMPUTATIONAL MODELI; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; Breiman L., 1993, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BROWN MPS, 2004, J COMPUT BIOL, V11, P227; Bryan K, 2005, COMP MED SY, P383, DOI 10.1109/CBMS.2005.37; Cai DY, 2000, BIOINFORMATICS, V16, P152, DOI 10.1093/bioinformatics/16.2.152; Carter RJ, 2001, NUCLEIC ACIDS RES, V29, P3928; Castelo R, 2004, BIOINFORMATICS, V20, P69, DOI 10.1093/bioinformatics/bth932; Cawley SL, 2003, BIOINFORMATICS S2, V19, pII36; Chang MF, 2002, WIREL COMMUN MOB COM, V2, P169, DOI 10.1002/wcm.43; Chen T, 2001, J COMPUT BIOL, V8, P325, DOI 10.1089/10665270152530872; Chickering D.M., 1994, LEARNING BAYESIAN NE; Chickering M, 1996, P 12 INT C UNC ART I, P150; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Christof T, 1997, J COMPUT BIOL, V4, P433, DOI 10.1089/cmb.1997.4.433; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Cowell R. G., 1999, PROBABILISTIC NETWOR, P442; DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1; Degroeve S, 2002, BIOINFORMATICS, V18, pS75; de Hoon M J L, 2004, Bioinformatics, V20 Suppl 1, pi101, DOI 10.1093/bioinformatics/bth927; De Maeyer M, 2000, METH MOL B, V143, P265; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DESMET F, 2002, BIOINFORMATICS, V20, P660; Devroye L., 1996, PROBABILISTIC THEORY, V31; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R. O., 1973, PATTERN CLASSIFICATI; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Durbin R., 1998, BIOL SEQUENCE ANAL P; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Ellrott K., 2002, BIOINFORMATICS, V18, P100; FALKENAUER E, 2002, EVOLUTIONARY COMPUTA, P219; Fiser A, 2000, PROTEIN SCI, V9, P1753; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E, 1951, USAF SCH AVIATION ME, V4, P261; Fogel G. B., 2002, EVOLUTIONARY COMPUTA, P195; Fogel GB, 2002, EVOLUTIONARY COMPUTA; Fogel GB, 2002, NUCLEIC ACIDS RES, V30, P5310, DOI 10.1093/nar/gkf653; Fogel G.B, 2005, IEEE CONNECTIONS, V3, P11; FORGY EW, 1965, BIOMETRICS, V21, P768; FRASCONI P, 2003, NATO SCI SERIES COMP; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; Geiger D., 1994, LEARNING GAUSSIAN NE; Gersho A., 1992, VECTOR QUANTIZATION; GILMAN A, 1995, BIOPHYS J, V69, P1321; Glick M, 2002, P NATL ACAD SCI USA, V99, P703, DOI 10.1073/pnas.022418199; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; Goldberg D, 1989, GENETIC ALGORITHMS S; GREEN DM, 1974, SIGNAL DETECTION THE; Greenspan G, 2004, BIOINFORMATICS, V20, P137, DOI 10.1093/bioinformatics/bth907; Guindon S, 2003, SYST BIOL, V52, P696, DOI 10.1080/10635150390235520; Hartemink A., 2001, PAC S BIOCOMPUT, V6, P422; Hastie T., 2001, ELEMENTS STAT LEARNI; Hautaniemi S, 2005, BIOINFORMATICS, V21, P2027, DOI 10.1093/bioinformatics/bti278; HECKERMAN D, 1995, TUTORAL LEARNING BAY; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; Higgins D, 2000, BIOINFORMATICS SEQUE; HIROSAWA M, 1995, COMPUT APPL BIOSCI, V11, P13; Hsu HP, 2003, J CHEM PHYS, V118, P444, DOI 10.1063/1.1522710; HSU HP, 2003, PHYS REV E, V68; Huang JL, 2003, BIOINFORMATICS, V19, P1303, DOI 10.1093/bioinformatics/btg166; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Husmeier D., 2005, PROBABILISTIC MODELI; HUSMEIER D, 2005, INFERRING GENETIC RE, P239; Husmeier D, 2003, BIOCHEM SOC T, V31, P1516; Hwang K.-B., 2001, METHODS MICROARRAY D, P167; Imoto S., 2003, P EUR C COMP BIOL; Imoto S., 2002, GENOME INFORMATICS, V13, p[369, 508]; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; Inza I, 2002, J INTELL FUZZY SYST, V12, P25; ISHIKAWA M, 1993, COMPUT APPL BIOSCI, V9, P267; Jacob E, 2005, BIOINFORMATICS, V21, P1403, DOI 10.1093/bioinformatics/bti156; Jagota A, 2000, DATA ANAL CLASSIFICA; Jarvis RM, 2005, BIOINFORMATICS, V21, P860, DOI 10.1093/bioinformatics/bti102; JENSEN F, 2001, BAYESIAN NETWORKS DE; JIANG T, 2002, CURRENT TOPICS COMPU; Jojic V, 2004, BIOINFORMATICS, V20, P161, DOI 10.1093/bioinformatics/bth917; Jung HY, 2002, BIOINFORMATICS, V18, pS141; Keith JM, 2002, BIOINFORMATICS, V18, P1494, DOI 10.1093/bioinformatics/18.11.1494; Kikuchi S, 2003, BIOINFORMATICS, V19, P643, DOI 10.1093/bioinformatics/btg027; Kim J, 1996, COMPUT APPL BIOSCI, V12, P259; Kim KJ, 2004, NEUROCOMPUTING, V61, P361, DOI 10.1016/j.neucom.2003.11.008; Kim S, 2004, BIOINFORMATICS, V20, P40, DOI 10.1093/bioinformatics/btg368; Kimura S, 2005, BIOINFORMATICS, V21, P1154, DOI 10.1093/bioinformatics/bti071; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kittler J., 1978, Pattern Recognition and Signal Processing; KLEINBAUM DG, 1982, COMMUN STAT A-THEOR, V11, P485, DOI 10.1080/03610928208828251; Knudsen S, 1999, BIOINFORMATICS, V15, P356, DOI 10.1093/bioinformatics/15.5.356; Koehl P, 1998, J CHEM PHYS, V108, P9540, DOI 10.1063/1.476402; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koza J R, 2001, PACIFIC S BIOCOMPUTI, V6, P434; Koza JR, 1992, GENETIC PROGRAMMING; Krallinger M, 2005, DRUG DISCOV TODAY, V10, P439, DOI 10.1016/S1359-6446(05)03376-3; Krasnogor N., 2002, LECT NOTES COMPUTER, P769; Krishnapuram B, 2004, J COMPUT BIOL, V11, P227, DOI 10.1089/1066527041410463; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Kumar S, 1996, MOL BIOL EVOL, V13, P584; KUNCHEVA L, 1993, INFORM PROCESS LETT, V46, P163, DOI 10.1016/0020-0190(93)90021-Z; KUNCHEVA LI, 2004, COMBINING PATTERN CL; LAMONT GB, 2002, EVOLUTIONARY COMPUTA, P137; LARRANAGA P, 2003, ARTIF INTELL, V31, pR3; Larranaga P, 2005, DATA ANALYSIS AND VISUALIZATION IN GENOMICS AND PROTEOMICS, P215, DOI 10.1002/0470094419.ch13; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 2002, ESTIMATION DISTRIBUT; Lauritzen SL, 1996, GRAPHICAL MODELS; LEE C, 1991, J MOL BIOL, V217, P373, DOI 10.1016/0022-2836(91)90550-P; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Lee PH, 2005, BIOINFORMATICS, V21, P2739, DOI 10.1093/bioinformatics/bti406; Leone M, 2005, BIOINFORMATICS, V21, P239, DOI 10.1093/bioinformatics/bth491; Lesh N., 2003, P 7 ANN INT C RES CO, P188, DOI 10.1145/640075.640099; Li HL, 2005, BIOINFORMATICS, V21, P1838, DOI 10.1093/bioinformatics/bti286; LI J, 2005, IEEE INTELLIGENT SYS, V20; Li LP, 2004, BIOINFORMATICS, V20, P1638, DOI 10.1093/bioinformatics/bth098; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Liang FM, 2001, J CHEM PHYS, V115, P3374, DOI 10.1063/1.1387478; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Ling CX, 2005, IEEE ACM T COMPUT BI, V2, P81, DOI 10.1109/TCBB.2005.25; Liu H., 1998, FEATURE SELECTION KN; Liu ZJ, 2003, PROTEINS, V50, P49, DOI 10.1002/prot.10253; Looger LL, 2001, J MOL BIOL, V307, P429, DOI 10.1006/jmbi.2000.4424; Lopez-Bigas N, 2004, NUCLEIC ACIDS RES, V32, P3108, DOI 10.1093/nar/gkh605; Lukashin AV, 2001, BIOINFORMATICS, V17, P405, DOI 10.1093/bioinformatics/17.5.405; MacCallum RM, 2004, BIOINFORMATICS, V20, P224, DOI 10.1093/bioinformatics/bth913; Markowetz F., 2003, P EUR C COMP BIOL; Mathe C, 2002, NUCLEIC ACIDS RES, V30, P4103, DOI 10.1093/nar/gkf543; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; McLachlan GJ, 1988, MIXTURE MODELS INFER; MCLACHLAN GJ, 2002, P IEEE, V90, P1722; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Meyer IM, 2004, NUCLEIC ACIDS RES, V32, P776, DOI 10.1093/nar/gkh211; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Middendorf M, 2004, BIOINFORMATICS, V20, P232, DOI 10.1093/bioinformatics/bth923; Minsky M., 1961, T I RADIO ENG, V49, P8; Mitchell T. M., 1997, MACHINE LEARNING; Moreira A, 2004, THEOR COMPUT SCI, V322, P297, DOI 10.1016/j.tcs.2004.03.014; Murphy K., 1999, MODELLING GENE EXPRE; Nachman I, 2004, Bioinformatics, V20 Suppl 1, pi248, DOI 10.1093/bioinformatics/bth941; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Nariai N, 2004, Pac Symp Biocomput, P336; Neapolitan E, 2003, LEARNING BAYESIAN NE; Neuwald AF, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-157; Nguyen Hung Dinh, 2002, Genome Inform, V13, P123; Noman N., 2005, P 2005 C GEN EV COMP, P439, DOI 10.1145/1068009.1068079; Olshen AB, 2002, BIOINFORMATICS, V18, P961, DOI 10.1093/bioinformatics/18.7.961; ONG IM, 2001, 1426 U WISC MAD COMP; Ong Irene M, 2002, Bioinformatics, V18 Suppl 1, pS241; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; Pan W, 2002, BIOINFORMATICS, V18, P546, DOI 10.1093/bioinformatics/18.4.546; Park LJ, 1997, MED BIOL ENG COMPUT, V35, P47, DOI 10.1007/BF02510391; Pasanen T, 2003, DNA MICROARRAY DATA; Pavlovic V, 2002, BIOINFORMATICS, V18, P19, DOI 10.1093/bioinformatics/18.1.19; PAZZANI MJ, 1997, ARTIFICIAL INTELLIGE, V4; Pe'er D, 2001, BIOINFORMATICS S1, V17, P215; Pearl J, 2000, CAUSALITY MODELS REA; Pearl J., 1988, PROBABILISTIC REASON; Pena JM, 2005, BIOINFORMATICS, V21, P224, DOI 10.1093/bioinformatics/bti1137; Perner P, 2002, ARTIF INTELL MED, V26, P161, DOI 10.1016/S0933-3657(02)00057-X; Pevzner P., 2000, COMPUTATIONAL MOL BI; Pollastri G, 2002, Bioinformatics, V18 Suppl 1, pS62; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; RAMASWAMY S, 2001, BIOINFORMATICS, V1, pS316; RANGELAND C, 2005, MODELLING GENETIC RE, P269; Raval A, 2002, BIOINFORMATICS, V18, P788, DOI 10.1093/bioinformatics/18.6.788; RIAZ T, 2004, P 2 AS PAC BIOINF C, P223; Ribeiro C. C., 2005, International Transactions in Operational Research, V12, DOI 10.1111/j.1475-3995.2005.498_1.x; RITCHIE MD, 2003, BMC BIOINFORMATICS, V4, P7; Robles JR, 2004, BIOINFORMATICS, V20, P3244, DOI 10.1093/bioinformatics/bth348; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saeys Y., 2003, BIOINFORMATICS, V19, pii179; Saeys Y, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-64; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Sakamoto E, 2001, IEEE C EVOL COMPUTAT, P720, DOI 10.1109/CEC.2001.934462; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Salzberg S, 1995, J Comput Biol, V2, P473, DOI 10.1089/cmb.1995.2.473; Santana R, 2004, LECT NOTES COMPUT SC, V3337, P388; Satten GA, 2004, BIOINFORMATICS, V20, P3128, DOI 10.1093/bioinformatics/bth372; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; Schneider TD, 1996, DISCRETE APPL MATH, V71, P259, DOI 10.1016/S0166-218X(96)00068-6; Scholkopf B., 2004, KERNEL METHODS COMPU; Scholkopf B., 1999, ADV KERNEL METHODS S; Sebban M, 2002, BIOINFORMATICS, V18, P235, DOI 10.1093/bioinformatics/18.2.235; Segal E, 2001, BIOINFORMATICS S1, V17, P243; SEIFFERT U, 2005, BIOINFORMATICS USING; Selbig J, 1999, BIOINFORMATICS, V15, P1039, DOI 10.1093/bioinformatics/15.12.1039; SHACHTER RD, 1989, MANAGE SCI, V35, P527, DOI 10.1287/mnsc.35.5.527; Sheng Q., 2003, BIOINFORMATICS S2, V19, pii196; Sheng QZ, 2005, DATA ANALYSIS AND VISUALIZATION IN GENOMICS AND PROTEOMICS, P153, DOI 10.1002/0470094419.ch10; Sherlock G, 2001, Brief Bioinform, V2, P350, DOI 10.1093/bib/2.4.350; SHI W, 2005, BIOINFORMATICS TECHN, P244; SHLOCK D, 2002, EVOLUTIONARY COMPUTA, P231; Shmulevich I, 2002, BIOINFORMATICS, V18, P555, DOI 10.1093/bioinformatics/18.4.555; Sima C, 2005, BIOINFORMATICS, V21, P1046, DOI 10.1093/bioinformatics/bti081; Smith J, 2004, RECENT ADV MEMETIC A, P105; Smith PWF, 1998, NATO ADV SCI I D-BEH, V89, P555; SPELLMAN PT, 1998, MOL BIOL CELL, V9, P3271; Spirtes P., 2000, P ATL S COMP BIOL; Stapley B J, 2002, Pac Symp Biocomput, P374; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Steffen M, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-34; STONE M, 1974, J R STAT SOC B, V36, P111; Sugimoto Naoya, 2004, Genome Inform, V15, P121; TAKAHO A, 2004, BIOINFORMATICS, V20, P2181; Tamada Y., 2003, BIOINFORMATICS, V19, pii227; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tan SN, 2002, C T COL I S, V3, P83; Troyanskaya OG, 2002, BIOINFORMATICS, V18, P1454, DOI 10.1093/bioinformatics/18.11.1454; TUFFERY P, 1991, J BIOMOL STRUCT DYN, V8, P1267; Valafar F, 2002, ANN NY ACAD SCI, V980, P41; Vapnik VN, 1995, NATURE STAT LEARNING; Vision TJ, 2000, GENETICS, V155, P407; Wang J. T., 2004, DATA MINING BIOINFOR; Wang RS, 2005, BIOINFORMATICS, V21, P2456, DOI 10.1093/bioinformatics/bti352; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; Webb A. R., 2002, STAT PATTERN RECOGNI, VSecond; Wit E, 2005, J ROY STAT SOC C-APP, V54, P817, DOI 10.1111/j.1467-9876.2005.00519.x; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; Won KJ, 2004, BIOINFORMATICS, V20, P3613, DOI 10.1093/bioinformatics/bth454; Wren JD, 2004, DNA CELL BIOL, V23, P695, DOI 10.1089/1044549042476929; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Wu C. H., 2000, NEURAL NETWORKS GENO; Wu JS, 2004, BIOINFORMATICS, V20, P1710, DOI 10.1093/bioinformatics/bth147; Wu X, 2003, BIOKDD03 3 ACM SIGKD, P63; Xing E., 2001, P 18 INT C MACH LEAR, P601; YANG C, 2004, BIOINFORMATICS, V20, P371; Yang JM, 2002, PROTEIN SCI, V11, P1897, DOI 10.1110/ps.4940102; Yanover C., 2003, ADV NEURAL INFORM PR, V15, P1457; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; Zhou GD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S7; Zuker M, 2003, NUCLEIC ACIDS RES, V31, P3406, DOI 10.1093/nar/gkg595	272	136	138	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463			BRIEF BIOINFORM	Brief. Bioinform.	MAR	2006	7	1					86	112		10.1093/bib/bbk007		27	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	090DL	WOS:000240930700007	16761367	
J	Dudek, AZ; Arodz, T; Galvez, J				Dudek, AZ; Arodz, T; Galvez, J			Computational methods in developing quantitative structure-activity relationships (QSAR): A review	COMBINATORIAL CHEMISTRY & HIGH THROUGHPUT SCREENING			English	Review						QSAR; molecular descriptors; feature selection; machine learning	SUPPORT VECTOR MACHINES; ARTIFICIAL NEURAL-NETWORKS; PARTIAL LEAST-SQUARES; HUMAN INTESTINAL-ABSORPTION; BRAIN-BARRIER PERMEATION; MOLECULAR-FIELD ANALYSIS; PAIR-CORRELATION METHOD; FEATURE-SELECTION; DRUG DISCOVERY; BIOLOGICAL-ACTIVITY	Virtual filtering and screening of combinatorial libraries have recently gained attention as methods complementing the high-throughput screening and combinatorial chemistry. These chemoinformatic techniques rely heavily on quantitative structure-activity relationship (QSAR) analysis, a field with established methodology and successful history. In this review, we discuss the computational methods for building QSAR models. We start with outlining their usefulness in high-throughput screening and identifying the general scheme of a QSAR model. Following, we focus on the methodologies in constructing three main components of QSAR model, namely the methods for describing the molecular structure of compounds. for selection of informative descriptors and for activity prediction. We present both the well-established methods as well as techniques recently introduced into the QSAR domain.	Univ Minnesota, Sch Med, Div Hematol Oncol & Transplantat, Minneapolis, MN 55455 USA; AGH Univ Sci & Technol, Inst Comp Sci, PL-30059 Krakow, Poland; Univ Valencia, Unit Drug Design & Mol Connect Res, E-46100 Burjassot, Valencia, Spain	Dudek, AZ (reprint author), Univ Minnesota, Sch Med, Div Hematol Oncol & Transplantat, 420 Delaware St SE,MMC 480, Minneapolis, MN 55455 USA.	dudek002@umn.edu					Adenot M, 2004, J CHEM INF COMP SCI, V44, P239, DOI 10.1021/ci034205d; Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; Akamatsu Miki, 2002, Current Topics in Medicinal Chemistry, V2, P1381, DOI 10.2174/1568026023392887; Bai JPF, 2004, J CHEM INF COMP SCI, V44, P2061, DOI 10.1021/ci040023n; Bajorath Jürgen, 2002, Nat Rev Drug Discov, V1, P882, DOI 10.1038/nrd941; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Barnard JM, 1997, J CHEM INF COMP SCI, V37, P141, DOI 10.1021/ci960090k; Baurin N, 2004, J CHEM INF COMP SCI, V44, P276, DOI 10.1021/ci0341565; Bleicher KH, 2003, NAT REV DRUG DISCOV, V2, P369, DOI 10.1038/nrd1086; Boser B.E., 1992, COLT 92 P 5 ANN WORK; Bravi G, 1997, J COMPUT AID MOL DES, V11, P79, DOI 10.1023/A:1008079512289; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; BURDEN FR, 1989, J CHEM INF COMP SCI, V29, P225, DOI 10.1021/ci00063a011; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; CAMMARAT.A, 1967, J MED CHEM, V10, P525, DOI 10.1021/jm00316a004; Catana C, 2005, J CHEM INF MODEL, V45, P170, DOI 10.1021/ci049797u; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Chin TL, 2004, J CHEM INF COMP SCI, V44, P154, DOI 10.1021/ci030294i; CHO SJ, 1995, J MED CHEM, V38, P1060, DOI 10.1021/jm00007a003; Cho SJ, 1996, J MED CHEM, V39, P1383, DOI 10.1021/jm9503052; Clark M, 2005, J CHEM INF MODEL, V45, P30, DOI 10.1021/ci049744c; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER T, IEEE T INFORM THEORY, V67, P21; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; Crivori P, 2000, J MED CHEM, V43, P2204, DOI 10.1021/jm990968+; Cruciani G., 2000, THEOCHEM, V503, DOI 10.1016/S0166-1280(99)00360-7; Daszykowski M, 2004, J CHEM INF COMP SCI, V44, P716, DOI 10.1021/ci034170h; de Julian-Ortiz JV, 1998, J MOL GRAPH MODEL, V16, P14, DOI 10.1016/S1093-3263(98)00013-8; DeLisle RK, 2004, J CHEM INF COMP SCI, V44, P862, DOI 10.1021/ci034188s; Deshpande M, 2005, IEEE T KNOWL DATA EN, V17, P1036, DOI 10.1109/TKDE.2005.127; Dove S, 1999, QUANT STRUCT-ACT REL, V18, P329, DOI 10.1002/(SICI)1521-3838(199910)18:4<329::AID-QSAR329>3.0.CO;2-V; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Estrada E, 2001, SAR QSAR ENVIRON RES, V12, P309, DOI 10.1080/10629360108032919; Estrada E, 2001, J CHEM INF COMP SCI, V41, P1015, DOI 10.1021/ci000170v; Estrada E, 1996, J CHEM INF COMP SCI, V36, P844, DOI 10.1021/ci950187r; Farkas O, 2005, J CHEM INF MODEL, V45, P339, DOI 10.1021/ci049827t; Feng J, 2003, J CHEM INF COMP SCI, V43, P1463, DOI 10.1021/ci034032s; Fisher RA, 1936, ANN EUGENIC, V7, P179; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Gallant S I, 1990, IEEE Trans Neural Netw, V1, P179, DOI 10.1109/72.80230; GALLEGOS A, 2004, J CHEM INF COMP SCI, V44, P321; GALVEZ J, 1994, J CHEM INF COMP SCI, V34, P520, DOI 10.1021/ci00019a008; GALVEZ J, 1991, Anales de la Real Academia de Farmacia, V57, P533; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; Gershell LJ, 2003, NAT REV DRUG DISCOV, V2, P321, DOI 10.1038/nrd1064; van de Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192, DOI 10.1038/nrd1032; Gini G, 2004, J CHEM INF COMP SCI, V44, P1897, DOI 10.1021/ci0401219; Goodnow RA, 2003, COMB CHEM HIGH T SCR, V6, P649; Guha R, 2005, J CHEM INF MODEL, V45, P800, DOI 10.1021/ci050022a; Guha R, 2005, J CHEM INF MODEL, V45, P65, DOI 10.1021/ci0497511; Guha R, 2004, J CHEM INF COMP SCI, V44, P2179, DOI 10.1021/ci049849f; Guner Osman F., 2002, Current Topics in Medicinal Chemistry, V2, P1321, DOI 10.2174/1568026023392940; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HALL LH, 1991, QUANT STRUCT-ACT REL, V10, P43, DOI 10.1002/qsar.19910100108; Hall LH, 2000, J CHEM INF COMP SCI, V40, P784, DOI 10.1021/ci990140w; HANSCH C, 1964, J AM CHEM SOC, V86, P1616, DOI 10.1021/ja01062a035; Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472; Heberger K, 2002, J CHEMOMETR, V16, P436, DOI 10.1002/cem.748; Helma C, 2004, J CHEM INF COMP SCI, V44, P1402, DOI 10.1021/ci034254q; Hemmateenejad B, 2005, J CHEM INF MODEL, V45, P190, DOI 10.1021/ci049766z; HIGO J, 1989, J COMPUT CHEM, V10, P376, DOI 10.1002/jcc.540100311; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hodgson J, 2001, NAT BIOTECHNOL, V19, P722, DOI 10.1038/90761; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hou TJ, 2004, J CHEM INF COMP SCI, V44, P266, DOI 10.1021/ci034184n; Hou TJ, 2004, J CHEM INF COMP SCI, V44, P1585, DOI 10.1021/ci049884m; Itskowitz P, 2005, J CHEM INF MODEL, V45, P777, DOI 10.1021/ci049628+; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Katritzky AR, 1996, J PHYS CHEM-US, V100, P10400, DOI 10.1021/jp953224q; KIER LB, 1993, QUANT STRUCT-ACT REL, V12, P383, DOI 10.1002/qsar.19930120406; KIER LB, 1981, J PHARM SCI, V70, P583, DOI 10.1002/jps.2600700602; KIRKPATRICK S, 1987, READINGS COMPUTER VI; KITTLER J, 1978, PATTERN RECOGNITIO E, V29, P41; KLEBE G, 1994, J MED CHEM, V37, P4130, DOI 10.1021/jm00050a010; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; KLOPMAN G, 1968, J AM CHEM SOC, V90, P223, DOI 10.1021/ja01004a002; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kvasnicka V, 1996, J CHEM INF COMP SCI, V36, P516, DOI 10.1021/ci9500703; Labute P, 2000, J MOL GRAPH MODEL, V18, P464, DOI 10.1016/S1093-3263(00)00068-1; Lemmen C, 2000, J COMPUT AID MOL DES, V14, P215, DOI 10.1023/A:1008194019144; Lewis RA, 2005, J MED CHEM, V48, P1638, DOI 10.1021/jm049228d; Lin TH, 2004, J CHEM INF COMP SCI, V44, P76, DOI 10.1021/ci030295a; Liu HX, 2004, J CHEM INF COMP SCI, V44, P1979, DOI 10.1021/ci049891a; Liu Y, 2004, J CHEM INF COMP SCI, V44, P1823, DOI 10.1021/ci049875d; MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095; Maurer W. D., 1975, ACM COMPUT SURV, V7, P5, DOI 10.1145/356643.356645; Mazzatorta P, 2004, J CHEM INF COMP SCI, V44, P105, DOI 10.1021/ci034193w; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Michalewicz Z., 1996, GENETIC ALGORITHMS D; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; Molina E, 2004, J CHEM INF COMP SCI, V44, P515, DOI 10.1021/ci0342019; MUELLER KR, 2005, J CHEM INF MODEL, V45, P249; Mulgrew B, 1996, IEEE SIGNAL PROC MAG, V13, P50, DOI 10.1109/79.487041; MULLIKEN RS, 1955, J CHEM PHYS, V23, P1833, DOI 10.1063/1.1740588; Murcia-Soler M, 2004, J CHEM INF COMP SCI, V44, P1031, DOI 10.1021/ci030340e; Pastor M, 2000, J MED CHEM, V43, P3233, DOI 10.1021/jm000941m; PEARLMAN RS, 1988, PHYS CHEM PROPERTIES; Pearlman RS, 1998, PERSPECT DRUG DISCOV, V9-11, P339, DOI 10.1023/A:1027232610247; Phatak A, 1997, J CHEMOMETR, V11, P311, DOI 10.1002/(SICI)1099-128X(199707)11:4<311::AID-CEM478>3.0.CO;2-4; Pirard B, 2004, COMB CHEM HIGH T SCR, V7, P271; Proudfoot Jr, 2002, BIOORG MED CHEM LETT, V12, P1647, DOI 10.1016/S0960-894X(02)00244-5; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rajko R, 2001, CHEMOMETR INTELL LAB, V57, P1, DOI 10.1016/S0169-7439(01)00101-0; RANDIC M, 1975, J AM CHEM SOC, V97, P6609, DOI 10.1021/ja00856a001; Roche O, 2002, J MED CHEM, V45, P137, DOI 10.1021/jm010934d; ROHRBAUGH RH, 1987, ANAL CHIM ACTA, V199, P99, DOI 10.1016/S0003-2670(00)82801-9; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Roy K, 2004, J CHEM INF COMP SCI, V44, P559, DOI 10.1021/ci0342066; Rusinko A, 2002, COMB CHEM HIGH T SCR, V5, P125; Schapire RE, 1998, ANN STAT, V26, P1651; SCHULTZ HP, 1989, J CHEM INF COMP SCI, V29, P227, DOI 10.1021/ci00063a012; Senese CL, 2004, J CHEM INF COMP SCI, V44, P1526, DOI 10.1021/ci049898s; Shoichet BK, 2004, NATURE, V432, P862, DOI 10.1038/nature03197; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Silverman BD, 1996, J MED CHEM, V39, P2129, DOI 10.1021/jm950589q; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Stahura FL, 2004, COMB CHEM HIGH T SCR, V7, P259; Stanton DT, 1999, J CHEM INF COMP SCI, V39, P11, DOI 10.1021/ci980102x; STANTON DT, 1992, J CHEM INF COMP SCI, V32, P306, DOI 10.1021/ci00008a009; Sun HM, 2004, J CHEM INF COMP SCI, V44, P748, DOI 10.1021/ci030304f; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tino P, 2004, J CHEM INF COMP SCI, V44, P1647, DOI 10.1021/ci034255i; Todeschini R, 1998, PERSPECT DRUG DISCOV, V9-11, P355, DOI 10.1023/A:1027284627085; TODESCHINI R, 1994, J CHEMOMETR, V8, P263, DOI 10.1002/cem.1180080405; Trohalaki S, 2004, J CHEM INF COMP SCI, V44, P1186, DOI 10.1021/ci0342627; Venkatraman V, 2004, J CHEM INF COMP SCI, V44, P1686, DOI 10.1021/ci049933v; Verdu-Andres J, 1998, APPL SPECTROSC, V52, P1425, DOI 10.1366/0003702981942843; VPNIK V, 1995, NATURE STAT LEARNING; Waller CL, 2004, J CHEM INF COMP SCI, V44, P758, DOI 10.1021/ci0342526; Waller CL, 1999, J CHEM INF COMP SCI, V39, P345, DOI 10.1021/ci980405r; Wegner JK, 2004, J CHEM INF COMP SCI, V44, P931, DOI 10.1021/ci034233w; Wegner JK, 2004, J CHEM INF COMP SCI, V44, P921, DOI 10.1021/ci0342324; Weiser J, 1998, J COMPUT CHEM, V19, P797, DOI 10.1002/(SICI)1096-987X(199805)19:7<797::AID-JCC9>3.0.CO;2-L; Wessel MD, 1998, J CHEM INF COMP SCI, V38, P726, DOI 10.1021/ci980029a; WIENER H, 1947, J AM CHEM SOC, V69, P17, DOI 10.1021/ja01193a005; Winkler DA, 1998, QUANT STRUCT-ACT REL, V17, P224, DOI 10.1002/(SICI)1521-3838(199806)17:03<224::AID-QSAR224>3.3.CO;2-Y; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1; WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1267, DOI 10.1021/ci049934n; Xue CX, 2004, J CHEM INF COMP SCI, V44, P950, DOI 10.1021/ci034280o; Xue CX, 2004, J CHEM INF COMP SCI, V44, P669, DOI 10.1021/ci034248u; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1693, DOI 10.1021/ci049820b; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1630, DOI 10.1021/ci049869h; Yao XJ, 2004, J CHEM INF COMP SCI, V44, P1257, DOI 10.1021/ci049965i; Zhang HB, 2005, J CHEM INF MODEL, V45, P440, DOI 10.1021/ci0498113; ZHOU ZX, 1990, J AM CHEM SOC, V112, P5720, DOI 10.1021/ja00171a007	158	131	134	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1386-2073			COMB CHEM HIGH T SCR	Comb. Chem. High Throughput Screen	MAR	2006	9	3					213	228		10.2174/138620706776055539		16	Biochemical Research Methods; Chemistry, Applied; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	018KP	WOS:000235763400009	16533155	
J	Prasad, AM; Iverson, LR; Liaw, A				Prasad, AM; Iverson, LR; Liaw, A			Newer classification and regression tree techniques: Bagging and random forests for ecological prediction	ECOSYSTEMS			English	Article						predictive mapping; data mining; classification and regression trees (CART); Regression Tree Analysis (RTA); decision tree; Multivariate Adaptive Regression Splines (MARS); Bagging Trees; Random Forests; Kappa; fuzzy Kappa; Canadian Climate Centre (CCC); global circulation model (GCM); eastern United States	EASTERN UNITED-STATES; CLIMATE-CHANGE; CATEGORICAL MAPS; MIGRATION RATES; PLANT MIGRATION; DECISION-TREE; VEGETATION; HABITAT; DISTRIBUTIONS; CLASSIFIERS	The task of modeling the distribution of a large number of tree species under future climate scenarios presents unique challenges. First, the model must be robust enough to handle climate data outside the current range without producing unacceptable instability in the output. In addition, the technique should have automatic search mechanisms built in to select the most appropriate values for input model parameters for each species so that minimal effort is required when these parameters are fine-tuned for individual tree species. We evaluated four statistical models-Regression Tree Analysis (RTA), Bagging Trees (BT), Random Forests (RF), and Multivariate Adaptive Regression Splines (MARS)-for predictive vegetation mapping under current and future climate scenarios according to the Canadian Climate Centre global circulation model. To test, we applied these techniques to four tree species common in the eastern United States: loblolly pine (Pinus taeda), sugar maple (Acer saccharum), American beech (Fagus grandifolia), and white oak (Quercus alba). When the four techniques were assessed with Kappa and fuzzy Kappa statistics, RF and BT were superior in reproducing current importance value (a measure of basal area in addition to abundance) distributions for the four tree species, as derived from approximately 100,000 USDA Forest Service's Forest Inventory and Analysis plots. Future estimates of suitable habitat after climate change were visually more reasonable with BT and RF, with slightly better performance by RF as assessed by Kappa statistics, correlation estimates, and spatial distribution of importance values. Although RTA did not perform as well as BT and RF, it provided interpretive models for species whose distributions were captured well by our current set of predictors. MARS was adequate for predicting current distributions but unacceptable for future climate. We consider RTA, BT, and RF modeling approaches, especially when used together to take advantage of their individual strengths, to be robust for predictive mapping and recommend their inclusion in the ecological toolbox.	US Forest Serv, USDA, NE Res Stn, Delaware, OH 43015 USA; Merck Res Labs, Biometr Res Dept, Rahway, NJ USA	Prasad, AM (reprint author), US Forest Serv, USDA, NE Res Stn, 359 Main Rd, Delaware, OH 43015 USA.	aprasad@fs.fed.us	Iverson, Louis/C-7554-2009	Iverson, Louis/0000-0001-9501-471X			Abraham A, 2001, LECT NOTES COMPUT SC, V2074, P235; BAKER FA, 1993, PLANT DIS, V77, P136; Boer GJ, 2000, CLIM DYNAM, V16, P427, DOI 10.1007/s003820050338; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2003, SETTING USING UNDERS; BREIMAN L, 2002, IMS WALD LECT, V2; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Buhlmann P, 2002, ANN STAT, V30, P927; CHAMBERS J M., 1998, PROGRAMMING DATA GUI; CHAMBERS JM, 1993, STAT MODELS NEW YORK; Chan JCW, 2001, IEEE T GEOSCI REMOTE, V39, P693; Clark JS, 1998, AM NAT, V152, P204, DOI 10.1086/286162; CLARK L. A., 1992, STAT MODELS S, P377; DAVIS MB, 1989, CLIMATIC CHANGE, V15, P75, DOI 10.1007/BF00138846; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; Dobbertin M, 1998, FOREST SCI, V44, P507; *ENV SYST RES I, 2001, ARC VER 8 1 2; Franklin J, 1998, J VEG SCI, V9, P733, DOI 10.2307/3237291; Franklin J., 1995, PROG PHYS GEOGR, V19, P494; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Furlanello C., 2003, P 3 INT WORKSH DISTR, P1; Hagen A, 2003, INT J GEOGR INF SCI, V17, P235, DOI 10.1080/13658810210157822; HAGEN A, 2002, S55000201RO RIVM MAP; Hansen M, 1996, INT J REMOTE SENS, V17, P1075; HANSEN MH, 1992, NC151 USDA FOR SERV; HAWKINS DM, 1999, COMPUT SCI STAT, V30, P534; Hernandez JE, 1997, J AM MOSQUITO CONTR, V13, P28; Higgins SI, 2003, OIKOS, V101, P354, DOI 10.1034/j.1600-0706.2003.12141.x; Hobbs RJ, 1994, ECOSCIENCE, V1, P346; Hothorn T, 2004, STAT MED, V23, P77, DOI 10.1002/sim.1593; Iverson LR, 1999, ECOL MODEL, V115, P77, DOI 10.1016/S0304-3800(98)00200-2; IVERSON LR, 1999, NE265 USDA FOR SERV; Iverson LR, 2002, FOREST ECOL MANAG, V155, P205, DOI 10.1016/S0378-1127(01)00559-X; Iverson LR, 1998, ECOL MONOGR, V68, P465, DOI 10.2307/2657150; KITTEL TGF, 2000, VEMAP PHASE 2 HIST F; LEES BG, 1991, ENVIRON MANAGE, V15, P823, DOI 10.1007/BF02394820; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Little E. L. J. (, 1971, MISCELLANEOUS PUBLIC, V1146; Little E.L.J., 1977, MISCELLANEOUS PUBLIC; Malcolm JR, 2002, J BIOGEOGR, V29, P835, DOI 10.1046/j.1365-2699.2002.00702.x; Meyer D., 2003, NEUROCOMPUTING, V55, P59; MICHAELSEN J, 1994, J VEG SCI, V5, P673, DOI 10.2307/3235882; Miller JR, 2004, BIOSCIENCE, V54, P310, DOI 10.1641/0006-3568(2004)054[0310:SETSOP]2.0.CO;2; Moisen GG, 2002, ECOL MODEL, V157, P209, DOI 10.1016/S0304-3800(02)00197-7; MONSERUD RA, 1992, ECOL MODEL, V62, P275, DOI 10.1016/0304-3800(92)90003-W; MOORE DM, 1991, ENVIRON MANAGE, V15, P59, DOI 10.1007/BF02393838; Munoz J, 2004, J VEG SCI, V15, P285, DOI 10.1658/1100-9233(2004)015[0285:COSMCU]2.0.CO;2; PETERS A, 2002, R NEWS, V2, P22; Pitelka LF, 1997, AM SCI, V85, P464; Pontius RG, 2000, PHOTOGRAMM ENG REM S, V66, P1011; Power C, 2001, INT J GEOGR INF SCI, V15, P77, DOI 10.1080/136588100750058715; Prasa A.M., 2003, LITTLES RANGE FIA IM; Prasad A.M., 2000, 4 INT C INT GIS ENV; PRASAD AM, 2000, CLIMATE CHANGE ATLAS; R Development Core Team, 2004, R LANG ENV STAT COMP; Reichard SH, 1997, CONSERV BIOL, V11, P193, DOI 10.1046/j.1523-1739.1997.95473.x; *RES I KNOWL SYST, 2003, MAP COMP KIT; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Schwartz MW, 2001, ECOSYSTEMS, V4, P568, DOI 10.1007/s10021-001-0030-3; Skurichina M, 2002, PATTERN ANAL APPL, V5, P121, DOI 10.1007/s100440200011; Steinberg D., 1999, MARS USER GUIDE; STOPPIANA D, 2003, INT J REMOTE SENS, V24, P2131; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Therneau TM, 1997, 61 MAYO CLIN; VERBYLA DL, 1987, CAN J FOREST RES, V17, P1150, DOI 10.1139/x87-177	68	420	433	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-9840			ECOSYSTEMS	Ecosystems	MAR	2006	9	2					181	199		10.1007/s10021-005-0054-1		19	Ecology	Environmental Sciences & Ecology	027OE	WOS:000236424100003		
J	Shi, T; Horvath, S				Shi, T; Horvath, S			Unsupervised learning with random forest predictors	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						biomarkers; cluster analysis; dissimilarity; ensemble predictors; tumor markers	RISK	A random forest (RF) predictor is an ensemble of individual tree predictors. As part of their construction, RF predictors naturally lead to a dissimilarity measure between the observations. One can also define an RF dissimilarity measure between unlabeled data: the idea is to construct an RF predictor that distinguishes the "observed" data from suitably generated synthetic data. The observed data are the original unlabeled data and the synthetic data are drawn from a reference distribution. Here we describe the properties of the RF dissimilarity and make recommendations on how to use it in practice. An RF dissimilarity can be attractive because it handles mixed variable types well, is invariant to monotonic transformations of the input variables, and is robust to outlying observations. The RF dissimilarity easily deals with a large number of variables due to its intrinsic variable selection; for example, the Addcl1 RF dissimilarity weighs the contribution of each variable according to how dependent it is on other variables. We find that the RF dissimilarity is useful for detecting tumor sample clusters on the basis of tumor marker expressions. In this application, biologically meaningful clusters can often be described with simple thresholding rules.	Univ Calif Los Angeles, Dept Human Genet, Gondca Ctr, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Dept Biostat, Gondca Ctr, Los Angeles, CA 90095 USA; Johnson & Johnson Co, Ortho Clin Diagnost, San Diego, CA 92121 USA	Shi, T (reprint author), Univ Calif Los Angeles, Dept Human Genet, Gondca Ctr, Los Angeles, CA 90095 USA.	shitao@uclalumni.net; shorvath@mednet.ucla.edu					Allen E, 2003, P NATL ACAD SCI USA, V100, P9940, DOI 10.1073/pnas.1737401100; Breiman L., 2003, RANDOM FORESTS MANUA; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cox DR, 1990, ANAL SURVIVAL DATA; Cox T. F., 2001, MULTIDIMENSIONAL SCA, V2nd; Hastie T., 2001, ELEMENTS STAT LEARNI; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Kruskal J. B., 1978, MULTIDIMENSIONAL SCA; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; LIU B, 2000, CLTREE CLUSTERING DE; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; R Development Core Team, 2004, R LANG ENV STAT COMP; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Rousseeuw P. J., 1990, FINDING GROUPS DATA; Seligson DB, 2005, NATURE, V435, P1262, DOI 10.1038/nature03672; Shepard R. N., 1972, MULTIDIMENSIONAL SCA; Shi T, 2005, MODERN PATHOL, V18, P547, DOI 10.1038/modpathol.3800322; VENABLES WN, 2002, MODERN APPL STAT SPL; Zhang HP, 1996, AM J EPIDEMIOL, V144, P989	20	38	39	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	MAR	2006	15	1					118	138		10.1198/106186006X94072		21	Statistics & Probability	Mathematics	021AC	WOS:000235953700007		
J	Ulintz, PJ; Zhu, J; Qin, ZHS; Andrews, PC				Ulintz, PJ; Zhu, J; Qin, ZHS; Andrews, PC			Improved classification of mass spectrometry database search results using newer machine learning approaches	MOLECULAR & CELLULAR PROTEOMICS			English	Article							PROTEIN IDENTIFICATION; SPECTRAL DATA; STATISTICAL SIGNIFICANCE; YEAST PROTEOME; TANDEM; ALGORITHM; MS/MS; VALIDATION; PEPTIDES; MODEL	Manual analysis of mass spectrometry data is a current bottleneck in high throughput proteomics. In particular, the need to manually validate the results of mass spectrometry database searching algorithms can be prohibitively time-consuming. Development of software tools that attempt to quantify the confidence in the assignment of a protein or peptide identity to a mass spectrum is an area of active interest. We sought to extend work in this area by investigating the potential of recent machine learning algorithms to improve the accuracy of these approaches and as a flexible framework for accommodating new data features. Specifically we demonstrated the ability of boosting and random forest approaches to improve the discrimination of true hits from false positive identifications in the results of mass spectrometry database search engines compared with thresholding and other machine learning approaches. We accommodated additional attributes obtainable from database search results, including a factor addressing proton mobility. Performance was evaluated using publically available electrospray data and a new collection of MALDI data generated from purified human reference proteins.	Univ Michigan, Natl Resource Proteom & Pathways, Bioinformat Program, Sch Publ Hlth, Ann Arbor, MI 48109 USA; Univ Michigan, Dept Stat, Sch Publ Hlth, Ann Arbor, MI 48109 USA; Univ Michigan, Dept Biostat, Sch Publ Hlth, Ann Arbor, MI 48109 USA	Ulintz, PJ (reprint author), Univ Michigan, Natl Resource Proteom & Pathways, Bioinformat Program, Sch Publ Hlth, 300 N Ingalls Bldg,Rm 1196, Ann Arbor, MI 48109 USA.	pulintz@umich.edu	Qin, Zhaohui/E-8196-2011; Andrews, Philip/	Qin, Zhaohui/0000-0002-1583-146X; Andrews, Philip/0000-0001-6843-5420			Anderson DC, 2003, J PROTEOME RES, V2, P137, DOI 10.1021/pr0255854; Bafna V., 2001, BIOINFORMATICS S1, V17, P13; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARUANA R, 2003, P ANN C AM MED INF A; Craig R, 2004, BIOINFORMATICS, V20, P1466, DOI 10.1093/bioinformatics/bth092; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; Eriksson J, 2004, J PROTEOME RES, V3, P32, DOI 10.1021/pr034048y; Fenyo D, 2003, ANAL CHEM, V75, P768, DOI 10.1021/ac0258709; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Geer LY, 2004, J PROTEOME RES, V3, P958, DOI 10.1021/pr0499491; Graumann J, 2004, MOL CELL PROTEOMICS, V3, P226, DOI 10.1074/mcp.M300099-MCP200; Hastie T., 2001, ELEMENTS STAT LEARNI; Havilio M, 2003, ANAL CHEM, V75, P435, DOI 10.1021/ac0258913; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; Kapp EA, 2003, ANAL CHEM, V75, P6251, DOI 10.1021/ac034616t; Keller A, 2002, ANAL CHEM, V74, P5383, DOI 10.1021/ac025747h; Keller Andrew, 2002, OMICS A Journal of Integrative Biology, V6, P207, DOI 10.1089/153623102760092805; Link AJ, 1999, NAT BIOTECHNOL, V17, P676; MacCoss MJ, 2002, ANAL CHEM, V74, P5593, DOI 10.1021/ac025826t; Moore RE, 2002, J AM SOC MASS SPECTR, V13, P378, DOI 10.1016/S1044-0305(02)00352-5; Nesvizhskii AI, 2003, ANAL CHEM, V75, P4646, DOI 10.1021/ac0341261; Peng JM, 2003, J PROTEOME RES, V2, P43, DOI 10.1021/pr025556v; PERKINS D, 1997, ELECTROPHORESIS, V20, P3551; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Sadygov RG, 2003, ANAL CHEM, V75, P3792, DOI 10.1021/ac034157w; STRAHLER JR, 2005, 53 AM SOC MASS SPECT; Sun W, 2004, MOL CELL PROTEOMICS, V3, P1194, DOI 10.1074/mcp.M400120-MCP200; Tabb DL, 2004, ANAL CHEM, V76, P1243, DOI 10.1021/ac0351163; Vapnik VN, 1999, NATURE STAT LEARNING, P138; Washburn MP, 2001, NAT BIOTECHNOL, V19, P242, DOI 10.1038/85686; Wysocki VH, 2000, J MASS SPECTROM, V35, P1399, DOI 10.1002/1096-9888(200012)35:12<1399::AID-JMS86>3.0.CO;2-R; Zhang N, 2002, PROTEOMICS, V2, P1406, DOI 10.1002/1615-9861(200210)2:10<1406::AID-PROT1406>3.0.CO;2-9	34	40	43	AMER SOC BIOCHEMISTRY MOLECULAR BIOLOGY INC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3996 USA	1535-9476			MOL CELL PROTEOMICS	Mol. Cell. Proteomics	MAR	2006	5	3					497	509		10.1074/mcp.M500233-MCP200		13	Biochemical Research Methods	Biochemistry & Molecular Biology	023RB	WOS:000236142800007	16321970	
J	Gislason, PO; Benediktsson, JA; Sveinsson, JR				Gislason, PO; Benediktsson, JA; Sveinsson, JR			Random Forests for land cover classification	PATTERN RECOGNITION LETTERS			English	Article; Proceedings Paper	3rd Pattern Recognition in Remote Sensing Workshop	AUG   27, 2004	Kingston Upon Thames, ENGLAND	Int Assoc Pattern Recognit	Kingston Univ	random forests; classification; decision trees; multisource remote sensing data	CONSENSUS THEORETIC CLASSIFICATION; REMOTE-SENSING DATA	Random Forests are considered for classification of multisource remote sensing and geographic data. Various ensemble classification methods have been proposed in recent years. These methods have been proven to improve classification accuracy considerably. The most widely used ensemble methods are boosting and bagging. Boosting is based on sample re-weighting but bagging uses bootstrapping. The Random Forest classifier uses bagging, or bootstrap aggregating, to form an ensemble of classification and regression tree (CART)-like classifiers. In addition, it searches only a random subset of the variables for a split at each CART node, in order to minimize the correlation between the classifiers in the ensemble. This method is not sensitive to noise or overtraining, as the resampling is not based on weighting. Furthermore, it is computationally much lighter than methods based on boosting and somewhat lighter than simple bagging. In the paper, the use of the Random Forest classifier for land cover classification is explored. We compare the accuracy of the Random Forest classifier to other better-known ensemble methods on multisource remote sensing and geographic data. (c) 2005 Elsevier B.V. All rights reserved.	Univ Iceland, Dept Elect & Comp Engn, IS-107 Reykjavik, Iceland	Benediktsson, JA (reprint author), Univ Iceland, Dept Elect & Comp Engn, Hjardarhaga 2-6, IS-107 Reykjavik, Iceland.	pallgi@hi.is; benedikt@hi.is; sveinsso@hi.is	Benediktsson, Jon/F-2861-2010				BENEDIKTSSON JA, 1992, IEEE T SYST MAN CYB, V22, P688, DOI 10.1109/21.156582; BENEDIKTSSON JA, 1990, IEEE T GEOSCI REMOTE, V28, P540, DOI 10.1109/TGRS.1990.572944; Benediktsson JA, 1997, IEEE T GEOSCI REMOTE, V35, P833, DOI 10.1109/36.602526; Breiman L, 1994, 421 U CAL DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 2003, SIAM WORKSHOP; Breiman L., 2001, MACH LEARN, V40, P5; Briem GJ, 2002, IEEE T GEOSCI REMOTE, V40, P2291, DOI 10.1109/TGRS.2002.802476; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); GISLASON PO, 2004, P 2004 IEEE INT GEOS, P1049; Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Kohavi R., 1995, P 8 EUR C MACH LEARN, P174; KUNCHEVA LI, 2003, IEEE T FUZZY SYST, V11, P1214; Richards J.A., 1999, REMOTE SENSING DIGIT; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; WITTEN IH, 1993, DATA MINING PRACTICA	19	235	243	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAR	2006	27	4					294	300		10.1016/j.patrec.2005.08.011		7	Computer Science, Artificial Intelligence	Computer Science	007CS	WOS:000234946000011		
J	Menze, BH; Ur, JA; Sherratt, AG				Menze, BH; Ur, JA; Sherratt, AG			Detection of ancient settlement mounds: Archaeological survey based on the SRTM terrain model	PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING			English	Article								In the present study we demonstrate the value of the SRTM three arcsecond terrain model for a virtual survey of archaeological sites: the detection and mapping of ancient settlement mounds in the Near East. These so-called "tells" are the result of millennia of occupation within the period from 8000-1000 BC, and form visible landmarks of the world's first farming and urban communities. The SRTM model provides for the first time an opportunity to scan areas not yet surveyed archaeologically on a supra-regional scale and to pinpoint probable tell sites. In order to map these historic monuments for the purpose of settlement-study and conservation, we develop a machine learning classifier which identifies probable tell sites from the terrain model. In a test, point-like elevations of a characteristic tell shape, standing out for more than 5 to 6 m in the DEM were successfully detected (851133 tells). False positives (327/(600*1200) pixels) were primarily due to natural elevations, resembling tells in height and size.	Univ Heidelberg, Interdisciplinary Ctr Sci Comp, Heidelberg, Germany; Harvard Univ, Dept Anthropol, Cambridge, MA 02138 USA; Univ Sheffield, Dept Archaeol, Sheffield, S Yorkshire, England	Menze, BH (reprint author), Univ Heidelberg, Interdisciplinary Ctr Sci Comp, Bergheimer Str 58, Heidelberg, Germany.	bjoern.menze@iwr.uni-hoidelberg.de					BAEK J, 2004, PATTERN RECOGN, V34, P1303; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; MENZE BH, 2005, FILTERING LINEAR SUB; MENZE BH, 2005, P CIPA INT S 26 SEPT; R Development Core Team, 2004, R LANG ENV STAT COMP; Sherratt A., 2004, ANTIQUITY, V78, P301; Ur J. A., 2002, AKKADICA, V123, P57; UR JA, 2004, THESIS U CHICAGO ULL; Wilkinson T. J., 2000, TELL BEYDAR ENV TECH, VVI, P1	10	24	24	AMER SOC PHOTOGRAMMETRY	BETHESDA	5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA	0099-1112			PHOTOGRAMM ENG REM S	Photogramm. Eng. Remote Sens.	MAR	2006	72	3					321	327				7	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	018GX	WOS:000235753500013		
J	Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartelt, M; Bartko, H; Bastieri, D; Bavikadi, R; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bretz, T; Britvitch, I; Camara, M; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Danielyan, V; Dazzi, F; De Angelis, A; De los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Jacon, P; Kalekin, O; Kranich, D; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Longo, F; Lopez, P; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Merck, M; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Peruzzo, L; Piccioli, A; Prandini, E; Rico, J; Rhode, W; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, SN; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stepanian, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vardanyan, A; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zapatero, J				Albert, J; Aliu, E; Anderhub, H; Antoranz, P; Armada, A; Asensio, M; Baixeras, C; Barrio, JA; Bartelt, M; Bartko, H; Bastieri, D; Bavikadi, R; Bednarek, W; Berger, K; Bigongiari, C; Biland, A; Bisesi, E; Bock, RK; Bretz, T; Britvitch, I; Camara, M; Chilingarian, A; Ciprini, S; Coarasa, JA; Commichau, S; Contreras, JL; Cortina, J; Curtef, V; Danielyan, V; Dazzi, F; De Angelis, A; De los Reyes, R; De Lotto, B; Domingo-Santamaria, E; Dorner, D; Doro, M; Errando, M; Fagiolini, M; Ferenc, D; Fernandez, E; Firpo, R; Flix, J; Fonseca, MV; Font, L; Galante, N; Garczarczyk, M; Gaug, M; Giller, M; Goebel, F; Hakobyan, D; Hayashida, M; Hengstebeck, T; Hohne, D; Hose, J; Jacon, P; Kalekin, O; Kranich, D; Laille, A; Lenisa, T; Liebing, P; Lindfors, E; Longo, F; Lopez, P; Lopez, M; Lorenz, E; Lucarelli, F; Majumdar, P; Maneva, G; Mannheim, K; Mariotti, M; Martinez, M; Mase, K; Mazin, D; Merck, M; Meucci, M; Meyer, M; Miranda, JM; Mirzoyan, R; Mizobuchi, S; Moralejo, A; Nilsson, K; Ona-Wilhelmi, E; Orduna, R; Otte, N; Oya, I; Paneque, D; Paoletti, R; Pasanen, M; Pascoli, D; Pauss, F; Pavel, N; Pegna, R; Peruzzo, L; Piccioli, A; Prandini, E; Rico, J; Rhode, W; Riegel, B; Rissi, M; Robert, A; Rugamer, S; Saggion, A; Sanchez, A; Sartori, P; Scalzotto, V; Schmitt, R; Schweizer, T; Shayduk, M; Shinozaki, K; Shore, SN; Sidro, N; Sillanpaa, A; Sobczynska, D; Stamerra, A; Stepanian, A; Stark, LS; Takalo, L; Temnikov, P; Tescaro, D; Teshima, M; Tonello, N; Torres, A; Torres, DF; Turini, N; Vankov, H; Vardanyan, A; Vitale, V; Wagner, RM; Wibig, T; Wittek, W; Zapatero, J			Observation of gamma rays from the Galactic center with the magic telescope	ASTROPHYSICAL JOURNAL			English	Article						acceleration of particles; Galaxy : center; gamma rays : observations	BLACK-HOLE; SAGITTARIUS-A; CENTER REGION; TEV EMISSION; DARK-MATTER; DIRECTION; EGRET; NEUTRONS; EAST	Recently, the Galactic center has been reported to be a source of very high energy (VHE) gamma-rays by the CANGAROO, VERITAS, and HESS experiments. The energy spectra as measured by these experiments show substantial differences. In this Letter we present MAGIC observations of the Galactic center, resulting in the detection of a differential gamma-ray flux consistent with a steady, hard-slope power law, described as dN gamma/(dA dt dE) = (2.9 +/- 0.6) x 10(-12) (E/TeV)-2.2 +/- 0.2 cm(-2) s(-1) TeV-1. The gamma-ray source is centered at (R.A., decl.) p (17(h)45(m)20(s), -29 degrees 2'). This result confirms the previous measurements by the HESS experiment and indicates a steady source of TeV gamma-rays. We briefly describe the observational technique used and the procedure implemented for the data analysis, and we discuss the results in the perspective of different models proposed for the acceleration of the VHE gamma-rays.	Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany; Inst Fis Altes Energies, E-08193 Barcelona, Spain; ETH, CH-8093 Hongg, Switzerland; Univ Complutense, E-28040 Madrid, Spain; Univ Autonoma Barcelona, E-08193 Barcelona, Spain; Univ Dortmund, D-44227 Dortmund, Germany; Univ Wurzburg, D-97074 Wurzburg, Germany; Univ Padua, I-35131 Padua, Italy; Ist Nazl Fis Nucl, I-35131 Padua, Italy; Univ Udine, I-33100 Udine, Italy; INFN Trieste, I-33100 Udine, Italy; Univ Lodz, PL-90236 Lodz, Poland; Yerevan Phys Inst, AM-375036 Yerevan, Armenia; Tuorla Observ, FI-21500 Piikkio, Finland; Univ Siena, I-53100 Siena, Italy; INFN Pisa, I-53100 Siena, Italy; Univ Calif Davis, Davis, CA 95616 USA; Humboldt Univ, D-12489 Berlin, Germany; Univ Trieste, I-34100 Trieste, Italy; INFN Trieste, I-34100 Trieste, Italy; Inst Nucl Energy Res, BG-1784 Sofia, Bulgaria; Univ Pisa, I-56126 Pisa, Italy; INFN Pisa, I-56126 Pisa, Italy; Inst Ciencies Espai, E-08193 Bellaterra, Barcelona, Spain	Bartko, H (reprint author), Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany.	hbartko@mppmu.mpg.de	De Angelis, Alessandro/B-5372-2009; Mannheim, Karl/F-6705-2012; Flix, Josep/G-5414-2012; Doro, Michele/F-9458-2012; chilingarian, ashot/B-1901-2014; Contreras Gonzalez, Jose Luis/K-7255-2014; Rico, Javier/K-8004-2014; Fernandez, Ester/K-9734-2014; lopez, marcos/L-2304-2014; GAug, Markus/L-2340-2014; Font, Lluis/L-4197-2014; Fernandez, Enrique/L-5387-2014; Tonello, Nadia/L-8065-2014; Moralejo Olaizola, Abelardo/M-2916-2014; Torres, Diego/F-3009-2015; Antoranz, Pedro/H-5095-2015; Miranda, Jose Miguel/F-2913-2013; Fonseca Gonzalez, Maria Victoria/I-2004-2015; Barrio, Juan/L-3227-2014	Doro, Michele/0000-0001-9104-3214; chilingarian, ashot/0000-0002-2018-9715; Contreras Gonzalez, Jose Luis/0000-0001-7282-2394; Rico, Javier/0000-0003-4137-1134; lopez, marcos/0000-0002-8791-7908; GAug, Markus/0000-0001-8442-7877; Font, Lluis/0000-0003-2109-5961; Fernandez, Enrique/0000-0002-6405-9488; Tonello, Nadia/0000-0003-0550-1667; Moralejo Olaizola, Abelardo/0000-0002-1344-9080; Torres, Diego/0000-0002-1522-9065; Antoranz, Pedro/0000-0002-3015-3601; Miranda, Jose Miguel/0000-0002-1472-9690; Fonseca Gonzalez, Maria Victoria/0000-0003-2235-0725; Barrio, Juan/0000-0002-0965-0259			Aharonian F, 2005, ASTRON ASTROPHYS, V432, pL25, DOI 10.1051/0004-6361:200500022; Aharonian F, 2004, ASTRON ASTROPHYS, V425, pL13, DOI 10.1051/0004-6361:200400055; Aharonian F, 2005, ASTROPHYS J, V619, P306, DOI 10.1086/426426; Atoyan A, 2004, ASTROPHYS J, V617, pL123, DOI 10.1086/427390; Baixeras C, 2004, NUCL INSTRUM METH A, V518, P188, DOI 10.1016/j.nima.2003.10.057; Bednarek W, 2002, MON NOT R ASTRON SOC, V331, P483, DOI 10.1046/j.1365-8711.2002.05207.x; Bernlohr K, 2000, ASTROPART PHYS, V12, P255, DOI 10.1016/S0927-6505(99)00093-6; Biermann PL, 2004, ASTROPHYS J, V604, pL29, DOI 10.1086/382072; Bock RK, 2004, NUCL INSTRUM METH A, V516, P511, DOI 10.1016/j.nima.2003.08.157; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bretl T., 2003, P 28 INT COSM RAY C, P2947; BRETZ T, 2003, P 28 INT COSM RAY C, P2943; CORTINA J, 2005, IN PRESS P 29 INT CO; Crocker RM, 2005, ASTROPHYS J, V622, P892, DOI 10.1086/427972; DOMINGOSANTAMAR.E, 2005, IN PRESS P 29 INT CO; Elsasser D, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.171302; FALCKE H, 1993, ASTRON ASTROPHYS, V278, pL1; Fatuzzo M, 2003, ASTROPHYS J, V596, P1035, DOI 10.1086/378041; Fegan DJ, 1997, J PHYS G NUCL PARTIC, V23, P1013, DOI 10.1088/0954-3899/23/9/004; FLIX J, 2005, ASTROPH0505313; Fomin VP, 1994, ASTROPART PHYS, V2, P137, DOI 10.1016/0927-6505(94)90036-1; GAUG M, 2005, IN PRESS P 29 INT CO; Grasso D, 2005, ASTROPART PHYS, V24, P273, DOI 10.1016/j.astropartphys.2005.07.005; Hartman RC, 1999, ASTROPHYS J SUPPL S, V123, P79, DOI 10.1086/313231; Hillas A M, 1985, 19TH P INT COSM RAY, V3, P445; Hooper D, 2005, ADV SPACE RES, V35, P130, DOI 10.1016/j.asr.2003.08.053; Hooper D, 2004, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2004/09/002; Horns D, 2005, PHYS LETT B, V607, P225, DOI 10.1016/j.physletb.2004.12.057; Kosack K, 2004, ASTROPHYS J, V608, pL97, DOI 10.1086/422469; LAROSA RN, 2005, APJ, V626, pL23; LaRosa TN, 2000, ASTRON J, V119, P207, DOI 10.1086/301168; Lessard RW, 2001, ASTROPART PHYS, V15, P1, DOI 10.1016/S0927-6505(00)00133-X; Mayer-Hasselwander HA, 1998, ASTRON ASTROPHYS, V335, P161; MIZOBUCHI S, 2005, IN PRESS P 29 INT CO; Morris M, 1996, ANNU REV ASTRON ASTR, V34, P645, DOI 10.1146/annurev.astro.34.1.645; Pohl M, 1997, ASTRON ASTROPHYS, V317, P441; Pohl M, 2005, ASTROPHYS J, V626, P174, DOI 10.1086/430085; Prada F, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.241301; Quataert E, 2005, ASTROPHYS J, V635, pL45, DOI 10.1086/499126; Rowell GP, 2003, ASTRON ASTROPHYS, V410, P389, DOI 10.1051/0004-6361:20031194; Schodel R, 2002, NATURE, V419, P694, DOI 10.1038/nature01121; Tsuchiya K, 2004, ASTROPHYS J, V606, pL115, DOI 10.1086/421292; WAGNER R, 2005, IN PRESS P 29 INT CO	43	114	114	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X			ASTROPHYS J	Astrophys. J.	FEB 20	2006	638	2	2				L101	L104		10.1086/501164		4	Astronomy & Astrophysics	Astronomy & Astrophysics	013RC	WOS:000235425900013		
J	Salmi, J; Moulder, R; Filen, JJ; Nevalainen, OS; Nyman, TA; Lahesmaa, R; Aittokallio, T				Salmi, J; Moulder, R; Filen, JJ; Nevalainen, OS; Nyman, TA; Lahesmaa, R; Aittokallio, T			Quality classification of tandem mass spectrometry data	BIOINFORMATICS			English	Article							PROTEIN IDENTIFICATION; MS/MS; PROTEOMICS; DATABASES; SEQUEST; PEPTIDES; SCORES	Motivation: Peptide identification by tandem mass spectrometry is an important tool in proteomic research. Powerful identification programs exist, such as SEQUEST, ProICAT and Mascot, which can relate experimental spectra to the theoretical ones derived from protein databases, thus removing much of the manual input needed in the identification process. However, the time-consuming validation of the peptide identifications is still the bottleneck of many proteomic studies. One way to further streamline this process is to remove those spectra that are unlikely to provide a confident or valid peptide identification, and in this way to reduce the labour from the validation phase. Results: We propose a prefiltering scheme for evaluating the quality of spectra before the database search. The spectra are classified into two classes: spectra which contain valuable information for peptide identification and spectra that are not derived from peptides or contain insufficient information for interpretation. The different spectral features developed for the classification are tested on a real-life material originating from human lymphoblast samples and on a standard mixture of 9 proteins, both labelled with the ICAT-reagent. The results show that the prefiltering scheme efficiently separates the two spectra classes.	Univ Turku, Dept Informat Technol, Turku, Finland; Univ Turku, Turku Ctr Comp Sci, Turku, Finland; Univ Turku, Turku Ctr Biotechnol, Turku, Finland; Abo Akad Univ, Turku, Finland; Finnish Inst Occupat Hlth, Helsinki, Finland; Univ Turku, Dept Math, SF-20500 Turku, Finland	Salmi, J (reprint author), Univ Turku, Dept Informat Technol, Turku, Finland.	jussi.salmi@it.utu.fi	Aittokallio, Tero/B-6583-2009	Aittokallio, Tero/0000-0002-0886-9769			Anderson DC, 2003, J PROTEOME RES, V2, P137, DOI 10.1021/pr0255854; Bern M, 2004, BIOINFORMATICS, V20, P49, DOI 10.1093/bioinformatics/bth947; Boehm AM, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-162; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cargile BJ, 2004, J PROTEOME RES, V3, P1082, DOI 10.1021/pr049946o; Chamrad DC, 2004, PROTEOMICS, V4, P619, DOI 10.1002/pmic.200300612; Cormen T. H., 1990, INTRO ALGORITHMS; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; Filen JJ, 2005, PROTEOMICS, V5, P4719, DOI 10.1002/pmic.200402016; Grossmann J, 2005, J PROTEOME RES, V4, P1768, DOI 10.1021/pr050070a; Keller A, 2002, ANAL CHEM, V74, P5383, DOI 10.1021/ac025747h; Keller Andrew, 2002, OMICS A Journal of Integrative Biology, V6, P207, DOI 10.1089/153623102760092805; Kinter M., 2000, PROTEIN SEQUENCING I; MOULDER R, 2005, PROTEOMICS, V11, P2748; Pedrioli PGA, 2004, NAT BIOTECHNOL, V22, P1459, DOI 10.1038/nbt1031; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Purvine S, 2004, OMICS, V8, P255, DOI 10.1089/omi.2004.8.255; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Razumovskaya J, 2004, PROTEOMICS, V4, P961, DOI 10.1002/pmic.200300656; Savitski MM, 2005, MOL CELL PROTEOMICS, V4, P1180, DOI 10.1074/mcp.T500009-MCP200; Sun W, 2004, MOL CELL PROTEOMICS, V3, P1194, DOI 10.1074/mcp.M400120-MCP200; Taylor JA, 2001, ANAL CHEM, V73, P2594, DOI 10.1021/ac001196o; Witten I., 2000, DATA MINING PRACTICA	23	27	29	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	FEB 15	2006	22	4					400	406		10.1093/bioinformatics/bti829		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	011OG	WOS:000235277300003	16352652	
J	Wu, BL				Wu, BL			Differential gene expression detection and sample classification using penalized linear regression models	BIOINFORMATICS			English	Article							CDNA MICROARRAY; STATISTICAL-METHODS; SHRUNKEN CENTROIDS; CLASS PREDICTION; CANCER; NORMALIZATION; SHRINKAGE; DISCOVERY	Differential gene expression detection and sample classification using microarray data have received much research interest recently. Owing to the large number of genes p and small number of samples n (p > n), microarray data analysis poses big challenges for statistical analysis. An obvious problem owing to the 'large p small n' is over-fitting. Just by chance, we are likely to find some non-differentially expressed genes that can classify the samples very well. The idea of shrinkage is to regularize the model parameters to reduce the effects of noise and produce reliable inferences. Shrinkage has been successfully applied in the microarray data analysis. The SAM statistics proposed by Tusher et al. and the 'nearest shrunken centroid' proposed by Tibshirani et al. are ad hoc shrinkage methods. Both methods are simple, intuitive and prove to be useful in empirical studies. Recently Wu proposed the penalized t/F-statistics with shrinkage by formally using the L-1 penalized linear regression models for two-class microarray data, showing good performance. In this paper we systematically discussed the use of penalized regression models for analyzing microarray data. We generalize the two-class penalized t/F-statistics proposed by Wu to multi-class microarray data. We formally derive the ad hoc shrunken centroid used by Tibshirani et al. using the L-1 penalized regression models. And we show that the penalized linear regression models provide a rigorous and unified statistical framework for sample classification and differential gene expression detection.	Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA	Wu, BL (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, A460 Mayo Bldg,MMC 303, Minneapolis, MN 55455 USA.	baolin@biostat.umn.edu					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang CC, 2001, LIBSVM LIB SUPPORT V; DeRisi J, 1996, NAT GENET, V14, P457; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Dudoit S, 2002, STAT SINICA, V12, P111; Efron B, 2004, ANN STAT, V32, P407; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lockhart DJ, 1996, NAT BIOTECHNOL, V14, P1675, DOI 10.1038/nbt1296-1675; Nachtsheim CJNJ, 2004, APPL LINEAR REGRESSI; Parmigiani G., 2003, ANAL GENE EXPRESSION; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Speed T, 2003, STAT ANAL GENE EXPRE; STOREY JD, 2005, UW BIOSTATISTICS WOR, V260; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Wu BL, 2005, BIOINFORMATICS, V21, P1565, DOI 10.1093/bioinformatics/bti217; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15	26	13	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	FEB 15	2006	22	4					472	476		10.1093/bioinformatics/bti827		5	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	011OG	WOS:000235277300013	16352654	
J	Gupta, S; Matthew, S; Abreu, PM; Aires-de-Sousa, J				Gupta, S; Matthew, S; Abreu, PM; Aires-de-Sousa, J			QSAR analysis of phenolic antioxidants using MOLMAP descriptors of local properties	BIOORGANIC & MEDICINAL CHEMISTRY			English	Article						local descriptors; chemical reactivity; neural networks; antioxidant activity	RADICAL SCAVENGING ACTIVITY; CAFFEIC ACID; FLAVONOIDS; DERIVATIVES; GLYCOSIDES	Molecular maps of atom-level properties (MOLMAPs) were developed to represent the diversity of chemical bonds existing in a molecule. Chemical reactivity, being related to the ability for bond breaking and bond making, is primarily determined by the properties of bonds available in a molecule. In order to use physicochemical properties of individual bonds for an entire molecule, and at the same time having a fixed-length molecular representation, all the bonds of a molecule are mapped into a fixed-size 2D self-organizing map (MOLMAP). This article illustrates the application of MOLMAP descriptors to QSAR, with a study of the radical scavenging activity of 47 naturally occurring phenolic antioxidants. Counterpropagation neural networks (CPG NNs) were trained with MOLMAP descriptors selected using genetic algorithms to predict antioxidant activity. The model Was Subsequently validated by the leave-one-out (LOO) procedure obtaining a q(2) of 0.71. Random Forests were grown with the entire set of MOLMAP descriptors giving 70% of correct classifications as potent, active or inactive in a LOO experiment. Interpretations of both models in terms of discriminant variables were concordant and allowed identifying bonds and substructures that are mostly responsible for antioxidant activity. This work shows how MOLMAPs can be used for data mining of structural and biological activity data, leading to the extraction of relationships between local properties and activity. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Nova Lisboa, Dept Quim, Fac Ciencias & Tecnol, P-2829516 Caparica, Portugal	Aires-de-Sousa, J (reprint author), Univ Nova Lisboa, Dept Quim, Fac Ciencias & Tecnol, P-2829516 Caparica, Portugal.	sunil.gupta@dq.fct.unl.pt	Matthew, Susan/E-3817-2012; Aires-de-Sousa, Joao/C-7826-2013; ABREU, PEDRO/C-9074-2013; REQUIMTE, AL/H-9106-2013; REQUIMTE, ORG/M-4578-2013; REQUIMTE, LAQV/N-9835-2013; ABREU, PEDRO/	Aires-de-Sousa, Joao/0000-0002-5887-2966; ABREU, PEDRO/0000-0002-5425-3893			Abougazar H, 2003, PLANTA MED, V69, P814, DOI 10.1055/s-2003-43214; Aires-de-Sousa J, 2002, CHEMOMETR INTELL LAB, V61, P167, DOI 10.1016/S0169-7439(01)00171-X; Amic D, 2003, CROAT CHEM ACTA, V76, P55; Braham H, 2005, J NAT PROD, V68, P517, DOI 10.1021/np049581m; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cheng ZY, 2002, BIOORGAN MED CHEM, V10, P4067, DOI 10.1016/S0968-0896(02)00267-5; Dizhbite T, 2004, BIORESOURCE TECHNOL, V95, P309, DOI 10.1016/j.biortech.2004.02.024; Grayer RJ, 2003, PHYTOCHEMISTRY, V64, P519, DOI 10.1016/S0031-9422(03)00192-4; Heim KE, 2002, J NUTR BIOCHEM, V13, P572, DOI 10.1016/S0955-2863(02)00208-5; Homeyer A. V., 2003, HDB CHEMOINFORMATICS, V3, P1239; Koleva II, 2002, PHYTOCHEM ANALYSIS, V13, P8, DOI 10.1002/pca.611; Lee SK, 1998, COMB CHEM HIGH T SCR, V1, P35; Lien EJ, 1999, FREE RADICAL BIO MED, V26, P285, DOI 10.1016/S0891-5849(98)00190-7; Matsuda H, 2003, BIOORGAN MED CHEM, V11, P5317, DOI 10.1016/j.bmc.2003.09.045; Parejo I, 2004, J ETHNOPHARMACOL, V94, P175, DOI 10.1016/j.jep.2004.05.017; Pellati F, 2004, J PHARMACEUT BIOMED, V35, P289, DOI 10.1016/S0731-7085(03)00645-9; Perez-Castorena AL, 2002, PLANTA MED, V68, P645, DOI 10.1055/s-2002-32890; R Development Core Team, 2004, R LANG ENV STAT COMP; Sadeghipour M, 2005, TOXICOL IN VITRO, V19, P155, DOI 10.1016/j.tiv.2004.06.009; SAROKA Z, 2003, FOOD CHEM TOXICOL, V41, P753; Sergediene E, 1999, FEBS LETT, V462, P392, DOI 10.1016/S0014-5793(99)01561-6; Shimoji Y, 2002, J AGR FOOD CHEM, V50, P6501, DOI 10.1021/jf020458f; Silva MM, 2002, FREE RADICAL RES, V36, P1219, DOI 10.1080/1071576021000016472; SIMON V, 1993, J AM CHEM SOC, V115, P9148, DOI 10.1021/ja00073a034; Song EK, 2001, PLANTA MED, V67, P876, DOI 10.1055/s-2001-18860; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tyrakowska B, 1999, FREE RADICAL BIO MED, V27, P1427, DOI 10.1016/S0891-5849(99)00192-6; Verma RR, 2004, CHEMBIOCHEM, V5, P1188, DOI 10.1002/cbic.200400094; Yokozawa T, 1998, BIOCHEM PHARMACOL, V56, P213, DOI 10.1016/S0006-2952(98)00128-2; Zhang HY, 2004, J MOL STRUC-THEOCHEM, V673, P199, DOI 10.1016/j.theochem.2003.12.014; Zhang HY, 2000, QUANT STRUCT-ACT REL, V19, P375, DOI 10.1002/1521-3838(200010)19:4<375::AID-QSAR375>3.3.CO;2-5; Zupan J., 1999, NEURAL NETWORKS CHEM	32	33	35	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0968-0896			BIOORGAN MED CHEM	Bioorg. Med. Chem.	FEB 15	2006	14	4					1199	1206		10.1016/j.bmc.2005.09.047		8	Biochemistry & Molecular Biology; Chemistry, Medicinal; Chemistry, Organic	Biochemistry & Molecular Biology; Pharmacology & Pharmacy; Chemistry	006PP	WOS:000234909700034	16230016	
J	Blower, PE; Cross, KP; Eichler, GS; Myatt, GJ; Weinstein, JN; Yang, CH				Blower, PE; Cross, KP; Eichler, GS; Myatt, GJ; Weinstein, JN; Yang, CH			Comparison of methods for sequential screening of large compound sets	COMBINATORIAL CHEMISTRY & HIGH THROUGHPUT SCREENING			English	Article						sequential screening; training set selection; Nadaraya-Watson kernel; recursive partitioning; k-nearest neighbors; random forest.	BIOLOGICAL-ACTIVITY; LIBRARY DESIGN; OPTIMIZATION; MOLECULES; SELECTION; IDENTIFY	Sequential screening is an iterative procedure that can greatly increase hit rates over random screening or non-iterative procedures. We studied the effects of three factors on enrichment rates: the method used to rank compounds, the molecular descriptor set and the selection of initial training set. The primary Factor influencing recovery rates was the method of selecting the initial training set. Rates For recovering active compounds were substantially lower with the diverse training sets than they were with training sets selected by other methods. Because structure-activity information is incrementally enhanced in intermediate training sets, sequential screening provides significant improvement in the average rate of recovery of active compounds when compared with non-iterative selection procedures.	Leadscope Inc, Columbus, OH 43215 USA; NCI, Mol Pharmacol Lab, NIH, Bethesda, MD 20892 USA	Blower, PE (reprint author), Leadscope Inc, 1393 Dublin Rd, Columbus, OH 43215 USA.	pblower@leadscope.com					BARNARD JM, 1992, J CHEM INF COMP SCI, V32, P644, DOI 10.1021/ci00010a010; Blower P, 2002, J CHEM INF COMP SCI, V42, P393, DOI 10.1021/ci0101049; BOYD MR, 1995, DRUG DEVELOP RES, V34, P91, DOI 10.1002/ddr.430340203; Bradley EK, 2003, J MED CHEM, V46, P4360, DOI 10.1021/jm020472j; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Efron B, 1993, INTRO BOOTSTRAP; Fligner MA, 2002, TECHNOMETRICS, V44, P110, DOI 10.1198/004017002317375064; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; Hastie T., 2001, ELEMENTS STAT LEARNI, P165; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Higgs RE, 1997, J CHEM INF COMP SCI, V37, P861, DOI 10.1021/ci9702858; Jones-Hertzog DK, 1999, J PHARMACOL TOXICOL, V42, P207, DOI 10.1016/S1056-8719(00)00073-3; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; Monks A, 1997, ANTI-CANCER DRUG DES, V12, P533; Roberts G, 2000, J CHEM INF COMP SCI, V40, P1302, DOI 10.1021/ci0000631; Rusinko A, 2002, COMB CHEM HIGH T SCR, V5, P125; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; van Rhee AM, 2003, J CHEM INF COMP SCI, V43, P941, DOI 10.1021/ci034023j; Weaver DC, 2004, CURR OPIN CHEM BIOL, V8, P264, DOI 10.1016/j.cbpa.2004.04.005; Wilton D, 2003, J CHEM INF COMP SCI, V43, P469, DOI 10.1021/ci025586i	22	8	8	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1386-2073			COMB CHEM HIGH T SCR	Comb. Chem. High Throughput Screen	FEB	2006	9	2					115	122		10.2174/138620706775541882		8	Biochemical Research Methods; Chemistry, Applied; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	014GY	WOS:000235468800006	16475969	
J	Berk, RA				Berk, Richard A.			An introduction to ensemble methods for data analysis	SOCIOLOGICAL METHODS & RESEARCH			English	Article						CART; data analysis; algorithmic methods; ensemble methods	REGRESSION TREES; CLASSIFICATION	This article provides an introduction to ensemble statistical procedures as a special case of algorithmic methods. The discussion begins with classification and regression trees (CART) as a didactic device to introduce many of the key issues. Following the material on CART is a consideration of cross-validation, bagging, random forests, and boosting. Major points are illustrated with analyses of real data.	Univ Calif Los Angeles, Los Angeles, CA 90024 USA	Berk, RA (reprint author), Univ Calif Los Angeles, Los Angeles, CA 90024 USA.						Berk RA, 2005, EVALUATION REV, V29, P358, DOI 10.1177/0193841X05275333; BERK RA, 2003, UNPUB ENSEMBLE PROCE; BERK RA, IN PRESS QUANTITATIV; BREIMAN L, 1984, CLASSIFICASTION REGR; BREIMAN L, 2001, WALD LECT 1 MACHINE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUEHLMANN P, 2002, ANN STAT, V30, P927; CHRISTIANINI N., 2000, INTRO SUPPORT VECTOR; Dasu T., 2003, EXPLORATORY DATA MIN; Faraway J, 2004, J COMPUT GRAPH STAT, V13, P537, DOI 10.1198/106186004X2507; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Grandvalet Y, 2004, MACH LEARN, V55, P251, DOI 10.1023/B:MACH.0000027783.34431.42; Hastie T., 2001, ELEMENTS STAT LEARNI; HOTHORN T, 2003, BUNDLING PREDICTORS; HOTHORN T, 2002, BAGGING SURVIVAL TRE; LeBlanc M, 1996, J AM STAT ASSOC, V91, P1641, DOI 10.2307/2291591; Loh WY, 2002, STAT SINICA, V12, P361; Mannor S., 2002, Computational Learning Theory. 15th Annual Conference on Computational Learning Theory, COLT 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2375); MERTZ CJ, 1999, MACH LEARN, V36, P33; Mojirsheibani M, 1999, J AM STAT ASSOC, V94, P600; Mojirsheibani M, 1997, STAT PROBABIL LETT, V36, P43, DOI 10.1016/S0167-7152(97)00047-3; Rosenbaum P. R., 2002, OBSERVATIONAL STUDIE; Schapire RE, 1999, P 16 INT JOINT C ART; Su XG, 2004, J COMPUT GRAPH STAT, V13, P586, DOI 10.1198/106186004X2165; Witten I. H., 2000, DATA MINING; Zhang H, 1999, RECURSIVE PARTITIONI	31	33	35	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0049-1241			SOCIOL METHOD RES	Sociol. Methods. Res.	FEB	2006	34	3					263	295		10.1177/0049124105283119		33	Social Sciences, Mathematical Methods; Sociology	Mathematical Methods In Social Sciences; Sociology	071AA	WOS:000239567800001		
J	Gey, S; Poggi, JM				Gey, S; Poggi, JM			Boosting and instability for regression trees	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						bagging; boosting; CART; instability; prediction; regression		The AdaBoost like algorithm for boosting CART regression trees is considered. The boosting predictors sequence is analysed on various data sets and the behaviour of the algorithm is investigated. An instability index of a given estimation method with respect to some training sample is defined. Based on the bagging algorithm, this instability index is then extended to quantify the additional instability provided by the boosting process with respect to the bagging one. Finally, the ability of boosting to track outliers and to concentrate on hard observations is used to explore a non-standard regression context. (c) 2004 Elsevier B.V. All rights reserved.	Univ Paris 05, Lab MAP5, F-75006 Paris, France; Univ Paris 11, Math Lab, UMR 8628, F-91405 Orsay, France	Gey, S (reprint author), Univ Paris 05, Lab MAP5, 45,Rue St Peres, F-75006 Paris, France.	servane.gey@math-info.univ-paris5.fr					Borra S, 2002, COMPUT STAT DATA AN, V38, P407, DOI 10.1016/S0167-9473(01)00068-8; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; Buhlmann P, 2002, ANN STAT, V30, P927; CHEZE N, 2003, STAT INF STOCHASTIC, V6, P155, DOI 10.1023/A:1023940117323; Drucker H., 1997, P 14 INT C MACH LEAR, P107; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; GEY S, 2002, 36 U PAR; Ghattas B, 1999, REV STAT APPL, VXLVII, P61; Lugosi G, 2004, ANN STAT, V32, P30; RATSCH G, 2000, P 13 C COMP LEARN TH; Ridgeway G, 1999, P 7 INT WORKSH ART I; Schapire RE, 1999, P 16 INT JOINT C ART; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Vayatis N, 2003, J MACHINE LEARNING R, V4, P861; Zemel RS, 2001, ADV NEUR IN, V13, P696	24	14	14	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JAN 30	2006	50	2					533	550		10.1016/j.csda.2004.09.001		18	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	969PJ	WOS:000232246200016		
J	Sander, O; Sommer, I; Lengauer, T				Sander, O; Sommer, I; Lengauer, T			Local protein structure prediction using discriminative models	BMC BIOINFORMATICS			English	Article							AMINO-ACID-SEQUENCE; SECONDARY STRUCTURE; FOLD RECOGNITION; DATA-BANK; FRAGMENTS; BACKBONE; ALPHABETS; PROSPECTS; PATTERNS; DATABASE	Background: In recent years protein structure prediction methods using local structure information have shown promising improvements. The quality of new fold predictions has risen significantly and in fold recognition incorporation of local structure predictions led to improvements in the accuracy of results. We developed a local structure prediction method to be integrated into either fold recognition or new fold prediction methods. For each local sequence window of a protein sequence the method predicts probability estimates for the sequence to attain particular local structures from a set of predefined local structure candidates. The first step is to define a set of local structure representatives based on clustering recurrent local structures. In the second step a discriminative model is trained to predict the local structure representative given local sequence information. Results: The step of clustering local structures yields an average RMSD quantization error of 1.19 angstrom for 27 structural representatives (for a fragment length of 7 residues). In the prediction step the area under the ROC curve for detection of the 27 classes ranges from 0.68 to 0.88. Conclusion: The described method yields probability estimates for local protein structure candidates, giving signals for all kinds of local structure. These local structure predictions can be incorporated either into fold recognition algorithms to improve alignment quality and the overall prediction accuracy or into new fold prediction methods.	Max Planck Inst Informat, Dept Computat Biol & Appl Algorithm, D-66123 Saarbrucken, Germany	Sander, O (reprint author), Max Planck Inst Informat, Dept Computat Biol & Appl Algorithm, Stuhlsatzenhausweg 85, D-66123 Saarbrucken, Germany.	osander@mpi-sb.mpg.de; sommer@mpi-sb.mpg.de; lengauer@mpi-sb.mpg.de					Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bonneau R, 2001, ANNU REV BIOPH BIOM, V30, P173, DOI 10.1146/annurev.biophys.30.1.173; Bradley P, 2003, PROTEINS, V53, P457, DOI 10.1002/prot.10552; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Bystroff C, 1996, CURR OPIN BIOTECH, V7, P417, DOI 10.1016/S0958-1669(96)80117-0; Camproux AC, 1999, PROTEIN ENG, V12, P1063, DOI 10.1093/protein/12.12.1063; Camproux AC, 2004, J MOL BIOL, V339, P591, DOI 10.1016/j.jmb.2004.04.005; Chang CC, 2001, LIBSVM LIB SUPPORT V; de Brevern AG, 2000, PROTEINS, V41, P271, DOI 10.1002/1097-0134(20001115)41:3<271::AID-PROT10>3.0.CO;2-Z; DeLano W. L., 2002, PYMOL MOL GRAPHICS S; Dodge C, 1998, NUCLEIC ACIDS RES, V26, P313, DOI 10.1093/nar/26.1.313; Du PC, 2003, PROTEIN ENG, V16, P407, DOI 10.1093/protein/gzg052; Etchebest C, 2005, PROTEINS, V59, P810, DOI 10.1002/prot.20458; Fawcett T, 2003, ROC GRAPHS NOTES PRA; Fetrow JS, 1997, PROTEINS, V27, P249, DOI 10.1002/(SICI)1097-0134(199702)27:2<249::AID-PROT11>3.0.CO;2-M; Han KF, 1996, P NATL ACAD SCI USA, V93, P5814, DOI 10.1073/pnas.93.12.5814; HAN KF, 1995, J MOL BIOL, V251, P176, DOI 10.1006/jmbi.1995.0424; Han KF, 1997, PROTEIN SCI, V6, P1587; Hartigan J. A., 1975, CLUSTERING ALGORITHM; HOBOHM U, 1992, PROTEIN SCI, V1, P409; Hou Y, 2003, BIOINFORMATICS, V19, P2294, DOI 10.1093/bioinformatics/btg317; Hsu C.-W., 2003, PRACTICAL GUIDE SUPP; Hunter CG, 2003, PROTEINS, V50, P580, DOI 10.1002/prot.10309; Hunter CG, 2003, PROTEINS, V50, P572, DOI 10.1002/prot.10310; Hvidsten TR, 2003, BIOINFORMATICS, V19, pII81, DOI 10.1093/bioinformatics/btg1064; Karchin R, 2004, PROTEINS, V55, P508, DOI 10.1002/prot.2008; Karchin R, 2003, PROTEINS, V51, P504, DOI 10.1002/prot.10369; KEARSLEY SK, 1989, ACTA CRYSTALLOGR A, V45, P208, DOI 10.1107/S0108767388010128; Kolodny R, 2002, J MOL BIOL, V323, P297, DOI 10.1016/S0022-2836(02)00942-7; Lin Chih-Jen, 2001, COMP METHODS MULTICL; Meyer D, 2002, BENCHMARKING SUPPORT; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; ROOMAN M, 1990, J MOL BIOL, V213, P328; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; SANDER C, 1991, PROTEINS, V9, P56, DOI 10.1002/prot.340090107; Scholkopf B, 2002, LEARNING KERNELS; Simons KT, 1997, J MOL BIOL, V268, P209, DOI 10.1006/jmbi.1997.0959; Soding J, 2003, BIOESSAYS, V25, P837, DOI 10.1002/bies.10321; Viksna J, 2001, LNCS, V2149, P98; VONOHSEN N, 2001, WORKSHOP ALGORITHMS, V2149, P11; WU TF, 2003, PROBABILITY ESTIMATE; Yu K, 2001, THEORETICAL DETERMIN	44	34	35	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JAN 11	2006	7								14	10.1186/1471-2105-7-14		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	012JO	WOS:000235335600001	16405736	
J	Diaz-Uriarte, R; de Andres, SA				Diaz-Uriarte, R; de Andres, SA			Gene selection and classification of microarray data using random forest	BMC BIOINFORMATICS			English	Article							MULTIPLE CANCER TYPES; EXPRESSION DATA; CROSS-VALIDATION; BREAST-CANCER; MULTICLASS CLASSIFICATION; STATISTICAL-METHODS; CLASS PREDICTION; TUMOR; DIAGNOSIS; ALGORITHMS	Background: Selection of relevant genes for sample classification is a common task in most gene expression studies, where researchers try to identify the smallest possible set of genes that can still achieve good predictive performance (for instance, for future use with diagnostic purposes in clinical practice). Many gene selection approaches use univariate (gene-by-gene) rankings of gene relevance and arbitrary thresholds to select the number of genes, can only be applied to two-class problems, and use gene selection ranking criteria unrelated to the classification algorithm. In contrast, random forest is a classification algorithm well suited for microarray data: it shows excellent performance even when most predictive variables are noise, can be used when the number of variables is much larger than the number of observations and in problems involving more than two classes, and returns measures of variable importance. Thus, it is important to understand the performance of random forest with microarray data and its possible use for gene selection. Results: We investigate the use of random forest for classification of microarray data (including multi-class problems) and propose a new method of gene selection in classification problems based on random forest. Using simulated and nine microarray data sets we show that random forest has comparable performance to other classification methods, including DLDA, KNN, and SVM, and that the new gene selection procedure yields very small sets of genes (often smaller than alternative methods) while preserving predictive accuracy. Conclusion: Because of its performance and features, random forest and gene selection using random forest should probably become part of the "standard tool-box" of methods for class prediction and gene selection with microarray data.	Spanish Natl Canc Ctr CNIO, Biotechnol Programme, Bioinformat Unit, Madrid 28029, Spain; Spanish Natl Canc Ctr CNIO, Biotechnol Programme, Cytogenet Unit, Madrid 28029, Spain	Diaz-Uriarte, R (reprint author), Spanish Natl Canc Ctr CNIO, Biotechnol Programme, Bioinformat Unit, Melchor Fernandez Almagro 3, Madrid 28029, Spain.	rdiaz@ligarto.org; salvarez@cnio.es	Diaz-Uriarte, Ramon/M-5517-2013	Diaz-Uriarte, Ramon/0000-0002-6637-9039			Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Alvarez S, 2005, CLIN CANCER RES, V11, P1146; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Bo T., 2002, GENOME BIOL, V3, P11; Braga-Neto U, 2004, BIOINFORMATICS, V20, P253, DOI 10.1093/bioinformatics/btg399; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bureau A, 2003, BMC GENET, V4, DOI 10.1186/1471-2156-4-S1-S64; Burges CJC, 1998, KNOWLEDGE DISCOVERY, V2, P121; Chang C.C., 2003, LIBSVM LIB SUPPORT V; Dettling M, 2004, J MULTIVARIATE ANAL, V90, P106, DOI 10.1016/j.jmva.2004.02.012; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; Diaz-Uriarte R, 2005, DATA ANALYSIS AND VISUALIZATION IN GENOMICS AND PROTEOMICS, P193, DOI 10.1002/0470094419.ch12; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Ein-Dor L, 2005, BIOINFORMATICS, V21, P171, DOI 10.1093/bioinformatics/bth469; FARAWAY J, 1992, J COMPUTATIONAL GRAP, V1, P251; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Furlanello C, 2003, NEURAL NETWORKS, V16, P641, DOI 10.1016/S0893-6080(03)00103-5; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gunther EC, 2003, P NATL ACAD SCI USA, V100, P9608, DOI 10.1073/pnas.1632587100; Harrell J, 2001, REGRESSION MODELING; Hastie T., 2001, ELEMENTS STAT LEARNI; Hua JP, 2005, BIOINFORMATICS, V21, P1509, DOI 10.1093/bioinformatics/bti171; Izmirlian G, 2004, ANN NY ACAD SCI, V1020, P154, DOI 10.1196/annals.1310.015; Jiang HY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-81; Jirapech-Umpai T, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-148; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Li Y, 2002, BIOINFORMATICS, V18, P1332, DOI 10.1093/bioinformatics/18.10.1332; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Man Michael Z, 2004, J Biopharm Stat, V14, P1065, DOI 10.1081/BIP-200035491; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Pan KH, 2005, P NATL ACAD SCI USA, V102, P8961, DOI 10.1073/pnas.0502674102; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; R Development Core Team, 2004, R LANG ENV STAT COMP; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ripley B. D., 1996, PATTERN RECOGNITION; Roepman P, 2005, NAT GENET, V37, P182, DOI 10.1038/ng1502; Romualdi C, 2003, HUM MOL GENET, V12, P823, DOI 10.1093/hmg/ddg093; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Schwender H, 2004, TOXICOL LETT, V151, P291, DOI 10.1016/j.toxlet.2004.02.021; Simon R, 2003, J NATL CANCER I, V95, P14; Simon RM KE, 2003, DESIGN ANAL DNA MICR; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; Svetnik V, 2004, LECT NOTES COMPUT SC, V3077, P334; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; TIERNEY L, 2004, SNOW SIMPLE NETWORK; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vaquerizas JM, 2005, NUCLEIC ACIDS RES, V33, pW616, DOI 10.1093/nar/gki500; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yeung KY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-12-r83; Yeung KY, 2005, BIOINFORMATICS, V21, P2394, DOI 10.1093/bioinformatics/bti319; YU H, 2004, RMPI INTERFACE WRAPP; Zhou X, 2005, BIOINFORMATICS, V21, P1559, DOI 10.1093/bioinformatics/bti216	66	435	447	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JAN 6	2006	7								3	10.1186/1471-2105-7-3		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	010WG	WOS:000235228000002	16398926	
S	Vibha, L; Harshavardhan, GM; Pranaw, K; Deepa, SP; Venugopal, KR; Patnaik, LM		Desai, BC; Gupta, SK		Vibha, L.; Harshavardhan, G. M.; Pranaw, K.; Deepa, Shenoy P.; Venugopal, K. R.; Patnaik, L. M.			Classification of mammograms using decision trees	10th International Database Engineering and Applications Symposium, Proceedings	International Database Engineering and Applications Symposium - Proceedings		English	Proceedings Paper	10th International Database Engineering and Applications Symposium (IDEAS 2006)	DEC 11-14, 2006	Delhi, INDIA	Concordia Univ, IEEE Comp Soc				Mammography is a medical imaging technique that combines, low-dose radiation and high-contrast, high-resolution film for examination of the breast and screening for breast cancer. This paper proposes a Random Forest Decision Classifier (RFDC) for classifying mammograms. Results of screening the mammograms are organised by classification and finally grouped into three categories i.e., Normal, Cancerous and Benign. Experimental results show that this method performs well with the classification accuracy reaching nearly 90% in comparison with the already existing algorithms.	Bangalore Univ, Univ Visvesvaraya Coll Engn, Dept CSE, Bangalore 560001, Karnataka, India	Vibha, L (reprint author), Bangalore Univ, Univ Visvesvaraya Coll Engn, Dept CSE, Bangalore 560001, Karnataka, India.						Antonie M.L., 2001, P 2 INT WORKSH MULT, P94; Breiman L, 1999, 567 U CAL DEP STAT; Christoyianni I, 2000, IEEE SIGNAL PROC MAG, V17, P54, DOI 10.1109/79.814646; LI HD, 1995, IEEE T MED IMAGING, V14, P565, DOI 10.1109/42.414622; VIBHA L, 2003, STUDY BREAST CANC DA; WANG T, 1998, IEEE T MED IMAGING, P498; ZAINE OR, 2002, P 3 INT WORKSH MULT, P62	7	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1098-8068		978-0-7695-2577-8	INT DATABASE ENG APP			2006							263	266				4	Computer Science, Information Systems	Computer Science	BFS96	WOS:000244449800032		
S	Prior, M; Windeatt, T		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Prior, M.; Windeatt, T.			Parameter mining using the out-of-bootstrap generalisation error estimate for Stochastic Discrimination and Random Forests	18th International Conference on Pattern Recognition, Vol 2, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ			CLASSIFIERS	Stochastic Discrimination is a machine learning algorithm with strong theoretical underpinnings and good published results on UCI datasets. However, it has not been popular amongst practitioners. We look at some of the issues involved in its use, propose the Out-of-Bootstrap error estimator as a means of tuning Stochastic Discrimination's and other classifiers' performance and contrast Stochastic Discrimination's utility with that of a related classification technique of Random Forests.	Univ Surrey, CVSSP, Guildford GU2 7XH, Surrey, England	Prior, M (reprint author), Univ Surrey, CVSSP, Guildford GU2 7XH, Surrey, England.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Freund Y., 1996, INT C MACH LEARN, P148; Fumera G, 2005, LECT NOTES COMPUT SC, V3541, P316; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kleinberg EM, 2000, IEEE T PATTERN ANAL, V22, P473, DOI 10.1109/34.857004; KLEINBERG EM, 1990, ANN MATH ARTIFICIAL, V1; KUNCHEVA L, 2003, 1 IB C PATT REC IM A; KUNCHEVA L, 2004, COMBINING PATTERN CL, P229; Prior M, 2005, LECT NOTES COMPUT SC, V3541, P286; RAO J, 1996, OUT OF BOOTSTRAP MET; TIBSHIRANI R, 2001, ELEMENTS STAT LEARNI, P274; TIN KH, C4 5 DECISION FOREST; Windeatt T, 2003, PATTERN RECOGN, V36, P2743, DOI 10.1016/S0031-3203(03)00191-2	15	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2521-0	INT C PATT RECOG			2006							498	501				4	Computer Science, Artificial Intelligence	Computer Science	BFB28	WOS:000240678300119		
S	Kovalev, VA; Petrou, M		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Kovalev, Vassili A.; Petrou, Maria			The classification gradient	18th International Conference on Pattern Recognition, Vol 3, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ				We propose a method that uses bootstraping to classify the pixles in the two halves of a sliding window, assuming that if there is a real image boundary separating the two halves, the pixels in the two halves will be classified in two separate classes. The accuracy of the classification is used as a local "gradient". High values of this gradient allow us to detect weak statistical borders in 2D and 3D images.	Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	Kovalev, VA (reprint author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.						Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cortes C., 1995, MACH LEARN, V20, P1; Dimitriadou E., 2005, E1071 MISC FUNCTIONS; Jackson A, 2002, AM J NEURORADIOL, V23, P7; KOVALEV VA, 2005, 8 INT C PATT REC INF, P229; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; MIRA JG, 1982, INT J RADIAT ONCOL, V8, P1625; Petrou M, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P970; Tan BB, 2003, CHEST, V123, p89S, DOI 10.1378/chest.123.1_suppl.89S; THERNEAU TM, 2005, RPART RECURSIVE PROG; WEHRENS R, 2004, CHEMOMETRICS INTELLI, P54	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2521-0	INT C PATT RECOG			2006							830	833				4	Computer Science, Artificial Intelligence	Computer Science	BFB29	WOS:000240705600200		
S	Andra, S; Nagy, G		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Andra, Srinivas; Nagy, George			Combining dichotomizers for MAP field classification	18th International Conference on Pattern Recognition, Vol 4, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ				A new method for combining dichotomizers like SVMs is proposed for classifying multi-class pattern fields. The novelty lies in the estimation of the style-constrained posterior field class probabilities from the frequencies of the training patterns in the regions of the feature space engendered by the pairwise decision boundaries of the dichotomizers. We show that on simulated data, this non-parametric field classifier is nearly optimal. On scanned printed digits, its accuracy is comparable to that of state-of-the-art style classifiers.	Rensselaer Polytech Inst, DocLab, ECSE, Troy, NY 12180 USA	Andra, S (reprint author), Rensselaer Polytech Inst, DocLab, ECSE, Troy, NY 12180 USA.						ANDRA S, 2005, COMBINING DICHOTOMIZ; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Gunter S, 2004, LECT NOTES COMPUT SC, V3138, P583; Lam L., 1997, HDB CHARACTER RECOGN, P79; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Sarkar M, 2005, THER DRUG MONIT, V27, P1, DOI 10.1097/00007691-200502000-00001; SAVICKY P, 2003, P 5 INT S INT DAT AN; Vapnik V., 1998, STAT LEARNING THEORY; Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19; VEERAMACHANENI S, 2003, P 6 INT C DOC AN REC, P1060; ZASLAVSKY T, 1975, MEM AM MATH SOC, V1, P154; ZHANG X, 2006, P SPIE ELECT IMAGING, V6067; ZHANG X, 2006, INT C PATTERN RECOGN	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2521-0	INT C PATT RECOG			2006							210	214				5	Computer Science, Artificial Intelligence	Computer Science	BFB30	WOS:000240707600051		
B	Joelsson, SR; Benediktsson, JA; Sveinsson, JR			IEEE	Joelsson, Sveinn R.; Benediktsson, Jon Atli; Sveinsson, Johannes R.			Feature selection for morphological feature extraction using random forests	2006 7th Nordic Signal Processing Symposium			English	Proceedings Paper	7th Nordic Signal Processing Symposium	JUN 07-09, 2006	Reykjavik, ICELAND				CLASSIFICATION	Morphological feature extraction (MFE) has been successfully used to increase classification accuracy and reduce the noise level for classification of aerial images. In this paper we explore feature selection and extraction for MFE using random forests (RFs) for classification and feature selection. The approach is compared to MFE from principal components extracted from the data, by principal component analysis (PCA), which has been successful in the past. The experimental results presented in this paper show that by estimating the most important features of our data set using RFs, and selecting a few of said features for MFE yields equal or better accuracies than by using PCs.	Univ Iceland, Dept Elect & Comp Engn, IS-107 Reykjavik, Iceland	Joelsson, SR (reprint author), Univ Iceland, Dept Elect & Comp Engn, Hjardarhaga 2-6, IS-107 Reykjavik, Iceland.						Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011; Soille P., 2003, MORPHOLOGICAL IMAGE	4	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0412-4				2006							10	13				4	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BFY15	WOS:000245415000004		
B	Joelsson, SR; Benediktsson, JA; Sveinsson, JR			IEEE	Joelsson, Sveinn R.; Benediktsson, Jon Atli; Sveinsson, Johannes R.			Feature selection for morphological feature extraction using random forests	2006 7th Nordic Signal Processing Symposium			English	Proceedings Paper	7th Nordic Signal Processing Symposium	JUN 07-09, 2006	Reykjavik, ICELAND				CLASSIFICATION	Morphological feature extraction (MFE) has been successfully used to increase classification accuracy and reduce the noise level for classification of aerial images. In this paper we explore feature selection and extraction for MFE using random forests (RFs) for classification and feature selection. The approach is compared to MFE from principal components extracted from the data, by principal component analysis (PCA), which has been successful in the past. The experimental results presented in this paper show that by estimating the most important features of our data set using RFs, and selecting a few of the features for MFE yields equal or better accuracies than by using PCs.	Univ Iceland, Dept Elect & Comp Engn, IS-107 Reykjavik, Iceland	Joelsson, SR (reprint author), Univ Iceland, Dept Elect & Comp Engn, Hjardarhaga 2-6, IS-107 Reykjavik, Iceland.		Benediktsson, Jon/F-2861-2010				Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011; Soille P., 2003, MORPHOLOGICAL IMAGE	4	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0412-4				2006							138	141				4	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BFY15	WOS:000245415000036		
S	Xue, J; Zhao, YX			IEEE	Xue, Jian; Zhao, Yunxin			Random forests-based confidence annotation using novel features from confusion network	2006 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING, VOLS 1-13	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	31st IEEE International Conference on Acoustics, Speech and Signal Processing	MAY 14-19, 2006	Toulouse, FRANCE	IEEE Signal Proc Soc				(1)In this paper, we propose a set of new features for confidence annotation, including three features derived from confusion network and one from statistical significance test. We also propose using Random Forests as confidence classifier. The new features are combined with a set of eight previously proposed confidence features, and the Random Forests is compared with Decision tree and Support Vector Machine. Experiments were conducted on telehealth captioning task with a vocabulary size of 46,489. Average confidence annotation accuracy of 84.69% was achieved on 5 doctors' test set. In addition, Random Forests was shown useful for feature importance ranking. The proposed features are shown important in confidence annotation and Random Forests achieved best results among the three classifiers.	Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA	Xue, J (reprint author), Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.	jxwr7@mizzou.edu; zhaoy@missouri.edu					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DONG B, 2005, P INT, P1457; EVERMANN G, 2000, P ICASSP, P1655; FU Y, 2005, P ICASSP, P93; GRETTER R, 2001, P INT C AC SPEECH SI, P557; HAKKANITUR D, 2002, P ICASSP, P3904; Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152; SARIKAYA R, 2003, P ICASSP, P604; Wessel F, 1998, INT CONF ACOUST SPEE, P225, DOI 10.1109/ICASSP.1998.674408; XUE J, 2005, P ICASSP, P853; Zhang R., 2001, P 7 EUR C SPEECH COM, P2105; ZHAO Y, 2006, P ICASSP 2006 MAY	12	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-0468-1	INT CONF ACOUST SPEE			2006							1149	1152				4	Acoustics; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Acoustics; Computer Science; Engineering; Imaging Science & Photographic Technology	BFZ22	WOS:000245559901170		
J	Zhang, J; Zulkernine, M			IEEE	Zhang, Jiong; Zulkernine, Mohammad			Anomaly Based Network Intrusion Detection with Unsupervised Outlier Detection	2006 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-12	IEEE International Conference on Communications		English	Proceedings Paper	IEEE International Conference on Communications (ICC 2006)	JUN 11-15, 2006	Istanbul, TURKEY	IEEE				Anomaly detection is a critical issue in Network Intrusion Detection Systems (NIDSs). Most anomaly based NIDSs employ supervised algorithms, whose performances highly depend on attack-free training data. However, this kind of training data is difficult to obtain in real world network environment. Moreover, with changing network environment or services, patterns of normal traffic will be changed. This leads to high false positive rate of supervised NIDSs. Unsupervised outlier detection can overcome the drawbacks of supervised anomaly detection. Therefore, we apply one of the efficient data mining algorithms called random forests algorithm in anomaly based NIDSs. Without attack-free training data, random forests algorithm can detect outliers in datasets of network traffic. In this paper, we discuss our framework of anomaly based network intrusion detection. In the framework, patterns of network services are built by random forests algorithm over traffic data. Intrusions are detected by determining outliers related to the built patterns. We present the modification on the outlier detection algorithm of random forests. We also report our experimental results over the KDD'99 dataset. The results show that the proposed approach is comparable to previously reported unsupervised anomaly detection approaches evaluated over the KDD'99 dataset.	[Zhang, Jiong; Zulkernine, Mohammad] Queens Univ, Sch Comp, Kingston, ON K7L 3N6, Canada	Zhang, J (reprint author), Queens Univ, Sch Comp, Kingston, ON K7L 3N6, Canada.	zhang@cs.queensu.ca; mzulker@cs.queensu.ca					Barbarra D, 2001, P 2001 IEEE WORKSH I; Barnett V, 1994, OUTLIERS STAT DATA, V3rd; BIVENS A, 2002, ARTIFICAL NEURAL NET; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Elkan C., 2000, SIGKDD EXPLORATIONS, V1, P63; Eskin Eleazar, 2002, APPL DATA MINING COM; Guo L., 2004, P 15 INT S SOFTW REL, P417, DOI DOI 10.1109/ISSRE.2004.35; KINGLSY L, 2005, AUSTR COMP SCI C NEW; Kou Y., 2003, P 3 IEEE INT C DAT M; LAZAREVIC A, 2003, P SIAM C DAT MIN SAN; Mahoney M., 2003, P REC ADV INTR DET R; MIT Lincoln Laboratory, DARPA INTR DET EV; POPESCU BE, 2004, THESIS STANFORD U; RAMADAS M, 2003, RAID; SMITH R, 2002, WL HAWK GRAD RES C 2; *SNORT, NETW INTR DET SYST; SUSAN MB, 2000, P NAT INF SYST SEC C; TAN KMC, 2002, RAID; Tran Q. A., 2004, 2 NETW RES WORKSH 18; *U WAIK, WEKA SOFTW MACH LEAR; Witten I. H., 1999, DATA MINING PRACTICA; Wu T.F., 2004, J MACHINE LEARNING R, V5; WU YI, 2004, THESIS STATE U NEW Y; Zhang J., 2005, P 3 ANN C PRIV SEC T; 1999, KDD 99 DATASETS UCI	25	12	13	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-3607		978-1-4244-0354-7	IEEE ICC			2006							2388	2393				6	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BTI69	WOS:000287032702082		
B	Waske, B; Schiefer, S; Braun, M			IEEE	Waske, Bjoern; Schiefer, Sebastian; Braun, Matthias			Random feature selection for decision tree classification of multi-temporal SAR data	2006 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS 1-8	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 31-AUG 04, 2006	Denver, CO	IEEE, IEEE Geosci & Remote Sensing Soc, Canadian Remote Sensing Soc, NASA, NOAA, Off Naval Res, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Ball Aerosp & Technologies Corp, Cooperat Inst Res Atmosphere, Colorado State Univ, Univ Colorado, Int Union Radio Sci		classification; decision free; multiple classifiers; random feature selection; SAR; multi-temporal	LAND-COVER CLASSIFICATION; CLASSIFIERS; SERIES	The accuracy of supervised land cover classifications depends on variables like the chosen algorithm, adequate training data and the selection of features. It has been shown that classification results can be improved by classifier ensembles. In the present study decision trees have been generated with random selections of all available features and combined into such a multiple classifier. The influence of the number of selected features and the size of the multiple classifiers on classification accuracy is investigated using a set of 14 SAR images. Results of multiple classifiers are always better than those of a decision tree based on all available features. Maximum accuracies were achieved with multiple classifiers that use decision trees based on 70% of the available features. The visual inspection of produced maps underlines the high quality of the results. The area is classified into homogeneous fields with little noise, only.	[Waske, Bjoern; Schiefer, Sebastian; Braun, Matthias] Univ Bonn, Ctr Remote Sensing Land Surfaces ZFL, D-53113 Bonn, Germany	Waske, B (reprint author), Univ Bonn, Ctr Remote Sensing Land Surfaces ZFL, D-53113 Bonn, Germany.	bwaske@uni-bonn.de	van der Linden, Sebastian/B-4516-2008				Benediktsson JA, 1997, IEEE T GEOSCI REMOTE, V35, P833, DOI 10.1109/36.602526; Blaes X, 2005, REMOTE SENS ENVIRON, V96, P352, DOI 10.1016/j.rse.2005.03.010; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Briem GJ, 2002, IEEE T GEOSCI REMOTE, V40, P2291, DOI 10.1109/TGRS.2002.802476; Bryll R, 2003, PATTERN RECOGN, V36, P1291, DOI 10.1016/S0031-3203(02)00121-8; Chust G, 2004, INT J REMOTE SENS, V25, P3513, DOI 10.1080/0143116032000160480; Del Frate F, 2003, IEEE T GEOSCI REMOTE, V41, P1611, DOI 10.1109/TGRS.2003.813530; Freund Y., 1996, P 13 INT C MACH LEAR; Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7; Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011; HO TK, 1998, IEEE T PATT ANALYS M, V20, P882; Kittler J, 1998, PATTERN ANAL APPL, V1, P18, DOI 10.1007/BF01238023; Latinne P, 2002, PATTERN ANAL APPL, V5, P201, DOI 10.1007/s100440200018; Laur H., 2002, ESTNREPMHL09 ESA; Pal M, 2003, REMOTE SENS ENVIRON, V86, P554, DOI 10.1016/S0034-4257(03)00132-9; QUINLAN JR, 1996, 13 NAT C ART INT POR; Quinlan JR, 1993, PROGRAMS MACHINE LEA	18	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-7803-9509-1	INT GEOSCI REMOTE SE			2006							168	171		10.1109/IGARSS.2006.48		4	Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Geology; Remote Sensing; Imaging Science & Photographic Technology	BIN08	WOS:000260989400044		
B	Kuo, BC; Chi, MH; Hung, CC; Hsieh, TY			IEEE	Kuo, Bor-Chen; Chi, Ming-Hung; Hung, Chin-Cheng; Hsieh, Tien-Yu			A Comparison of Hierarchical Classification Processes Based on Hyperspectral Image	2006 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS 1-8	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 31-AUG 04, 2006	Denver, CO	IEEE, IEEE Geosci & Remote Sensing Soc, Canadian Remote Sensing Soc, NASA, NOAA, Off Naval Res, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Ball Aerosp & Technologies Corp, Cooperat Inst Res Atmosphere, Colorado State Univ, Univ Colorado, Int Union Radio Sci		hierarchical classification; max-cut; feature extraction		In this study, the performances of hyperspectral image classification using three max-cut based BHC schemes are compared. The first one is original BHC scheme and the second is applied feature extraction in the root node. The last is applied feature extraction in the each non-leaf node. The real data experimental results show that applying feature extraction in the each non-leaf node is the best strategy. Among the combinations of two feature extraction methods, DAFE and NWFE and three base classifiers, using NWFE and NIL base classifier can reach the best performance.	[Kuo, Bor-Chen; Chi, Ming-Hung] Natl Taichung Univ, Grad Sch Educ Measurement & Stat, Taichung, Taiwan	Kuo, BC (reprint author), Natl Taichung Univ, Grad Sch Educ Measurement & Stat, Taichung, Taiwan.	kbc@mail.ntcu.edu.tw; bms093106@ms3.ntcu.edu.tw; chung@spsu.edu; yoyostationyoyo@hotmail.com					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHEN Y, 2004, IEEE INT GEOSC REM S, V2, P949; Cristianini N., 2000, INTRO SUPPORT VECTOR; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; HERBRICH R., 2002, LEARNING KERNEL CLAS; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; KUMAR S, 1999, GAMLS GEN FRAMEWORK; KUO BC, IEEE T GEOS IN PRESS; Rajan S, 2004, LECT NOTES COMPUT SC, V3077, P283; SHAWETAYLOR J, 2004, KERNEL METHODS PATTE, P195; Todd M.J., 2001, SEMIDEFINITE OPTIMIZ; Vapnik VN, 1995, NATURE STAT LEARNING	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-7803-9509-1	INT GEOSCI REMOTE SE			2006							948	951		10.1109/IGARSS.2006.244		4	Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Geology; Remote Sensing; Imaging Science & Photographic Technology	BIN08	WOS:000260989400239		
B	Kellndorfer, JM; Walker, W; LaPoint, E; Hoppus, M; Westfall, J			IEEE	Kellndorfer, Josef M.; Walker, Wayne; LaPoint, Elizabeth; Hoppus, Mike; Westfall, Jim			Modeling Height, Biomass, and Carbon in US Forests from FIA, SRTM, and Ancillary National Scale Data Sets	2006 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS 1-8	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 31-AUG 04, 2006	Denver, CO	IEEE, IEEE Geosci & Remote Sensing Soc, Canadian Remote Sensing Soc, NASA, NOAA, Off Naval Res, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Ball Aerosp & Technologies Corp, Cooperat Inst Res Atmosphere, Colorado State Univ, Univ Colorado, Int Union Radio Sci		Biomass; Carbon; Vegetation Height; Scattering Phase Center Height; InSAR; Radar; Interferometry; Optical; Multi-spectral; SRTM; Landsat ETM; Forest Inventory; DEM; Object Oriented; Segmentation; Regression Trees	RADAR TOPOGRAPHY MISSION	A U.S. national scale modeling effort is underway to map height, biomass and carbon layers for the Year 2000 exploiting synergies among recently developed national-scale data sets derived from Shuttle Radar Topography Mission (SRTM) and Landsat ETM data. Due to the short radar wavelengths used for the SRTM mission (C-band and X-band), the SRTM InSAR signal represents a reflective surface rather than the ground elevation whenever vegetation or anthropogenic features are present. By differencing ground elevations from SRTM elevations over vegetated terrain a spatially continuous height signal, the mean height of the scattering phase center (MH(SPC)), can be extracted which is correlated with true vegetation canopy height. The MH(SPC) is dependent on the scattering characteristics of the observed canopy which are largely a function of vegetation cover type, density, and phenological state. Given a ground measured reference dataset of vegetation canopy height, the SRTM MH(SPC) signal can then be used with information on cover type and density to spatially estimate vegetation canopy height with empirically developed regression models. Subsequently, given spatial estimates of vegetation canopy height in conjunction with information on vegetation cover type and density, aboveground dry biomass can be modeled as well. Finally, spatial data layers of carbon distribution can be calculated with established aboveground dry biomass to carbon conversion factors. Within the conterminous United States, a timely confluence of spatial data sets provides the framework for the development of empirical regression models and their application at a national scale. In addition to the SRTM mission, national-scale data sets of ground surface elevation (i.e., National Elevation Dataset, NED), existing vegetation type (i.e., LANDFIRE) and canopy density (i.e., National Land Cover Database, NLCD 2001,) are currently being produced for the circa 2000 timeframe. These data sets are complemented by a database of ca. 150,000 forest plots provided by the USDA Forest Service Forest Inventory and Analysis (FIA) program. A novel approach based on object-oriented image analysis is employed to address SRTM inherent noise characteristics and to enhance the accuracy of the InSAR signal. As a statistical modeling framework a regression tree based approach is employed. A prototype study in central Utah covering 62,000 km(2) (i.e., NLCD 2001 mapping zone 16), which contains a diversity of vegetation types is now completed. Based on data from 508 FIA field plots, overall vegetation canopy height and aboveground dry biomass estimates at r(2) (and absolute error) values of 0.78 (2.1 m) and 0.56 (24 tons/ha) were obtained. The NBCD 2000 project is scheduled for completion in late 2008. Data will be accessible at 30 m postings via the U.S. Geological Survey seamless data server as mapping zones are completed.	[Kellndorfer, Josef M.; Walker, Wayne] Woods Hole Res Ctr, Falmouth, MA 02540 USA	Kellndorfer, JM (reprint author), Woods Hole Res Ctr, 149 Woods Hole Rd, Falmouth, MA 02540 USA.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; *FIA, 2004, FOR INV AN NAT COR F, V1; GESCH DB, 2006, DIGITAL ELE IN PRESS; Homer C, 2004, PHOTOGRAMM ENG REM S, V70, P829; KELLNDOFER J, 2006, REMOTE SENSING UNPUB; Kellndorfer J, 2004, REMOTE SENS ENVIRON, V93, P339, DOI 10.1016/j.rse.2004.07.017; PIERCE LE, 2006, PHOTOGRAMME IN PRESS; Rodriguez E, 2006, PHOTOGRAMM ENG REM S, V72, P249; Smith B, 2003, GEOPHYS RES LETT, V30, DOI 10.1029/2002GL016643; WALKER WS, 2006, REMOTE SENSING UNPUB	10	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-7803-9509-1	INT GEOSCI REMOTE SE			2006							3591	3594		10.1109/IGARSS.2006.920		4	Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Geology; Remote Sensing; Imaging Science & Photographic Technology	BIN08	WOS:000260989402106		
S	Hernandez-Lobato, D; Martinez-Munoz, G; Suarez, A			IEEE	Hernandez-Lobato, Daniel; Martinez-Munoz, Gonzalo; Suarez, Alberto			Pruning in ordered regression bagging ensembles	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE				An efficient procedure for pruning regression ensembles is introduced. Starting from a bagging ensemble, pruning proceeds by ordering the regressors in the original ensemble and then selecting a subset for aggregation. Ensembles of increasing size are built by including first the regressors that perform best when aggregated. This strategy gives an approximate solution to the problem of extracting from the original ensemble the minimum error subensemble, which we prove to be NP-hard. Experiments show that pruned ensembles with only 20% of the initial regressors achieve better generalization accuracies than the complete bagging ensembles. The performance of pruned ensembles is analyzed by means of the bias-variance decomposition of the error.	Univ Autonoma Madrid, Dept Comp Sci, Escuela Politecn Super, E-28049 Madrid, Spain	Hernandez-Lobato, D (reprint author), Univ Autonoma Madrid, Dept Comp Sci, Escuela Politecn Super, C Francisco Tomas & Valiente 11, E-28049 Madrid, Spain.	daniel.hernandez@uam.es; gonzalo.matrinez@uam.es; alberto.suarez@uam.es	Hernandez-Lobato, Daniel/E-8337-2012; Martinez-Munoz, Gonzalo/K-7269-2012; Suarez, Alberto/D-6293-2011	Hernandez-Lobato, Daniel/0000-0001-5845-437X; Martinez-Munoz, Gonzalo/0000-0002-6125-6056; Suarez, Alberto/0000-0003-4534-0909			Bakker B, 2003, NEURAL NETWORKS, V16, P261, DOI 10.1016/S0893-6080(02)00187-9; Bengio Y, 2004, J MACH LEARN RES, V5, P1089; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 1999, USING ADAPTIVE BAGGI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown G, 2005, J MACH LEARN RES, V6, P1621; Chambers J. M., 1992, STAT MODELS S; Cormen T. H., 1990, INTRO ALGORITHMS; Drucker H., 1997, P 14 INT C MACH LEAR, P107; Efron B., 1994, INTRO BOOTSTRAP; Frank E., 2005, DATA MINING PRACTICA; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; HASHEM S, 1999, COMBINING ARTIFICIAL, P101; Jacobs M, 1991, J Laparoendosc Surg, V1, P79, DOI 10.1089/lps.1991.1.79; KROGH A, 1992, ADV NEUR IN, V4, P950; KUNG FH, 1986, P STAT COMP SECT AM, P340; Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; Martinez-Munoz G, 2004, Proceedings of the IASTED International Conference on Artificial Intelligence and Applications, Vols 1and 2, P258; Nocedal J., 1999, NUMERICAL OPTIMIZATI; Perrone M. P., 1993, NEURAL NETWORKS SPEE, P126; R Development Core Team, 2005, R LANG ENV STAT COMP; UEDA N, 1996, P INT C NEUR NETW, P90; Venables W. N., 2002, MODERN APPL STAT; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	26	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							1266	1273				8	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125902030		
S	Guyon, I; Alamdari, ARSA; Dror, G; Buhmann, JM			IEEE	Guyon, Isabelle; Alamdari, Amir Reza Saffari Azar; Dror, Gideon; Buhmann, Joachim M.			Performance prediction challenge	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE				A major challenge for machine learning algorithms in real world applications is to predict their performance. We have approached this question by organizing a challenge in performance prediction for WCCI 2006. The class of problems addressed are classification problems encountered in pattern recognition (classification of images, speech recognition), medical diagnosis, marketing (customer categorization), text categorization (filtering of spam). Over 100 participants have been trying to build the best possible classifier from training data and guess their generalization error on a large unlabeled test set. The challenge scores indicate that cross-validation yields good results both for model selection and performance prediction. Alternative model selection strategies were also sometimes employed with success. The challenge web site keeps open for post-challenge submissions: http://www.modelselecLinf.ethz.ch/.	Graz Univ Technol, ICG, A-8010 Graz, Austria	Guyon, I (reprint author), Graz Univ Technol, ICG, A-8010 Graz, Austria.	isabelle@clopinet.com					Bishop C., 1996, NEURAL NETWORKS PATT, V1st; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang CC, 2001, LIBSVM LIB SUPPORT V; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GUYON I, 2005, EXPT DESIGN WCCI 200; Guyon I., 2005, ADV NEURAL INFORM PR, V17, P545; Hastie T., 2001, SPRINGER SERIES STAT; KAZAKOV D, MLNET MACHINE LEARNI; KEARNS MJ, 1995, COMPUTATIONAL LEARNI, P21; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; Newman C.B.D.J., 1998, UCI REPOSITORY MACHI; Stoppiglia H., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753733; Vapnik V., 1998, STAT LEARNING THEORY; WEBB A, 2002, STAT PASTTERN RECOGN; Weston J., 2005, SPIDER MACHINE LEARN	17	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							1649	1656				8	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125903007		
S	Dahinden, C			IEEE	Dahinden, Corinne			Classification with tree-based ensembles applied to the WCCI 2006 Performance Prediction Challenge datasets	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE				Our contribution to the WCC1 2006 Performance Prediction Challenge is built on a modified Random Forests scheme, with cross-validation as a means for tuning parameters and estimating error-rates. This simple and computationally very efficient approach was found to yield better predictive performance than many algorithms of much higher complexity.	ETH, Seminar Stat, CH-8092 Zurich, Switzerland	Dahinden, C (reprint author), ETH, Seminar Stat, CH-8092 Zurich, Switzerland.	dahinden@stat.math.ethz.ch					Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; GUYON I, IN PRESS FEATURE EXT	3	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							1669	1672				4	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125903010		
S	Boulle, M			IEEE	Boulle, Marc			Regularization and averaging of the selective Naive Bayes classifier	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE			CATEGORICAL ATTRIBUTES; VALUES	The Naive Bayes classifier has proved to be very effective on many real data applications. Its performances usually benefit from an accurate estimation of univariate conditional probabilities and from variable selection. However, although variable selection is a desirable feature, it is prone to overfitting. In this paper, we introduce a new regularization technique to select the most probable subset of variables and propose a new model averaging method. The weighting scheme on the models reduces to a weighting scheme on the variables, and finally results in a Naive Bayes with "soft variable selection". Extensive experimental results show that the averaged regularized classifier outperforms the initial Selective Naive Bayes classifier.	France Telecom R&D, F-22307 Lannion, France	Boulle, M (reprint author), France Telecom R&D, 2 Ave Pierre Marzia, F-22307 Lannion, France.	marc.boulle@lfrancetelecom.com					Blake C. L., 1998, UCI REPOSITORY MACHI; BOULLE M, IN PRESS MACHINE LEA; Boulle M, 2005, LECT NOTES ARTIF INT, V3587, P228; Boulle M, 2005, J MACH LEARN RES, V6, P1431; BOULLE M, IN PRESS FEATURE EXT, V2; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dash D., 2002, P 19 INT C MACH LEAR, P91; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Fawcett Tom, 2003, HPL20034; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Guyon I., 2003, DESIGN EXPT NIPS 200; GUYON I, 2006, IEEE WORLD C COMP IN; Hoeting JA, 1999, STAT SCI, V14, P382; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Langley P., 1994, P 10 C UNC ART INT, P399; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; RAFTERY AE, 2003, 433 U WASH DEP STAT; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Witten I. H., 2000, DATA MINING; YANG Y, 2002, P PAC RIM KNOWL ACQ; Zheng Z., 1998, P 10 EUR C MACH LEAR, P196	23	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							1680	1688				9	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125903012		
S	Xue, F; Subbu, R; Bonissone, P			IEEE	Xue, Feng; Subbu, Raj; Bonissone, Piero			Locally weighted fusion of multiple predictive models	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE		bootstrapping; information fusion; neural network; ensemble; multiple models	NEURAL-NETWORKS; CLASSIFIERS; COMBINATION; CONFIDENCE; INTERVALS	Fusing the outputs from an ensemble of models in an effective way can often boost overall model accuracy. This paper presents a novel method, called locally weighted fusion, which aggregates the results of multiple predictive models based on local accuracy measures of these models in the neighborhood of the probe point for which we want to make a prediction. While we demonstrate the method in the context of multiple neural network models, the concepts may be applied to other predictive techniques as well. This fusion method is applied to develop highly accurate models for emissions, efficiency, and load prediction in a complex real-world power plant. The locally weighted fusion method boosts the predictive performance by 20-40% over the baseline single model approach for the various prediction targets. Relative to this approach, fusion strategies which apply averaging or globally weighting only produce a 26% performance boost over the baseline.	Gen Elect, Global Res Ctr, Niskayuna, NY 12309 USA	Xue, F (reprint author), Gen Elect, Global Res Ctr, 1 Res Circle, Niskayuna, NY 12309 USA.	xue@research.ge.com; subbu@research.ge.com; bonissone@research.ge.com					BONISSONE P, 2005, P 2005 MULT CLASS SY, P376; Bonissone P., 2004, P 2004 MULT SYST MCS, P154; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; De Veaux RD, 1998, TECHNOMETRICS, V40, P273, DOI 10.2307/1270528; Efron B, 1993, INTRO BOOTSTRAP; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; Heskes T, 1997, ADV NEUR IN, V9, P176; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Kuncheva LI, 2002, IEEE T SYST MAN CY B, V32, P146, DOI 10.1109/3477.990871; Lam L., 1994, P 12 INT C PATT REC, V2, P418, DOI 10.1109/ICPR.1994.576970; Lowe D, 1999, NEURAL COMPUT APPL, V8, P77, DOI 10.1007/s005210050009; McCullagh P., 1989, GEN LINEAR MODELS, Vsecond; Papadopoulos G, 2001, IEEE T NEURAL NETWOR, V12, P1278, DOI 10.1109/72.963764; Roli F., 2001, LNCS, V2096, P78; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; Sharp M, 1996, NATO ASI S 4 SCI TEC, V8, P3; Tibshirani R, 1996, NEURAL COMPUT, V8, P152, DOI 10.1162/neco.1996.8.1.152; Turner K., 1996, CONNECT SCI, V8, P385; Verikas A, 1999, PATTERN RECOGN LETT, V20, P429, DOI 10.1016/S0167-8655(99)00012-4; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	23	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							2137	2143				7	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125903077		
S	Evangelista, PF; Embrechts, MJ; Szymanski, BK			IEEE	Evangelista, Paul F.; Embrechts, Mark J.; Szymanski, Boleslaw K.			Data fusion for outlier detection through pseudo-ROC curves and rank distributions	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE			SUPPORT; AREA	This paper proposes a novel method of fusing models for classification of unbalanced data. The unbalanced data contains a majority of healthy (negative) instances, and a minority of unhealthy (positive) instances. The applicability of this type of classification problem with security applications inspired the naming of such problems as security classification problems (SCP). The area under the ROC curve (AUC) is the metric utilized to measure classifier performance, and in order to better understand AUC and ROC behavior, pseudo-ROC curves created from simulated data are introduced. ROC curves depend entirely upon the rankings created by classifiers. The rank distributions discussed in this paper display classifier performance in a novel form, and the behavior of these rank distributions provides insight into classifier fusion for the SCP. Rank distributions, which illustrate the probability of a particular rank containing a positive or negative instance, will be introduced and used to explain why synergistic classifier fusion occurs.	US Mil Acad, Dept Syst Engn, West Point, NY 10996 USA	Evangelista, PF (reprint author), US Mil Acad, Dept Syst Engn, West Point, NY 10996 USA.	paul.evangelista@usma.edu; embrem@rpi.edu; szymansk@rpi.edu	Szymanski, Boleslaw/A-9121-2009	Szymanski, Boleslaw/0000-0002-0307-6743			Bertsekas DP, 2002, INTRO PROBABILITY; BONISSONE P, 2004, P MULTIPLE CLASSIFIE; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHIH CC, 2004, LIBSVM LIB SUPPORT V; EGAN JP, 2003, SIGNAL DETECTION THE; EVANGELISTA PF, 2004, COMPUTER INTRUSION D, P489; EVBANGELISTA PF, 2005, P EUR S ART NEUR NET; FAWCETT T, 2003, HPL20034 HEWL PACK; FAWCETT T, 2001, IEEE INT C DAT MIN; FAWCETT T, 2001, MACHINE LEARNING J, V42, P203; HANLEY JA, 1982, RADIOLOGY, V143, P29; Haykin S., 1999, NEURAL NETWORKS COMP; Ho Tin Kam, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; HOFMANN A, 2004, INT JOINT C NEUR NET; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; LUDMILA I, 2003, IEEE T FUZZY SYST, V11, P729; LUDMILA I, 2003, P 1 IB C PATT REC IM; LUDMILA I, 2004, COMBINING PATTERN CL; PARSONS L, 2004, SIGKDD EXPLORATIONS; PAUL F, 2005, P INT JOINT C NEUR N; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2	25	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							2166	2173				8	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125904003		
S	Tuv, E; Borisov, A; Torkkola, K			IEEE	Tuv, Eugene; Borisov, Alexander; Torkkola, Kari			Feature selection using ensemble based ranking against artificial contrasts	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE				In contrast to typical variable selection methods such as CFS, tree-based ensemble methods can produce numerical importances of input variables of mixed type considering all variable interactions, not just one or two variables at a time. However, they do not indicate a cut-off point: how to set a threshold to the importance. This paper presents an efficient approach to doing this using artificial contrast variables. The result is a truly autonomous variable selection method in both multilevel classification and regression settings that can handle huge number of variables of mixed type with potentially non randomly missing values, resistant to noise both in input and response space, considers all variable interactions, and does not require a pre-set number of important variables.	Intel Corp, Anal & Control Technol Dept, Santa Clara, CA 95051 USA	Tuv, E (reprint author), Intel Corp, Anal & Control Technol Dept, Santa Clara, CA 95051 USA.	eugene.tuv@intel.com; alexander.borisov@intel.com; Kari.Torkkola@motorola.com					BORISOV A, 2005, FEATURE EXTRACTION; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Friedman J. H., 1999, GREEDY FUNCTION APPR; Guyon I, 2002, MACH LEARN, V46; HALL M, 1998, THEIS WAIKATO U HAMI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; LANGLEY P, 1996, IEEE EXPERT, V11; Radivojac P, 2004, P 15 EUR C MACH LEAR, P334; TORKKOLA K, 2005, FEATURE EXTRACTION F; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; TUV E, 2005, FEATURE EXTRACTION	13	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							2181	2185				5	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125904005		
S	Eklund, NHW; Goebel, KF			IEEE	Eklund, Neil H. W.; Goebel, Kai F.			Using meta-features to boost the performance of classifier fusion schemes for time series data	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE			ENSEMBLES	Accurate detection of faults and prediction of equipment remaining useful life result in considerable economic benefit to industry due to avoidance of unscheduled downtime and costly secondary damage. This paper described an approach to improving the performance of fault detection schemes that operate on time series data by fusing the results of an ensemble of classifiers that operate on the raw data. A meta-feature is designed to provide an indication of the historical state of other classifiers in the system, and to aid in fusion by allowing the individual classification results to be discounted appropriately. This meta-feature is shown to provide a substantial performance increase for fusion schemes. Data from actual aircraft engine/airframe systems are used to assess the performance of the approach.	GE Global Res, Niskayuna, NY 12305 USA	Eklund, NHW (reprint author), GE Global Res, 1 Res Circle, Niskayuna, NY 12305 USA.	eklund@research.ge.com; gobelk@research.ge.com					ASHBY M, 2000, P IEEE AER C; Bartlett MS, 1963, SANKHYA A, V25, P245; Bishop C.M., 1995, NEURAL NETWORKS PATT; BREIMAN L, 2004, RANDOM FOREST TOOLBO; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cawley G. C., 2000, SUPPORT VECTOR MACHI; Dietterich TG, 1997, AI MAG, V18, P97; EKLUND N, 2005, P 2005 IEEE MIDS WOR; EPANECHN.VA, 1969, THEOR PROBAB APPL+, V14, P153, DOI 10.1137/1114019; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gerra-Salcedo C., 1999, P GEN EV COMP C, P236; GOEBEL K, 2006, IN PRESS IEEE AER C; GOEBEL K, 2006, IN PRESS P SPIE; GOEBEL K, 2005, IEEE AER C 05 12 MAR, P1; Goebel K, 2001, AI EDAM, V15, P335, DOI 10.1017/S0890060401154077; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Haykin S., 1999, NEURAL NETWORKS COMP; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X; LOSKIEWICZBUCZA.A, 1994, P 3 IEEE C FUZZ SYST, V2, P1412; Mao J., 1998, P IEEE INT JOINT C N, V3, P1828; Nadaraya EN, 1965, THEOR PROBAB APPL, V10, P186; NELSON M, 1999, P INF DEC CONTR, P395; Opitz D. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Petit-Renaud S, 2004, INT J APPROX REASON, V35, P1, DOI 10.1016/S0888-613X(03)00056-2; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rao N. S. V., 2000, Information Fusion, V1, DOI 10.1016/S1566-2535(00)00004-X; Shimshoni Y, 1998, IEEE T SIGNAL PROCES, V46, P1194, DOI 10.1109/78.668782; Smets P., 1994, ADV DEMPSTER SHAFER, P5; STREAMSON C, 1997, DIABETES REV, V5, P2; TUMER K, 1999, P INT JOINT C NEUR N; Vapnik VN, 1995, NATURE STAT LEARNING; Venkatraman ES, 2000, BIOMETRICS, V56, P1134, DOI 10.1111/j.0006-341X.2000.01134.x; Yan WZ, 2002, P SOC PHOTO-OPT INS, V4733, P88, DOI 10.1117/12.475498	39	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							3223	3230				8	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125905077		
S	Torkkola, K; Gardner, M; Schreiner, C; Zhang, KS; Leivian, B; Summers, J			IEEE	Torkkola, Kari; Gardner, Mike; Schreiner, Chris; Zhang, Keshu; Leivian, Bob; Summers, John			Sensor selection for driving state recognition	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE				Driver activity recognition in the car cockpit is a necessary component for intelligent driver assistance systems. Since this has to be based on the sensor data stream available from the vehicle, an important question is what sensors are necessary and for which driver activities. We present results of a large-scale sensor selection study with naturalistic driving data looking at driving maneuver classification using ensemble methods.	Motorola Inc, Intelligent Syst Lab, Tempe, AZ 85282 USA	Torkkola, K (reprint author), Motorola Inc, Intelligent Syst Lab, 2900 S Diablo Way,MD DW286, Tempe, AZ 85282 USA.	Kari.Torkkola@motorola.com					BOER ER, 2001, DRIVER ASSESSMENT, P225; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Guyon I, 2006, FEATURE EXTRACTION F; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Liu A., 1997, P IEEE C INT TRANSP, P236, DOI 10.1109/ITSC.1997.660481; Liu H., 1998, FEATURE SELECTION KN; MITROVIC D, 1998, ROAD SAF C 1998; Neale V. L., 2002, 809536 DOT HS; Ng A. Y., 2001, ADV NEURAL INFORM PR, V14; Oliver N, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P7, DOI 10.1109/IVS.2000.898310; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SALVUCCI D, 2001, TRANSPORTATION RES R; TANAKA J, 2000, P IEEE INT TRANSP SY, P382; Torkkola K., 2004, Proceedings. The 7th International IEEE Conference on Intelligent Transportation Systems (IEEE Cat. No.04TH8749), DOI 10.1109/ITSC.2004.1398919; TORKKOLA K, 2003, P INT C MACH LEARN A, P81	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							4734	4739				6	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125908064		
S	Richards, G; Wang, WJ			IEEE	Richards, Graeme; Wang, Wenjia			Investigations on the characteristics of random decision tree ensembles	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE			MULTIPLE CLASSIFIER SYSTEMS	An ensemble is viewed as a machine learning system that combines multiple models to work collectively in the hope of producing a better performance than that of individuals. However, an ensemble's accuracy cannot be easily determined as it involves several factors, e.g. individual model's accuracy, diversity between its member models, decision-making strategy and number of members and the relationships between them are unclear. This paper, taking random decision tree ensembles as testing platforms, investigates these relationships and the strategies for creating ensembles from randomly generated trees. Specifically, we devised three sets of procedures for conducting experiments using twelve data sets from the UCI repository to determine the importance of individual model accuracy and the diversity between decision tree models within an ensemble. The main findings of the investigations are presented and discussed in the paper.	Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England	Richards, G (reprint author), Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich T G, 2000, MULTIPLE CLASSIER SY; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, INT C MACH LEARN, P148; Giacinto G, 2001, PATTERN RECOGN LETT, V22, P25, DOI 10.1016/S0167-8655(00)00096-9; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho T.K., 2002, HYBRID METHODS PATTE, P171; Partridge D., 1997, 348 EX U DEP COMP SC; Quinlan J. R., 1992, C4 5 PROGRAM MACHINE; Ruta D., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.008; WANG W, 2004, IEEE ICDM04 WORKSH D; Wang WJ, 2000, LECT NOTES COMPUT SC, V1857, P240	15	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							5140	5147				8	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125909044		
S	Pardo, M; Sberveglieri, G			IEEE	Pardo, Matteo; Sberveglieri, Giorgio			Random Forests, Nearest Shrunken Centroids and support vector machines for the classification of diverse E-nose datasets	2006 IEEE SENSORS, VOLS 1-3	IEEE Sensors		English	Proceedings Paper	5th IEEE Sensors Conference	OCT 22-25, 2006	Daegu, SOUTH KOREA	IEEE				Sensors practitioners don't make full use of the power of state-of-the-art pattern recognition (PR) algorithms and software. In this paper we apply -to our knowledge for the first time- Random Forests (RF) and Nearest Shrunken Centroids (NSC) to the classification of three E-Nose datasets of different hardness. We compare the classification rate with the one obtained by SVM. The classifiers parameters are optimized in an inner cross-validation (CV) cycle and the error is calculated by outer CV in order to avoid any bias. RF and SVM have a similar classification performance (SVM has an edge on the most difficult dataset). On the other hand, RF and NSC have an in-built feature selection mechanism that is very helpful for understanding the structure of the dataset and evaluating sensors.	Univ Brescia, CNR, INFM, Sensor Lab, Brescia, Italy	Pardo, M (reprint author), Univ Brescia, CNR, INFM, Sensor Lab, Brescia, Italy.	pardo@ing.unibs.it	pardo, matteo/D-7090-2011				Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Ruschhaupt M., 2004, STAT APPL GENET MOL, V3; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488	3	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1930-0395		978-1-4244-0375-2	IEEE SENSOR			2006							424	426				3	Acoustics; Engineering, Electrical & Electronic; Optics	Acoustics; Engineering; Optics	BGN28	WOS:000248587500108		
B	Yan, WZ		Sun, F; Liu, HP		Yan, Weizhong			Application of random forest to aircraft engine fault diagnosis	2006 IMACS: Multiconference on Computational Engineering in Systems Applications, Vols 1 and 2			English	Proceedings Paper	IMACS Multiconference on Computational Engineering in Systems Applications (CESA 2006)	OCT 04-06, 2006	Beijing, PEOPLES R CHINA	IMACS, IEEE SMC Soc, Tsinghua Univ, Ecole Centrale Lille, Ecole Natl Superieure Arts & Ind Textiles, Natl Nat Sci Fdn China		aircraft engine; classification; diagnosis; performance evaluation; random forests	CLASSIFICATION	Aircraft engine fault diagnosis plays a critical role in modern, cost-effective condition-based maintenance strategy in aircraft industry. Due to several inherent characteristics associated with aircraft engines, accurately diagnosing aircraft engine faults is a challenging classification problem. As a result, aircraft engine fault diagnosis. has been an active research topic attracting tremendous research interests in machine learning community. In this paper, random forest classifier, a recently emerged machine learning technique, is applied to aircraft engine fault diagnosis in an attempt to achieve more accurate and reliable classification performance. Our primary objective is to evaluate effectiveness of random forest classifier on aircraft engine fault diagnosis. By designing a real-world aircraft engine fault diagnostic system, this paper investigates design details of random forest classifier and evaluates its performance. In this paper, we also make some efforts on investigating strategies for improving random forest performance specifically for aircraft engine fault diagnosis problem.	GE Global Res Ctr, Niskayuna, NY 12309 USA	Yan, WZ (reprint author), GE Global Res Ctr, Niskayuna, NY 12309 USA.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Friedman J., 1996, ANOTHER APPROACH POL; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; Gibbons J., 1985, NONPARAMETRIC STAT I; GOEBEL K, 2000, P IEEE 2000 AER C AD, V6, P155; Hastie T, 1998, ANN STAT, V26, P451; Lee T.-W., 1998, INDEPENDENT COMPONEN; LI YG, 2002, J POWER ENERGY A, V216; MERRINGTON G, ASME J ENG GAS TURBI, V113; Ogaji SOT, 2003, P I MECH ENG A-J POW, V217, P149, DOI 10.1243/09576500360611173; ROBNIKSIKONJA M, 2004, MACHINE LEARNING; ROEMER M, 2002, P AUTOTESTCON IEEE S, P365; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; VOLPONI A, 2003, JANNAF C; YAN WZ, 2003, THESIS DEP MECH ENG	16	0	0	TSINGHUA UNIVERSITY PRESS	BEIJING	TSINGHUA UNIVERSITY HAIDIANQU, BEIJING 100084, PEOPLES R CHINA			978-7-302-13922-5				2006							468	475				8	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Telecommunications	Automation & Control Systems; Computer Science; Telecommunications	BFR75	WOS:000244084600088		
S	Barnich, O; Jodogne, S; Van Droogenbroeck, M		BlancTalon, J; Philips, W; Popescu, D; Scheunders, P		Barnich, Olivier; Jodogne, Sebastien; Van Droogenbroeck, Marc			Robust analysis of silhouettes by morphological size distributions	ADVANCED CONCEPTS FOR INTELLIGENT VISION SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Advanced Concepts for Intelligent Vision Systems	SEP 18-21, 2006	Antwerp, BELGIUM	Univ Antwerp, Ghent Univ, Faculty Engn Sci, Philips Res, IEEE Benelux Signal Proc Chapter, Eurasip, Barco, DSP Valley, FWO Res Comm Audiovisual Syst			REAL-TIME TRACKING	We address the topic of real-time analysis and recognition of silhouettes. The method that we propose first produces object features obtained by a new type of morphological operators, which can be seen as an extension of existing granulometric filters, and then insert them into a tailored classification scheme. Intuitively, given a binary segmented image, our operator produces the set of all the largest rectangles that can be wedged inside any connected component of the image. The latter are obtained by a standard background subtraction technique and morphological filtering. To classify connected components into one of the known object categories, the rectangles of a connected component are submitted to a machine learning algorithm called EXtremely RAndomized trees (Extra-trees). The machine learning algorithm is fed with a static database of silhouettes that contains both positive and negative instances. The whole process, including image processing and rectangle classification, is carried out in real-time. Finally we evaluate our approach on one of today's hot topics: the detection of human silhouettes. We discuss experimental results and show that our method is stable and computationally effective. Therefore, we assess that algorithms like ours introduce new ways for the detection of humans in video sequences.	Univ Liege, Dept Elect Elect & Comp Sci, Inst Montefiore, B-4000 Liege, Belgium	Barnich, O (reprint author), Univ Liege, Dept Elect Elect & Comp Sci, Inst Montefiore, B-28, B-4000 Liege, Belgium.						BAGDANOV A, 2002, P INT C PATT REC, V1, P478; Boulgouris NV, 2005, IEEE SIGNAL PROC MAG, V22, P78, DOI 10.1109/MSP.2005.1550191; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; GEURTS P, 2006, IN PRESS MACHINE LEA; Hadwiger H, 1957, VORLESUNGEN UBER INH; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MAREE R, 2005, IEEE C COMP VIS PATT, V1, P34; MATHES T, 2005, P BRIT MACH VIS C OX, P849; Mikolajczyk K, 2003, P IEEE C COMP VIS PA, V2, P257; Nene S. A., 1996, COLUMBIA OBJECT IMAG; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Power P. W., 2002, P IM VIS COMP AUCKL; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Serra J., 1982, IMAGE ANAL MATH MORP; STAUFFER C, 1999, P IEEE C COMP VIS PA, P264; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Van Droogenbroeck M, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P197; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236	21	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-44630-3	LECT NOTES COMPUT SC			2006	4179						734	745				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE67	WOS:000241489100067		
S	Prinzie, A; Van den Poel, D		Perner, P		Prinzie, Anita; Van den Poel, Dirk			Exploiting randomness for feature selection in multinomial logit: A CRM cross-sell application	ADVANCES IN DATA MINING: APPLICATIONS IN MEDICINE, WEB MINING, MARKETING, IMAGE AND SIGNAL MINING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th Industrial Conference on Data Mining (ICDM 2006)	JUL 14-15, 2006	Leipzig, GERMANY				SUPPORT VECTOR MACHINES; CLASSIFICATION; STRATEGIES	Data mining applications addressing classification problems must master two key tasks: feature selection and model selection. This paper proposes a random feature selection procedure integrated within the multinomial logit (MNL) classifier to perform both tasks simultaneously. We assess the potential of the random feature selection procedure (exploiting randomness) as compared to an expert feature selection method (exploiting domain-knowledge) on a CRM cross-sell application. The results show great promise as the predictive accuracy of the integrated random feature selection in the MNL algorithm is substantially higher than that of the expert feature selection method.	Univ Ghent, Dept Mkt, B-9000 Ghent, Belgium	Prinzie, A (reprint author), Univ Ghent, Dept Mkt, Hoveniersberg 24, B-9000 Ghent, Belgium.	Anita.Prinzie@UGent.be; Dirk.VandenPoel@UGent.be	Prinzie, Anita/A-4537-2008				Agrawal D, 1996, J RETAILING, V72, P383, DOI 10.1016/S0022-4359(96)90020-2; Baltas G, 2001, J BUS RES, V51, P115, DOI 10.1016/S0148-2963(99)00058-2; Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Barsalou L., 1991, PSYCHOL LEARN MOTIV, P1; Ben-Akiva M. E., 1985, DISCRETE CHOICE ANAL; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buchtala O, 2005, IEEE T SYST MAN CY B, V35, P928, DOI 10.1109/TSMCB.2005.847743; CORFMAN KP, 1991, J MARKETING RES, V28, P368, DOI 10.2307/3172873; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Dietterich TG, 1997, AI MAG, V18, P97; Fawcett Tom, 2003, HPL20034; GREEN DM, 1966, SIGNAL DETECTION THE; HUANG Y, 2004, LECT NOTES ARTIF INT, V3275, P162; JOHNSON MD, 1984, J CONSUM RES, V11, P741, DOI 10.1086/209010; Knott A, 2002, J INTERACT MARK, V16, P59, DOI 10.1002/dir.10038; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; MORRISON DG, 1969, J MARKETING RES, V6, P156, DOI 10.2307/3149666; PRINZIE A, 2006, IN PRESS DECISION SU; Sindhwani V, 2004, IEEE T NEURAL NETWOR, V15, P937, DOI 10.1109/TNN.2004.828772; XING B, 2001, P 15 INT C MACH LEAR, P601	23	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-36036-0	LECT NOTES ARTIF INT			2006	4065						310	323				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEV61	WOS:000239623700025		
S	Liu, FT; Ting, KM		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Liu, FT; Ting, KM			Variable randomness in decision tree ensembles	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				In this paper, we propose Max-diverse.alpha, which has a mechanism to control the degrees of randomness in decision tree ensembles. This control gives an ensemble the means to balance the two conflicting functions of a random random ensemble, i.e., the abilities to model non-axis-parallel boundary and eliminate irrelevant features. We find that this control is more sensitive to the one provided by Random Forests. Using progressive training errors, we are able to estimate an appropriate randomness for any given data prior to any predictive tasks. Experiment results show that Max-diverse.alpha is significantly better than Random Forests and Max-diverse Ensemble, and it is comparable to the state-of-the-art C5 boosting.	Monash Univ, Gippsland Sch Informat Technol, Churchill 3842, Australia	Liu, FT (reprint author), Monash Univ, Gippsland Sch Informat Technol, Churchill 3842, Australia.	Tony.Liu@infotech.monash.edu.au; KaiMing.Ting@infotech.monash.edu.au					Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buttrey S, 2003, P 2003 JOINT STAT M; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Fan W, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P51; Hastie T., 2001, ELEMENTS STAT LEARNI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Holte R. C., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence; JI C, 1997, IEEE T NEURAL NETWOR, V8, P494; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; LIU FT, 2005, 9 PAC AS C PAKDD, P605; Quinlan J., 1993, C4 5 PROGRAMS MACHIN	14	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						81	90				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600012		
S	Fan, HJ; Fan, M; Ramamohanarao, K; Liu, MX		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Fan, HJ; Fan, M; Ramamohanarao, K; Liu, MX			Further improving emerging pattern based classifiers via bagging	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore		emerging patterns; classification; bagging; ensemble learning		Emerging Patterns (EPs) are those itemsets whose supports in one class are significantly higher than their supports in the other class. In this paper we investigate how to "bag" EP-based classifiers to build effective ensembles. We design a new scoring function based on growth rates to increase the diversity of individual classifiers and an effective scheme to combine the power of ensemble members. The experimental results confirm that our method of "bagging" EP-based classifiers can produce a more accurate and noise tolerant classifier ensemble.	Univ Melbourne, Dept CSSE, Parkville, Vic 3052, Australia; Zhengzhou Univ, Dept Comp Sci, Zhengzhou 450052, Peoples R China	Fan, HJ (reprint author), Univ Melbourne, Dept CSSE, Parkville, Vic 3052, Australia.	hfan@csse.unimelb.edu.au; mfan@zzu.edu.cn; rao@csse.unimelb.edu.au; mxliu@zzu.edu.cn					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dong G., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Dong G., 1999, P 2 INT C DISC SCI, P30; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Ian H. W., 1999, DATA MINING PRACTICA; Jinyan Li, 2001, KNOWL INF SYST, V3, P131, DOI DOI 10.1007/PL00011662; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849	10	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						91	96				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600013		
S	Frank, E; Pfahringer, B		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Frank, E; Pfahringer, B			Improving on bagging with input smearing	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				Bagging is an ensemble learning method that has proved to be a useful tool in the arsenal of machine learning practitioners. Commonly applied in conjunction with decision tree learners to build an ensemble of decision trees, it often leads to reduced errors in the predictions when compared to using a single tree. A single tree is built from a training set of size N. Bagging is based on the idea that, ideally, we would like to eliminate the variance due to a particular training set by combining trees built from all training sets of size N. However, in practice, only one training set is available, and bagging simulates this platonic method by sampling with replacement from the original training data to form new training sets. In this paper we pursue the idea of sampling from a kernel density estimator of the underlying distribution to form new training sets, in addition to sampling from the data itself. This can be viewed as "smearing out" the resampled training data to generate new datasets, and the amount of "smear" is controlled by a parameter. We show that the resulting method, called "input smearing", can lead to improved results when compared to bagging. We present results for both classification and regression problems.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Frank, E (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.	eibe@cs.waikato.ac.nz; bernhard@cs.waikato.ac.nz	Frank, Eibe/A-1434-2008	Frank, Eibe/0000-0001-6152-7111			Achlioptas D, 2001, 20 ANN S PRINC DAT S, P274; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domingos P., 1997, P 14 INT C MACH LEAR, P98; Freund Y., 1996, 13 INT C MACH LEARN, P148; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; MELVILLE P, 2004, CREATING DIVERSITY E, V6, P99; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Newman D.J., 1998, UCI REPOSITORY MACHI; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Rennie J.D.M., 2003, P 20 INT C MACH LEAR, P616; Ting K., 1997, 14 INT C MACH LEARN, P367; TORGO L, 2005, REGRESSION DATASETS; WANG Y, 1997, P POST PAP EUR C MAC	19	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						97	106				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600014		
S	Kim, DS; Lee, SM; Park, JS		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, H		Kim, Dong Seong; Lee, Sang Min; Park, Jong Sou			Building lightweight intrusion detection system based on random forest	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISNN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong			ANOMALY DETECTION	This paper proposes a new approach to build lightweight Intrusion Detection System (IDS) based on Random Forest (RF). RF is a special kind of ensemble learning techniques and it turns out to perform very well compared to other classification algorithms such as Support Vector Machines (SVM) and Artificial Neural Networks (ANN). In addition, RF produces a measure of importance of feature variables. Our approach is able not only to show high detection rates but also to figure out stable output of important features simultaneously. The results of experiments on KDD 1999 intrusion detection dataset indicate the feasibility of our approach.	Hankuk Aviat Univ, Network Secur Lab, Dept Comp Engn, Goyang City 412791, Gyeonggi Do, South Korea	Kim, DS (reprint author), Hankuk Aviat Univ, Network Secur Lab, Dept Comp Engn, 200-1 Hwajeon Dong, Goyang City 412791, Gyeonggi Do, South Korea.	dskim@hau.ac.kr; minuri33@hau.ac.kr; jspark@hau.ac.kr					Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Fox K.L., 1990, P 13 NAT COMP SEC C; Fugate M, 2002, LECT NOTES COMPUT SC, V2388, P186; Hu W., 2003, P INT C MACH LEARN A, P168; Kim DS, 2005, LECT NOTES COMPUT SC, V3498, P415; Kruegel C, 2002, P IEEE S SECUR PRIV, P285, DOI 10.1109/SECPRI.2002.1004378; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; MUKKAMALA S, 2005, P INT C AD NAT COMP, P458; NGUYEN BV, 2002, APPL SUPPORT VECTOR; OURSTON D, 2002, P 36 HAW INT C SYST, P334; Park JS, 2005, LECT NOTES COMPUT SC, V3822, P279; SABHNANI M, 2004, INTELLIGENT ANAL; Song H., 2005, P 2005 ACM SIGDA 13, P238, DOI 10.1145/1046192.1046223; Sung A. H., 2003, Proceedings 2003 Symposium on Applications and the Internet, DOI 10.1109/SAINT.2003.1183050	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-34482-9	LECT NOTES COMPUT SC			2006	3973						224	230				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BET87	WOS:000239485300033		
S	Altun, O; Albayrak, S; Ekinci, A; Bukun, B		Sattar, A; Kang, BH		Altun, Oguz; Albayrak, Songul; Ekinci, Ali; Bukun, Behzat			Turkish fingerspelling recognition system using axis of least inertia based fast alignment	AI 2006: Advances in Artificial Intelligence, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	19th Australian Joint Conference on Artificial Intelligence	DEC 04-08, 2006	Hobart, AUSTRALIA			Turkish fingerspelling recognition; fast alignment; angle of orientation; axis of least inertia; minimum bounding square; classification	SIGN-LANGUAGE RECOGNITION; VIDEO	Fingerspelling is used in sign language to spell out names of people and places for which there is no sign or for which the sign is not known. In this work we describe a Turkish fingerspelling recognition system that recognizes all 29 letters of the Turkish alphabet. A single representative frame is extracted from the sign video, since that frame is enough for recognition purposes of the letters mentioned. Processing a single frame, instead of the whole video, increases speed considerably. The skin regions in the representative frame are extracted by color segmentation in YCrCb space before clearing noise regions by morphological opening. A novel fast alignment method that uses the angle of orientation between the axis of least inertia and y axis is applied to hand regions. This method compensates small orientation differences but increases big ones. This is desirable when differentiating the fingerspelling signs, some of which are close in shape but different in orientation. Also the use of minimum bounding square is advised, which helps in resizing without breaking the alignment. Binary values of this minimum bounding square are directly used as feature values, and that allowed experimenting with different classification schemes. Features like mean radial distance and circularity are also used for increasing success rate. Classifiers like kNN, SVM, Naive Bayes, and RBF Network are experimented with, and INN and SVM are found to be the best two of them. The video database was created by 3 different signers, a set of 290 training videos, and a separate set of 174 testing videos are used in experiments. The best classifiers INN and SVM achieved a success rate of 99.43% and 98.83% respectively.	Yildiz Tech Univ, Dept Commun Engn, Istanbul, Turkey	Altun, O (reprint author), Yildiz Tech Univ, Dept Commun Engn, Istanbul, Turkey.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALTUN O, 2006, PSIVT 2006; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHAI D, 2000, TENCON 2000; FERIS R, 2004, 2004 IEEE COMP SOC C; FRITZKE B, 1994, NEURAL PROCESS LETT, V1, P2, DOI 10.1007/BF02312392; Gao W, 2004, PATTERN RECOGN, V37, P2389, DOI 10.1016/j.patcog.2004.04.008; Haberdar H, 2005, LECT NOTES COMPUT SC, V3733, P677; HABERDAR H, 2006, INT S METH INT SYST; Holden EJ, 2005, MACH VISION APPL, V16, P312, DOI 10.1007/s00138-005-0003-1; ISAACS J, 2004, 36 SE S IEEE SYST TH, P132, DOI 10.1109/SSST.2004.1295634; John G. H., 1995, 11 C UNC ART INT, P338; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Lamari M. V., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), DOI 10.1109/IJCNN.1999.833533; McCallum A., 1998, AAAI 98 WORKSH LEARN; Quinlan Ross, 1993, C4 5 PROGRAM MACHINE; REBOLLAR J, 2000, INT C MULT INT PITTS; SAZONOV V, 2003, GRAPHICON 2003, P85; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Umbaugh SE, 1998, COMPUTER VISION IMAG	20	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-49787-5	LECT NOTES COMPUT SC			2006	4304						473	481				9	Computer Science, Artificial Intelligence	Computer Science	BFV69	WOS:000244891200051		
S	Luksza, M; Kluge, B; Ostrowski, J; Karczmarski, J; Gambin, A		Bucher, P; Moret, BME		Luksza, Marta; Kluge, Boguslaw; Ostrowski, Jerzy; Karczmarski, Jakub; Gambin, Anna			Efficient model-based clustering for LC-MS data	ALGORITHMS IN BIOINFORMATICS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Workshop on Algorithms in Bioinformatics (WABI 2006)	SEP 11-13, 2006	Zurich, SWITZERLAND	Int Soc computat Biol, European Assoc Theoret Comp Sci, Eidgenoss Tech Hochschule Zurich			MASS-SPECTROMETRY DATA; CLASSIFICATION; PROTEOMICS; ALIGNMENT	Proteomic mass spectrometry is gaining an increasing role in diagnostics and in studies on protein complexes and biological systems. The issue of high-throughput data processing is therefore becoming more and more significant. The problems of data imperfectness, presence of noise and of various errors introduced during experiments arise. In this paper we focus on the peak alignment problem. As an alternative to heuristic based approaches to aligning peaks from different mass spectra we propose a mathematically sound method which exploits the model-based approach. In this framework experiment errors are modeled as deviations from real values and mass spectra are regarded as finite Gaussian mixtures. The advantage of such an approach is that-it provides convenient techniques for adjusting parameters and selecting solutions of best quality. The method can be parameterized by assuming various constraints. In this paper we investigate different classes of models and select the most suitable one. We analyze the results in terms of statistically Significant biomarkers that can be identified after alignment of spectra.	Warsaw Univ, Inst Informat, PL-02097 Warsaw, Poland; Med Ctr Postgrad Educ, Dept Gastroenterol, PL-02781 Warsaw, Poland; Marie Curie Sklodowska Univ, Mem Canc Ctr & Inst Oncol, PL-02781 Warsaw, Poland	Luksza, M (reprint author), Warsaw Univ, Inst Informat, Banacha 2, PL-02097 Warsaw, Poland.		Gambin, Anna/I-3580-2012				Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DELAGLIO F, 1995, J BIOMOL NMR, V6, P277, DOI 10.1007/BF00197809; Dempster A., 1977, J ROYAL STAT SOC B, P1; Ester M., 1996, 2 INT C KNOWL DISC D, P226; FRALEY C, 2002, 415R U WASH DEP STAT; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; GAMBIN A, 2006, IN PRESS INT J MASS; HAUGHTON DMA, 1988, ANN STAT, V16, P342, DOI 10.1214/aos/1176350709; Petersen KB, 2005, NEURAL COMPUT, V17, P1921, DOI 10.1162/0899766054322991; Prakash A, 2006, MOL CELL PROTEOMICS, V5, P423, DOI 10.1074/mcp.M500133-MCP200; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Smith CA, 2006, ANAL CHEM, V78, P779, DOI 10.1021/ac051437y; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Wang WX, 2003, ANAL CHEM, V75, P4818, DOI 10.1021/ac026468x; Wong JWH, 2005, BIOINFORMATICS, V21, P2088, DOI 10.1093/bioinformatics/bti300; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-39583-0	LECT NOTES COMPUT SC			2006	4175						32	43				12	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BFI95	WOS:000242125600004		
J	Latino, DARS; Aires-de-Sousa, J				Latino, DARS; Aires-de-Sousa, J			Genome-scale classification of metabolic reactions: A chemoinformatics approach	ANGEWANDTE CHEMIE-INTERNATIONAL EDITION			English	Article						bioinformatics; chemoinformatics; computer chemistry; enzymes; metabolism	CHEMICAL-REACTIONS; ORGANIC-REACTIONS; HIERARCHICAL-CLASSIFICATION; ENZYME FUNCTION; NEURAL-NETWORK; SYSTEM; ELECTRONEGATIVITY; QUANTIFICATION; NOMENCLATURE; KNOWLEDGE		Univ Nova Lisboa, Fac Ciencias & Tecnol, CQFB, Dept Quim, P-2929516 Caparica, Portugal; Univ Nova Lisboa, Fac Ciencias & Tecnol, REQUIMTE, Dept Quim, P-2929516 Caparica, Portugal	Aires-de-Sousa, J (reprint author), Univ Nova Lisboa, Fac Ciencias & Tecnol, CQFB, Dept Quim, P-2929516 Caparica, Portugal.	jas@fct.unl.pt	Aires-de-Sousa, Joao/C-7826-2013; REQUIMTE, AL/H-9106-2013; REQUIMTE, ORG/M-4578-2013; REQUIMTE, LAQV/N-9835-2013; Latino, Diogo/D-7476-2013	Aires-de-Sousa, Joao/0000-0002-5887-2966; Latino, Diogo/0000-0002-7622-3249			Barrett A. J., 1992, ENZYME NOMENCLATURE; BREIMAN L, 2004, R PORT; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen L., 2003, HDB CHEMOINFORMATICS, P348; CHEN L, 1996, ANGEW CHEM, V108, P844, DOI 10.1002/ange.19961080727; Chen LR, 1997, J AM CHEM SOC, V119, P4033, DOI 10.1021/ja960027b; FUJITA S, 1986, J CHEM INF COMP SCI, V26, P205, DOI 10.1021/ci00052a009; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; GASTEIGER J, 2004, P BEILST I S CHEM TH; GASTEIGER J, 1985, ANGEW CHEM INT EDIT, V24, P687, DOI 10.1002/anie.198506871; GASTEIGER J, 1979, TETRAHEDRON, V35, P1419, DOI 10.1016/0040-4020(79)85037-1; GASTEIGER J, 1990, J CHEM INF COMP SCI, V30, P467, DOI 10.1021/ci00068a019; Gasteiger Johann, 2003, Mini-Reviews in Medicinal Chemistry, V3, P789, DOI 10.2174/1389557033487656; Goto S, 1998, BIOINFORMATICS, V14, P591, DOI 10.1093/bioinformatics/14.7.591; Hatzimanikatis V, 2004, CURR OPIN STRUC BIOL, V14, P300, DOI 10.1016/j.sbi.2004.04.004; Hendrickson JB, 1997, J CHEM INF COMP SCI, V37, P852, DOI 10.1021/ci970040v; HUTCHINGS HG, 1984, J CHEM SOC P2, P559; HUTCHINGS MG, 1983, TETRAHEDRON LETT, V24, P2541, DOI 10.1016/S0040-4039(00)81976-0; Kanehisa M., 2004, NUCLEIC ACIDS RES, V32, P277; Kanehisa M, 1997, TRENDS GENET, V13, P375, DOI 10.1016/S0168-9525(97)01223-7; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Kohonen T, 1988, SELF ORG ASS MEMORY; KOTERA M, 2000, J AM CHEM SOC, V126, P16487; MOOCK TE, 1988, TETRAHEDRON COMPUT M, V1, P117, DOI 10.1016/0898-5529(88)90016-4; R Development Core Team, 2004, R LANG ENV STAT COMP; ROSE JR, 1994, J CHEM INF COMP SCI, V34, P74, DOI 10.1021/ci00017a010; SALLER H, 1985, ANGEW CHEM, V97, P699; Satoh H, 1998, J CHEM INF COMP SCI, V38, P210, DOI 10.1021/ci9701190; SIMON V, 1993, J AM CHEM SOC, V115, P9148, DOI 10.1021/ja00073a034; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tian WD, 2003, J MOL BIOL, V333, P863, DOI 10.1016/j.jmb.2003.08.057; Tipton K, 2000, BIOINFORMATICS, V16, P34, DOI 10.1093/bioinformatics/16.1.34; Tratch SS, 1998, J CHEM INF COMP SCI, V38, P349, DOI 10.1021/ci960098u; Zhang QY, 2005, J CHEM INF MODEL, V45, P1775, DOI 10.1021/ci0502707; Zupan J., 1999, NEURAL NETWORKS CHEM	35	27	28	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1433-7851			ANGEW CHEM INT EDIT	Angew. Chem.-Int. Edit.		2006	45	13					2066	2069		10.1002/anie.200503833		4	Chemistry, Multidisciplinary	Chemistry	026XQ	WOS:000236377000015	16498690	
S	Barrett, SJ; Langdon, WB		Tiwari, A; Knowles, J; Avineri, E; Dahal, K; Roy, R		Barrett, S. J.; Langdon, W. B.			Advances in the application of machine learning techniques in drug discovery, design and development	Applications of Soft Computing: Recent Trends	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	10th Online World Conference on Soft Computing in Industrial Applications (WSC10)	SEP 19-OCT 07, 2005	ELECTR NETWORK	World Federat Soft Comp, Springer, BT, Elsevier, European Neural Network Soc, N Amer Fuzzy Log & Technol, Int Fuzzy Syst Assoc			SUPPORT VECTOR MACHINES; SINGLE NUCLEOTIDE POLYMORPHISMS; PARTICLE SWARM OPTIMIZATION; GENE-EXPRESSION DATA; MICROARRAY DATA; CANCER CLASSIFICATION; FEATURE-SELECTION; NEURAL-NETWORK; PHARMACEUTICAL-INDUSTRY; BREAST-CANCER	Machine learning tools, in particular support vector machines (SVM), Particle Swarm Optimisation (PSO) and Genetic Programming (GP), are increasingly used in pharmaceuticals research and development. They are inherently suitable for use with 'noisy', high dimensional (many variables) data, as is commonly used in cheminformatic (i.e. In silico screening), bioinformatic (i.e. bio-marker studies, using DNA chip data) and other types of drug research studies. These aspects are demonstrated via review of their current usage and future prospects in context with drug discovery activities.	GlaxoSmithKline Inc, Anal Applicat Res & Technol, R&D, Greenford UB6 0HE, Middx, England	Barrett, SJ (reprint author), GlaxoSmithKline Inc, Anal Applicat Res & Technol, R&D, Greenford Rd, Greenford UB6 0HE, Middx, England.						Agrafiotis DK, 2002, J MED CHEM, V45, P1098, DOI 10.1021/jm0104668; AMBOISE, 2002, PNAS, V99, P6562; ANDO, 2004, GP EM, V5, P145; Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; Bains W, 2004, PROG BIOPHYS MOL BIO, V86, P205, DOI 10.1016/j.pbiomolbio.2003.09.001; BANZHAF, 1998, GENETIC PROGRAMMING; Bao L, 2002, FEBS LETT, V521, P109, DOI 10.1016/S0014-5793(02)02835-1; BARRETT SJ, 2005, COLL INN CTR ADV INS; BHASIN, 2004, NUCL ACIDS RES, V32, pW383; Bhasin M, 2004, J BIOL CHEM, V279, P23262, DOI 10.1074/jbc.M401932200; BIESHEUVEL, 2005, THESIS U UTRECHT; Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; BOSER, 1992, 5 ANN ACM WORKSH COL; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRENEMAN, 2002, ADME TOX S ORL ACS M; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BURBIDGE, 2001, 6 INT WORK C ART N 1, V2084; BURBIDGE, 2001, COMPUTERS IND, V26, P4; Butte A, 2002, NAT REV DRUG DISCOV, V1, P951, DOI 10.1038/nrd.961; Byvatov E, 2005, CHEMBIOCHEM, V6, P997, DOI 10.1002/cbic.200400400; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; Cedeno W, 2003, J COMPUT AID MOL DES, V17, P255, DOI 10.1023/A:1025338411016; CHEN, 2004, WORLD SCI; Chen HF, 2004, QSAR COMB SCI, V23, P603, DOI 10.1002/qsar.200430884; CONGDOM, 2003, CEC, P320; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; Dobson PD, 2005, J MOL BIOL, V345, P187, DOI 10.1016/j.jmb.2004.10.024; Doniger S, 2002, J COMPUT BIOL, V9, P849, DOI 10.1089/10665270260518317; Dubey A, 2005, J THEOR BIOL, V234, P351, DOI 10.1016/j.jtbi.2004.11.037; EBERHART, 1999, CEC, P1927; EBERHART, 2001, SWARM INTELLIGENCE; FRADKIN, 2005, SVM ANAL CROSS SECTI; FUJAREWICZ, 2003, INT J APPL MATH COMP, V13, P327; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; Guo T, 2005, PROTEIN ENG DES SEL, V18, P65, DOI 10.1093/protein/gzi006; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hand D. J., 1999, SIGKDD EXPLORATIONS, V1, P16; HARDLE, 2004, SURVIVAL ANAL SUPPOR; Heddad A, 2004, LECT NOTES COMPUT SC, V3005, P31; Hong JH, 2004, LECT NOTES COMPUT SC, V3003, P78; Hou TJ, 2004, CURR PHARM DESIGN, V10, P1011, DOI 10.2174/1381612043452721; HOWARD, 2003, BIOSYSTEMS, V72, P19; HOWLEY, 2005, IN PRESS ARTIFICIAL; Huang YL, 2005, CLIN IMAG, V29, P179, DOI 10.1016/j.clinimag.2004.08.002; Igel C, 2005, LECT NOTES COMPUT SC, V3410, P534; Jerebko AK, 2005, ACAD RADIOL, V12, P479, DOI 10.1016/j.acra.2004.04.024; Johnson HE, 2003, PHYTOCHEMISTRY, V62, P919, DOI 10.1016/S0031-9422(02)00722-7; JONES, 1999, ENCY COMPUTATIONAL C; Jong K, 2004, LECT NOTES COMPUT SC, V3005, P41; Jorissen RN, 2005, J CHEM INF MODEL, V45, P549, DOI 10.1021/ci049641u; KELL, 2002, BIOINFORMATICS WORLD, P16; Kim JH, 2004, BIOINFORMATICS, V20, P3179, DOI 10.1093/bioinformatics/bth382; Kless A, 2004, LECT NOTES ARTIF INT, V3303, P191; KOZA, 2001, PAC S BIOCOMP, P434; Koza JR, 1992, GENETIC PROGRAMMING; LANGDON, 2003, LNCS, V2611, P87; LANGDON, 2004, EVOLUTIONARY COMPUTI, P211; LANGDON, 2002, LNCS, V2278, P60; LANGDON, 2001, SOFT COMPUTING IND R, P597; LI, 2005, GENOMICS, V85, P16; LI, 2005, IN PRESS COMPUTERS B; Lin WQ, 2005, J CHEM INF MODEL, V45, P535, DOI 10.1021/ci049642m; Listgarten J, 2004, CLIN CANCER RES, V10, P2725, DOI 10.1158/1078-0432.CCR-1115-03; LIU, 2005, DRUG DISCOVERY TODAY, V2, P179; Liu HX, 2004, J COMPUT AID MOL DES, V18, P389, DOI 10.1007/s10822-004-2722-1; LU, 2004, J PHARM BIOMED ANAL, V35, P679; MALOSSINI, 2004, P 2 EUR WORKSH DAT M; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Miwakeichi F, 2001, COMPUT BIOL MED, V31, P41, DOI 10.1016/S0010-4825(00)00021-4; Moore JH, 2004, LECT NOTES COMPUT SC, V3005, P63; Moore JH, 2002, GENET EPIDEMIOL, V23, P57, DOI 10.1002/gepi.01117; MUCHNIK, 2004, INFLUENCES BREAST CA; NG, 2004, DRUGS DISCOVERY APPR; Nicolotti O, 2002, J MED CHEM, V45, P5069, DOI 10.1021/jm020919o; Norinder U, 2003, NEUROCOMPUTING, V55, P337, DOI 10.1016/S0925-2312(03)00374-6; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; Prados J, 2004, PROTEOMICS, V4, P2320, DOI 10.1002/pmic.200400857; Ratti E, 2001, PURE APPL CHEM, V73, P67, DOI 10.1351/pac200173010067; Reif DM, 2004, EXPERT REV PROTEOMIC, V1, P67, DOI 10.1586/14789450.1.1.67; Roses AD, 2002, NAT REV DRUG DISCOV, V1, P541, DOI 10.1038/nrd840; RUNARSSON, 2004, NEURAL INFORM PROCES, V3, P59; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; Schneider G, 2005, NAT REV DRUG DISCOV, V4, P649, DOI 10.1038/nrd1799; Schneider G, 2004, PROTEOMICS, V4, P1571, DOI 10.1002/pmic.200300786; SCHRATTENHOLZ, 2004, DRUG DISCOVERY TODAY, V1, P1; SEBAG, 2004, LNCS, P384; Seike M, 2004, PROTEOMICS, V4, P2776, DOI 10.1002/pmic.200300795; SHAWETAYLOR, 2000, INTRO SUPPORT VECTOR; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Shen Q, 2004, J COMPUT CHEM, V25, P1726, DOI 10.1002/jcc.20094; SHYU, 2004, GP EM, V5, P121; Simek K, 2004, ENG APPL ARTIF INTEL, V17, P417, DOI 10.1016/j.engappai.2004.04.015; SMITS, 2005, GENETIC PROGRAMMING, V3; SOLMAJER, 2004, DRUG DISCOVERY TODAY, V1, P247; SUWA, 2004, GPCR G PROTEIN COUPL; TAKAHASHI, 2005, J COMPUT CHEM JPN, V4, P43; Takaoka Y, 2003, J CHEM INF COMP SCI, V43, P1269, DOI 10.1021/ci0340431; Teramoto R, 2005, FEBS LETT, V579, P2878, DOI 10.1016/j.febslet.2005.04.045; Thukral SK, 2005, TOXICOL PATHOL, V33, P343, DOI 10.1080/01926230590927230; Tobita M, 2005, BIOORG MED CHEM LETT, V15, P2886, DOI 10.1016/j.bmcl.2005.03.080; Tsai KY, 2005, BIOINFORMATICS, V21, P1180, DOI 10.1093/bioinformatics/bti099; Vapnik VN, 1995, NATURE STAT LEARNING; Vinayagam A, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-116; Wachowiak MP, 2004, IEEE T EVOLUT COMPUT, V8, P289, DOI [10.1109/TEVC.2004.826068, 10.1109/tevc.2004.826068]; WANG, 2004, HICOMB; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Watkins SM, 2002, CURR OPIN MOL THER, V4, P224; XIAO, 2003, HICOMB; XU, 2002, MOLECULES, V7, P566; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1693, DOI 10.1021/ci049820b; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477; YAP, 2005, IN PRESS J CHEM INF; Yap CW, 2004, TOXICOL SCI, V79, P170, DOI 10.1093/toxsci/kfh082; Yoon Y, 2003, CLIN CHEM LAB MED, V41, P529, DOI 10.1515/CCLM.2003.080; Zhao CY, 2004, J CHEM INF COMP SCI, V44, P2040, DOI 10.1021/ci049877y	118	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-29123-7	ADV SOFT COMP			2006							99	110				12	Computer Science, Artificial Intelligence	Computer Science	BEV85	WOS:000239657900010		
S	Mansmann, U; Ruschhaupt, M; Huber, W		Dongarra, J; Madsen, K; Wasniewski, J		Mansmann, U; Ruschhaupt, M; Huber, W			Reproducible statistical analysis in microarray profiling studies	APPLIED PARALLEL COMPUTING: STATE OF THE ART IN SCIENTIFIC COMPUTING	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Workshop on State of the Art in Scientific Computing	JUN 20-23, 2004	Lyngby, DENMARK	Tech Univ Denmark, Dept Informat & Math Modelling, High Performance Comp, Numerical Algorithms Grp Ltd, Comsol A/S Denmark, Sun Microsyst Denmark, UNI C Danish Comp Ctr Denmark, Microsoft Denmark, IBM, Denmark			GENE-EXPRESSION DATA; BREAST-CANCER; CLASSIFICATION; PREDICTION	Reproducibility of calculations is a longstanding issue within the statistical community. Due to the complexity of the algorithms, the size of the data sets, and the limitations of the medium printed paper it is usually not possible to report all the minutiae of the data processing and statistical computations. Like the critical assessment of a mathematical proof it should be possible to check the software behind a complex data analysis. To achieve reproducible calculations and to offer an extensible Computational framework the tool of a compendium is discussed.	Univ Heidelberg, Dept Med Biometry & Informat, INF 305, D-69120 Heidelberg, Germany; German Canc Res Ctr, Div Mol Genome Anal, D-69120 Heidelberg, Germany	Mansmann, U (reprint author), Univ Heidelberg, Dept Med Biometry & Informat, INF 305, D-69120 Heidelberg, Germany.	mansmann@imbi.uni-heidelberg.de					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; [Anonymous], COMMUNICATION; Berger JO, 2003, STAT SCI, V18, P1, DOI 10.1214/ss/1056397485; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brenton JD, 2003, LANCET, V362, P340, DOI 10.1016/S0140-6736(03)14053-6; Bullinger L, 2004, NEW ENGL J MED, V350, P1605, DOI 10.1056/NEJMoa031046; CAREY VJ, 2001, CHANCE, V14, P46; Chang JC, 2003, LANCET, V362, P362, DOI 10.1016/S0140-6736(03)14023-8; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eilers P. H. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4266, DOI 10.1117/12.427987; Gentleman R, 2002, R NEWS, V2, P11; Huang E, 2003, LANCET, V361, P1590, DOI 10.1016/S0140-6736(03)13308-9; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Leisch F, 2002, COMPSTAT 2002: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P575; LEISCH F, 2003, CHANCE, V16, P41; Sawitzki G, 2002, COMPUTATION STAT, V17, P65, DOI 10.1007/s001800200091; Simon R, 2003, J NATL CANCER I, V95, P14; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshiranis RJ, 2002, STAT APPL GENET MOL, V1, P1; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V.N., 1999, NATURE STAT LEARNING	23	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29067-2	LECT NOTES COMPUT SC			2006	3732						939	948				10	Computer Science, Theory & Methods	Computer Science	BEE79	WOS:000237003200114		
S	Evangelista, PF; Embrechts, MJ; Szymanski, BK		Abraham, A; DeBaets, B; Koppen, M; Nickolay, B		Evangelista, Paul F.; Embrechts, Mark J.; Szymanski, Boleslaw K.			Taming the curse of dimensionality in kernels and novelty detection	APPLIED SOFT COMPUTING TECHNOLOGIES: THE CHALLENGE OF COMPLEXITY	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	9th Online Conference on Soft Computing in Industrial Applications	SEP 20-OCT 08, 2004	ELECTR NETWORK	World Federat Soft Comp, Elsevier, Springer, IEEE Syst, Man & Cybernet Soc, NAFIPS, European Soc Fuzzy Log & Technol, Int Fuzzy Syst Assoc			SUPPORT	The curse of dimensionality is a well known but not entirely well-understood phenomena. Too much data, in terms of the number of input variables, is not always a good thing. This is especially true when the problem involves unsupervised learning or supervised learning with unbalanced data (many negative observations but minimal positive observations). This paper addresses two issues involving high dimensional data: The first issue explores the behavior of kernels in high dimensional data. It is shown that variance, especially when contributed by meaningless noisy variables, confounds learning methods. The second part of this paper illustrates methods to overcome dimensionality problems with unsupervised learning utilizing subspace models. The modeling approach involves novelty detection with the one-class SVM.	US Mil Acad, Dept Syst Engn, West Point, NY 10996 USA	Evangelista, PF (reprint author), US Mil Acad, Dept Syst Engn, West Point, NY 10996 USA.		Szymanski, Boleslaw/A-9121-2009	Szymanski, Boleslaw/0000-0002-0307-6743			AGGARWAL CC, 2001, P 2001 ACM SIGMOD IN; BENNETT KP, 2001, SUPPORT VECTOR MACHI, V2; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; BONISSONE P, 2004, P MULT CLASS SYST MC; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang C. -C., 2004, LIBSVM LIB SUPPORT V; Chen Y., 2001, P IEEE INT C IM PROC; DUMOUCHEL W, 2001, STAT SCI, V16, P1; EVANGELISTA PF, 2005, EUR S ART NEUR NETW; EVANGELISTA PF, 2005, INT JONT C NEUR NETW; Glen AG, 2004, COMPUT STAT DATA AN, V44, P451, DOI 10.1016/S0167-9473(02)00234-7; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HOFMANN A, 2004, INT JOINT C NEUR NET; Koppen M., 2000, 5 ONL WORLD C SOFT C; KUNCHEVA LI, 2004, COMBINING PATTERN CL; KUNCHEVA LI, 2003, P 1 IB C PATT REC IM; Kuncheva LI, 2003, IEEE T FUZZY SYST, V11, P729, DOI 10.1109/TFUZZ.2003.819842; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; MA JS, 2003, INT JOINT C NEUR NET; PARSONS L, 2004, SIGKDD EXPLORATIONS; Rohatgi V. K., 2001, INTRO PROBABILITY ST; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; STOLFO S, 2003, 3 IEEE C DAT MIN WOR; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; YANG J, 2004, 18 INT C DAT ENG, P517	28	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-31649-3	ADV SOFT COMP			2006	34						425	438		10.1007/3-540-31662-0_33		14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEN47	WOS:000238287700033		
S	Mukkamala, S; Liu, QZ; Veeraghattam, R; Sung, AH		Rutkowski, L; Tadeusiewicz, R; Zadeh, LA; Zurada, J		Mukkamala, Srinivas; Liu, Qingzhong; Veeraghattam, Rajeev; Sung, Andrew H.			Feature selection and ranking of key genes for tumor classification: Using microarray gene expression data	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING - ICAISC 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Artificial Intelligence and Soft Computing (ICAISC 2006)	JUN 25-29, 2006	Zakopane, POLAND	Polish Neural Network Soc, Acad Humanities & Econ, Czestochowa Univ, Dept Comp Engn, IEEE Computat Intelligence Soc, Poland Chapter			PREDICTION; PATTERNS; GENOME	In this paper we perform a t-test for significant gene expression analysis in different dimensions based on molecular profiles from microarray data, and compare several computational intelligent techniques for classification accuracy on Leukemia, Lymphoma and Prostate cancer datasets of broad institute and Colon cancer dataset from Princeton gene expression project. Classification accuracy is evaluated with Linear genetic Programs, Multivariate Regression Splines (MARS), Classification and Regression Tress (CART) and Random Forests. Linear Genetic Programs and Random forests perform the best for detecting malignancy of different tumors. Our results demonstrate the potential of using learning machines in diagnosis of the malignancy of a tumor. We also address the related issue of ranking the importance of input features, which is itself a problem of great interest. Elimination of the insignificant inputs (genes) leads to a simplified problem and possibly faster and more accurate classification of microarray gene expression data. Experiments on select cancer datasets have been carried out to assess the effectiveness of this criterion. Results show that using significant features gives the most remarkable performance and performs consistently well over microarray gene expression datasets we used. The classifiers used perform the best using the most significant features expect for Prostate cancer dataset.	New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA; New Mexico Inst Min & Technol, Inst Complex Addit Syst & Anal, Socorro, NM 87801 USA	Mukkamala, S (reprint author), New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA.	srinivas@cs.nmt.edu; liu@cs.nmt.edu; rajeev@cs.nmt.edu; sung@cs.nmt.edu	Zurada, Jacek/B-8687-2013				Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Berry G, 1994, STAT METHODS MED RES; Breiman L., 1986, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Goldberg D.E., 1989, GENETIC ALGORITHM SE; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; Koza JR, 1992, GENETIC PROGRAMMING; Peterson C, 2003, ARTIF INTELL MED, V28, P59, DOI 10.1016/S0933-3657(03)00035-6; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Singh D, 2002, CANCER CELL, V1, P227; TAMYO P, 1999, P NATL ACAD SCI USA, V96, P2907	16	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-35748-3	LECT NOTES COMPUT SC			2006	4029						951	961				11	Computer Science, Artificial Intelligence	Computer Science	BEV54	WOS:000239600000100		
S	Martinez-Munoz, G; Sanchez-Martinez, A; Hernandez-Lobato, D; Suarez, A		Kollias, S; Stafylopatis, A; Duch, W; Oja, E		Martinez-Munoz, Gonzalo; Sanchez-Martinez, Aitor; Hernandez-Lobato, Daniel; Suarez, Alberto			Building ensembles of neural networks with class-switching	ARTIFICIAL NEURAL NETWORKS - ICANN 2006, PT 1	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	16th International Conference on Artificial Neural Networks (ICANN 2006)	SEP 10-14, 2006	Athens, GREECE	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc			CLASSIFICATION	This article investigates the properties of ensembles of neural networks, in which each network in the ensemble is constructed using a perturbed version of the training data. The perturbation consists in switching the class labels of a subset of training examples selected at random. Experiments on several UCI and synthetic datasets show that these class-switching ensembles can obtain improvements in classification performance over both individual networks and bagging ensembles.	Univ Autonoma Madrid, E-28049 Madrid, Spain	Martinez-Munoz, G (reprint author), Univ Autonoma Madrid, Ave Francisco Tomas & Valiente 11, E-28049 Madrid, Spain.	gonzalo.martinez@uam.es; aitor.sanchezm@estudiante.uam.es; daniel.hernandez@uam.es; alberto.suarez@uam.es	Hernandez-Lobato, Daniel/E-8337-2012; Martinez-Munoz, Gonzalo/K-7269-2012; Suarez, Alberto/D-6293-2011	Hernandez-Lobato, Daniel/0000-0001-5845-437X; Martinez-Munoz, Gonzalo/0000-0002-6125-6056; Suarez, Alberto/0000-0003-4534-0909			Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CANTADOR I, 2005, IWANN, P208; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Ho T. K., 1998, P 14 INT C PATT REC, V1, P545; Igel C, 2000, P 2 INT ICSC S NEUR, P115; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kong E., 1995, P 12 INT C MACH LEAR, P313; Martinez-Munoz G, 2005, PATTERN RECOGN, V38, P1483, DOI 10.1016/j.patcog.2005.02.020; Nissen S., 2003, IMPLEMENTATION FAST; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Perrone M. P., 1993, NEURAL NETWORKS SPEE, P126; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Schapire RE, 1998, ANN STAT, V26, P1651; Sharkey A.J., 1999, COMBINING ARTIFICIAL; Valentini G, 2004, J MACH LEARN RES, V5, P725; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	26	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-38625-4	LECT NOTES COMPUT SC			2006	4131						178	187				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE51	WOS:000241472100019		
J	Airoldi, EM; Anderson, AG; Fienberg, SE; Skinner, KK				Airoldi, Edoardo M.; Anderson, Annelise G.; Fienberg, Stephen E.; Skinner, Kiron K.			Who Wrote Ronald Reagan's Radio Addresses?	BAYESIAN ANALYSIS			English	Article						Ronald Reagan; Radio Addresses; Authorship; Stylometry; Data Mining; Classification; Function Words; Semantic Analysis; Naive Bayes; Full Bayes; Poisson; Negative-Binomial; Modal Approximation; Mean Approximation		In his campaign for the U. S. presidency from 1975 to 1979, Ronald Reagan delivered over 1000 radio broadcasts. For over 600 of these we have direct evidence of Reagan's authorship. The aim of this study was to determine the authorship of 312 of the broadcasts for which no direct evidence is available. We addressed the prediction problem for speeches delivered in different epochs and we explored a wide range of off-the-shelf classification methods and fully Bayesian generative models. Eventually we produced separate sets of predictions using the most accurate classifiers, based on non-contextual words as well as on semantic features, for the 312 speeches of uncertain authorship. All the predictions agree on 135 of the "unknown" speeches, whereas the fully Bayesian models agree on an additional 154 of them. The magnitude of the posterior odds of authorship led us to conclude that Ronald Reagan drafted 167 speeches and was aided in the preparation of the remaining 145. Our inferences were not sensitive to "reasonable" variations in the sets of constants underlying the prior distributions, and the cross-validated accuracy of our best fully Bayesian model was above 90 percent in all cases. The agreement of multiple methods for predicting the authorship for the "unknown" speeches reinforced our confidence in the accuracy of our classifications.	[Airoldi, Edoardo M.; Fienberg, Stephen E.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; [Anderson, Annelise G.] Stanford Univ, Hoover Inst, Stanford, CA 94305 USA; [Fienberg, Stephen E.] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA; [Skinner, Kiron K.] Carnegie Mellon Univ, Dept Hist, Pittsburgh, PA 15213 USA; [Skinner, Kiron K.] Carnegie Mellon Univ, Dept Social & Decis Sci, Pittsburgh, PA 15213 USA	Airoldi, EM (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.		Airoldi, Edoardo/A-8575-2009				AIROLDI EM, 2006, LECT NOTES IN PRESS; AIROLDI EM, 2005, P CLASS SOC N AM INT; AIROLDI EM, 2003, CMUSTAT03789; Beeferman D., 1997, P 35 ANN M ASS COMP, P373; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Bishop Y. M. M., 1975, DISCRETE MULTIVARIAT; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burrows J. F., 1992, Literary & Linguistic Computing, V7, DOI 10.1093/llc/7.2.91; Church K.W., 1995, P 18 ANN INT ACM SIG, P310, DOI 10.1145/215206.215376; COLLINS J, 2001, DOCU SCOPE JAVA APPL; DAWES R, 1976, 5 OR RES I; de Morgan Augustus, 1872, BUDGET PARADOXES; Erosheva E, 2004, P NATL ACAD SCI USA, V101, P5220, DOI 10.1073/pnas.0307760101; Erosheva EA, 2005, STUD CLASS DATA ANAL, P11, DOI 10.1007/3-540-28084-7_2; Hastie T., 2001, ELEMENTS STAT LEARNI; Hoel P., 1954, INTRO MATH STAT; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Johnson N. L., 1992, UNIVARIATE DISCRETE; Mendenhall TC, 1887, SCIENCE, V11, P237; MILLER GA, 1954, ANNU REV PSYCHOL, P137; Mitchell T. M., 1997, MACHINE LEARNING; MOSTELLER F, 1968, HDB SOCIAL PSYCHOL, V1, P80; Mosteller F, 1964, INFERENCE DISPUTED A; Mosteller F., 1984, APPL BAYESIAN CLASSI; Ripley B. D., 1996, PATTERN RECOGNITION; SIMON HA, 1955, BIOMETRIKA, V42, P425; Skinner Kiron K., 2001, REAGAN HIS OWN HAND; Skinner Kiron K., 2004, REAGANS PATH VICTORY; SKINNER KK, 2001, STORIES HIS OWN HAND; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Tibshirani RJ, 1998, INTRO BOOTSTRAP; Wasserman L, 2004, ALL STAT; Welch BL, 1938, BIOMETRIKA, V29, P350, DOI 10.2307/2332010; YULE UG, 1944, STAT STUDY LIT VOCAB; Zhai Chengxiang, 2001, P 24 ANN INT ACM SIG, P334, DOI DOI 10.1145/383952.384019; Zipf G. K., 1932, SELECTED STUDIES PRI	38	15	15	INT SOC BAYESIAN ANALYSIS	PITTSBURGH	CARNEGIE MELLON UNIV, DEPT STTISTICS, PITTSBURGH, PA 15213 USA	1931-6690			BAYESIAN ANAL	Bayesian Anal.		2006	1	2					289	319				31	Mathematics, Interdisciplinary Applications; Statistics & Probability	Mathematics	V10EI	WOS:000207446900006		
J	Shieh, GS; Jiang, YC; Shih, YS				Shieh, GS; Jiang, YC; Shih, YS			Comparison of support vector machines to other classifiers using gene expression data	COMMUNICATIONS IN STATISTICS-SIMULATION AND COMPUTATION			English	Article						classification; machine learning; microarray gene expression data; support vector machines; tumor class	CLASSIFICATION TREES; HUMAN CANCER; MICROARRAY; PATTERNS; PREDICTION; CELL	Support vector machines (SVMs) was shown to outperform Fisher's linear discriminant analysis and two classification trees (C4.5 and MOC1) in binary classification of microarray gene expression data (MGED) (Brown et al., 2000; Furey et al. 2000). However, multiclass classification is more commonly encountered in identifying tumor subtypes using MGED. Using MGED, Dudoit et al. (2002) showed that diagonal linear discriminant analysis (DLDA) outperformed other linear and quadratic discriminants, nearest neighbor, and classification trees with univariate splits. It is of interest, therefore, to compare performance of SVMs to DLDA and the latest two classification trees with linear splits, which performered better than trees with univariate splits, in multiclass classification of MGED. Furthermore, the performance of SVMs with different types of kernels were studied by three types of multiclass MGED. Finally, we investigate how irrelevant and correlated variables (features) influence the performance of the three classifiers. Some suggestions are made for multiclass classification of MGED.	Acad Sinica, Inst Stat Sci, Taipei 115, Taiwan; Natl Chung Cheng Univ, Inst Stat Sci, Chiayi, Taiwan	Shieh, GS (reprint author), Acad Sinica, Inst Stat Sci, Taipei 115, Taiwan.	gshieh@stat.sinica.edu.tw					Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cristianini N., 2000, INTRO SUPPORT VECTOR; DeRisi J, 1996, NAT GENET, V14, P457; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Loh WY, 1997, STAT SINICA, V7, P815; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Vapnik V., 1998, STAT LEARNING THEORY; Zhang HP, 2003, P NATL ACAD SCI USA, V100, P4168, DOI 10.1073/pnas.0230559100	16	5	5	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0361-0918			COMMUN STAT-SIMUL C	Commun. Stat.-Simul. Comput.	JAN-MAR	2006	35	1					241	256		10.1080/03610910500416215		16	Statistics & Probability	Mathematics	001NX	WOS:000234544700014		
S	Cannon, EO; Mitchell, JBO		Berthold, MR; Glen, R; Fischer, I		Cannon, Edward O.; Mitchell, John B. O.			Classifying the world anti-doping agency's 2005 prohibited list using the Chemistry Development Kit fingerprint	COMPUTATIONAL LIFE SCIENCES II, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Symposium on Computational Life Sciences	SEP 27-29, 2006	Cambridge, ENGLAND	Mol Graph Modelling Soc, ALTANA Pharma AG, AstraZeneca R&D, Boehringer Ingelheim, Inpharmatica, Unilever R&D Port Sunlight, Unilever Corp Res				We used the freely available Chemistry Development Kit (CDK) fingerprint to classify 5235 representative molecules taken from ten banned classes in the 2005 World Anti-Doping Agency's (WADA) prohibited list, including molecules taken from the corresponding activity classes in the MDL Drug Data Report (MDDR). We used both Random Forest and k-Nearest Neighbours (kNN) algorithms to generate classifiers. The kNN classifiers with k = 1 gave a very slightly better Matthews Correlation Coefficient than the Random Forest classifiers; the latter, however, predicted fewer false positives. The performance of kNN classifiers tended to decline with increasing k. The performance of the CDK fingerprint is essentially equivalent to that of Unity 2D. Our results suggest that it will be possible to use freely available chemoinformatics tools to aid the fight against drugs in sport, while minimising the risk of wrongfully penalising innocent athletes.	Univ Cambridge, Dept Chem, Unilever Ctr Mol Sci Informat, Cambridge CB2 1EW, England	Cannon, EO (reprint author), Univ Cambridge, Dept Chem, Unilever Ctr Mol Sci Informat, Lensfield Rd, Cambridge CB2 1EW, England.	jbom1@cam.ac.uk	Mitchell, John/F-9863-2010	Mitchell, John/0000-0002-0379-6097			Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CANNON EO, UNPUB J CHEM INF MOD; Death AK, 2004, J CLIN ENDOCR METAB, V89, P2498, DOI 10.1210/jc.2004-0033; HENDELSMAN DJ, 2004, SCI STKE, V244, pPE41; KONTAXAKIS SG, 2002, P 4 INT C TECHN AUT; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; R Development Core Team, 2005, R LANG ENV STAT COMP; Steinbeck C, 2003, J CHEM INF COMP SCI, V43, P493, DOI 10.1021/ci025584y; Wild DJ, 2000, J CHEM INF COMP SCI, V40, P155, DOI 10.1021/ci990086j	10	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-45767-4	LECT NOTES COMPUT SC			2006	4216						173	182				10	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BFI96	WOS:000242127600017		
S	Lee, CI; Tsai, CJ; Ku, CW		Gavrilova, M; Gervasi, O; Kumar, V; Tan, CJK; Taniar, D; Lagana, A; Mun, Y; Choo, H		Lee, CI; Tsai, CJ; Ku, CW			An evolutionary and attribute-oriented ensemble classifier	COMPUTATIONAL SCIENCE AND ITS APPLICATIONS - ICCSA 2006, PT 2	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Conference on Computational Science and Its Applications (ICCSA 2006)	MAY 08-AUG 11, 2003	Glasgow, SCOTLAND	IEE, Univ Perugia, Univ Calgary, Univ Minnesota, Queens Univ Belfast, ERCIM, OptimaNumerics, INTEL, AMD				In the research area of decision tree, numerous researchers have been focusing on improving the predictive accuracy. However, obvious improvement can hardly be made until the introduction of the ensemble classifier. In this paper, we propose an Evolutionary Attribute-Oriented Ensemble Classifier (EAOEC) to improve the accuracy of sub-classifiers and at the same time maintain the diversity among them. EAOEC uses the idea of evolution to choose proper attribute subset for the building of every sub-classifier. To avoid the huge computation cost for the evolution, EAOEC uses the gini value gained during the construction of a sub-tree as the evolution basis to build the next sub-tree. Eventually, EAOEC classifier uses uniform weight voting to combine all sub-classifiers and experiments show that EAOEC can efficiently improve the predictive accuracy.	Natl Univ Tainan, Grad Inst Comp Sci & Informat Engn, Tainan, Taiwan; Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu, Taiwan	Lee, CI (reprint author), Natl Univ Tainan, Grad Inst Comp Sci & Informat Engn, Tainan, Taiwan.	leeci@mail.nutn.edu.tw; tsaicj@cis.nctu.edu.tw					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CUNNINGHAM P, 2000, DIVERSITY VERSUS QUA, P109; Freund Y, 1996, EXPT NEW BOOSTING AL, P148; Guerra-Salcedo C, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P236; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HO TK, 1995, RANDOM DECISION FORE, P278; Kuncheva L, 2000, ICPR, P2168; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; MDLVILLE P, 2004, DIVERSE ENSEMBLES AC; Mehta M, 1996, SLIQ FAST SCALABLE C, P18; MEHTA M, 1995, MDL BASED DECISION T, P216; Opitz D. W., 1999, FEATURE SELECTION EM, P379; QUINLAN JR, 1993, PROGRAM MACHINE LEAR; Rastogi R, 2000, DATA MIN KNOWL DISC, V4, P315, DOI 10.1023/A:1009887311454; Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P957, DOI 10.1007/0-387-25465-X_45; Shipp C. A., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00051-9; Windeatt T, 2004, INT C PATT RECOG, P454, DOI 10.1109/ICPR.2004.1334564; Wolpert DH, 1999, MACH LEARN, V35, P41, DOI 10.1023/A:1007519102914; XIE Z, 2005, ENHANCING SNNB LOCAL, P523	21	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-34072-6	LECT NOTES COMPUT SC			2006	3981						1210	1218				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEL00	WOS:000237646100128		
S	Chen, HT; Liu, TL; Fuh, CS		Leonardis, A; Bischof, H; Pinz, A		Chen, HT; Liu, TL; Fuh, CS			Segmenting highly articulated video objects with weak-prior random forests	COMPUTER VISION - ECCV 2006, PT 4, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	9th European Conference on Computer Vision (ECCV 2006)	MAY 07-13, 2006	Graz, AUSTRIA	Adv Comp Vis, Graz Univ Technol, Univ Ljubljana			IMAGE SEGMENTATION; RECOGNITION; EXTRACTION; SNAKES; CUTS	We address the problem of segmenting highly articulated video objects in a wide variety of poses. The main idea of our approach is to model the prior information of object appearance via random forests. To automatically extract an object from a video sequence, we first build a random forest based on image patches sampled from the initial template. Owing to the nature of using a randomized technique and simple features, the modeled prior information is considered weak, but on the other hand appropriate for our application. Furthermore, the random forest can be dynamically updated to generate prior probabilities about the configurations of the object in subsequent image frames. The algorithm then combines the prior probabilities with low-level region information to produce a sequence of figure-ground segmentations. Overall, the proposed segmentation technique is useful and flexible in that one can easily integrate different cues and efficiently select discriminating features to model object appearance and handle various articulations.	Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan	Chen, HT (reprint author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.	pras@iis.sinica.edu.tw; liutyng@iis.sinica.edu.tw; fuh@csie.ntu.edu.tw					Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; BLAKE A, 2004, ECCV, V1, P428; Blake A., 1998, ACTIVE CONTOURS APPL; BORENSTEIN E, 2002, ECCV, V2, P109; BOYKOV Y, 1998, CVPR, P648; Boykov Y., 2001, ICCV, VI, P105; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHAN T, 2005, CVPR, V2, P1164; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R., 2003, CVPR, V2, pII, DOI DOI 10.1109/CVPR.2003.1211479; FOWLKES C, 2003, CVPR, V2, P54; Gavrila D. M., 2000, ECCV, V2, P37; Geman S., 1984, PATTERN ANAL MACHINE, VPAMI-6, P721, DOI DOI 10.1109/TPAMI.1984.4767596; KUMAR MP, 2005, CVPR, V1, P18; Lepetit V., 2005, C COMP VIS PATT REC, V2, P775; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Martin D., 2001, ICCV, V2, P416, DOI DOI 10.1109/ICCV.2001.937655; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; Mori G., 2004, CVPR, V2, pII; Mumford D., 1985, CVPR, P22; Paragios N., 2000, ECCV, V2, P224; REN X, 2005, NIPS, V18; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Toyama K, 2001, ICCV, V2, P50; Tu Z., 2003, ICCV, P18; Viola P., 2001, CVPR, V1, P1, DOI DOI 10.1109/CVPR.2001.990517; WU Y, 2003, CVPR, V2, P649; Yedidia JS, 2003, EXPLORING ARTIFICIAL, P239; YU SX, 2003, CVPR, V2, P39; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884	34	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33838-1	LECT NOTES COMPUT SC			2006	3954		4				373	385				13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEK45	WOS:000237557400029		
J	Fox, T; Krieg, JM				Fox, Thomas; Krieg, Jan M.			Machine learning techniques for in silico modeling of drug metabolism	CURRENT TOPICS IN MEDICINAL CHEMISTRY			English	Review						in silico ADMET; QSAR; classification; drug metabolism; cytochrome P450; machine learning; non-linear models	SUPPORT VECTOR MACHINES; UDP-GLUCURONOSYLTRANSFERASE ISOFORMS; CYTOCHROME-P450 3A4 INHIBITORS; ARTIFICIAL NEURAL-NETWORKS; ACTIVE-SITES; CHEMICAL METABOLISM; COMPOUND LIBRARIES; AQUEOUS SOLUBILITY; QSPR MODELS; PREDICTION	The computational assessment of drug metabolism has gained considerable interest in pharmaceutical research. Amongst others, machine learning techniques have been employed to model relationships between the chemical Structure of a compound and its metabolic fate. Examples for these techniques, which were originally developed in fields far from drug discovery, are artificial neural networks or Support vector machines. This paper summarizes the application of various machine learning techniques to predict the interaction between organic molecules and metabolic enzymes. More complex endpoints Such as metabolic stability or in vivo clearance will also be addressed. It is shown that the prediction of metabolic endpoints with machine learning techniques has made considerable progress over the past few years. Depending oil the procedure used, either classification or quantitative prediction is possible for even large and diverse compound sets. Together with the expanding experimental data basis, these in silico methods have become valuable tools in the drug discovery and development process.	Boehringer Ingelheim Pharma GmbH & Co KG, Dept Lead Discovery, D-88397 Biberach, Germany	Krieg, JM (reprint author), Boehringer Ingelheim Pharma GmbH & Co KG, Dept Lead Discovery, D-88397 Biberach, Germany.	jan.kriegl@bc.boehringer-ingelheim.com					ANZALI S., 1998, 3D QSAR DRUG DESIGN, V2, P273; Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; Balakin Konstantin V, 2005, Curr Drug Discov Technol, V2, P99, DOI 10.2174/1570163054064666; Balakin KV, 2004, DRUG METAB DISPOS, V32, P1111, DOI 10.1124/dmd.104.000364; Balakin KV, 2004, DRUG METAB DISPOS, V32, P1183, DOI 10.1124/dmd.104.000356; BARRETT SJ, 2006, APPL SOFT COMPUTING; BARRETT SJ, 2005, 10 ONL WORLD C SOFT; Baumann K, 2003, TRAC-TREND ANAL CHEM, V22, P395, DOI 10.1016/S0165-9936(03)00607-1; Beck ME, 2005, J CHEM INF MODEL, V45, P273, DOI 10.1021/ci049687n; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breimann L, 1984, CLASSIFICATION REGRE; Bruneau P, 2001, J CHEM INF COMP SCI, V41, P1605, DOI 10.1021/ci010363y; Bugrim A, 2004, DRUG DISCOV TODAY, V9, P127, DOI 10.1016/S1359-6446(03)02971-4; Burden FR, 2000, J CHEM INF COMP SCI, V40, P1423, DOI 10.1021/ci000450a; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Bursi R, 2001, J MOL GRAPH MODEL, V19, P552, DOI 10.1016/S1093-3263(01)00089-4; Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67; Chohan KK, 2005, J MED CHEM, V48, P5154, DOI 10.1021/jm048959a; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cruciani G, 2005, J MED CHEM, V48, P6970, DOI 10.1021/jm050529c; Dabrowski MJ, 2002, J AM CHEM SOC, V124, P11866, DOI 10.1021/ja027552x; Dajani R, 1999, J BIOL CHEM, V274, P37862, DOI 10.1074/jbc.274.53.37862; Danielson PB, 2002, CURR DRUG METAB, V3, P561, DOI 10.2174/1389200023337054; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; de Groot MJ, 2004, CURR TOP MED CHEM, V4, P1803, DOI 10.2174/1568026043387061; de Groot MJ, 2002, ADV DRUG DELIVER REV, V54, P367, DOI 10.1016/S0169-409X(02)00009-1; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Ekins S, 2001, J PHARMACOL TOXICOL, V45, P65, DOI 10.1016/S1056-8719(01)00119-8; Ekins S, 2001, DRUG METAB DISPOS, V29, P936; Ekins S, 2003, BIOCHEM SOC T, V31, P611, DOI 10.1042/BST0310611; Ekins Sean, 2005, Expert Opin Drug Metab Toxicol, V1, P303, DOI 10.1517/17425255.1.2.303; Ekins S, 2000, J PHARMACOL EXP THER, V295, P463; Ekins S, 2003, DRUG METAB DISPOS, V31, P1077, DOI 10.1124/dmd.31.9.1077; Eriksson L, 2003, ENVIRON HEALTH PERSP, V111, P1361, DOI 10.1289/ehp.5758; Evans WE, 1999, SCIENCE, V286, P487, DOI 10.1126/science.286.5439.487; van de Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192, DOI 10.1038/nrd1032; Guengerich FP, 2005, CYTOCHROME P450 STRU, P377, DOI 10.1007/0-387-27447-2_10; Guengerich FP, 2001, CHEM RES TOXICOL, V14, P611, DOI 10.1021/tx0002583; Guha R, 2004, J MOL GRAPH MODEL, V23, P1, DOI 10.1016/j.jmgm.2004.03.003; Kurogi Y, 2001, CURR MED CHEM, V8, P1035; Hansch C, 2004, DRUG METAB REV, V36, P105, DOI 10.1081/DMR-120028428; Hawkins D. M., 1995, FIRM FORMAL INFERENC; Hawkins D. M., 1982, TOPICS APPL MULTIVAR; Houston JB, 2000, DRUG METAB DISPOS, V28, P246; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Hutzler JM, 2005, CURR OPIN DRUG DISC, V8, P51; Jalaie M., 2005, CHEMOINFORMATICS CON, P449; Jones JP, 2002, DRUG METAB DISPOS, V30, P7, DOI 10.1124/dmd.30.1.7; Kennedy T, 1997, DRUG DISCOV TODAY, V2, P436, DOI 10.1016/S1359-6446(97)01099-4; Kenworthy KE, 2001, DRUG METAB DISPOS, V29, P1644; Khan KK, 2002, MOL PHARMACOL, V61, P495, DOI 10.1124/mol.61.3.495; King CD, 2000, CURR DRUG METAB, V1, P143, DOI 10.2174/1389200003339171; Kless A, 2004, LECT NOTES ARTIF INT, V3303, P191; Kola I, 2004, NAT REV DRUG DISCOV, V3, P711, DOI 10.1038/nrd1470; Korolev D, 2003, J MED CHEM, V46, P3631, DOI 10.1021/jm030102a; Korzekwa KR, 1998, BIOCHEMISTRY-US, V37, P4137, DOI 10.1021/bi9715627; KORZEKWA KR, 1993, PHARMACOGENETICS, V3, P1, DOI 10.1097/00008571-199302000-00001; Kriegl JM, 2005, QSAR COMB SCI, V24, P491, DOI 10.1002/qsar.200430925; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Kubinyi H, 2002, QUANT STRUCT-ACT REL, V21, P348, DOI 10.1002/1521-3838(200210)21:4<348::AID-QSAR348>3.0.CO;2-D; Kubinyi H, 1998, ENCY COMPUTATIONAL C, P2309; Kumar GN, 2001, MED RES REV, V21, P397, DOI 10.1002/med.1016; Langowski J, 2002, ADV DRUG DELIVER REV, V54, P407, DOI 10.1016/S0169-409X(02)00011-X; Li AP, 2001, DRUG DISCOV TODAY, V6, P357, DOI 10.1016/S1359-6446(01)01712-3; Livingstone DJ, 2000, J CHEM INF COMP SCI, V40, P195, DOI 10.1021/ci990162i; LIVINGSTONE DJ, 1993, J MED CHEM, V36, P1295, DOI 10.1021/jm00061a023; Livingstone DJ, 1997, J COMPUT AID MOL DES, V11, P135, DOI 10.1023/A:1008074223811; Mackay D. J. C., 1994, MODELS NEURAL NETWOR, P211; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Manallack DT, 1999, EUR J MED CHEM, V34, P195, DOI 10.1016/S0223-5234(99)80052-X; Manga N, 2005, SAR QSAR ENVIRON RES, V16, P43, DOI 10.1080/10629360412331319871; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Miners JO, 2004, ANNU REV PHARMACOL, V44, P1, DOI 10.1146/annurev.pharmtox.44.101802.121546; Mitchell T. M., 1997, MACHINE LEARNING; Molnar L, 2002, BIOORG MED CHEM LETT, V12, P419, DOI 10.1016/S0960-894X(01)00771-5; Moon T, 2000, QUANT STRUCT-ACT REL, V19, P257, DOI 10.1002/1521-3838(200006)19:3<257::AID-QSAR257>3.0.CO;2-2; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Neal R. M., 1996, BAYESIAN LEARNING NE; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1992, C4 5 PROGRAMS MACHIN; Rendic S, 1997, DRUG METAB REV, V29, P413, DOI 10.3109/03602539709037591; Rios GR, 2002, DRUG METAB DISPOS, V30, P1364, DOI 10.1124/dmd.30.12.1364; Schneider G, 1998, PROG BIOPHYS MOL BIO, V70, P175, DOI 10.1016/S0079-6107(98)00026-1; Schneider G, 1999, J MED CHEM, V42, P5072, DOI 10.1021/jm991030j; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Shen M, 2003, J MED CHEM, V46, P3013, DOI 10.1021/jm020491t; Singh SB, 2003, J MED CHEM, V46, P1330, DOI 10.1021/jm020400s; Smith D. A., 2001, PHARMACOKINETICS MET; Smith PA, 2004, J MOL GRAPH MODEL, V22, P507, DOI 10.1016/j.jmgm.2004.03.011; SMOLA AJ, 1998, NCSTR1998030; Sorich MJ, 2003, J CHEM INF COMP SCI, V43, P2019, DOI 10.1021/ci034108k; Sorich MJ, 2004, J MED CHEM, V47, P5311, DOI 10.1021/jm0495529; Susnow RG, 2003, J CHEM INF COMP SCI, V43, P1308, DOI 10.1021/ci030283p; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Teckentrup A, 2004, J CHEM INF COMP SCI, V44, P626, DOI 10.1021/ci034223v; Terfloth L, 2001, DRUG DISCOV TODAY, V6, pS102; Todeschini R., 2000, HDB MOL DESCRIPTORS; Tropsha A, 2003, QSAR COMB SCI, V22, P69, DOI 10.1002/qsar.200390007; Trotter MWB, 2003, QSAR COMB SCI, V22, P533, DOI 10.1002/qsar.200310006; Vapnik VN, 1995, NATURE STAT LEARNING; Williams JA, 2002, DRUG METAB DISPOS, V30, P1266, DOI 10.1124/dmd.30.11.1266; Winkler DA, 2004, DRUG FUTURE, V29, P1043, DOI 10.1358/dof.2004.029.10.863395; Wrighton SA, 2000, DRUG METAB REV, V32, P339, DOI 10.1081/DMR-100102338; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Yan AX, 2003, J CHEM INF COMP SCI, V43, P429, DOI 10.1021/ci025590u; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Zamora I, 2003, J MED CHEM, V46, P2313, DOI 10.1021/jm021104i; Zheng WF, 2000, J CHEM INF COMP SCI, V40, P185, DOI 10.1021/ci980033m; Zuegge J, 2002, QUANT STRUCT-ACT REL, V21, P249, DOI 10.1002/1521-3838(200208)21:3<249::AID-QSAR249>3.0.CO;2-S; Zuegge J, 2001, CLIN PHARMACOKINET, V40, P553, DOI 10.2165/00003088-200140070-00006; Zupan J., 1999, NEURAL NETWORKS CHEM; 1996, NEURAL NETWORKS QSAR	119	42	42	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1568-0266			CURR TOP MED CHEM	Curr. Top. Med. Chem.		2006	6	15					1579	1591		10.2174/156802606778108915		13	Chemistry, Medicinal	Pharmacology & Pharmacy	081GI	WOS:000240304800003	16918470	
J	Arimoto, R				Arimoto, Rieko			Computational models for predicting interactions with cytochrome p450 enzyme	CURRENT TOPICS IN MEDICINAL CHEMISTRY			English	Review							MOLECULAR-FIELD ANALYSIS; SUBSTRATE-BINDING-SITE; COMPETITIVE CYP2C9 INHIBITORS; RELATIONSHIP 3D/4D-QSAR ANALYSES; P450-MEDIATED DRUG-METABOLISM; ACTIVE-SITE; PHARMACOPHORE MODEL; COMBINED PROTEIN; 3A4 INHIBITORS; CATALYTIC ACTIVITY	Cytochrome p450 (CYP) enzymes are predominantly involved in Phase I metabolism of xenobiotics. As only 6 isoenzymes are responsible for similar to 90% of known oxidative drug metabolism, a number of frequently prescribed drugs share the CYP-mediated metabolic pathways. Competing for a single enzyme by the co-administered therapeutic agents can Substantially alter the plasma concentration and clearance of the agents. Furthermore, many drugs are known to inhibit certain p450 enzymes which they are not substrates for. Because some drug-drug interactions could cause serious adverse events leading to a costly failure of drug development, early detection of potential drug-drug interactions is highly desirable. The ultimate goal is to be able to predict the CYP specificity and the interactions for a novel compound from its chemical structure. Current computational modeling approaches, such as two-dimensional and three-dimensional quantitative structure-activity relationship (QSAR), pharmacophore mapping and machine learning methods have resulted in statistically valid predictions. Homology models have been often combined with 3D-QSAR models to impose additional steric restrictions and/or to identify the interaction site on the proteins. This article summarizes the available models, methods, and key findings for CYP1A2, 2A6, 2C9, 2D6 and 3A4 isoenzymes.	Vertex Pharmaceut Inc, Cambridge, MA 02139 USA	Arimoto, R (reprint author), Vertex Pharmaceut Inc, 130 Waverly St, Cambridge, MA 02139 USA.	rieko_arimoto@vrtx.com					Afzelius L, 2002, J COMPUT AID MOL DES, V16, P443, DOI 10.1023/A:1021281008423; Afzelius L, 2001, MOL PHARMACOL, V59, P909; Afzelius L, 2004, J MED CHEM, V47, P907, DOI 10.1021/jm030972s; AHMAD SR, 1995, LANCET, V345, P508, DOI 10.1016/S0140-6736(95)90595-2; Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; Asikainen A, 2003, TOXICOL IN VITRO, V17, P449, DOI 10.1016/S0887-2333(03)00065-1; Balakin KV, 2004, DRUG METAB DISPOS, V32, P1111, DOI 10.1124/dmd.104.000364; Balakin KV, 2004, DRUG METAB DISPOS, V32, P1183, DOI 10.1124/dmd.104.000356; Boxenbaum H, 1999, J PHARM PHARM SCI, V2, P47; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; Chohan KK, 2005, J MED CHEM, V48, P5154, DOI 10.1021/jm048959a; Cohen LH, 2003, DRUG METAB DISPOS, V31, P1005, DOI 10.1124/dmd.31.8.1005; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; Crespi CL, 1997, ANAL BIOCHEM, V248, P188, DOI 10.1006/abio.1997.2145; Crespi CL, 1998, MED CHEM RES, V8, P457; Crivori P, 2004, J COMPUT AID MOL DES, V18, P155, DOI 10.1023/B:JCAM.0000035184.11906.c2; Cruciani G, 2000, EUR J PHARM SCI, V11, pS29, DOI 10.1016/S0928-0987(00)00162-7; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; deGroot MJ, 1996, CHEM RES TOXICOL, V9, P1079, DOI 10.1021/tx960003i; de Groot MJ, 2002, J MED CHEM, V45, P1983, DOI 10.1021/jm0110791; de Groot MJ, 1999, J MED CHEM, V42, P4062, DOI 10.1021/jm991058v; deGroot MJ, 1997, CHEM RES TOXICOL, V10, P41, DOI 10.1021/tx960129f; DeGroot MJ, 1997, XENOBIOTICA, V27, P357; de Groot MJ, 2002, ADV DRUG DELIVER REV, V54, P367, DOI 10.1016/S0169-409X(02)00009-1; de Groot MJ, 1999, J MED CHEM, V42, P1515, DOI 10.1021/jm981118h; DEGROOT MJ, 1995, DRUG METAB DISPOS, V23, P667; De Rienzo F, 2000, J COMPUT AID MOL DES, V14, P93, DOI 10.1023/A:1008187802746; Dietterich T. G., 2003, HDB BRAIN THEORY NEU, P405; Domanski TL, 2001, BIOCHEMISTRY-US, V40, P10150, DOI 10.1021/bi010758a; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Ekins S, 1999, J PHARMACOL EXP THER, V291, P424; Ekins S, 2001, DRUG METAB DISPOS, V29, P936; Ekins S, 2000, DRUG METAB DISPOS, V28, P994; Ekins S, 1999, J PHARMACOL EXP THER, V290, P429; Ekins S, 1999, PHARMACOGENETICS, V9, P477; Ekins S, 2003, DRUG METAB DISPOS, V31, P1077, DOI 10.1124/dmd.31.9.1077; ELLIS SW, 1995, J BIOL CHEM, V270, P29055; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FUHR U, 1993, MOL PHARMACOL, V43, P191; GHONEIM MM, 1981, CLIN PHARMACOL THER, V29, P749; GOODFORD PJ, 1985, J MED CHEM, V28, P849, DOI 10.1021/jm00145a002; Guengerich FP, 2002, BIOCHEMISTRY-US, V41, P11025, DOI 10.1021/bi020341k; Haining RL, 1999, BIOCHEMISTRY-US, V38, P3285, DOI 10.1021/bi982161+; Haji-Momenian S, 2003, BIOORGAN MED CHEM, V11, P5545, DOI 10.1016/S0968-0896(03)00525-X; Hayhurst GP, 2001, BIOCHEM J, V355, P373, DOI 10.1042/0264-6021:3550373; He MX, 1999, ARCH BIOCHEM BIOPHYS, V372, P16, DOI 10.1006/abbi.1999.1468; HONIG PK, 1993, JAMA-J AM MED ASSOC, V269, P1513, DOI 10.1001/jama.269.12.1513; Hosea NA, 2000, BIOCHEMISTRY-US, V39, P5929, DOI 10.1021/bi992765t; Hutzler JM, 2002, DRUG METAB DISPOS, V30, P355, DOI 10.1124/dmd.30.4.355; Jalaie Mehran, 2004, Methods Mol Biol, V275, P449; Jones BC, 1996, DRUG METAB DISPOS, V24, P260; Jones JP, 1996, DRUG METAB DISPOS, V24, P1; Kenworthy KE, 1999, BRIT J CLIN PHARMACO, V48, P716; Klebe G, 1998, PERSPECT DRUG DISCOV, V12, P87, DOI 10.1023/A:1017025803403; Korhonen LE, 2005, J MED CHEM, V48, P3808, DOI 10.1021/jm0489713; Korolev D, 2003, J MED CHEM, V46, P3631, DOI 10.1021/jm030102a; Korzekwa KR, 1998, BIOCHEMISTRY-US, V37, P4137, DOI 10.1021/bi9715627; KOYMANS L, 1992, CHEM RES TOXICOL, V5, P211, DOI 10.1021/tx00026a010; Krayenbuhl JC, 1999, EUR J CLIN PHARMACOL, V55, P559, DOI 10.1007/s002280050673; Kriegl JM, 2005, EUR J PHARM SCI, V24, P451, DOI 10.1016/j.ejps.2004.12.009; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Le Bourdonnec B, 2005, BIOORG MED CHEM LETT, V15, P2647, DOI 10.1016/j.bmcl.2005.03.020; Lee H, 1998, BIOCHEM PHARMACOL, V55, P1369, DOI 10.1016/S0006-2952(97)00644-8; LEWIS DFV, 1986, BIOCHEM PHARMACOL, V35, P2179, DOI 10.1016/0006-2952(86)90589-7; Lichter JB, 1997, CURR OPIN BIOTECH, V8, P692, DOI 10.1016/S0958-1669(97)80121-8; Lin JH, 1998, CLIN PHARMACOKINET, V35, P361, DOI 10.2165/00003088-199835050-00003; Locuson CW, 2005, DRUG METAB DISPOS, V33, P873, DOI 10.1124/dmd.105.004325; MANCY A, 1995, BIOCHEMISTRY-US, V34, P10365, DOI 10.1021/bi00033a007; Mancy A, 1996, BIOCHEMISTRY-US, V35, P16205, DOI 10.1021/bi961950t; Melet A, 2003, ARCH BIOCHEM BIOPHYS, V409, P80, DOI 10.1016/S0003-9861(02)00548-9; MEYER UA, 1986, XENOBIOTICA, V16, P449; Molnar L, 2002, BIOORG MED CHEM LETT, V12, P419, DOI 10.1016/S0960-894X(01)00771-5; Norinder U, 2005, SAR QSAR ENVIRON RES, V16, P1, DOI 10.1080/10629360412331319835; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Onderwater RCA, 1999, CHEM RES TOXICOL, V12, P555, DOI 10.1021/tx980248q; Pastor M, 2000, J MED CHEM, V43, P3233, DOI 10.1021/jm000941m; PoliScaife S, 1997, BIOCHEMISTRY-US, V36, P12672, DOI 10.1021/bi970527x; Poso A, 2001, J COMPUT AID MOL DES, V15, P195, DOI 10.1023/A:1008102217770; Rahnasto M, 2005, J MED CHEM, V48, P440, DOI 10.1021/jm049536b; Rao S, 2000, J MED CHEM, V43, P2789, DOI 10.1021/jm000048n; SANZ F, 1994, QUANT STRUCT-ACT REL, V13, P281, DOI 10.1002/qsar.19940130305; Schoch GA, 2004, J BIOL CHEM, V279, P9497, DOI 10.1074/jbc.M312516200; SHIMADA T, 1994, J PHARMACOL EXP THER, V270, P414; SHOU M, 1994, BIOCHEMISTRY-US, V33, P6450, DOI 10.1021/bi00187a009; Stresser DM, 2000, DRUG METAB DISPOS, V28, P1440; STROBL GR, 1993, J MED CHEM, V36, P1136, DOI 10.1021/jm00061a004; Szklarz GD, 1997, J COMPUT AID MOL DES, V11, P265, DOI 10.1023/A:1007956612081; Vapnik VN, 1995, NATURE STAT LEARNING; Vaz RJ, 2005, BIOORG MED CHEM LETT, V15, P3816, DOI 10.1016/j.bmcl.2005.06.007; Wanchana S, 2003, PHARMACEUT RES, V20, P1401, DOI 10.1023/A:1025702009611; Wang RW, 2000, DRUG METAB DISPOS, V28, P360; Wester MR, 2004, J BIOL CHEM, V279, P35630, DOI 10.1074/jbc.M405427200; Williams PA, 2003, NATURE, V424, P464, DOI 10.1038/nature01862; Williams PA, 2004, SCIENCE, V305, P683, DOI 10.1126/science.1099736; Williams PA, 2000, MOL CELL, V5, P121, DOI 10.1016/S1097-2765(00)80408-6; WOLFF T, 1985, CANCER RES, V45, P2116; Wrighton SA, 2000, DRUG METAB REV, V32, P339, DOI 10.1081/DMR-100102338; Yano JK, 2005, NAT STRUCT MOL BIOL, V12, P822, DOI 10.1038/nsmb971; Yano JK, 2004, J BIOL CHEM, V279, P38091, DOI 10.1074/jbc.C400293200; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Zlokarnik G, 2005, DRUG DISCOV TODAY, V10, P1443, DOI 10.1016/S1359-6446(05)03580-4	104	38	39	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1568-0266			CURR TOP MED CHEM	Curr. Top. Med. Chem.		2006	6	15					1609	1618		10.2174/156802606778108951		10	Chemistry, Medicinal	Pharmacology & Pharmacy	081GI	WOS:000240304800005	16918472	
S	Sandri, M; Zuccolotto, P		Zani, S; Cerioli, A; Riani, M; Vichi, M		Sandri, Marco; Zuccolotto, Paola			Variable selection using random forests	DATA ANALYSIS, CLASSIFICATION AND THE FORWARD SEARCH	Studies in Classification Data Analysis and Knowledge Organization		English	Proceedings Paper	Biennial Meeting of the Classification-and-Data-Analysis-Group of the Italian-Statistical-Society	JUN 06-08, 2005	Parma, ITALY	Italian Stat Soc, Classificat & Data Anal Grp	Univ Parma			One of the main topic in the development of predictive models is the identification of variables which axe predictors of a given outcome. Automated model selection methods, such as backward or forward stepwise regression, are classical solutions to this problem, but are generally based on strong assumptions about the functional form of the model or the distribution of residuals. In this paper an alternative selection method, based on the technique of Random Forests, is proposed in the context of classification, with an application to a real dataset.	Univ Brescia, Dipartimento Metodi Quantitat, I-25122 Brescia, Italy	Sandri, M (reprint author), Univ Brescia, Dipartimento Metodi Quantitat, cda S Chiara 50, I-25122 Brescia, Italy.	zuk@eco.unibs.it	Zuccolotto, Paola/C-2539-2011; Sandri, Marco/L-2875-2013	Sandri, Marco/0000-0002-1422-5695			Austin PC, 2004, AM STAT, V58, P131, DOI 10.1198/0003130043277; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 2002, MANUAL SETTING UP US; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Ennis M, 1998, STAT MED, V17, P2501; GUGLIELMI A, 2002, ENDOSCOPY, V34, P771; HOCKING RR, 1976, BIOMETRICS, V42, P1; MILLER AJ, 1984, J ROY STAT SOC A STA, V147, P389, DOI 10.2307/2981576; RAIMAN L, 1984, CLASSIFICATION REGRE; SANDRI M, 2006, UNPUB ANAL BIAS EFFE; SANDRI M, 2004, CLASSIFICATION RANDO, P235	14	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-35977-X	STUD CLASS DATA ANAL			2006							263	270		10.1007/3-540-35978-8_30		8	Computer Science, Artificial Intelligence; Statistics & Probability	Computer Science; Mathematics	BFE02	WOS:000241360600030		
J	Bhattacharyya, S; Epstein, J; Suva, LJ				Bhattacharyya, Sudeepa; Epstein, Joshua; Suva, Larry J.			Biomarkers that discriminate multiple myeloma patients with or without skeletal involvement detected using SELDI-TOF mass spectrometry and statistical and machine learning tools	DISEASE MARKERS			English	Article						SELDI; surface-enhanced laser desorption/ionization; Multiple Myeloma; biomarkers	ENHANCED LASER-DESORPTION; PARTIAL LEAST-SQUARES; OVARIAN-CANCER; EXPRESSION PROFILES; PROTEOMIC PATTERNS; BREAST-CANCER; RANDOM FOREST; CLASSIFICATION; SERUM; DIAGNOSIS	Multiple Myeloma (MM) is a severely debilitating neoplastic disease of B cell origin, with the primary source of morbidity and mortality associated with unrestrained bone destruction. Surface enhanced laser desorption/ionization time-of-flight mass spectrometry (SELDI-TOF MS) was used to screen for potential biomarkers indicative of skeletal involvement in patients with MM. Serum samples from 48 MM patients, 24 with more than three bone lesions and 24 with no evidence of bone lesions were fractionated and analyzed in duplicate using copper ion loaded immobilized metal affinity SELDI chip arrays. The spectra obtained were compiled, normalized, and mass peaks with mass-to-charge ratios (m/z) between 2000 and 20,000 Da identified. Peak information from all fractions was combined together and analyzed using univariate statistics, as well as a linear, partial least squares discriminant analysis (PLS-DA), and a non-linear, random forest (RF), classification algorithm. The PLS-DA model resulted in prediction accuracy between 96-100%, while the RF model was able to achieve a specificity and sensitivity of 87.5% each. Both models as well as multiple comparison adjusted univariate analysis identified a set of four peaks that were the most discriminating between the two groups of patients and hold promise as potential biomarkers for future diagnostic and/or therapeutic purposes.	Univ Arkansas Med Sci, Dept Orthoped Surg, Ctr Orthoped Res, Little Rock, AR 72205 USA; Univ Arkansas Med Sci, Myeloma Inst Res & Treatment, Little Rock, AR 72205 USA	Suva, LJ (reprint author), Univ Arkansas Med Sci, Dept Orthoped Surg, Ctr Orthoped Res, 4301 W Markham St,644, Little Rock, AR 72205 USA.	SuvaLarryJ@uams.edu					Barlogie B, 2004, BLOOD, V103, P20, DOI 10.1182/blood-2003-04-1045; Barlogie B, 1997, SEMIN HEMATOL, V34, P67; BATAILLE R, 1991, J CLIN INVEST, V88, P62, DOI 10.1172/JCI115305; BATAILLE R, 1992, HEMATOL ONCOL CLIN N, V6, P285; BENSMAIL H, 2005, BIOMED BIOTECHNOL, V2, P80; Bhattacharyya S, 2004, NEOPLASIA, V6, P674, DOI 10.1593/neo.04262; Breiman L., 1996, OUT BAG ESTIMATION; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUBLEY GJ, 1995, CLIN ONCOLOGY AM CAN, P470; DURIE BGM, 1975, CANCER, V36, P842, DOI 10.1002/1097-0142(197509)36:3<842::AID-CNCR2820360303>3.0.CO;2-U; Gelady P., 1986, ANAL CHIM ACTA, V35, P1; Grizzle William E, 2005, Cancer Inform, V1, P86; Gunther EC, 2003, P NATL ACAD SCI USA, V100, P9608, DOI 10.1073/pnas.1632587100; Hong HX, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S2-S5; Izmirlian G, 2004, ANN NY ACAD SCI, V1020, P154, DOI 10.1196/annals.1310.015; Jeffries N, 2005, BIOINFORMATICS, V21, P3066, DOI 10.1093/bioinformatics/bti482; Kettapeh-Wold S., 1999, INTRO MULTI MEGAVARI, P490; KLEIN B, 1995, SEMIN HEMATOL, V32, P4; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; Lee KR, 2003, PROTEOMICS, V3, P1680, DOI 10.1002/pmic.200300515; Li JN, 2002, CLIN CHEM, V48, P1296; Lundquist M, 2005, FEMS MICROBIOL LETT, V243, P303, DOI 10.1016/j.femsle.2004.12.020; Merchant M, 2000, ELECTROPHORESIS, V21, P1164, DOI 10.1002/(SICI)1522-2683(20000401)21:6<1164::AID-ELPS1164>3.3.CO;2-S; Mundy GR, 1998, EUR J CANCER, V34, P246, DOI 10.1016/S0959-8049(97)10133-2; Musumarra G, 2003, BIOL CHEM, V384, P321, DOI 10.1515/BC.2003.037; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Nguyen DV, 2002, BIOINFORMATICS, V18, P1216, DOI 10.1093/bioinformatics/18.9.1216; Oken MM, 1997, CANCER INVEST, V15, P57, DOI 10.3109/07357909709018918; Papadopoulos MC, 2004, LANCET, V363, P1358, DOI 10.1016/S0140-6736(04)16046-7; Paweletz CP, 2001, DIS MARKERS, V17, P301; Petricoin EF, 2003, CLIN CHEM, V49, P533, DOI 10.1373/49.4.533; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; Roodman GD, 2001, J CLIN ONCOL, V19, P3562; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tang N, 2004, MASS SPECTROM REV, V23, P34, DOI 10.1002/mas.10066; TAUBE T, 1992, EUR J HAEMATOL, V49, P192; Tian E, 2003, NEW ENGL J MED, V349, P2483, DOI 10.1056/NEJMoa030847; Westfall Peter H., 1993, RESAMPLING BASED MUL; Wold H., 1966, MULTIVARIATE ANAL, P391; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Wulfkuhle JD, 2003, NAT REV CANCER, V3, P267, DOI 10.1038/nrc.1043	43	17	19	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0278-0240			DIS MARKERS	Dis. Markers		2006	22	4					245	255				11	Biotechnology & Applied Microbiology; Genetics & Heredity; Medicine, Research & Experimental; Pathology	Biotechnology & Applied Microbiology; Genetics & Heredity; Research & Experimental Medicine; Pathology	167SR	WOS:000246472100008	17124346	
S	Cutler, A; Stevens, JR		Kimmel, A; Oluver, B		Cutler, Adele; Stevens, John R.			Random forests for microarrays	DNA MICROARRAYS, PART B: DATABASES AND STATISTICS	Methods in Enzymology		English	Review; Book Chapter							GENE-EXPRESSION DATA; CLASSIFICATION	Random Forests is a powerful multipurpose tool for predicting and understanding data. If gene expression data come from known groups or classes (e.g., tumor patients and controls), Random Forests can rank the genes in terms of their usefulness in separating the groups. When the groups are unknown, Random Forests uses an intrinsic measure of the similarity of the genes to extract useful multivariate structure, including clusters. This chapter summarizes the Random Forests methodology and illustrates its use on freely available data sets.	Utah State Univ, Dept Math & Stat, Logan, UT 84322 USA	Cutler, A (reprint author), Utah State Univ, Dept Math & Stat, Logan, UT 84322 USA.						Ayroles JF, 2006, METHOD ENZYMOL, V411, P214, DOI 10.1016/S0076-6879(06)11011-3; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cox T. F., 2001, MULTIDIMENSIONAL SCA, V2nd; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Gollub J, 2006, METHOD ENZYMOL, V411, P194, DOI 10.1016/S0076-6879(06)11010-1; Hastie T., 2001, ELEMENTS STAT LEARNI; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; R Development Core Team, 2004, R LANG ENV STAT COMP; Rousseauw J., 1983, S AFR MED J, V64, P430; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498	16	22	22	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA	0076-6879		978-0-12-182816-5	METHOD ENZYMOL	Methods Enzymol.		2006	411						422	+		10.1016/S0076-6879(06)11023-X		13	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	BFT40	WOS:000244506300023	16939804	
J	Bunn, AG; Goetz, SJ				Bunn, Andrew G.; Goetz, Scott J.			Trends in satellite-observed circumpolar photosynthetic activity from 1982 to 2003: The influence of seasonality, cover type, and vegetation density	EARTH INTERACTIONS			English	Article						global change; boreal; remote sensing	NET PRIMARY PRODUCTION; LIGHT-USE EFFICIENCY; LEAF-AREA INDEX; CARBON-CYCLE; PHYTOMASS PRODUCTION; HIGH-LATITUDES; ARCTIC TUNDRA; WHITE SPRUCE; PLANT-GROWTH; AVHRR DATA	Time series analyses of a 22-yr record of satellite observations the northern circumpolar high latitudes were conducted, and trends in photosynthetic activity were assessed using a series of statistical The results indicate that most of the northern circumpolar high latitudes 85%) showed no significant trend in vegetation activity despite systematic warming during the period of analysis. Of the areas that did change, showed the expected trends in "greening" of vegetation activity. There however, significant differences in the magnitude and even in the direction of trends when stratified by vegetation type and density. Tundra areas and predominantly showed greening trends. Forested areas showed in activity ("browning") in many areas, and these were systematically in areas with denser tree cover - whether deciduous or evergreen, or broad-leafed. The seasonality of the trends was also distinct between vegetation types, with a divergence in trends between late spring and early summer (positive) versus late summer (negative) portions of the growing seasons in forested areas. In contrast, tundra and other predominantly herbaceous areas showed positive trends in all portions of the growing season. These results confirm recent findings across the high latitudes of North America and are supported by an increasing array of in situ measurements. They indicate that the boreal forest biome might be responding to climate change in previously unexpected ways, and point to a need for an expanded observational network, additional analysis of existing datasets ( e. g., tree rings), and improvements in process models of ecosystem responses to climate change.	Woods Hole Res Ctr, Falmouth, MA 02540 USA	Bunn, AG (reprint author), Woods Hole Res Ctr, 149 Woods Hole Rd, Falmouth, MA 02540 USA.	abunn@whrc.org					Achard F., 2005, IDENTIFICATION HOT S; ACIA, 2004, IMP WARM ARCT ARCT C; Aksenov D., 2002, ATLAS RUSSIAS INTACT; Angert A, 2005, P NATL ACAD SCI USA, V102, P10823, DOI 10.1073/pnas.0501647102; ASRAR G, 1984, AGRON J, V76, P300; ASRAR G, 1985, REMOTE SENS ENVIRON, V17, P211, DOI 10.1016/0034-4257(85)90095-1; Barber VA, 2000, NATURE, V405, P668, DOI 10.1038/35015049; Bartalev SA, 2003, INT J REMOTE SENS, V24, P1977, DOI 10.1080/0143116031000066297; BONAN GB, 1992, NATURE, V359, P716, DOI 10.1038/359716a0; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown M., 2004, EOS T, V85, P565, DOI DOI 10.1029/2004EO520003; Brown RD, 2000, J CLIMATE, V13, P2339, DOI 10.1175/1520-0442(2000)013<2339:NHSCVA>2.0.CO;2; Bunn AG, 2005, GEOPHYS RES LETT, V32, DOI 10.1029/2005GL023646; Chapin FS, 2005, SCIENCE, V310, P657, DOI 10.1126/science.1117368; CHAPMAN WL, 1993, B AM METEOROL SOC, V74, P33, DOI 10.1175/1520-0477(1993)074<0033:RVOSIA>2.0.CO;2; Cox PM, 2000, NATURE, V408, P184, DOI 10.1038/35041539; Dai A, 2004, J HYDROMETEOROL, V5, P1117, DOI 10.1175/JHM-386.1; DAUGHTRY CST, 1992, REMOTE SENS ENVIRON, V39, P141, DOI 10.1016/0034-4257(92)90132-4; Defries RS, 2000, INT J REMOTE SENS, V21, P1389, DOI 10.1080/014311600210236; Delbart N, 2005, REMOTE SENS ENVIRON, V97, P26, DOI 10.1016/j.rse.2005.03.011; DICKEY DA, 1981, ECONOMETRICA, V49, P1057, DOI 10.2307/1912517; Dufresne JL, 2002, GEOPHYS RES LETT, V29, DOI 10.1029/2001GL013777; Easterling DR, 2000, J GEOPHYS RES-ATMOS, V105, P20101, DOI 10.1029/2000JD900166; Field CB, 1991, RESPONSE PLANTS MULT, P35; Fomby TB, 2002, J CLIMATE, V15, P117, DOI 10.1175/1520-0442(2002)015<0117:TAOSRT>2.0.CO;2; Giri C, 2005, REMOTE SENS ENVIRON, V94, P123, DOI 10.1016/j.rse.2004.09.005; Goel N.S., 1994, REMOTE SENS REV, V10, P309, DOI DOI 10.1080/02757259409532252; Goetz SJ, 1998, CAN J FOREST RES, V28, P375, DOI 10.1139/cjfr-28-3-375; Goetz SJ, 1999, ADV ECOL RES, V28, P57, DOI 10.1016/S0065-2504(08)60029-X; Goetz SJ, 2005, P NATL ACAD SCI USA, V102, P13521, DOI 10.1073/pnas.0506179102; GORHAM E, 1991, ECOL APPL, V1, P182, DOI 10.2307/1941811; Hansen J, 2005, SCIENCE, V308, P1431, DOI 10.1126/science.1110252; Hansen MC, 2002, REMOTE SENS ENVIRON, V83, P320, DOI 10.1016/S0034-4257(02)00080-9; Hansen MC, 2005, INT J REMOTE SENS, V26, P4359, DOI 10.1080/01431160500113435; Hansen MC, 2002, REMOTE SENS ENVIRON, V83, P303, DOI 10.1016/S0034-4257(02)00079-2; Hintze JL, 1998, AM STAT, V52, P181, DOI 10.2307/2685478; Jarvis PG, 1997, J GEOPHYS RES-ATMOS, V102, P28953, DOI 10.1029/97JD01176; Kaufmann RK, 2004, GEOPHYS RES LETT, V31, DOI 10.1029/2004GL019608; Keeling CD, 1996, NATURE, V382, P146, DOI 10.1038/382146a0; Lapenis A, 2005, GLOBAL CHANGE BIOL, V11, P2090, DOI 10.1111/j.1365-2486.2005.01069.x; Latifovic R, 2004, REMOTE SENS ENVIRON, V89, P116, DOI 10.1016/j.rse.2003.11.002; Lawrence R, 2004, REMOTE SENS ENVIRON, V90, P331, DOI 10.1016/j.rse.2004.01.007; Lawrence RL, 2006, REMOTE SENS ENVIRON, V100, P356, DOI 10.1016/j.rse.2005.10.014; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lloyd AH, 2002, CLIMATIC CHANGE, V52, P481, DOI 10.1023/A:1014278819094; Lloyd AH, 2005, ECOLOGY, V86, P1687, DOI 10.1890/03-0786; Mouillot F, 2005, GLOBAL CHANGE BIOL, V11, P398, DOI 10.1111/j.1365-2486.2005.00920.x; Myneni RB, 1997, NATURE, V386, P698, DOI 10.1038/386698a0; MYNENI RB, 1995, IEEE T GEOSCI REMOTE, V33, P481, DOI 10.1109/36.377948; Nemani RR, 2003, SCIENCE, V300, P1560, DOI 10.1126/science.1082750; NIKOLAUK VA, 1973, ATLAS FORESTRY USSR; Overpeck J, 1997, SCIENCE, V278, P1251, DOI 10.1126/science.278.5341.1251; R Development Core Team, 2005, R LANG ENV STAT COMP; RICHARDSON AJ, 1977, PHOTOGRAMM ENG REM S, V43, P1541; Ryan MG, 1997, J GEOPHYS RES-ATMOS, V102, P28871, DOI 10.1029/97JD01236; Scott D.W., 1992, MULTIVARIATE DENSITY; SELLERS PJ, 1987, REMOTE SENS ENVIRON, V21, P143, DOI 10.1016/0034-4257(87)90051-4; Serreze MC, 2000, CLIMATIC CHANGE, V46, P159, DOI 10.1023/A:1005504031923; Siegel S, 1988, NONPARAMETRIC STAT; Slayback DA, 2003, GLOBAL CHANGE BIOL, V9, P1, DOI 10.1046/j.1365-2486.2003.00507.x; Small J, 2003, P NATL ACAD SCI USA, V100, P15341, DOI 10.1073/pnas.2236969100; SPANNER MA, 1990, REMOTE SENS ENVIRON, V33, P97, DOI 10.1016/0034-4257(90)90036-L; STEINBERG DC, 2006, IN PRESS IEEE T GEOS; Sturm M, 2001, J CLIMATE, V14, P336, DOI 10.1175/1520-0442(2001)014<0336:SSIIAT>2.0.CO;2; Sturm M, 2005, BIOSCIENCE, V55, P17, DOI 10.1641/0006-3568(2005)055[0017:WBPCHC]2.0.CO;2; Sukhinin AI, 2004, REMOTE SENS ENVIRON, V93, P546, DOI 10.1016/j.rse.2004.08.011; TUCKER CJ, 1981, REMOTE SENS ENVIRON, V11, P171, DOI 10.1016/0034-4257(81)90018-3; TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0; Tucker CJ, 2005, INT J REMOTE SENS, V26, P4485, DOI 10.1080/01431160500168686; Turner DP, 2003, GLOBAL CHANGE BIOL, V9, P383, DOI 10.1046/j.1365-2486.2003.00573.x; Vogelsang TJ, 1998, ECONOMETRICA, V66, P123, DOI 10.2307/2998543; Wilmking M, 2004, GLOBAL CHANGE BIOL, V10, P1724, DOI 10.1111/j.1365-2486.2004.00826.x; Yoshikawa K, 2003, PERMAFROST PERIGLAC, V14, P151, DOI 10.1002/ppp.451; Zhou LM, 2001, J GEOPHYS RES-ATMOS, V106, P20069, DOI 10.1029/2000JD000115	75	11	11	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	1087-3562			EARTH INTERACT	Earth Interact.		2006	10								12			19	Geosciences, Multidisciplinary	Geology	096XJ	WOS:000241409800001		
S	Rodriguez, JJ; Maudes, JM		Brewka, G; Coraeschi, S; Perini, A; Traverso, P		Rodriguez, Juan J.; Maudes, Jesus M.			Ensembles of Grafted Trees	ECAI 2006, PROCEEDINGS	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	17th European Conference on Artificial Intelligence	AUG 28, 2006	Riva del Garda, ITALY					Grafted trees are trees that are constructed using two methods. The first method creates an initial tree, while the second method is used to complete the tree. In this work, the first classifier is an unpruned tree from a 10% sample of the training data. Grafting is a method for constructing ensembles of decision trees, where each tree is a grafted tree. Grafting by itself is better than Bagging. Moreover, grafted trees can also be used with any other ensemble method. It is clearly beneficial for Bagging and Random Forests. When using grafted trees with Boosting, the results depends of the considered variant. The best overall method is Grafted Random Forest.	[Rodriguez, Juan J.; Maudes, Jesus M.] Univ Burgos, Burgos, Spain	Rodriguez, JJ (reprint author), Univ Burgos, Burgos, Spain.	jjrodriguez@ubu.es; jmaudes@ubu.es	Rodriguez, Juan/B-1014-2008	Rodriguez, Juan/0000-0002-3291-2739			Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Frank E., 2005, DATA MINING PRACTICA; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kuncheva L., 2004, COMBINING PATTERN CL; Li JY, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P585; NADEAU C, 2003, MACHINE LEARNING, V52; Schapire R., 2002, MSRI WORKSH NONL EST; WEBB GI, 1999, 16 INT JOINT C ART I	13	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		978-1-58603-642-3	FR ART INT			2006	141						803	804				2	Computer Science, Artificial Intelligence	Computer Science	BMY20	WOS:000273875100182		
J	Wahde, M; Szallasi, Z				Wahde, M; Szallasi, Z			A survey of methods for classification of gene expression data using evolutionary algorithms	EXPERT REVIEW OF MOLECULAR DIAGNOSTICS			English	Review						cancer; data classification; evolutionary algorithms; gene expression	SUPPORT VECTOR MACHINES; B-CELL LYMPHOMA; MICROARRAY DATA; MOLECULAR CLASSIFICATION; OLIGONUCLEOTIDE ARRAYS; SAMPLE CLASSIFICATION; SYSTEMATIC VARIATION; BREAST-CANCER; PREDICTION; CDNA	The rapid increase in the quantity of available biologic data over the last decade, brought about by the introduction of massively parallel methods for gene expression measurements, has highlighted the need for more efficient computational techniques for analysis. This paper reviews the use of evolutionary algorithms (EAs) in connection with classification based on gene expression data matrices. Brief introductions to data classification methods and EAs are given, followed by a survey of studies dealing with the application of evolutionary algorithms to various (cancer related) data sets. The general conclusion, based on the published results surveyed here, is that EAs may constitute an efficient method for optimal gene selection, and can also help in reducing the size (number of features used) of classifiers. In many cases, the classification accuracy obtained using EAs, often in conjunction with other methods, represents a significant improvement over results obtained without the use of EAs. However, long-term, independent clinical follow-up studies will be essential to validate prognostic markers identified by the use of EA-based methods.	Chalmers, Dept Appl Mech, SE-41296 Gothenburg, Sweden	Wahde, M (reprint author), Chalmers, Dept Appl Mech, SE-41296 Gothenburg, Sweden.	mattias.wahde@chalmers.se; zszallasi@chip.org					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; BACK T, 1998, HDB EOVLUTIONARY COM; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Churchill GA, 2002, NAT GENET, V32, P490, DOI 10.1038/ng1031; Deb K, 2003, BIOSYSTEMS, V72, P111, DOI 10.1016/S0303-2647(03)00138-2; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; DRAGHICI S, 2006, IN PRESS TRENDS GENE; Eilers P. H. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4266, DOI 10.1117/12.427987; Fogel G. B., 2003, EVOLUTIONARY COMPUTA; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HASTIE T, 2001, ELEMENTS STAT LEARNI, V14; Haykin S., 1999, NEURAL NETWORKS COMP; Hoffmann R, 2002, GENOME BIOL, V3, DOI 10.1186/gb-2002-3-7-research0033; HOLLAND JH, 1975, ADAPTATION NATURAL A; Holland MJ, 2002, J BIOL CHEM, V277, P14363, DOI 10.1074/jbc.C200101200; Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lee JK, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-12-r82; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; LI L, 2000, P 1 C CRIT ASS MICR, pA6061; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Lin T. S., 2005, P 3 AS PAC BIOINF C, P229, DOI 10.1142/9781860947322_0023; Liu J, 2001, Genome Inform, V12, P14; Liu JJ, 2005, BIOINFORMATICS, V21, P2691, DOI 10.1093/bioinformatics/bti419; LIVINGSTON G, 2003, 20 INT C MACH LEARN; Mecham BH, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh071; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Mitchell M., 1996, INTRO GENETIC ALGORI; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; Peng SH, 2003, FEBS LETT, V555, P358, DOI 10.1016/S0014-5793(03)01275-4; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Ramoni MF, 2002, P NATL ACAD SCI USA, V99, P9121, DOI 10.1073/pnas.132656399; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Rousseeuw P. J., 1990, FINDING GROUPS DATA; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Smyth Gordon K, 2003, Methods Mol Biol, V224, P111; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Speed T, 2003, STAT ANAL GENE EXPRE; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Stoughton RB, 2005, ANNU REV BIOCHEM, V74, P53, DOI 10.1146/annurev.biochem.74.082803.133212; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1998, STAT LEARNING THEORY; WAHDE M, 2001, FDN SYSTEMS BIOL; WAHDE M, 2005, SOFT COMPUTING; Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15; Yang YH, 2002, NAT REV GENET, V3, P579; Zhang JH, 2005, GENOMICS, V85, P297, DOI 10.1016/j.ygeno.2004.11.004	55	9	9	FUTURE DRUGS LTD	LONDON	UNITEC HOUSE, 3RD FL, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON N3 1QB, ENGLAND	1473-7159			EXPERT REV MOL DIAGN	Expert Rev. Mol. Diagn.	JAN	2006	6	1					101	110		10.1586/14737159.6.1.101		10	Pathology	Pathology	003ZO	WOS:000234722000012	16359271	
B	Zhang, J; Zulkernine, M			IEEE Comp Soc	Zhang, Jiong; Zulkernine, Mohammad			A hybrid network intrusion detection technique using random forests	First International Conference on Availability, Reliability and Security, Proceedings			English	Proceedings Paper	1st International Conference on Availability, Reliability and Security	APR 20-22, 2006	Vienna, AUSTRIA	European Network & Informat Secur Agcy, Tech Univ Wien, Vienna Univ Techol, Oesterreich Comp Gesell, Austrian Comp Soc	Vienna Univ Technol	intrusion detection; data mining; random forests; network security; hybrid detection		Intrusion detection is important in network security. Most current network intrusion detection systems (NIDSs) employ either misuse detection or anomaly detection. However, misuse detection cannot detect unknown intrusions, and anomaly detection usually has high false positive rate. To overcome the limitations of both techniques, we incorporate both anomaly and misuse detection into the NIDS. In this paper, we present our framework of the hybrid system. The system combines the misuse detection and anomaly detection components in which the random forests algorithm is applied. We discuss the advantages of the framework and also report our experimental results over the KDD'99 dataset. The results show that the proposed approach can improve the detection performance of the NIDSs, where only anomaly or misuse detection technique is used.	Queens Univ, Sch Comp, Kingston, ON K7L 3N6, Canada	Zhang, J (reprint author), Queens Univ, Sch Comp, Kingston, ON K7L 3N6, Canada.						Anderson D., 1995, SRICSL9507; Barbara D, 2001, P 2001 IEEE WORKSH I; Breiman L., RANDOM FORESTS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Elkan C., 2000, SIGKDD EXPLORATIONS, V1, P63; Endorf C., 2004, INTRUSION DETECTION; Eskin Eleazar, 2002, APPL DATA MINING COM; Guo L., 2004, P 15 INT S SOFTW REL, P417, DOI DOI 10.1109/ISSRE.2004.35; Lee W., 2000, ACM T INFORM SYSTEM, V3; LEUNG K, 2005, AUSTR COMP SCI C NEW; Mahoney M., 2003, P REC ADV INTR DET R; MIT Lincoln Laboratory, DARPA INTR DET EV; POPESCU BE, 2004, THESIS STANFORD U; TOMBINI E, 2004, 20 ANN COMP SEC APPL; *U WAIK, WEKA SOFTW MACH LEAR; Wu T.F., 2004, J MACHINE LEARNING R, V5; WU YM, 2004, THESIS STATE U NY; ZHANG J, 2006, 2006 IEEE INT C COMM; Zhang J., 2005, P 3 ANN C PRIV SEC T, P53; 1999, KDD 99 DATASETS UCI	20	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2567-9				2006							262	269				8	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEL18	WOS:000237699600034		
S	Thomas, J; Jouve, PE; Nicoloyannis, N		Esposito, F; Ras, ZW; Malerba, D; Semeraro, G		Thomas, Julien; Jouve, Pierre-Emmanuel; Nicoloyannis, Nicolas			Optimisation and evaluation of random forests for imbalanced datasets	FOUNDATIONS OF INTELLIGENT SYSTEMS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th International Symposium on Methodologies for Intelligent Systems	SEP 27-29, 2006	Bari, ITALY	Univ Bari, Dept Comp Sci, Univ Studi Bari, Dipartimento Informat				This paper deals with an optimization of Random Forests which aims at: adapting the concept of forest for learning imbalanced data as well as taking into account user's wishes as far as recall and precision rates are concerned. We propose to adapt Random Forest on two levels. First of all, during the forest creation thanks to the use of asymmetric entropy measure associated to specific leaf class assignation rules. Then, during the voting step, by using an alternative strategy to the classical majority voting strategy. The automation of this second step requires a specific methodology for results quality assessment. This methodology allows the user to define his wishes concerning (1) recall and precision rates for each class of the concept to learn, and, (2) the importance he wants to confer to each one of those classes. Finally, results of experimental evaluations are presented.	Univ Lyon 2, Lab ERIC, F-69365 Lyon 07, France; Co Fenics, Lyon, France	Thomas, J (reprint author), Univ Lyon 2, Lab ERIC, F-69365 Lyon 07, France.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHAN PK, 2001, P 4 INT C KNOWL DISC, P164; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Chen C., 2004, USING RANDOM FOREST; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Grzymala-Busse W.J., 2000, AAAI WORKSH 17 C AI, P69; HETTICH S, 1999, UCI KDD ARCHIVE; JAPKOWICZ N, 2000, P INT C ART INT; KAVSEK B, 2004, EUROPEAN C ARTIFICIA; Kirkpatrick S., 1983, SCIENCE, V220, P4598; Leon F., 2004, P 8 INT S AUT CONTR; MARCELLIN S, 2006, IPMU 06; Pazzani M., 1994, P 11 INT C MACH LEAR; Weiss G. M., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Weiss G.M., 2004, SIGKDD EXPLORATIONS, V6, P7, DOI DOI 10.1145/1007730.1007734	15	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-45764-X	LECT NOTES ARTIF INT			2006	4203						622	631				10	Computer Science, Artificial Intelligence	Computer Science	BFF98	WOS:000241647800069		
S	Gatnar, E		Spiliopoulou, M; Kruse, R; Borgelt, C; Nurnberger, A; Gaul, W		Gatnar, E			A wrapper feature selection method for combined tree-based classifiers	FROM DATA AND INFORMATION ANALYSIS TO KNOWLEDGE ENGINEERING	Studies in Classification Data Analysis and Knowledge Organization		English	Proceedings Paper	29th Annual Conference of the German-Classification-Society	MAR 09-11, 2005	Magdeburg, GERMANY	German Classificat Soc	Otto Guericke Univ Magdeburg			The aim of feature selection is to find the subset of features that maximizes the classifier performance. Recently, we have proposed a correlation-based feature selection method for the classifier ensembles based on Hellwig heuristic (CFSH). In this paper we show that further improvement of the ensemble accuracy can be achieved by combining the CFSH method with the wrapper approach.	Katowice Univ Econ, Inst Stat, PL-40226 Katowice, Poland	Gatnar, E (reprint author), Katowice Univ Econ, Inst Stat, Ul Bogucicka 14, PL-40226 Katowice, Poland.						AMIT Y, 2001, MULTIPLE RANDOMIZED; Blake C. L., 1998, UCI REPOSITORY MACHI; BREIMAN L, 1999, 547 U CAL DEP STAT; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GATNAR E, 2005, DATA ANAL DECISION S, P30, DOI 10.1007/3-540-28397-8_4; Gatnar E, 2005, ST CLASS DAT ANAL, P129, DOI 10.1007/3-540-28084-7_12; Ginsberg M, 1993, ESSENTIALS ARTIFICIA; HELLWIG Z, 1969, STAT REV, V3; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; KIRA A, 1992, P 9 INT WORKSH MACH, P249; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; Singh M, 1995, P 12 INT C MACH LEAR, P497; Therneau TM, 1997, INTRO RECURSIVE PART; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; WALESIAK M, 1987, STAT REV, V1, P37; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	23	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-31313-3	STUD CLASS DATA ANAL			2006							119	125		10.1007/3-540-31314-1_13		7	Computer Science, Artificial Intelligence	Computer Science	BED68	WOS:000236886800013		
S	Mullensiefen, D; Hermig, C		Spiliopoulou, M; Kruse, R; Borgelt, C; Nurnberger, A; Gaul, W		Mullensiefen, D; Hermig, C			Modeling memory for melodies	From Data and Information Analysis to Knowledge Engineering	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	29th Annual Conference of the German-Classification-Society	MAR 09-11, 2005	Magdeburg, GERMANY	German Classificat Soc	Otto Guericke Univ Magdeburg			The aim of the presented study was to find structural descriptions of melodies that influence recognition memory for melodies. 24 melodies were played twice to 42 test persons. In the second turn, some of the melodies were changed, and the subjects were asked whether they think that the melody has been exactly the same as in -the first turn or not. The variables used to predict the subject judgments comprise data about the subjects' musical experience, features of the original melody and its position in the music piece, and informations about the change between the first and the second turn. Classification and regression methods have been carried out and tested on a subsample. The prediction problem turned out to be difficult. The results seem to be influenced strongly by differences between the subjects and between the melodies that had not been recorded among the regressor variables.	Univ Hamburg, Musikwissensch Inst, D-20354 Hamburg, Germany	Mullensiefen, D (reprint author), Univ Hamburg, Musikwissensch Inst, D-20354 Hamburg, Germany.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DOWLING W. J., 2002, MUSIC PERCEPT, V19, P249; DOWLING WJ, 1995, PERCEPT PSYCHOPHYS, V57, P136, DOI 10.3758/BF03206500; EITING MH, 1984, MUSIC PERCEPT, V2, P78; Frieler K., 2004, COMPUTING MUSICOLOGY, V13, P147; Harrell FE, 2001, REGRESSION MODELING; MULLENSIEFEN D, 2004, THESIS U HAMBURG; TAYLOR JA, 1984, PSYCHOMUSICOLOGY, V3, P16; VERWEIJ PJM, 1994, STAT MED, V13, P2427, DOI 10.1002/sim.4780132307	9	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-31313-3	ST CLASS DAT ANAL			2006							732	739		10.1007/3-540-31314-1_90		8	Computer Science, Artificial Intelligence	Computer Science	BED68	WOS:000236886800090		
S	Kim, DS; Lee, SM; Park, JS		Min, G; DiMartino, B; Yang, LT; Guo, M; Ruenger, G		Kim, Dong Seong; Lee, Sang Min; Park, Jong Son			Toward lightweight Intrusion Detection System through Simultaneous Intrinsic Model Identification	Frontiers of High Performance Computing and Networking - ISPA 2006 Workshops, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	ISPA 2006 International Workshops FHPCN, XHPC, S-GRACE, GridGIS, HPC-GTP, PDCE, ParDMCom, WOMP, ISDF, and UPWN	DEC 04-07, 2006	Sorrento, ITALY			Intrusion Detection System; data mining; Random Forest		Intrusion Detection System (IDS) should guarantee high detection rates with minimum overheads to figure out intrusion detection model and process audit data. The previous approaches have mainly focused on feature selection of audit data and parameters optimization of intrusion detection models. However, feature selection and parameters optimization have been performed in separate way. Several hybrid approaches based on soft computing techniques are able to perform both of them together but they have more computational overheads. In this paper, we propose a new approach named Simultaneous Intrinsic Model Identification (SIMI), which enable one to perform both feature selection and parameters optimization together without any additional computational overheads. SIMI adopts Random Forest (RF) which is a promising machine learning algorithm and has been shown similar or better classification rates compared to Support Vector Machines (SVM). SIMI is able to model lightweight intrinsic intrusion detection model with optimized parameters and features. After determination of the intrinsic intrusion detection model, we visualize normal and attack patterns in 2 dimensional space using Multidimensional Scaling (MDS). We carry out several experiments on KDD 1999 intrusion detection dataset and validate the feasibility of our approach.	Hankuk Aviat Univ, Network Secur Lab, Seoul, South Korea	Kim, DS (reprint author), Hankuk Aviat Univ, Network Secur Lab, Seoul, South Korea.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dash M., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183893; Hall M.A., 1997, P 4 INT C NEUR INF P, P855; Johnson PRE, 1997, BRIT J HAEMATOL, V97, P1, DOI 10.1046/j.1365-2141.1997.00984.x; Kim DS, 2005, LECT NOTES COMPUT SC, V3498, P415; Kim DS, 2003, LECT NOTES COMPUT SC, V2662, P747; MIDDLEMISS M, 2003, 3 INT C HYBR INT SYS; Moradi M., 2004, P IEEE INT C ADV INT; MUKKAMALA S, 2005, P INT C AD NAT COMP, P458; NOELIA SM, NEW WRAPPER METHOD F; Park JS, 2005, LECT NOTES COMPUT SC, V3822, P279; RYLANDER B, 2001, THESIS U IDAHO; SABHNANI M, 2004, FAILURE MACHINE LEAR; Sung A. H., 2003, Proceedings 2003 Symposium on Applications and the Internet, DOI 10.1109/SAINT.2003.1183050; Young F. W., 1994, THEORY APPL MULTIDIM; Zhang J., 2005, P 3 ANN C PRIV SEC T	16	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-49860-5	LECT NOTES COMPUT SC			2006	4331						981	989				9	Computer Science, Theory & Methods	Computer Science	BFT38	WOS:000244504200100		
J	Moon, H; Ahn, H; Kodell, RL; Lin, CJ; Baek, S; Chen, JJ				Moon, Hojin; Ahn, Hongshik; Kodell, Ralph L.; Lin, Chien-Ju; Baek, Songjoon; Chen, James J.			Classification methods for the development of genomic signatures from high-dimensional data	GENOME BIOLOGY			English	Article							GENE-EXPRESSION DATA; BREAST-CANCER; CLASS DISCOVERY; PREDICTION; TREES	Personalized medicine is defined by the use of genomic signatures of patients to assign effective therapies. We present Classification by Ensembles from Random Partitions ( CERP) for class prediction and apply CERP to genomic data on leukemia patients and to genomic data with several clinical variables on breast cancer patients. CERP performs consistently well compared to the other classification algorithms. The predictive accuracy can be improved by adding some relevant clinical/histopathological measurements to the genomic data.	Natl Ctr Toxicol Res, Div Biometry & Risk Assessment, FDA, Jefferson, AR 72079 USA; SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA	Moon, H (reprint author), Natl Ctr Toxicol Res, Div Biometry & Risk Assessment, FDA, NCTR Rd, Jefferson, AR 72079 USA.	hojin.moon@fda.hhs.gov					AHN H, 2006, SUNYSBAMS0603 DEP AP; Ahn H, 1997, BIOMETRICS, V53, P435, DOI 10.2307/2533948; Ahn H., 1995, J COMPUTATIONAL GRAP, V4, P55, DOI 10.2307/1390627; Alexandridis R, 2004, BIOINFORMATICS, V20, P2545, DOI 10.1093/bioinformatics/bth281; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Early Breast Cancer Trialists' Collaborative Group, 1996, LANCET, V352, P930; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; Kuncheva LI, 2003, PATTERN ANAL APPL, V6, P22, DOI 10.1007/s10044-002-0173-7; Loh WY, 1997, STAT SINICA, V7, P815; MCGUIRE WL, 1991, J NATL CANCER I, V83, P154, DOI 10.1093/jnci/83.3.154; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik VN, 1995, NATURE STAT LEARNING; WILLIAMS DA, 1975, BIOMETRICS, V31, P949, DOI 10.2307/2529820; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	22	9	9	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1474-760X			GENOME BIOL	Genome Biol.		2006	7	12							R121	10.1186/gb-2006-7-12-r121		7	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	132UG	WOS:000243967100015	17181863	
J	Steffens, M; Lamina, C; Illig, T; Bettecken, T; Vogler, R; Entz, P; Suk, EK; Toliat, MR; Klopp, N; Caliebe, A; Konig, IR; Kohler, K; Ludemann, J; Lacava, AD; Fimmers, R; Lichtner, P; Ziegler, A; Wolf, A; Krawczak, M; Nurnberg, P; Hampe, J; Schreiber, S; Meitinger, T; Wichmann, HE; Roeder, K; Wienker, TF; Baur, MP				Steffens, Michael; Lamina, Claudia; Illig, Thomas; Bettecken, Thomas; Vogler, Rainer; Entz, Patricia; Suk, Eun-Kyung; Toliat, Mohammad Reza; Klopp, Norman; Caliebe, Amke; Koenig, Inke R.; Koehler, Karola; Luedemann, Jan; Lacava, Amalia Diaz; Fimmers, Rolf; Lichtner, Peter; Ziegler, Andreas; Wolf, Andreas; Krawczak, Michael; Nuernberg, Peter; Hampe, Jochen; Schreiber, Stefan; Meitinger, Thomas; Wichmann, H. -Erich; Roeder, Kathryn; Wienker, Thomas F.; Baur, Max P.			SNP-based analysis of genetic substructure in the German population	HUMAN HEREDITY			English	Article						German population; genetic substructure; F-statistics; genomic control	GENOMIC CONTROL; ASSOCIATION; STRATIFICATION; DIVERSITY; MARKERS; POLYMORPHISMS; INFERENCE; IMPACT; DETECT; CANCER	Objective: To evaluate the relevance and necessity to account for the effects of population substructure on association studies under a case-control design in central Europe, we analysed three samples drawn from different geographic areas of Germany. Two of the three samples, POPGEN (n = 720) and SHIP (n = 709), are from north and north-east Germany, respectively, and one sample, KORA (n = 730), is from southern Germany. Methods: Population genetic differentiation was measured by classical F-statistics for different marker sets, either consisting of genome-wide selected coding SNPs located in functional genes, or consisting of selectively neutral SNPs from 'genomic deserts'. Quantitative estimates of the degree of stratification were performed comparing the genomic control approach [Devlin B, Roeder K: Biometrics 1999;55:997-1004], structured association [Pritchard JK, Stephens M, Donnelly P: Genetics 2000;155:945959] and sophisticated methods like random forests [Breiman L: Machine Learning 2001;45:5-32]. Results: F-statistics showed that there exists a low genetic differentiation between the samples along a north-south gradient within Germany (F-ST(KORA/POPGEN): 1.7 . 10(-4); F-ST(KORA/SHIP): 5.4 . 10(-4); F-ST(POPGEN/SHIP): -1.3 . 10(-5)). Conclusion: Although the F-ST-values are very small, indicating a minor degree of population structure, and are too low to be detectable from methods without using prior information of subpopulation membership, such as STRUCTURE [Pritchard JK, Stephens M, Donnelly P: Genetics 2000;155:945-959], they may be a possible source for confounding due to population stratification. Copyright (c) 2006 S. Karger AG, Basel.	Univ Bonn, Inst Med Biometry Informat & Epidemiol, DE-53105 Bonn, Germany; Tech Univ Munich, Inst Epidemiol, GSF, Natl Res Ctr, D-8000 Munich, Germany; Tech Univ Munich, Inst Human Genet, D-8000 Munich, Germany; GSF, Natl Res Ctr, Inst Human Genet, Munich, Germany; Univ Kiel, Dept Gen Internal Med, Kiel, Germany; Max Delbruck Ctr, Gene Mapping Ctr, Berlin, Germany; Univ Kiel, Inst Med Stat & Informat, Kiel, Germany; Med Univ Lubeck, Inst Med Biometry & Stat, D-23538 Lubeck, Germany; Univ Gottingen, Dept Genet Epidemiol, D-3400 Gottingen, Germany; Univ Greifswald, Inst Clin Chem & Lab Med, Greifswald, Germany; Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA	Steffens, M (reprint author), Univ Bonn, Inst Med Biometry Informat & Epidemiol, Sigmund Freud Str 25, DE-53105 Bonn, Germany.	steffens@imbie.meb.uni-bonn.de	Schreiber, Stefan/B-6748-2008; Hampe, Jochen/A-2555-2010; Konig, Inke/A-4544-2009; Krawczak, Michael/A-8964-2010; Ziegler, Andreas/G-4246-2012; Lamina, Claudia/F-7608-2010; Ziegler, Andreas/	Schreiber, Stefan/0000-0003-2254-7771; Hampe, Jochen/0000-0002-2421-6127; Ziegler, Andreas/0000-0002-8386-5397			Abecasis GR, 2001, BIOINFORMATICS, V17, P742, DOI 10.1093/bioinformatics/17.8.742; Bacanu SA, 2000, AM J HUM GENET, V66, P1933, DOI 10.1086/302929; Bamshad MJ, 2003, AM J HUM GENET, V72, P578, DOI 10.1086/368061; Barbujani G, 1997, P NATL ACAD SCI USA, V94, P4516, DOI 10.1073/pnas.94.9.4516; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Campbell CD, 2005, NAT GENET, V37, P868, DOI 10.1038/ng1607; Cavalli-Sforza LL, 1994, HIST GEOGRAPHY HUMAN; CHAKRABORTY R, 1993, EXS, V67, P153; Clopper CJ, 1934, BIOMETRIKA, V26, P404, DOI 10.2307/2331986; Deng HW, 2001, GENETICS, V159, P1319; Devlin B, 1999, BIOMETRICS, V55, P997, DOI 10.1111/j.0006-341X.1999.00997.x; Devlin B, 2001, GENET EPIDEMIOL, V21, P273, DOI 10.1002/gepi.1034; Devlin B, 2004, NAT GENET, V36, P1129, DOI 10.1038/ng1104-1129; Edwards AWF, 2003, BIOESSAYS, V25, P798, DOI 10.1002/bies.10315; Freedman ML, 2004, NAT GENET, V36, P388, DOI 10.1038/ng1333; Goudet J, 1995, J HERED, V86, P485; Hao K, 2004, EUR J HUM GENET, V12, P1001, DOI 10.1038/sj.ejhg.5201273; Helgason A, 2005, NAT GENET, V37, P90, DOI 10.1038/ng1492; Holle R, 2005, GESUNDHEITSWESEN, V67, P19; John U, 2001, SOZ PRAVENTIV MED, V46, P186, DOI 10.1007/BF01324255; Jorde LB, 2000, AM J HUM GENET, V66, P979, DOI 10.1086/302825; Jorgenson E, 2005, GENET EPIDEMIOL, V29, pS86, DOI 10.1002/gepi.20114; Kohler K, 2006, ANN HUM GENET, V70, P98, DOI 10.1111/j.1529-8817.2005.00214.x; Krawczak M, 2006, COMMUNITY GENET, V9, P55, DOI 10.1159/000090694; Liu KJ, 2005, BIOINFORMATICS, V21, P2128, DOI 10.1093/bioinformatics/bti282; Luedemann J, 2002, STROKE, V33, P2929, DOI 10.1161/01.STR.0000038422.57919.7F; Maraganore DM, 2005, AM J HUM GENET, V77, P685, DOI 10.1086/496902; Marchini J, 2004, NAT GENET, V36, P512, DOI 10.1038/ng1337; MORTON NE, 1992, ANN MED, V24, P557, DOI 10.3109/07853899209167010; Pritchard JK, 1999, AM J HUM GENET, V65, P220, DOI 10.1086/302449; Pritchard JK, 2000, GENETICS, V155, P945; Pritchard JK, 2001, NAT GENET, V28, P203, DOI 10.1038/90026; Romualdi C, 2002, GENOME RES, V12, P602, DOI 10.1101/gr.214902; Rosenberg NA, 2005, PLOS GENET, V1, P660, DOI 10.1371/journal.pgen.0010070; Shriver Mark D., 2004, Human Genomics, V1, P274; Thomas DC, 2002, CANCER EPIDEM BIOMAR, V11, P505; Voight BF, 2005, PLOS GENET, V1, P302, DOI 10.1371/journal.pgen.0010032; Wacholder S, 2002, CANCER EPIDEM BIOMAR, V11, P513; Wacholder S, 2000, J NATL CANCER I, V92, P1151, DOI 10.1093/jnci/92.14.1151; Wahlund S, 1928, HEREDITAS, V11, P65; Weir B. S., 1996, GENETIC DATA ANAL; Wichmann HE, 2005, GESUNDHEITSWESEN, V67, P26; WRIGHT S, 1951, ANN EUGENIC, V15, P323; Wright S, 1921, GENETICS, V6, P111; Wright S, 1922, AM NAT, V56, P330, DOI 10.1086/279872; Yang BZ, 2005, GENET EPIDEMIOL, V28, P302, DOI 10.1002/gepi.20070	46	88	88	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	0001-5652			HUM HERED	Hum. Hered.		2006	62	1					20	29		10.1159/000095850		10	Genetics & Heredity	Genetics & Heredity	097OS	WOS:000241458300003	17003564	
J	Sabbagh, A; Darlu, P				Sabbagh, Audrey; Darlu, Pierre			Data-mining methods as useful tools for predicting individual drug response: Application to CYP2D6 data	HUMAN HEREDITY			English	Article						CYP2D6; marker selection; decision tree; random forests; artificial neural network; multifactor dimensionality reduction	MULTIFACTOR-DIMENSIONALITY REDUCTION; DEXTROMETHORPHAN O-DEMETHYLATION; SINGLE-NUCLEOTIDE POLYMORPHISMS; ARTIFICIAL NEURAL-NETWORK; DETECTING GENE-GENE; LINKAGE DISEQUILIBRIUM; SCHIZOPHRENIC-PATIENTS; JAPANESE POPULATION; AFRICAN-AMERICANS; MARKER GENOTYPES	Objectives: Selecting a maximally informative subset of polymorphisms to predict a clinical outcome, such as drug response, requires appropriate search methods due to the increased dimensionality associated with looking at multiple genotypes. In this study, we investigated the ability of several pattern recognition methods to identify the most informative markers in the CYP2D6 gene for the prediction of CYP2D6 metabolizer status. Methods: Four data-mining tools were explored: decision trees, random forests, artificial neural networks, and the multifactor dimensionality reduction (MDR) method. Marker selection was performed separately in eight population samples of different ethnic origin to evaluate to what extent the most informative markers differ across ethnic groups. Results: Our results show that the number of polymorphisms required to predict CYP2D6 metabolic phenotype with a high accuracy can be dramatically reduced owing to the strong haplotype block structure observed at CYP2D6. MDR and neural networks provided nearly identical results and performed the best. Conclusion: Data-mining methods, such as MDR and neural networks, appear as promising tools to improve the efficiency of genotyping tests in pharmacogenetics with the ultimate goal of pre-screening patients for individual therapy selection with minimum genotyping effort. Copyright (c) 2006 S. Karger AG, Basel.	INSERM, U535, Unite Rech Genet Epidemiol & Struct Populat Humai, Villejuif, France	Sabbagh, A (reprint author), Hop Paul Brousse, INSERM, U535, BP 1000, FR-94817 Villejuif, France.	sabbagh@vjf.inserm.fr					Abecasis GR, 2000, BIOINFORMATICS, V16, P182, DOI 10.1093/bioinformatics/16.2.182; Andersson T, 2005, CLIN PHARMACOL THER, V78, P559, DOI 10.1016/j.clpt.2005.08.013; ARTHUR H, 1995, J CLIN PSYCHOPHARM, V15, P211, DOI 10.1097/00004714-199506000-00010; Barclay ML, 2003, PHARMACOGENETICS, V13, P627, DOI 10.1097/01.fpc.0000054129.14659.ef; BERTILSSON L, 1993, LANCET, V341, P63, DOI 10.1016/0140-6736(93)92546-6; BREIMAN L, 2004, RANDOM FORESTS VERSI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brockmoller J, 2002, CLIN PHARMACOL THER, V72, P438, DOI 10.1067/mcp.2002.127494; Cai WM, 1999, CLIN PHARMACOL THER, V66, P516, DOI 10.1016/S0009-9236(99)70015-9; Chen C., USING RANDOM FOREST; Cheverud JM, 2001, HEREDITY, V87, P52, DOI 10.1046/j.1365-2540.2001.00901.x; Chou WH, 2000, J CLIN PSYCHOPHARM, V20, P246, DOI 10.1097/00004714-200004000-00019; Curtis D, 2001, ANN HUM GENET, V65, P95, DOI 10.1046/j.1469-1809.2001.6510095.x; DAHL ML, 1995, PHARMACOGENETICS, V5, P159, DOI 10.1097/00008571-199506000-00004; Dalen P, 1998, CLIN PHARMACOL THER, V63, P444, DOI 10.1016/S0009-9236(98)90040-6; DEVLIN B, 1995, GENOMICS, V29, P311; Devlin B, 2003, GENET EPIDEMIOL, V25, P36, DOI 10.1002/gepi.10237; Di Luca Monica, 2005, J Transl Med, V3, P30, DOI 10.1186/1479-5876-3-30; Ebisawa Aiko, 2005, Drug Metab Pharmacokinet, V20, P294, DOI 10.2133/dmpk.20.294; Evans WE, 2001, ANNU REV GENOM HUM G, V2, P9, DOI 10.1146/annurev.genom.2.1.9; Furman KD, 2004, PHARMACOGENETICS, V14, P279, DOI 10.1097/01.fpc.0000114720.42625.65; Fuselli S, 2004, EUR J HUM GENET, V12, P916, DOI 10.1038/sj.ejhg.5201243; Gaedigk A, 2005, PHARMACOGENOMICS J, V5, P173, DOI 10.1038/sj.tpj.6500305; Gaedigk A, 2002, CLIN PHARMACOL THER, V72, P76, DOI 10.1067/mcp.2002.125783; Gaedigk A, 1999, PHARMACOGENETICS, V9, P669; Garcia-Barcelo M, 2000, CLIN CHEM, V46, P18; Griese EU, 1999, PHARMACOGENETICS, V9, P715, DOI 10.1097/01213011-199912000-00006; Griese EU, 2001, PHARMACOGENETICS, V11, P69, DOI 10.1097/00008571-200102000-00008; Griese EU, 1998, PHARMACOGENETICS, V8, P15, DOI 10.1097/00008571-199802000-00003; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; Halldorsson BV, 2004, HUM HERED, V58, P190, DOI 10.1159/000083546; Hoh J, 2003, NAT REV GENET, V4, P701, DOI 10.1038/nrg1155; Hosking L. K., 2002, Pharmacogenomics Journal, V2, P165, DOI 10.1038/sj.tpj.6500096; Huang JD, 1999, CLIN PHARMACOL THER, V65, P402, DOI 10.1016/S0009-9236(99)70134-7; Ingelman-Sundberg M, 2005, PHARMACOGENOMICS J, V5, P6, DOI 10.1038/sj.tpj.6500285; Isaza CA, 2000, METHOD FIND EXP CLIN, V22, P695, DOI 10.1358/mf.2000.22.9.802286; Iwahashi K, 1997, CLIN CHIM ACTA, V265, P143, DOI 10.1016/S0009-8981(97)00113-7; Ji L, 2002, CHINESE MED J-PEKING, V115, P1780; KIMURA S, 1989, AM J HUM GENET, V45, P889; Kirchheiner J, 2004, MOL PSYCHIATR, V9, P442, DOI 10.1038/sj.mp.4001494; Kirchheiner J, 2001, ACTA PSYCHIAT SCAND, V104, P173, DOI 10.1034/j.1600-0447.2001.00299.x; Kubota T, 2000, BRIT J CLIN PHARMACO, V50, P31, DOI 10.1046/j.1365-2125.2000.00209.x; LEWONTIN RC, 1964, GENETICS, V49, P49; Lunetta KL, 2004, BMC GENET, V5, DOI 10.1186/1471-2156-5-32; Marez D, 1997, PHARMACOGENETICS, V7, P193, DOI 10.1097/00008571-199706000-00004; McElroy S, 2000, AAPS PharmSci, V2, pE33; MIKUS G, 1994, J PHARMACOL EXP THER, V268, P546; Murphy GM, 2003, AM J PSYCHIAT, V160, P1830, DOI 10.1176/appi.ajp.160.10.1830; North BV, 2003, ANN HUM GENET, V67, P348, DOI 10.1046/j.1469-1809.2003.00030.x; Nyholt DR, 2004, AM J HUM GENET, V74, P765, DOI 10.1086/383251; Ozawa Shogo, 2004, Drug Metab Pharmacokinet, V19, P83, DOI 10.2133/dmpk.19.83; Phillips KA, 2001, JAMA-J AM MED ASSOC, V286, P2270, DOI 10.1001/jama.286.18.2270; Poulsen L, 1996, EUR J CLIN PHARMACOL, V51, P289, DOI 10.1007/s002280050200; Raimundo S, 2004, CLIN PHARMACOL THER, V76, P128, DOI 10.1016/j.clpt.2004.04.009; Rau T, 2002, PHARMACOGENETICS, V12, P465, DOI 10.1097/00008571-200208000-00007; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Sabbagh A, 2006, GENET MED, V8, P76, DOI 10.1097/01.gim.0000200951.54346.d6; Sachse C, 1997, AM J HUM GENET, V60, P284; Sallee FR, 2000, J CHILD ADOL PSYCHOP, V10, P27, DOI 10.1089/cap.2000.10.27; Schaeffeler E, 2003, HUM MUTAT, V22, P476, DOI 10.1002/humu.10280; Scordo MG, 2000, EUR J CLIN PHARMACOL, V56, P679, DOI 10.1007/s002280000222; Serretti Alessandro, 2004, BMC Med Genet, V5, P27, DOI 10.1186/1471-2350-5-27; Shimizu Takako, 2003, Drug Metab Pharmacokinet, V18, P48, DOI 10.2133/dmpk.18.48; Shimizu Takako, 2003, Drug Metab Pharmacokinet, V18, P71, DOI 10.2133/dmpk.18.71; Solus JF, 2004, PHARMACOGENOMICS, V5, P895, DOI 10.1517/14622416.5.7.895; Soyama Akiko, 2004, Drug Metab Pharmacokinet, V19, P313, DOI 10.2133/dmpk.19.313; Spina E, 1997, EUR J CLIN PHARMACOL, V51, P395, DOI 10.1007/s002280050220; Tateishi T, 1999, CLIN PHARMACOL THER, V65, P570, DOI 10.1016/S0009-9236(99)70077-9; Tomita Y, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-120; Wan YJY, 2001, PHARMACOGENETICS, V11, P489, DOI 10.1097/00008571-200108000-00004; Wennerholm A, 1999, PHARMACOGENETICS, V9, P707, DOI 10.1097/01213011-199912000-00005; Wennerholm A, 2001, PHARMACOGENETICS, V11, P417, DOI 10.1097/00008571-200107000-00005; Wilke RA, 2005, NAT REV DRUG DISCOV, V4, P911, DOI 10.1038/nrd1874; Zhang H, 1999, RECURSIVE PARTITIONI; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5	76	8	8	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	0001-5652			HUM HERED	Hum. Hered.		2006	62	3					119	134		10.1159/000096416		16	Genetics & Heredity	Genetics & Heredity	099SC	WOS:000241614800001	17057402	
S	Zhang, K; Fan, W; Buckles, B; Yuan, XJ; Xu, ZJ		Clifton, CW; Zhong, N; Liu, JM; Wah, BW; Wu, XD		Zhang, Kun; Fan, Wei; Buckles, Bill; Yuan, Xiaojing; Xu, Zujia			Discovering unrevealed properties of probability estimation trees: On algorithm selection and performance explanation	ICDM 2006: Sixth International Conference on Data Mining, Proceedings	IEEE International Conference on Data Mining		English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE				There has been increasing interest to design better probability, estimation trees, or PETs, for ranking and probability estimation. Capable of generating class membership probabilities, PETs have been shown to be highly accurate and flexible for many difficult problems, such as cost-sensitive learning and matching skewed distributions. There are a large number of PET algorithms available, and about ten of them are well-known. This large number provides an advantage, but it also creates confusion in practice. One would ask "given a new dataset, which algorithm to choose and what performance to expect and not to expect? What are the reasons to explain either good or bad performance under different situations? " In this paper, we systematically, for the first time, answer these important questions by conducting a large-scale empirical comparison of five popular PETs by examining their A UC, MSE and error rate "learning curves " (instead of training-test split based cross-validation). Using the maximum AUC achieved by v any of the evaluated probability estimation tree algorithms, we demonstrate that the preference of a probability estimation tree on different evaluation metrics can be accurately characterized by the "signal-noise separability" of the dataset, as well as. some other observable statistics of the dataset explained further in the paper. Moreover, in order to understand their relative performance, many important and previously unrevealed properties of each PET's mechanism and heuristics are analyzed and evaluated. Importantly, a practical guide for choosing the most appropriate PET algorithm given a new data mining problem is provided.	Tulane Univ, EECS Dept, New Orleans, LA 70118 USA; IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA; Univ Houston, Coll Technol, Houston, TX 77004 USA; Dillard Univ, Dept Comp Sci, New Orleans, LA 70122 USA	Zhang, K (reprint author), Tulane Univ, EECS Dept, New Orleans, LA 70118 USA.						Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DAVIDSON I, ECMLPKDD 2006; DeGroot M.H., 1982, STATISTICAL DECISION, V1, P291; Ennis M, 1998, STAT MED, V17, P2501; Fan W, 2002, INT CON DISTR COMP S, P445; FAN W, 2005, ICDM 2005, P154; Fan W, 2003, ICDM, P51; Fan W., 2004, AAAI, P336; FAN W, 2004, EDBT, P801; Fawcett T, 2003, ROC GRAPHS NOTES PRA; FERRI C, 2003, ECML; GREEN DM, 1966, SIGNAL DETECTION THE; Hand D. J., 1997, CONSTRUCTION ASSESSM; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; LING C, 2003, ICML; LIU F, 2005, THESIS MONASH U; Perlich C., 2003, J MACHINE LEARNING R, V4, P211; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Quinlan J.R., 1993, C4 5 PROGRAMS EMPIRI; Wei Fan, 2004, KDD 04, P128; ZHANG K, ICDM2005, P817	24	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		978-0-7695-2701-7	IEEE DATA MINING			2006							741	752				12	Computer Science, Information Systems	Computer Science	BFZ37	WOS:000245601900073		
S	Caruana, R; Munson, A; Niculescu-Mizil, A		Clifton, CW; Zhong, N; Liu, JM; Wah, BW; Wu, XD		Caruana, Rich; Munson, Art; Niculescu-Mizil, Alexandru			Getting the most out of ensemble selection	ICDM 2006: Sixth International Conference on Data Mining, Proceedings	IEEE International Conference on Data Mining		English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE				We investigate four previously unexplored aspects of ensemble selection, a procedure for building ensembles of classifiers. First we test whether adjusting model predictions to put them on a canonical scale makes the ensembles more effective. Second, we explore the performance of ensemble selection when different amounts of data are available for ensemble hillclimbing. Third, we quantify the benefit of ensemble selection's ability to optimize to arbitrary metrics. Fourth, we study the performance impact of pruning the number of models available for ensemble selection. Based on our results we present improved ensemble selection methods that double the benefit of the original method.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Caruana, R (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Breiman L., 2001, MACHINE LEARNING, V45; CARUANA R, 2006, 20062045 CORN U; Caruana R., 2004, ICML; DOMINGOS P, 2000, ICML; DUIN RPW, 2002, ICPR; MARGINEANTU DD, 1997, ICML; Martinez-Munoz G., 2006, ICML; MUNSON A, 2005, HLT EMNLP; NICULESCUMIZIL A, 2005, ICML 05; Platt J.C., 1999, ADV LARGE MARGIN CLA; ROLI F, 2001, MULTIPLE CLASSIFER S; Street W., 2001, KDD; TSOUMAKAS G, 2005, INTELLIGENT DATA ANA, V9; Zhang Y., 2006, J MACHINE LEARNING R, V7	14	20	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		978-0-7695-2701-7	IEEE DATA MINING			2006							828	833				6	Computer Science, Information Systems	Computer Science	BFZ37	WOS:000245601900085		
S	Tahir, MA; Smith, J		Clifton, CW; Zhong, N; Liu, JM; Wah, BW; Wu, XD		Tahir, Muhammad Atif; Smith, James			Improving nearest neighbor classifier using Tabu Search and ensemble distance metrics	ICDM 2006: Sixth International Conference on Data Mining, Proceedings	IEEE International Conference on Data Mining		English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE			STATISTICAL PATTERN-RECOGNITION; ALGORITHMS	The nearest-neighbor (NN) classifier has long been used in pattern recognition, exploratory data analysis, and data mining problems. A vital consideration in obtaining good results with this technique is the choice of distance function, and correspondingly which features to consider when computing distances between samples. In this paper a new ensemble technique is proposed to improve the performance of NN classifier The proposed approach combines multiple NN classifiers, where each classifier uses a different distance function and potentially a different set of features (feature vector). These feature vectors are determined for each distance metric using Simple Voting Scheme incorporated in Tabu Search (TS). The proposed ensemble classifier with different distance metrics and different feature vectors (TS-DF/NN) is evaluated using various benchmark data sets from UCI Machine Learning Repository. Results have indicated a significant increase in the performance when compared with various well-known classifiers. Furthermore, the proposed ensemble method is also compared with ensemble classifier using different distance metrics but with same feature vector (with or without Feature Selection (FS)).	Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.						BAO Y, 2004, LNCS, V3177; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake C. L., UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R. O., 1973, PATTERN CLASSIFICATI; Frank E., 2005, DATA MINING PRACTICA; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Glover F., 1989, ORSA Journal on Computing, V1; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1993, Annals of Operations Research, V41; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KOHAVI R, 1995, P 8 EUR C MACH LEARN; KORYCINSKI D, 2003, P IEEE INT GEOSC REM; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Michie D., 1994, MACHINE LEARNING NEU; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SAIT SM, 1999, GEN ITERATIVE ALGORI; TAHIR MA, 2004, IEEE P INT C PATT RE; TAHIR MA, 2004, LNCS, V3177; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		978-0-7695-2701-7	IEEE DATA MINING			2006							1086	1090				5	Computer Science, Information Systems	Computer Science	BFZ37	WOS:000245601900132		
B	Kurgan, LA; Rahbari, M; Homaeian, L		Wani, A; Li, T; Kurgan, L; Ye, J; Liu, Y		Kurgan, Lukasz A.; Rahbari, Mandana; Homaeian, Leila			Impact of the predicted protein structural content on prediction of structural classes for the twilight zone proteins	ICMLA 2006: 5th International Conference on Machine Learning and Applications, Proceedings			English	Proceedings Paper	5th International Conference on Machine Learning and Applications	DEC 14-16, 2006	Orlando, FL	Assoc Machine Learning & Applicat, Calif State Univ Bakersfield, Armstrong Atlantic State Univ, Florida Int Univ, IEEE, Univ Louisville			AMINO-ACID-COMPOSITION; SECONDARY STRUCTURE PREDICTION; INFORMATION DISCREPANCY; GLOBULAR-PROTEINS; NEURAL-NETWORKS; SEQUENCE; CLASSIFICATION; RECOGNITION; ALGORITHMS; HOMOLOGY	This paper addresses in silico prediction of protein structural classes as defined in the SCOP database. The SCOP defines total of 11 classes, while majority of proteins are classified to the 4 classes: all-alpha, all-beta, alpha/beta and alpha+beta. The main goals of this paper are to experimentally evaluate the impact of predicted protein secondary structure content on the structural class prediction and to develop a novel protein sequence representation. The experiments include application of three protein sequence representations and four classifiers to prediction of both 4 and 11 structural classes. The predictions are performed using a large dataset of low homology (twilight zone) sequences. The proposed sequence representation includes the predicted structural content, which provides the strongest contribution towards classification, composition and composition moment vectors, hydrophobic autocorrelations, chemical group composition and molecular weight of the protein. The predicted content values are shown on average to improve the prediction accuracy by 3.3% and 4.2% for the 4 and 11 classes, respectively, when compared to sequence representation that does not utilize this information. Finally, we propose a very compact, 20 dimensional sequence representation that is shown to improve the prediction accuracy by 5.1-8.5% when compared with recently published results.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2M7, Canada	Kurgan, LA (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2M7, Canada.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bu WS, 1999, EUR J BIOCHEM, V266, P1043, DOI 10.1046/j.1432-1327.1999.00947.x; Cai YD, 2003, J THEOR BIOL, V221, P115, DOI 10.1006/jtbi.2003.3179; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1993, J PROTEIN CHEM, V12, P169, DOI 10.1007/BF01026038; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.3.CO;2-B; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Eisenhaber F, 1996, PROTEINS, V25, P169, DOI 10.1002/(SICI)1097-0134(199606)25:2<169::AID-PROT3>3.3.CO;2-5; FAUCHERE JL, 1983, EUR J MED CHEM, V18, P369; Feng KY, 2005, BIOCHEM BIOPH RES CO, V334, P213, DOI 10.1016/j.bbrc.2005.06.075; Frank E., 2005, DATA MINING PRACTICA; Gromiha MM, 1998, PROTEIN ENG, V11, P249, DOI 10.1093/protein/11.4.249; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Jin LX, 2003, COMPUT BIOL CHEM, V27, P373, DOI 10.1016/S1476-9271(02)00087-7; Kedarisetti KD, 2006, COMPUT BIOL CHEM, V30, P393, DOI 10.1016/j.compbiolchem.2006.06.003; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; KRIGBAUM WR, 1973, P NATL ACAD SCI USA, V70, P2809, DOI 10.1073/pnas.70.10.2809; Kurgan LA, 2006, PATTERN RECOGN, V39, P2323, DOI 10.1016/j.patcog.2006.02.014; LEVITT M, 1976, NATURE, V261, P552, DOI 10.1038/261552a0; Lin K, 2005, BIOINFORMATICS, V21, P152, DOI 10.1093/bioinformatics/bth487; LIN Z, 2001, PROTEIN CHEM, V20, P217; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; MUSKAL SM, 1992, J MOL BIOL, V225, P713, DOI 10.1016/0022-2836(92)90396-2; Pollastri G, 2005, BIOINFORMATICS, V21, P1719, DOI 10.1093/bioinformatics/bti203; Rost B, 1999, PROTEIN ENG, V12, P85, DOI 10.1093/protein/12.2.85; Ruan JS, 2005, ARTIF INTELL MED, V35, P19, DOI 10.1016/j.artmed.2005.02.006; SANDER C, 1991, PROTEINS, V9, P56, DOI 10.1002/prot.340090107; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P577, DOI 10.1016/j.bbrc.2005.06.128; Sikonja M.R., 1997, P 14 INT C ICML 97, P296; Wang ZX, 2000, PROTEINS, V38, P165, DOI 10.1002/(SICI)1097-0134(20000201)38:2<165::AID-PROT5>3.0.CO;2-V; Yang Y. M., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; ZHANG CT, 1995, PROTEIN ENG, V8, P425, DOI 10.1093/protein/8.5.425; ZHANG CT, 1992, PROTEIN SCI, V1, P401; Zhang ZD, 2001, J THEOR BIOL, V208, P65, DOI 10.1006/jtbi.2000.2201	40	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-2735-2				2006							180	186				7	Computer Science, Artificial Intelligence	Computer Science	BFT06	WOS:000244477800028		
S	Shoemaker, L; Banfield, RE; Hall, LO; Bowyer, KW; Kegelmeyer, WP			IEEE Comp Soc	Shoemaker, Larry; Banfield, Robert E.; Hall, Lawrence O.; Bowyer, Kevin W.; Kegelmeyer, W. Philip			Learning to predict salient regions from disjoint and skewed training sets	ICTAI-2006: Eighteenth International Conference on Tools with Artificial Intelligence, Proceedings	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	18th International Conference on Tools with Artificial Intelligence (ICTAI-2006)	NOV 13-15, 2006	Washington, DC	IEEE Comp Soc, Biol & Artificial Intelligence Soc, ITRI Wright State Univ, Virginia Tech CS Dept				We present an ensemble learning approach that achieves accurate predictions from arbitrarily partitioned data. The partitions come from the distributed processing requirements of a large scale simulation where the volume of the data is such that classifiers can train only on data local to a given partition. As a result of the partition reflecting the need for efficient simulation analysis, rather than the needs of data mining, the class statistics vary across partitions; indeed some classes will likely be absent from some partitions. We combine a fast ensemble learning algorithm with majority voting to generate an accurate working model of the simulation. Results from several simulations show that regions of interest are successfully identified in spite of training set class imbalances. Accuracy is analyzed both at the level of nodes in the simulation data structure, and in terms of higher-level regions of interest. It is shown that over 98% of salient regions are found in independent test sets. Hence, this approach will be a significant time saver for simulation users and developers.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	Shoemaker, L (reprint author), Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave, Tampa, FL 33620 USA.		Bowyer, Kevin/	Bowyer, Kevin/0000-0002-7562-4390			BANFIELD RE, 2005, 6 INT WORKSH MULT CL, P196; BANFIELD RE, 2004, 5 INT C MULT CLASS S, P223; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; HALL L, 2004, 2004 IEEE INT C SYST, V2, P1447, DOI 10.1109/ICSMC.2004.1399834; Henderson A., 2004, PARAVIEW GUIDE; KOEGLER WS, 2005, ADV INTELLIGENT DATA, V6, P192; LEE BS, 2001, P INT C DAT SYST ADV, P533; PILCH M, SCI PREDICTION; SCHOOF LA, 1998, EXODUS 2 FINITE ELEM	9	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		978-0-7695-2728-4	PROC INT C TOOLS ART			2006							116	123				8	Computer Science, Artificial Intelligence	Computer Science	BFW79	WOS:000245172700016		
J	Li, HF; Jiang, T; Zhang, KS				Li, HF; Jiang, T; Zhang, KS			Efficient and robust feature extraction by maximum margin criterion	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						feature extraction; linear discriminant analysis (LDA); maximum margin criterion (MMC); small sample size problem	DISCRIMINANT-ANALYSIS; GENE-EXPRESSION; SAMPLE-SIZE; PATTERN-RECOGNITION; CLASSIFICATION; PREDICTION; ALGORITHM; SYSTEM	In pattern recognition, feature extraction techniques are widely employed to reduce the dimensionality of data and to enhance the discriminatory information. Principal component analysis (PCA) and linear discriminant analysis (LDA) are the two most popular linear dimensionality reduction methods. However, PCA is not very effective for the extraction of the most discriminant features, and LDA is not stable due to the small sample size problem. In this paper, we propose some new (linear and nonlinear) feature extractors based on maximum margin criterion (MMC). Geometrically, feature extractors based on MMC maximize the (average) margin between classes after dimensionality reduction. It is shown that MMC can represent class separability better than PCA. As a connection to LDA, we may also derive LDA from MMC by incorporating some constraints. By using some other constraints, we establish a new linear feature extractor that does not suffer from the small sample size problem, which is known to cause serious stability problems for LDA. The kernelized (nonlinear) counterpart of this linear feature extractor is also established in the paper. Our extensive experiments demonstrate that the new feature extractors are effective, stable, and efficient.	Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA; Motorola Inc, Human Interact Res Lab, Tempe, AZ 85282 USA	Li, HF (reprint author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	hli@cs.ucr.edu; jiang@cs.ucr.edu; keshu.zhang@motorola.com					Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bellman R., 1961, ADAPTIVE CONTROL PRO; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; Golub G. H., 1996, MATRIX COMPUTATIONS; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; HONG ZQ, 1991, PATTERN RECOGN, V24, P317, DOI 10.1016/0031-3203(91)90074-F; Huang R., 2002, P INT C PATT REC QUE, V3, P29; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KRISHNAIAH P, 1982, HDB STAT, V2, P835; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Ratsch G., 1999, P IEEE INT WORKSH NE, V9, P41; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; Samaria F., 1994, 2 IEEE WORKSH APPL C; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Stewart G.W., 1973, INTRO MATRIX COMPUTA; TIAN Q, 1986, OPT ENG, V25, P834, DOI 10.1117/12.7973916; Vapnik V., 1998, STAT LEARNING THEORY; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; ZHAO W, 1999, CARTR914 U MAR CTR A	30	224	268	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JAN	2006	17	1					157	165		10.1109/TNN.2005.860852		9	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	015FC	WOS:000235536300014	16526484	
S	Eruhimov, V; Martyanov, V; Raulefs, P; Tuv, E		Corchado, E; Yin, H; Botti, V; Fyfe, C		Eruhimov, Victor; Martyanov, Vladimir; Raulefs, Peter; Tuv, Eugene			Combining unsupervised and supervised approaches to feature selection for multivariate signal compression	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2006)	SEP 20-23, 2006	Burgos, SPAIN		Univ Burgos			A problem of learning from a database where each sample consists of several time series and a single response is considered. We are interested in maximum data reduction that preserves predictive power of the original time series, and at the same time allows reasonable reconstruction quality of the original signals. Each signal is decomposed into a set of wavelet features that are coded according to their importance consisting of two terms. The first depends on the influence of the feature on the expected signal reconstruction error, and the second is determined by feature importance for the response prediction. The latter is calculated by building series of boosted decision tree ensembles. We demonstrate that such combination maintains small signal distortion rates, and ensures no increase in the prediction error in contrast to the unsupervised compression with the same reduction ratio.	Intel Corp, Anal & Control Technol, Santa Clara, CA 95051 USA	Eruhimov, V (reprint author), Intel Corp, Anal & Control Technol, Santa Clara, CA 95051 USA.	victor.eruhimov@intel.com; vladimir.martyanov@intel.com; peter.raulefs@intel.com; eugene.tuv@intel.com					BORISOV A, 2005, FEATURE EXTRACTION F; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Daubechies I., 1992, 10 LECT WAVELETS; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Friedman J, 1999, STOCHASTIC GRADIENT; Friedman J. H., 1999, GREEDY FUNCTION APPR; Gersho A., 1991, VECTOR QUANTIZATION; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Jeong MK, 2006, TECHNOMETRICS, V48, P26, DOI 10.1198/004017005000000553; Jin JH, 2001, J INTELL MANUF, V12, P257, DOI 10.1023/A:1011248925750; MacKay DJC, 2003, INFORMATION THEORY I; Mallat S, 1999, WAVELET TOUR SIGNAL; TORKKOLA K, 2005, FEATURE EXTRACTION F; TUV E, 2005, IN PRESS IEEE INTELL; TUV E, 2005, FEATURE EXTRACTION F	16	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-45485-3	LECT NOTES COMPUT SC			2006	4224						480	487				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFG81	WOS:000241790900058		
S	Tuv, E; Borisov, A; Torkkola, K		Corchado, E; Yin, H; Botti, V; Fyfe, C		Tuv, Eugene; Borisov, Alexander; Torkkola, Kari			Best subset feature selection for massive mixed-type problems	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2006)	SEP 20-23, 2006	Burgos, SPAIN		Univ Burgos			We address the problem of identifying a non-redundant subset of important variables. All modern feature selection approaches including filters, wrappers, and embedded methods experience problems in very general settings with massive mixed-type data, and with complex relationships between the inputs and the target. We propose an efficient ensemble-based approach measuring statistical independence between a target and a potentially very large number of inputs including any meaningful order of interactions between them, removing redundancies from the relevant ones, and finally ranking variables in the identified minimum feature set. Experiments with synthetic data illustrate the sensitivity and the selectivity of the method, whereas the scalability of the method is demonstrated with a real car sensor data base.	Intel, Anal & Control Technol, Chandler, AZ USA; Intel, Anal & Control Technol, Nizhnii Novgorod, Russia; Motorola Inc, Intelligent Syst Lab, Tempe, AZ USA	Tuv, E (reprint author), Intel, Anal & Control Technol, Chandler, AZ USA.	eugene.tuv@intel.com; alexander.borisov@intel.com; Kari.Torkkola@motorola.com					BORISOV A, 2005, FEATURE EXTRACTION F; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Friedman J. H., 1999, GREEDY FUNCTION APPR; GABRILOVICH E, 2004, P ICML 04; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; TORKKOLA K, 2005, FEATURE EXTRACTION F; TORKKOLA K, 2005, P 2005 IEEE INT VEH, P638; TUV E, 2006, P INT JOINT C NEUR N; TUV E, 2005, FEATURE EXTRACTION F	10	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-45485-3	LECT NOTES COMPUT SC			2006	4224						1048	1056				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFG81	WOS:000241790900125		
B	Bartlow, N; Cukic, B		OConner, L		Bartlow, Nick; Cukic, Bojan			Evaluating the reliability of credential hardening through keystroke dynamics	ISSRE 2006:17th International Symposium on Software Reliability Engineering, Proceedings			English	Proceedings Paper	17th International Symposium on Software Reliability Engineering	NOV 07-10, 2006	Raleigh, NC	IEEE Comp Soc, IEEE Comp Soc Tech Council Software Engn, IEEE Reliab Soc				Most computer systems rely on usernames and passwords as a mechanism for authentication and access control. These credential sets offer weak protection to a broad scope of applications with differing levels of sensitivity. Traditional physiological biometric systems such as finger-print, face, and iris recognition are not readily deployable in remote authentication schemes. Keystroke dynamics provide the ability to combine the ease of use of username / password schemes with the increased trustworthiness associated with biometrics. Our research extends previous work on keystroke dynamics by incorporating shift-key patterns. The system is capable of operating at various points on a traditional ROC curve depending on application specific security needs. A 1% False Accept Rate is attainable at a 14% False Reject Rate. An Equal Error Rate of 5% is suitable for systems requiring a relatively low security. As a username password authentication scheme, our approach decreases the system penetration rate associated with compromised passwords by 95%-99%. Said performance measures can be further improved through optimization of the classification algorithm on a user specific basis.	W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA	Bartlow, N (reprint author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.						Adams A., 1999, Communications of the ACM, V42, DOI 10.1145/322796.322806; [Anonymous], 1989, The Microsoft Keyboard Layout Creator, Patent No. 4805222; BARTLOW N, 2005, THESIS W VIRGINIA U; Breiman L., 1999, RANDOM FORESTS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DESOUZA KC, 2005, HICSS; Filho J.R. M., 2006, Pattern Recogn. Lett., V27, P1440, Patent No. [4621334, 4,621,334]; Gaines RS, 1980, R256NSF RAND CORP; GUO L, 2004, ROBUST PREDICTION FA; Ives B, 2004, COMMUN ACM, V47, P75, DOI 10.1145/975817.975820; JOYCE R, 1990, COMMUNICATIONS ACM, V33; *LLC, 2002, BIOP BIOP QUEST ANSW; Monrose F., 2002, International Journal of Information Security, V1, DOI 10.1007/s102070100006; OBAIDAT MS, 1993, IEEE T IND ELECTRON, V40, P235, DOI 10.1109/41.222645; Obaidat MS, 1997, IEEE T SYST MAN CY B, V27, P261, DOI 10.1109/3477.558812; Schneier B, 1993, APPL CRYPTOGRAPHY PR; SHAFFER G, 2004, GEODSOFT GOOD BAD PA; Singh S., 1999, CODE BOOK SCI SECREC	18	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-2684-3				2006							117	126				10	Computer Science, Software Engineering	Computer Science	BFR93	WOS:000244110800011		
J	Song, MH; Clark, M				Song, MH; Clark, M			Development and evaluation of an in silico model for hERG binding	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	4th Indo-US Workshop on Mathematical Chemistry	JAN 08-12, 2005	Pune, INDIA				K+ CHANNEL BLOCKERS; LONG-QT-SYNDROME; POTASSIUM CHANNEL; PREDICTION; QSAR; DRUGS; INHIBITION; INSIGHTS	It has been recognized that drug-induced QT prolongation is related to blockage of the human ether-a-go-go-related gene (hERG) ion channel. Therefore, it is prudent to evaluate the hERG binding of active compounds in early stages of drug discovery. In silico approaches provide an economic and quick method to screen for potential hERG liability. A diverse set of 90 compounds with hERG IC50 inhibition data was collected from literature references. Fragment-based QSAR descriptors and three different statistical methods, support vector regression, partial least squares, and random forests, were employed to construct QSAR models for hERG binding affinity. Important fragment descriptors relevant to hERG binding affinity were identified through an efficient feature selection method based on sparse linear support vector regression. The support vector regression predictive model built upon selected fragment descriptors outperforms the other two statistical methods in this study, resulting in an r(2) of 0.912 and 0.848 for the training and testing data sets, respectively. The support vector regression model was applied to predict hERG binding affinities of 20 in-house compounds belonging to three different series. The model predicted the relative binding affinity well for two out of three compound series. The hierarchical clustering and dendrogram results show that the compound series with the best prediction has much higher structural similarity and more neighbors of training compounds than the other two compound series, demonstrating the predictive scope of the model. The combination of a QSAR model and postprocessing analysis, such as clustering and visualization, provides a way to assess the confidence level of QSAR prediction results on the basis of similarity to the training set.	Locus Pharmaceut, Blue Bell, PA 19422 USA	Clark, M (reprint author), Locus Pharmaceut, 512 Township Line Rd, Blue Bell, PA 19422 USA.	mclark@locuspharma.com					Aronov AM, 2004, BIOORGAN MED CHEM, V12, P2307, DOI 10.1016/j.bmc.2004.02.003; Bains W, 2004, PROG BIOPHYS MOL BIO, V86, P205, DOI 10.1016/j.pbiomolbio.2003.09.001; BENNETT KPB, 2003, J MACHINE LEARNING R, V3, P1229; BI J, 2002, ADV NEURAL INFORM PR, P593; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cavalli A, 2002, J MED CHEM, V45, P3844, DOI 10.1021/jm0208875; Clark M, 2005, J CHEM INF MODEL, V45, P30, DOI 10.1021/ci049744c; Duffy EM, 2000, J AM CHEM SOC, V122, P2878, DOI 10.1021/ja993663t; Ekins S, 2002, J PHARMACOL EXP THER, V301, P427, DOI 10.1124/jpet.301.2.427; Keating MT, 1996, SCIENCE, V272, P681, DOI 10.1126/science.272.5262.681; Keseru GM, 2003, BIOORG MED CHEM LETT, V13, P2773, DOI 10.1016/S0960-894X(03)00492-X; Kratochwil NA, 2002, BIOCHEM PHARMACOL, V64, P1355, DOI 10.1016/S0006-2952(02)01074-2; Mitcheson JS, 2000, P NATL ACAD SCI USA, V97, P12329, DOI 10.1073/pnas.210244497; Pearlstein RA, 2003, BIOORG MED CHEM LETT, V13, P1829, DOI 10.1016/S0960-894X(03)00196-3; Roche O, 2002, CHEMBIOCHEM, V3, P455, DOI 10.1002/1439-7633(20020503)3:5<455::AID-CBIC455>3.0.CO;2-L; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P854, DOI 10.1021/ci00020a020; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P1912, DOI 10.1021/ci049782w; Smola A, 1998, NC2TR1998030; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Vapnik V., 1998, STAT LEARNING THEORY; Witchel HJ, 2002, J PHARMACOL TOXICOL, V48, P65, DOI 10.1016/S1056-8719(03)00041-8; Zolotoy Alexander B., 2003, Current Medicinal Chemistry - Cardiovascular & Hematological Agents, V1, P225, DOI 10.2174/1568016033477432; 2005, 2 2 0 R FDN	23	89	89	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	JAN-FEB	2006	46	1					392	400		10.1021/ci050308f		9	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	008DU	WOS:000235021200042	16426073	
S	Struyf, J; Dzeroski, S		Bonchi, F; Boulicaut, JF		Struyf, J; Dzeroski, S			Constraint based induction of multi-objective regression trees	KNOWLEDGE DISCOVERY IN INDUCTIVE DATABASES	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th International Workshop on Knowledge Discovery in Inductive Databases	OCT   03, 2005	Oporto, PORTUGAL				DECISION TREES	Constrained based inductive systems are a key component of inductive databases and responsible for building the models that satisfy the constraints in the inductive queries. In this paper, we propose a constraint based system for building multi-objective regression trees. A multi-objective regression tree is a decision tree capable of predicting several numeric variables at once. We focus on size and accuracy constraints. By either specifying maximum size or minimum accuracy, the user can trade-off size (and thus interpretability) for accuracy. Our approach is to first build a large tree based on the training data and to prune it in a second step to satisfy the user constraints. This has the advantage that the tree can be stored in the inductive database and used for answering inductive queries with different constraints. Besides size and accuracy constraints, we also briefly discuss syntactic constraints. We evaluate our system on a number of real world data sets and measure the size versus accuracy trade-off.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium; Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana 1000, Slovenia	Struyf, J (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Louvain, Belgium.	Jan.Struyf@cs.kuleuven.be; Saso.Dzeroski@ijs.si					Almuallim H, 1996, ARTIF INTELL, V83, P347, DOI 10.1016/0004-3702(95)00060-7; Blockeel H, 1998, P 15 INT C MACH LEAR, P55; BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1007/BF00993345; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; De Raedt L., 2002, SIGKDD EXPLORATIONS, V4, P69; DEMSAR D, 2005, IN PRESS ECOLOGICAL; DEMSAR D, 2005, ANN M EC SOC AM MONT; DZEROSKI S, 2005, UNPUB 2 INT C COEX G; Dzeroski S, 2000, APPL INTELL, V13, P7, DOI 10.1023/A:1008323212047; Frank E., 2005, DATA MINING PRACTICA; Garofalakis M, 2003, DATA MIN KNOWL DISC, V7, P187, DOI 10.1023/A:1022445500761; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Kampichler C, 2000, SOIL BIOL BIOCHEM, V32, P197, DOI 10.1016/S0038-0717(99)00147-9; Quinlan J. R., 1993, M KAUFMANN SERIES MA; SAIN RS, 2002, COMPUTING SCI STAT, V34, P232	17	26	26	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33292-8	LECT NOTES COMPUT SC			2006	3933						222	233				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEG95	WOS:000237245300013		
S	Tsymbal, A; Pechenizkiy, M; Cunningham, P		Furnkranz, J; Scheffer, T; Spiliopoulou, M		Tsymbal, Alexey; Pechenizkiy, Mykola; Cunningham, Padraig			Dynamic integration with random forests	MACHINE LEARNING: ECML 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	17th European Conference on Machine Learning (ECML 2006)	SEP 18-22, 2006	Berlin, GERMANY	Google, Humboldt Univ Berlin, Deutsch Forsch Gemeinsch, KD-Ubiq, European Off Aerosp Res & Dev, USAF Res Lab, STRATO A G, IBM, PASCAL, Mach Learning				Random Forests (RF) are a successful ensemble prediction technique that uses majority voting or averaging as a combination function. However, it is clear that each tree in a random forest may have a different contribution in processing a certain instance. In this paper, we demonstrate that the prediction performance of RF may still be improved in some domains by replacing the combination function with dynamic integration, which is based on local performance estimates. Our experiments also demonstrate that the RF Intrinsic Similarity is better than the commonly used Heterogeneous Euclidean/Overlap Metric in finding a neighbourhood for local estimates in the context of dynamic integration of classification random forests.	Trinity Coll Dublin, Dept Comp Sci, Dublin, Ireland; Univ Jyvaskyla, Dept Math IT, Jyvaskyla, Finland	Tsymbal, A (reprint author), Trinity Coll Dublin, Dept Comp Sci, Dublin, Ireland.	Alexey.Tsymbal@cs.tcd.ie; mpechen@it.jyu.fi; Padraig.Cunningham@cs.tcd.ie					Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI 10.1145/502512.502546; Blake C., 1999, UCI REPOSITORY MACHI; BREIMAN L, 1996, 486 U CAL STAT DEP; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Robnik-Sikonja M, 2004, LECT NOTES COMPUT SC, V3201, P359; ROONEY N, 2004, LNCS, V3181, P164; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; TSYMBAL A, 2006, TCDCS200623 DEP COMP; Tsymbal A., 2005, P 19 INT JOINT C ART, P877; Tsymbal A, 2000, LECT NOTES COMPUT<D>, V1910, P116; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I., 2000, DATA MINING PRACTICA	14	13	14	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-45375-X	LECT NOTES COMPUT SC			2006	4212						801	808				8	Computer Science, Artificial Intelligence	Computer Science	BFJ25	WOS:000242308000077		
J	Mansmann, U; Rushhaupt, M; Huber, W				Mansmann, U; Rushhaupt, M; Huber, W			Reproducible statistical analysis in microarray profiling studies	METHODS OF INFORMATION IN MEDICINE			English	Article; Proceedings Paper	Conference on Statistical Methodology in Bioinformatics and Clinical Trials	APR, 2004	Prague, CZECH REPUBLIC	Int Med Informat Assoc		classification; reproducibility; microarray profiling studies; statistical computation	GENE-EXPRESSION DATA; BREAST-CANCER; CLASSIFICATION; PREDICTION	Objectives: Microarrays are a recent biotechnology that offers the hope of improved cancer classification. A number of publications presented clinically promising results by combining this new kind of biological data with specifically designed algorithmic approaches. But, reproducing published results in this domain is harder than it may seem. Methods: This paper presents examples, discusses the problems hidden in the published analyses and demonstrates a strategy to improve the situation which is based on the vignette technology available from the R and Bioconductor projects. Results. The tool of a compendium is discussed to achieve reproducible calculations and to offer an extensible computational framework. A compendium is a document that bundles primary data, processing methods (computational code), derived data, and statistical output with textual documentation and conclusions. It is interactive in the sense that it allows for the modification of the processing options, plugging in new data, or inserting further algorithms and visualizations. Conclusions. Due to the complexity of the algorithms, the size of the data sets, and the limitations of the medium printed paper it is usually not possible to report all the minutiae of the data processing and statistical computations. The technique of a compendium allows a complete critical assessment of a complex analysis.	Univ Munich, IBE, D-80539 Munich, Germany; German Canc Res Ctr, Div Mol Genome Anal, INF 580, D-6900 Heidelberg, Germany; EMBL, EBI, Cambridge, England	Mansmann, U (reprint author), LMU Munchen, Sch Med, IBE, Chair Biometry & Bioinformat, Marchioninistr 15, D-81377 Munich, Germany.	mansmann@ibe.med.uni-muenchen.de					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Berger JO, 2003, STAT SCI, V18, P1, DOI 10.1214/ss/1056397485; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brenton JD, 2003, LANCET, V362, P340, DOI 10.1016/S0140-6736(03)14053-6; Bullinger L, 2004, NEW ENGL J MED, V350, P1605, DOI 10.1056/NEJMoa031046; CAREY VJ, 2001, CHANCE, V14, P46; Chang JC, 2003, LANCET, V362, P362, DOI 10.1016/S0140-6736(03)14023-8; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eilers PHC, 2001, P SOC PHOTO-OPT INS, V2, P187; GENTLEMAN R, 1996, R NEWS, V2, P11; Huang E, 2003, LANCET, V361, P1590, DOI 10.1016/S0140-6736(03)13308-9; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; LEE JW, 2004, IN PRESS COMPUTATION; Leisch F, 2002, COMPSTAT 2002: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P575; LEISCH F, 2003, CHANCE, V16, P41; Sawitzki G, 2002, COMPUTATION STAT, V17, P65, DOI 10.1007/s001800200091; Simon R, 2003, J NATL CANCER I, V95, P14; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshiranis RJ, 2002, STAT APPL GENET MOL, V1, P1; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V.N., 1999, NATURE STAT LEARNING	23	1	1	SCHATTAUER GMBH-VERLAG MEDIZIN NATURWISSENSCHAFTEN	STUTTGART	HOLDERLINSTRASSE 3, D-70174 STUTTGART, GERMANY	0026-1270			METHOD INFORM MED	Methods Inf. Med.		2006	45	2					139	145				7	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	022JM	WOS:000236051700002	16538278	
S	Nguyen, HN; Vu, TN; Ohn, SY; Park, YM; Han, MY; Kim, CW		Gelbukh, A; ReyesGarcia, CA		Nguyen, Ha-Nam; Vu, Trung-Nghia; Ohn, Syng-Yup; Park, Young-Mee; Han, Mi Young; Kim, Chul Woo			Feature elimination approach based on random forest for cancer diagnosis	MICAI 2006: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th Mexican International Conference on Artificial Intelligence (MICAI 2006)	NOV 13-17, 2006	Apizaco, MEXICO	SMIA, DGEST, INAOE, ITAM	Technol Inst Apizaco		CLASSIFICATION; SELECTION; TUMOR	The performance of learning tasks is very sensitive to the characteristics of training data. There are several ways to increase the effect of learning performance including standardization, normalization, signal enhancement, linear or non-linear space embedding methods, etc. Among those methods, determining the relevant and informative features is one of the key steps in the data analysis process that helps to improve the performance, reduce the generation of data, and understand the characteristics of data. Researchers have developed the various methods to extract the set of relevant features but no one method prevails. Random Forest, which is an ensemble classifier based on the set of tree classifiers, turns out good classification performance. Taking advantage of Random Forest and using wrapper approach first introduced by Kohavi et al, we propose a new algorithm to find the optimal subset of features. The Random Forest is used to obtain the feature ranking values. And these values are applied to decide which features are eliminated in the each iteration of the algorithm. We conducted experiments with two public datasets: colon cancer and leukemia cancer. The experimental results of the real world data showed that the proposed method results in a higher prediction rate than a baseline method for certain data sets and also shows comparable and sometimes better performance than the feature selection methods widely used.	Hankuk Aviat Univ, Dept Comp & Informat Engn, Seoul, South Korea	Nguyen, HN (reprint author), Hankuk Aviat Univ, Dept Comp & Informat Engn, Seoul, South Korea.	namnhvn@gmail.com; nghiavtr@gmail.com; syohn@hau.ac.kr; Young-Mee.Park@roswellpark.org; myhan703@hanmail.net; cwkim@plaza.snu.ac.kr	KIM, Chul-Woo/F-7008-2011; Vu, Trung Nghia/	Vu, Trung Nghia/0000-0001-7945-5750			Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHEN XW, 2003, IEEE COMP SOC BIOINF, P504; DAS S, 2001, P 18 ICML; Doak J., 1992, CSE9218 U CAL DEP CO; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Frohlich H, 2003, PROC INT C TOOLS ART, P142, DOI 10.1109/TAI.2003.1250182; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Mehta M, 1996, P 5 INT C EXT DAT TE, P18; NG AY, 1989, P 15 INT C MACH LEAR; NGUYEN HN, 2005, P 1 INT C NAT COMP; SU T, 2002, P INT JOINT C NEUR N, P286; TORKKOLA K, 2004, 7 INT IEEE C INT TRA, P636; WU YM, 2004, P 2004 IEEE COMP SOC, V2, P251; XING E, 2001, P 18 ICML; Zhang HP, 2003, P NATL ACAD SCI USA, V100, P4168, DOI 10.1073/pnas.0230559100	19	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-49026-5	LECT NOTES ARTIF INT			2006	4293						532	542				11	Computer Science, Artificial Intelligence	Computer Science	BFU02	WOS:000244587700050		
S	Tan, PJ; Dowe, DL		Gelbukh, A; ReyesGarcia, CA		Tan, Peter J.; Dowe, David L.			Decision forests with oblique decision trees	MICAI 2006: Advances in Artificial Intelligence, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	5th Mexican International Conference on Artificial Intelligence (MICAI 2006)	NOV 13-17, 2006	Apizaco, MEXICO	SMIA, DGEST, INAOE, ITAM	Technol Inst Apizaco		MML INFERENCE; MULTIWAY JOINS; CLASSIFIERS; GRAPHS	Ensemble learning schemes have shown impressive increases in prediction accuracy over single model schemes. We introduce a new decision forest learning scheme, whose base learners are Minimum Message Length (MML) oblique decision trees. Unlike other tree inference algorithms, MML oblique decision tree learning does not over-grow the inferred trees. The resultant trees thus tend to be shallow and do not require pruning. MML decision trees are known to be resistant to over-fitting and excellent at probabilistic predictions. A novel weighted averaging scheme is also proposed which takes advantage of high probabilistic prediction accuracy produced by MML oblique decision trees. The experimental results show that the new weighted averaging offers solid improvement over other averaging schemes, such as majority vote. Our MML decision forests scheme also returns favourable results compared to other ensemble learning algorithms on data sets with binary classes.	Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia	Tan, PJ (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia.						Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COMLEY JW, 2005, UNPUB ADV MINIMUM DE, P265; Comley J.W., 2003, P HAW INT C STAT REL; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T., 1998, AI MAG, V18, P97; Dowe D. L., 1996, 3 AUSTR C MATH COMP, P233; DOWE DL, 1998, 14 AUSTR STAT C ASC1, P144; DOWE DL, IN PRESS BRIT J PHIL; DOWE DL, 1993, 93190 MON U DEP COMP; FERRI C, 2004, P 21 INT C MACH LEAR, P106; Frank E., 2005, DATA MINING PRACTICA; Freund Y., 1996, INT C MACH LEARN, P148; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; MEHTA M, 1995, 1 INT C KNOWL DISC D, P216; Melville P., 2004, J INFORM FUSION SPEC, V6, P99; Needham S.L., 2001, P 8 INT WORKSH ART I, P253; OLIVER JJ, 1991, WORKSH 8 INT JOINT C; Oliver J. J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Quinlan J.R., 1992, C4 5 PROGRAMS MACHIN; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Tan PJ, 2002, LECT NOTES ARTIF INT, V2557, P131; Tan PJ, 2004, LECT NOTES ARTIF INT, V3339, P1082; Tan PJ, 2003, LECT NOTES ARTIF INT, V2903, P269; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; WALLACE CS, 1968, COMPUT J, V11, P185; Wallace C.S., 2005, STAT INDUCTIVE INFER; Wallace CS, 1999, COMPUT J, V42, P270, DOI 10.1093/comjnl/42.4.270	33	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-49026-5	LECT NOTES ARTIF INT			2006	4293						593	603				11	Computer Science, Artificial Intelligence	Computer Science	BFU02	WOS:000244587700056		
S	Kim, DS; Lee, SM; Park, JS		Gelbukh, A; ReyesGarcia, CA		Kim, Dong Seong; Lee, Sang Min; Park, Jong Son			Toward lightweight detection and visualization for denial of service attacks	MICAI 2006: Advances in Artificial Intelligence, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	5th Mexican International Conference on Artificial Intelligence (MICAI 2006)	NOV 13-17, 2006	Apizaco, MEXICO	SMIA, DGEST, INAOE, ITAM	Technol Inst Apizaco		INTRUSION DETECTION SYSTEM; SELECTION	In this paper, we present a lightweight detection and visualization methodology for Denial of Service (DoS) attacks. First, we propose a new approach based on Random Forest (RF) to detect DoS attacks. The classifycation accuracy of RF is comparable to that of Support Vector Machines (SVM). RF is also able to produce the importance value of individual feature. We adopt RF to select intrinsic important features for detecting DoS attacks in a lightweight way. And then, with selected features, we plot both DoS attacks and normal traffics in 2 dimensional space using Multi-Dimensional Scaling (MDS). The visualization results show that simple MDS can help one to visualize DoS attacks without any expert domain knowledge. The experimental results on the KDD 1999 intrusion detection dataset validate the possibility of our approach.	Hankuk Aviat Univ, Network Secur Lab, Seoul, South Korea	Kim, DS (reprint author), Hankuk Aviat Univ, Network Secur Lab, Seoul, South Korea.						Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DASH M, FEATURE SELECTION CL; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; HALL MA, FEATURE SUBSET SELEC; Kim DS, 2005, LECT NOTES COMPUT SC, V3498, P415; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; NOELIA SM, NEW WRAPPER METHOD F; Park JS, 2005, LECT NOTES COMPUT SC, V3822, P279; SABHNANI M, 2004, INTELLIGENT ANAL; Sung A. H., 2003, Proceedings 2003 Symposium on Applications and the Internet, DOI 10.1109/SAINT.2003.1183050; YOUNG FW, 1994, THEORV APPL MULTIDIM	13	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-49026-5	LECT NOTES ARTIF INT			2006	4293						632	640				9	Computer Science, Artificial Intelligence	Computer Science	BFU02	WOS:000244587700060		
S	Goebel, KF; Hu, X; Eklund, NHW; Yan, WZ		Dasarathy, BV		Goebel, Kai F.; Hu, Xiao; Eklund, Neil H. W.; Yan, Weizhong			Fusing diverse monitoring algorithms for robust change detection	MULTISENSOR, MULTISOURCE INFORMATIN FUSION: ARCHITECTURES, ALGORITHMS, AND APPLICATIONS 2006	Proceedings of SPIE		English	Proceedings Paper	Conference on Multisensor, Multisource Information Fusion	APR 19-20, 2006	Kissimmee, FL	SPIE		change detection; diagnostics; abnormal condition detection; information fusion; classifier fusion	ENSEMBLES	Change detection is an important task in remotely monitoring and diagnosing equipment and other processes. Specifically, early detection of differences that indicate abnormal conditions has the promise to provide considerable savings in averting secondary damage and preventing system outage. Of course, accurate early detection has to be balanced against the successful rejection of false positive alarms. In noisy environments, such as aircraft engine monitoring, this proves to be a difficult undertaking for any one algorithm. In this paper, we investigate the performance improvement that can be gained by aggregating the information from a set of diverse change detection algorithms. Specifically, we examine a set of change detectors that utilize a variety of different techniques such as neural nets, random forests, and support vector machines. The different techniques have different detection sensitivities and different false positive rates. For fusion, we consider the Dempster regression technique that operates well for time series as well as averaging schemes, and a meta-classifiers. We provide results using illustrative examples from aircraft engine monitoring.	GE Global Res, Niskayuna, NY 12309 USA	Goebel, KF (reprint author), GE Global Res, 1 Res Circle, Niskayuna, NY 12309 USA.	goebe1k@crd.ge.com					ASHBY M, 2000, P IEEE AER C, P309; Bishop C.M., 1995, NEURAL NETWORKS PATT; BREIMAN L, 2004, RANDOM FOREST TOOLBO; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cawley G. C., 2000, SUPPORT VECTOR MACHI; Dietterich TG, 1997, AI MAG, V18, P97; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gerra-Salcedo C., 1999, P GEN EV COMP C, P236; Goebel K, 2001, AI EDAM, V15, P335, DOI 10.1017/S0890060401154077; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Haykin S., 1999, NEURAL NETWORKS COMP; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HU X, 2006, IN PRESS P 60 MFPT; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; LOSKIEWICZBUCZA.A, 1994, P 3 IEEE C FUZZ SYST, V2, P1412; Mao J., 1998, P IEEE INT JOINT C N, V3, P1828; Nadaraya EN, 1965, THEOR PROBAB APPL, V10, P186; NELSON M, 1999, P INF DEC CONTR, P395; Opitz D. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Petit-Renaud S, 2004, INT J APPROX REASON, V35, P1, DOI 10.1016/S0888-613X(03)00056-2; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rao N. S. V., 2000, Information Fusion, V1, DOI 10.1016/S1566-2535(00)00004-X; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Shimshoni Y, 1998, IEEE T SIGNAL PROCES, V46, P1194, DOI 10.1109/78.668782; Smets P., 1994, ADV DEMPSTER SHAFER, P5; TUMER K, 1999, P INT JOINT C NEUR N; Vapnik VN, 1995, NATURE STAT LEARNING; Yan WZ, 2002, P SOC PHOTO-OPT INS, V4733, P88, DOI 10.1117/12.475498	32	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-6298-5	PROC SPIE			2006	6242								62420M	10.1117/12.665922		11	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BES05	WOS:000239225800021		
S	Shen, KQ; Ong, CJ; Li, XP; Zheng, H; Wilder-Smith, EPV		King, I; Wang, J; Chan, L; Wang, DL		Shen, Kai Quan; Ong, Chong Jin; Li, Xiao Ping; Zheng, Hui; Wilder-Smith, Einar P. V.			Feature selection using SVM probabilistic outputs	NEURAL INFORMATION PROCESSING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	13th International Conference on Neural Informational Processing	OCT 03-06, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, K C Wong Educ Fdn				A ranking criterion based on the posterior probability is proposed for feature selection on support vector machines (SVM). This criterion has the advantage that it is directly related to the importance of the features. Four approximations are proposed for the evaluation of this criterion. The performances of these approximations, used in the recursive feature elimination (RFE) approach, are evaluated on various artificial and real-world problems. Three of the proposed approximations show good performances consistently, with one having a slight edge over the other two. Their performances compare favorably with feature selection methods in the literature.	Natl Univ Singapore, Dept Mech Engn, Singapore 117576, Singapore; Natl Univ Singapore, Duv Bioengn, Singapore 117576, Singapore; Natl Univ Singapore, Dept Med, Singapore 119074, Singapore	Shen, KQ (reprint author), Natl Univ Singapore, Dept Mech Engn, EA 04-24,9 Engn Dr 1, Singapore 117576, Singapore.	shen@nus.edu.sg; mpeongcj@nus.edu.sg; mpelixp@nus.edu.sg; zhenghui@nus.edu.sg; mdcwse@nus.edu.sg	Wilder-Smith, Einar/	Wilder-Smith, Einar/0000-0003-3402-7503			Boser B., 1992, 5 ANN ACM WORKSH COL, P144; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; GUYON I, 2003, NIPS 2003 FEATURE SE; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 1996, CLASSIFICATION PAIRW; Lin H-T, 2003, NOTE PLATTS PROBABIL; Platt J., 2000, ADV LARGE MARGIN CLA; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753706; Ratsch G., 1999, NEURAL NETWORKS SIGN, V9, P41, DOI DOI 10.1109/NNSP.1999.788121; RATSCH G, BENCHMARK REPOSITORY; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; Vapnik V.N., 1982, ESTIMATION DEPENDENC; WESTON J, 2001, ADV NEURAL INFORMATI, V13	20	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-46479-4	LECT NOTES COMPUT SC			2006	4232						782	791				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFG80	WOS:000241790100087		
S	Lemaire, V; Feraud, R		King, I; Wang, J; Chan, L; Wang, DL		Lemaire, Vincent; Feraud, Raphael			Driven forward features selection: A comparative study on neural networks	NEURAL INFORMATION PROCESSING, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	13th International Conference on Neural Informational Processing	OCT 03-06, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, K C Wong Educ Fdn			REGRESSION	In the field of neural networks, feature selection has been studied for the last ten years and classical as well as original methods have been employed. This paper reviews the efficiency of four approaches to do a driven forward features selection on neural networks. We assess the efficiency of these methods compare to the simple Pearson criterion in case of a regression problem.	France Telecom, R&D Lannion, Bagneux, France	Lemaire, V (reprint author), France Telecom, R&D Lannion, Bagneux, France.	vincent.lemaire@orange-ft.com					Breiman L., 2001, MACHINE LEARNING, V45; Burkitt A. N., 1992, Complex Systems, V6; Feraud R, 2002, NEURAL NETWORKS, V15, P237, DOI 10.1016/S0893-6080(01)00127-7; GUYON I, 2006, IN PRESS FEATURE EXT; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Kohavi R., 1997, ARTIFICIAL INTELLIGE, V97; LEMAIRE V, 2004, INT JOINT C NEUR NET; LERAY P, 1998, LIP6; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Miller A.J., 1990, SUBSET SELECTION REG; MOODY J, 1994, PREDICTION RISK ARCH; REFENES A, 1996, P NNCM 96; REFENES AN, 1994, NEURAL NETWORKS, V7, P375; Ruck D. W., 1990, J NEURAL NETWORK COM, V2, P40; THOMPSON ML, 1978, INT STAT REV, V46, P129, DOI 10.2307/1402809; YACOUB M, 1997, ANNIE, P527; 2003, J MACHINE LEARNING R, V3	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-46481-6	LECT NOTES COMPUT SC			2006	4233						693	702				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BFG61	WOS:000241753100077		
S	Nguyen, HN; Ohn, SY		King, I; Wang, J; Chan, L; Wang, DL		Nguyen, Ha-Nam; Ohn, Syng-Yup			DRFE: Dynamic Recursive Feature Elimination for gene identification based on Random Forest	NEURAL INFORMATION PROCESSING, PT 3, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	13th International Conference on Neural Informational Processing	OCT 03-06, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, K C Wong Educ Fdn			CLASSIFICATION; SELECTION; TUMOR	Determining the relevant features is a combinatorial task in various fields of machine learning such as text mining, bioinformatics, pattern recognition, etc. Several scholars have developed various methods to extract the relevant features but no method is really superior. Breiman proposed Random Forest to classify a pattern based on CART tree algorithm and his method turns out good results compared to other classifiers. Taking advantages of Random Forest and using wrapper approach which was first introduced by Kohavi et. al, we propose an algorithm named Dynamic Recursive Feature Elimination (DRFE) to find the optimal subset of features for reducing noise of the data and increasing the performance of classifiers. In our method, we use Random Forest as induced classifier and develop our own defined feature elimination function by adding extra terms to the feature scoring. We conducted experiments with two public datasets: Colon cancer and Leukemia cancer. The experimental results of the real world data showed that the proposed method has higher prediction rate compared to the baseline algorithm. The obtained results are comparable and sometimes have better performance than the widely used classification methods in the same literature of feature selection.	Hankuk Aviat Univ, Dept Comp Engn, Seoul, South Korea	Nguyen, HN (reprint author), Hankuk Aviat Univ, Dept Comp Engn, Seoul, South Korea.	nghanam@hau.ac.kr; syohn@hau.ac.kr					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHEN XW, 2003, IEEE COMP SOC BIOINF, P504; DAS S, 2001, P 18 ICML; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Frohlich H, 2003, PROC INT C TOOLS ART, P142, DOI 10.1109/TAI.2003.1250182; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Mehta M, 1996, P 5 INT C EXT DAT TE, P18; NG AY, 1998, P 15 INT C MACH LEAR; NGUYEN HN, 2005, P 5 INT C NAT COMP; SU T, 2002, P INT JOINT C NEUR N, P286; TORKKOLA K, 2004, 7 INT IEEE C INT TRA, P636; WU YM, 2004, P 2004 IEEE COMP SOC, V2, P251; XING E, 2001, P 18 ICML; Zhang HP, 2003, P NATL ACAD SCI USA, V100, P4168, DOI 10.1073/pnas.0230559100	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-46484-0	LECT NOTES COMPUT SC			2006	4234						1	10				10	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BFG63	WOS:000241759000001		
J	Turner, JA; Smyth, P; Macciardi, F; Fallon, JH; Kennedy, JL; Potkin, SG				Turner, JA; Smyth, P; Macciardi, F; Fallon, JH; Kennedy, JL; Potkin, SG			Imaging phenotypes and genotypes in schizophrenia	NEUROINFORMATICS			English	Review						schizophrenia; neuroimaging; genetics; endophenotypes; data mining	DINUCLEOTIDE REPEAT POLYMORPHISM; CASE-CONTROL ASSOCIATION; CELL-ADHESION MOLECULE; GLYCOPROTEIN MOG GENE; FALSE DISCOVERY RATE; D3 RECEPTOR GENE; FMRI TIME-SERIES; NEUROTROPHIC FACTOR; LINKAGE-DISEQUILIBRIUM; BIPOLAR DISORDER	Schizophrenia is associated with subtle structural and functional brain abnormalities. Both recent and classical data suggest that it is a heterogeneous disorder that is clearly heritable. The cause and course of schizophrenia are poorly understood, and classical categories of clinical symptoms have not been particularly useful in identifying its pathophysiology or predicting its treatment. The possible genetic risk factors for schizophrenia are numerous; however, the connection between the genotype and the time-course, or the multifaceted symptoms of the disease, has yet to be established. Brain imaging methods that study the structure or function of the cortical and subcortical regions have also identified distinct patterns that distinguish schizophrenics from controls, and that may identify meaningful subtypes of schizophrenia. The predictive relationship between these imaging phenotypes and disease characteristics such as treatment response is only beginning to be revealed. The emergence of the field of imaging genetics, combining genetic, and neuroimaging data, holds much promise for the deeper understanding and improved treatment of diseases such as schizophrenia. In this article we review some of the key findings in imaging phenotyping and genotyping of schizophrenia, and the initial endeavors at their combination into more meaningful and predictive patterns, or endophenotypes identifying the relationships among clinical symptoms, course, genes, and the underlying pathophysiology.	Univ Calif Irvine, Dept Psychiat & Human Behav, Irvine, CA 92697 USA; Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA; Univ Milan, Policlin MultiMedica, Milan, Italy; Univ Milan, Dept Sci & Biomed Technol, Milan, Italy; Univ Calif Irvine, Dept Anat & Neurobiol, Irvine, CA 92697 USA; Univ Toronto, Neurosci Res Dept, CAMH, Toronto, ON M5T 1R8, Canada; Univ Toronto, Neurogenet Sect, CAMH, Toronto, ON M5T 1R8, Canada	Potkin, SG (reprint author), Univ Calif Irvine, Dept Psychiat & Human Behav, Irvine, CA 92697 USA.	sgpotkin@uci.edu	Potkin, Steven/A-2021-2013; Turner, Jessica/H-7282-2015; Potkin, Steven/	Turner, Jessica/0000-0003-0076-8434; Potkin, Steven/0000-0003-1028-1013			Adler LE, 1999, BIOL PSYCHIAT, V46, P8, DOI 10.1016/S0006-3223(99)00085-2; Anokhin AP, 2003, NEUROSCI LETT, V353, P45, DOI 10.1016/j.neulet.2003.09.014; Baldi P, 2002, DNA MICROARRAYS GENE; Baldi P., 2001, BIOINFORMATICS MACHI; BARBEAU D, 1995, P NATL ACAD SCI USA, V92, P2785, DOI 10.1073/pnas.92.7.2785; Basile VS, 2002, HUM MOL GENET, V11, P2517, DOI 10.1093/hmg/11.20.2517; Basile VS, 1999, NEUROPSYCHOPHARMACOL, V21, P17, DOI 10.1016/S0893-133X(98)00114-6; BECHARA A, 1994, COGNITION, V50, P7, DOI 10.1016/0010-0277(94)90018-3; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Berry M.J.A., 2004, DATA MINING TECHNIQU; Bookheimer SY, 2000, NEW ENGL J MED, V343, P450, DOI 10.1056/NEJM200008173430701; Botstein D, 2003, NAT GENET, V33, P228, DOI 10.1038/ng1090; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown BW, 1997, STAT MED, V16, P2511, DOI 10.1002/(SICI)1097-0258(19971130)16:22<2511::AID-SIM693>3.0.CO;2-4; Buchsbaum MS, 2002, SCHIZOPHR RES, V55, P25, DOI 10.1016/S0920-9964(01)00206-7; Bunney BG, 1997, J PSYCHIAT RES, V31, P159, DOI 10.1016/S0022-3956(96)00038-6; Cadez I, 2003, DATA MIN KNOWL DISC, V7, P399, DOI 10.1023/A:1024992613384; Callicott JH, 1998, BIOL PSYCHIAT, V44, P941, DOI 10.1016/S0006-3223(98)00264-9; Cannon TD, 2000, AM J HUM GENET, V67, P369, DOI 10.1086/303006; Cao XH, 2004, NEUROINFORMATICS, V2, P101, DOI 10.1385/NI:2:1:101; Cardon LR, 2001, NAT REV GENET, V2, P91, DOI 10.1038/35052543; Carlson CS, 2003, NAT GENET, V33, P518, DOI 10.1038/ng1128; Caspi A, 2003, SCIENCE, V301, P386, DOI 10.1126/science.1083968; Chakravarti A, 1999, NAT GENET, V21, P56, DOI 10.1038/4482; Chumakov I, 2002, P NATL ACAD SCI USA, V99, P13675, DOI 10.1073/pnas.182412499; Chung C, 2003, SYNAPSE, V50, P29, DOI 10.1002/syn.10228; Cotter D, 1998, NEUROREPORT, V9, P1379, DOI 10.1097/00001756-199805110-00024; Cribbie RA, 2003, BRIT J MATH STAT PSY, V56, P167, DOI 10.1348/000711003321645412; Cusi D, 1997, LANCET, V349, P1353, DOI 10.1016/S0140-6736(97)01029-5; Daly MJ, 2002, CELL, V109, P283, DOI 10.1016/S0092-8674(02)00742-0; Davidson S, 2000, NAT BIOTECHNOL, V18, P1134, DOI 10.1038/81100; Davis KL, 2003, ARCH GEN PSYCHIAT, V60, P443, DOI 10.1001/archpsyc.60.5.443; Davis KL, 2003, LANCET, V362, P758, DOI 10.1016/S0140-6736(03)14297-3; De Luca V, 2004, NEUROPSYCHOPHARMACOL, V29, P1522, DOI 10.1038/sj.npp.1300466; DeSilva U, 1997, GENOME RES, V7, P157, DOI 10.1101/gr.7.2.157; Devlin B, 1999, BIOMETRICS, V55, P997, DOI 10.1111/j.0006-341X.1999.00997.x; Devlin B, 2003, GENET EPIDEMIOL, V25, P36, DOI 10.1002/gepi.10237; DOHERTY P, 1990, NATURE, V343, P464, DOI 10.1038/343464a0; Drysdale CM, 2000, P NATL ACAD SCI USA, V97, P10483, DOI 10.1073/pnas.97.19.10483; Durany N, 2001, SCHIZOPHR RES, V52, P79, DOI 10.1016/S0920-9964(00)00084-0; Tamminga CA, 2002, AM J PSYCHIAT, V159, P12; Egan MF, 2001, BIOL PSYCHIAT, V50, P98, DOI 10.1016/S0006-3223(01)01133-7; Egan MF, 2001, P NATL ACAD SCI USA, V98, P6917, DOI 10.1073/pnas.111134598; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fallon JH, 2003, CLIN NEUROSCI RES, V3, P77, DOI 10.1016/S1566-2772(03)00022-7; Fan JB, 2002, MOL PSYCHIATR, V7, P100, DOI 10.1038/sj/mp/4000945; Fatemi SH, 2000, MOL PSYCHIATR, V5, P654, DOI 10.1038/sj.mp.4000783; Freedman R, 1997, P NATL ACAD SCI USA, V94, P587, DOI 10.1073/pnas.94.2.587; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Friston KJ, 2003, NEUROIMAGE, V19, P1240, DOI 10.1016/S1053-8119(03)00144-7; Gabriel SB, 2002, SCIENCE, V296, P2225, DOI 10.1126/science.1069424; Garver DL, 2000, J CLIN PSYCHIAT, V61, P964; Genovese CR, 2002, NEUROIMAGE, V15, P870, DOI 10.1006/nimg.2001.1037; Goodnight Charles J., 2000, P129; Gottesman II, 2003, AM J PSYCHIAT, V160, P636, DOI 10.1176/appi.ajp.160.4.636; Guidotti A, 2000, ARCH GEN PSYCHIAT, V57, P1061, DOI 10.1001/archpsyc.57.11.1061; GUR RE, 1995, ARCH GEN PSYCHIAT, V52, P657; Hakak Y, 2001, P NATL ACAD SCI USA, V98, P4746, DOI 10.1073/pnas.081071198; Hand D. J., 2001, PRINCIPLES DATA MINI; Harrelson GL, 2005, ATHLET THER TODAY, V10, P5; Harrison PJ, 1998, LANCET, V352, P1669, DOI 10.1016/S0140-6736(98)03341-8; Hastie T., 2001, ELEMENTS STAT LEARNI; Hawi Z, 1998, PSYCHIAT RES, V81, P111, DOI 10.1016/S0165-1781(98)00076-6; Heberlein AS, 2004, J COGNITIVE NEUROSCI, V16, P1143, DOI 10.1162/0898929041920423; Heckers S, 1999, ARCH GEN PSYCHIAT, V56, P1117, DOI 10.1001/archpsyc.56.12.1117; Herskovits EH, 2003, NEUROIMAGE, V19, P1664, DOI 10.1016/S1053-8119(03)00231-3; Herskovits EH, 2004, IEEE T MED IMAGING, V23, P723, DOI 10.1109/TMI.2004.826949; Herskovits EH, 2000, METHOD INFORM MED, V39, P291; Hodgkinson CA, 2004, AM J HUM GENET, V75, P862, DOI 10.1086/425586; HOHE MR, 2000, HUM MOL GENET, V19, P2895; Honer WG, 1997, NEUROSCIENCE, V78, P99, DOI 10.1016/S0306-4522(96)00489-7; Hynes M, 1999, CURR OPIN NEUROBIOL, V9, P26, DOI 10.1016/S0959-4388(99)80004-X; Jain A. K., 1988, ALGORITHMS CLUSTERIN; JESTE DV, 1982, BIOL PSYCHIAT, V17, P199; Joosten PHLJ, 2001, NAT GENET, V27, P215, DOI 10.1038/84867; Jordan M., 1999, LEARNING GRAPHICAL M; Karson CN, 1999, MOL PSYCHIATR, V4, P39, DOI 10.1038/sj.mp.4000459; Katsanis J, 2000, PSYCHOPHYSIOLOGY, V37, P724, DOI 10.1017/S0048577200991480; Kennedy JL, 2003, SCIENCE, V302, P822, DOI 10.1126/science.1092132; KENNEDY JL, 1992, NUCLEIC ACIDS RES, V20, P1171, DOI 10.1093/nar/20.5.1171; Kilpatrick L, 2003, NEUROIMAGE, V20, P2091, DOI 10.1016/j.neuroimage.2003.08.006; Kim UK, 2003, SCIENCE, V299, P1221, DOI 10.1126/science.1080190; Kleinbaum D.G., 1994, LOGISTIC REGRESSION; KLEMPAN TA, 2005, NEURODEVELOPMENT SCH; Kohane I., 2003, MICROARRAYS INTEGRAT, Vfirst; Kohtz JD, 1998, DEVELOPMENT, V125, P5079; Krawczak M, 2001, AM J HUM GENET, V69, P361, DOI 10.1086/321973; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Lawrie SM, 1998, BRIT J PSYCHIAT, V172, P110, DOI 10.1192/bjp.172.2.110; Lee KB, 2001, PSYCHIAT RES, V104, P11, DOI 10.1016/S0165-1781(01)00294-3; Lerer B, 2002, NEUROPSYCHOPHARMACOL, V27, P105, DOI 10.1016/S0893-133X(02)00293-2; Letovsky SI, 1998, AM J NEURORADIOL, V19, P1869; Lin KK, 2004, P NATL ACAD SCI USA, V101, P15955, DOI 10.1073/pnas.0407114101; Lohmueller KE, 2003, NAT GENET, V33, P177, DOI 10.1038/ng1071; MALFROY L, 1995, HUM GENET, V96, P737, DOI 10.1007/BF00210310; MALFROY L, 1995, HUM GENET, V96, P738; Marchini J, 2004, NEUROIMAGE, V22, P1203, DOI 10.1016/j.neuroimage.2004.03.030; MARTIN LF, 2004, PSYCHOPHARMACOLOGY B; Martucci L, 2003, AM J MED GENET B, V119B, P24, DOI 10.1002/ajmg.b.20014; MCGINNIS RE, 2001, NAT GENET, V28, P129; McGinnis RE, 2001, NAT GENET, V28, P128, DOI 10.1038/88839; McLachlan G, 2002, FINITE MIXTURE MODEL; McLachlan G.J., 2004, ANAL MICROARRAY GENE; Mechelli A, 2003, J COGNITIVE NEUROSCI, V15, P925, DOI 10.1162/089892903770007317; Meltzer HY, 2003, ARCH GEN PSYCHIAT, V60, P82; Miyaoka T, 1999, SCHIZOPHR RES, V38, P1, DOI 10.1016/S0920-9964(98)00179-0; Mohn AR, 1999, CELL, V98, P427, DOI 10.1016/S0092-8674(00)81972-8; Muglia P, 2003, MOL PSYCHIATR, V8, P146, DOI 10.1038/sj.mp.4001221; Mukaetova-Ladinska EB, 2002, NEUROSCI LETT, V317, P161, DOI 10.1016/S0304-3940(01)02458-2; Murphy K., 2002, THESIS UC BERKELEY; Nadri C, 2004, SCHIZOPHR RES, V71, P377, DOI 10.1016/j.schres.2004.02.020; NANKO S, 1994, ACTA PSYCHIAT SCAND, V89, P390, DOI 10.1111/j.1600-0447.1994.tb01534.x; Nichols T, 2003, STAT METHODS MED RES, V12, P419, DOI 10.1191/0962280203sm341ra; Northoff G, 2004, SCHIZOPHRENIA BULL, V30, P405; Nyholt DR, 2001, HUM GENET, V109, P564, DOI 10.1007/s00439-001-0611-4; Ohmori O, 2000, NEUROSCI LETT, V279, P125, DOI 10.1016/S0304-3940(99)00970-2; Ott J, 2000, AM J HUM GENET, V67, P289, DOI 10.1086/303031; Pearl J., 1988, PROBABILISTIC REASON; Peltonen L, 2001, SCIENCE, V291, P1224, DOI 10.1126/science.291.5507.1224; Penny W, 2003, NEUROIMAGE, V19, P727, DOI 10.1016/S1053-8119(03)00071-5; Penny WD, 2005, NEUROIMAGE, V24, P350, DOI 10.1016/j.neuroimage.2004.08.034; Perneger TV, 1998, BRIT MED J, V316, P1236; Pevzner P., 2000, COMPUTATIONAL MOL BI; Potkin SG, 2002, AM J PSYCHIAT, V159, P227, DOI 10.1176/appi.ajp.159.2.227; Potkin SG, 2003, BIOL PSYCHIAT, V54, P444, DOI 10.1016/S0006-3223(03)00178-1; Potkin SG, 2003, MOL PSYCHIATR, V8, P109, DOI 10.1038/sj.mp.4001191; Prasad KMR, 2005, MOL PSYCHIATR, V10, P213, DOI 10.1038/sj.mp.4001562; Prasad KMR, 2004, AM J PSYCHIAT, V161, P1612, DOI 10.1176/appi.ajp.161.9.1612; PRITCHARD JK, 2001, AM J HUM GENET, V46, P222; Pröschel M, 1992, Hum Mol Genet, V1, P353, DOI 10.1093/hmg/1.5.353-a; Purdon PL, 1998, HUM BRAIN MAPP, V6, P239, DOI 10.1002/(SICI)1097-0193(1998)6:4<239::AID-HBM4>3.0.CO;2-4; Reich DE, 2003, NAT GENET, V33, P457, DOI 10.1038/ng1133; Rice DS, 2001, ANNU REV NEUROSCI, V24, P1005, DOI 10.1146/annurev.neuro.24.1.1005; Risch N, 2002, GENOME BIOL, V3; Risch N, 1996, SCIENCE, V273, P1516, DOI 10.1126/science.273.5281.1516; RISCH N, 1996, SCIENCE, V273, P1517; Roberts NA, 2004, COGN AFFECT BEHAV NE, V4, P307, DOI 10.3758/CABN.4.3.307; Rodriguez MA, 2000, P NATL ACAD SCI USA, V97, P3550, DOI 10.1073/pnas.050589797; Rothman KJ, 1998, MODERN EPIDEMIOLOGY, P329; Sasaki T, 1997, AM J MED GENET, V74, P443, DOI 10.1002/(SICI)1096-8628(19970725)74:4<443::AID-AJMG17>3.3.CO;2-J; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B., 2004, KERNEL METHODS COMPU; SCHWABE D, 1995, LOW G, V6, P11; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; SELEMON LD, 1995, ARCH GEN PSYCHIAT, V52, P805; Sham P C, 1998, Stat Methods Med Res, V7, P279, DOI 10.1191/096228098677382724; Shenton ME, 2001, SCHIZOPHR RES, V49, P1, DOI 10.1016/S0920-9964(01)00163-3; Sivagnansundaram S, 2003, CLIN NEUROSCI RES, V3, P5, DOI 10.1016/S1566-2772(03)00014-8; Sklar P, 2001, NAT GENET, V28, P126, DOI 10.1038/88836; Small GW, 2002, J MOL NEUROSCI, V19, P17, DOI 10.1007/s12031-002-0005-7; Small GW, 2000, P NATL ACAD SCI USA, V97, P6037, DOI 10.1073/pnas.090106797; Smyth P, 2000, STAT METHODS MED RES, V9, P309, DOI 10.1191/096228000701555181; Smyth P, 1997, NEURAL COMPUT, V9, P227, DOI 10.1162/neco.1997.9.2.227; Smyth P, 2002, COMMUN ACM, V45, P33; Speed T, 2003, STAT ANAL GENE EXPRE; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Spinks R, 2004, AM J MED GENET B, V127B, P20, DOI 10.1002/ajmg.b.20175; Stober G, 1999, BIOL PSYCHIAT, V45, P1585, DOI 10.1016/S0006-3223(99)00024-4; Stone VE, 1998, J COGNITIVE NEUROSCI, V10, P640, DOI 10.1162/089892998562942; STRAUB RE, 1995, NAT GENET, V11, P287, DOI 10.1038/ng1195-287; Straub RE, 2002, AM J HUM GENET, V71, P337, DOI 10.1086/341750; Swift-Scanlan T, 2002, PSYCHIATR GENET, V12, P43, DOI 10.1097/00041444-200203000-00006; Tabor HK, 2002, NAT REV GENET, V3, P391, DOI 10.1038/nrg796; Tachikawa H, 2001, NEUROPSYCHOBIOLOGY, V43, P131, DOI 10.1159/000054880; Takahashi M, 2000, MOL PSYCHIATR, V5, P293, DOI 10.1038/sj.mp.4000718; Terwilliger JD, 1998, CURR OPIN BIOTECH, V9, P578, DOI 10.1016/S0958-1669(98)80135-3; Thome J, 1996, NEUROREPORT, V7, P1413, DOI 10.1097/00001756-199605310-00018; Thompson PM, 1998, BIOL PSYCHIAT, V43, P239, DOI 10.1016/S0006-3223(97)00204-7; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; TOGA A, 2000, BRAIN MAPPING METHOD; Tsuang Ming T., 1998, Kaohsiung Journal of Medical Sciences, V14, P405; TURETSKY B, 1995, ARCH GEN PSYCHIAT, V52, P1061; Tuulio-Henriksson A, 2000, Duodecim, V116, P1453; Ujike H, 2001, NEUROSCI LETT, V301, P41, DOI 10.1016/S0304-3940(01)01602-0; Vicente AM, 1997, MOL PSYCHIATR, V2, P65, DOI 10.1038/sj.mp.4000235; Wang JTL, 1999, PATTERN DISCOVERY BI; Wang WYS, 2003, GENET EPIDEMIOL, V24, P36, DOI 10.1002/gepi.10216; Wei J, 2000, NAT GENET, V25, P376, DOI 10.1038/78044; WEI J, 2000, NAT GENET, V25, P377; Weinberger DR, 1996, PHILOS T R SOC B, V351, P1495, DOI 10.1098/rstb.1996.0135; Weinberger DR, 2001, BIOL PSYCHIAT, V50, P825, DOI 10.1016/S0006-3223(01)01252-5; Weiss KM, 2000, NAT GENET, V26, P151, DOI 10.1038/79866; Winkler G., 2003, IMAGE ANAL RANDOM FI; WINOKUR G, 1975, PSYCHOPHARMACOL COMM, V1, P567; Wolkin A, 1996, AM J PSYCHIAT, V153, P346; Wong AHC, 2004, BIOL PSYCHIAT, V56, P24, DOI 10.1016/j.biopsych.2004.03.008; Wong AHC, 2003, MOL PSYCHIATR, V8, P156, DOI 10.1038/sj.mp.4001237; Wright P, 2001, SCHIZOPHR RES, V47, P1, DOI 10.1016/S0920-9964(00)00022-0; Xu JZ, 2001, AM J MED GENET, V105, P669, DOI 10.1002/ajmg.1549; Young IR, 1998, OCEAN ENG, V25, P261, DOI 10.1016/S0029-8018(97)00011-5; Zai G, 2005, GENES BRAIN BEHAV, V4, P2, DOI 10.1111/j.1601-183X.2004.00089.x; Zaykin DV, 2002, HUM HERED, V53, P79, DOI 10.1159/000057986	192	18	19	HUMANA PRESS INC	TOTOWA	999 RIVERVIEW DRIVE SUITE 208, TOTOWA, NJ 07512 USA	1539-2791			NEUROINFORMATICS	Neuroinformatics		2006	4	1					21	49		10.1385/NI:4:1:21		29	Computer Science, Interdisciplinary Applications; Neurosciences	Computer Science; Neurosciences & Neurology	015ER	WOS:000235535200003	16595857	
B	Florea, F; Rogozan, A; Bensrhair, A; Darmoni, S		Cernat, M; Nicolaide, A; Margineanu, I		Florea, F.; Rogozan, A.; Bensrhair, A.; Darmoni, S.			Comparison of feature-selection and classification techniques for medical image modality categorization	PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON OPTIMIZATION OF ELECTRICAL AND ELECTRONIC EQUIPMENT, VOL IV			English	Proceedings Paper	10th International Conference on Optimization of Electrical and Electronic Equipment (OPTIM 2006)	MAY 18-19, 2006	Brasov, ROMANIA	Transilvania Univ Brasov, Fac Elect Engn & Comp Sci, Politehn Univ Timisoara, Fac Elect Engn, Tech Univ Cluj-Napoca, Fac Elect Engn, IEEE, IEE, VDE			CONTENT-BASED RETRIEVAL; DATABASES	Today, medical images are representing a significant part of on-line medical knowledge and a valuable component of diagnosis and teaching. The information carried by the images attached to on-line medical documents is a significant criteria for the user when evaluating the documents relevance. Our research is focused on the automatic extraction of medical image knowledge, to provide semantic image information to the index of CISMeF heath resources (i.e documents). This paper address the extraction of the image medical modality by image feature representation, dimensionality reduction and categorization. Our experiments were conducted on a image database, containing six medical modalities. We compared the relative contribution in describing the image content, of some fundamental image texture and statistical features. Various feature selection methods were used to create a compact and relevant feature set, for a precise and fast classification. Classification accuracy of around 90% were noted with several classifiers, with a top performance of 90.16% for SVM.	[Florea, F.; Rogozan, A.; Bensrhair, A.; Darmoni, S.] INSA, LITIS Lab, Rouen, France	Florea, F (reprint author), INSA, LITIS Lab, Rouen, France.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ANTANI S, 2002, P 3 IND C COMP VIS G; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chu WW, 1998, IEEE T KNOWL DATA EN, V10, P872, DOI 10.1109/69.738355; El-Kwae EA, 2000, J DIGIT IMAGING, V13, P70; Goldberg D, 1989, GENETIC ALGORITHMS S; GULD M, 2004, P SPIE, V5371; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Jahne B., 1999, HDB COMPUTER VISION, V2; KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8; LANDWEHR N, 2003, ECML 2003; Lee T., 1996, IEEE T PATTERN ANAL, V18, P1; Lehmann TM, 2003, P SOC PHOTO-OPT INS, V5033, P440, DOI 10.1117/12.480677; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; MULLER H, 2003, P MED INF EUR C MIE; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661; Platt J., 1998, ADV KERNEL METHODS S; Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768; TANG TL, 2000, SPIE P, V3976; Zhang W., 1998, P IEEE WORKSH BIOM I, P221	21	0	0	TRANSILVANIA UNIV PRESS-BRASOV	BRASOV	BD EROILOR NR 9, BRASOV, RO-500030, ROMANIA			978-973-635-706-0				2006							161	168				8	Education, Scientific Disciplines; Engineering, Electrical & Electronic	Education & Educational Research; Engineering	BHU30	WOS:000256419100030		
B	Reif, DM; Motsinger, AA; McKinney, BA; Crowe, JE; Moore, JH			IEEE	Reif, David M.; Motsinger, Alison A.; McKinney, Brett A.; Crowe, James E., Jr.; Moore, Jason H.			Feature selection using a random forests classifier for the integrated analysis of multiple data types	Proceedings of the 2006 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology			English	Proceedings Paper	IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology	SEP 28-29, 2006	Toronto, CANADA			Random Forests (TM); gene-gene interactions; feature selection; multiple data types; data integration	SYSTEMS BIOLOGY; ADVERSE EVENTS; EPISTASIS; ASSOCIATION; DISEASES	Complex clinical phenotypes arise from the concerted interactions among the myriad components of a biological system. Therefore, comprehensive models can only be developed through the integrated study of multiple types of experimental data gathered from the system in question. The Random Forests (TM) (RF) method is adept at identifying relevant features having only slight main effects in high-dimensional data. This method is well-suited to integrated analysis, as relevant attributes may be selected from categorical or continuous data, and there may be interactions across data types. RF is a natural approach for studying gene-gene, gene-protein, or protein-protein interactions because importance scores for particular attributes take interactions into account. Thus, Random Forests is a promising solution to the analysis challenge posed by high-dimensional datasets including interactions among attributes of different types. In this study, we characterize the performance of RF on a range of simulated genetic and/or proteomic datasets. We compare the performance of RF in identifying relevant attributes when given genetic data alone, proteomic data alone, or a combined dataset of genetic plus proteomic data. Our results indicate that utilizing multiple data types is beneficial when the disease model is complex and the phenotypic outcome-associated data type is unknown. The results of this study also show that RF is adept at identifying relevant features in high-dimensional data with small main effects and low heritability.	Vanderbilt Univ, Dept Mol Physiol & Biophys, Ctr Human Genet Res, Nashville, TN 37232 USA	Reif, DM (reprint author), Vanderbilt Univ, Dept Mol Physiol & Biophys, Ctr Human Genet Res, Nashville, TN 37232 USA.		Reif, David/; Crowe, James/B-5549-2009	Reif, David/0000-0001-7815-6767; Crowe, James/0000-0002-0049-1079			BREIMAN L, 1987, CLASSIFICATION REGR; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2004, RANDOM FORESTS; Bureau A, 2005, GENET EPIDEMIOL, V28, P171, DOI 10.1002/gepi.20041; Culverhouse R, 2002, AM J HUM GENET, V70, P461, DOI 10.1086/338759; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Hood L, 2003, MECH AGEING DEV, V124, P9, DOI 10.1016/S0047-6374(02)00164-1; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Kooperberg C, 2005, GENET EPIDEMIOL, V28, P157, DOI 10.1002/gepi.20042; Lazarou J, 1998, JAMA-J AM MED ASSOC, V279, P1200, DOI 10.1001/jama.279.15.1200; Lunetta KL, 2004, BMC GENET, V5, DOI 10.1186/1471-2156-5-32; Marchini J, 2005, NAT GENET, V37, P413, DOI 10.1038/ng1537; McKinney Brett A, 2006, Appl Bioinformatics, V5, P77, DOI 10.2165/00822942-200605020-00002; McKinney BA, 2006, J INFECT DIS, V194, P444, DOI 10.1086/505503; Moore JH, 2005, BIOESSAYS, V27, P637, DOI 10.1002/bias.20236; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Nelson MR, 2001, GENOME RES, V11, P458, DOI 10.1101/gr.172901; Province MA, 2001, ADV GENET, V42, P273, DOI 10.1016/S0065-2660(01)42028-1; *R DEV COR TEAM, 2006, R LANG ENV STAT COMP, pO6410; Reif DM, 2004, EXPERT REV PROTEOMIC, V1, P67, DOI 10.1586/14789450.1.1.67; Robnik-Sikonja M, 2004, LECT NOTES COMPUT SC, V3201, P359; Rock MT, 2004, J INFECT DIS, V189, P1401, DOI 10.1086/382510; Tahri-Daizadeh N, 2003, GENOME RES, V13, P1952, DOI 10.1101/gr.1254203; Wilke RA, 2005, NAT REV DRUG DISCOV, V4, P911, DOI 10.1038/nrd1874	24	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			1-4244-0623-4				2006							171	178				8	Mathematical & Computational Biology	Mathematical & Computational Biology	BFW23	WOS:000245066100024		
B	Langmead, CJ		Jiang, T; Yang, UC; Chen, YPP; Wong, L		Langmead, CJ			A randomized algorithm for learning Mahalanobis metrics: Application to classification and regression of biological data	Proceedings of the 4th Asia-Pacific Bioinformatics Conference	Series on Advances in Bioinformatics and Computational Biology		English	Proceedings Paper	4th Asia-Pacific Bioinformatics Conference	FEB 13-16, 2006	Taipei, TAIWAN				CHEMICAL-SHIFTS	We present a randomized algorithm for semi-supervised learning of Mahalanobis metrics over R-n. The inputs to the algorithm are a set, U, of unlabeled points in R-n, a set of pairs of points, S = {(x,y)i};x,y is an element of U, that are known to be similar, and a set of pairs of points, D = {(x, y)i}; x, y is an element of U, that are known to be dissimilar. The algorithm randomly samples S, D, and m-dimensional subspaces of R-n and learns a metric for each subspace. The metric over R-n is a linear combination of the subspace metrics. The randomization addresses issues of efficiency and overfitting. Extensions of the algorithm to learning non-linear metrics via kernels, and as a pre-processing step for dimensionality reduction are discussed. The new method is demonstrated on a regression problem (structure-based chemical shift prediction) and a classification problem (predicting clinical outcomes for immunomodulatory strategies for treating severe sepsis).	Carnegie Mellon Univ, Dept Comp Sci, Dept Biol Sci, Pittsburgh, PA 15213 USA	Langmead, CJ (reprint author), Carnegie Mellon Univ, Dept Comp Sci, Dept Biol Sci, Wean Hall 4212, Pittsburgh, PA 15213 USA.						Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Case D. A., 2004, AMBER 8; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; Clermont G, 2004, CRIT CARE MED, V32, P2061, DOI 10.1097/01.CCM.0000142394.28791.C3; Cornilescu G, 1999, J BIOMOL NMR, V13, P289, DOI 10.1023/A:1008392405740; Cox T., 1994, MULTIDIMENSIONAL SCA; Dietterich T.G., 2000, P 1 INT WORKSH MULT, P1; Hastie T., 2001, ELEMENTS STAT LEARNI; Jolliffe I. T., 1989, PRINCIPAL COMPONENT; Langmead Christopher James, 2004, Proc IEEE Comput Syst Bioinform Conf, P278; Langmead CJ, 2004, J BIOMOL NMR, V29, P111, DOI 10.1023/B:JNMR.0000019247.89110.e6; Mielke SP, 2003, BIOINFORMATICS, V19, P2054, DOI 10.1093/bioinformatics/btg280; SEAVEY B R, 1991, Journal of Biomolecular NMR, V1, P217, DOI 10.1007/BF01875516; Tsang I. W., 2003, P INT C ART NEUR NET, P126; Xing E. P., 2002, ADV NEURAL INFORM PR, V15; Xu XP, 2001, J BIOMOL NMR, V21, P321, DOI 10.1023/A:1013324104681; Zhang HY, 2003, J BIOMOL NMR, V25, P173, DOI 10.1023/A:1022836027055	18	0	0	IMPERIAL COLLEGE PRESS	COVENT GARDEN	57 SHELTON STREET, COVENT GARDEN WC2H 9HE, ENGLAND			1-86094-623-2	SER ADV BIOINFORM			2006	3						217	226		10.1142/9781860947292_0025		10	Biochemical Research Methods; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BEC75	WOS:000236818700025		
B	Arun, K; Langmead, CJ		Jiang, T; Yang, UC; Chen, YPP; Wong, L		Arun, K; Langmead, CJ			Structure based chemical shift prediction using random forests non-linear regression	Proceedings of the 4th Asia-Pacific Bioinformatics Conference	Series on Advances in Bioinformatics and Computational Biology		English	Proceedings Paper	4th Asia-Pacific Bioinformatics Conference	FEB 13-16, 2006	Taipei, TAIWAN				NMR-SPECTRA; PROTEINS; DATABASE; IDENTIFICATION; ASSIGNMENT; N-15; C-13	Protein nuclear magnetic resonance (NMR) chemical shifts are among the most accurately measurable spectroscopic parameters and are closely correlated to protein structure because of their dependence on the local electronic environment. The precise nature of this correlation remains largely unknown. Accurate prediction of chemical shifts from existing structures' atomic co-ordinates will permit close study of this relationship. This paper presents a novel non-linear regression based approach to chemical shift prediction from protein structure. The regression model employed 'combines quantum, classical and empirical variables and provides statistically significant improved prediction accuracy over existing chemical shift predictors, across protein backbone atom types. The results presented here were obtained using the Random Forest regression algorithm on a protein entry data set derived from the RefDB re-referenced chemical shift database.	Carnegie Mellon Univ, Dept Biol Sci, Dept Comp Sci, Sch Comp Sci, Pittsburgh, PA 15213 USA	Arun, K (reprint author), Carnegie Mellon Univ, Dept Biol Sci, Dept Comp Sci, Sch Comp Sci, 4400 5th Ave, Pittsburgh, PA 15213 USA.						Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cornilescu G, 1999, J BIOMOL NMR, V13, P289, DOI 10.1023/A:1008392405740; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dominguez C, 2003, J AM CHEM SOC, V125, P1731, DOI 10.1021/ja026939x; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Hamelryck T, 2005, PROTEINS, V59, P38, DOI 10.1002/prot.20379; Hus JC, 2002, J MAGN RESON, V157, P119, DOI 10.1006/jmre.2002.2569; Langmead Christopher James, 2004, Proc IEEE Comput Syst Bioinform Conf, P278; Meiler J, 2003, J BIOMOL NMR, V26, P25, DOI 10.1023/A:1023060720156; Mielke SP, 2003, BIOINFORMATICS, V19, P2054, DOI 10.1093/bioinformatics/btg280; Neal S, 2003, J BIOMOL NMR, V26, P215, DOI 10.1023/A:1023812930288; Peng C, 2004, J BIOMOL NMR, V29, P491, DOI 10.1023/B:JNMR.0000034351.37982.9e; Sibley AB, 2003, BIOPHYS J, V84, P1223; Wang Guoli, S2C DATABASE CORRELA; WISHART DS, 1994, J BIOMOL NMR, V4, P171; Xu XP, 2001, J BIOMOL NMR, V21, P321, DOI 10.1023/A:1013324104681; Zhang HY, 2003, J BIOMOL NMR, V25, P173, DOI 10.1023/A:1022836027055	18	3	3	IMPERIAL COLLEGE PRESS	COVENT GARDEN	57 SHELTON STREET, COVENT GARDEN WC2H 9HE, ENGLAND			1-86094-623-2	SER ADV BIOINFORM			2006	3						317	326		10.1142/9781860947292_0035		10	Biochemical Research Methods; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BEC75	WOS:000236818700035		
B	Karunaratne, T; Bostrom, H		Kovalerchuk, B		Karunaratne, Thashmee; Bostrom, Henrik			Learning to classify structured data by graph propositionalization	Proceedings of the Second IASTED International Conference on Computational Intelligence			English	Proceedings Paper	2nd IASTED International Conference on Computational Intelligence	NOV 20-22, 2006	San Francisco, CA	Int Assoc Sci & Technol Dev		machine learning; graph; classification; structured data	PATTERNS	Existing methods for learning from structured data are limited with respect to handling large or isolated substructures and also impose constraints on search depth and induced structure length. An approach to learning from structured data using a graph based propositionalization method, called finger printing, is introduced that addresses the limitations of current methods. The method is implemented in a system called DIFFER, which is demonstrated to compare favorable to existing state-of-art methods on some benchmark data sets. It is shown that further improvements can be obtained by combining the features generated by finger printing with features generated by previous methods.	Stockholm Univ, Dept Comp & Syst Sci, SE-16440 Kista, Sweden	Karunaratne, T (reprint author), Stockholm Univ, Dept Comp & Syst Sci, Forum 100, SE-16440 Kista, Sweden.						Borgwardt K.M., 2005, ICDM 2005, P74; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bringmann B, 2005, LECT NOTES ARTIF INT, V3721, P46; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; DEBNATH AK, 1991, J MED CHEM, V34, P786, DOI 10.1021/jm00106a046; Dehaspe L, 1999, DATA MIN KNOWL DISC, V3, P7, DOI 10.1023/A:1009863704807; DERAEDT L, 2001, IJCAI01 17 INT JOINT, V2, P853; FISCHER J, 2004, IEEE SMC 2004 C P, P4578; Frank E., 2005, DATA MINING PRACTICA; Gonzalez J., 2001, P PRED TOX CHALL WOR; HELMA C, 2002, P BEILST I WORKSH BO; Horvath T., 2004, P 10 ACM SIGKDD INT, P158, DOI 10.1145/1014052.1014072; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; Krogel MA, 2003, LECT NOTES ARTIF INT, V2835, P197; LAVRAC N, 2002, P 12 INT C IND LOG P; LAVRAC N, 2000, EXTENDED TRANSFORMAT; Michie D., 1994, INT COMPUTING COMMUN; Muggleton S., 1992, INDUCTIVE LOGIC PROG, P281; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; NATTEE C, 2005, SAINT WORKSH 2005, P332; Quinlan J.R., 1993, LECT NOTES ARTIF INT, V667, P3; Ramon J, 2003, P 1 INT WORKSH MIN G, P65; SRINIVASAN A, 1999, PRGTR0899 OXF U; Washio T., 2003, SIGKDD EXPLORATIONS, V5, P59; Zaki Mohammed J., 2003, KDD 2003, P316	25	3	3	ACTA PRESS ANAHEIM	ANAHEIM	PO BOX 5124, ANAHEIM, CA 92814-5124 USA			978-0-88986-602-7				2006							393	398				6	Computer Science, Artificial Intelligence	Computer Science	BFQ37	WOS:000243777100069		
S	Rudnicki, WR; Kierczak, M; Koronacki, J; Komorowski, J		Greco, S; Hata, Y; Hirano, S; Inuiguchi, M; Miyamoto, S; Nguyen, HS; Slowinski, R		Rudnicki, Witold R.; Kierczak, Marcin; Koronacki, Jacek; Komorowski, Jan			A statistical method for determining importance of variables in an information system	Rough Sets and Current Trends in Computing, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	5th International Conference on Rough Sets and Current Trends in Computing	NOV 06-08, 2006	Kobe, JAPAN					A new method for estimation of attributes' importance for supervised classification, based on the random forest approach, is presented. Essentially, an iterative scheme is applied, with each step consisting of several runs of the random forest program. Each run is performed on a suitably modified data set: values of each attribute found unimportant at earlier steps are randomly permuted between objects. At each step, apparent importance of an attribute is calculated and the attribute is declared unimportant if its importance is not uniformly better than that of the attributes earlier found unimportant. The procedure is repeated until only attributes scoring better than the randomized ones are retained. Statistical significance of the results so obtained is verified. This method has been applied to 12 data sets of biological origin. The method was shown to be more reliable than that based on standard application of a random forest to assess attributes' importance.	Univ Warsaw, ICM, Warsaw, Poland; Univ Uppsala, Linnaeus Ctr Bioinformat, Uppsala, Sweden; Polish Acad Sci, Inst Comp Sci, PL-00901 Warsaw, Poland	Rudnicki, WR (reprint author), Univ Warsaw, ICM, Pawinskiego 5A, Warsaw, Poland.		Rudnicki, Witold/B-6670-2012; Komorowski, Jan/M-2667-2013	Rudnicki, Witold/0000-0002-7928-4944; Komorowski, Jan/0000-0002-0766-8789			AGOTNES T, LNCS, V1704, P193; Bazan J., 2001, LECT NOTES ARTIF INT, V2005, P106; Bishop C., 1996, NEURAL NETWORKS PATT, V1st; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cowell R. G., 1999, PROBABILISTIC NETWOR, P442; Duentsch I., 1998, ARTIF INTELL, V106, P109; DUENTSCH I, 1997, INT J HUM-COMPUT ST, V46, P589; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Hastie T., 2001, ELEMENTS STAT LEARNI; Komorowski J, 2002, HDB DATA MINING KNOW, P554; MAKOSA E, 2005, THESIS UPPSSALA U; NGUYEN HS, 1998, FUNDAMENTA INFORMATI, V34, P129; NGUYEN HS, 1998, ROUGH SETS KNOWLEDGE, V2, P55; PAWLAK Z, 1981, INFORM SYST, V6, P205, DOI 10.1016/0306-4379(81)90023-5; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pearl J., 1988, PROBABILISTIC REASON; Ripley B. D., 1996, PATTERN RECOGNITION	18	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-47693-8	LECT NOTES ARTIF INT			2006	4259						557	566				10	Computer Science, Artificial Intelligence	Computer Science	BFM83	WOS:000243122700058		
S	Goebel, KF; Yan, WZ; Eklund, NHW; Hu, X; Avasarala, V; Celaya, J		Inaudi, D; Ecke, W; Culshaw, B; Peters, KJ; Udd, E		Goebel, Kai F.; Yan, Weizhong; Eklund, Neil H. W.; Hu, Xiao; Avasarala, Vishwanath; Celaya, Jose			Defect classification of highly noisy NDE data using classifier ensembles - art. no. 61671O	Smart Structures and Materials 2006: Smart Sensor Monitoring Systems and Applications	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Smart Structures and Materials 2006 Conference	FEB 27-MAR 02, 2006	San Diego, CA	SPIE, Amer Soc Mech Engineers, Intelligent Mat Forum, Jet Propuls Lab, Natl Sci Fdn		classification; diagnostics; abnormal condition detection; information fusion; classifier fusion		In this paper, we present a feature selection and classification approach that was used to assess highly noisy sensor data from a NDE field study. Multiple, heterogeneous NDT sensors were employed to examine the solid structure. The goal was to differentiate between two types of phenomena occur-ring in a solid structure where one phenomenon was benign, the other was malignant. Manual distinction between these two types is almost impossible. To address these issues, we used sensor validation techniques to select the best available sensor that had the least noise effects and the best defect signature in the region of interest. Hundreds of features were formulated and extracted from data of the selected sensors. Next, we employed separability measures and correlation measures to select the most promising set of features. Because the NDE sensors poorly described the different defect types under consideration, the resulting features also exhibited poor separability. The focus of this paper is on how one can improve the classification under these constraints while minimizing the risk of overfitting (the number of field data was small). Results are shown from a number of different classifiers and classifier ensembles that were tuned to a set true positive rate using the Neyman-Pearson criterion.	GE Global Res, Niskayuna, NY 12309 USA	Goebel, KF (reprint author), GE Global Res, 1 Res Circle, Niskayuna, NY 12309 USA.						Bishop C.M., 1995, NEURAL NETWORKS PATT; BREIMAN L, 2004, RANDOM FOREST TOOLBO; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cawley G. C., 2000, SUPPORT VECTOR MACHI; Dietterich TG, 1997, AI MAG, V18, P97; Fisher RA, 1936, ANN EUGEN, V7, P178; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; LOSKIEWICZBUCZA.A, 1994, P 3 IEEE C FUZZ SYST, V2, P1412; Mao J., 1998, P IEEE INT JOINT C N, V3, P1828; NELSON M, 1999, P INF DEC CONTR, P395; Opitz D. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rao N. S. V., 2000, Information Fusion, V1, DOI 10.1016/S1566-2535(00)00004-X; SHIMSHONI Y, 1998, IEEE T SIGNAL PROCES, V46, P194; Smets P., 1994, ADV DEMPSTER SHAFER, P5; Vapnik VN, 1995, NATURE STAT LEARNING; YAN W, 2004, P SPIE MULTISENSOR M, P59; Yan WZ, 2002, P SOC PHOTO-OPT INS, V4733, P88, DOI 10.1117/12.475498	23	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-6220-9	P SOC PHOTO-OPT INS			2006	6167						O1671	O1671	61671O	10.1117/12.659704		12	Instruments & Instrumentation; Materials Science, Multidisciplinary; Optics	Instruments & Instrumentation; Materials Science; Optics	BEO49	WOS:000238445300048		
J	Segal, MR				Segal, Mark R.			Validation in genomics: CpG island methylation revisited	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						multiple testing; cross-validation; local false discovery rate; classification; sequence features		In a recent article in PLoS Genetics, Bock et al., (2006) undertake an extensive computational epigenetics analysis of the ability of DNA sequence-derived features, capturing attributes such as tetramer frequencies, repeats and predicted structure, to predict the methylation status of CpG islands. Their suite of analyses appears highly rigorous with regard to accompanying validation procedures, employing stringent Bonferroni corrections, stratified cross-validation, and follow-up experimental verification. Here, however, we showcase concerns with the validation steps, in part ascribable to the genome scale of the investigation, that serve as a cautionary note and indicate the heightened need for careful selection of analytic and companion validation methods. A series of new analyses of the same CpG island methylation data helps illustrate these issues, not just for this particular study, but also analogous investigations involving high-dimensional predictors with complex between-feature dependencies.	Univ Calif San Francisco, San Francisco, CA USA	Segal, MR (reprint author), Univ Calif San Francisco, San Francisco, CA USA.	mark@biostat.ucsf.edu					Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BHASIN M, 2005, FEBS LETT, V579, DOI UNSP 43024308; Bock C, 2006, PLOS GENET, V2, P243, DOI 10.1371/journal.pgen.0020026; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dudoit S, 2003, STAT SCI, V18, P71, DOI 10.1214/ss/1056397487; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; Efron B, 2004, ANN STAT, V32, P407; Efron B., 2006, CORRELATION LARGE SC; Efron B, 2004, J AM STAT ASSOC, V99, P96, DOI 10.1198/016214504000000089; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Efron B., 2005, LOCAL FALSE DISCOVER; FEINBERG AP, 2004, NAT REV CANCER, V4, DOI UNSP 143153; FELTUS FA, 2003, P NATL ACAD SCI USA, V100, DOI UNSP 1225312258; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; GENTLEMAN R, 2005, BIOINFORMATICS COMPT; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; HANDA V, 2005, J MOL BIOL, V348, DOI UNSP 11031112; Hastie T., 2001, ELEMENTS STAT LEARNI; HEARD E, 2004, CURR OPIN CELL BIOL, V16, DOI UNSP 247255; Jin W, 2001, NAT GENET, V29, P389, DOI 10.1038/ng766; PARK MY, 2006, IN PRESS BIOSTATISTI; Pollard K. S., 2005, BIOINFORMATICS COMPU, P251; REIK W, 2003, THERIOGENOLOGY, V59, P2132; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Segal MR, 2006, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; SMYTH GK, 2004, STAT APPL GENET MOL, V3, DOI DOI 10.2202/1544-6115.1027; Smyth Gordon K, 2003, Methods Mol Biol, V224, P111; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; STOREY JD, 2005, OPTIMAL DISCOVERY PR; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; TIBSHIRANI RJ, 2002, STAT APPL GENETICS M, V1; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Venables W.N., 1999, MODERN APPL STAT SPL; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Wu B., 2005, BIOINFORMATICS, V22, P472, DOI 10.1093/bioinformatics/bti827; YAMADA Y, 2004, GENOME RES, V14, DOI UNSP 247266; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	43	2	2	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2006	5								29			19	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	V43TY	WOS:000202958600002		
S	Rogers, J; Gunn, S		Saunders, G; Grobelnik, M; Gunn, S; ShaweTaylor, J		Rogers, Jeremy; Gunn, Steve			Identifying feature relevance using a random forest	SUBSPACE, LATENT STRUCTURE AND FEATURE SELECTION	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	Workshop on Subspace, Latent Structure and Feature Selection	FEB 23-25, 2005	Bohinj, SLOVENIA	PASCAL Network Excellence				It is known that feature selection and feature relevance can benefit the performance and interpretation of machine learning algorithms. Here we consider feature selection within a Random Forest framework. A feature selection technique is introduced that combines hypothesis testing with an approximation to the expected performance of an irrelevant feature during Random Forest construction. It is demonstrated that the lack of implicit feature selection within Random Forest has an adverse effect on the accuracy and efficiency of the algorithm. It is also shown that irrelevant features can slow the rate of error convergence and a theoretical justification of this effect is given.	Univ Southampton, Image Speech & Intelligent Res Grp, Sch Elect & Comp Sci, Southampton SO9 5NH, Hants, England	Rogers, J (reprint author), Univ Southampton, Image Speech & Intelligent Res Grp, Sch Elect & Comp Sci, Southampton SO9 5NH, Hants, England.						Blake C. L., 1998, UCI REPOSITORY MACHI; BORISOV A, 2006, IN PRESS FEATURE EXT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHEN YW, 2006, IN PRESS FEATURE EXT; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Friedman JH, 1994, FLEXIBLE METRIC NEAR; GUYON I, 2006, IN PRESS FEATURE EXT; Hall Mark A., 2000, 17 INT C MACH LEARN, P359; Ho T.K., 1998, LECT NOTES COMPUTER, V1451, P640; John G, 1994, MACH LEARN, P121; ROGERS J, 2005, LECT NOTES COMPUTER, V3635; ROOBAERT D, 2006, IN PRESS FEATURE EXT; Svetnik V, 2004, LECT NOTES COMPUT SC, V3077, P334; Yu L., 2003, MACH LEARN, P856	17	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-34137-4	LECT NOTES COMPUT SC			2006	3940						173	184				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEM13	WOS:000238094700012		
S	Wu, YF; Wang, C; Ng, SC			IEEE	Wu, Yunfeng; Wang, Cong; Ng, S. C.			Bagging.LMS: A bagging-based linear fusion with least-mean-square error update for regression	TENCON 2006 - 2006 IEEE REGION 10 CONFERENCE, VOLS 1-4	TENCON-IEEE Region 10 Conference Proceedings		English	Proceedings Paper	IEEE Region 10 Conference (TENCON 2006)	NOV 14-17, 2006	Hong Kong, PEOPLES R CHINA	IEEE			CLASSIFIERS	The merits of linear decision fusion in multiple learner systems have been widely accepted, and their practical applications are rich in literature. In this paper we present a new linear decision fusion strategy named Bagging.LMS, which takes advantage of the least-mean-square (LMS) algorithm to update the fusion parameters in the Bagging ensemble systems. In the regression experiments on four synthetic and two benchmark data sets, we compared this method with the Bagging-based Simple Average and Adaptive Mixture of Experts ensemble methods. The empirical results show that the Bagging.LMS method may significantly reduce the regression errors versus the other two types of Bagging ensembles, which indicates the superiority of the suggested Bagging.LMS method.	Beijing Univ Posts & Telecommun, Sch Informat Engn, Beijing 100876, Peoples R China	Wu, YF (reprint author), Beijing Univ Posts & Telecommun, Sch Informat Engn, Xi Tu Cheng Rd 10, Beijing 100876, Peoples R China.		Wu, Yunfeng/B-9337-2009	Wu, Yunfeng/0000-0002-3612-7818			Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Efron B, 1993, INTRO BOOTSTRAP; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fumera G, 2005, IEEE T PATTERN ANAL, V27, P942, DOI 10.1109/TPAMI.2005.109; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; Ridgeway G, 1999, COMPUTING SCI STAT, V31, P172; Riedmiller M., 1993, P IEEE INT C NEUR NE, V1, P586, DOI DOI 10.1109/ICNN.1993.298623; ROLI F, 2002, P 5 INT C INF FUS IF, V1, P278, DOI 10.1109/ICIF.2002.1021162; SITSON MO, 1996, CSDTR9619 U LONDON L; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; WU Y, 2004, P IEEE IJCNN, V3, P2437; WU Y, 2005, P 17 IEEE INT C TOOL, P699; WU Y, 2003, P 25 IEEE EMBS ANN I, V3, P2265	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0886-1420		978-1-4244-0548-0	TENCON IEEE REGION			2006							207	210				4	Computer Science, Artificial Intelligence; Telecommunications	Computer Science; Telecommunications	BGD18	WOS:000246127500053		
S	Kouzani, AZ			IEEE	Kouzani, A. Z.			Faceparts for recognition	TENCON 2006 - 2006 IEEE REGION 10 CONFERENCE, VOLS 1-4	TENCON-IEEE Region 10 Conference Proceedings		English	Proceedings Paper	IEEE Region 10 Conference (TENCON 2006)	NOV 14-17, 2006	Hong Kong, PEOPLES R CHINA	IEEE				A facial classification system that utilises images of faceparts is presented in this paper. Each facepart region is allocated a degree of importance. The random forests approach is employed for classification. The approach grows many classification trees where each tree gives a classification decision. The forest selects the classification that gives the most votes. Experimental results are presented and discussed.	Deakin Univ, Sch Informat Technol & Engn, Geelong, Vic 3217, Australia	Kouzani, AZ (reprint author), Deakin Univ, Sch Informat Technol & Engn, Geelong, Vic 3217, Australia.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Gunn SR, 1997, SUPPORT VECTOR MACHI; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Tolba A.S., 2006, INT J SIGNAL PROCESS, V2, P88; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	6	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0886-1420		978-1-4244-0548-0	TENCON IEEE REGION			2006							1232	1235				4	Computer Science, Artificial Intelligence; Telecommunications	Computer Science; Telecommunications	BGD18	WOS:000246127502044		
J	Ye, YQ; Zhong, XY; Zhang, HP				Ye, YQ; Zhong, XY; Zhang, HP			A genome-wide tree- and forest-based association analysis of comorbidity of alcoholism and smoking	BMC GENETICS			English	Article; Proceedings Paper	14th Genetic Analysis Workshop	SEP 07-19, 2004	Noordwijkerhout, NETHERLANDS				DEPENDENCE; RISK	Genetic mechanisms underlying alcoholism are complex. Understanding the etiology of alcohol dependence and its comorbid conditions such as smoking is important because of the significant health concerns. In this report, we describe a method based on classification trees and deterministic forests for association studies to perform a genome-wide joint association analysis of alcoholism and smoking. This approach is used to analyze the single-nucleotide polymorphism data from the Collaborative Study on the Genetics of Alcoholism in the Genetic Analysis Workshop 14. Our analysis reaffirmed the importance of sex difference in alcoholism. Our analysis also identified genes that were reported in other studies of alcoholism and identified new genes or single-nucleotide polymorphisms that can be useful candidates for future studies.	Yale Univ, Sch Med, Dept Epidemiol & Publ Hlth, New Haven, CT 06520 USA	Zhang, HP (reprint author), Yale Univ, Sch Med, Dept Epidemiol & Publ Hlth, 333 Cedar St, New Haven, CT 06520 USA.	yye@masal.med.yale.edu; xiaoyun.zhong@yale.edu; heping.zhang@yale.edu					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dick DM, 2003, ALCOHOL CLIN EXP RES, V27, P868, DOI 10.1097/01.ALC.0000065436.24221.63; Drobes DJ, 2002, ALCOHOL RES HEALTH, V26, P136; Edenberg HJ, 2002, ALCOHOL RES HEALTH, V26, P214; Gelernter J, 2004, AM J MED GENET B, V128B, P94, DOI 10.1002/ajmg.b.30019; Gong YW, 2001, CAN J PHYSIOL PHARM, V79, P977, DOI 10.1139/cjpp-79-12-977; GRANT B, 1992, ALCOHOL HEALTH RES W, V18, P243; Madden PAF, 2000, ALCOHOL RES HEALTH, V24, P209; Zhang HP, 2003, P NATL ACAD SCI USA, V100, P4168, DOI 10.1073/pnas.0230559100; Zhang H, 1999, RECURSIVE PARTITIONI; Zhang HP, 2000, BIOMETRICS, V56, P815, DOI 10.1111/j.0006-341X.2000.00815.x; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5	12	16	16	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2156			BMC GENET	BMC Genet.	DEC 30	2005	6			1					S135	10.1186/1471-2156-6-S1-S135		5	Genetics & Heredity	Genetics & Heredity	023CR	WOS:000236103400135	16451594	
J	Chen, XW; Liu, M				Chen, XW; Liu, M			Prediction of protein-protein interactions using random decision forest framework	BIOINFORMATICS			English	Article							INTERACTION SITES; BUDDING-YEAST; DATABASE; SEQUENCE; NETWORK; UPDATE; DOMAIN; ORDER	Motivation: Protein interactions are of biological interest because they orchestrate a number of cellular processes such as metabolic pathways and immunological recognition. Domains are the building blocks of proteins; therefore, proteins are assumed to interact as a result of their interacting domains. Many domain-based models for protein interaction prediction have been developed, and preliminary results have demonstrated their feasibility. Most of the existing domain-based methods, however, consider only single-domain pairs (one domain from one protein) and assume independence between domain-domain interactions. Results: In this paper, we introduce a domain-based random forest of decision trees to infer protein interactions. Our proposed method is capable of exploring all possible domain interactions and making predictions based on all the protein domains. Experimental results on Saccharomyces cerevisiae dataset demonstrate that our approach can predict protein-protein interactions with higher sensitivity (79.78%) and specificity (64.38%) compared with that of the maximum likelihood approach. Furthermore, our model can be used to infer interactions not only for single-domain pairs but also for multiple domain pairs.	Univ Kansas, Bioinformat & Computat Life Sci Lab, ITTC, Dept Elect Engn & Comp Sci, Lawrence, KS 66045 USA	Chen, XW (reprint author), Univ Kansas, Bioinformat & Computat Life Sci Lab, ITTC, Dept Elect Engn & Comp Sci, 1520 W 15th St, Lawrence, KS 66045 USA.	xwchen@ku.edu					Bailis JM, 2003, NAT CELL BIOL, V5, P1111, DOI 10.1038/ncb1069; Bateman A, 2004, NUCLEIC ACIDS RES, V32, pD138, DOI 10.1093/nar/gkh121; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dandekar T, 1998, TRENDS BIOCHEM SCI, V23, P324, DOI 10.1016/S0968-0004(98)01274-2; Deng MH, 2002, GENOME RES, V12, P1540, DOI 10.1101/gr.153002; Enright A. J., 1999, NATURE, V402, P25; Fariselli P, 2002, EUR J BIOCHEM, V269, P1356, DOI 10.1046/j.1432-1033.2002.02767.x; Finn RD, 2005, BIOINFORMATICS, V21, P410, DOI 10.1093/bioinformatics/bti011; Goh CS, 2000, J MOL BIOL, V299, P283, DOI 10.1006/jmbi.2000.3732; Han Dongsoo, 2003, Genome Inform, V14, P250; Han Dong-Soo, 2004, Genome Inform, V15, P171; Ho T. K., 1995, P 3 INT C DOC AN REC, P278; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Huynen M, 2000, GENOME RES, V10, P1204, DOI 10.1101/gr.10.8.1204; Ito T, 2000, P NATL ACAD SCI USA, V97, P1143, DOI 10.1073/pnas.97.3.1143; Jones S, 1997, J MOL BIOL, V272, P133, DOI 10.1006/jmbi.1997.1233; Kim Wan Kyu, 2002, Genome Inform, V13, P42; Kini RM, 1996, FEBS LETT, V385, P81, DOI 10.1016/0014-5793(96)00327-4; Lee SE, 2001, CURR BIOL, V11, P784, DOI 10.1016/S0960-9822(01)00228-7; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Mrowka R, 2001, GENOME RES, V11, P1971, DOI 10.1101/gr.206701; Ng S., 2003, BIOINFORMATICS, V10, P359; Ng SK, 2003, NUCLEIC ACIDS RES, V31, P251, DOI 10.1093/nar/gkg079; Pazos F, 1997, J MOL BIOL, V271, P511, DOI 10.1006/jmbi.1997.1198; Pazos F, 2001, PROTEIN ENG, V14, P609, DOI 10.1093/protein/14.9.609; Qi YJ, 2005, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2005, P531; Quinlan J. R., 1979, Expert Systems in the Micro-Electronic Age. Proceedings of the 1979 AISB Summer School; Quinlan J. R., 1983, MACHINE LEARNING ART, P463; Salwinski L, 2004, NUCLEIC ACIDS RES, V32, pD449, DOI 10.1093/nar/gkh086; Schwikowski B, 2000, NAT BIOTECHNOL, V18, P1257, DOI 10.1038/82360; Sprinzak E, 2001, J MOL BIOL, V311, P681, DOI 10.1006/jmbi.2001.4920; Uetz P, 2000, NATURE, V403, P623; Wojcik J, 2001, Bioinformatics, V17 Suppl 1, pS296; Xenarios I, 2001, NUCLEIC ACIDS RES, V29, P239, DOI 10.1093/nar/29.1.239; Zhou HX, 2001, PROTEINS, V44, P336, DOI 10.1002/prot.1099	37	136	152	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	DEC 15	2005	21	24					4394	4400		10.1093/bioinformatics/bti721		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	991XY	WOS:000233849400012	16234318	
J	Luellen, JK; Shadish, WR; Clark, MH				Luellen, JK; Shadish, WR; Clark, MH			Propensity scores - An introduction and experimental test	EVALUATION REVIEW			English	Article						propensity score; quasi-experiment; classification tree; bagging; ensemble methods	MATCHING METHODS; PROGRAM; BIAS; SUBCLASSIFICATION; ESTIMATORS; ADJUSTMENT; CAUSAL; ABUSE	Propensity score analysis is a relatively recent statistical innovation that is useful in the analysis of data from quasi-experiments. The goal of propensity score analysis is to balance two non-equivalent groups on observed covariates to get more accurate estimates of the effects of a treatment on which the two groups differ. This article presents a general introduction to propensity score analysis, provides an example using data from a quasi-experiment compared to a benchmark randomized experiment, offers practical advice about how to do such analyses, and discusses some limitations of the approach. It also presents the first detailed instructions to appear in the literature on how to use classification tree analysis and bagging for classification trees in the construction of propensity scores. The latter two examples serve as an introduction for researchers interested in computing propensity scores using more complex classification algorithms known as ensemble methods.	Univ Memphis, Dept Psychol, Memphis, TN 38152 USA; Univ Calif Merced, Merced, CA USA; So Illinois Univ, Carbondale, IL 62901 USA	Luellen, JK (reprint author), Univ Memphis, Dept Psychol, Memphis, TN 38152 USA.	jluellen@memphis.edu					Agodini R, 2004, REV ECON STAT, V86, P180, DOI 10.1162/003465304323023741; Aiken LS, 1998, EVALUATION REV, V22, P207, DOI 10.1177/0193841X9802200203; Angrist J, 2004, REV ECON STAT, V86, P58, DOI 10.1162/003465304323023679; BECKER RA, 1998, NEW 2 LANGUAGE PROGR; Behrman JR, 2004, REV ECON STAT, V86, P108, DOI 10.1162/003465304323023714; BERK RA, 1985, AM SOCIOL REV, V50, P253, DOI 10.2307/2095413; BERK RA, 1999, THINKING PROGRAM EVA, P66; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CLARK MH, 2000, THESIS U MEMPHIS; COCHRAN WG, 1968, BIOMETRICS, V24, P295, DOI 10.2307/2528036; Connors AF, 1996, JAMA-J AM MED ASSOC, V276, P889, DOI 10.1001/jama.276.11.889; CZAJKA JL, 1992, J BUS ECON STAT, V10, P117, DOI 10.2307/1391671; Dehejia RH, 2002, REV ECON STAT, V84, P151, DOI 10.1162/003465302317331982; DRAKE C, 1993, BIOMETRICS, V49, P1231, DOI 10.2307/2532266; FRIEDMAN J, 1998, 199 STANF U DIV BIOS; Frolich M, 2004, REV ECON STAT, V86, P77, DOI 10.1162/003465304323023697; Glazerman S, 2003, ANN AM ACAD POLIT SS, V589, P63, DOI 10.1177/0002716203254879; Gu Xing S., 1993, J COMPUTATIONAL GRAP, V2, P405, DOI DOI 10.1080/10618600.1993.10474623; HASTIE T, 2001, ELEMENTS STATE LEARN; Heckman J, 2004, REV ECON STAT, V86, P30, DOI 10.1162/003465304323023660; Heckman JJ, 1997, REV ECON STUD, V64, P605, DOI 10.2307/2971733; Hirano K., 2001, HLTH SERVICES OUTCOM, V2, P259, DOI [10.1023/A:1020371312283, DOI 10.1023/A:1020371312283]; HUANG IC, HLTH SERVICES RES; Imbens GW, 2004, REV ECON STAT, V86, P4, DOI 10.1162/003465304323023651; Imbens GW, 2000, BIOMETRIKA, V87, P706, DOI 10.1093/biomet/87.3.706; Joffe MM, 1999, AM J EPIDEMIOL, V150, P327; Jones AS, 2004, J INTERPERS VIOLENCE, V19, P1002, DOI 10.1177/0886260504268005; Lechner M, 2002, REV ECON STAT, V84, P205, DOI 10.1162/003465302317411488; LIAW A, 2003, RAMSOM FOREST PACKAG; Lu B, 2001, J AM STAT ASSOC, V96, P1245, DOI 10.1198/016214501753381896; Michalopoulos C, 2004, REV ECON STAT, V86, P156, DOI 10.1162/003465304323023732; MORRAL A, 2001, NIDA RES MONOGR, V182, P111; PETERS A, 2004, IPRED PACKAGE SOFTWA; PRUZEK RM, 2002, ANN M SOC MULT EXPT; *R DEV COR TEAM, 2004, R 1 9 0 WIND COMP SO; RIDGEWAY G, 2003, GBM PACK SOFTW MAN; Rosenbaum P. R., 2002, OBSERVATIONAL STUDIE, P295; Rosenbaum P. R., 2002, OBSERVATIONAL STUDIE; Rosenbaum P. R, 2002, OBSERVATIONAL STUDIE, V2nd, P71; ROSENBAUM PR, 1991, ANN INTERN MED, V115, P901; ROSENBAUM PR, 1986, J EDUC STAT, V11, P207; ROSENBAUM PR, 1991, BIOMETRICS, V47, P87, DOI 10.2307/2532498; Rosenbaum PR, 2002, OBSERVATIONAL STUDIE, P105; ROSENBAUM PR, 1983, BIOMETRIKA, V70, P41, DOI 10.1093/biomet/70.1.41; ROSENBAUM PR, 1985, AM STAT, V39, P33, DOI 10.2307/2683903; ROSENBAUM PR, 1984, J AM STAT ASSOC, V79, P516, DOI 10.2307/2288398; ROSSI PH, 2004, EVALUATION SYSTEMATI, P265; RUBIN DB, 1998, NONRANDOMIZED COMP C, P85; Rubin DB, 1996, BIOMETRICS, V52, P249, DOI 10.2307/2533160; RUBIN DB, 1992, ANN STAT, V20, P1079, DOI 10.1214/aos/1176348671; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; Shadish W. R., 2002, EXPT QUASI EXPT DESI; SHADISH WR, 2003, UNPUB RANDOMIZED EXP; SHADISH WR, FETSCHRIFT LEE SECHR; Sianesi B, 2004, REV ECON STAT, V86, P133, DOI 10.1162/003465304323023723; Smith HL, 1997, SOCIOL METHODOL, V27, P325, DOI 10.1111/1467-9531.271030; Stanley J., 1963, EXPT QUASI EXPT DESI; STONE RA, 1995, MED CARE, V33, pAS56; THERNEAU TM, 2003, RPART PACK SOFTW MAN; THERNEAU TM, 1997, 61 MAY CLIN DEP HLTH; Zhao Z, 2004, REV ECON STAT, V86, P91, DOI 10.1162/003465304323023705	63	102	102	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0193-841X			EVALUATION REV	Eval. Rev.	DEC	2005	29	6					530	558		10.1177/0193841X05275596		29	Social Sciences, Interdisciplinary	Social Sciences - Other Topics	982CI	WOS:000233135100002	16244051	
J	Kawakita, M; Minami, M; Eguchi, S; Lennert-Cody, CE				Kawakita, M; Minami, M; Eguchi, S; Lennert-Cody, CE			An introduction to the predictive technique AdaBoost with a comparison to generalized additive models	FISHERIES RESEARCH			English	Article						classification; boosting; decision stump; AsymBoost; logistic regression; shark bycatch	SMOOTHING PARAMETER-ESTIMATION; SHARK CATCH RATES; LONGLINE FISHERY; REGRESSION	The recently developed statistical learning method boosting is introduced for use with fisheries data. Boosting is a predictive technique for classification that has been shown to perform well with problematic data. The use of boosting algorithms AdaBoost and AsymBoost, with decision stumps, are described in detail, and their use is demonstrated with shark bycatch data from the eastern Pacific Ocean tuna purse-seine fishery. In addition, results of AdaBoost are compared to those obtained from generalized additive models (GAM). Compared to the logistic GAM, the prediction performance of AdaBoost was more stable, even with correlated predictors. Standard deviations of the test error were often considerably smaller for AdaBoost than for the logistic GAM. AdaBoost score plots, graphical displays of the contribution of each predictor to the discriminant function, were also more stable than score plots of the logistic GAM, particularly in regions of sparse data. AsymBoost, a variant of AdaBoost developed for binary classification of a skewed response variable, was shown to be effective at reducing the false negative ratio without substantially increasing the overall test error. Boosting shows promise for applications to fisheries data, both as a predictive technique and as a tool for exploratory data analysis. (c) 2005 Elsevier B.V. All rights reserved.	Grad Univ Adv Studies, Dept Stat Sci, Tokyo 1068569, Japan; Inst Stat Math, Tokyo 1068569, Japan; Interamer Trop Tuna Commiss, La Jolla, CA 92037 USA	Kawakita, M (reprint author), Grad Univ Adv Studies, Dept Stat Sci, Tokyo 1068569, Japan.	kawakita@ism.ac.jp	Eguchi, Shinto/A-9103-2012				BAYLIFF WH, 2001, 13 IATTC, P122; Bigelow KA, 1999, FISH OCEANOGR, V8, P178, DOI 10.1046/j.1365-2419.1999.00105.x; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T. J., 1990, GEN ADDITIVE MODELS; *IATTC, 2004, ANN REP INT AM TROP; Kearns M., 1988, TR1488 HARV U AIK CO; LO NCH, 1992, CAN J FISH AQUAT SCI, V49, P2515, DOI 10.1139/f92-278; McCullagh P., 1989, GENERALIZED LINEAR M, VSecond; Murata N, 2004, NEURAL COMPUT, V16, P1437, DOI 10.1162/089976604323057452; Oshitani S, 2003, FISHERIES SCI, V69, P456, DOI 10.1046/j.1444-2906.2003.00645.x; Punt AE, 2000, FISH RES, V45, P129, DOI 10.1016/S0165-7836(99)00106-X; Ryan T.P., 1997, MODERN REGRESSION ME; SWARTZMAN G, 1992, CAN J FISH AQUAT SCI, V49, P1366, DOI 10.1139/f92-152; Taquet M, 1997, AQUAT LIVING RESOUR, V10, P137, DOI 10.1051/alr:1997015; Tserpes G, 1999, AQUAT LIVING RESOUR, V12, P167, DOI 10.1016/S0990-7440(00)88468-5; VIOLA P, 2001, NEURAL INFORM PROCES, P14; Walsh WA, 2001, FISH RES, V53, P115, DOI 10.1016/S0165-7836(00)00306-4; Walsh WA, 2002, FISH RES, V58, P79, DOI 10.1016/S0165-7836(01)00361-7; WATTERS GM, 1999, 10 IATTC; Wood SN, 2003, J ROY STAT SOC B, V65, P95, DOI 10.1111/1467-9868.00374; Wood SN, 2004, J AM STAT ASSOC, V99, P673, DOI 10.1198/016214504000000980; Wood SN, 2000, J ROY STAT SOC B, V62, P413, DOI 10.1111/1467-9868.00240	29	12	16	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-7836			FISH RES	Fish Res.	DEC	2005	76	3					328	343		10.1016/j.fishres.2005.07.011		16	Fisheries	Fisheries	980FY	WOS:000233001000003		
J	Debeljak, Z; Marohnic, V; Srecnik, G; Medic, M				Debeljak, Z; Marohnic, V; Srecnik, G; Medic, M			Novel approach to evolutionary neural network based descriptor selection and QSAR model development	JOURNAL OF COMPUTER-AIDED MOLECULAR DESIGN			English	Article						benzodiazepines; descriptor selection; evolutionary neural networks; QSAR; wrappers	MOLECULAR SIMILARITY-MATRICES; LATENT VARIABLE REGRESSION; QUANTITATIVE STRUCTURE; CROSS-VALIDATION; BENZODIAZEPINE/GABA(A) RECEPTORS; SYSTEMATIC EVALUATION; AROMATIC-AMINES; ALGORITHM; PREDICTION; INHIBITORS	Capability of evolutionary neural network (ENN) based QSAR approach to direct the descriptor selection process towards stable descriptor subset (DS) composition characterized by acceptable generalization, as well as the influence of description stability on QSAR model interpretation have been examined. In order to analyze the DS stability and QSAR model generalization properties multiple random dataset partitions into training and test set were made. Acceptability criteria proposed by Golbraikh et al. [J. Comput.-Aided Mol. Des., 17 (2003) 241] have been chosen for selection of highly predictive QSAR models from a set of all models produced by ENN for each dataset splitting. All QSAR models that pass Golbraikh's filter generated by ENN for each dataset partition were collected. Two final DS forming principles were compared. Standard principle is based on selection of descriptors characterized by highest frequencies among all descriptors that appear in the pool [J. Chem. Inf. Comput. Sci., 43 (2003) 949]. Search across the model pool for DS that are stable against multiple dataset subsampling i.e. universal DS solutions is the basis of novel approach. Based on described principles benzodiazepine QSAR has been proposed and evaluated against results reported by others in terms of final DS composition and model predictive performance.	Osijek Clin Hosp, Dept Med Biochem, Osijek, Croatia; AVL AST, Zagreb 10000, Croatia; PLIVA DD, Analyt Dev Dept, Zagreb 10000, Croatia; Univ Zagreb, Fac Pharm & Biochem, Dept Med Chem, Zagreb 10000, Croatia	Debeljak, Z (reprint author), Osijek Clin Hosp, Dept Med Biochem, J Huttlera 4, Osijek, Croatia.	debeljak.zeljko@kbo.hr					ABRAHAM A, 2002, OPTIMIZATION EVOLUTI; AOYAMA T, 1990, J MED CHEM, V33, P2583, DOI 10.1021/jm00171a037; Baumann K, 2003, TRAC-TREND ANAL CHEM, V22, P395, DOI 10.1016/S0165-9936(03)00607-1; Baumann K, 2002, J CHEMOMETR, V16, P351, DOI 10.1002/cem.729; Baumann K, 2002, J CHEMOMETR, V16, P339, DOI 10.1002/cem.730; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L., 1994, BAGGING PREDICTORS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chiu TL, 2003, QSAR COMB SCI, V22, P519, DOI 10.1002/qsar.200310004; Clark RD, 2003, J COMPUT AID MOL DES, V17, P265, DOI 10.1023/A:1025366721142; DUDEWITZ EJ, 1988, MODERN MATH STAT; GASTEIGER J, 1993, ANGEW CHEM INT EDIT, V32, P503, DOI 10.1002/anie.199305031; Golbraikh A, 2003, J COMPUT AID MOL DES, V17, P241, DOI 10.1023/A:1025386326946; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Haykin S., 1999, NEURAL NETWORKS COMP; Hemmateenejad B, 2003, J CHEM INF COMP SCI, V43, P1328, DOI 10.1021/ci025661p; KOHAVI R, 1995, FEATURE SUBSET SELEC; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R, 1995, STUDY CROSS VALIDATI; Kyngas J, 1996, QUANT STRUCT-ACT REL, V15, P296, DOI 10.1002/qsar.19960150404; Leardi R, 1998, CHEMOMETR INTELL LAB, V41, P195, DOI 10.1016/S0169-7439(98)00051-3; Lunneborg C. E, 2000, DATA ANAL RESAMPLING; MADDALENA DJ, 1995, J MED CHEM, V38, P715, DOI 10.1021/jm00004a017; Mattioni BE, 2003, J CHEM INF COMP SCI, V43, P949, DOI 10.1021/ci034013i; MOLINA LC, 2002, 2002 IEEE INT C DAT; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Patankar SJ, 2000, J CHEM INF COMP SCI, V40, P706, DOI 10.1021/ci990125r; Patankar SJ, 2002, J CHEM INF COMP SCI, V42, P1053, DOI 10.1021/ci010114+; Shen Q, 2003, ANAL BIOANAL CHEM, V375, P248, DOI 10.1007/s00216-002-1668-1; So SS, 1996, J MED CHEM, V39, P5246, DOI 10.1021/jm960536o; So SS, 1996, J MED CHEM, V39, P1521, DOI 10.1021/jm9507035; So SS, 1997, J MED CHEM, V40, P4347, DOI 10.1021/jm970487v; So SS, 2000, J CHEM INF COMP SCI, V40, P762, DOI 10.1021/ci990130v; So SS, 1997, J MED CHEM, V40, P4360, DOI 10.1021/jm970488n; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; TETKO IV, 1995, J CHEM INF COMP SCI, V35, P826, DOI 10.1021/ci00027a006; Todeschini R, 2004, ANAL CHIM ACTA, V515, P199, DOI 10.1016/j.aca.2003.12.010; Tropsha A, 2003, QSAR COMB SCI, V22, P69, DOI 10.1002/qsar.200390007; WAGENER M, 1995, J AM CHEM SOC, V117, P7769, DOI 10.1021/ja00134a023; Yao X, 1998, IEEE T SYST MAN CY B, V28, P417, DOI 10.1109/3477.678637; ZELL A, 1998, STUTTGART NEURAL NET	43	2	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-654X			J COMPUT AID MOL DES	J. Comput.-Aided Mol. Des.	DEC	2005	19	12					835	855		10.1007/s10822-005-9022-2		21	Biochemistry & Molecular Biology; Biophysics; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biophysics; Computer Science	049NB	WOS:000238022200001	16607572	
J	Berk, R; Li, A; Hickman, L				Berk, R; Li, A; Hickman, L			Statistical difficulties in determining the role of race in capital cases: A re-analysis of data from the state of Maryland	JOURNAL OF QUANTITATIVE CRIMINOLOGY			English	Article						race; death penalty; logistic regression; propensity scores; classification and regression trees; random forests	DEATH-PENALTY; PROSECUTORIAL DISCRETION; RACIAL-DISCRIMINATION	In this paper, we re-analyze data used to study the role of race in capital cases in the state of Maryland. We show that when alternative, and arguably more appropriate, statistical procedures are applied, the racial effects reported in early work turn out to be very fragile. The methodological point is more general: conventional causal modeling with observational data is not likely to produce robust results for a variety of criminal justice applications.	Dept Stat, Los Angeles, CA 90095 USA; RAND Corp, Santa Monica, CA 90401 USA	Berk, R (reprint author), Dept Stat, UCLA8125 Math Sci Bldg,405 Hilgard Ave, Los Angeles, CA 90095 USA.						BALDUS DC, 1983, J CRIM LAW CRIM, V74, P661, DOI 10.2307/1143133; Barnett A., 1985, UC DAVIS LAW REV, V18, P1327; Berk RA, 2003, REGRESSION ANAL CONS; BERK RA, 1993, LAW SOC REV, V27, P89, DOI 10.2307/3053749; BERK RA, 2005, IN PRESS SOCIOL METH; BERK RA, 2005, IN PRESS DATA MINING; Bienen Leigh B., 1988, RUTGERS LAW REV, V41, P27; BONCZAR TP, 2003, CAPITAL PUNISHMENT 2; BOWERS W, 1983, CRIME DELINQUENCY, V74, P563; BOWERS WJ, 1980, CRIME DELINQUENCY, V26, P563, DOI 10.1177/001112878002600409; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cook RD, 1999, APPL REGRESSION INCL; FREEDMAN DA, 2001, US BERKELEY DEP STAT, V601; *GEN ACC OFF, 1990, GGD9057 GAO SEN HOUS; Greene W. H., 2003, ECONOMETRIC ANAL, VFifth; Gross S. R., 1989, DEATH DISCRIMINATION; GROSS SR, 1984, STANFORD LAW REV, V37, P27, DOI 10.2307/1228652; Hastie R, 1990, GEN ADDITIVE MODELS; HECKMAN J, 1999, Q J EC           FEB, P45; JACOBY JE, 1982, J CRIM LAW CRIM, V73, P379, DOI 10.2307/1143036; Keil T. J., 1990, JUSTICE Q, V7, P189, DOI 10.1080/07418829000090531; Kennedy P., 1998, GUIDE ECONOMETRICS; KLECK G, 1981, AM SOCIOL REV, V46, P783, DOI 10.2307/2095079; Klein S., 1991, JURIMETRICS, V32, P33; KLEPPER S, 1983, RES SENTENCING SEARC; MORTON SC, 2000, PUBLIC POLICY STAT C, P94; Paternoster R., 2003, EMPIRICAL ANAL MARYL; PATERNOSTER R, 1984, LAW SOC REV, V18, P437, DOI 10.2307/3053431; Paternoster Raymond, 1988, S CAROLINA LAW REV, V39, P245; RADELET ML, 1985, LAW SOC REV, V19, P587, DOI 10.2307/3053422; RADELET ML, 1981, AM SOCIOL REV, V46, P918, DOI 10.2307/2095088; Rosenbaum P. R., 2002, OBSERVATIONAL STUDIE; ROSENBAUM PR, 1983, BIOMETRIKA, V70, P41, DOI 10.1093/biomet/70.1.41; Thompson S.K., 2002, SAMPLING; Weiss RE, 1996, LAW SOC REV, V30, P607, DOI 10.2307/3054130	37	18	18	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0748-4518			J QUANT CRIMINOL	J. Quant. Criminol.	DEC	2005	21	4					365	390		10.1007/s10940-005-7354-7		26	Criminology & Penology	Criminology & Penology	971RZ	WOS:000232403500001		
J	Supek, F; Smuc, T; Lucic, B				Supek, F; Smuc, T; Lucic, B			A prototype structure-activity relationship model based on National Cancer Institute cell line screening data	PERIODICUM BIOLOGORUM			English	Article						antitumor drugs; topological descriptors; self-organizing map; support vector machine		Background and Purpose: The National Cancer Institute maintains a database of over 45000 chemicals screened for in vitro activity on many human cancer cell lines. Such abundance of data might be exploited to computationally predict the utility of antitumor drug candidates, starting from a numerical description of molecular structures. Materials and Methods: Each of the 10000 examined chemicals is described with 450 topological descriptors in attempt to capture the composition of the molecule and the way its atoms are interconnected. The descriptors are compressed using PCA down to 50 components, retaining 95% of the original information. Self-organizing maps were built (using in-house I2SOM software) and support vector machines trained (using We a software) to demonstrate and quantify the utility of predicting anticancer activity of chemicals. Results: The self-organizing maps demonstrated a clear improvement over negative controls in visualizations of compound activity oil two selected cell lines, although the patterns were not clear enough to reliably perforin clustering. An analogous conclusion can be drawn for the self-organizing map trained to show cellular mechanism of action. An SVM has proven moderately able to perform both regression (activity level) and classification (active vs. inactive) tasks oil the selected chemicals. Conclusions: We have shown that the in vitro antitumor activity of a compound can be predicted, although higher accuracy would be desired in most situations. The characteristics of the trained SVM show that performance of the models could be greatly improved by expanding the dataset with additional descriptors and additional chemicals.	Rudjer Boskovic Inst, Informat Syst Lab, Zagreb 10000, Croatia; Rudjer Boskovic Inst, Informat Syst Lab, Zagreb 10000, Croatia; Rudjer Boskovic Inst, Theoret Chem Grp, Zagreb 10000, Croatia	Supek, F (reprint author), Rudjer Boskovic Inst, Informat Syst Lab, Bijenicka 54, Zagreb 10000, Croatia.	fsupek@irb.hr	Supek, Fran/B-2359-2012; Lucic, Bono/L-7472-2013				BOYD MR, 1995, DRUG DEVELOP RES, V34, P91, DOI 10.1002/ddr.430340203; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Frank E., 2005, DATA MINING PRACTICA; GUTMAN I, 1975, J CHEM PHYS, V62, P3399, DOI 10.1063/1.430994; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105; RANDIC M, 1975, J AM CHEM SOC, V97, P6609, DOI 10.1021/ja00856a001; Vapnik V., 1998, STAT LEARNING THEORY	8	1	1	PERIODICUM BIOLOGORUM	ZAGREB	HRVATSKO PRIRODOSLOVNO DRUSTVO ILICA 16/111, 41000 ZAGREB, CROATIA	0031-5362			PERIOD BIOL	Period. Biol.	DEC	2005	107	4					451	455				5	Biology	Life Sciences & Biomedicine - Other Topics	002EF	WOS:000234593600013		
J	Dabney, AR				Dabney, AR			Classification of microarrays to nearest centroids	BIOINFORMATICS			English	Article							GENE-EXPRESSION PATTERNS; SHRUNKEN CENTROIDS; CLASS PREDICTION; DNA MICROARRAYS; CANCER; DIAGNOSIS	Motivation: Classification of biological samples by microarrays is a topic of much interest. A number of methods have been proposed and successfully applied to this problem. It has recently been shown that classification by nearest centroids provides an accurate predictor that may outperform much more complicated methods. The 'Prediction Analysis of Microarrays' (PAM) approach is one such example, which the authors strongly motivate by its simplicity and interpretability. In this spirit, I seek to assess the performance of classifiers simpler than even PAM. Results: I surprisingly show that the modified t-statistics and shrunken centroids employed by PAM tend to increase misclassification error when compared with their simpler counterparts. Based on these observations, I propose a classification method called 'Classification to Nearest Centroids' (ClaNC). ClaNC ranks genes by standard t-statistics, does not shrink centroids and uses a class-specific gene-selection procedure. Because of these modifications, ClaNC is arguably simpler and easier to interpret than PAM, and it can be viewed as a traditional nearest centroid classifier that uses specially selected genes. I demonstrate that ClaNC error rates tend to be significantly less than those for PAM, for a given number of active genes.	Univ Washington, Dept Biostat, Seattle, WA 98195 USA	Dabney, AR (reprint author), Univ Washington, Dept Biostat, Seattle, WA 98195 USA.	adabney@u.washington.edu	Dabney, Alan/C-1171-2011				Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; DUDOIT S, 2000, 576 U CAL BERK; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Mardia KV, 1979, MULTIVARIATE ANAL; Nguyen DV, 2004, COMPUT STAT DATA AN, V46, P407, DOI 10.1016/j.csda.2003.08.001; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Stein C., 1956, P 3 BERK S MATH STAT, V1, P197; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	22	61	61	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	NOV 15	2005	21	22					4148	4154		10.1093/bioinformatics/bti681		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	983FZ	WOS:000233218100011	16174683	
J	Springer, C; Adalsteinsson, H; Young, MM; Kegelmeyer, PW; Roe, DC				Springer, C; Adalsteinsson, H; Young, MM; Kegelmeyer, PW; Roe, DC			PostDOCK: A structural, empirical approach to scoring protein ligand complexes	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							ITERATIVE PARTIAL EQUALIZATION; ORBITAL ELECTRONEGATIVITY; MOLECULAR DOCKING; BINDING; SOLVATION; DATABASES; ENERGY; MODEL; CLASSIFICATION; COOPERATIVITY	In this work we introduce a postprocessing filter (PostDOCK) that distinguishes true binding ligand-protein complexes from docking artifacts (that are created by DOCK 4.0.1). PostDOCK is a pattern recognition system that relies on (1) a database of complexes, (2) biochemical descriptors of those complexes, and (3) machine learning tools. We use the protein databank (PDB) as the structural database of complexes and create diverse training and validation sets from it based on the "families of structurally similar proteins" (FSSP) hierarchy. For the biochemical descriptors, we consider terms from the DOCK score, empirical scoring, and buried solvent accessible surface area. For the machine-learners, we use a random forest classifier and logistic regression. Our results were obtained on a test set of 44 structurally diverse protein targets. Our highest performing descriptor combinations obtained similar to 19-fold enrichment (39 of 44 binding complexes were correctly identified, while only allowing 2 of 44 decoy complexes), and our best overall accuracy was 92%.	Sandia Natl Labs, Livermore, CA 94551 USA	Springer, C (reprint author), Sandia Natl Labs, POB 969,MS 9951, Livermore, CA 94551 USA.	clayton.springer@novartis.com					Ben-Naim A, 1998, J CHEM PHYS, V109, P7443, DOI 10.1063/1.477366; Bissantz C, 2000, J MED CHEM, V43, P4759, DOI 10.1021/jm001044l; BOHM HJ, 1994, J COMPUT AID MOL DES, V8, P243, DOI 10.1007/BF00126743; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brunzell H, 2000, PATTERN RECOGN, V33, P1741, DOI 10.1016/S0031-3203(99)00142-9; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Duda R. O., 2001, PATTERN CLASSFICIATI; EISENBERG D, 1986, NATURE, V319, P199, DOI 10.1038/319199a0; Eldridge MD, 1997, J COMPUT AID MOL DES, V11, P425, DOI 10.1023/A:1007996124545; Ewing TJA, 2001, J COMPUT AID MOL DES, V15, P411, DOI 10.1023/A:1011115820450; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; GASTEIGER J, 1981, ORG MAGN RESONANCE, V15, P353, DOI 10.1002/mrc.1270150408; Gohlke H, 2000, J MOL BIOL, V295, P337, DOI 10.1006/jmbi.1999.3371; Holm L, 1997, NUCLEIC ACIDS RES, V25, P231, DOI 10.1093/nar/25.1.231; HOLM L, 1994, NUCLEIC ACIDS RES, V22, P3600; Jones G, 1997, J MOL BIOL, V267, P727, DOI 10.1006/jmbi.1996.0897; LEO A, PROGRAMS CLOP CMR; Lum K, 1999, J PHYS CHEM B, V103, P4570, DOI 10.1021/jp984327m; Majeux N, 2001, PROTEINS, V42, P256, DOI 10.1002/1097-0134(20010201)42:2<256::AID-PROT130>3.0.CO;2-4; MARSILI M, 1980, CROAT CHEM ACTA, V53; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; McCullagh P., 1989, GEN LINEAR MODELS, Vsecond; MENG EC, 1992, J COMPUT CHEM, V13, P505, DOI 10.1002/jcc.540130412; Muegge I, 1999, J MED CHEM, V42, P791, DOI 10.1021/jm980536j; OROZCO M, 1993, BIOCHEMISTRY-US, V32, P12864, DOI 10.1021/bi00210a040; Pang YP, 2001, J COMPUT CHEM, V22, P1750, DOI 10.1002/jcc.1129; Robinson GW, 1999, J CHEM PHYS, V111, P698, DOI 10.1063/1.479349; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Sham YY, 2000, PROTEINS, V39, P393, DOI 10.1002/(SICI)1097-0134(20000601)39:4<393::AID-PROT120>3.0.CO;2-H; Shoichet BK, 1999, PROTEINS, V34, P4, DOI 10.1002/(SICI)1097-0134(19990101)34:1<4::AID-PROT2>3.0.CO;2-6; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306; VARSHNEY A, 1993, FAST ANAL COMPUTATIO; Venables WN, 1994, MODERN APPL STAT S P; WALLQVIST A, 1995, J PHYS CHEM-US, V99, P5705, DOI 10.1021/j100015a063; WEINER SJ, 1984, J AM CHEM SOC, V106, P765, DOI 10.1021/ja00315a051; WILLETT P, SIMILARITY CLUSTERIN; Zhang LY, 2001, J COMPUT CHEM, V22, P591, DOI 10.1002/jcc.1031; Zou XQ, 1999, J AM CHEM SOC, V121, P8033, DOI 10.1021/ja984102p	39	32	32	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	NOV 3	2005	48	22					6821	6831		10.1021/jm0493360		11	Chemistry, Medicinal	Pharmacology & Pharmacy	980KL	WOS:000233017300010	16250641	
J	Curnow, SJ; Falciani, F; Durrani, OM; Cheung, CMG; Ross, EJ; Wloka, K; Rauz, S; Wallace, GR; Salmon, M; Murray, PI				Curnow, SJ; Falciani, F; Durrani, OM; Cheung, CMG; Ross, EJ; Wloka, K; Rauz, S; Wallace, GR; Salmon, M; Murray, PI			Multiplex bead immunoassay analysis of aqueous humor reveals distinct cytokine profiles in uveitis	INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			English	Article							ENDOTOXIN-INDUCED UVEITIS; EXPERIMENTAL AUTOIMMUNE UVEORETINITIS; FUCHS HETEROCHROMIC CYCLITIS; OCULAR INFLAMMATION; PROINFLAMMATORY CYTOKINES; INTRAOCULAR INFLAMMATION; RECEPTOR ANTAGONIST; ANTERIOR UVEITIS; SINGLE-SAMPLE; TNF-ALPHA	PURPOSE. To extensively characterize the complex network of cytokines present in uveitis aqueous humor (AqH), and the relationships between cytokines and the cellular infiltrate. METHODS. AqH from noninflammatory control subjects and patients with idiopathic, Fuchs' heterochromic cyclitis (FHC), and herpes-viral or Behcet's uveitis were analyzed for IL-1 beta, -2, - 4, - 5, - 7, - 8, - 10, - 12, - 13, - 15, TNF alpha, IFN gamma, CCL2 (MCP-1), CCL5 (RANTES), CCL11 (Eotaxin), TGF beta 2, and CXCL12 (SDF-1), using multiplex bead immunoassays. The cellular infiltrate was also determined for each sample. RESULTS. Idiopathic uveitis AqH, compared with noninflammatory controls, was characterized by high levels of IL-6, IL-8, CCL2 and IFN gamma, the levels of which correlated with each other. For IL-6 and IL-8 these levels were proportional to the number of neutrophils present. By contrast, the levels of both TGF beta 2 and CXCL12 decreased in idiopathic uveitis AqH with increasing inflammation. Cluster analysis showed a degree of segregation between noninflammatory and idiopathic uveitis AqH. Further examination using random forest analysis yielded a complete distinction between these two groups. The minimum cytokines required for this classification were IL-6, IL-8, CCL2, IL-13, TNF alpha, and IL-2. CONCLUSIONS. Application of multiplex bead immunoassays has allowed us to identify distinct patterns of cytokines that relate to both clinical disease and the cellular infiltrates present. Bioinformatics analysis allowed identification of cytokines that differentiate idiopathic uveitis from noninflammatory control AqH and are likely to be important for the pathogenesis of uveitis.	Univ Birmingham, Sch Med, Div Immun & Infect, Inst Biomed Res,MRC,Ctr Immune Regulat, Birmingham B15 2TT, W Midlands, England; Univ Birmingham, City Hosp NHS Trust, Birmingham & Midland Eye Ctr, Div Immun & Infect,Acad Unit Ophthalmol, Birmingham, W Midlands, England; Univ Birmingham, Sch Biosci, Birmingham, W Midlands, England	Curnow, SJ (reprint author), Univ Birmingham, Sch Med, Div Immun & Infect, Inst Biomed Res,MRC,Ctr Immune Regulat, Birmingham B15 2TT, W Midlands, England.	s.j.curnow@bham.ac.uk	Falciani, Francesco/F-3490-2010				Akpek EK, 1999, OPHTHALMOLOGY, V106, P2291; Alcami A, 2003, NAT REV IMMUNOL, V3, P36, DOI 10.1038/nri980; Battaglia M, 2004, TRANSPLANTATION, V77, pS16, DOI 10.1097/01.TP.0000106468.96542.26; Boyd SR, 2001, SURV OPHTHALMOL, V46, P209, DOI 10.1016/S0039-6257(01)00275-2; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buggage RR, 1999, INVEST OPHTH VIS SCI, V40, P2462; Calder VL, 1999, INVEST OPHTH VIS SCI, V40, P2019; Caspi RR, 1997, EYE, V11, P209; Cook EB, 2001, J IMMUNOL METHODS, V254, P109, DOI 10.1016/S0022-1759(01)00407-0; Crane IJ, 2001, INVEST OPHTH VIS SCI, V42, P1547; Curnow SJ, 2004, J IMMUNOL, V173, P5290; DEVOS AF, 1994, INVEST OPHTH VIS SCI, V35, P1100; DEBOER JH, 1993, INVEST OPHTH VIS SCI, V34, P3376; de Jager W, 2003, CLIN DIAGN LAB IMMUN, V10, P133, DOI 10.1128/CDLI.10.1.133-139.2003; de Smet MD, 2001, PROG RETIN EYE RES, V20, P761, DOI 10.1016/S1350-9462(01)00011-8; El-Shabrawi Y, 1998, OPHTHALMOLOGY, V105, P1659, DOI 10.1016/S0161-6420(98)99035-2; El-Shabrawi Y, 2000, CURR EYE RES, V20, P211, DOI 10.1076/0271-3683(200003)20:3;1-9;FT211; Fedyk ER, 2001, J IMMUNOL, V166, P5749; Forrester J V, 1999, Chem Immunol, V73, P159; Greiner K, 2004, INVEST OPHTH VIS SCI, V45, P170, DOI 10.1167/iovs.03-0659; Hamzaoui K, 2002, SCAND J RHEUMATOL, V31, P205; Hill T, 2005, CLIN EXP IMMUNOL, V139, P132, DOI 10.1111/j.1365-2249.2005.02669.x; Hitchon CA, 2004, J RHEUMATOL, V31, P2336; HOEKZEMA R, 1990, CURR EYE RES, V9, P207, DOI 10.3109/02713689008999443; Kellar KL, 2001, CYTOMETRY, V45, P27, DOI 10.1002/1097-0320(20010901)45:1<27::AID-CYTO1141>3.0.CO;2-I; Khan SS, 2004, CYTOM PART B-CLIN CY, V61B, P35, DOI 10.1002/cyto.b.20021; Kim SJ, 2002, INVEST OPHTH VIS SCI, V43, P758; Lacomba MS, 2000, ARCH OPHTHALMOL-CHIC, V118, P768; Li QA, 1999, AUTOIMMUNITY, V30, P171, DOI 10.3109/08916939908993851; Wakefield D, 1999, Dev Ophthalmol, V31, P53; Mo JS, 1998, EXP EYE RES, V66, P547, DOI 10.1006/exer.1997.0451; Muhaya M, 1999, CLIN EXP IMMUNOL, V116, P410; Muhaya M, 1998, CLIN EXP IMMUNOL, V111, P123; Murray PI, 1999, CLIN EXP IMMUNOL, V117, P455; MURRAY PI, 1990, INVEST OPHTH VIS SCI, V31, P917; MURRAY PI, 1990, CURR EYE RES, V9, P53, DOI 10.3109/02713689008999420; Ohta K, 2000, INVEST OPHTH VIS SCI, V41, P2591; Ohta K, 2000, J IMMUNOL, V164, P1185; Oliver KG, 1998, CLIN CHEM, V44, P2057; Ongkosuwito JV, 1998, INVEST OPHTH VIS SCI, V39, P2659; Petrinovic-Doresic J, 1999, OCUL IMMUNOL INFLAMM, V7, P75, DOI 10.1076/ocii.7.2.75.4017; Prabhakar U, 2002, J IMMUNOL METHODS, V260, P207, DOI 10.1016/S0022-1759(01)00543-9; Santos Lacomba M, 2001, OPHTHALMIC RES, V33, P251; Tuaillon N, 2002, INVEST OPHTH VIS SCI, V43, P1493; Ueda Y, 2004, J EXP MED, V199, P47, DOI 10.1084/jem.20031104; Verma MJ, 1997, CURR EYE RES, V16, P1202, DOI 10.1076/ceyr.16.12.1202.5034; Vignali DAA, 2000, J IMMUNOL METHODS, V243, P243, DOI 10.1016/S0022-1759(00)00238-6	47	81	83	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	0146-0404			INVEST OPHTH VIS SCI	Invest. Ophthalmol. Vis. Sci.	NOV	2005	46	11					4251	4259		10.1167/iovs.05-0444		9	Ophthalmology	Ophthalmology	977MH	WOS:000232807400042	16249505	
J	Zhang, QY; Aires-de-Sousa, J				Zhang, QY; Aires-de-Sousa, J			Structure-based classification of chemical reactions without assignment of reaction centers	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							ORGANIZING NEURAL-NETWORK; HIERARCHICAL-CLASSIFICATION; SYSTEM; PREDICTION; KNOWLEDGE; TOOL	The automatic classification of chemical reactions is of high importance for the analysis of reaction databases, reaction retrieval, reaction prediction, or synthesis planning. In this work, the classification of photochemical reactions was investigated with no explicit assignment of the reacting centers. Classifications were explored with Random Forests or Kohonen neural networks in three different situations, using different levels of information: (a) pairs of reactants were classified according to the type of reaction they produce, (b) products, were classified according to the type of reaction from which they can be synthesized, and (c) reactions were classified from the difference between the descriptors of the product and the descriptors of the reactants. fit all cases Molecular maps of atom-level properties (MOLMAPs) were Used as descriptors. They are generated by a self-organizing map and encode physicochemical properties of the bonds available in a molecule. Correct classification could be achieved for approximately 90% of the 78 actions in all independent test set.	Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Quim, CQFB, P-2829516 Caparica, Portugal; Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Quim, REQUIMTE, P-2829516 Caparica, Portugal	Aires-de-Sousa, J (reprint author), Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Quim, CQFB, P-2829516 Caparica, Portugal.	jas@fct.unl.pt	Aires-de-Sousa, Joao/C-7826-2013; REQUIMTE, AL/H-9106-2013; REQUIMTE, ORG/M-4578-2013; REQUIMTE, LAQV/N-9835-2013	Aires-de-Sousa, Joao/0000-0002-5887-2966; 			Aires-de-Sousa J, 2002, CHEMOMETR INTELL LAB, V61, P167, DOI 10.1016/S0169-7439(01)00171-X; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen L., 2003, HDB CHEMOINFORMATICS, P348; Chen L, 1996, ANGEW CHEM INT EDIT, V35, P763, DOI 10.1002/anie.199607631; CHEN LG, 1995, J ORG CHEM, V60, P8002, DOI 10.1021/jo00129a047; Chen LR, 1997, J AM CHEM SOC, V119, P4033, DOI 10.1021/ja960027b; *CLASSIFY, INF REACT CLASS PROG; Dugundji J., 1973, TOP CURR CHEM, V39, P19; FUJITA S, 1986, J CHEM INF COMP SCI, V26, P205, DOI 10.1021/ci00052a009; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; Gasteiger J, 1988, PHYSICAL PROPERTY PR, P119; GASTEIGER J, 1994, J AM CHEM SOC, V116, P4608, DOI 10.1021/ja00090a009; Hendrickson JB, 1997, J CHEM INF COMP SCI, V37, P852, DOI 10.1021/ci970040v; Huth JR, 2005, J AM CHEM SOC, V127, P217, DOI 10.1021/ja0455547; Kohonen T., 1988, SELF ORG ASSOCIATIVE; Kotera M, 2004, J AM CHEM SOC, V126, P16487, DOI 10.1021/ja0466457; MOOCK TE, 1988, TETRAHEDRON COMPUT M, V1, P117, DOI 10.1016/0898-5529(88)90016-4; Polanski J, 2000, COMPUT CHEM, V24, P615, DOI 10.1016/S0097-8485(00)00064-4; R Development Core Team R, 2004, R LANG ENV STAT COMP; ROSE JR, 1994, J CHEM INF COMP SCI, V34, P74, DOI 10.1021/ci00017a010; SACHER O, 2001, THESIS U ERLANGEN NU; Satoh H, 1999, J CHEM INF COMP SCI, V39, P671, DOI 10.1021/ci9801567; Satoh H, 1998, J CHEM INF COMP SCI, V38, P210, DOI 10.1021/ci9701190; Satoh H, 2000, B CHEM SOC JPN, V73, P1955, DOI 10.1246/bcsj.73.1955; SIMON V, 1993, J AM CHEM SOC, V115, P9148, DOI 10.1021/ja00073a034; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Todd MH, 2005, CHEM SOC REV, V34, P247, DOI 10.1039/b104620a; Tratch SS, 1998, J CHEM INF COMP SCI, V38, P349, DOI 10.1021/ci960098u	28	41	46	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	NOV-DEC	2005	45	6					1775	1783		10.1021/ci0502707		9	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	989QS	WOS:000233689400042	16309284	
J	Kennedy, RE; Livingston, L; Riddick, A; Marwitz, JH; Kreutzer, JS; Zasler, ND				Kennedy, RE; Livingston, L; Riddick, A; Marwitz, JH; Kreutzer, JS; Zasler, ND			Evaluation of the neurobehavioral functioning inventory as a depression screening tool after traumatic brain injury	JOURNAL OF HEAD TRAUMA REHABILITATION			English	Article						depression; screening; structured interview; traumatic brain injury	PSYCHIATRIC-DISORDERS; NATIONAL-INSTITUTE; MAJOR DEPRESSION; INDIVIDUALS; PREVALENCE; DISABILITY; ADULTS; SCALE	Objective: To examine the utility of the Neurobehavioral Functioning Inventory (NFI) for diagnosing depression in a rehabilitation setting. Design: In a prospective study, a structured clinical interview (Structured Clinical Interview for DSM-IV-TR) was used to identify DSM-IV-defiried major depressive disorder (MDD) symptoms among patients with traumatic brain injury (TBI). NFI Depression scale items were compared with DSM-IV diagnosis obtained by the Structured Clinical Interview for DSM-IV Axis I Disorders. Setting: Outpatient neuropsychology clinic at a university hospital, private outpatient physical medicine and rehabilitation clinic, and a long-term specialized living assistance program. Participants: Participants consisted of 78 patients with TBI who were at least 3 months postinjury and 18 years of age or older. Main Outcome Measures: Structured Clinical Interview for DSM-IV Axis I Disorders and the NFI. Results: Psychiatric diagnostic interview with the Structured Clinical Interview for DSM-IV Axis I Disorders indicated that 50% of patients with TBI in our sample had at least one of the following in their lifetime: MDD, MDD due to general medical condition, dysthymia, or adjustment disorder with depressed mood. Thirty percent met diagnostic criteria for current MDD with or without general medical condition. Analyses of the NFI items revealed that individuals with depression endorsed greater levels of problems than did those without depression on 14 of the 32 items related to the DSM-IV symptom domains for depression (P < .00156 with Bonferroni correction). In predicting the diagnosis of depression using individual NFI items, the classification rate based on the Random Forests estimate was 83%. Conclusion: Findings indicate that the NFI items differentiated between depressed and non-depressed patients with TBI. Imposing minimal burden on patients and staff, the NFI appears to have good predictive value in diagnosing major depression. In clinical practice and research, the NFI is a potentially valuable screening tool for identifying major depression in persons with TBI.	Virginia Commonwealth Univ, Dept Psychiat, Richmond, VA 23298 USA; Virginia Commonwealth Univ, Dept Phys Med & Rehabil, Richmond, VA 23298 USA	Kennedy, RE (reprint author), Virginia Commonwealth Univ, Dept Psychiat, Box 980032, Richmond, VA 23298 USA.	rkennedy@vcu.edu					Al-Adawi S, 2004, J NEUROPSYCH CLIN N, V16, P435, DOI 10.1176/appi.neuropsych.16.4.435; American Psychiatric Association, 2000, DIAGN STAT MAN MENT; [Anonymous], 2004, R LANGUAGE ENV STAT; Babin PR, 2003, BRAIN INJURY, V17, P889, DOI 10.1080/0269905031000088595; Beck AT, 1993, BECK DEPRESSION INVE; Bender D. S., 2000, HDB PSYCHIAT MEASURE, P45; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BULLOCK MR, 2002, NEUROSURG FOCUS, V13, P1, DOI 10.3171/foc.2002.13.1.6; Deb S, 1999, AM J PSYCHIAT, V156, P374; Derogatis L R, 1974, Mod Probl Pharmacopsychiatry, V7, P79; Doppenberg EMR, 2004, J NEUROSURG ANESTH, V16, P87, DOI 10.1097/00008506-200401000-00019; Evans CC, 2005, J HEAD TRAUMA REHAB, V20, P488, DOI 10.1097/00001199-200511000-00002; FANN JR, 1995, AM J PSYCHIAT, V152, P1493; FEDOROFF JP, 1991, AM J PSYCHIAT, V148, P1172; FEDOROFF JP, 1992, AM J PSYCHIAT, V149, P918; FIRST MB, BACKGROUND ARTICLES; First MB, 1996, STRUCTURED CLIN INTE; FIRST MB, SCID FREQUENTLY ASKE; Gasquoine PG, 1992, NEUROPSYCHOLOGY, V6, P187, DOI 10.1037//0894-4105.6.3.187; Gaynes BN, 2004, ANN INTERN MED, V140, P822; GODFREY HPD, 1993, J CLIN EXP NEUROPSYC, V15, P503, DOI 10.1080/01688639308402574; GOMEZHERNANDEZ R, 1997, ARCH PHYS MED REHAB, V78, P13216; HAMILTON M, 1960, J NEUROL NEUROSUR PS, V23, P56, DOI 10.1136/jnnp.23.1.56; HarrisonFelix C, 1996, J HEAD TRAUMA REHAB, V11, P1, DOI 10.1097/00001199-199610000-00002; Hibbard MR, 1998, J HEAD TRAUMA REHAB, V13, P24; Hibbard MR, 2004, ARCH PHYS MED REHAB, V85, pS43, DOI 10.1016/j.apmr.2003.08.116; Jorge RE, 2004, ARCH GEN PSYCHIAT, V61, P42, DOI 10.1001/archpsyc.61.1.42; KATHOL RG, 1990, AM J PSYCHIAT, V147, P1021; KESSLER RC, 1994, ARCH GEN PSYCHIAT, V51, P8; Kreutzer JS, 1996, ARCH PHYS MED REHAB, V77, P116, DOI 10.1016/S0003-9993(96)90155-0; Kreutzer JS, 2001, BRAIN INJURY, V15, P563, DOI 10.1080/02699050010009108; Kreutzer JS, 1999, NEUROBEHAVIORAL FUNC; LEWIS G, 1992, PSYCHOL MED, V22, P465; McDaniel JS, 2000, PSYCHIAT CARE MED PA, P149; ROBINS LN, 1981, ARCH GEN PSYCHIAT, V38, P381; Rosenthal M, 1998, ARCH PHYS MED REHAB, V79, P90, DOI 10.1016/S0003-9993(98)90215-5; Seel RT, 2003, ARCH PHYS MED REHAB, V84, P1621, DOI 10.1053/S0003-9993(03)00270-3; Seel RT, 1997, ARCH PHYS MED REHAB, V78, P1254, DOI 10.1016/S0003-9993(97)90340-3; Seel RT, 2003, ARCH PHYS MED REHAB, V84, P177, DOI 10.1053/apmr.2003.50106; Sliwinski M, 1998, J HEAD TRAUMA REHAB, V13, P40; TEASDALE G, 1974, LANCET, V2, P81; van Reekum R, 2000, J NEUROPSYCH CLIN N, V12, P316, DOI 10.1176/appi.neuropsych.12.3.316; Wallace CA, 2000, BRAIN INJURY, V14, P549; Wing J. K., 1974, MEASUREMENT CLASSIFI; World Health Organization, 1993, COMP INT DIAGN INT V; 2004, RANDOM FOREST BREIMA	46	15	17	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3261 USA	0885-9701			J HEAD TRAUMA REHAB	J. Head Trauma Rehabil.	NOV-DEC	2005	20	6					512	526		10.1097/00001199-200511000-00004		15	Clinical Neurology; Rehabilitation	Neurosciences & Neurology; Rehabilitation	986YF	WOS:000233484900004	16304488	
J	Tan, AC; Naiman, DQ; Xu, L; Winslow, RL; Geman, D				Tan, AC; Naiman, DQ; Xu, L; Winslow, RL; Geman, D			Simple decision rules for classifying human cancers from gene expression profiles	BIOINFORMATICS			English	Article							PROSTATE-CANCER; MOLECULAR CLASSIFICATION; MICROARRAY DATA; LEUKEMIA; PREDICTION; TUMOR; SIGNATURES; ADENOCARCINOMA; CARCINOMAS; DIAGNOSIS	Motivation: Various studies have shown that cancer tissue samples can be successfully detected and classified by their gene expression patterns using machine learning approaches. One of the challenges in applying these techniques for classifying gene expression data is to extract accurate, readily interpretable rules providing biological insight as to how classification is performed. Current methods generate classifiers that are accurate but difficult to interpret. This is the trade-off between credibility and comprehensibility of the classifiers. Here, we introduce a new classifier in order to address these problems. It is referred to as k-TSP (k-Top Scoring Pairs) and is based on the concept of 'relative expression reversals'. This method generates simple and accurate decision rules that only involve a small number of gene-to-gene expression comparisons, thereby facilitating follow-up studies. Results: In this study, we have compared our approach to other machine learning techniques for class prediction in 19 binary and multi-class gene expression datasets involving human cancers. The k-TSP classifier performs as efficiently as Prediction Analysis of Microarray and support vector machine, and outperforms other learning methods (decision trees, k-nearest neighbour and naive Bayes). Our approach is easy to interpret as the classifier involves only a small number of informative genes. For these reasons, we consider the k-TSP method to be a useful tool for cancer classification from microarray gene expression data.	Whitaker Biomed Engn Inst, Ctr Cardiovasc Bioinformat & Modeling, Baltimore, MD 21218 USA; Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA	Tan, AC (reprint author), Whitaker Biomed Engn Inst, Ctr Cardiovasc Bioinformat & Modeling, 3400 N Charles St, Baltimore, MD 21218 USA.	actan@jhu.edu	Naiman, Daniel/A-3304-2010; Geman, Donald/A-3325-2010; Tan, Aik Choon/A-3135-2011	Naiman, Daniel/0000-0001-6504-9081; 			Tan Aik Choon, 2003, Appl Bioinformatics, V2, pS75; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; BERNSTEIN ID, 1992, BLOOD, V79, P1811; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bo T., 2002, GENOME BIOL, V3, P11; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang MS, 2000, BIOCHEM BIOPH RES CO, V279, P732, DOI 10.1006/bbrc.2000.3992; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; GEMAN D, 2004, STAT APPL GENETI MOL, V3; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; GRIFFIN JD, 1983, BLOOD, V62, P557; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Haste H, 1997, PSYCHOLOGIST, V10, P507; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Long PM, 2003, MACH LEARN, V52, P31, DOI 10.1023/A:1023937123600; Mutis T, 1999, BLOOD, V93, P2336; Pavlidis P, 2003, BIOINFORMATICS, V19, P295, DOI 10.1093/bioinformatics/19.2.295; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Stuart RO, 2004, P NATL ACAD SCI USA, V101, P615, DOI 10.1073/pnas.2536479100; Su AI, 2001, CANCER RES, V61, P7388; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tsutsumi S, 2003, CANCER RES, V63, P4882; Welsh JB, 2001, CANCER RES, V61, P5974; Witten I., 2000, DATA MINING PRACTICA; Yang XJ, 2004, NUCLEIC ACIDS RES, V32, P959, DOI 10.1093/nar/gkh252; YEOH AEJ, 2002, CANCER CELL, V1, P133	43	145	150	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	OCT 15	2005	21	20					3896	3904		10.1093/bioinformatics/bti631		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	974MQ	WOS:000232596300013	16105897	
J	Viaene, S; Dedene, G; Derrig, RA				Viaene, S; Dedene, G; Derrig, RA			Auto claim fraud detection using Bayesian learning neural networks	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						automobile insurance; claim fraud; neural network; Bayesian learning; evidence framework	ROC CURVE; CLASSIFICATION; REGRESSION; PREDICTIONS; FRAMEWORK; SHRINKAGE; MODELS; AREA	This article explores the explicative capabilities of neural network classifiers with automatic relevance determination weight regularization, and reports the findings from applying these networks for personal injury protection automobile insurance claim fraud detection. The automatic relevance determination objective function scheme provides us with a way to determine which inputs are most informative to the trained neural network model. An implementation of MacKay's, (1992a,b) evidence framework approach to Bayesian learning is proposed as a practical way of training such networks. The empirical evaluation is based on a data set of closed claims from accidents that occurred in Massachusetts, USA during 1993. (c) 2005 Elsevier Ltd. All rights reserved.	Katholieke Univ Leuven, B-3000 Louvain, Belgium; Vlerick Leuven Gent Management Sch, B-9000 Ghent, Belgium; Univ Amsterdam, NL-1018 WB Amsterdam, Netherlands; Automobile Insurers Bur Massachusetts, Boston, MA 02110 USA; Insurance Fraud Bur Massachusetts, Boston, MA 02110 USA	Viaene, S (reprint author), Katholieke Univ Leuven, Naamsestr 69, B-3000 Louvain, Belgium.	stijn.viaene@econ.kuleuven.ac.be	Viaene, Stijn/C-2981-2009				Allison P. D., 1999, LOGISTIC REGRESSION; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bengio Y, 2000, NEURAL COMPUT, V12, P1889, DOI 10.1162/089976600300015187; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 2001, NONP LARG MULT DAT M; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buntine W., 1990, THESIS U TECHNOLOGY; *CAN COAL INS FRAU, 2002, INS FRAUD; Cestnik B., 1990, P EUR C ART INT, P147; *COAL INS FRAUD, 2002, INS FRAUD CRIM YOU P; *COM EUR ASS, 1997, EUR INS ANT GUID CEA; *COM EUR ASS, 1996, EUR INS ANT GUID CEA; COPAS JB, 1983, J R STAT SOC B, V45, P311; Cussens J., 1993, P EUR C MACH LEARN V, P136; DERRIG RA, 2002, J RISK INSURANCE, V69; DERRIG RA, 1998, R9841 DOI AUT INS BU; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; DIACONIS P, 1983, SCI AM, V248, P116; Dietterich T.G., 2002, HDB BRAIN THEORY NEU, P405; Domingos P., 2000, P 17 INT C MACH LEAR, P223; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; Duda R., 2000, PATTERN CLASSIFICATI; Fayyad U., 1993, P 13 INT JOINT C ART, P1022; Good I. J., 1965, ESTIMATION PROBABILI; GRANDVALET Y, 1998, P 8 INT C ART NEUR N, P201; Hand D. J., 1997, CONSTRUCTION ASSESSM; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; JOOS P, 1998, P ECML WORKSH APPL M, P59; Kass G., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Kohavi R., 1997, P 9 EUR C MACH LEARN; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; LACHER RC, 1995, EUR J OPER RES, V85, P53, DOI 10.1016/0377-2217(93)E0274-2; Lee KC, 1996, DECIS SUPPORT SYST, V18, P63, DOI 10.1016/0167-9236(96)00018-8; MacKay D, 1994, ASHRAE T, V100, P1053; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MARQUARDT DW, 1980, J AM STAT ASSOC, V75, P87, DOI 10.2307/2287388; Mobley BA, 2000, ARTIF INTELL MED, V18, P187, DOI 10.1016/S0933-3657(99)00040-8; Nabney I., 2001, NETLAB ALGORITHMS PA; Neal R., 1998, NEURAL NETWORKS MACH; Neal R. M., 1996, BAYESIAN LEARNING NE; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Parmanto B., 1996, Connection Science, V8, DOI 10.1080/095400996116848; Piramuthu S, 1999, EUR J OPER RES, V112, P310, DOI 10.1016/S0377-2217(97)00398-6; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Salchenberger L, 1997, COMPUT OPER RES, V24, P435, DOI 10.1016/S0305-0548(96)00064-0; SHARMA SK, 1996, ITAL J FOOD SCI, V2, P107; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; VANDELAAR P, 2000, INPUT SELECTION BASE; Viaene S, 2002, J RISK INSUR, V69, P373, DOI 10.1111/1539-6975.00023; VIAENE S, 2002, THESIS KU LEUEVEN; Weisberg Herbert W., 1991, J INSURANCE REGULATI, V9, P497; Weisberg H.I., 1998, RISQUES, V35, P75; WEISBERG HI, 1995, R9512 AUT INS BUR MA; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609	59	21	21	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	OCT	2005	29	3					653	666		10.1016/j.eswa.2005.04.030		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	961JW	WOS:000231659400014		
J	Lariviere, B; Van den Poel, D				Lariviere, B; Van den Poel, D			Investigating the post-complaint period by means of survival analysis	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; customer relationship management; consumer complaint behavior; actual customer behavior; proportionality; survival forests	WORD-OF-MOUTH; CUSTOMER PERCEPTIONS; FINANCIAL SERVICES; PERCEIVED JUSTICE; BEHAVIOR; MODEL; SATISFACTION; INTENTIONS; REGRESSION; MANAGEMENT	Firms increasingly view each contact with their customers as an opportunity that needs to be managed. The primary purpose of this article is to gain a better understanding of the customers' post-complaint period. Specific focus is placed on the impact of effective complaint handling on actual customer behavior throughout the time, whereas previous research has mainly focused on time-invariant or intentional measures. Survival analysis techniques are used to investigate the longitudinal behavior of complainants after their problem recovery. The proportionality assumption is tested for each explanatory variable under investigation. In addition, the impact for each variable is estimated by means of survival forests. Survival forests enable us to explore the evolution over time of the effects of the covariates under investigation. As such, the impact of each explanatory variable is allowed to change when the experiment evolves over time, in contrast to `proportional' models that restrict these estimates to be stationary. Our research is performed in the context of a financial services provider and analyses the post-complaint periods of 2326 customers. Our findings indicate that (i) it is interesting to consider complainants since they represent a typical and rather active customer segment, (ii) furthermore, it is beneficiary to invest in complaint handling, since these investments are likely to influence customers' future behavior and (iii) survival forests are a helpful tool to investigate the impact of complaint handling on future customer behavior, since its components provide evidence of changing effects over time. (c) 2005 Elsevier Ltd. All rights reserved.	State Univ Ghent, Dept Marketing, B-9000 Ghent, Belgium	Lariviere, B (reprint author), State Univ Ghent, Dept Marketing, Hoveniersberg 24, B-9000 Ghent, Belgium.	bart.lariviere@ugent.be					Allison DP, 1999, LOGISTIC REGRESSION; Bland JM, 1998, BRIT MED J, V317, P1572; BLODGETT JG, 1993, J RETAILING, V69, P399, DOI 10.1016/0022-4359(93)90015-B; Boucher KM, 2001, MATH COMPUT MODEL, V33, P1361, DOI 10.1016/S0895-7177(00)00321-6; Bougie R, 2003, J ACAD MARKET SCI, V31, P377, DOI 10.1177/0092070303254412; Bowman D, 2001, J MARKETING RES, V38, P281, DOI 10.1509/jmkr.38.3.281.18863; BREIMAN L, 2003, USE SURVIVAL FORESTS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 2002, WALD LECT M I MATH S; Conlon DE, 1996, ACAD MANAGE J, V39, P1040, DOI 10.2307/256723; EFRON B, 1988, J AM STAT ASSOC, V83, P414, DOI 10.2307/2288857; FORNELL C, 1988, MARKET SCI, V7, P287, DOI 10.1287/mksc.7.3.287; FORNELL C, 1987, J MARKETING RES, V24, P337, DOI 10.2307/3151381; KEAVENEY SM, 1995, J MARKETING, V59, P71, DOI 10.2307/1252074; Kumar D, 1997, EUR J OPER RES, V99, P507, DOI 10.1016/S0377-2217(96)00317-7; Lariviere B, 2004, EXPERT SYST APPL, V27, P277, DOI 10.1016/j.eswa.2004.02.002; LARIVIERE B, 2005, EXPERT SYSTEMS APPL, V29; Leeflang Peter H., 2000, BUILDING MODELS MARK; Levesque T., 1996, INT J BANK MARKETING, V14, P12, DOI 10.1108/02652329610151340; Maxham JG, 2003, J MARKETING, V67, P46, DOI 10.1509/jmkg.67.1.46.18591; Maxham JG, 2002, J RETAILING, V78, P239, DOI 10.1016/S0022-4359(02)00100-8; Maxham JG, 2001, J BUS RES, V54, P11, DOI 10.1016/S0148-2963(00)00114-4; MOITRA JG, 1993, ACAD MANAGE J, V36, P1430; MORROWHOWELL N, 1994, SOC WORK RES, V18, P247; RAMLAUHANSEN H, 1983, ANN STAT, V11, P453, DOI 10.1214/aos/1176346152; SINGH J, 1988, J MARKETING, V52, P93, DOI 10.2307/1251688; Smith AK, 1999, J MARKETING RES, V36, P356, DOI 10.2307/3152082; Stare J, 2001, COMPUT METH PROG BIO, V64, P45, DOI 10.1016/S0169-2607(00)00083-3; Stephens N, 1998, J ACAD MARKET SCI, V26, P172, DOI 10.1177/0092070398263001; Tax SS, 1998, J MARKETING, V62, P60, DOI 10.2307/1252161; THERNEAU TM, 2000, MODELIGN SURVIVAL DA; Van den Poel D, 2004, EUR J OPER RES, V157, P196, DOI 10.1016/S0377-2217(03)00069-9; Wirtz J, 2004, J ACAD MARKET SCI, V32, P159, DOI 10.1177/0092070303261416; Young MR, 1998, MANAGE SCI, V44, P188, DOI 10.1287/mnsc.44.2.188; Zeithaml VA, 1996, J MARKETING, V60, P31, DOI 10.2307/1251929	35	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	OCT	2005	29	3					667	677		10.1016/j.eswa.2005.04.035		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	961JW	WOS:000231659400015		
J	Martinez-Munoz, G; Suarez, A				Martinez-Munoz, G; Suarez, A			Switching class labels to generate classification ensembles	PATTERN RECOGNITION			English	Article						classification; ensemble methods; bagging; boosting; decision tree	CLASSIFIERS; ACCURACY	Ensembles that combine the decisions of classifiers generated by using perturbed versions of the training set where the classes of the training examples are randomly switched can produce a significant error reduction, provided that large numbers of units and high class switching rates are used. The classifiers generated by this procedure have statistically uncorrelated errors in the training set. Hence, the ensembles they form exhibit a similar dependence of the training error on ensemble size, independently of the classification problem. In particular, for binary classification problems, the classification performance of the ensemble on the training data can be analysed in terms of a Bernoulli process. Experiments on several UCI datasets demonstrate the improvements in classification accuracy that can be obtained using these class-switching ensembles. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Autonoma Madrid, Escuela Politecn Super, E-28049 Madrid, Spain	Martinez-Munoz, G (reprint author), Univ Autonoma Madrid, Escuela Politecn Super, C Francisco Tomas & Valiente 11, E-28049 Madrid, Spain.	gonzalo.martinez@uam.es; alberto.suarez@uam.es	Martinez-Munoz, Gonzalo/K-7269-2012; Suarez, Alberto/D-6293-2011	Martinez-Munoz, Gonzalo/0000-0002-6125-6056; Suarez, Alberto/0000-0003-4534-0909			Bias Breiman L., 1996, 460 U CAL STAT DEP; BLAKE CL, 1998, UCI EPOSITORY MACHIN; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGR; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Bryll R, 2003, PATTERN RECOGN, V36, P1291, DOI 10.1016/S0031-3203(02)00121-8; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P138; Hothorn T, 2003, PATTERN RECOGN, V36, P1303, DOI 10.1016/S0031-3203(02)00169-3; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Martinez-Munoz G, 2004, IEEE T SYST MAN CY C, V34, P393, DOI 10.1109/TSMCC.2004.833295; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; SCHAPIRE R, 1998, ANN STAT, V12, P1651; Sharkey A.J., 1999, COMBINING ARTIFICIAL; Skurichina M, 1998, PATTERN RECOGN, V31, P909, DOI 10.1016/S0031-3203(97)00110-6; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849	22	37	41	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	OCT	2005	38	10					1483	1494		10.1016/j.patcog.2005.02.020		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	956HX	WOS:000231291900002		
J	Candau, JN; Fleming, RA				Candau, JN; Fleming, RA			Landscape-scale spatial distribution of spruce budworm defoliation in relation to bioclimatic conditions	CANADIAN JOURNAL OF FOREST RESEARCH-REVUE CANADIENNE DE RECHERCHE FORESTIERE			English	Article; Proceedings Paper	12th Annual Conference of the International-Boreal-Forest-Research-Association	MAY 03-06, 2004	Fairbanks, AK	Int Boreal Forest Res Assoc			CHORISTONEURA-FUMIFERANA; STATISTICAL-METHODS; WHITE SPRUCE; BALSAM FIR; FOREST; LEPIDOPTERA; TORTRICIDAE; CANADA; AUTOCORRELATION; SUSCEPTIBILITY	Two empirical statistical models were developed to describe the spatial variation in defoliation by spruce budworm (Choristoneura fumiferana Clem.), as recorded by Ontario's Forest Health Survey from 1967 to 1998. These models revealed a number of relationships between the spatial distributions of aerially detectable spruce budworm defoliation and bioclimatic conditions over the landscape. A classification tree model relates the northern and southern boundaries of defoliation to the relative abundance of different tree species that host spruce budworm. Between these boundaries, the classification tree uses the maximum winter temperature and the minimum temperature in May to describe where detectable defoliation occurred. A regression tree model uses a total of eight variables related to winter temperatures, forest composition, spring temperatures, summer temperatures, and precipitation to estimate the defoliation frequency in areas where defoliation was detected at least once from 1967 to 1998. High defoliation frequencies were associated with dry Junes (precipitation, < 86 mm) and cool springs (mean minimum temperature < -2.7 degrees C). Conversely, low frequencies were associated with cold winters (mean minimum temperature < -23.3 degrees C; mean maximum temperature > -11.0 degrees C) in the north and a low abundance of host species (percentage of the basal area occupied by balsam fir, white spruce, and black spruce, < 14.3%) in the south. Spatial autocorrelation in the bioclimatic variables had little effect on their relationships with the spatial distribution of the defoliation frequency.	INRA, Unite Rech Forestieres Mediterraneennes, F-84000 Avignon, France; Canadian Forest Serv, Great Lakes Forest Res Ctr, Sault Ste Marie, ON P6A 2E5, Canada	Candau, JN (reprint author), INRA, Unite Rech Forestieres Mediterraneennes, Ave A Vivaldi, F-84000 Avignon, France.	jean-noel.candau@avignon.inra.fr					BALCH RE, 1946, ENTOMOLOGY DIVISION, V60; Baldwin D. J. B., 2000, ECOLOGY MANAGED TERR, P12; BATZER HO, 1985, FOREST CHRON, V61, P75; BLAIS J. R., 1961, FOREST CHRON, V37, P192; BLAIS JR, 1958, CAN ENTOMOL, V15, P354; BLAIS JR, 1968, FOREST CHRON, V44, P17; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; *CAN COUNC FOR MIN, 1995, COMP CAN FOR STAT 19; Candau J.N., 1998, CAN J FOREST RES, V28, P1; CEREZKE HH, 1985, FOREST INSECT PESTS, P59; Cliff A. D., 1981, SPATIAL PROCESSES MO; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; Diniz JAF, 2003, GLOBAL ECOL BIOGEOGR, V12, P53, DOI 10.1046/j.1466-822X.2003.00322.x; Draper N, 1981, APPL REGRESSION ANAL; Fleming R. A., 1996, Silva Fennica, V30, P281; Fleming R., 1999, CAN J REMOTE SENS, V25, P388; FLEMING RA, 1984, CAN ENTOMOL, V116, P633; Fleming RA, 2002, CLIMATIC CHANGE, V55, P251, DOI 10.1023/A:1020299422491; FLEMING RA, 1992, CAN ENTOMOL, V124, P1101; Frank R., 1990, SILVICS N AM, V654, P26; GREENBANK D. O., 1956, CANADIAN JOUR ZOOL, V34, P453, DOI 10.1139/z56-048; HARDY Y, 1986, USDA FOR SERV MISC P, V1449; HARDY YJ, 1983, FOREST SCI, V29, P715; HARVEY GT, 1985, CAN ENTOMOL, V117, P1451; Harvey N, 1996, AUST COMPUT J, V28, P2; Houston D. R., 1984, Arboricultural Journal, V8, P137; HOWSE GM, 1995, FOREST INSECT PESTS, P41; HOWSE GM, 1995, FOREST INSECT PESTS, P679; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; KEMP WP, 1979, ENVIRON ENTOMOL, V8, P993; Legendre P., 1998, NUMERICAL ECOLOGY; LEGENDRE P, 1993, ECOLOGY, V74, P1659, DOI 10.2307/1939924; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; LICHSTEIN JW, 2002, ECOL MONOGR, V73, P445; LYSYK TJ, 1990, CAN ENTOMOL, V122, P253; MACKEY BG, 1994, TR6 CAN FOR SERV GRE; MacKinnon WE, 2003, FOREST SCI, V49, P657; McCullough DG, 1998, ANNU REV ENTOMOL, V43, P107, DOI 10.1146/annurev.ento.43.1.107; MEATING JH, 1982, OX343 CAN FOR SERV G; MILLER C. A., 1958, CANADIAN JOUR ZOOL, V36, P409; MOORE DM, 1991, ENVIRON MANAGE, V15, P59, DOI 10.1007/BF02393838; MORRIS RF, 1963, DYNAMICS EPIDEMIC SP, P116; MOTT DG, 1963, DYNAMICS EPIDEMIC SP, P189; Munoz J, 2004, J VEG SCI, V15, P285, DOI 10.1658/1100-9233(2004)015[0285:COSMCU]2.0.CO;2; Nealis VG, 2004, CAN J FOREST RES, V34, P1870, DOI 10.1139/X04-061; Nienstaedt H., 1990, SILVICS N AM, V654, P204; *OMNR, 1996, ONT DIG TOP DAT; *OMNR, 1996, FOR RES ONT 1996; PILON J. G., 1961, CANADIAN ENT, V93, P118; POWER JM, 1991, PIX101 CAN FOR SERV, P119; Price DT, 2000, AGR FOREST METEOROL, V101, P81, DOI 10.1016/S0168-1923(99)00169-0; REGNIERE J, 1982, CAN ENTOMOL, V114, P811; ROSE A. H., 1954, CANADIAN ENT, V86, P174; ROYAMA T, 1984, ECOL MONOGR, V54, P429, DOI 10.2307/1942595; Shepherd RF, 1995, CAN ENTOMOL, V127, P813; SHORTLE WC, 1983, EUR J FOREST PATHOL, V13, P1; Sippell W.L., 1983, SPRUCE BUDWORM PROBL, P17; Sterner T.E., 1982, FOREST INSECT DIS CO; STOCKS BJ, 1987, FOREST CHRON, V63, P8; Su Q, 1996, CAN J FOREST RES, V26, P1620, DOI 10.1139/x26-182; Therneau T.M., 1997, 61 MAY CLIN SECT STA, P61; UVAROV B. P., 1931, TRANS ENT SOC [LONDON], V79, P1; VOLNEY WJA, 1992, CAN J FOREST RES, V22, P198, DOI 10.1139/x92-026; Volney WJA, 2000, AGR ECOSYST ENVIRON, V82, P283, DOI 10.1016/S0167-8809(00)00232-2; Wellington W.G., 1950, Canadian Journal of Research Ottawa D, V28, P308; WELLINGTON W. G., 1949, SCI AGRIC [OTTAWA], V29, P201; WELLINGTON W. G., 1950, TRANS ROY SOC CANADA SEC 5 3RD SER, V44, P89; WELLINGTON W. G., 1949, SCI AGRIC [OTTAWA], V29, P216; WELSH DA, 1983, SPRUCE BUDWORM PROBL, P27; Williams D. W., 1997, Acta Phytopathologica et Entomologica Hungarica, V32, P205; ZHU ZL, 1992, J FOREST, V90, P27	72	32	33	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA, ONTARIO K1A 0R6, CANADA	0045-5067			CAN J FOREST RES	Can. J. For. Res.-Rev. Can. Rech. For.	SEP	2005	35	9					2218	2232		10.1139/X05-078		15	Forestry	Forestry	991GL	WOS:000233800300016		
J	Zhao, H; Sinha, AP				Zhao, H; Sinha, AP			An efficient algorithm for generating generalized decision forests	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article						cascade generalization; classification; data mining; decision forest; decision tree; machine learning	CASCADE GENERALIZATION; TREES	A shortcoming of univariate decision tree learners is that they do not learn intermediate concepts and select only one of the input features in the branching decision at each intermediate tree node. It has been empirically demonstrated that cascading other classification methods, which learn intermediate concepts, with decision tree learners can alleviate such representational bias of decision trees and potentially improve classification performance. However, a more complex model that fits training data better may not necessarily perform better on unseen data, commonly referred to as the overfitting problem. To find the most appropriate degree of such cascade generalization, a decision forest (i.e., a set of decision trees with other classification models cascaded to different degrees) needs to be generated, from which the best decision tree can then be identified. In this paper, the authors propose an efficient algorithm for generating such decision forests. The algorithm uses an extended decision tree data structure and constructs any node that is common to multiple decision trees only once. The authors have empirically evaluated the algorithm using 32 data sets for classification problems from the University of California, Irvine (UCI) machine learning repository and report on results demonstrating the efficiency of the algorithm in this paper.	Univ Wisconsin, Sch Business Adm, Milwaukee, WI 53201 USA	Sinha, AP (reprint author), Univ Wisconsin, Sch Business Adm, Milwaukee, WI 53201 USA.	hzhao@uwm.edu; sinha@uwm.edu					Bioch JC, 1997, LECT NOTES ARTIF INT, V1263, P232; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T.G., 2000, P 1 INT WORKSH MULT, P1; Domingos P., 2000, P 17 INT C MACH LEAR, P231; Gama J., 1999, P 16 INT C MACH LEAR, P134; Gama J, 2000, MACH LEARN, V41, P315, DOI 10.1023/A:1007652114878; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Heath D., 1993, P 13 INT JOINT C ART, P1002; Hosmer D.W., 2000, APPL LOGISTIC REGRES; JOHN GH, 1996, LECT NOTES STAT, V5, P375; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Murphy M A, 1994, J Clin Neurosci, V1, P257, DOI 10.1016/0967-5868(94)90066-3; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Weiss SM, 1991, COMPUTER SYSTEMS LEA; Witten I., 2000, DATA MINING PRACTICA; Yildiz O. T., 2000, P 17 INT C MACH LEAR, P1175; Zhao HM, 2004, IEEE T KNOWL DATA EN, V16, P727, DOI 10.1109/TKDE.2004.3	26	8	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4427			IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	SEP	2005	35	5					754	762		10.1109/TSMCA.2005.843392		9	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	956AC	WOS:000231270300015		
J	Hothorn, T; Leisch, F; Zeileis, A; Hornik, K				Hothorn, T; Leisch, F; Zeileis, A; Hornik, K			The design and analysis of benchmark experiments	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						bootstrap; cross-validation; hypothesis testing; model comparison; performance	CLASSIFICATION LEARNING ALGORITHMS; CROSS-VALIDATION; GENERALIZATION ERROR; PREDICTION RULE; MODEL SELECTION; TREES; CLASSIFIERS; REGRESSION; SPLINES; TESTS	The assessment of the performance of learners by means of benchmark experiments is an established exercise. In practice, benchmark studies are a tool to compare the performance of several competing algorithms for a certain learning problem. Cross-validation or resampling techniques are commonly used to derive point estimates of the performances which are compared to identify algorithms with good properties. For several benchmarking problems, test procedures taking the variability of those point estimates into account have been suggested. Most of the recently proposed inference procedures are based on special variance estimators for the cross-validated performance. We introduce a theoretical framework for inference problems in benchmark experiments and show that standard statistical test procedures can be used to test for differences in the performances. The theory is based on well-defined distributions of performance measures which can be compared with established tests. To demonstrate the usefulness in practice, the theoretical results are applied to regression and classification benchmark studies based on artificial and real world data.	Univ Erlangen Nurnberg, Inst Med Informat Biometrie & Epidemiol, D-91054 Erlangen, Germany; Vienna Tech Univ, Inst Stat & Wahrscheinlichkeitstheorie, A-1040 Vienna, Austria; Wirtschaftsuniv Wien, Inst Stat & Math, A-1090 Vienna, Austria	Hothorn, T (reprint author), Univ Erlangen Nurnberg, Inst Med Informat Biometrie & Epidemiol, Waldstr 6, D-91054 Erlangen, Germany.	Torsten.Hothom@rzmail.uni-erlangen.de; Friedrich.Leisch@ci.tuwien.ac.at; Achim.Zeileis@wu-wien.ac.at; Kurt.Homik@wu-wien.ac.at	Hothorn, Torsten/A-3639-2010; Leisch, Friedrich/A-6977-2013	Hothorn, Torsten/0000-0001-8301-0471; Leisch, Friedrich/0000-0001-7278-1983			Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812; Berger V. W., 2002, J MODERN APPL STAT M, V1, P74; Berger VW, 2000, STAT MED, V19, P1319, DOI 10.1002/(SICI)1097-0258(20000530)19:10<1319::AID-SIM490>3.3.CO;2-S; Blake C. L., 1998, UCI REPOSITORY MACHI; Blockeel H., 2002, J MACHINE LEARNING R, V3, P621, DOI DOI 10.1162/JMLR.2003.3.4-5.621; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1996, 94708 U CAL STAT DEP; Buhlmann P, 2002, STAT SCI, V17, P52, DOI 10.1214/ss/1023798998; Bylander T, 2002, MACH LEARN, V48, P287, DOI 10.1023/A:1013964023376; Chang CC, 2001, LIBSVM LIB SUPPORT V; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DIMITRIADOU E, 2004, E1071 MISC FUNCTIONS; Dudoit S, 2005, STAT METHODOL, V2, P131, DOI 10.1016/j.stamet.2005.02.003; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1993, INTRO BOOTSTRAP; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; Gu C, 2001, J COMPUT GRAPH STAT, V10, P581, DOI 10.1198/106186001317114992; Hajek J., 1999, THEORY RANK TESTS; Hastie T., 2001, ELEMENTS STAT LEARNI; Hochberg Y, 1987, MULTIPLE COMP PROCED; HOTHORN T, 2003, THESIS U DORTMUND GE; Hothorn T, 2005, COMPUT STAT DATA AN, V49, P1068, DOI 10.1016/j.csda.2004.06.019; Hothorn T, 2003, PATTERN RECOGN, V36, P1303, DOI 10.1016/S0031-3203(02)00169-3; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Kim H, 2003, J COMPUT GRAPH STAT, V12, P512, DOI 10.1198/1061860032049; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; LAUTER J, 1992, STABILE MULTIVARIATE; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Meyer D., 2001, R NEWS, V1, P23; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; PATTESON JG, 1992, BENCHMARKING BASICS; Pesarin F., 2001, MULTIVARIATE PERMUTA; Peters A., 2002, R NEWS, V2, P33; Pittman J, 2002, J COMPUT GRAPH STAT, V11, P615, DOI 10.1198/106186002448; Pizarro J, 2002, NEUROCOMPUTING, V48, P155, DOI 10.1016/S0925-2312(01)00653-1; R Development Core Team, 2004, R LANG ENV STAT COMP; Ripley B. D., 1996, PATTERN RECOGNITION; Schiavo RA, 2000, INT STAT REV, V68, P295, DOI 10.2307/1403415; STONE M, 1974, J R STAT SOC B, V36, P111; Therneau TM, 1997, 61 SECT BIOST MAYO C; Vapnik V. N., 1998, STAT LEARNING; Vehtari A, 2002, NEURAL COMPUT, V14, P2439, DOI 10.1162/08997660260293292; Venables WN, 2002, MODERN APPL STAT S, V4th; Wolpert DH, 1999, MACH LEARN, V35, P41, DOI 10.1023/A:1007519102914	55	36	36	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	SEP	2005	14	3					675	699		10.1198/106186005X59630		25	Statistics & Probability	Mathematics	008LK	WOS:000235042000010		
J	Bunn, AG; Goetz, SJ; Fiske, GJ				Bunn, AG; Goetz, SJ; Fiske, GJ			Observed and predicted responses of plant growth to climate across Canada	GEOPHYSICAL RESEARCH LETTERS			English	Article							CARBON BALANCE; FOREST; VARIABILITY; SENSITIVITY; INDEX; US	Using satellite observations from 1981 - 2000, and data interpolated from surface weather stations, we examined the association between gross photosynthetic activity ( Pg) and climate across the boreal forest and tundra of Canada. The response of annual and interannual Pg was tightly coupled to climate, and seasonal associations between Pg and climate varied with plant functional types. The most important variable for modeling summer growth of conifer forests was the previous spring minimum temperature, whereas tundra responded primarily to summer maximum temperature. Using general circulation model predictors to 2050, we project that tundra will continue to grow vigorously in the coming decades while conifer forests will not. Increased tundra productivity will likely be associated with changes in vegetation composition ( e. g., woody proliferation). If these biotic responses are stationary and persist as predicted, terrestrial carbon budgets will need to be modified.	Woods Hole Res Ctr, Woods Hole, MA 02543 USA	Bunn, AG (reprint author), Woods Hole Res Ctr, Box 296, Woods Hole, MA 02543 USA.	abunn@whrc.org					Alward RD, 1999, SCIENCE, V283, P229, DOI 10.1126/science.283.5399.229; *ARCT CLIM IMP ASS, 2004, IMP WAR ARCT ARCT CL; Barr AG, 2004, AGR FOREST METEOROL, V126, P237, DOI 10.1016/j.agrformet.2004.06.011; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown M., 2004, EOS T, V85, P565, DOI DOI 10.1029/2004EO520003; Fritts H.C., 2001, TREE RINGS CLIMATE; Frolking S, 1997, J GEOPHYS RES-ATMOS, V102, P29053, DOI 10.1029/96JD03707; Goetz SJ, 1999, ADV ECOL RES, V28, P57, DOI 10.1016/S0065-2504(08)60029-X; GOETZ SJ, 2005, IN PRESS P NATL ACAD; Goulden ML, 1998, SCIENCE, V279, P214, DOI 10.1126/science.279.5348.214; Goward SN, 1995, J BIOGEOGR, V22, P549, DOI 10.2307/2845953; Houghton RA, 2003, GLOBAL CHANGE BIOL, V9, P500, DOI 10.1046/j.1365-2486.2003.00620.x; Jenkins JP, 2002, GEOPHYS RES LETT, V29, DOI 10.1029/2001GL014008; KATTSOV VM, 2004, IMPACTS WARMING ARCT, P100; Keeling CD, 1996, NATURE, V382, P146, DOI 10.1038/382146a0; Larcher W, 1995, PHYSL PLANT ECOLOGY, V3rd; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lucht W, 2002, SCIENCE, V296, P1687, DOI 10.1126/science.1071828; MCKENNEY D, 2004, REGIONAL NATL INT CL; Moberg A, 2005, NATURE, V433, P613, DOI 10.1038/nature03265; MYNENI RB, 1995, IEEE T GEOSCI REMOTE, V33, P481, DOI 10.1109/36.377948; NYNENI RB, 1991, NATURE, V386, P698; PALKO S, 1995, 9 ANN S GIS; Parmesan C, 2003, NATURE, V421, P37, DOI 10.1038/nature01286; Peterson DW, 2001, ECOLOGY, V82, P3330, DOI 10.1890/0012-9658(2001)082[3330:MHGRTC]2.0.CO;2; R Core Development Team, 2005, R LANG ENV STAT COMP; Root TL, 2003, NATURE, V421, P57, DOI 10.1038/nature01333; Slayback DA, 2003, GLOBAL CHANGE BIOL, V9, P1, DOI 10.1046/j.1365-2486.2003.00507.x; Sturm M, 2001, NATURE, V411, P546, DOI 10.1038/35079180; TUCKER CJ, 2005, IN PRESS INT J REMOT; Xiao JF, 2004, GLOBAL CHANGE BIOL, V10, P437, DOI 10.1111/j.1529-8817.2003.00745.x; Zhou LM, 2001, J GEOPHYS RES-ATMOS, V106, P20069, DOI 10.1029/2000JD000115	33	38	38	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0094-8276			GEOPHYS RES LETT	Geophys. Res. Lett.	AUG 25	2005	32	16							L16710	10.1029/2005GL023646		4	Geosciences, Multidisciplinary	Geology	960CU	WOS:000231568600006		
J	Huang, XH; Pan, W; Grindle, S; Han, XQ; Chen, YJ; Park, SJ; Miller, LW; Hall, J				Huang, XH; Pan, W; Grindle, S; Han, XQ; Chen, YJ; Park, SJ; Miller, LW; Hall, J			A comparative study of discriminating human heart failure etiology using gene expression profiles	BMC BIOINFORMATICS			English	Article							PARTIAL LEAST-SQUARES; TUMOR CLASSIFICATION; MICROARRAY DATA; LINEAR-REGRESSION; CANCER; CARDIOMYOPATHY; AMIODARONE; SHRINKAGE; DIAGNOSIS; SELECTION	Background: Human heart failure is a complex disease that manifests from multiple genetic and environmental factors. Although ischemic and non-ischemic heart disease present clinically with many similar decreases in ventricular function, emerging work suggests that they are distinct diseases with different responses to therapy. The ability to distinguish between ischemic and non-ischemic heart failure may be essential to guide appropriate therapy and determine prognosis for successful treatment. In this paper we consider discriminating the etiologies of heart failure using gene expression libraries from two separate institutions. Results: We apply five new statistical methods, including partial least squares, penalized partial least squares, LASSO, nearest shrunken centroids and random forest, to two real datasets and compare their performance for multiclass classification. It is found that the five statistical methods perform similarly on each of the two datasets: it is difficult to correctly distinguish the etiologies of heart failure in one dataset whereas it is easy for the other one. In a simulation study, it is confirmed that the five methods tend to have close performance, though the random forest seems to have a slight edge. Conclusions: For some gene expression data, several recently developed discriminant methods may perform similarly. More importantly, one must remain cautious when assessing the discriminating performance using gene expression profiles based on a small dataset; our analysis suggests the importance of utilizing multiple or larger datasets.	Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA; Univ Minnesota, Sch Med, Dept Med, Div Cardiovasc, Minneapolis, MN 55455 USA	Pan, W (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA.	xiaohong@biostat.umn.edu; weip@biostat.umn.edu; grind001@umn.edu; hanxx057@umn.edu; chenx106@umn.edu; jlhall@umn.edu; mille278@umn.edu; jlhall@umn.edu					Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Aronow BJ, 2001, PHYSIOL GENOMICS, V6, P19; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DETTLING M, 2003, BIOINFORMATICS, V19, P1063; Ding B., 2004, BIOCONDUCTOR PROJECT; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; DOVAL HC, 1994, LANCET, V344, P493, DOI 10.1016/S0140-6736(94)91895-3; Dries DL, 2001, J AM COLL CARDIOL, V38, P421, DOI 10.1016/S0735-1097(01)01408-5; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Felker GM, 2003, J AM COLL CARDIOL, V41, P997, DOI 10.1016/S0735-1097(02)02968-6; Felker GM, 2000, NEW ENGL J MED, V342, P1077, DOI 10.1056/NEJM200004133421502; Fort G, 2005, BIOINFORMATICS, V21, P1104, DOI 10.1093/bioinformatics/bti114; FRIEDMAN J, 1996, APPROACH POLYCHOTOMO; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; Ghosh D, 2003, BIOMETRICS, V59, P992, DOI 10.1111/j.0006-341X.2003.00114.x; Ghosh Debashis, 2002, Pac Symp Biocomput, P18; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hall JL, 2004, PHYSIOL GENOMICS, V17, P283, DOI 10.1152/physiolgenomics.00004.2004; Hastie T, 1998, ANN STAT, V26, P451; Hastie T., 2001, ELEMENT STAT LEARNIN; HAWKINS DM, 2003, CHANCE, V16, P19; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Huang XH, 2004, BIOINFORMATICS, V20, P888, DOI 10.1093/bioinformatics/btg499; Huang XH, 2003, BIOINFORMATICS, V19, P2072, DOI 10.1093/bioinformatics/btg283; Huang XH, 2005, COMPUT BIOL CHEM, V29, P204, DOI 10.1016/j.compbiolchem.2005.04.002; Hwang JJ, 2002, PHYSIOL GENOMICS, V10, P31, DOI 10.1152/physiolgenomics.00122.2001.; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Kittleson M, 2003, J AM COLL CARDIOL, V41, P2029, DOI 10.1016/S0735-1097(03)00417-0; Kittleson MM, 2004, CIRCULATION, V110, P3444, DOI 10.1161/01.CIR.0000148178.19465.11; Levy D, 1996, JAMA-J AM MED ASSOC, V275, P1557, DOI 10.1001/jama.275.20.1557; Lloyd-Jones D M, 2001, Curr Cardiol Rep, V3, P184, DOI 10.1007/s11886-001-0021-1; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Nicol RL, 2000, ANNU REV GENOM HUM G, V1, P179, DOI 10.1146/annurev.genom.1.1.179; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Rifkin R, 2003, SIAM REV, V45, P706, DOI 10.1137/S0036144502411986; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Simon R, 2003, J NATL CANCER I, V95, P14; Simon R, 2004, NAT CLIN PRACT ONCOL, V1, P4, DOI 10.1038/ncponc0006; SINGH SN, 1995, NEW ENGL J MED, V333, P77, DOI 10.1056/NEJM199507133330201; Tan FL, 2002, P NATL ACAD SCI USA, V99, P11387, DOI 10.1073/pnas.162370099; Tan YX, 2004, COMPUT BIOL CHEM, V28, P235, DOI 10.1016/j.compbiolchem.2004.05.002; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918; West M., 2003, BAYESIAN STAT, P733; WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Zhang H, 1999, RECURSIVE PARTITIONI; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	54	25	27	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	AUG 24	2005	6								205	10.1186/1471-2105-6-205		15	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	966OU	WOS:000232031200001	16120216	
J	Berk, RA; He, Y; Sorenson, SB				Berk, RA; He, Y; Sorenson, SB			Developing a practical forecasting screener for domestic violence incidents	EVALUATION REVIEW			English	Article						domestic violence; data mining; police; spousal assault; family violence	INTIMATE PARTNER VIOLENCE; RISK-FACTORS	In this article, the authors report on the development of a short screening tool that deputies in the Los Angeles Sheriffs Department could use in the field to help forecast domestic violence incidents in particular households. The data come from more than 500 households to which sheriff's deputies were dispatched in fall 2003. Information on potential predictors was collected at the scene. Outcomes were measured during a 3-month follow-up. Data were analyzed with modern data-mining procedures in which true forecasts were evaluated. A screening instrument was developed based on a small fraction of the information collected. Making the screening instrument more complicated did not improve forecasting skill. Taking the relative costs of false positives and false negatives into account, the instrument correctly forecasted future calls for service about 60% of the time. Future calls involving domestic violence misdemeanors and felonies were correctly forecast about 50% of the time. The 50% figure is important because such calls require a law enforcement response and yet are, a relatively smallfraction of all domestic violence calls for service.	Univ Calif Los Angeles, Los Angeles, CA 90024 USA	Berk, RA (reprint author), Univ Calif Los Angeles, Los Angeles, CA 90024 USA.						BERK RA, SOCIOLOGICAL METHODS; BERK RA, 1984, LAW SOC REV, V18, P479, DOI 10.2307/3053432; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; *CAL DEP JUST, 2003, CRIME DEL CAL; Campbell JC, 2003, AM J PUBLIC HEALTH, V93, P1089, DOI 10.2105/AJPH.93.7.1089; Cattaneo LB, 2003, J COMMUNITY PSYCHOL, V31, P349, DOI 10.1002/jcop.10056; Dutton D. G., 2000, TRAUMA VIOLENCE ABUS, V1, P171, DOI DOI 10.1177/1524838000001002004; Efron B, 1993, INTRO BOOTSTRAP; Fein R. A., 1995, THREAT ASSESSMENT AP; Hastie R., 2001, ELEMENTS STAT LEARNI; Houry D, 2004, ACAD EMERG MED, V11, P662, DOI 10.1197/j.aem.2003.11.019; Roehl J, 2000, JUSTICE SYST J, V21, P171; SHERMAN LW, 1992, POLICING DOMESTIC VI; SHERMAN LW, 1992, AM SOCIOL REV, V57, P680, DOI 10.2307/2095921; Skogan W., 2003, FAIRNESS EFFECTIVENE; Straus M. A., 1990, PHYS VIOLENCE AM FAM	17	10	10	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0193-841X			EVALUATION REV	Eval. Rev.	AUG	2005	29	4					358	383		10.1177/0193841X05275333		26	Social Sciences, Interdisciplinary	Social Sciences - Other Topics	943ZC	WOS:000230393700004	15985524	
J	Lariviere, B; Van den Poel, D				Lariviere, B; Van den Poel, D			Predicting customer retention and profitability by using random forests and regression forests techniques	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data mining; customer relationship management; customer retention and profitability; random forests and regression forests	LONG-LIFE CUSTOMERS; FINANCIAL SERVICES; IMPACT; SEGMENTATION; SATISFACTION; PROVIDERS; MODEL; BASE	In an era of strong customer relationship management (CRM) emphasis, firms strive to build valuable relationships with their existing customer base. In this study, we attempt to better understand three important measures of customer outcome: next buy, partial-defection and customers' profitability evolution. By means of random forests techniques we investigate a broad set of explanatory variables, including past customer behavior, observed customer heterogeneity and some typical variables related to intermediaries. We analyze a real-life sample of 100,000 customers taken from the data warehouse of a large European financial services company. Two types of random forests techniques are employed to analyze the data: random forests are used for binary classification, whereas regression forests are applied for the models with linear dependent variables. Our research findings demonstrate that both random forests techniques provide better fit for the estimation and validation sample compared to ordinary linear regression and logistic regression models. Furthermore, we find evidence that the same set of variables have a different impact on buying versus defection versus profitability behavior. Our findings suggest that past customer behavior is more important to generate repeat purchasing and favorable profitability evolutions, while the intermediary's role has a greater impact on the customers' defection proneness. Finally, our results demonstrate the benefits of analyzing different customer outcome variables simultaneously, since an extended investigation of the next buy-partial-defection-customer profitability triad indicates that one cannot fully understand a particular outcome without understanding the other related behavioral outcome variables. (C) 2005 Elsevier Ltd. All rights reserved.	State Univ Ghent, Dept Mkt, B-9000 Ghent, Belgium	Lariviere, B (reprint author), State Univ Ghent, Dept Mkt, Hoveniersberg 24, B-9000 Ghent, Belgium.	bart.lariviere@ugent.be					Athanassopoulos AD, 2000, J BUS RES, V47, P191, DOI 10.1016/S0148-2963(98)00060-5; Baesens B, 2004, EUR J OPER RES, V156, P508, DOI [10.1016/S0377-2217(03)00043-2, 10.1016/s0377-2217(03)00043-2]; Baesens B, 2002, EUR J OPER RES, V138, P191, DOI 10.1016/S0377-2217(01)00129-1; Bhattacharya CB, 1998, J ACAD MARKET SCI, V26, P31, DOI 10.1177/0092070398261004; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buckinx W, 2005, EUR J OPER RES, V164, P252, DOI 10.1016/j.ejor.2003.12.010; Colgate MR, 2000, J ACAD MARKET SCI, V28, P375, DOI 10.1177/0092070300283006; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Deng Y. P., 2004, BMC BIOINFORMATICS, V5, P1; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; GANESAN S, 1994, J MARKETING, V58, P1, DOI 10.2307/1252265; Ganesh J, 2000, J MARKETING, V64, P65, DOI 10.1509/jmkg.64.3.65.18028; Guenzi P, 2004, INT J SERV IND MANAG, V15, P365, DOI 10.1108/09564230410552059; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hoch SJ, 1999, MARKET SCI, V18, P527, DOI 10.1287/mksc.18.4.527; Hsieh NC, 2004, EXPERT SYST APPL, V27, P623, DOI 10.1016/j.eswa.2004.06.007; HUBER CP, 1998, MCKINSEY Q, P148; Hwang H, 2004, EXPERT SYST APPL, V26, P181, DOI 10.1016/S0957-4174(03)00133-7; Ishwaran H, 2004, J AM STAT ASSOC, V99, P591, DOI 10.1198/016214504000000638; Kamakura W.A., 1991, INT J RES MARK, V8, P329, DOI 10.1016/0167-8116(91)90030-B; Lariviere B, 2004, EXPERT SYST APPL, V27, P277, DOI 10.1016/j.eswa.2004.02.002; Lewis B. R., 1991, INT J BANK MARKETING, V9, P3, DOI 10.1108/02652329110001143; Luo T, 2004, IEEE T SYST MAN CY B, V34, P1753, DOI 10.1109/TSMCB.2004.830340; McNeal J.U., 1999, KIDS MARKET MYTHS RE; Patterson PG, 2003, J RETAILING, V79, P107, DOI 10.1016/S0022-4359(03)00009-5; Reinartz WJ, 2000, J MARKETING, V64, P17, DOI 10.1509/jmkg.64.4.17.18077; Reinartz WJ, 2003, J MARKETING, V67, P77, DOI 10.1509/jmkg.67.1.77.18589; Van den Poel D, 2004, EUR J OPER RES, V157, P196, DOI 10.1016/S0377-2217(03)00069-9; van Dolen W, 2002, J RETAILING, V78, P265, DOI 10.1016/S0022-4359(02)00067-2	30	60	62	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	AUG	2005	29	2					472	484		10.1016/j.eswa.2005.04.043		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	951RE	WOS:000230947400025		
J	Zhou, ZH; Yu, Y				Zhou, ZH; Yu, Y			Ensembling local learners through multimodal perturbation	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						data mining; ensemble learning; local learner; machine learning; multimodal perturbation; nearest-neighbor classifier; stable base learner	DECISION TREES; ACCURACY; CLASSIFIERS	Ensemble learning algorithms train multiple component learners and then combine their predictions. In order to generate a strong ensemble, the component learners should be with high accuracy as well as high diversity. A popularly used scheme in generating accurate but diverse component learners is to perturb the training data with resampling methods, such as the bootstrap sampling used in bagging. However, such a scheme is not very effective on local learners such as nearest-neighbor classifiers because a slight change in training data can hardly result in local learners with big differences. In this paper, a new ensemble algorithm named Filtered Attribute Subspace based Bagging with Injected Randomness (FASBIR) is proposed for building ensembles of local learners, which utilizes multimodal perturbation to help generate accurate but diverse component learners. In detail, FASBIR employs the perturbation on the training data with bootstrap sampling, the perturbation on the input attributes with attribute filtering and attribute subspace selection, and the perturbation on the learning parameters with randomly configured distance metrics. A large empirical study shows that FASBIR is effective in building ensembles of nearest-neighbor classifiers, whose performance is better than that of many other ensemble algorithms.	Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhouzh@nju.edu.cn; yuy@lamda.nju.edu.cn					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Alkoot FM, 2002, PATTERN ANAL APPL, V5, P326; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Bias Breiman L., 1996, 460 U CAL STAT DEP; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cherkauer K. J., 1996, P 13 AAAI WORKSH INT, P15; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Dietterich T, 2002, HDB BRAIN THEORY NEU; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Efron B, 1993, INTRO BOOTSTRAP; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; HALL LO, 2003, P 3 IEEE INT C DAT M, P533; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho T.K., 1998, LECT NOTES COMPUTER, V1451, P640; Kolen JF, 1991, ADV NEURAL INFORMATI, V3, P860; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; KWOK SW, 1988, P 4 ANN C UNCERTAINT, P327; Lam L., 2000, LECT NOTES COMPUTER, V1857, P78; Latinne P, 2000, LECT NOTES COMPUT SC, V1857, P200; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tumer K, 2003, PATTERN ANAL APPL, V6, P65, DOI 10.1007/s10044-002-0181-7; Vlachos M., 2002, P 8 ACM SIGKDD INT C, P645; Zhou ZH, 2005, J COMPUT SCI TECHNOL, V20, P48, DOI 10.1007/s11390-005-0005-5	30	45	56	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2005	35	4					725	735		10.1109/TSMCB.2005.845396		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	946JT	WOS:000230569000007	16128456	
J	Hamza, M; Larocque, D				Hamza, M; Larocque, D			An empirical comparison of ensemble methods based on classification trees	JOURNAL OF STATISTICAL COMPUTATION AND SIMULATION			English	Article						bagging; boosting; arcing; random forest (RF); classification tree; CART; noise; linear combination of variables; splitting rule; Gini; entropy; twoing	ALGORITHMS	In this paper, we perform an empirical comparison of the classification error of several ensemble methods based on classification trees. This comparison is performed by using 14 data sets that are publicly available and that were used by Lim, Loh and Shih [Lim, T., Loh, W. and Shih, Y.-S., 2000, A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms. Machine Learning, 40, 203-228.]. The methods considered are a single tree, Bagging, Boosting (Arcing) and random forests (RF). They are compared from different perspectives. More precisely, we look at the effects of noise and of allowing linear combinations in the construction of the trees, the differences between some splitting criteria and, specifically for RF, the effect of the number of variables from which to choose the best split at each given node. Moreover, we compare our results with those obtained by Lim et al. [Lim, T., Loh, W. and Shih, Y-S., 2000, A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms. Machine Learning, 40, 203-228.]. In this study, the best overall results are obtained with RF. In particular, RF are the most robust against noise. The effect of allowing linear combinations and the differences between splitting criteria are small on average, but can be substantial for some data sets.	HEC Montreal, Dept Management Sci, Montreal, PQ H3T 2A7, Canada	Larocque, D (reprint author), HEC Montreal, Dept Management Sci, 3000 Chemin Cote Sainte Catherine, Montreal, PQ H3T 2A7, Canada.	denis.larocque@hec.ca					Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1996, MACH LEARN, V24, P41, DOI 10.1023/A:1018094028462; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Maclin R., 1999, J ARTIFICIAL INTELLI, V11, P169; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; SERVEDIO RA, 2001, P 14 ANN C COMP LEAR, P472	15	27	27	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0094-9655			J STAT COMPUT SIM	J. Stat. Comput. Simul.	AUG	2005	75	8					629	643		10.1080/00949650410001729472		15	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	962AD	WOS:000231702500003		
J	Feng, BY; Shelat, A; Doman, TN; Guy, RK; Shoichet, BK				Feng, BY; Shelat, A; Doman, TN; Guy, RK; Shoichet, BK			High-throughput assays for promiscuous inhibitors	NATURE CHEMICAL BIOLOGY			English	Article							ORAL BIOAVAILABILITY; DRUG DISCOVERY; IDENTIFICATION; LIBRARIES; MOLECULES; MECHANISM	High-throughput screening (HTS) searches large libraries of chemical compounds for those that can modulate the activity of a particular biological target; it is the dominant technique used in early-stage drug discovery. A key problem in HTS is the prevalence of nonspecific or 'promiscuous' inhibitors. These molecules have peculiar properties, act on unrelated targets and can dominate the results from screening campaigns(1). Several explanations have been proposed to account for promiscuous inhibitors, including chemical reactivity(1,2), interference in assay read-out(2), high molecular flexibility(3) and hydrophobicity(2,4). The diversity of these models reflects the apparently unrelated molecules whose behaviors they seek to explain. However, a single mechanism may explain the effects of many promiscuous inhibitors: some organic molecules form large colloid-like aggregates that sequester and thereby inhibit enzymes(5). Hits from HTS, leads for drug discovery and even several drugs appear to act through this mechanism at micromolar concentrations(5-9). Here, we report two rapid assays for detecting promiscuous aggregates that we tested against 1,030 'drug-like' molecules. The results from these assays were used to test two preliminary computational models of this phenomenon and as benchmarks to develop new models.	Univ Calif San Francisco, Dept Pharmaceut Chem, San Francisco, CA 94143 USA; Univ Calif San Francisco, Grad Grp Chem & Chem Biol, San Francisco, CA 94143 USA; Eli Lilly & Co, Lilly Corp Ctr, Indianapolis, IN 46285 USA	Guy, RK (reprint author), Univ Calif San Francisco, Dept Pharmaceut Chem, 1700 4th St, San Francisco, CA 94143 USA.	rguy@cgl.ucsf.edu; shoichet@cgl.ucsf.edu	Guy, Rodney/G-4936-2013; Shelat, Anang /J-4995-2013; Guy, Rodney/J-7107-2013	Guy, Rodney/0000-0002-9638-2060			Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Frenkel YV, 2005, J MED CHEM, V48, P1974, DOI 10.1021/jm049439i; Ghose AK, 1999, J COMB CHEM, V1, P55, DOI 10.1021/cc9800071; Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1; McGovern SL, 2003, J MED CHEM, V46, P4265, DOI 10.1021/jm030266r; McGovern SL, 2002, J MED CHEM, V45, P1712, DOI 10.1021/jm010533y; McGovern SL, 2003, J MED CHEM, V46, P1478, DOI 10.1021/jm020427b; Rishton GM, 1997, DRUG DISCOV TODAY, V2, P382, DOI 10.1016/S1359-6446(97)01083-0; Roche O, 2002, J MED CHEM, V45, P137, DOI 10.1021/jm010934d; Ryan AJ, 2003, J MED CHEM, V46, P3448, DOI 10.1021/jm0340896; Seidler J, 2003, J MED CHEM, V46, P4477, DOI 10.1021/jm030191r; Veber DF, 2002, J MED CHEM, V45, P2615, DOI 10.1021/jm020017n; Walters WP, 1999, CURR OPIN CHEM BIOL, V3, P384, DOI 10.1016/S1367-5931(99)80058-1; Weston GS, 1998, J MED CHEM, V41, P4577, DOI 10.1021/jm980343w	14	175	179	NATURE PUBLISHING GROUP	NEW YORK	345 PARK AVENUE SOUTH, NEW YORK, NY 10010-1707 USA	1552-4450			NAT CHEM BIOL	Nat. Chem. Biol.	AUG	2005	1	3					146	148		10.1038/nchembio718		3	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	975GJ	WOS:000232648700013	16408018	
J	Geurts, P; Fillet, M; de Seny, D; Meuwis, MA; Malaise, M; Merville, MP; Wehenkel, L				Geurts, P; Fillet, M; de Seny, D; Meuwis, MA; Malaise, M; Merville, MP; Wehenkel, L			Proteomic mass spectra classification using decision tree based ensemble methods	BIOINFORMATICS			English	Article							OVARIAN-CANCER	Motivation: Modern mass spectrometry allows the determination of proteomic fingerprints of body fluids like serum, saliva or urine. These measurements can be used in many medical applications in order to diagnose the current state or predict the evolution of a disease. Recent developments in machine learning allow one to exploit such datasets, characterized by small numbers of very high-dimensional samples. Results: We propose a systematic approach based on decision tree ensemble methods, which is used to automatically determine proteomic biomarkers and predictive models. The approach is validated on two datasets of surface-enhanced laser desorption/ionization time of flight measurements, for the diagnosis of rheumatoid arthritis and inflammatory bowel diseases. The results suggest that the methodology can handle a broad class of similar problems.	Univ Liege, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium; Univ Liege, Lab Clin Chem & Rheumatol, CBIG, B-4000 Liege, Belgium	Geurts, P (reprint author), Univ Liege, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium.	p.geurts@ulg.ac.be					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Fung E. T., 2002, COMPUTATIONAL PROT S, V32, pS34; Hastie T., 2001, ELEMENTS STAT LEARNI; Izmirlian G, 2004, ANN NY ACAD SCI, V1020, P154, DOI 10.1196/annals.1310.015; Jong K, 2004, LECT NOTES COMPUT SC, V3005, P41; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Li J, 2003, BIOINFORMATICS S2, V19, pii93; Liu Huiqing, 2002, Genome Inform, V13, P51; Pusch W, 2003, PHARMACOGENOMICS, V4, P463, DOI 10.1517/phgs.4.4.463.22753; Qu YS, 2002, CLIN CHEM, V48, P1835; QUINLAN J, 1986, C4 5 PROGRAMS MACHIN; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; Wehenkel L., 1998, AUTOMATIC LEARNING T; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210	19	71	77	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JUL 15	2005	21	14					3138	3145		10.1093/bioinformatics/bti494		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	941GX	WOS:000230204400011	15890743	
J	Groner, RS; Peters, A; Brueckl, WM; Matzel, KE; Klein-Hitpass, L; Brabletz, T; Papadopoulos, T; Hohenberger, W; Reingruber, B; Lausen, B				Groner, RS; Peters, A; Brueckl, WM; Matzel, KE; Klein-Hitpass, L; Brabletz, T; Papadopoulos, T; Hohenberger, W; Reingruber, B; Lausen, B			Microarray versus conventional prediction of lymph node metastasis in colorectal carcinoma	CANCER			English	Article						gene expression; colorectal carcinoma; lymph node metastasis; microarray	ENDOTHELIAL GROWTH-FACTOR; GENE-EXPRESSION PROFILES; ENDOSCOPIC TREATMENT; PROGNOSTIC-FACTORS; CDNA MICROARRAY; T1 CARCINOMA; RISK-FACTORS; CANCER; RECTUM; COLON	BACKGROUND. The authors investigated whether microarray-based gene expression analysis of primary tumor biopsy material could be used to predict lymph node status in patients with colorectal carcinoma (CRC). Lymphatic metastasis strongly determines treatment algorithms in CRC. Currently, postoperative histology results are needed to determine lymph node status. Reliable preoperative information would be useful to advance treatment strategies. METHODS. in specimens from 66 patients with CRC from the Erlangen Registry of Colorectal Cancer, 41 shock-frozen samples of International Union Against Cancer (UICC) Stage I-II CRC and 25 samples of UICC Stage III CRC were microdissected manually, RNA was isolated, and gene chips (HG-U133A; Affymetrix) were hybridized. Prediction rates for lymphatic metastasis were calculated using conventional clinicopathologic parameters, gene expression data, and a combination of both. Prediction error, specificity, and sensitivity were analyzed using six different statistical classifiers. RESULTS. Analysis of conventional parameters produced a positive prediction rate that ranged between 53% and 61%, sensitivity of 42%, and specificity of 72%. Microarray prediction rates were between 62% and 67% for lymphatic metastasis. Specificity was between 76% and 83%, and sensitivity was between 38% and 48%, depending on the statistical procedure. The conventional estimates were improved by 9-12% when array data were added. CONCLUSIONS. Current data show that the prediction of lymphatic metastasis can be improved by gene expression profiling of the primary tumor biopsy, alone or in combination with conventional parameters. Gene expression profiling may become valuable increasingly in planning treatment for patients with CRC. (c) 2005 American Cancer Society.	Univ Erlangen Nurnberg, Dept Surg, D-91054 Erlangen, Germany; Univ Erlangen Nurnberg, Dept Med Informat Biometry & Epidemiol, D-91054 Erlangen, Germany; Univ Erlangen Nurnberg, Dept Internal Med 1, D-91054 Erlangen, Germany; Univ Essen Gesamthsch, Dept Cell Biol, Essen, Germany; Univ Erlangen Nurnberg, Dept Pathol, D-91054 Erlangen, Germany	Groner, RS (reprint author), Univ Erlangen Nurnberg, Dept Surg, Krankenhausstr 12, D-91054 Erlangen, Germany.	roland.croner@chir.imed.uni-erlangen.de	Lausen, Berthold/D-4063-2012	Lausen, Berthold/0000-0002-0594-7258			Affymetrix, 2002, STAT ALG DESCR DOC; Aoki R, 1998, DIS COLON RECTUM, V41, P1262, DOI 10.1007/BF02258227; BIRKENKAMPDEMTRODE, 2002, CANCER RES, V62, P4352; Breiman L., 1996, OUT OF BAG ESTIMATIO; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Church James M, 2003, Dis Colon Rectum, V46, P389, DOI 10.1007/s10350-004-6561-x; Croner RS, 2004, J LAB CLIN MED, V143, P344, DOI 10.1016/j.lab.2004.03.003; DeRisi J, 1996, NAT GENET, V14, P457; Durig J, 2003, BLOOD, V101, P2748, DOI 10.1182/blood-2002-09-2683; Egashira Y, 2004, MODERN PATHOL, V17, P503, DOI 10.1038/modpathol.3800030; Frederiksen CM, 2003, J CANCER RES CLIN, V129, P263, DOI 10.1007/s00432-003-0434-x; Fujisaki K, 1998, AM J GASTROENTEROL, V93, P249; Gentleman R, 2002, R NEWS, V2, P11; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hermanek P, 2000, ZBL CHIR, V125, P790, DOI 10.1055/s-2000-10046; HERMANEK P, 1995, TUMORI, V81, P60; Hippo Y, 2002, CANCER RES, V62, P233; Hohenberger W, 1998, LANGENBECK ARCH SURG, V383, P402, DOI 10.1007/s004230050152; Hohenberger W, 1997, RECTAL CANC SURG OPT, P353; HOTHORN T, IN PRESS COMPUT STAT; Hothorn T, 2003, PATTERN RECOGN, V36, P1303, DOI 10.1016/S0031-3203(02)00169-3; Hsiao LL, 2001, PHYSIOL GENOMICS, V7, P97; Huang J, 2001, J SURG RES, V99, P222, DOI 10.1006/jsre.2001.6195; Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Irizarry RA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng015; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Karayiannakis AJ, 2002, SURGERY, V131, P548, DOI 10.1067/msy.2002.123011; Koumura H, 1997, Gan To Kagaku Ryoho, V24 Suppl 2, P324; Lau WY, 2000, ONCOL RES, V12, P59; Lausen B, 2004, BIOMETRICAL J, V46, P364, DOI 10.1002/bimj.200310030; Lauter J, 1998, ANN STAT, V26, P1972; LAUTER J, 1992, STABILE MULTIVARIATE; Leethanakul C, 2000, ORAL ONCOL, V36, P474, DOI 10.1016/S1368-8375(00)00039-7; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Maeda K, 2003, SURG TODAY, V33, P736, DOI 10.1007/s00595-003-2592-5; Matsumoto T, 2002, GASTROINTEST ENDOSC, V56, P354, DOI 10.1067/mge.2002.127156; Nachamkin I, 2001, J CLIN MICROBIOL, V39, P754, DOI 10.1128/JCM.39.2.754-757.2001; Nascimbeni R, 2002, DIS COLON RECTUM, V45, P200, DOI 10.1007/s10350-004-6147-7; Notterman DA, 2001, CANCER RES, V61, P3124; Oh-e H, 2001, DIS COLON RECTUM, V44, P1129, DOI 10.1007/BF02234633; Okuyama T, 2002, DIS COLON RECTUM, V45, P628, DOI 10.1007/s10350-004-6259-0; Peters A., 2002, R NEWS, V2, P33; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Sakuragi M, 2003, DIS COLON RECTUM, V46, P1626, DOI 10.1097/01.DCR.0000100821.53077.DD; Sauer Rolf, 2002, Pathology and Oncology Research, V8, P7; SMITH CA, 2003, R NEWS, V3, P17; Sobin L., 2002, TNM CLASSIFICATION M, V2nd; Stremmel C, 2002, INT J COLORECTAL DIS, V17, P131, DOI 10.1007/s00384-001-0370-7; TANAKA S, 1995, ONCOLOGY, V52, P134; TANAKA S, 1995, J GASTROENTEROL, V30, P710, DOI 10.1007/BF02349636; Tannapfel A, 1997, AM J GASTROENTEROL, V92, P1182; Vapnik V, 2000, NATURE STAT LEARNING; Westfall Peter H., 1993, RESAMPLING BASED MUL; Yamaguchi A, 1996, J CLIN ONCOL, V14, P1122; Yamamoto H, 2003, J PATHOL, V199, P176, DOI 10.1002/path.1277	57	0	1	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0008-543X	1097-0142		CANCER-AM CANCER SOC	Cancer	JUL 15	2005	104	2					395	404		10.1002/cncr.21170		10	Oncology	Oncology	943CZ	WOS:000230331000024		
J	Buckinx, W; Van den Poel, D				Buckinx, W; Van den Poel, D			Customer base analysis: partial defection of behaviourally loyal clients in a non-contractual FMCG retail setting	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article						marketing; customer relationship management; forecasting; churn analysis; retention analysis; retailing; classification; logistic regression; ARD neural networks; random forests	SWITCHING BEHAVIOR; EVIDENCE FRAMEWORK; MARKET SHARE; SERVICES; SATISFACTION; CLASSIFICATION; PROFITABILITY; RETENTION; NETWORKS; PROVIDER	Customer relationship management (CRM) enjoys increasing attention as a countermeasure to switching behaviour of customers. Because foregone profits of (partially) defected customers can be significant, an increase of the retention rate can be very profitable. In this paper we focus on the treatment of a company's most behaviourally loyal customers in a non-contractual setting. We build a model in order to predict partial defection by behaviourally loyal clients using three classification techniques: Logistic regression, automatic relevance determination (ARD) Neural Networks and Random Forests. Focusing on partial attrition of high-frequency shoppers who exhibit a regular visit pattern may overcome the problem of unidentifiability of total defection in non-contractual settings. Classification accuracy (PCC) and area under the receiver operating characteristic curve (AUC) are used to evaluate classifier performance on a test/hold-out sample. Using real-life data from an FMCG retailer, we show that future partial defection can be successfully predicted, i.e. exceeding the benchmark hurdle of the null model. There are no significant differences in terms of performance among alternative classification techniques. Similar to direct-marketing applications we find that past behavioural variables, more specifically RFM variables (recency, frequency, and monetary value) are the best predictors of partial customer defection. This set of variables complements demographic variables confirming findings by other authors about its importance in predicting churn behaviour. Moreover, additional variables (listed in decreasing order of importance) such as the length of customer relationship, mode of payment, buying behaviour across categories, usage of promotions and brand purchase behaviour are shown to be moderately useful to incorporate in attrition models. (C) 2004 Elsevier B.V. All rights reserved.	State Univ Ghent, Dept Mkt, B-9000 Ghent, Belgium	Van den Poel, D (reprint author), State Univ Ghent, Dept Mkt, Hoveniersberg 24, B-9000 Ghent, Belgium.	wouter.buckinx@ugent.be; dirk.vandenpoel@ugent.be	Van den Poel, Dirk/	Van den Poel, Dirk/0000-0002-8676-8103			ANDERSON E, 1989, MARKET SCI, V8, P310, DOI 10.1287/mksc.8.4.310; ANDERSON EW, 1994, J MARKETING, V58, P53, DOI 10.2307/1252310; Anderson J., 1982, HDB STATISTICS, P169, DOI 10.1016/S0169-7161(82)02010-0; Athanassopoulos AD, 2000, J BUS RES, V47, P191, DOI 10.1016/S0148-2963(98)00060-5; BAESENS B, 2004, EUROPEAN J OPERATION, V156, P242; Baesens B, 2002, EUR J OPER RES, V138, P191, DOI 10.1016/S0377-2217(01)00129-1; BAWA K, 1987, J MARKETING, V51, P99, DOI 10.2307/1251251; Bhattacharjee S, 1998, SEED SCI TECHNOL, V26, P1; BLATTBERG RC, 2000, CUSTOMER EQUITY BUIL; Bloemer JMM, 2003, INT J RES MARK, V20, P117, DOI 10.1016/S0167-8116(03)00014-4; Bolton RN, 1998, MARKET SCI, V17, P45, DOI 10.1287/mksc.17.1.45; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUCKINX W, 2004, IN PRESS EXPERT SYST; CARROLL P, 1993, J RETAIL BANKING, V15, P7; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Colgate M., 1996, INT J BANK MARKETING, V14, P23, DOI 10.1108/02652329610113144; Corstjens M, 2000, J MARKETING RES, V37, P281, DOI 10.1509/jmkr.37.3.281.18781; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Dwyer Robert F., 1997, J DIRECT MARKETING, V11, P6; Ganesh J, 2000, J MARKETING, V64, P65, DOI 10.1509/jmkg.64.3.65.18028; Hoekstra Janny C., 1999, J MARKET FOCUSED MAN, V3, P257, DOI 10.1023/A:1009842805871; Jones MA, 2000, J RETAILING, V76, P259, DOI 10.1016/S0022-4359(00)00024-5; Keaveney SM, 2001, J ACAD MARKET SCI, V29, P374, DOI 10.1177/03079450094225; Kim SY, 1999, MARKET SCI, V18, P59, DOI 10.1287/mksc.18.1.59; Lemon KN, 2002, J MARKETING, V66, P1, DOI 10.1509/jmkg.66.1.1.18447; Lindgreen A., 2002, J RELATIONSHIP MARKE, V1, P69, DOI 10.1300/J366v01n03_05; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; Mittal B., 1998, J SERV MARK, V12, P177, DOI 10.1108/08876049810219502; Mittal V, 2001, J MARKETING RES, V38, P131, DOI 10.1509/jmkr.38.1.131.18832; MIZERSKI RW, 1982, J CONSUM RES, V9, P301, DOI 10.1086/208925; MORGAN RM, 1994, J MARKETING, V58, P20, DOI 10.2307/1252308; MORRISON DG, 1969, J MARKETING RES, V6, P156, DOI 10.2307/3149666; MORWITZ VG, 1993, J CONSUM RES, V20, P46, DOI 10.1086/209332; Mozer MC, 2000, IEEE T NEURAL NETWOR, V11, P690, DOI 10.1109/72.846740; Nabney I., 2001, NETLAB ALGORITHMS PA; NIELSEN AC, 2001, MAJOR STUDY TRACK ST; Niraj R, 2001, J MARKETING, V65, P1, DOI 10.1509/jmkg.65.3.1.18332; OBRIEN L, 1995, HARVARD BUS REV, V73, P75; PEELEN E, 1989, J DIRECT MARKETING, V3, P7, DOI 10.1002/dir.4000030104; Penny WD, 1999, NEURAL NETWORKS, V12, P877, DOI 10.1016/S0893-6080(99)00040-4; Peterson R. A., 1995, J ACAD MARKET SCI, V23, P278, DOI 10.1177/009207039502300407; POPKOWSKI LPT, 2000, J RETAILING, V76, P323; Reichheld FF, 1996, HARVARD BUS REV, V74, P56; REICHHELD FF, 1990, HARVARD BUS REV, V68, P105; Reinartz W, 2002, HARVARD BUS REV, V80, P86; Reinartz WJ, 2000, J MARKETING, V64, P17, DOI 10.1509/jmkg.64.4.17.18077; RUST RT, 1993, J RETAILING, V69, P193, DOI 10.1016/0022-4359(93)90003-2; SCHMITTLEIN DC, 1994, MARKET SCI, V13, P41, DOI 10.1287/mksc.13.1.41; Sheth J. N., 1995, J ACAD MARKET SCI, V23, P255, DOI 10.1177/009207039502300405; SONNENBERG F, 1990, MARKETING WIN; STUM DL, 1991, TRAIN DEV J, V45, P34; VAKRATSAS D, 1998, J CONSUMER MARKETING, V15, P6, DOI 10.1108/07363769810202646; Van den Poel D., 2003, TIJDSCHRIFT EC MANAG, V48, P371; Van den Poel D, 2004, EUR J OPER RES, V157, P196, DOI 10.1016/S0377-2217(03)00069-9; Verhoef PC, 2002, J ACAD MARKET SCI, V30, P202, DOI 10.1177/00970302030003002; VERSTRAETEN G, 2002, DATA MINING, V3, P521; VIAENE S, 2002, INT J INTELL SYST, V16, P1023; WEERAHANDI S, 1995, J MARKETING RES, V32, P85, DOI 10.2307/3152113; Wu CC, 2000, EUR J OPER RES, V127, P109, DOI 10.1016/S0377-2217(99)00326-4; Zeithaml VA, 1996, J MARKETING, V60, P31, DOI 10.2307/1251929; Zhang Q, 2002, IEEE T INFORM THEORY, V48, P2105; Ziliani C., 2000, The International Review of Retail, Distribution and Consumer Research, V10, P355, DOI 10.1080/09593960050138921	65	84	86	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217			EUR J OPER RES	Eur. J. Oper. Res.	JUL 1	2005	164	1					252	268		10.1016/j.ejor.2003.12.010		17	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	888CA	WOS:000226350600021		
J	Li, SQ; Fedorowicz, A; Singh, H; Soderholm, SC				Li, SQ; Fedorowicz, A; Singh, H; Soderholm, SC			Application of the random forest method in studies of local lymph node assay based skin sensitization data	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							TOXICITY; MODEL	The random forest and classification tree modeling methods are used to build predictive models of the skin sensitization activity of a chemical. A new two-stage backward elimination algorithm for descriptor selection in the random forest method is introduced. The predictive performance of the random forest model was maximized by tuning voting thresholds to reflect the unbalanced size of classification groups in available data. Our results show that random forest with a proposed backward elimination procedure outperforms a single classification tree and the standard random forest method in predicting Local Lymph Node Assay based skin sensitization activity. The proximity measure obtained from the random forest is a natural similarity measure that can be used for clustering of chemicals. Based on this measure, the clustering analysis partitioned the chemicals into several groups sharing similar molecular patterns. The improved random forest method demonstrates the potential for future QSAR studies based on a large number of descriptors or when the number of available data points is limited.	NIOSH, Hlth Effect Lab Div, Morgantown, WV 26505 USA; W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA	Li, SQ (reprint author), NIOSH, Hlth Effect Lab Div, Morgantown, WV 26505 USA.	sw14@cdc.gov					Andersen KE, 2003, INT ARCH OCC ENV HEA, V76, P347, DOI 10.1007/s00420-002-0420-7; ASHBY J, 1995, CONTACT DERMATITIS, V33, P165, DOI 10.1111/j.1600-0536.1995.tb00538.x; BASKETTER DA, 1992, CONTACT DERMATITIS, V27, P137, DOI 10.1111/j.1600-0536.1992.tb05241.x; BREIMAN L, 2003, RF TOOLS CLASS 2 EYE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DUPUIS G, 1982, ALLERGIC CONTACT DER; ELSNER LP, 2000, HDB OCCUPATIONAL DER; Enslein K, 1997, FOOD CHEM TOXICOL, V35, P1091, DOI 10.1016/S0278-6915(97)87277-8; FEDOROWICZ A, 2005, IN PRESS CHEM RES TO; Fedorowicz A, 2004, INT J MOL SCI, V5, P55; Gao H, 1999, J CHEM INF COMP SCI, V39, P164, DOI 10.1021/ci980140g; Guo L., 2004, P 15 INT S SOFTW REL, P417, DOI DOI 10.1109/ISSRE.2004.35; Haneke KE, 2001, REGUL TOXICOL PHARM, V34, P274, DOI 10.1006/rtph.2001.1498; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Lushniak BD, 2003, INT ARCH OCC ENV HEA, V76, P325, DOI 10.1007/s00420-002-0417-2; Mosier PD, 2003, CHEM RES TOXICOL, V16, P721, DOI 10.1021/tx020104i; National Institutes of Health (NIH), 1999, NIH PUBL, V99-4564; Patlewicz G, 2001, CONTACT DERMATITIS, V44, P331, DOI 10.1034/j.1600-0536.2001.044006331.x; *R, R R DEV COR TEAM; REMLINGER K, 2004, INTRO APPL RANDOM FO; Ren SJ, 2002, TOXICOL LETT, V129, P151, DOI 10.1016/S0378-4274(01)00550-1; Roberts DW, 2000, CONTACT DERMATITIS, V42, P154, DOI 10.1034/j.1600-0536.2000.042003154.x; Rodford R, 2003, ENVIRON TOXICOL CHEM, V22, P1855, DOI 10.1897/01-438; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g	24	33	34	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	JUL-AUG	2005	45	4					952	964		10.1021/ci050049u		13	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	950NO	WOS:000230864300016	16045289	
J	Guha, R; Stanton, DT; Jurs, PC				Guha, R; Stanton, DT; Jurs, PC			Interpreting computational neural network quantitative structure-activity relationship models: A detailed interpretation of the weights and biases	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							STRUCTURE-PROPERTY RELATIONSHIP; QSAR MODELS; BIOLOGICAL-ACTIVITY; DESCRIPTORS; PREDICTION; EXTRACTION; RULES; SET	In this work, we present a methodology to interpret the weights and biases of a computational neural network (CNN) quantitative structure-activity relationship model. The methodology allows one to understand how an input descriptor is correlated to the predicted output by the network. The method consists of two parts. First, the nonlinear transform for a given neuron is linearized. This allows LIS to determine how a given neuron affects the downstream output. Next, a ranking scheme for neurons in a layer is developed. This allows us to develop interpretations of a CNN model similar in manner to the partial least squares (PLS) interpretation method for linear models described by Stanton (Stanton, D. T. J. Chem. Inf. Comput. Sci. 2003, 43 1423-1433). The method is tested on three datasets covering both physical and biological properties. The results of this interpretation method correspond well to PLS interpretations for linear models using the same descriptors as the CNN models, and they are consistent with the generally accepted physical interpretations for these properties.	Penn State Univ, Dept Chem, University Pk, PA 16802 USA; Procter & Gamble Co, Miami Valley Labs, Cincinnati, OH 45252 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, University Pk, PA 16802 USA.	pcj@psu.edu					AUDUS KL, 1992, ADV DRUG RES, V23, P1; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; BOLOGNA G, 2000, P 6 BRAZ S NEUR NETW; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Castro JL, 2002, IEEE T NEURAL NETWOR, V13, P101, DOI 10.1109/72.977279; CHASTRETTE M, 1994, EUR J MED CHEM, V29, P343, DOI 10.1016/0223-5234(94)90058-2; CHEN PCY, 1997, NEURAL NETWORKS; Chipman HA, 1998, COMP SCI STAT, V30, P84; FU X, 2001, EVOLUTIONARY COMPUTA; GARSON DG, 1991, AI EXPERT        APR, P47; Goll ES, 1999, J CHEM INF COMP SCI, V39, P974, DOI 10.1021/ci9900711; Gratton JA, 1997, J PHARM PHARMACOL, V49, P1211; Guha R, 2004, J CHEM INF COMP SCI, V44, P1440, DOI 10.1021/ci0499469; Guha R, 2005, J CHEM INF MODEL, V45, P800, DOI 10.1021/ci050022a; Guha R, 2004, J CHEM INF COMP SCI, V44, P2179, DOI 10.1021/ci049849f; Gupta A, 1999, IEEE T KNOWL DATA EN, V11, P985, DOI 10.1109/69.824621; HAWKINS DM, 1998, COMPUT SCI STAT, V30, P543; Haykin S, 2001, NEURAL NETWORKS; Hervas C, 2004, J CHEM INF COMP SCI, V44, P1576, DOI 10.1021/ci049948t; HORNIK K, 1993, NEURAL NETWORKS, V6, P1069; ISHIBUCHI H, 1999, FUZZ SYST C P IEEE I; Kier L., 1986, MOL CONNECTIVITY STR; Kier L. B., 1975, J PHARM SCI, V64; Kier L. B., 1976, MOL CONNECTIVITY CHE; KIER LB, 1976, J PHARM SCI, V65, P1806, DOI 10.1002/jps.2600651228; LiMin Fu, 1994, IEEE Transactions on Systems, Man and Cybernetics, V24, DOI 10.1109/21.299696; Mak B, 1998, IEEE T SYST MAN CY C, V28, P561, DOI 10.1109/5326.725342; MATTIONI BE, 2003, THESIS PENNSYLVANIA; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Patel H, 2002, CHEMOSPHERE, V48, P603, DOI 10.1016/S0045-6535(02)00114-5; RANDIC M, 1984, J CHEM INF COMP SCI, V24, P164, DOI 10.1021/ci00043a009; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; SATO M, 2001, NEURAL NETWORKS; SIU KY, 1992, NEURAL NETWORKS; STANTON DT, 1990, ANAL CHEM, V62, P2323, DOI 10.1021/ac00220a013; Stanton DT, 2004, J CHEM INF COMP SCI, V44, P1010, DOI 10.1021/ci034284t; Stanton DT, 2003, J CHEM INF COMP SCI, V43, P1423, DOI 10.1021/ci0340658; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; TICKLE AB, 1997, NEURAL NETWORKS; URBANEK S, 2002, IN PRESS P 2002 JOIN; YAO S, 1996, FUZZY SYSTEMS; YOON Y, 1994, DECIS SUPPORT SYST, V11, P497, DOI 10.1016/0167-9236(94)90021-3	43	40	42	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	JUL-AUG	2005	45	4					1109	1121		10.1021/ci050110v		13	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	950NO	WOS:000230864300033	16045306	
J	Tutz, G; Binder, H				Tutz, G; Binder, H			Localized classification	STATISTICS AND COMPUTING			English	Article						local logistic regression; discrimination; data adaptive tuning parameters; selection of predictors; localized discrimination	LOGISTIC-REGRESSION; MODELS; APPROXIMATION	The main problem with localized discriminant techniques is the curse of dimensionality, which seems to restrict their use to the case of few variables. However, if localization is combined with a reduction of dimension the initial number of variables is less restricted. In particular it is shown that localization yields powerful classifiers even in higher dimensions if localization is combined with locally adaptive selection of predictors. A robust localized logistic regression ( LLR) method is developed for which all tuning parameters are chosen data- adaptively. In an extended simulation study we evaluate the potential of the proposed procedure for various types of data and compare it to other classification procedures. In addition we demonstrate that automatic choice of localization, predictor selection and penalty parameters based on cross validation is working well. Finally the method is applied to real data sets and its real world performance is compared to alternative procedures.	Univ Munich, Inst Stat, D-80799 Munich, Germany; Univ Regensburg, Klin & Poliklin Psychiat & Psychotherapie, D-8400 Regensburg, Germany	Tutz, G (reprint author), Univ Munich, Inst Stat, Akad Str 1, D-80799 Munich, Germany.	tutz@stat.uni-muenchen.de	Binder, Harald/C-7413-2009	Binder, Harald/0000-0002-5666-8662			ALBERT A, 1984, BIOMETRIKA, V71, P1; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Breiman L, 2002, MANUAL SETTING USING; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; CHAPELLE O, 1999, ADV NEURAL INFORMATI, V12; Efron B, 2004, ANN STAT, V32, P407; Fix E., 1951, 4 US AIR FORC SCH AV; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Gijbels T, 1996, LOCAL POLYNOMIAL MOD; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; Hand DJ, 2003, AM STAT, V57, P124, DOI 10.1198/0003130031423; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HOERL AE, 1970, TECHNOMETRICS, V12, P55; HOLM S, 1979, SCAND J STAT, V6, P65; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Kauermann G, 2000, J NONPARAMETR STAT, V12, P343, DOI 10.1080/10485250008832812; KIRA K, 1992, MACHINE LEARNING /, P249; Kohavi R., 1998, FEATURE SELECTION KN, P33; Loader C, 1999, LOCAL REGRESSION LIK; Michie D., 1994, MACHINE LEARNING NEU; Powell MJD, 2002, MATH PROGRAM, V92, P555, DOI 10.1007/s101070100290; RIEDMAN JH, 1994, FLEXIBLE METRIC NEAR; Ripley B. D., 1996, PATTERN RECOGNITION; SCHAAL S, 1998, ADV NEURAL INFORMATI, V10; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Venables WN, 1999, MODERN APPL STAT S P	35	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0960-3174			STAT COMPUT	Stat. Comput.	JUL	2005	15	3					155	166		10.1007/s11222-005-1305-x		12	Computer Science, Theory & Methods; Statistics & Probability	Computer Science; Mathematics	937EH	WOS:000229906900001		
J	Seligson, DB; Horvath, S; Shi, T; Yu, H; Tze, S; Grunstein, M; Kurdistani, SK				Seligson, DB; Horvath, S; Shi, T; Yu, H; Tze, S; Grunstein, M; Kurdistani, SK			Global histone modification patterns predict risk of prostate cancer recurrence	NATURE			English	Article							TARGETED RECRUITMENT; GENE-EXPRESSION; ACETYLATION; YEAST; CHROMATIN; ANTIGEN; P300	Aberrations in post-translational modifications of histones have been shown to occur in cancer cells but only at individual promoters(1); they have not been related to clinical outcome. Other than being targeted to promoters, modifications of histones, such as acetylation and methylation of lysine and arginine residues, also occur over large regions of chromatin including coding regions and non-promoter sequences, which are referred to as global histone modifications(2). Here we show that changes in global levels of individual histone modifications are also associated with cancer and that these changes are predictive of clinical outcome. Through immunohistochemical staining of primary prostatectomy tissue samples, we determined the percentage of cells that stained for the histone acetylation and dimethylation of five residues in histones H3 and H4. Grouping of samples with similar patterns of modifications identified two disease subtypes with distinct risks of tumour recurrence in patients with low-grade prostate cancer. These histone modification patterns were predictors of outcome independently of tumour stage, preoperative prostate-specific antigen levels, and capsule invasion. Thus, widespread changes in specific histone modifications indicate previously undescribed molecular heterogeneity in prostate cancer and might underlie the broad range of clinical behaviour in cancer patients.	Univ Calif Los Angeles, David Geffen Sch Med, Dept Biol Chem, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, David Geffen Sch Med, Dept Pathol & Lab Med, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, David Geffen Sch Med, Dept Human Genet, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Sch Publ Hlth, Dept Biostat, Los Angeles, CA 90095 USA	Kurdistani, SK (reprint author), Univ Calif Los Angeles, David Geffen Sch Med, Dept Biol Chem, Los Angeles, CA 90095 USA.	skurdistani@mednet.ucla.edu					Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bunting PS, 2002, CLIN CHIM ACTA, V315, P71, DOI 10.1016/S0009-8981(01)00717-3; Cleveland W., 1993, VISUALIZING DATA; Debes JD, 2003, CANCER RES, V63, P7638; Farkas A, 1998, UROLOGY, V52, P444, DOI 10.1016/S0090-4295(98)00242-8; Fraga MF, 2005, NAT GENET, V37, P391, DOI 10.1038/ng1531; Gayther SA, 2000, NAT GENET, V24, P300, DOI 10.1038/73536; Giles RH, 1998, TRENDS GENET, V14, P178, DOI 10.1016/S0168-9525(98)01438-3; GLEASON DONALD F., 1966, CANCER CHEMO THERAP REP, V50, P125; Han M, 2001, J UROLOGY, V166, P416, DOI 10.1016/S0022-5347(05)65955-1; Jacobson S, 1999, CURR OPIN GENET DEV, V9, P175, DOI 10.1016/S0959-437X(99)80027-6; Jemal A, 2003, CA-CANCER J CLIN, V53, P5; Kononen J, 1998, NAT MED, V4, P844, DOI 10.1038/nm0798-844; Krebs JE, 2000, CELL, V102, P587, DOI 10.1016/S0092-8674(00)00081-7; Kurdistani SK, 2004, CELL, V117, P721, DOI 10.1016/j.cell.2004.05.023; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; Muraoka M, 1996, ONCOGENE, V12, P1565; Peterson CL, 2004, CURR BIOL, V14, pR546, DOI 10.1016/j.cub.2004.07.007; Reid JL, 2000, MOL CELL, V6, P1297, DOI 10.1016/S1097-2765(00)00128-3; Rezai-Zadeh N, 2003, GENE DEV, V17, P1019, DOI 10.1101/gad.1068003; Shi T, 2005, MODERN PATHOL, V18, P547, DOI 10.1038/modpathol.3800322; Suka N, 2001, MOL CELL, V8, P473, DOI 10.1016/S1097-2765(01)00301-X; Vogelauer M, 2000, NATURE, V408, P495	24	503	531	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	0028-0836			NATURE	Nature	JUN 30	2005	435	7046					1262	1266		10.1038/nature03672		5	Multidisciplinary Sciences	Science & Technology - Other Topics	940JJ	WOS:000230140500049	15988529	
J	Hothorn, T; Lausen, B				Hothorn, T; Lausen, B			Bundling classifiers by bagging trees	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						bagging; ensemble-methods; method selection; error rate estimation	COMBINED CLASSIFICATION RULE; COMBINING CLASSIFIERS; MULTIVARIATE TESTS; REGRESSION	The quest of selecting the best classifier for a discriminant analysis problem is often rather difficult. A combination of different types of classifiers promises to lead to improved predictive models compared to selecting one of the competitors. An additional learning sample, for example the out-of-bag sample, is used for the training of arbitrary classifiers. Classification trees are employed to bundle their predictions for the bootstrap sample. Consequently, a combined classifier is developed. Benchmark experiments show that the combined classifier is superior to any of the single classifiers in many applications. (c) 2004 Elsevier B.V. All rights reserved.	Univ Erlangen Nurnberg, Inst Med Informat Biometrie & Epidemiol, D-91054 Erlangen, Germany	Hothorn, T (reprint author), Univ Erlangen Nurnberg, Inst Med Informat Biometrie & Epidemiol, Waldstr 6, D-91054 Erlangen, Germany.	torsten.hothorn@rzmail.uni-erlangen.de; berthold.lausen@rzmail.uni-erlangen.de	Hothorn, Torsten/A-3639-2010; Lausen, Berthold/D-4063-2012	Hothorn, Torsten/0000-0001-8301-0471; Lausen, Berthold/0000-0002-0594-7258			Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Buhlmann P, 2002, ANN STAT, V30, P927; Buttrey SE, 2002, COMPUT STAT DATA AN, V40, P27, DOI 10.1016/S0167-9473(01)00098-6; Bylander T, 2002, MACH LEARN, V48, P287, DOI 10.1023/A:1013964023376; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Hothorn T, 2003, ARTIF INTELL MED, V27, P65, DOI 10.1016/S0933-3657(02)00085-4; Hothorn T, 2003, PATTERN RECOGN, V36, P1303, DOI 10.1016/S0031-3203(02)00169-3; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; Lauter J, 1999, ANN STAT, V27, P1441; Lauter J, 1998, ANN STAT, V26, P1972; Lauter J, 1996, BIOMETRICAL J, V38, P5; LAUTER J, 1992, STABILE MULTIVARIATE; LeBlanc M, 1996, J AM STAT ASSOC, V91, P1641, DOI 10.2307/2291591; LEISCH F, 2001, MLBENCH COLLECTION A; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Merz CJ, 1999, MACH LEARN, V36, P33, DOI 10.1023/A:1007559205422; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Mojirsheibani M, 1999, J AM STAT ASSOC, V94, P600; Mojirsheibani M, 2002, J MULTIVARIATE ANAL, V81, P28, DOI 10.1006/jmva.2001.1990; Mojirsheibani M, 1997, STAT PROBABIL LETT, V36, P43, DOI 10.1016/S0167-7152(97)00047-3; Peters A., 2002, R NEWS, V2, P33; RAO JS, 1997, OUT OB BOOTSTRAP MET; Yang YH, 2003, STAT SINICA, V13, P783; Yang YH, 2001, J AM STAT ASSOC, V96, P574, DOI 10.1198/016214501753168262	34	47	48	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JUN 15	2005	49	4					1068	1078		10.1016/j.csda.2004.06.019		11	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	939MP	WOS:000230077400007		
J	Ding, BY; Gentleman, R				Ding, BY; Gentleman, R			Classification using generalized partial least squares	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						cross-validation; Firth's procedure; gene expression; iteratively reweighted partial least squares; (quasi) separation; two-stage PLS	GENE-EXPRESSION DATA; LOGISTIC-REGRESSION MODELS; CANCER CLASSIFICATION; EXISTENCE; SELECTION; PATTERNS; TUMOR; BIAS	Advances in computational biology have made simultaneous monitoring of thousands of features possible. The high throughput technologies not only bring about a much richer information context in which to study various aspects of gene function, but they also present the challenge of analyzing data with a large number of covariates and few samples. As an integral part of machine learning, classification of samples into two or more categories is almost always of interest to scientists. We address the question of classification in this setting by extending partial least squares (PLS), a popular dimension reduction tool in chemometrics, in the context of generalized linear regression, based on a previous approach, iteratively reweighted partial least squares, that is, IRWPLS. We compare our results with two-stage PLS and with other classifiers. We show that by phrasing the problem in a generalized linear model setting and by applying Firth's procedure to avoid (quasi)separation, we often get lower classification error rates.	Amgen Inc, Med Affairs Biostat, Newbury Pk, CA 91320 USA; Fred Hutchinson Canc Res Ctr, Program Computat Biol, Div Publ Hlth Sci, Seattle, WA 98104 USA	Ding, BY (reprint author), Amgen Inc, Med Affairs Biostat, 1 Amgen Ctr Dr,Mail Stop 24-2-A, Newbury Pk, CA 91320 USA.	bding@amgen.com; rgentlem@fhcrc.org					ALBERT A, 1984, BIOMETRIKA, V71, P1; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Breiman L, 2002, MANUAL SETTING USING; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen Y, 1997, J Biomed Opt, V2, P364, DOI 10.1117/1.429838; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eilers P. H. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4266, DOI 10.1117/12.427987; Fahrmeir L., 2001, MULTIVARIATE STAT MO, V2nd; FIRTH D, 1993, BIOMETRIKA, V80, P27, DOI 10.1093/biomet/80.1.27; Firth D, 1992, ADV GLIM STAT MODELL, P91; FIRTH D, 1993, BIOMETRIKA, V82, P667; Firth D, 1992, COMPUTATION STAT, V1, P553; Fisher RA, 1936, ANN EUGENIC, V7, P179; FORT G, 2003, TR0331 IAP; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Heinze G, 2002, STAT MED, V21, P2409, DOI 10.1002/sim.1047; HELLAND IS, 1988, COMMUN STAT SIMULAT, V17, P581, DOI 10.1080/03610918808812681; Hoskuldsson A, 1988, J CHEMOMETR, V2, P211, DOI DOI 10.1002/CEM.1180020306; KRUSKAL J, 1978, INT ENCY STAT; Marx BD, 1996, TECHNOMETRICS, V38, P374, DOI 10.2307/1271308; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; McCullagh P., 1989, GEN LINEAR MODELS, Vsecond; Nas T., 1989, MULTIVARIATE CALIBRA; Newton MA, 2001, J COMPUT BIOL, V8, P37, DOI 10.1089/106652701300099074; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Nguyen DV, 2002, BIOINFORMATICS, V18, P1216, DOI 10.1093/bioinformatics/18.9.1216; Ripley B. D., 1996, PATTERN RECOGNITION; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; SANTNER TJ, 1986, BIOMETRIKA, V73, P755; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1); Venables WN, 2002, MODERN APPL STAT S, V4th; Wang CY, 1999, PHOTOCHEM PHOTOBIOL, V69, P471, DOI 10.1111/j.1751-1097.1999.tb03314.x; WOLD H., 1975, PERSPECTIVES PROBABI	38	30	30	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	JUN	2005	14	2					280	298		10.1198/106186005X47697		19	Statistics & Probability	Mathematics	008LJ	WOS:000235041900003		
J	Svetnik, V; Wang, T; Tong, C; Liaw, A; Sheridan, RP; Song, QH				Svetnik, V; Wang, T; Tong, C; Liaw, A; Sheridan, RP; Song, QH			Boosting: An ensemble learning tool for compound classification and QSAR modeling	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							RESISTANCE REVERSAL AGENTS; SUPPORT VECTOR MACHINE; LIBRARY DESIGN; RANDOM FOREST; PREDICTION; MOLECULES; DRUGS; DESCRIPTORS; SIMILARITY; ACCURACY	A classification and regression tool, J. H. Friedman's Stochastic Gradient Boosting (SGB), is applied to predicting a compound's quantitative or categorical biological activity based on a quantitative description of the compound's molecular structure. Stochastic Gradient Boosting is a procedure for building a sequence of models, for instance regression trees (as in this paper), whose outputs are combined to form a predicted quantity, either an estimate of the biological activity, or a class label to which a molecule belongs. In particular, the SGB procedure builds a model in a stage-wise manner by fitting each tree to the gradient of a loss function: e.g., squared error for regression and binomial log-likelihood for classification. The values of the gradient are computed for each sample in the training set, but only a random sample of these gradients is used at each stage. (Friedman showed that the well-known boosting algorithm, AdaBoost of Freund and Schapire, could be considered as a particular case of SGB.) The SGB method is used to analyze 10 cheminformatics data sets, most of which are publicly available. The results show that SGB's performance is comparable to that of Random Forest, another ensemble learning method, and are generally competitive with or superior to those of other QSAR methods. The use of SGB's variable importance with partial dependence plots for model interpretation is also illustrated.	Merck Res Labs, Biometr Res & Mol Syst, Rahway, NJ 07065 USA; Univ Wisconsin, Dept Stat, Madison, WI 53706 USA	Svetnik, V (reprint author), Merck Res Labs, Biometr Res & Mol Syst, POB 2000, Rahway, NJ 07065 USA.	vladimir_svetnik@merck.com	Tong, Christopher/A-5761-2009	Tong, Christopher/0000-0003-0770-3270			Bakken GA, 2000, J MED CHEM, V43, P4534, DOI 10.1021/jm000244u; Bemis GW, 1996, J MED CHEM, V39, P2887, DOI 10.1021/jm9602928; Bemis GW, 1999, J MED CHEM, V42, P5095, DOI 10.1021/jm9903996; Bradley EK, 2003, J MED CHEM, V46, P4360, DOI 10.1021/jm020472j; BREIMAN L, 2002, 277 M I MATH STAT BA; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUSH BL, 1993, J CHEM INF COMP SCI, V33, P756, DOI 10.1021/ci00015a015; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Chang C.C., LIBSVM LIB SUPPORT V; Chen C., 2004, USING RANDOM FOREST; Cheng A, 2003, J COMPUT AID MOL DES, V17, P811, DOI 10.1023/B:JCAM.0000021834.50768.c6; CODRINGTON CW, 2001, P 18 INT C MACH LEAR, P59; DeLisle RK, 2004, J CHEM INF COMP SCI, V44, P862, DOI 10.1021/ci034188s; Dietterich T, 2002, HDB BRAIN THEORY NEU; Dixon SL, 1999, J COMPUT AID MOL DES, V13, P533, DOI 10.1023/A:1008061017938; DOMINGOS P, 2000, P 17 NAT C ART INT A; Doniger S, 2002, J COMPUT BIOL, V9, P849, DOI 10.1089/10665270260518317; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; FRIEDMAN JH, IMPORTANCE SAMPLED L; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; GILLIGAN PJ, 1992, J MED CHEM, V35, P4344, DOI 10.1021/jm00101a012; Hastie T., 2001, ELEMENTS STAT LEARNI; HAWKINS DM, 1999, COMPUT SCI STAT, V30, P534; He P, 2004, CHEMOMETR INTELL LAB, V70, P39, DOI 10.1016/j.chemolab.2003.10.001; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HOCHMAN JH, 2004, AAPS WORKSH OPT DRUG; Kauffman GW, 2001, J CHEM INF COMP SCI, V41, P1553, DOI 10.1021/ci010073h; Klopman G, 1997, MOL PHARMACOL, V52, P323; LIAW A, RANDOM FOREST PACKAG; MEIR R, 2002, LECT NOTES ARTIF INT, V2600, P119; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; *MIL CHEM, DRAGON; *MOL DES LTD, MDL DRUG DAT REP; Penzotti JE, 2004, CURR OPIN DRUG DISC, V7, P49; Penzotti JE, 2002, J MED CHEM, V45, P1737, DOI 10.1021/jm0255062; RIDGEWAY G, GHM PACKAGE; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Schapire RE, 1998, ANN STAT, V26, P1651; Schwenk H, 2000, NEURAL COMPUT, V12, P1869, DOI 10.1162/089976600300015178; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P1912, DOI 10.1021/ci049782w; SHERIDAN RP, 1994, J COMPUT AID MOL DES, V8, P323, DOI 10.1007/BF00126749; Susnow RG, 2003, J CHEM INF COMP SCI, V43, P1308, DOI 10.1021/ci030283p; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Svetnik V, 2004, LECT NOTES COMPUT SC, V3077, P334; Tong W, 2003, ENVIRON TOXICOL CHEM, V22, P1680, DOI 10.1897/01-198; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; van Rhee AM, 2003, J CHEM INF COMP SCI, V43, P941, DOI 10.1021/ci034023j; Weaver DC, 2004, CURR OPIN CHEM BIOL, V8, P264, DOI 10.1016/j.cbpa.2004.04.005; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Wolpert D. H., 1995, MATH GEN	55	62	63	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAY-JUN	2005	45	3					786	799		10.1021/ci0500379		14	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	929YZ	WOS:000229384000026	15921468	
J	Guha, R; Jurs, PC				Guha, R; Jurs, PC			Interpreting computational neural network QSAR models: A measure of descriptor importance	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							QUANTITATIVE STRUCTURE-ACTIVITY; STRUCTURE-PROPERTY RELATIONSHIP; MOLECULAR-STRUCTURE; BIOLOGICAL-ACTIVITY; SHAPE INDEX; PREDICTION; IDENTIFICATION; ARTEMISININ; EXTRACTION; GRAPHS	We present a method to measure the relative importance of the descriptors present in a QSAR model developed with a computational neural network (CNN). The approach is based on a sensitivity analysis of the descriptors. We tested the method on three published data sets for which linear and CNN models were previously built. The original work reported interpretations for the linear models, and we compare the results of the new method to the importance of descriptors in the linear models as described by a PLS technique. The results indicate that the proposed method is able to rank descriptors such that important descriptors in the CNN model correspond to the important descriptors in the linear model.	Penn State Univ, Dept Chem, University Pk, PA 16802 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, University Pk, PA 16802 USA.						Avery MA, 2002, J MED CHEM, V45, P292, DOI 10.1021/jm0100234; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOLOGNA G, 2000, P 6 BRAZ S NEUR NETW; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Castro JL, 2002, IEEE T NEURAL NETWOR, V13, P101, DOI 10.1109/72.977279; CHEN PCY, 1997, NEUR NETW INT C; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; FU X, 2001, EVOLUTIONARY COMPUTA; Goldberg D. E., 2000, GENETIC ALGORITHMS S; Goldstein H., 1950, CLASSICAL MECH; Goll ES, 1999, J CHEM INF COMP SCI, V39, P974, DOI 10.1021/ci9900711; Guha R, 2004, J CHEM INF COMP SCI, V44, P1440, DOI 10.1021/ci0499469; Guha R, 2004, J CHEM INF COMP SCI, V44, P2179, DOI 10.1021/ci049849f; Gupta A, 1999, IEEE T KNOWL DATA EN, V11, P985, DOI 10.1109/69.824621; Haykin S, 2001, NEURAL NETWORKS; Hervas C, 2004, J CHEM INF COMP SCI, V44, P1576, DOI 10.1021/ci049948t; ISHIBUCHI N, 1999, FUZZ SYST C P IEEE I; JONES WT, 1992, IEEE P SE; Jurs P, 1979, COMPUTER ASSISTED DR; Kier L., 1986, MOL CONNECTIVITY STR; Kier L. B., 1975, J PHARM SCI, V64; Kier L. B., 1976, MOL CONNECTIVITY CHE; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P1, DOI 10.1002/qsar.19860050102; KIER LB, 1976, J PHARM SCI, V65, P1806, DOI 10.1002/jps.2600651228; KIER LB, 1985, QUANT STRUCT-ACT REL, V4, P109, DOI 10.1002/qsar.19850040303; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P7, DOI 10.1002/qsar.19860050103; KOHONEN T, 1994, SELF ORG MAPS, V30; LiMin Fu, 1994, IEEE Transactions on Systems, Man and Cybernetics, V24, DOI 10.1109/21.299696; Liu SS, 1998, J CHEM INF COMP SCI, V38, P387, DOI 10.1021/ci970109z; LU X, 1994, ENVIRON TOXICOL CHEM, V13, P841; MATTIONI BE, 2003, THESIS PENNSYLVANIA; Mosier PD, 2002, ANAL CHEM, V74, P1360, DOI 10.1021/ac0112059; NEY H, 1995, IEEE T PATTERN ANAL, V17, P107, DOI 10.1109/34.368176; Pandey A, 2002, J MED CHEM, V45, P3772, DOI 10.1021/jm020143r; Patankar SJ, 2002, J CHEM INF COMP SCI, V42, P1053, DOI 10.1021/ci010114+; RANDIC M, 1984, J CHEM INF COMP SCI, V24, P164, DOI 10.1021/ci00043a009; So SS, 1996, J MED CHEM, V39, P1521, DOI 10.1021/jm9507035; STANTON D, COMMUNICATION; STANTON DT, 1990, ANAL CHEM, V62, P2323, DOI 10.1021/ac00220a013; Stanton DT, 2004, J CHEM INF COMP SCI, V44, P1010, DOI 10.1021/ci034284t; Stanton DT, 2003, J CHEM INF COMP SCI, V43, P1423, DOI 10.1021/ci0340658; Stuper A. J., 1979, COMPUTER ASSISTED ST; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; Taha IA, 1999, IEEE T KNOWL DATA EN, V11, P448, DOI 10.1109/69.774103; TAKAHASHI T, 1991, IJCNN 91 SEATTL INT; WESSEL MD, 1994, ANAL CHEM, V66, P2480, DOI 10.1021/ac00087a012; WESSEL MD, 1997, THESIS PENNSYLVANIA; YAO S, 1996, FUZZ SYST P 5 IEEE I	51	58	60	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAY-JUN	2005	45	3					800	806		10.1021/ci050022a		7	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	929YZ	WOS:000229384000027	15921469	
J	Granitto, PM; Verdes, PF; Ceccatto, HA				Granitto, PM; Verdes, PF; Ceccatto, HA			Neural network ensembles: evaluation of aggregation algorithms	ARTIFICIAL INTELLIGENCE			English	Article						machine learning; ensemble methods; neural networks; regression		Ensembles of artificial neural networks show improved generalization capabilities that outperform those of single networks. However, for aggregation to be effective, the individual networks must be as accurate and diverse as possible. An important problem is, then, how to tune the aggregate members in order to have an optimal compromise between these two conflicting conditions. We present here an extensive evaluation of several algorithms for ensemble construction, including new proposals and comparing them with standard methods in the literature. We also discuss a potential problem with sequential aggregation algorithms: the non-frequent but damaging selection through their heuristics of particularly bad ensemble members. We introduce modified algorithms that cope with this problem by allowing individual weighting of aggregate members. Our algorithms and their weighted modifications are favorably tested against other methods in the literature, producing a sensible improvement in performance on most of the standard statistical databases used as benchmarks. (c) 2004 Elsevier B.V. All rights reserved.	Univ Nacl Rosario, CONICET, Inst Fis Rosario, RA-2000 Rosario, Santa Fe, Argentina	Ceccatto, HA (reprint author), Univ Nacl Rosario, CONICET, Inst Fis Rosario, Blvd 27 Febrero 210 Bis, RA-2000 Rosario, Santa Fe, Argentina.	ceccatto@ifir.edu.ar	Granitto, Pablo/A-3645-2013				Avnimelech R, 1999, NEURAL COMPUT, V11, P499, DOI 10.1162/089976699300016746; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Carney J G, 2000, Int J Neural Syst, V10, P267, DOI 10.1016/S0129-0657(00)00027-2; Drucker H., 1999, COMBINING ARTIFICIAL, P51; Drucker H., 1997, P 14 INT C MACH LEAR, P107; Duffy N., 2000, P 13 ANN C COMP LEAR, P208; Efron B, 1993, INTRO BOOTSTRAP; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Friedman J. H., 1999, GREEDY FUNCTION APPR; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Grant JM, 2001, WOMEN HEALTH ISS, V11, P305, DOI 10.1016/S1049-3867(01)00095-0; IKEDA K, 1979, OPT COMMUN, V30, P257, DOI 10.1016/0030-4018(79)90090-7; Karakoulas G, 2000, ADV NEUR IN, P247; Muller A, 1999, CLIN DIAGN LAB IMMUN, V6, P243; Naftaly U, 1997, NETWORK-COMP NEURAL, V8, P283, DOI 10.1088/0954-898X/8/3/004; NAVONE H, 2001, REV IBEROAMERICANA I, V3, P70; Ratsch G, 2002, MACH LEARN, V48, P189, DOI 10.1023/A:1013907905629; Ridgeway G., 1999, P ART INT STAT, P152; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; Sharkey A.J., 1999, COMBINING ARTIFICIAL; Zemel RS, 2001, ADV NEUR IN, V13, P696; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	24	43	54	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702			ARTIF INTELL	Artif. Intell.	APR	2005	163	2					139	162		10.1016/j.artint.2004.09.006		24	Computer Science, Artificial Intelligence	Computer Science	909JW	WOS:000227857200001		
J	Lee, JW; Lee, JB; Park, M; Song, SH				Lee, JW; Lee, JB; Park, M; Song, SH			An extensive comparison of recent classification tools applied to microarray data	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						microarray; classification; feature selection	GENE-EXPRESSION DATA; DNA MICROARRAYS; DISCRIMINANT-ANALYSIS; SHRUNKEN CENTROIDS; CLASS PREDICTION; CANCER; REGRESSION; PATTERNS; GENOME; TUMOR	Since most classification articles have applied a single technique to a single gene expression dataset, it is crucial to assess the performance of each method through a comprehensive comparative study. We evaluate by extensive comparison study extending Dudoit et at. (J. Amer. Statist. Assoc. 97 (2002) 77) the performance of recently developed classification methods in microarray experiment, and provide the guidelines for finding the most appropriate classification tools in various situations. We extend their comparison in three directions: more classification methods (21 methods), more datasets (7 datasets) and more gene selection techniques (3 methods). Our comparison study shows several interesting facts and provides the biolopsts and the biostatisticians some insights into the classification tools in microarray data analysis. T-his study also shows that the more sophisticated classifiers give better performances than classical methods such as kNN, DLDA DQDA and the choice of gene selection method has much effect on the performance of the classification methods, and thus the classification methods should be considered together with the gene selection criteria. (C) 2004 Elsevier B.V. All rights reserved.	Korea Univ, Dept Stat, Seoul 136701, South Korea; Eulji Med Coll, Dept Pre Med, Taejon 301832, South Korea	Lee, JW (reprint author), Korea Univ, Dept Stat, 5-1 Anam Dong, Seoul 136701, South Korea.	jael@korea.ac.kr; jungboky@korea.ac.kr; mira@emc.eulji.ac.kr; ssong@korea.ac.kr	Moorthy, Kohbalan/B-2470-2015	Moorthy, Kohbalan/0000-0002-6184-0359			Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Breiman L., 1994, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; Chang CC, 2001, LIBSVM LIB SUPPORT V; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; DING B, 2003, CLASSIFICATION USING; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Hastie Trevor, 1996, J R STAT SOC B, V58, P158; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lander ES, 1999, NAT GENET, V21, P3, DOI 10.1038/4427; Lemeshow S, 1989, APPL LOGISTIC REGRES; Marx BD, 1996, TECHNOMETRICS, V38, P374, DOI 10.2307/1271308; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Vapnik V., 1998, STAT LEARNING THEORY; ZURUDA J, 1992, INTRO ARTIFICIAL NEU	34	170	177	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	APR 1	2005	48	4					869	885		10.1016/j.csda.2004.03.017		17	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	892OD	WOS:000226659000015		
J	Arimoto, R; Prasad, MA; Gifford, EM				Arimoto, R; Prasad, MA; Gifford, EM			Development of CYP3A4 inhibition models: Comparisons of machine-learning techniques and molecular descriptors	JOURNAL OF BIOMOLECULAR SCREENING			English	Article						CYP3A4; BFC; in silico screening; machine learning; structural fingerprint; similarity index; kappa	CYTOCHROME-P450 ACTIVE-SITES; DRUG-DRUG INTERACTIONS; HUMAN LIVER-MICROSOMES; IN-VITRO; 3A4 INHIBITORS; KETOCONAZOLE; METABOLISM; PHARMACOPHORE; DISCOVERY; CYP2D6	Computational models of cytochrome P450 3A4 inhibition were developed based on high-throughput screening data for 4470 proprietary compounds. Multiple models differentiating inhibitors (IC50 < 3 mu M) and noninhibitors were generated using various machine-learning algorithms (recursive partitioning [RP], Bayesian classifier, logistic regression, k-nearest-neighbor, and support vector machine [SVM]) with structural fingerprints and topological indices. Nineteen models were evaluated by internal 10-fold cross-validation and also by an independent test set. Three most predictive models, Barnard Chemical Information (BCI)-fingerprint/SVM, MDL-keyset/SVM, and topological indices/RP, correctly classified 249,248, and 236 compounds of 291 noninhibitors and 135,137, and 147 compounds of 179 inhibitors in the validation set. Their overall accuracies were 82%, 82%, and 81%, respectively. Investigating applicability of the BCI/SVM model found a strong correlation between the predictive performance and the structural similarity to the training set. Using Tanimoto similarity index as a confidence measurement for the predictions, the limitation of the extrapolation was 0.7 in the case of the BCI/SVM model. Taking consensus of the 3 best models yielded a further improvement in predictive capability, kappa = 0.65 and accuracy = 83%. The consensus model could also be tuned to minimize either false positives or false negatives depending on the emphasis of the screening. (Journal of Biomolecular Screening 2005:197-205).	Pfizer Global Res & Dev, Ann Arbor, MI USA	Arimoto, R (reprint author), Vertex Pharmaceut Inc, 130 Waverly St, Cambridge, MA 02139 USA.	rieko_arimoto@vrtx.com					AHMAD SR, 1995, LANCET, V345, P508, DOI 10.1016/S0140-6736(95)90595-2; Baune B, 1999, DRUG METAB DISPOS, V27, P565; Blanchard N, 2004, CURR DRUG METAB, V5, P147, DOI 10.2174/1389200043489072; Boxenbaum H, 1999, J PHARM PHARM SCI, V2, P47; Breiman L., 1984, CLASSIFCATION REGRES; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cohen LH, 2003, DRUG METAB DISPOS, V31, P1005, DOI 10.1124/dmd.31.8.1005; Crespi CL, 1997, ANAL BIOCHEM, V248, P188, DOI 10.1006/abio.1997.2145; Crespi CL, 1998, MED CHEM RES, V8, P457; de Groot MJ, 2002, ADV DRUG DELIVER REV, V54, P367, DOI 10.1016/S0169-409X(02)00009-1; Dietterich T. G., 2003, HDB BRAIN THEORY NEU, P405; DOWNS GM, 1989, J CHEM INF COMP SCI, V29, P207, DOI 10.1021/ci00063a009; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Ekins S, 2001, DRUG METAB DISPOS, V29, P936; Ekins S, 1999, J PHARMACOL EXP THER, V290, P429; Ekins S, 2003, DRUG METAB DISPOS, V31, P1077, DOI 10.1124/dmd.31.9.1077; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Galetin A, 2002, DRUG METAB DISPOS, V30, P1512, DOI 10.1124/dmd.30.12.1512; Gao F, 2002, J BIOMOL SCREEN, V7, P373, DOI 10.1089/108705702320351231; Gasteiger J., 1990, TETRAHEDRON COMPUT M, V3, P537, DOI DOI 10.1016/0898-5529(90)90156-3; HONIG PK, 1993, JAMA-J AM MED ASSOC, V269, P1513, DOI 10.1001/jama.269.12.1513; Hutzler JM, 2002, DRUG METAB DISPOS, V30, P355, DOI 10.1124/dmd.30.4.355; Joachims T., 2002, LEARNING CLASSIFY TE; Kenworthy KE, 1999, BRIT J CLIN PHARMACO, V48, P716; Kier L., 1999, MOL STRUCTURE DESCRI; Kier L., 1986, MOL CONNECTIVITY STR; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P1, DOI 10.1002/qsar.19860050102; KOMAREK PR, 2003, 9 INT WORKSH ART INT; Korzekwa KR, 1998, BIOCHEMISTRY-US, V37, P4137, DOI 10.1021/bi9715627; Krayenbuhl JC, 1999, EUR J CLIN PHARMACOL, V55, P559, DOI 10.1007/s002280050673; Lichter JB, 1997, CURR OPIN BIOTECH, V8, P692, DOI 10.1016/S0958-1669(97)80121-8; Lin JH, 2002, DRUG DRUG INTERACTIO, P415; Lin JH, 1998, CLIN PHARMACOKINET, V35, P361, DOI 10.2165/00003088-199835050-00003; LIU T, 2004, ADV NEURAL INFORMATI, P16; Molnar L, 2002, BIOORG MED CHEM LETT, V12, P419, DOI 10.1016/S0960-894X(01)00771-5; PROVOST F, 1998, 15 INT C MACH LEARN; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Riley RJ, 2001, PHARMACEUT RES, V18, P652, DOI 10.1023/A:1011085411050; Smith DA, 1997, DRUG DISCOV TODAY, V2, P479, DOI 10.1016/S1359-6446(97)01085-4; STOKES ME, 1995, CATEGORICAL DATA ANA, P98; Stresser DM, 2000, DRUG METAB DISPOS, V28, P1440; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Vapnik VN, 1995, NATURE STAT LEARNING; Wang JS, 1999, PHARMACOL TOXICOL, V85, P157; Wang RW, 2000, DRUG METAB DISPOS, V28, P360; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Williams PA, 2004, SCIENCE, V305, P683, DOI 10.1126/science.1099736; Wrighton SA, 2000, DRUG METAB REV, V32, P339, DOI 10.1081/DMR-100102338; Yano JK, 2004, J BIOL CHEM, V279, P38091, DOI 10.1074/jbc.C400293200	54	48	48	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1087-0571			J BIOMOL SCREEN	J. Biomol. Screen	APR	2005	10	3					197	205		10.1177/1087057104274091		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Chemistry, Analytical	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Chemistry	916KX	WOS:000228384900001	15809315	
J	Ernst, D; Geurts, P; Wehenkel, L				Ernst, D; Geurts, P; Wehenkel, L			Tree-based batch mode reinforcement learning	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						batch mode reinforcement learning; regression trees; ensemble methods; supervised learning; fitted value iteration; optimal control		Reinforcement learning aims to determine an optimal control policy from interaction with a system or from observations gathered from a system. In batch mode, it can be achieved by approximating the so-called Q-function based on a set of four-tuples (x(t), u(t), r(t), x(t+1)) where x(t) denotes the system state at time t, u(t) the control action taken, r(t) the instantaneous reward obtained and x(t+1) the successor state of the system, and by determining the control policy from this Q-function. The Q-function approximation may be obtained from the limit of a sequence of (batch mode) supervised learning problems. Within this framework we describe the use of several classical tree-based supervised learning methods (CART, Kd-tree, tree bagging) and two newly proposed ensemble algorithms, namely extremely and totally randomized trees. We study their performances on several examples and find that the ensemble methods based on regression trees perform well in extracting relevant information about the optimal control policy from sets of four-tuples. In particular, the totally randomized trees give good results while ensuring the convergence of the sequence, whereas by relaxing the convergence constraint even better accuracy results are provided by the extremely randomized trees.	Univ Liege, Inst Montefiore, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium	Ernst, D (reprint author), Univ Liege, Inst Montefiore, Dept Elect Engn & Comp Sci, Sart Tilman B28, B-4000 Liege, Belgium.	ERNST@MONTEFIORE.ULG.AC.BE; GEURTS@MONTEFIORE.ULG.AC.BE; LWH@MONTEFIORE.ULG.AC.BE					BAGNELL D, 2003, P NEUR INF PROC SYST; BAIRD LC, 1995, MACH LEARN, P9; Bellman R, 1957, DYNAMIC PROGRAMMING; Bellman R., 1963, MATH COMPUT, V17, P155, DOI 10.2307/2003635; Boyan J.A., 1995, ADV NEURAL INFORM PR, V7, P369; Boyan JA, 2002, MACH LEARN, V49, P233, DOI 10.1023/A:1017936530646; Breiman L., 2000, 577 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; ERNST D, 2005, IN PRESS INTELLIGENT; ERNST D, 2003, P 14 EUR C MACH LEAR, P96; ERNST D, 2003, THESIS U LIEGE BELGI; GEURTS P, 2004, UNPUB EXTREMELY RAND; GORDON G, 1999, THESIS CARNEGIEMELLO; Gordon G.J., 1995, P 12 INT C MACH LEAR, P261; GORDON GJ, 1995, VFA WORKSH ML 95; HERNENDEZLERMA O, 1996, DISCRETE TIME MARKOV; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Kakade S., 2002, P 19 INT C MACH LEAR, P267; Lagoudakis M. G., 2003, J MACHINE LEARNING R, V4, P1107, DOI DOI 10.1162/JMLR.2003.4.6.1107; LAGOUDAKIS MG, 2003, P 20 INT C MACH LEAR, P424; LANGFORD J, 2004, UNPUB REDUCING T STE; LIN LJ, 1993, THESIS CARNEGIEMELLO; LIN Y, 2002, 1005 U WISC DEP STAT; Luenberger D. G., 1969, OPTIMIZATION VECTOR; McCallum A., 1996, THESIS U ROCHESTER R; Moore AW, 1995, MACH LEARN, V21, P199, DOI 10.1007/BF00993591; MOORE AW, 1993, MACH LEARN, V13, P103, DOI 10.1023/A:1022635613229; NG AY, 1999, P 16 C UNC ART INT, P406; Ormoneit D, 2002, MACH LEARN, V49, P161, DOI 10.1023/A:1017928328829; Ormoneit D, 2002, IEEE T AUTOMAT CONTR, V47, P1624, DOI 10.1109/TAC.2002.803530; Randlov J., 1998, P 15 INT C MACH LEAR, P463; Rust J, 1997, ECONOMETRICA, V65, P487, DOI 10.2307/2171751; SINGH SP, 1995, ADV NEURAL INFORM PR, P359; Smart W. D., 2000, P 17 INT C MACH LEAR, P903; SPONG MW, 1994, IEEE INT CONF ROBOT, P2356; Sutton R. S., 1998, REINFORCEMENT LEARNI, V1st; Sutton RS, 1996, ADV NEUR IN, V8, P1038; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; TSITSIKLIS JN, 1994, MACH LEARN, V16, P185, DOI 10.1023/A:1022689125041; Tsitsiklis JN, 1996, MACH LEARN, V22, P59, DOI 10.1007/BF00114724; Uther W. T. B., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; WANG X, 1999, P IJCAI 99 WORKSH ST; Watkins C., 1989, THESIS CAMBRIDGE U C; YOSHIMOTO J, 1999, P 1999 IEEE INT C SY, P516	46	125	127	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	APR	2005	6						503	556				54	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HI	WOS:000236329600006		
J	Shi, T; Seligson, D; Belldegrun, AS; Palotie, A; Horvath, S				Shi, T; Seligson, D; Belldegrun, AS; Palotie, A; Horvath, S			Tumor classification by tissue microarray profiling: random forest clustering applied to renal cell carcinoma	MODERN PATHOLOGY			English	Article						tissue microarray; renal cell carcinoma; random forest clustering; tumor marker; tumor class discovery	IMMUNOHISTOCHEMICAL ANALYSIS; EXPRESSION; GENE; IDENTIFICATION; DISCOVERY; PROGNOSIS; SURVIVAL; THERAPY; MARKERS; PROTEIN	We describe a novel strategy (random forest clustering) for tumor profiling based on tissue microarray data. Random forest clustering is attractive for tissue microarray and other immunohistochemistry data since it handles highly skewed tumor marker expressions well and weighs the contribution of each marker according to its relatedness with other tumor markers. This is the first tumor class discovery analysis of renal cell carcinoma patients based on protein expression profiles. The tissue array data contained at least three tumor samples from each of 366 renal cell carcinoma patients. The eight tumor markers explore tumor proliferation, cell cycle abnormalities, cell mobility, and the hypoxia pathway. Since the procedure is unsupervised, no clinicopathological data or traditional classifications are used a priori. To explore whether the tissue microarray data can be used to identify fundamental subtypes of renal cell carcinoma patients, we first carried out random forest clustering of all 366 patients. By analyzing the tumor markers simultaneously, the procedure automatically detected classes that correspond to clear- vs non-clear cell tumors (demonstration of proof-of-principle). The resulting molecular grouping provides better prediction of survival (logrank P = 0.000090) than this classical pathological grouping (logrank P = 0.023). We then sought to extend the class discovery by searching for finer subclasses of clear cell patients. The procedure automatically discovered: (a) two classes corresponding to low- and high-grade patients (demonstration of proof-of-principle); (b) a subgroup of long-surviving clear cell patients with a distinct molecular profile and (c) two novel tumor subclasses in low-grade clear cell patients that could not be explained by any clinicopathological variables (demonstration of discovery).	Univ Calif Los Angeles, Dept Human Genet, Los Angeles, CA 90095 USA; Univ Helsinki, Cent Hosp, Dept Lab, Helsinki, Finland; Univ Helsinki, Finish Genome Ctr, Helsinki, Finland; Univ Calif Los Angeles, Dept Urol, Los Angeles, CA 90024 USA; Univ Calif Los Angeles, Dept Pathol & Lab Med, Los Angeles, CA 90024 USA; Univ Calif Los Angeles, Dept Biostat, Los Angeles, CA 90024 USA	Horvath, S (reprint author), Univ Calif Los Angeles, Dept Human Genet, 695 Charles E Young Dr S, Los Angeles, CA 90095 USA.	shorvath@mednet.ucla.edu					Alimov A, 1999, ANTICANCER RES, V19, P3841; Boer JM, 2001, GENOME RES, V11, P1861; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bui MHT, 2003, CLIN CANCER RES, V9, P802; Cheville JC, 2003, AM J SURG PATHOL, V27, P612, DOI 10.1097/00000478-200305000-00005; FUHRMAN SA, 1982, AM J SURG PATHOL, V6, P655, DOI 10.1097/00000478-198210000-00007; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hedberg Y, 2003, BRIT J CANCER, V88, P1417, DOI 10.1038/sj.bjc.6600922; Hotakainen K, 2003, INT J CANCER, V104, P631, DOI 10.1002/ijc.11000; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Jacobsen J, 2004, BJU INT, V93, P297, DOI 10.1111/j.1464-410X.2004.04605.x; Jemal A, 2003, CA-CANCER J CLIN, V53, P5; Kim HL, 2004, CLIN CANCER RES, V10, P5464, DOI 10.1158/1078-0432.CCR-04-0488; Kononen J, 1998, NAT MED, V4, P844, DOI 10.1038/nm0798-844; Langner C, 2004, MODERN PATHOL, V17, P180, DOI 10.1038/modpathol.3800032; Langner C, 2004, J UROLOGY, V171, P611, DOI 10.1097/01.ju.0000108040.14303.c2; Moch H, 1999, AM J PATHOL, V154, P981, DOI 10.1016/S0002-9440(10)65349-7; OKEN MM, 1982, AM J CLIN ONCOL-CANC, V5, P649, DOI 10.1097/00000421-198212000-00014; RIETHMULLER G, 1994, LANCET, V343, P1177, DOI 10.1016/S0140-6736(94)92398-1; Rioux-Leclercq N, 2000, UROLOGY, V55, P501, DOI 10.1016/S0090-4295(99)00550-6; Rousseeuw P. J., 1990, FINDING GROUPS DATA; Sabo E, 1997, BRIT J UROL, V80, P864, DOI 10.1046/j.1464-410X.1997.00489.x; SHETYE J, 1989, ANTICANCER RES, V9, P395; SHI T, 2003, ATL S COMP BIOL GEN; Shieh DB, 1999, CANCER, V85, P47, DOI 10.1002/(SICI)1097-0142(19990101)85:1<47::AID-CNCR7>3.0.CO;2-L; Sobin LH, 1997, CANCER, V80, P1803, DOI 10.1002/(SICI)1097-0142(19971101)80:9<1803::AID-CNCR16>3.0.CO;2-9; Steck PA, 1997, NAT GENET, V15, P356, DOI 10.1038/ng0497-356; Takahashi M, 2003, ONCOGENE, V22, P6810, DOI 10.1038/sj.onc.1206869; Takahashi M, 2001, P NATL ACAD SCI USA, V98, P9754, DOI 10.1073/pnas.171209998; Velickovic M, 2002, MODERN PATHOL, V15, P479, DOI 10.1038/modpathol.3880551; Young AN, 2001, AM J PATHOL, V158, P1639, DOI 10.1016/S0002-9440(10)64120-X	31	64	67	NATURE PUBLISHING GROUP	NEW YORK	345 PARK AVE SOUTH, NEW YORK, NY 10010-1707 USA	0893-3952			MODERN PATHOL	Mod. Pathol.	APR	2005	18	4					547	557		10.1038/modpathol.3800322		11	Pathology	Pathology	908ZB	WOS:000227827600012	15529185	
J	Parkhurst, DF; Brenner, KP; Dufour, AP; Wymer, LJ				Parkhurst, DF; Brenner, KP; Dufour, AP; Wymer, LJ			Indicator bacteria at five swimming beaches - analysis using random forests	WATER RESEARCH			English	Article						random forests; tree regression; swimming beaches; indicator bacteria	RISK	"Random forests," an extension of tree regression, provide a relatively new technique for exploring relationships of a response variable like the density of indicator bacteria in water to numerous potential explanatory variables. We used this tool to study relationships of indicator density at five beaches to numerous other variables and found that day of the week, indicator density 24 h earlier, water depth at the sampling point, cloud cover, and others were related to density at one or more of the beaches. Using data from the first 52 days of measurement allowed predicting indicator densities in the following 10 days to order of magnitude at some of the beaches. Our analyses served to demonstrate the potential usefulness of this analytic tool for large data sets with many variables. Crown Copyright (c) 2005 Published by Elsevier Ltd. All rights reserved.	Indiana Univ, Sch Publ & Environm Affairs, Environm Sci Res Ctr, Bloomington, IN 47405 USA; US EPA, Natl Exposure Res Lab, Cincinnati, OH 45268 USA	Parkhurst, DF (reprint author), Indiana Univ, Sch Publ & Environm Affairs, Environm Sci Res Ctr, 1315 E 10th St, Bloomington, IN 47405 USA.	parkhurs@indiana.edu					Box GEP, 1978, STAT EXPT; BREIMAN L, 2003, COMMUNICATION; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Crump KS, 1998, RISK ANAL, V18, P293, DOI 10.1111/j.1539-6924.1998.tb01296.x; Haas CN, 1996, WATER RES, V30, P1036, DOI 10.1016/0043-1354(95)00228-6; *INS CORP, 2001, S PLUS 6 WIND GUID S, V2; LIAW A, 2003, RANDOMFOREST; Parkin T, 1998, PROGRAM-ELECTRON LIB, V32, P92; *R DEV COR TEAM, 2003, R A LANG ENV STAT CO; Rejwan C, 1999, ECOLOGY, V80, P341, DOI 10.1890/0012-9658(1999)080[0341:TRAOTN]2.0.CO;2; Therneau TM, 1997, INTRO RECURSIVE PART; Venables WN, 1999, MODERN APPL STAT S P; WYMER LJ, 2004, EPA600R04023 US	14	16	16	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0043-1354			WATER RES	Water Res.	APR	2005	39	7					1354	1360		10.1016/j.watres.2004.01.001		7	Engineering, Environmental; Environmental Sciences; Water Resources	Engineering; Environmental Sciences & Ecology; Water Resources	929MY	WOS:000229351400016	15862335	
J	Firth, L; Hazelton, ML; Campbell, EP				Firth, L; Hazelton, ML; Campbell, EP			Predicting the onset of Australian winter rainfall by nonlinear classification	JOURNAL OF CLIMATE			English	Article							SOUTHERN OSCILLATION; TEMPERATURE	A method for predicting the timing of winter rains is presented, making no assumptions about the functional form of any relationships that may exist. Ideas built on classification and regression trees and machine learning are used to develop robust predictive rules. These methods are applied in a case study to predict the timing of winter rain in five farming towns in the southwest of Western Australia. The variables used to construct the model are mean monthly sea Surface temperatures (SSTs) over a 72-cell grid in the Indian Ocean, Perth monthly mean sea level pressure (MSLP), and monthly values of the Southern Oscillation index (SOI). A predictive model is constructed from data over the period 1949-99. This model correctly classifies the onset of the winter rains approximately 80% of the time with SST variables proving to be the most important in deriving the predictions. Further analysis indicates a change point in the mid-1970s, a well-known phenomenon in the region. The prediction rates are significantly worse after 1975. Furthermore. the important region of the Indian Ocean, in terms of SSTs for prediction, moves from the Tropics down toward the Southern Ocean after this date.	Data Anal Australia, Perth, WA, Australia; Univ Western Australia, Perth, WA 6009, Australia; CSIRO, Perth, WA, Australia	Hazelton, ML (reprint author), Univ Western Australia, Sch Math & Stat, M019,35 Stirling Highway, Crawley, WA 6009, Australia.	martin@maths.uwa.edu.au	Campbell, Edward/F-1509-2010				Breiman L., 1996, OUT BAG ESTIMATION; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, ANN STAT, V24, P2350; BREIMAN L, MANUAL SETTING UP US; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CAMPBELL E, 2000, UNDERSTANDING CLIMAT, P179; DIETTERICH TG, MACHINE LEARNING BIA; Drosdowsky W, 2001, J CLIMATE, V14, P1677, DOI 10.1175/1520-0442(2001)014<1677:NACNGS>2.0.CO;2; Efron B, 1993, INTRO BOOTSTRAP; GOWER J, 1998, ENCY BIOSTATISTICS, V1, P656; GRAF HF, 2001, 330 MAX PLANCK I MET; Hastie T., 2001, ELEMENTS STAT LEARNI; Huntley D., 2000, CLIN PSYCHOL, V53, P3; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; IOCI, 2002, CLIM VAR CHANG S W W; MCBRIDE JL, 1983, MON WEATHER REV, V111, P1998, DOI 10.1175/1520-0493(1983)111<1998:SRBARA>2.0.CO;2; NICHOLLS N, 2000, UNDERSTANDING CLIMAT, P1; NICHOLLS N, 1984, J CLIMATOL, V4, P425; NICHOLLS N, 1991, VEGETATIO, V91, P23, DOI 10.1007/BF00036045; Nicholls N, 1989, J CLIMATE, V2, P965, DOI 10.1175/1520-0442(1989)002<0965:SSTAAW>2.0.CO;2; NICHOLLS N, 1985, J CLIMATOL, V5, P553; Palmer TN, 1999, J CLIMATE, V12, P575, DOI 10.1175/1520-0442(1999)012<0575:ANDPOC>2.0.CO;2; ROBERTSON G, 2001, DIRECTOR GENERALS OV; White WB, 1996, NATURE, V380, P699, DOI 10.1038/380699a0	26	6	6	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	0894-8755			J CLIMATE	J. Clim.	MAR 15	2005	18	6					772	781		10.1175/JCLI-3291.1		10	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	911NZ	WOS:000228012600002		
J	Tseng, GC; Wong, WH				Tseng, GC; Wong, WH			Tight clustering: A resampling-based approach for identifying stable and tight patterns in data	BIOMETRICS			English	Article						microarray; resampling; scattered points; unsupervised learning.	GENE-EXPRESSION; CELL-CYCLE; MODEL; MIXTURE; GENOME	In this article, we propose a method for clustering that produces tight and stable clusters without forcing all points into clusters. The methodology is general but was initially motivated from cluster analysis of microarray experiments. Most current algorithms aim to assign all genes into clusters. For many biological studies, however, we are mainly interested in identifying the most informative, tight, and stable clusters of sizes, say, 20-60 genes for further investigation. W want to avoid the contamination of tightly regulated expression patterns of biologically relevant genes due to other genes whose expressions are only loosely compatible with these patterns. "Tight clustering" has been developed specifically to address this problem. It applies K-means clustering as an intermediate clustering engine. Early truncation of a hierarchical clustering tree is used to overcome the local minimum problem in K-means clustering. The tightest and most stable clusters are identified in a sequential manner through an analysis of the tendency of genes to be grouped together under repeated resampling. We validated this method in a simulated example and applied it to analyze a set of expression profiles in the study of embryonic stem cells.	Univ Pittsburgh, Dept Biostat, Pittsburgh, PA 15261 USA; Univ Pittsburgh, Dept Human Genet, Pittsburgh, PA 15261 USA; Harvard Univ, Dept Stat, Cambridge, MA 02138 USA; Harvard Univ, Dept Biostat, Cambridge, MA 02138 USA	Tseng, GC (reprint author), Univ Pittsburgh, Dept Biostat, Pittsburgh, PA 15261 USA.	ctseng@pitt.edu; wwong@stat.harvard.edu					Arbeitman MN, 2002, SCIENCE, V297, P2270, DOI 10.1126/science.1072152; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; DAY NE, 1969, BIOMETRIKA, V56, P463, DOI 10.2307/2334652; Dudoit S, 2002, GENOME BIOL, V3; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; GILOVICH T, 1985, COGNITIVE PSYCHOL, V17, P295, DOI 10.1016/0010-0285(85)90010-6; Hartigan J., 1979, APPLIED STATISTICS, V28, P126; Hastie T., 2001, ELEMENTS STAT LEARNI; Kimura H, 1996, GENES CELLS, V1, P977, DOI 10.1046/j.1365-2443.1996.840284.x; Liu J. S., 2003, BAYESIAN STAT, V7, P249; MACQUEEN J, 1965, ANN MATH STAT, V36, P1084; McLachlan GJ, 1988, MIXTURE MODELS INFER; McLachlan GJ, 2003, COMPUT STAT DATA AN, V41, P379, DOI 10.1016/S0167-9473(02)00183-4; Medvedovic M, 2002, BIOINFORMATICS, V18, P1194, DOI 10.1093/bioinformatics/18.9.1194; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Sharan R., 2000, Proceedings. Eighth International Conference on Intelligent Systems for Molecular Biology; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Tibshirani R., 2001, CLUSTER VALIDATION P; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977	22	95	100	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0006-341X			BIOMETRICS	Biometrics	MAR	2005	61	1					10	16		10.1111/j.0006-341X.2005.031032.x		7	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	905NX	WOS:000227576600002	15737073	
J	He, LN; Jurs, PC; Kreatsoulas, C; Custer, LL; Durham, SK; Pearl, GM				He, LN; Jurs, PC; Kreatsoulas, C; Custer, LL; Durham, SK; Pearl, GM			Probabilistic neural network multiple classifier system for predicting the genotoxicity of quinolone and quinoline derivatives	CHEMICAL RESEARCH IN TOXICOLOGY			English	Article							MOLECULAR-STRUCTURE; STRUCTURE-PROPERTY; TOPOLOGICAL DESCRIPTOR; ORGANIC-COMPOUNDS; SOS CHROMOTEST; BOILING POINTS; INDEX; ANTIBACTERIALS; INHIBITION; METABOLISM	Quinolone and quinoline are known to be liver carcinogens in rodents, and a number of their derivatives have been shown to exhibit mutagenicity in the Ames test, using Salmonella typhimurium strain TA 100 in the presence of S9. Both the carcinogenicity and the mutagenicity of quinolone and quinoline derivatives, as determined by SAS, can be attributed to their genotoxicity potential. This potential, which is measured by genotoxicity tests, is a good indication of carcinogenicity and mutagenicity because compounds that are positive in these tests have the potential to be human carcinogens and/or mutagens. In this study, a collection of quinolone and quinoline derivatives' carcinogenicity is determined by qualitatively predicting their genotoxicity potential with predictive PNN (probabilistic neural network) classification models. In addition, a multiple classifier system is also developed to improve the predictability of genotoxicity. Superior results are seen with the multiple classifier system over the individual PNN classification models. With the multiple classifier system, 89.4% of the quinolone derivatives were predicted correctly, and higher predictability is seen with the quinoline derivatives at 92.2% correct. The multiple classifier system not only is able to accurately predict the genotoxicity but also provides an insight about the main determinants of genotoxicity of the quinolone and quinoline derivatives. Thus, the PNN multiple classifier system generated in this study is a beneficial contributor toward predictive toxicology in the design of less carcinogenic bioactive compounds.	Penn State Univ, Dept Chem, University Pk, PA 16802 USA; Bristol Myers Squibb Co, Princeton, NJ 08453 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, University Pk, PA 16802 USA.						ABRAHAM RJ, 1987, J COMPUT CHEM, V9, P288; Appelbaum PC, 2000, INT J ANTIMICROB AG, V16, P5, DOI 10.1016/S0924-8579(00)00192-8; Aylward J M, 1993, J Am Optom Assoc, V64, P787; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Bataille L, 2002, J HEPATOL, V37, P696, DOI 10.1016/S0168-8278(02)00268-4; BENBROOK DM, 1986, ANTIMICROB AGENTS CH, V29, P1; BERNSTEIN H, 1963, INVEST OPHTH VISUAL, V2, P384; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bush K, 2000, CURR OPIN CHEM BIOL, V4, P433, DOI 10.1016/S1367-5931(00)00106-X; COHEN MA, 1991, DIAGN MICR INFEC DIS, V14, P245, DOI 10.1016/0732-8893(91)90039-I; DEWAR MJS, 1985, J AM CHEM SOC, V107, P3902, DOI 10.1021/ja00299a024; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T.G., 2000, P 1 INT WORKSH MULT, P1; DIXO SL, 1992, J COMPUT CHEM, V18, P492; ENGLE EC, 1982, J BACTERIOL, V149, P92; GOLDSTEIN H, 1950, CLASSICAL MECH, P144; Goldstein H., 1950, CLASSICAL MECH; GUDAS LJ, 1976, J MOL BIOL, V101, P459, DOI 10.1016/0022-2836(76)90240-0; Gupta S, 1999, J CHEM INF COMP SCI, V39, P272, DOI 10.1021/ci980073q; He LN, 2003, CHEM RES TOXICOL, V16, P1567, DOI 10.1021/tx030032a; HOFNUNG M, 1988, ANN NY ACAD SCI, V534, P817, DOI 10.1111/j.1749-6632.1988.tb30169.x; Jefferson EA, 2003, BIOORG MED CHEM LETT, V13, P1635, DOI 10.1016/S0960-894X(03)00285-3; Jurs P, 1979, COMPUTER ASSISTED DR; Katritzky AR, 1996, J PHYS CHEM-US, V100, P10400, DOI 10.1021/jp953224q; Kier L., 1986, MOL CONNECTIVITY STR; Kier LB, 2000, J CHEM INF COMP SCI, V40, P792, DOI 10.1021/ci990135s; KIER LB, 1990, PHARMACEUT RES, V7, P801, DOI 10.1023/A:1015952613760; LAVOIE EJ, 1991, CARCINOGENESIS, V12, P217, DOI 10.1093/carcin/12.2.217; Lescher GY, 1962, J MED PHARM CHEM, V91, P1063; Lohray BB, 1998, BIOORG MED CHEM LETT, V8, P525, DOI 10.1016/S0960-894X(98)00063-8; LUKE BT, 1994, J CHEM INF COMP SCI, V34, P1279, DOI 10.1021/ci00022a009; MADAN AK, 1999, J CHEM INF COMP SCI, V39, P9; Makinen M, 1997, J PHOTOCH PHOTOBIO B, V37, P182, DOI 10.1016/S1011-1344(96)07425-8; Mattioni BE, 2002, J CHEM INF COMP SCI, V42, P94, DOI 10.1021/ci0100696; Mitchell BE, 1998, J CHEM INF COMP SCI, V38, P489, DOI 10.1021/ci970117f; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Patankar SJ, 2002, J CHEM INF COMP SCI, V42, P1053, DOI 10.1021/ci010114+; PEARLMAN RS, 1980, MOL SURFACE AREA VOL; QUILLARDET P, 1993, MUTAT RES, V297, P235, DOI 10.1016/0165-1110(93)90019-J; ROHRBAUGH RH, 1987, ANAL CHEM, V59, P1048, DOI 10.1021/ac00134a025; ROLI JFK, 2002, 3 INT WORKSH MULT CL; RUSSELL CJ, 1992, ANAL CHEM, V64, P1350, DOI 10.1021/ac00037a009; SAEKI K, 1993, BIOL PHARM BULL, V16, P232; Sharma V, 1997, J CHEM INF COMP SCI, V37, P273, DOI 10.1021/ci960049h; SIPORIN C, 1989, ANNU REV MICROBIOL, V43, P601, DOI 10.1146/annurev.micro.43.1.601; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; STANTON DT, 1990, ANAL CHEM, V62, P2323, DOI 10.1021/ac00220a013; STEWART JJP, 1990, J COMPUT AID MOL DES, V4, P1, DOI 10.1007/BF00128336; STEWART JPP, MOPAC 6 0 QUANTUM CH; STOUCH TR, 1986, J CHEM INF COMP SCI, V26, P4, DOI 10.1021/ci00049a002; Stuper A. J., 1979, COMPUTER ASSISTED ST; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; TAKAHASHI K, 1988, CHEM PHARM BULL, V36, P4630; *US EPA, 1985, HLTH ENV EFF PROF QU; Vinogradov S. N., 1971, HYDROGEN BONDING; Wasserman P. D., 1993, ADV METHODS NEURAL C, P35; WESSEL MD, 1995, J CHEM INF COMP SCI, V35, P841, DOI 10.1021/ci00027a008	59	2	3	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0893-228X			CHEM RES TOXICOL	Chem. Res. Toxicol.	MAR	2005	18	3					428	440		10.1021/tx049742m		13	Chemistry, Medicinal; Chemistry, Multidisciplinary; Toxicology	Pharmacology & Pharmacy; Chemistry; Toxicology	909OH	WOS:000227868700004	15777083	
J	Ham, J; Chen, YC; Crawford, MM; Ghosh, J				Ham, J; Chen, YC; Crawford, MM; Ghosh, J			Investigation of the random forest framework for classification of hyperspectral data	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article; Proceedings Paper	IEEE Workshop on Advances in Techniques for Analysis of Remotely Sensed Data held in Honor of David A Landgrebe	OCT 27-28, 2003	Greenbelt, MD	IEEE	NASA Goddard Space Flight Visitor Ctr	binary hierarchical classifier (BHC); classification; classification and regression trees (CART); Hyperion; hyperspectral; Okavango Delta; random forests; random subspace feature selection	RANDOM SUBSPACE METHOD; CLASSIFIERS; COVER	Statistical classification of hyperspectral data is challenging because the inputs are high in dimension and represent multiple classes that are sometimes quite mixed, while the amount and quality of ground truth in the form of labeled data is typically limited. The resulting classifiers are often unstable and have poor generalization. This paper investigates two approaches based on the concept of random forests of classifiers implemented within a binary hierarchical multiclassifier system, with the goal of achieving improved generalization of the classifier in analysis of hyperspectral data, particularly when the quantity of training data is limited. A new classifier is proposed that incorporates bagging of training samples and adaptive random subspace feature selection within a binary hierarchical classifier (BHC), such that the number of features that is selected at each node of the tree is dependent on the quantity of associated training data. Results are compared to a random forest implementation based on the framework of classification and regression trees. For both methods, classification results obtained from experiments on data acquired by the National Aeronautics and Space Administration (NASA) Airborne Visible/Infrared Imaging Spectrometer instrument over the Kennedy Space Center, Florida, and by Hyperion on the NASA Earth Observing I satellite over the Okavango Delta of Botswana are superior to those from the original best basis BHC algorithm and a random subspace extension of the BHC.	Univ Texas, Ctr Space Res, Austin, TX 78759 USA; Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA	Ham, J (reprint author), Univ Texas, Ctr Space Res, Austin, TX 78759 USA.	jham@csr.utexas.edu; yanji@csr.utexas.edu; crawford@csr.utexas.edu; ghosh@ece.utexas.edu					Asner GP, 2002, INT J REMOTE SENS, V23, P3939, DOI 10.1080/01431160110115960; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Boardman J., 1994, P INT GEOSC REM SENS, P2369, DOI 10.1109/IGARSS.1994.399740; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CRAWFORD M, 2003, 2003 TYRRH INT WORKS; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Jackson Q, 2001, IEEE T GEOSCI REMOTE, V39, P2664, DOI 10.1109/36.975001; Jia XP, 1999, IEEE T GEOSCI REMOTE, V37, P538; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; Kumar S., 1999, P APPL SCI COMP INT, P24; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718; Lee J. F., 1997, APPL LANGUAGE LEARNI, V8, P1; Morgan JT, 2004, INT J PATTERN RECOGN, V18, P777, DOI 10.1142/S0218001404003411; NEUENSCHWANDER AL, 2005, IN PRESS INT J REMOT; Pearlman JS, 2003, IEEE T GEOSCI REMOTE, V41, P1160, DOI 10.1109/TGRS.2003.815018; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Skurichina M, 2002, PATTERN ANAL APPL, V5, P121, DOI 10.1007/s100440200011; Tadjudin S, 1999, IEEE T GEOSCI REMOTE, V37, P2113, DOI 10.1109/36.774728; Turner K., 1996, CONNECT SCI, V8, P385	26	185	193	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	MAR	2005	43	3					492	501		10.1109/TGRS.2004.842481		10	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	899FJ	WOS:000227130000009		
J	Fan, GZ; Gray, JB				Fan, GZ; Gray, JB			Regression tree analysis using TARGET	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						Bayesian CART; CART; data mining; genetic algorithm; prediction; random forests	ADAPTIVE MODEL SELECTION; ALGORITHM; SEARCH	Regression trees are a popular alternative to classical regression methods. A number of approaches exist for constructing regression trees. Most of these techniques, including CART, are sequential in nature and locally optimal at each node split, so the final tree solution found may not be the best tree overall. In addition, small changes in the training data often lead to large changes in the final result due to the relative instability of these greedy tree-growing algorithms. Ensemble techniques, such as random forests, attempt to take advantage of this instability by growing a forest of trees from the data and averaging their predictions. The predictive performance is improved, but the simplicity of a single-tree solution is lost. In earlier work, we introduced the Tree Analysis with Randomly Generated and Evolved Trees (TARGET) method for constructing classification trees via genetic algorithms. In this article, we extend the TARGET approach to regression trees. Simulated data and real world data are used to illustrate the TARGET process and compare its performance to CART, Bayesian CART, and random forests. The empirical results indicate that TARGET regression trees have better predictive performance than recursive partitioning methods, such as CART, and single-tree stochastic search methods, such as Bayesian CART. The predictive performance of TARGET is slightly worse than that of ensemble methods, such as random forests, but the TARGET solutions are far more interpretable.	Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada; Univ Alabama, Appl Stat Program, Tuscaloosa, AL 35487 USA; Univ Alabama, Dept Informat Syst Stat & Management Sci, Tuscaloosa, AL 35487 USA	Fan, GZ (reprint author), Univ Waterloo, Dept Stat & Actuarial Sci, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.	gfan@uwaterloo.ca; bgray@cba.ua.edu					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cherkauer K.J., 1996, P 2 INT C KNOWL DISC, P315; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; Denison DGT, 1998, BIOMETRIKA, V85, P363; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; FU Z, 2000, THESIS U MARYLAND CO; Goldberg D, 1989, GENETIC ALGORITHMS S; GRAY JB, 2003, TARGET TREE ANAL RAN; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLLAND JH, 1975, ADAPTATION NATURAL A; Koza J. R., 1991, Parallel Problem Solving from Nature. 1st Workshop, PPSN 1 Proceedings; PAPAGELIS A, 2001, C P ICML 01 WILL US; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shen XT, 2002, J AM STAT ASSOC, V97, P210, DOI 10.1198/016214502753479356; TIBSHIRANI R, 1999, J COMPUT GRAPH STAT, V8, P671, DOI 10.2307/1390820; Tibshirani R, 1999, J ROY STAT SOC B, V61, P529, DOI 10.1111/1467-9868.00191; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609	20	15	15	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	1061-8600	1537-2715		J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	MAR	2005	14	1					206	218		10.1198/106186005X37210		13	Statistics & Probability	Mathematics	008LG	WOS:000235041600012		
J	Brown, M; Dunn, WB; Ellis, DI; Goodacre, R; Handl, J; Knowles, JD; O'Hagan, S; Spasic, I; Kell, DB				Brown, Marie; Dunn, Warwick B.; Ellis, David I.; Goodacre, Royston; Handl, Julia; Knowles, Joshua D.; O'Hagan, Steve; Spasic, Irena; Kell, Douglas B.			A metabolome pipeline: from concept to data to knowledge	METABOLOMICS			English	Review						metabolomics; chemometrics; data processing; databases; machine learning; genetic algorithms; genetic programming; evolutionary computing	PYROLYSIS MASS-SPECTROMETRY; FUNCTIONAL GENOMICS; SYSTEMS BIOLOGY; NEURAL-NETWORKS; EXPLANATORY ANALYSIS; EVOLUTIONARY COMPUTATION; QUANTITATIVE-ANALYSIS; PLANT METABOLOMICS; OLIVE OILS; METABONOMICS	Metabolomics, like other omics methods, produces huge datasets of biological variables, often accompanied by the necessary metadata. However, regardless of the form in which these are produced they are merely the ground substance for assisting us in answering biological questions. In this short tutorial review and position paper we seek to set out some of the elements of "best practice" in the optimal acquisition of such data, and in the means by which they may be turned into reliable knowledge. Many of these steps involve the solution of what amount to combinatorial optimization problems, and methods developed for these, especially those based on evolutionary computing, are proving valuable. This is done in terms of a "pipeline" that goes from the design of good experiments, through instrumental optimization, data storage and manipulation, the chemometric data processing methods in common use, and the necessary means of validation and cross-validation for giving conclusions that are credible and likely to be robust when applied in comparable circumstances to samples not used in their generation.	[Brown, Marie; Dunn, Warwick B.; Ellis, David I.; Goodacre, Royston; Handl, Julia; Knowles, Joshua D.; O'Hagan, Steve; Spasic, Irena; Kell, Douglas B.] Univ Manchester, Sch Chem, Manchester M60 1QD, Lancs, England	Kell, DB (reprint author), Univ Manchester, Sch Chem, Faraday Bldg,Sackville St,POB 88, Manchester M60 1QD, Lancs, England.	dbk@umist.ac.uk	Spasic, Irena/D-2259-2010; Kell, Douglas/E-8318-2011; Goodacre, Roy/J-1600-2012	Kell, Douglas/0000-0001-5838-7963; Goodacre, Roy/0000-0003-2230-645X	BBSRC; EPSRC; NERC; The Gottlieb Daimler and Karl Benz Foundation; RSC	We thank the BBSRC, EPSRC, NERC, The Gottlieb Daimler and Karl Benz Foundation and the RSC for financial support, and Nigel Hardy and Helen Fuell for useful discussions.	Achard F, 2001, BIOINFORMATICS, V17, P115, DOI 10.1093/bioinformatics/17.2.115; Aharoni Asaph, 2002, OMICS A Journal of Integrative Biology, V6, P217, DOI 10.1089/15362310260256882; Allen J, 2004, APPL ENVIRON MICROB, V70, P6157, DOI 10.1128/AEM.70.10.6157-6165.2004; Allen J, 2003, NAT BIOTECHNOL, V21, P692, DOI 10.1038/nbt823; Back T, 1997, HDB EVOLUTIONARY COM; Banzhaf W, 1998, GENETIC PROGRAMMING; Barrow JD, 1995, LEFT HAND CREATION O; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Bernardo J. M., 2000, BAYESIAN THEORY; Berry D., 1996, STAT BAYESIAN PERSPE; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bland M, 1987, INTRO MED STAT; BOOCH G, 1999, UNIFIED MODELLING LA; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brindle JT, 2002, NAT MED, V8, P1439, DOI 10.1038/nm802; CHATFIELD C, 1995, J ROY STAT SOC A STA, V158, P419, DOI 10.2307/2983440; Chen P.P.-S., 1976, ACM T DATABASE SYST, V1, P9, DOI 10.1145/320434.320440; Corne D, 1999, NEW IDEAS OPTIMIZATI; Cornell M, 2003, YEAST, V20, P1291, DOI 10.1002/yea.1047; Cornish-Bowden A, 2001, NATURE, V409, P571, DOI 10.1038/35054646; Dasgupta P., 1999, MULTIOBJECTIVE HEURI; Davies ZS, 2000, APPL ENVIRON MICROB, V66, P1435, DOI 10.1128/AEM.66.4.1435-1443.2000; De Smet F, 2002, BIOINFORMATICS, V18, P735, DOI 10.1093/bioinformatics/18.5.735; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Dudoit Sandrine, 2002, GENOME BIOL, V3, DOI DOI 10.1186/GB-2002-3-7-RESEARCH0036; Duran AL, 2003, BIOINFORMATICS, V19, P2283, DOI 10.1093/bioinformatics/btg315; Efron B, 1993, INTRO BOOTSTRAP; Ellis DI, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P111; Estivill-Castro V., 2002, SIGKDD EXPLORATIONS, V4, P65; Everitt B.S., 1993, CLUSTER ANAL, V3rd; Fell D., 1996, UNDERSTANDING CONTRO; Fernie AR, 2003, FUNCT PLANT BIOL, V30, P111, DOI 10.1071/FP02163; Fiehn O, 2003, EUR J BIOCHEM, V270, P579, DOI 10.1046/j.1432-1033.2003.03427.x; Fiehn O, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P199; Fiehn O, 2002, PLANT MOL BIOL, V48, P155, DOI 10.1023/A:1013713905833; Fiehn O, 2001, COMPAR FUNCT GENOM, V2, P155, DOI 10.1002/cfg.82; Fiehn O, 2000, NAT BIOTECHNOL, V18, P1157, DOI 10.1038/81137; Fisher R. A., 1951, DESIGN EXPT; FLEISCHMANN RD, 1995, SCIENCE, V269, P496, DOI 10.1126/science.7542800; Flury B., 1988, MULTIVARIATE STAT PR; Fogel D.B., 2000, SOLVE IT MODERN HEUR; Foster JA, 2001, NAT REV GENET, V2, P428, DOI 10.1038/35076523; Gilbert R. J., 1999, LATE BREAKING PAPERS, P23; Gilbert RJ, 1997, ANAL CHEM, V69, P4381, DOI 10.1021/ac970460j; Goodacre R, 2003, VIB SPECTROSC, V32, P33, DOI 10.1016/S0924-2031(03)00045-6; GOODACRE R, 1993, J SCI FOOD AGR, V63, P297, DOI 10.1002/jsfa.2740630306; Goodacre R, 2004, TRENDS BIOTECHNOL, V22, P245, DOI 10.1016/j.tibtech.2004.03.007; Goodacre R, 1996, CURR OPIN BIOTECH, V7, P20, DOI 10.1016/S0958-1669(96)80090-5; GOODACRE R, 1993, ANAL CHIM ACTA, V279, P17, DOI 10.1016/0003-2670(93)85062-O; GOODACRE R, 1992, NATURE, V359, P594, DOI 10.1038/359594a0; Goodacre R, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P239; Goodacre R, 2002, ANALYST, V127, P1457, DOI 10.1039/b206037j; Greenland S, 1998, MODERN EPIDEMIOLOGY; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Handl J, 2004, LECT NOTES COMPUT SC, V3242, P1081; Hardy N, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P277; Harrigan G, 2003, METABOLIC PROFILING; Hastie T., 2001, ELEMENTS STAT LEARNI; Heinrich R., 1996, REGULATION CELLULAR; Hicks C.R., 1999, FUNDAMENTAL CONCEPTS; Hill AB, 1991, B HILLS PRINCIPLES M; Hofmeyr JHS, 1996, J THEOR BIOL, V182, P371, DOI 10.1006/jtbi.1996.0176; Hucka M, 2003, BIOINFORMATICS, V19, P524, DOI 10.1093/bioinformatics/btg015; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jenkins H, 2004, NAT BIOTECHNOL, V22, P1601, DOI 10.1038/nbt1041; Johnson H. E., 2000, Genetic Programming and Evolvable Machines, V1, DOI 10.1023/A:1010014314078; Johnson HE, 2003, PHYTOCHEMISTRY, V62, P919, DOI 10.1016/S0031-9422(02)00722-7; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Jones A, 2004, BIOINFORMATICS, V20, P1583, DOI 10.1093/bioinformatics/bth; Kaderbhai NN, 2003, COMP FUNCT GENOM, V4, P376, DOI 10.1002/cfg.302; KELL DB, 1986, FEMS MICROBIOL LETT, V39, P305, DOI 10.1111/j.1574-6968.1986.tb01863.x; Kell DB, 2004, CURR OPIN MICROBIOL, V7, P296, DOI 10.1016/j.mib.2004.04.012; Kell DB, 2001, PLANT PHYSIOL, V126, P943, DOI 10.1104/pp.126.3.943; Kell DB, 2000, TRENDS BIOTECHNOL, V18, P93, DOI 10.1016/S0167-7799(99)01407-9; Kell DB, 2004, BIOESSAYS, V26, P99, DOI 10.1002/bies.10385; Kell DB, 2002, MOL BIOL REP, V29, P237, DOI 10.1023/A:1020342216314; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kohonen T, 1989, SELF ORG ASS MEMORY; Kose F, 2001, BIOINFORMATICS, V17, P1198, DOI 10.1093/bioinformatics/17.12.1198; Koza J.R., 2003, GENETIC PROGRAMMING; Koza J.R., 1994, GENETIC PROGRAMMING; Koza JR, 1999, GENETIC PROGRAMMING, V3; Koza JR, 1992, GENETIC PROGRAMMING; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Langdon W. B., 1998, GENETIC PROGRAMMING; Langdon W. B., 2002, FDN GENETIC PROGRAMM; Lenz EM, 2003, J PHARMACEUT BIOMED, V33, P1103, DOI 10.1016/S0731-7085(03)00410-2; Leonard T., 1999, BAYESIAN METHODS ANA; LI XJ, 2003, METABOLIC PROFILING; Lindon JC, 2003, ANAL CHEM, V75, p384A, DOI 10.1021/ac031386+; Lindon JC, 2003, TOXICOL APPL PHARM, V187, P137, DOI 10.1016/S0041-008X(02)00079-0; Lindon JC, 2000, CONCEPT MAGNETIC RES, V12, P289, DOI 10.1002/1099-0534(2000)12:5<289::AID-CMR3>3.0.CO;2-W; Livingstone D. J., 1995, DATA ANAL CHEM; Mendes Pedro, 2002, Brief Bioinform, V3, P134; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T. M., 1997, MACHINE LEARNING; Montgomery D.C., 2001, DESIGN ANAL EXPT; Montgomery DC, 1995, RESPONSE SURFACE MET; MUGGLETON S, 1990, NEW GENERAT COMPUT, V8, P295; Nas T., 1989, MULTIVARIATE CALIBRA; Nicholson JK, 2002, NAT REV DRUG DISCOV, V1, P153, DOI 10.1038/nrd728; Nicholson JK, 2003, NAT REV DRUG DISCOV, V2, P668, DOI 10.1038/nrd1157; OHAGAN S, 2004, ANAL CHEM IN PRESS; Oliver SG, 1998, TRENDS BIOTECHNOL, V16, P373, DOI 10.1016/S0167-7799(98)01214-1; Orchard S, 2003, PROTEOMICS, V3, P1374, DOI 10.1002/pmic.200300496; Page RDM, 1998, MOL EVOLUTION PHYLOG; Paton NW, 2000, BIOINFORMATICS, V16, P548, DOI 10.1093/bioinformatics/16.6.548; Pearl J, 2000, CAUSALITY MODELS REA; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Raamsdonk LM, 2001, NAT BIOTECHNOL, V19, P45; RAMONI M, 1998, THEORY PRACTICE BAYE; Rayward-Smith V., 1996, MODERN HEURISTIC SEA; Reeves Colin R., 1995, MODERN HEURISTIC TEC; Ripley B. D., 1996, PATTERN RECOGNITION; Roessner U, 2000, PLANT J, V23, P131, DOI 10.1046/j.1365-313x.2000.00774.x; Rothman KJ, 2002, EPIDEMIOLOGY INTRO; Rowland JJ, 2003, BIOSYSTEMS, V72, P187, DOI 10.1016/S0303-2647(03)00143-6; Schlesselman JJ, 1982, CASE CONTROL STUDIES; SEASHOLTZ MB, 1993, ANAL CHIM ACTA, V277, P165, DOI 10.1016/0003-2670(93)80430-S; Shannon Claude E., 1949, MATH THEORY COMMUNIC; Solanky KS, 2003, ANAL BIOCHEM, V323, P197, DOI 10.1016/j.ab.2003.08.028; Steuer R, 2003, BIOINFORMATICS, V19, P1019, DOI 10.1093/bioinformatics/btg120; Sumner LW, 2003, PHYTOCHEMISTRY, V62, P817, DOI 10.1016/S0031-9422(02)00708-2; Taylor CF, 2003, NAT BIOTECHNOL, V21, P247, DOI 10.1038/nbt0303-247; Taylor J, 2002, BIOINFORMATICS, V18, pS241; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Urbanczyk-Wochniak E, 2003, EMBO REP, V4, P989, DOI 10.1038/sj.embor.embor944; Vaidyanathan S, 2003, ANAL CHEM, V75, P6679, DOI 10.1021/ac034669a; Vaidyanathan S, 2004, ANAL CHEM, V76, P5024, DOI 10.1021/ac049684; Weiss SM, 1991, COMPUTER SYSTEMS LEA; WEUSTERBOTZ D, 1995, PROCESS BIOCHEM, V30, P563, DOI 10.1016/0032-9592(94)00036-H; Wilson ID, 2003, J CHROMATOGR A, V1000, P325, DOI 10.1016/S0021-9673(03)00504-1; Woodward AM, 2004, ANALYST, V129, P542, DOI 10.1039/b403134b	138	65	69	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1573-3882			METABOLOMICS	Metabolomics	MAR	2005	1	1					39	51		10.1007/s11306-005-1106-4		13	Endocrinology & Metabolism	Endocrinology & Metabolism	V63QM	WOS:000204301600006		
J	Hall, P; Kang, KH				Hall, P; Kang, KH			Bandwidth choice for nonparametric classification	ANNALS OF STATISTICS			English	Article						Bayes risk; bootstrap; cross-validation; classification error; discrimination; error rate; kernel methods; nonparametric density estimation	CROSS-VALIDATION; DENSITY-ESTIMATION; ERROR RATE; DISCRIMINATION; PROBABILITY; RULES; CONVERGENCE; CLASSIFIERS; REGRESSION; ALGORITHM	It is shown that, for kernel-based classification with univariate distributions and two populations, optimal bandwidth choice has a dichotomous character. If the two densities cross at just one point. where their curvature.,, have the same signs, then minimum Bayes risk is achieved using bandwidths which are an order of magnitude larger than those which minimize pointwise estimation error. On the other hand, if the curvature signs are different, or if there are multiple crossing points. then bandwidths of conventional size are generally appropriate. The range of different modes of behavior is narrower in multivariate settings. There, the optimal size of bandwidth is generally the same as that which is appropriate for pointwise density estimation. These properties motivate empirical rules for bandwidth choice.	Australian Natl Univ, Ctr Math & Applicat, Canberra, ACT 0200, Australia; Hankuk Univ Foreign Studies, Dept Stat, Yongin 449791, South Korea	Hall, P (reprint author), Australian Natl Univ, Ctr Math & Applicat, Canberra, ACT 0200, Australia.	halpstat@pretty.anu.edu.au; khkang@hufs.ac.kr					Ancukiewicz M, 1998, J CLASSIF, V15, P129, DOI 10.1007/s003579900023; Baek S, 2000, ELECTRON LETT, V36, P1821, DOI 10.1049/el:20001249; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHANDA KC, 1989, STAT PROBABIL LETT, V8, P81, DOI 10.1016/0167-7152(89)90088-6; Cover T. M., 1968, P HAW INT C SYST SCI, P413; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; Devroye L., 1996, PROBABILISTIC THEORY, V31; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; EHRENFEUCHT A, 1989, INFORM COMPUT, V82, P247, DOI 10.1016/0890-5401(89)90002-3; FIX E, 1951, 2149004 USAF SCO AV; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P779; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; GYORGI L, 2002, DISTRIBUTION FREE TH; HALL P, 1989, STAT PROBABIL LETT, V8, P109, DOI 10.1016/0167-7152(89)90002-3; HALL P, 1983, ANN STAT, V11, P1156; HALL P, 2002, EFFECT BANDWIDTH CHO; Hardle W., 1987, STATISTICS, V18, P21, DOI 10.1080/02331888708801986; HOLMSTROM L, 1992, J MULTIVARIATE ANAL, V42, P245, DOI 10.1016/0047-259X(92)90046-I; Jiang WX, 2002, ANN STAT, V30, P51, DOI 10.1214/aos/1015362184; KHARIN YS, 1979, STAT PROBLEMS CONTRO, V38, P77; KHARIN YS, 1983, AUTOMAT REM CONTR+, V44, P72; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; KRZYZAK A, 1991, NATO ADV SCI I C-MAT, V335, P347; LAPKO AV, 1993, NONPARAMETRIC CLASSI; Lin CT, 2001, COMMUN STAT-THEOR M, V30, P319, DOI 10.1081/STA-100002034; LUGOSI G, 1994, IEEE T INFORM THEORY, V40, P475, DOI 10.1109/18.312167; Lugosi G, 1996, ANN STAT, V24, P687; Mammen E, 1999, ANN STAT, V27, P1808; MARRON JS, 1983, ANN STAT, V11, P1142; MIELNICZUK J, 1989, J STAT PLAN INFER, V23, P53, DOI 10.1016/0378-3758(89)90039-6; PAWLAK M, 1993, IEEE T INFORM THEORY, V39, P979, DOI 10.1109/18.256504; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Schapire RE, 1998, ANN STAT, V26, P1651; Steele BM, 2000, STAT COMPUT, V10, P349, DOI 10.1023/A:1008933626919; STOLLER DS, 1954, J AM STAT ASSOC, V49, P770, DOI 10.2307/2281538; STONE CJ, 1984, ANN STAT, V12, P1285, DOI 10.1214/aos/1176346792; Yang YH, 1999, IEEE T INFORM THEORY, V45, P2285; Yang YH, 1999, IEEE T INFORM THEORY, V45, P2271	43	19	20	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	FEB	2005	33	1					284	306		10.1214/009053604000000959		23	Statistics & Probability	Mathematics	918VX	WOS:000228576800015		
J	Alvarez, S; Diaz-Uriarte, R; Osorio, A; Barroso, A; Melchor, L; Paz, MF; Honrado, E; Rodriguez, R; Urioste, M; Valle, L; Diez, O; Cigudosa, JC; Dopazo, J; Esteller, M; Benitez, J				Alvarez, S; Diaz-Uriarte, R; Osorio, A; Barroso, A; Melchor, L; Paz, MF; Honrado, E; Rodriguez, R; Urioste, M; Valle, L; Diez, O; Cigudosa, JC; Dopazo, J; Esteller, M; Benitez, J			A predictor based on the somatic genomic changes of the BRCA1/BRCA2 breast cancer tumors identifies the non-BRCA1/BRCA2 tumors with BRCA1 promoter hypermethylation	CLINICAL CANCER RESEARCH			English	Article							SPORADIC BREAST; OVARIAN-CANCER; FAMILIES; GENES; MUTATIONS; CARRIERS	The genetic changes underlying in the development and progression of familial breast cancer are poorly understood. To identify a somatic genetic signature of tumor progression for each familial group, BRCA1, BRCA2, and non-BRCA1/BRCA2 (BRCAX) tumors, by high-resolution comparative genomic hybridization, we have analyzed 77 tumors previously characterized for BRCA1 and BRCA2 germ line mutations. Based on a combination of the somatic genetic changes observed at the six most different chromosomal regions and the status of the estrogen receptor, we developed using random forests a molecular classifier, which assigns to a given tumor a probability to belong either to the BRCA1 or to the BRCA2 class. Because 76.5% (26 of 34) of the BRCAX cases were classified with our predictor to the BRCA1 class with a probability of > 50%, we analyzed the BRCA1 promoter region for aberrant methylation in all the BRCAX cases. We found that 15 of the 34 BRCAX analyzed tumors had hypermethylation of the BRCA1 gene. When we considered the predictor, we observed that all the cases with this epigenetic event were assigned to the BRCA1 class with a probability of >50%. Interestingly, 84.6% of the cases (11 of 13) assigned to the BRCA1 class with a probability >80% had an aberrant methylation of the BRCA1 promoter. This fact suggests that somatic BRCA1 inactivation could modify the profile of tumor progression in most of the BRCAX cases.	Spanish Natl Canc Ctr, Dept Human Genet, Mol Pathol Programme, Madrid 28029, Spain; Spanish Natl Canc Ctr, Canc Epigenet Grp, Mol Pathol Programme, Madrid 28029, Spain; Spanish Natl Canc Ctr, Bioinformat Unit, Madrid 28029, Spain; Spanish Natl Canc Ctr, Cytogenet Unit, Biotechnol Programme, Madrid 28029, Spain; H Santa Creu & Sant Pau, Dept Genet, Barcelona, Spain	Alvarez, S (reprint author), Spanish Natl Canc Ctr, Dept Human Genet, Mol Pathol Programme, N328029, Madrid 28029, Spain.	salvarez@cnio.es	Dopazo, Joaquin/A-9270-2014; Osorio, Ana/I-4324-2014; Diaz-Uriarte, Ramon/M-5517-2013; Valle, Laura/H-8118-2012; Melchor, Lorenzo/H-7221-2015; Esteller, Manel/L-5956-2014	Dopazo, Joaquin/0000-0003-3318-120X; Osorio, Ana/0000-0001-8124-3984; Diaz-Uriarte, Ramon/0000-0002-6637-9039; Valle, Laura/0000-0003-0371-0844; Melchor, Lorenzo/0000-0002-5322-2817; Esteller, Manel/0000-0003-4490-6093			ALVAREZ S, 2001, GENE CHROMOSOME CANC, V323, P285; AMBROISE C, 2002, P NATL ACAD SCI USA, V9910, P6562; *BREAST CANC LINK, 2000, ONCOGENE, V1936, P4170; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CAMPOS B, 2001, ANN ONCOL, V1212, P1699; Catteau A, 1999, ONCOGENE, V18, P1957, DOI 10.1038/sj.onc.1202509; DELAHOYA M, 2002, INT J CANCER, V974, P466; Esteller M, 2000, J NATL CANCER I, V92, P564, DOI 10.1093/jnci/92.7.564; Ford D, 1998, AM J HUM GENET, V62, P676, DOI 10.1086/301749; GOLDHIRSCH A, 2003, J CLIN ONCOL, V2117, P3357; GRUSHKO TA, 2004, CLIN CANCER RES, V102, P499; GUNTHER EC, 2003, P NATL ACAD SCI USA, P9608; Harrell FE, 2001, REGRESSION MODELING; HEDEFALK I, 2001, NEW ENGL J MED, V3448, P539; HEDENFALK I, 2003, P NATL ACAD SCI USA, V1005, P2532; HERRERO J, 2003, NUCLEIC ACIDS RES, V3113, P3461; Kainu T, 2000, P NATL ACAD SCI USA, V97, P9603, DOI 10.1073/pnas.97.17.9603; Kirchhoff M, 1998, CYTOMETRY, V31, P163, DOI 10.1002/(SICI)1097-0320(19980301)31:3<163::AID-CYTO3>3.0.CO;2-M; Kirchhoff M, 2000, EUR J HUM GENET, V8, P661, DOI 10.1038/sj.ejhg.5200512; Lakhani SR, 2002, J CLIN ONCOL, V20, P2310, DOI 10.1200/JCO.2002.09.023; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Nathanson KL, 2001, HUM MOL GENET, V10, P715, DOI 10.1093/hmg/10.7.715; NESS GO, 2002, AM J MED GENET, V1132, P125; Osorio A, 2000, BRIT J CANCER, V82, P1266, DOI 10.1054/bjoc.1999.1089; PALACIOS J, 2003, CLIN CANC RES 1, V910, P3606; Seitz S, 1997, ONCOGENE, V14, P741, DOI 10.1038/sj.onc.1200881; Simon R, 2003, J NATL CANCER I, V95, P14; Thorlacius S, 1998, LANCET, V352, P1337, DOI 10.1016/S0140-6736(98)03300-5; Tirkkonen M, 1997, CANCER RES, V57, P1222; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; WESSELS LF, 2002, CANCER RES, V6223, P7110; ZUDAIRE I, 2002, HISTOPATHOLOGY, V406, P547	33	42	44	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	FEB 1	2005	11	3					1146	1153				8	Oncology	Oncology	893SV	WOS:000226740400024	15709182	
J	Bureau, A; Dupuis, J; Falls, K; Lunetta, KL; Hayward, B; Keith, TP; Van Eerdewegh, P				Bureau, A; Dupuis, J; Falls, K; Lunetta, KL; Hayward, B; Keith, TP; Van Eerdewegh, P			Identifying SNPs predictive of phenotype using random forests	GENETIC EPIDEMIOLOGY			English	Article						genotype-phenotype association; predictive importance; classification trees; case-control study	ASSOCIATION; CANCER; GENES	There has been a great interest and a few successes in the identification of complex disease susceptibility genes in recent years. Association studies, where a large number of single-nucleotide polymorphisms (SNPs) are typed in a sample of cases and controls to determine which genes are associated with a specific disease, provide a powerful approach for complex disease gene mapping. Genes of interest in those studies may contain large numbers of SNPs that classical statistical methods cannot handle simultaneously without requiring prohibitively large sample sizes. By contrast, high-dimensional nonparametric methods thrive on large numbers of predictors. This work explores the application of one such method, random forests, to the problem of identifying SNPs predictive of the phenotype in the case-control study design. A random forest is a collection of classification trees grown on bootstrap samples of observations, using a random subset of predictors to define the best split at each node. The observations left out of the bootstrap samples are used to estimate prediction error. The importance of a predictor is quantified by the increase in misclassification occurring when the values of the predictor are randomly permuted. We extend the concept of importance to pairs of predictors, to capture joint effects, and we explore the behavior of importance measures over a range of two-locus disease models in the presence of a varying number of SNPs unassociated with the phenotype. We illustrate the application of random forests with a data set of asthma cases and unaffected controls genotyped at 42 SNPs in ADAM33, a previously identified asthma susceptibility gene. SNPs and SNP pairs highly associated with asthma tend to have the highest importance index value, but predictive importance and association do not always coincide. (C) 2004 Wiley-Liss, Inc.	Oscient Pharmaceut, Dept Human Genet, Waltham, MA USA; Univ Lethbridge, Sch Hlth Sci, Lethbridge, AB T1K 3M4, Canada; Boston Univ, Sch Publ Hlth, Dept Biostat, Boston, MA USA; Boston Univ, Sch Med, Dept Neurol, Boston, MA 02118 USA; Calileo Genom Inc, St Laurent, PQ, Canada; Harvard Univ, Sch Med, Dept Psychiat, Boston, MA 02115 USA	Bureau, A (reprint author), Univ Laval, Dept Social & Prevent Med, Pavillon Est,2180 Chem St Foy, Quebec City, PQ G1K 7P4, Canada.	alexandre.bureau@msp.ulaval.ca					BREIMAN L, 2003, RANDOM FORESTS VERSI; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUREAU A, 2003, BMC GENET S, V4, P64; Chiano MN, 1998, ANN HUM GENET, V62, P55, DOI 10.1046/j.1469-1809.1998.6210055.x; Cook Nancy R., 2004, Statistics in Medicine, V23, P1439, DOI 10.1002/sim.1749; EXCOFFIER L, 1995, MOL BIOL EVOL, V12, P921; Fleiss J. L, 2003, STAT METHODS RATES P, Vthird; Glazier AM, 2002, SCIENCE, V298, P2345, DOI 10.1126/science.1076641; *GOLD HEL INC, 2002, HEL TREE MAN VERS 2; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; HASEMAN JK, 1972, BEHAV GENET, V2, P3, DOI 10.1007/BF01066731; Horng JT, 2004, IEEE T INF TECHNOL B, V8, P59, DOI 10.1109/TITB.2004.824738; Kim HS, 2004, PAIN, V109, P488, DOI 10.1016/j.pain.2004.02.027; Morton NE, 1998, P NATL ACAD SCI USA, V95, P11389, DOI 10.1073/pnas.95.19.11389; Pociot F, 2004, AM J HUM GENET, V74, P647, DOI 10.1086/383095; Schwender H, 2004, TOXICOL LETT, V151, P291, DOI 10.1016/j.toxlet.2004.02.021; Van Eerdewegh P, 2002, NATURE, V418, P426, DOI 10.1038/nature00878; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5	19	161	172	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0741-0395			GENET EPIDEMIOL	Genet. Epidemiol.	FEB	2005	28	2					171	182		10.1002/gepi.20041		12	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	891GB	WOS:000226568200006	15593090	
J	Pal, M				Pal, M			Random forest classifier for remote sensing classification	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article							LAND-COVER CLASSIFICATION	Growing an ensemble of decision trees and allowing them to vote for the most popular class produced a significant increase in classification accuracy for land cover classification. The objective of this study is to present results obtained with the random forest classifier and to compare its performance with the support vector machines (SVMs) in terms of classification accuracy, training time and user defined parameters. Landsat Enhanced Thematic Mapper Plus (ETM+) data of an area in the UK with seven different land covers were used. Results from this study suggest that the random forest classifier performs equally well to SVMs in terms of classification accuracy and training time. This study also concludes that the number of user-defined parameters required by random forest classifiers is less than the number required for SVMs and easier to define.	Natl Inst Technol, Dept Civil Engn, Haryana 136119, India	Pal, M (reprint author), Natl Inst Technol, Dept Civil Engn, Haryana 136119, India.	mpce_pal@yahoo.co.uk	Pal, Mahesh /P-1136-2014	Pal, Mahesh /0000-0003-1805-2952			Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; Breiman L., 1999, 567 U CAL STAT DEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Briem GJ, 2002, IEEE T GEOSCI REMOTE, V40, P2291, DOI 10.1109/TGRS.2002.802476; Chang CC, 2001, LIBSVM LIB SUPPORT V; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dietterich T. G., 2002, ENSEMBLE LEARNING HD; Feller W., 1968, INTRO PROBABILITY TH, VI; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedl MA, 1999, IEEE T GEOSCI REMOTE, V37, P969, DOI 10.1109/36.752215; Giacinto G., 1997, P EUR S INT TECHN BA, P166; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; Muchoney D, 2000, INT J REMOTE SENS, V21, P1115, DOI 10.1080/014311600210100; Pal M, 2003, REMOTE SENS ENVIRON, V86, P554, DOI 10.1016/S0034-4257(03)00132-9; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Vapnik VN, 1995, NATURE STAT LEARNING	18	156	159	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161			INT J REMOTE SENS	Int. J. Remote Sens.	JAN 10	2005	26	1					217	222		10.1080/01431160412331269698		6	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	893NH	WOS:000226726000016		
J	Cohen, S; Ruppin, E; Dror, G		Kaelbling, LP; Saffotti, A		Cohen, Shay; Ruppin, Eytan; Dror, Gideon			Feature Selection Based on the Shapley Value	19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05)			English	Proceedings Paper	19th International Joint Conference on Artificial Intelligence (IJCAI 05)	JUL 30-AUG 05, 2005	Edinburgh, SCOTLAND	BCS, Scottish Enterprise, QinetiQ, BTO, Foresight, Microsoft Research, ERCIM, Intelligent Applications Ltd, IBM, CologNET, Intel, Google				We present and study the Contribution-Selection algorithm (CSA), a novel algorithm for feature selection. The algorithm is based on the Multi-perturbation Shapley Analysis, a framework which relies on game theory to estimate usefulness. The algorithm iteratively estimates the usefulness of features and selects them accordingly, using either forward selection or backward elimination Empirical comparison with several other existing feature selection methods shows that the backward elimination variant of CSA leads to the most accurate classification results on an array of datasets.	[Cohen, Shay; Ruppin, Eytan] Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel	Cohen, S (reprint author), Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.	cshay@post.tau.ac.il; ruppin@post.tau.ac.il; gideon@mta.ac.il					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Guyon I., 2003, NIPS 2003 WORKSH FEA; Joachims J, 1999, ADV KERNEL METHODS S; KEINAN A, 2004, NEURAL COMPUTATION, V16; Koller D., 1996, P 13 INT C MACH LEAR, P284; Perkins S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753698; Shapley L. S., 1953, CONTRIBUTIONS THEORY, P307	9	3	3	IJCAI-INT JOINT CONF ARTIF INTELL	FREIBURG	ALBERT-LUDWIGS UNIV FREIBURG GEORGES-KOHLER-ALLEE, INST INFORMATIK, GEB 052, FREIBURG, D-79110, GERMANY							2005							665	670				6	Computer Science, Artificial Intelligence	Computer Science	BUS48	WOS:000290233000107		
S	Wang, WJ; Richards, G; Rea, S			IEEE	Wang, Wenjia; Richards, Graeme; Rea, Sarah			Hybrid data mining ensemble for predicting osteoporosis risk	2005 27th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Vols 1-7	PROCEEDINGS OF ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY		English	Proceedings Paper	27th Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society	AUG 31-SEP 03, 2005	Shanghai, PEOPLES R CHINA	IEEE Engn Med & Biol Soc, Chinese Acad Engn Sci			MULTIVERSION SOFTWARE; NEURAL-NETWORK	This paper presents the research in developing data mining ensembles for predicting the risk of osteoporosis prevalence in women. Osteoporosis is a bone disease that commonly occurs among postmenopausal women and no effective treatments are available at the moment, except prevention, which requires early diagnosis. However, early detection of the disease is very difficult. This research aims to devise an intelligent diagnosis support system by using data mining ensemble technology to assist General Practitioners assessing patient's risk at developing osteoporosis. The paper describes the methods for constructing effective ensembles through measuring diversity between individual predictors. Hybrid ensembles are implemented by neural networks and decision tress. The ensembles built for predicting osteoporosis are evaluated by the real-world data and the results indicate that the hybrid ensembles have relatively high-level of diversity and thus are able to improve prediction accuracy.	Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England	Wang, WJ (reprint author), Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.						BRAZIER K, 2004, P 5 INT C INT DAT EN, P333; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COOPER, 1992, J BONE MINERAL RES; Dietterich TG, 2000, LECT NOTES COMPUTER, V1857; ECKHARDT DE, 1985, IEEE T SOFTWARE ENG, V11, P1511, DOI 10.1109/TSE.1985.231895; Esposito R., 2003, P 18 INT JOINT C ART, P499; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; KROGH K, 1995, ADV NEURAL INFORMATI, V7, P231; KUNCHEVA L, 2003, MEASURES DIVERSITY C; LITTLEWOOD B, 1989, IEEE T SOFTWARE ENG, V15, P1596, DOI 10.1109/32.58771; Partridge D, 1997, INFORM SOFTWARE TECH, V39, P707, DOI 10.1016/S0950-5849(97)00023-2; Partridge D, 1996, NEURAL COMPUT, V8, P869, DOI 10.1162/neco.1996.8.4.869; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RICHARDS G, 2005, MACHINE LEARNING; TUNER K, 1999, P IJCNN1999 WASH DC; WANG W, 1998, NEURAP98, P351; Wang W, 2001, NEURAL COMPUT, V13, P1603, DOI 10.1162/089976601750265027; Wang W, 2000, NEURAL COMPUT APPL, V9, P101, DOI 10.1007/PL00009895; WANG W, 2001, P IJCNN 01 IEEE INNS, P2376; WANG W, 2002, IDEAL 02 IEEE EPSRC	23	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1094-687X		0-7803-8740-6	P ANN INT IEEE EMBS			2005							886	889				4	Engineering, Biomedical	Engineering	BER00	WOS:000238998400231		
S	Shen, KQ; Li, XP; Pullens, WLPM; Zheng, H; Ong, CJ; Wilder-Smith, EPV			IEEE	Shen, K. Q.; Li, X. P.; Pullens, W. L. P. M.; Zheng, H.; Ong, C. J.; Wilder-Smith, E. P. V.			Key feature extraction for fatigue identification using random forests	2005 27TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-7	PROCEEDINGS OF ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY		English	Proceedings Paper	27th Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society	AUG 31-SEP 03, 2005	Shanghai, PEOPLES R CHINA	IEEE Engn Med & Biol Soc, Chinese Acad Engn Sci			DRIVER FATIGUE	Electroencephalogram (EEG) might be the most predictive and reliable physiological indicator of mental fatigue. However, the extraction of key features from massive EEG data for mental fatigue identification remains a challenge. The objective of this study is to identify the key EEG features in relationship to mental fatigue, from a broad pool of EEG features generated by quantitative EEG (qEEG) techniques, using Random Forests (RF), which is a recently developed machine learning algorithm. The method is applied to key EEG feature extraction for 5-level mental fatigue identification using the five subjects' EEG data recorded in 25-hour fatigue experiments. RF produces significant feature reduction with little compromise of the classification performance. The identified key EEG features also indicate that electrode locations in frontal and occipital regions of the brain are most important for adequate representation of the deactivation of functional lobes of the brain, which is consistent with the anatomical areas known to be involved in mental fatigue. It is also interesting to discover that the four frequency bands are all important for the mental fatigue identification.	Natl Univ Singapore, Singapore 117548, Singapore	Shen, KQ (reprint author), Natl Univ Singapore, Singapore 117548, Singapore.	shen@nus.edu.sg; mpelixp@nus.edu.sg; w.l.p.m.pullens@student.tue.nl; g0402969@nus.edu.sg; mpeongcj@nus.edu.sg; mdcwse@nus.edu.sg	Wilder-Smith, Einar/	Wilder-Smith, Einar/0000-0003-3402-7503			Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 2003, RF TOOLS CLASS 2 EYE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Grandjean E, 1981, FITTING TASK MAN; GUYON I, 2004, P 18 ANN C NEUR INF; Horne JA, 1995, J SLEEP RES, V4, P23; Lal SKL, 2003, J SAFETY RES, V34, P321, DOI 10.1016/S0022-4375(03)00027-6; Lal SKL, 2001, BIOL PSYCHOL, V55, P173, DOI 10.1016/S0301-0511(00)00085-5; Lal SKL, 2002, PSYCHOPHYSIOLOGY, V39, P313, DOI 10.1017/S0048577201393095; Makeig S, 1996, COGNITIVE BRAIN RES, V4, P15, DOI 10.1016/0926-6410(95)00042-9; Muzur A, 2002, TRENDS COGN SCI, V6, P475, DOI 10.1016/S1364-6613(02)01992-7; Niedermeyer E, 1999, ELECTROENCEPHALOGRAP; Ogilvie RD, 2001, SLEEP MED REV, V5, P247, DOI 10.1053/smrv.2001.0145; OKOGBAA OG, 1994, APPL ERGON, V25, P355, DOI 10.1016/0003-6870(94)90054-X; Vapnik V., 1998, STAT LEARNING THEORY	15	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1094-687X		0-7803-8740-6	P ANN INT IEEE EMBS			2005							2044	2047		10.1109/IEMBS.2005.1616859		4	Engineering, Biomedical	Engineering	BER00	WOS:000238998401258		
B	Li, HF; Zhang, KS; Jiang, T			IEEE Comp Soc	Li, HF; Zhang, KS; Jiang, T			Robust and accurate cancer classification with gene expression profiling	2005 IEEE COMPUTATIONAL SYSTEMS BIOINFORMATICS CONFERENCE, PROCEEDINGS			English	Proceedings Paper	IEEE Computational Systems Bioinformatics Conference	AUG 08-11, 2005	Stanford, CA	IEEE Comp Soc Tech Comm Bioinformat			DISCRIMINANT-ANALYSIS; TUMOR CLASSIFICATION; SAMPLE-SIZE; PATTERN-RECOGNITION; FEATURE-SELECTION; FACE RECOGNITION; CLASS PREDICTION; EIGENFACES; MICROARRAY; ALGORITHM	Robust and accurate cancer classification is critical in cancer treatment Gene expression profiling is expected to enable us to diagnose tumors precisely and systematically. However the classification task in this context is very challenging because of the curse of dimensionality and the small sample size problem. In this paper we propose a novel method to solve these two problems. Our method is able to map gene expression data into a very low dimensional space and thus meets the recommended samples to features per class ratio. As a result, it can be-used to classify new samples robustly with low and trustable (estimated) error rates. The method is based on linear discriminant analysis (LDA). However the conventional LDA requires that the within-class scatter matrix S(w) be nonsingular. Unfortunately, S(w) is always singular in the case of cancer classification due to the small sample size problem. To overcome this problem, we develop a generalized linear discriminant analysis (GLDA) that is a general, direct and complete solution to optimize Fisher's criterion. GLDA is mathematically well-founded and coincides with the conventional LDA when S(w) is nonsingular Different front the conventional LDA, GLDA does not assume. the nonsingularity of S(w) and thus naturally solves the small sample size problem. To accommodate the high dimensionality of scatter matrices, a fast algorithm of GLDA is also developed. Our extensive experiments on seven public cancer datasets show that the method performs well. Especially on some difficult instances that have very small samples to-genes per class ratios, our method achieves much. higher accuracies than widely used classification methods such as support vector machines, random forests, etc.	Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA	Li, HF (reprint author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.	hli@cs.ucr.edu; keshu.zhang@motorola.com; jiang@cs.ucr.edu					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bellman R., 1961, ADAPTIVE CONTROL PRO; Ben-Dor A., 2000, P 4 ANN INT C COMP M, P54, DOI 10.1145/332306.332328; Bo TH, 2002, GENOME BIOL, V3; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub G. H., 1996, MATRIX COMPUTATIONS; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Hodges Jr J, 1951, DISCRIMINATORY ANAL; HONG ZQ, 1991, PATTERN RECOGN, V24, P317, DOI 10.1016/0031-3203(91)90074-F; Huang R., 2002, P INT C PATT REC QUE, V3, P29; Jain A. K., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; LI H, 2003, ADV NEURAL INFORMATI, V16, P97; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; MUKHERJEE S, 1998, 1677 AI; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; RAO CR, 1948, J ROY STAT SOC B, V10, P159; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Slonim D. K., 2000, P 4 ANN INT C COMP M, P263, DOI 10.1145/332306.332564; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; TIAN Q, 1986, OPT ENG, V25, P834, DOI 10.1117/12.7973916; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik V., 1998, STAT LEARNING THEORY; Weston J, 2001, ADV NEUR IN, V13, P668; Yeang Chen-Hsiang, 2001, BIOINFORMATICS, V17, P316; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhang HP, 2003, P NATL ACAD SCI USA, V100, P4168, DOI 10.1073/pnas.0230559100	47	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2344-7				2005							310	321				12	Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Genetics & Heredity	Biotechnology & Applied Microbiology; Computer Science; Genetics & Heredity	BCX83	WOS:000231800100035		
S	Siohan, O; Ramabhadran, B; Kingsbury, B			IEEE	Siohan, O; Ramabhadran, B; Kingsbury, B			Constructing ensembles of ASR systems using randomized decision trees	2005 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1-5: SPEECH PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	30th IEEE International Conference on Acoustics, Speech, and Signal Processing	MAR 19-23, 2005	Philadelphia, PA	IEEE			RECOGNITION; SPEECH	Building multiple automatic speech recognition (ASR) systems and combining their outputs using voting techniques such as ROVER is an effective technique for lowering the overall word error rate. A successful system combination approach requires the construction of multiple systems with complementary errors, or the combination will not outperform any of the individual systems. In general this is achieved empirically, for example by building systems on different input features. In this paper, we present a systematic approach for building multiple ASR systems in which the decision tree state-tying procedure that is used to specify context-dependent acoustic models is randomized. Experiments carried out on two large vocabulary recognition tasks. MALACH and DARPA EARS, illustrate the effectiveness of the approach.	IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA	Siohan, O (reprint author), IBM Corp, TJ Watson Res Ctr, 1101 Kitchawan Rd,Rte 134-POB 218, Yorktown Hts, NY 10598 USA.	siohan@us.ibm.com; bhuvana@us.ibm.com; bedk@us.ibm.com					Anastasakos T., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607807; Bahl L, 1991, P INT C AC SPEECH SI, P185, DOI 10.1109/ICASSP.1991.150308; Bisani M., 2004, P IEEE INT C AC SPEE, P409; BREIMAN L, 1999, 567 U C BERK STAT DE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Byrne W, 2004, IEEE T SPEECH AUDI P, V12, P420, DOI 10.1109/TSA.2004.828702; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; DIMITRAKAKIS C, 2004, P IEEE INT C AC SPEE; Fiscus J, 1997, P IEEE WORKSH AUT SP, P347; Freund Y., 1996, P 13 INT C MACH LEAR; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; NIYOGI P, 2000, P IEEE INT C AC SPEE; Reichl W, 2000, IEEE T SPEECH AUDI P, V8, P555, DOI 10.1109/89.861375; SCHWENK H, 1999, P IEEE INT C AC SPEE, V2, P1009; SOLTAU H, UNPUB ICASSP 05; ZWEIG G, 2000, P IEEE INT C AC SPEE, V3, P1527	20	12	12	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		0-7803-8874-7	INT CONF ACOUST SPEE			2005							197	200				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BCI02	WOS:000229404200050		
S	Kotsiantis, SB; Tsekouras, GE; Pintelas, PE		Bozanis, P; Houstis, EN		Kotsiantis, SB; Tsekouras, GE; Pintelas, PE			Bagging model trees for classification problems	ADVANCES IN INFORMATICS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th Panhellenic Conference on Informatics (PCI 2005)	NOV 11-13, 2005	Volos, GREECE	Alpha Bank, Microsoft Hellas, Hellen Org Telecommun, Div Thessaly, Minicipal Volos, Univ Thessaly, Fdn Res & Technol, Hellas FORTH, Ctr Res & Technol, Hellas CERTH				Structurally, a model tree is a regression method that takes the form of a decision tree with linear regression functions instead of terminal class values at its leaves. In this study, model trees are coupled with bagging for solving classification problems. In order to apply this regression technique to classification problems, we consider the conditional class probability function and seek a model-tree approximation to it. During classification, the class whose model tree generates the greatest approximated probability value is chosen as the predicted class. We performed a comparison with other well known ensembles of decision trees, on standard benchmark datasets and the performance of the proposed technique was greater in most cases.	Univ Patras, Dept Math, Educ Software Dev Lab, GR-26110 Patras, Greece; Univ Aegean, Dept Cultural Technol & Commun, Mitilini, Greece	Kotsiantis, SB (reprint author), Univ Patras, Dept Math, Educ Software Dev Lab, GR-26110 Patras, Greece.	sotos@math.upatras.gr; gtsek@ct.aegean.gr; pintelas@math.upatras.gr	kotsiantis, sotiris/C-5640-2009; Tsekouras, George/	kotsiantis, sotiris/0000-0002-2247-3082; Tsekouras, George/0000-0001-7006-1536			Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; Freund Y, P ICML 96, P148; Kleinberg EM, 2000, LECT NOTES COMPUT SC, V1857, P67; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kotsiantis S, 2004, APPL ARTIF INTELL, V18, P411, DOI 10.1080/08839510490442058; Landwehr N, 2003, LECT NOTES ARTIF INT, V2837, P241; Malerba D, 2004, IEEE T PATTERN ANAL, V26, P612, DOI 10.1109/TPAMI.2004.1273937; Melville P., 2003, P 18 INT JOINT C ART, P505; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Opitz D., 1999, ARTIF INTELL, V11, P169; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Wang Y., 1997, P 9 EUR C MACH LEARN, P128; Witten I., 2000, DATA MINING PRACTICA	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29673-5	LECT NOTES COMPUT SC			2005	3746						328	337				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BDJ02	WOS:000233675500031		
S	Liu, FT; Ting, KM; Fan, W		Ho, TB; Cheung, D; Liu, H		Liu, FT; Ting, KM; Fan, W			Maximizing tree diversity by building complete-random decision trees	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific/Asia Conference on Knowledge Discovery and Data Mining	MAY 18-20, 2005	Hanoi, VIETNAM					One of the ways to lower generalization error of decision pp tree ensemble is to maximize tree diversity. Building complete-random trees forgoes strength obtained from a test selection criterion. However, it achieves higher tree diversity. We provide a taxonomy of different randomization methods and find that complete-random test selection produces diverse trees and other randomization methods such as bootstrap sampling may impair tree growth and limit tree diversity. The well accepted practice in constructing decision trees is to apply bootstrap sampling and voting. To challenge this practice, we explore eight variants of complete-random trees using three parameters: ensemble methods, tree height restriction and sample randomization. Surprisingly, the most accurate variant is very simple and performs comparably to Bagging and Random Forests. It achieves good results by maximizing tree diversity and is called Max-diverse Ensemble.	Monash Univ, Sch Comp & Informat Technol, Churchill, Vic 3842, Australia; IBM Corp, TJ Watson Res, Hawthorne, NY 10532 USA	Liu, FT (reprint author), Monash Univ, Sch Comp & Informat Technol, Churchill, Vic 3842, Australia.	Tony.Liu@infotech.monash.edu.au; KaiMing.Ting@infotech.monash.edu.au; weifan@us.ibm.com					Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domingos P., 2000, P 17 INT C MACH LEAR, P223; Fan W, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P51; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Quinlan J., 1993, C4 5 PROGRAMS MACHIN	10	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26076-5	LECT NOTES ARTIF INT			2005	3518						605	610				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCL84	WOS:000229956700069		
J	Raza, K; Falciani, F; Curnow, SJ; Ross, EJ; Lee, CY; Akbar, AN; Lord, JM; Gordon, C; Buckley, CD; Salmon, M				Raza, K; Falciani, F; Curnow, SJ; Ross, EJ; Lee, CY; Akbar, AN; Lord, JM; Gordon, C; Buckley, CD; Salmon, M			Early rheumatoid arthritis is characterized by a distinct and transient synovial fluid cytokine profile of T cell and stromal cell origin	ARTHRITIS RESEARCH & THERAPY			English	Article							NECROSIS-FACTOR-ALPHA; INFLAMMATORY ARTHRITIS; DENDRITIC CELLS; PERIPHERAL-BLOOD; GAMMA-INTERFERON; GENE-EXPRESSION; IFN-GAMMA; FIBROBLASTS; APOPTOSIS; DISEASE	Pathological processes involved in the initiation of rheumatoid synovitis remain unclear. We undertook the present study to identify immune and stromal processes that are present soon after the clinical onset of rheumatoid arthritis ( RA) by assessing a panel of T cell, macrophage, and stromal cell related cytokines and chemokines in the synovial fluid of patients with early synovitis. Synovial fluid was aspirated from inflamed joints of patients with inflammatory arthritis of duration 3 months or less, whose outcomes were subsequently determined by follow up. For comparison, synovial fluid was aspirated from patients with acute crystal arthritis, established RA and osteoarthritis. Rheumatoid factor activity was blocked in the synovial fluid samples, and a panel of 23 cytokines and chemokines measured using a multiplex based system. Patients with early inflammatory arthritis who subsequently developed RA had a distinct but transient synovial fluid cytokine profile. The levels of a range of T cell, macrophage and stromal cell related cytokines ( e. g. IL-2, IL-4, IL-13, IL-17, IL-15, basic fibroblast growth factor and epidermal growth factor) were significantly elevated in these patients within 3 months after symptom onset, as compared with early arthritis patients who did not develop RA. In addition, this profile was no longer present in established RA. In contrast, patients with non-rheumatoid persistent synovitis exhibited elevated levels of interferon-gamma at initiation. Early synovitis destined to develop into RA is thus characterized by a distinct and transient synovial fluid cytokine profile. The cytokines present in the early rheumatoid lesion suggest that this response is likely to influence the microenvironment required for persistent RA.	Univ Birmingham, MRC, Ctr Immune Regulat, Div Immun & Infect, Birmingham, W Midlands, England; Sandwell & W Birmingham Hosp NHS Trust, City Hosp, Dept Rheumatol, Birmingham, W Midlands, England; Univ Birmingham, Sch Biosci, Birmingham, W Midlands, England; Sandwell & W Birmingham Hosp NHS Trust, City Hosp, Dept Radiol, Birmingham, W Midlands, England; UCL Royal Free & Univ Coll Med Sch, Dept Immunol & Mol Pathol, London, England	Raza, K (reprint author), Univ Birmingham, MRC, Ctr Immune Regulat, Div Immun & Infect, Birmingham, W Midlands, England.	k.raza@bham.ac.uk	Falciani, Francesco/F-3490-2010				Akbar AN, 1997, IMMUNOL TODAY, V18, P72, DOI 10.1016/S0167-5699(97)01003-7; Akbar AN, 1996, EUR J IMMUNOL, V26, P294, DOI 10.1002/eji.1830260204; ARNETT FC, 1988, ARTHRITIS RHEUM, V31, P315, DOI 10.1002/art.1780310302; Bathon JM, 2000, NEW ENGL J MED, V343, P1586, DOI 10.1056/NEJM200011303432201; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Berglin E, 2004, ARTHRITIS RES THER, V6, pR303, DOI 10.1186/ar1187; Blades MC, 2002, ARTHRITIS RHEUM, V46, P824, DOI 10.1002/art.10102; Boers M, 1997, LANCET, V350, P309, DOI 10.1016/S0140-6736(97)01300-7; BREIMAN L, MANUAL SETTING UP US; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brennan FM, 2002, ARTHRITIS RHEUM, V46, P31, DOI 10.1002/1529-0131(200201)46:1<31::AID-ART10029>3.0.CO;2-5; BUCALA R, 1991, J EXP MED, V173, P569, DOI 10.1084/jem.173.3.569; Bucht A, 1996, CLIN EXP IMMUNOL, V103, P357; Buckley CD, 2000, J IMMUNOL, V165, P3423; Buckley CD, 2001, TRENDS IMMUNOL, V22, P199, DOI 10.1016/S1471-4906(01)01863-4; Chiaramonte MG, 1999, J CLIN INVEST, V104, P777, DOI 10.1172/JCI7325; Conaghan PG, 2003, ARTHRITIS RHEUM, V48, P64, DOI 10.1002/art.10747; Cox T.F., 2000, MULTIDIMENSIONAL SCA; Curnow SJ, 2004, J IMMUNOL, V173, P5290; Firestein GS, 2002, ARTHRITIS RHEUM, V46, P298, DOI 10.1002/art.502; Firestein GS, 2003, NATURE, V423, P356, DOI 10.1038/nature01661; FIRESTEIN GS, 1987, ARTHRITIS RHEUM, V30, P864, DOI 10.1002/art.1780300804; Fossiez F, 1996, J EXP MED, V183, P2593, DOI 10.1084/jem.183.6.2593; Gerli R, 2002, CLIN EXP IMMUNOL, V129, P549, DOI 10.1046/j.1365-2249.2002.01913.x; GREGERSEN PK, 1987, ARTHRITIS RHEUM, V30, P1205, DOI 10.1002/art.1780301102; HEINZEL FP, 1991, P NATL ACAD SCI USA, V88, P7011, DOI 10.1073/pnas.88.16.7011; HUSBY G, 1985, ARTHRITIS RHEUM, V28, P174, DOI 10.1002/art.1780280212; JACOBS MJM, 1994, IMMUNOLOGY, V83, P390; Jakubzick C, 2003, AM J PATHOL, V162, P1475, DOI 10.1016/S0002-9440(10)64280-0; Joosten LAB, 1999, ARTHRITIS RES, V1, P81, DOI 10.1186/ar14; Jovanovic DV, 1998, J IMMUNOL, V160, P3513; Kaufman J, 2004, J IMMUNOL, V172, P1862; KURKI P, 1992, ARTHRITIS RHEUM, V35, P914, DOI 10.1002/art.1780350810; Leung BP, 2002, J IMMUNOL, V169, P7071; MATTHEWS N, 1993, ARTHRITIS RHEUM, V36, P603, DOI 10.1002/art.1780360505; McInnes IB, 1997, NAT MED, V3, P189, DOI 10.1038/nm0297-189; Miossec P, 2003, ARTHRITIS RHEUM, V48, P594, DOI 10.1002/art.10816; MODLIN RL, 1994, J INVEST DERMATOL, V102, P828, DOI 10.1111/1523-1747.ep12381958; Morita Y, 1998, ARTHRITIS RHEUM, V41, P1669, DOI 10.1002/1529-0131(199809)41:9<1669::AID-ART19>3.0.CO;2-G; Mottonen T, 2002, ARTHRITIS RHEUM, V46, P894, DOI 10.1002/art.10135; Nielen MMJ, 2004, ARTHRITIS RHEUM, V50, P380, DOI 10.1002/art.20018; Pap T, 2000, ARTHRITIS RES, V2, P361, DOI 10.1186/ar113; Parsonage G, 2003, THROMB HAEMOSTASIS, V90, P688, DOI 10.1160/TH03-04-0208; Pilling D, 1999, EUR J IMMUNOL, V29, P1041, DOI 10.1002/(SICI)1521-4141(199903)29:03<1041::AID-IMMU1041>3.0.CO;2-#; Raza K, 2003, RHEUMATOLOGY, V42, P976, DOI 10.1093/rheumatology/keg269; Relic B, 2001, J IMMUNOL, V166, P2775; Salmon M, 1997, J CLIN INVEST, V99, P439, DOI 10.1172/JCI119178; SALMON M, 1997, IMMUNOLOGIST, V5, P87; Santiago-Schwarz F, 2001, J IMMUNOL, V167, P1758; SCHUMACH.HR, 1972, ARTHRITIS RHEUM, V15, P465, DOI 10.1002/art.1780150502; Sebbag M, 1997, EUR J IMMUNOL, V27, P624, DOI 10.1002/eji.1830270308; Seo SK, 2004, NAT MED, V10, P1088, DOI 10.1038/nm1107; Tak PP, 1997, ARTHRITIS RHEUM, V40, P217, DOI 10.1002/art.1780400206; Visser H, 2002, ARTHRITIS RHEUM, V46, P357, DOI 10.1002/art.10117; Weyand CM, 2003, ANN NY ACAD SCI, V987, P140; Zhou LJ, 1996, P NATL ACAD SCI USA, V93, P2588, DOI 10.1073/pnas.93.6.2588; Zvaifler N J, 1973, Adv Immunol, V16, P265, DOI 10.1016/S0065-2776(08)60299-0	57	201	207	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1478-6354			ARTHRITIS RES THER	Arthritis Res. Ther.		2005	7	4					R784	R795		10.1186/ar1733		12	Rheumatology	Rheumatology	952QH	WOS:000231020100016	15987480	
S	Ma, Y; Cukic, B; Singh, H		Kanade, T; Jain, A; Ratha, NK		Ma, Y; Cukic, B; Singh, H			A classification approach to multi-biometric score fusion	AUDIO AND VIDEO BASED BIOMETRIC PERSON AUTHENTICATION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Conference on Audio- and Video-Based Biometric Person Authentication	JUL 20-22, 2005	Hilton Rye Town, NY	IAPR, IBMRes, Identix, Motorola Biometr, Springer, Proximex, TBS, Us Biometr, VideoMining			INFORMATION FUSION	The use of biometrics for identity verification of an individual is increasing in many application areas such as border/port entry/exit, access control, civil identification and network security. Multi-biometric systems use more than one biometric of an individual. These systems are known to help in reducing false match and false non-match errors compared to a single biometric device. Several algorithms have been used in literature for combining results of more than one biometric device. In this paper we discuss a novel application of random forest algorithm in combining matching scores of several biometric devices for identity verification of an individual. Application of random forest algorithm is illustrated using matching scores data on three biometric devices: fingerprint, face and hand geometry. To investigate the performance of the random forest algorithm, we conducted experiments on different subsets of the original data set. The results of all the experiments are exceptionally encouraging.	W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA; W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA	Ma, Y (reprint author), W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA.	yma@stat.wvu.edu; cukic@csee.wvu.edu; hsingh@stat.wvu.edu	Cukic, Bojan/B-8287-2009				Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, WALD LECT 2 LOOKING; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 2004, RANDOM FORESTS CLASS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Ceccarelli M, 1997, NEUROCOMPUTING, V14, P345, DOI 10.1016/S0925-2312(96)00038-0; Chen C., USING RANDOM FOREST; JAIN A, 2003, IMAGE VIDEO BASED BI; Kittler J., 1998, IEEE T PATTERN ANAL, V20; LAM L, 1997, IEEE T SYSTEMS MAN A, V27; Lee D. S., 1993, P 3 INT WORKSH FRONT, P153; LIAW A, 2004, 36 S INT BALT MARYL; LIPNICKAS A, 2001, 7 INT C INF NETW SYS; NANDAKUMAR K, SCORE NORMALIZATION; OH J, 2003, P 29 ANN NE BIOENG C; REMLINGER KS, INTRO APPL RANDOM FO; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; SNELICK R, 2003, P 5 INT C MULT INT V; Speed T, 2003, STAT ANAL GENE EXPRE; TAHANI H, 1990, IEEE T SYST MAN CYB, V20, P733, DOI 10.1109/21.57289; Tou J. T., 1981, PATTERN RECOGNITION; VERLINDE P, 1999, P 2 INT C AUD VID BA, P189; XU L, 1992, IEEE T SYSTEMS MAN C, V22; ZUEV Y, 1996, FDN INFORMATION DECI, P206	24	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-27887-7	LECT NOTES COMPUT SC			2005	3546						484	493				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCT50	WOS:000231117100050		
B	Marsolo, K; Parthasarathy, S; Ding, C			IEEE Computer Society	Marsolo, K; Parthasarathy, S; Ding, C			A multi-level approach to SCOP fold recognition	BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering			English	Proceedings Paper	5th IEEE Symposium on Bioinformatics and Bioengineering	OCT 19-21, 2005	Minneapolis, MN	IEEE Comp Soc, Biol & Artificial Intelligence Soc, Univ Minnesota, Digital Technol Ctr, Wright State Univ, ITRI, IEEE				The classification of proteins based on their structure can play an important role in the deduction or discovery of protein function. However the relatively low number of solved protein structures and the unknown relationship between structure and sequence requires an alternative method of representation for classification to be effective. Furthermore, the large number of potential folds causes problems for many classification strategies, increasing the likelihood that the classifier will reach a local optima while trying to distinguish between all of the possible structural categories. Here we present a hierarchical strategy for structural classification that first partitions proteins based on their SCOP class before attempting to assign a protein fold. Using a well-known dataset derived from the 27 most-populated SCOP folds and several sequence-based descriptor properties as input features, we test a number of classification methods, including Naive Bayes and Boosted C4.5. Our strategy achieves an average fold recognition of 74%, which is significantly higher than the 56-60% previously reported in the literature, indicating the effectiveness of a multi-level approach.	Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	Marsolo, K (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRESLOW LA, 1996, AOC96014 NCARAI; CHINNASAMY A, 2004, P PSB 2004; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Freund Y., 1996, 13 INT C MACH LEARN, P148; John G. H., 1995, 11 C UNC ART INT, P338; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; SHI SYM, 2004, P IEEE CIBCB; Tan Aik Choon, 2003, Genome Inform, V14, P206	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2476-1				2005							57	64				8	Biochemical Research Methods; Engineering, Biomedical	Biochemistry & Molecular Biology; Engineering	BDM77	WOS:000234335200008		
B	Li, JY; Liu, HQ; Li, L			IEEE Computer Society	Li, JY; Liu, HQ; Li, L			Diagnostic rules induced by an ensemble method for childhood leukemia	BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering			English	Proceedings Paper	5th IEEE Symposium on Bioinformatics and Bioengineering	OCT 19-21, 2005	Minneapolis, MN	IEEE Comp Soc, Biol & Artificial Intelligence Soc, Univ Minnesota, Digital Technol Ctr, Wright State Univ, ITRI, IEEE				We introduce a new ensemble method based on decision tree to discover significant and diversified rules for subtype classification of childhood acute lymphoblastic leukemia, a heterogeneous disease with individual subtypes differing in their response to chemotherapy. Our approach simply uses each of top-ranked features as root node to build up different trees in the ensemble. Since these trees are all generated from original training samples, rules derived by our algorithm are true and reliable. This is a characteristic of our method contrast to state-of-the-art methods such as Bagging, Boosting and Random Forest which may produce false rules. Experimental results on a large gene expression profiling data set of childhood leukemia patients demonstrate that our proposed method is not only superior to other classifiers' performance, but also can identify a small subset of genes for biomarker analysis.	Inst Infocomm Res, Singapore 119613, Singapore	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BURGE T, 1998, PHILOS PERSPECTIVES, V12, P1; Fayyad U., 1993, P 13 INT JOINT C ART, P1022; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Li J, 2003, BIOINFORMATICS S2, V19, pii93; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2476-1				2005							246	249				4	Biochemical Research Methods; Engineering, Biomedical	Biochemistry & Molecular Biology; Engineering	BDM77	WOS:000234335200033		
S	Schmidt-Heck, W; Zeilinger, K; Pless, G; Gerlach, JC; Pfaff, M; Guthke, R		Oliveira, JL; Maojo, V; MartinSanchez, F; Pereira, AS		Schmidt-Heck, W; Zeilinger, K; Pless, G; Gerlach, JC; Pfaff, M; Guthke, R			Prediction of the performance of human liver cell bioreactors by donor organ data	BIOLOGICAL AND MEDICAL DATA ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Symposium on Biological and Medical Data Analysis	NOV 10-11, 2005	Aveiro, PORTUGAL				SUPPORT	Human liver cell bioreactors are used in extracorporeal liver support therapy. To optimize bioreactor operation with respect to clinical application an early prediction of the long-term bioreactor culture performance is of interest. Data from 70 liver cell bioreactor runs labeled by low (n=18), medium (n=34) and high (n=18) performance were analyzed by statistical and machine learning methods. 25 variables characterizing donor organ properties, organ preservation, cell isolation and cell inoculation prior to bioreactor operation were analyzed with respect to their importance to bioreactor performance prediction. Results obtained were compared and assessed with respect to their robustness. The inoculated volume of liver cells was found to be the most relevant variable allowing the prediction of low versus medium/high bioreactor performance with an accuracy of 84%.	Leibniz Inst Nat Prod Res & Infect Biool, Knoell Inst, D-07745 Jena, Germany; Univ Med Berlin, Div Expt Surg, D-13353 Berlin, Germany; Univ Pittsburgh, Dept Surg, McGowan Inst Regenerat Med, Pittsburgh, PA USA; Univ Pittsburgh, Dept Bioengn, McGowan Inst Regenerat Med, Pittsburgh, PA USA; BioControl Jena GmbH, D-07745 Jena, Germany	Schmidt-Heck, W (reprint author), Leibniz Inst Nat Prod Res & Infect Biool, Knoell Inst, Beutenbergstr 11A, D-07745 Jena, Germany.	wolfgang.schmidt-heck@hki-jena.de; katrin.zeilinger@charite.de; joerg.gerlach@charite.de; michael.pfaff@biocontrol-jena.com; reinhard.guthke@hki-jena.de	Pless-Petig, Gesine/F-3639-2010				Breiman L, 2001, RANDOM FORESTS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Gerlach JC, 2001, INT J ARTIF ORGANS, V24, P793; Gerlach JC, 2003, TRANSPLANTATION, V76, P781, DOI 10.1097/01.TP.0000083319.36931.32; GERLACH JC, 1994, TRANSPLANTATION, V57, P1318, DOI 10.1097/00007890-199405150-00005; Guthke R, 1998, J BIOTECHNOL, V65, P37, DOI 10.1016/S0168-1656(98)00120-5; PFAFF M, 2004, P EUNITE 2004 S, P57; Schmidt-Heck W, 2004, LECT NOTES COMPUT SC, V3337, P427; Vapnik V., 1998, STAT LEARNING THEORY; Zeilinger K, 2004, TISSUE ENG, V10, P1113, DOI 10.1089/ten.2004.10.1113	10	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29674-3	LECT NOTES COMPUT SC			2005	3745						109	119				11	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Medical Informatics	Biochemistry & Molecular Biology; Computer Science; Medical Informatics	BDM89	WOS:000234378000012		
S	Gatnar, E		Weihs, C; Gaul, W		Gatnar, E			Dimensionality of random subspaces	Classification - the Ubiquitous Challenge	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	28th Annual Conference of the Gesellschaft-fur-Klassifikation	MAR 09-11, 2004	Dortmund, GERMANY	Gesell Klassifikat, Deutsch Forsch Gemeinsch, Dortmund-Project, Univ Dortmund, Fachbereich Statistik, NRW Beneluxstaaten, Landesbeauftragter Bezieh Zwischen Hochschulen, NOVARTIS, Roche Diagnost, sas Deutschland, Sonderforsch Bereich 475, Springer- Verlag, John Wiley & Sons	Univ Dortmund			Significant improvement of classification accuracy can be obtained by aggregation of multiple models. Proposed methods in this field are mostly based. on sampling cases from the training set, or changing weights for cases. Reduction of classification error can also be achieved by random selection of variables to the training subsamples or directly to the model. In this paper we propose a method of feature selection for ensembles that significantly reduces the dimensionality of the subspaces.	Katowice Univ Econ, Inst Stat, PL-40226 Katowice, Poland	Gatnar, E (reprint author), Katowice Univ Econ, Inst Stat, Ul Bogucicka 14, PL-40226 Katowice, Poland.						AMIT Y, 2001, MULTIPLE RANDOMIZED; Blake C. L., 1998, UCI REPOSITORY MACHI; BREIMAN L, 1999, 547 U CAL DEP STAT; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Fayyad U., 1993, P 13 INT JOINT C ART, P1022; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Hall M. A., 2000, P 17 INT C MACH LEAR; HELLWIG Z, 1969, STAT REV, P3; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; KIRA A, 1992, P 9 INT WORKSH MACH, P249; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; OZA NC, 1999, NASAARCIC1999126 COM; Press W.H., 1989, NUMERICAL RECIPES PA; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Therneau TM, 1997, INTRO RECURSIVE PART; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	22	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-25677-6	ST CLASS DAT ANAL			2005							129	136		10.1007/3-540-28084-7_12		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI52	WOS:000233600100012		
S	Rodriguez, JJ; Alonso, CJ; Prieto, OJ		Cabestany, J; Prieto, A; Sandoval, F		Rodriguez, JJ; Alonso, CJ; Prieto, OJ			Bias and variance of rotation-based ensembles	COMPUTATIONAL INTELLIGENCE AND BIOINSPIRED SYSTEMS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	8th Biennial Meeting of the International Work-Conference on Artificial Neural Networks	JUN 08-10, 2005	Vilanova, SPAIN	Univ Politecn Catalunya, Univ Granada, Univ Malaga, Spanish Minist Educ & Ciencia, City Council Vilanova				In Machine Learning, ensembles are combination of classifiers. Their objective is to improve the accuracy. In previous works, we have presented a method for the generation of ensembles, named rotation-based. It transforms the training data set; it groups, randomly, the attributes in different subgroups, and applies, for each group, an axis rotation. If the used method for the induction of the classifiers is not invariant to rotations in the data set, the generated classifiers can be very different. In this way, different classifiers can be obtained (and combined) using the same induction method. The bias-variance decomposition of the error is used to get some insight into the behaviour of a classifier. It has been used to explain the success of ensemble learning techniques. In this work the bias and variance for the presented and other ensemble methods are calculated and used for comparison purposes.	Univ Burgos, Burgos, Spain; Univ Valladolid, Dept Informat, Grp Sist Inteligentes, E-47002 Valladolid, Spain	Rodriguez, JJ (reprint author), Univ Burgos, Burgos, Spain.	jjrodriguez@ubu.es; calonso@infor.uva.es	Rodriguez, Juan/B-1014-2008	Rodriguez, Juan/0000-0002-3291-2739			Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Domingos P, 2000, 17 INT C MACH LEARN, P231; HAN J, 2001, DATA MINIGN CONCEPTS; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Kohavi R, 1996, 13 INT MACH LEARN C; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; RODRIGUEZ JJ, 2004, URRENT TOPICS ARTIFI, P498; SCHAPIRE RE, 2002, MSRI WORKSH NONLINEA; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; WEBB GI, 2004, ESTIMATING BIAS VARI; Witten I. H., 1999, DATA MINING PRACTICA	17	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26208-3	LECT NOTES COMPUT SC			2005	3512						779	786				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCO15	WOS:000230384000095		
S	Rogers, JD; Gunn, SR		Winkler, J; Niranjan, M; Lawrence, N		Rogers, JD; Gunn, SR			Ensemble algorithms for feature selection	DETERMINISTIC AND STATISTICAL METHODS IN MACHINE LEARNING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	1st International Workshop on Deterministic and Statistical Methods in Machine Learning	SEP 07-10, 2004	Sheffield, ENGLAND	Engn & Phys Sci Res Council, London Math Soc, PASCAL European Framework 6 Network Excellence, Univ Sheffield				Many feature selection algorithms are limited in that they attempt to identify relevant feature subsets by examining the features individually. This paper introduces a technique for determining feature relevance using the average information gain achieved during the construction of decision tree ensembles. The technique introduces a node complexity measure and a statistical method for updating the feature sampling distribution based upon confidence intervals to control the rate of convergence. A feature selection threshold is also derived, using the expected performance of an irrelevant feature. Experiments demonstrate the potential of these methods and illustrate the need for both feature weighting and selection.	Univ Southampton, Sch Elect & Comp Sci, Image Speech & Intelligent Syst Res Grp, Southampton SO9 5NH, Hants, England	Rogers, JD (reprint author), Univ Southampton, Sch Elect & Comp Sci, Image Speech & Intelligent Syst Res Grp, Southampton SO9 5NH, Hants, England.						Blake C. L., 1998, UCI REPOSITORY MACHI; BORISOV A, 2005, IN PRESS FEATURE EXT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Hall Mark A., 2000, 17 INT C MACH LEARN, P359; Ho T.K., 1998, LECT NOTES COMPUTER, V1451, P640; JOHN G, 1984, MACH LEARN, P121; Koller D., 1996, INT C MACH LEARN, P284; Opitz DW, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P379; ROOBAERT D, 2005, IN PRESS FEATURE EXT; SCOTT M, 1998, PARCEL FEATURE SUBSE; Yu L., 2003, MACH LEARN, P856	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29073-7	LECT NOTES ARTIF INT			2005	3635						180	198				19	Computer Science, Artificial Intelligence	Computer Science	BDF66	WOS:000233290600011		
B	Fan, W; Greengrass, E; McCloskey, J; Yu, PS; Drummey, K		Han, J; Wah, BW; Raghavan, V; Wu, X; Rastogi, R		Fan, W; Greengrass, E; McCloskey, J; Yu, PS; Drummey, K			Effective estimation of posterior probabilities: Explaining the accuracy of randomized decision tree approaches	Fifth IEEE International Conference on Data Mining, Proceedings			English	Proceedings Paper	5th IEEE International Conference on Data Mining	NOV 27-30, 2005	Houston, TX	IEEE Comp Soc, TCII, IEEE Comp Soc, TCPAMI, IBM Res, Knowledge & Informat Syst, Web Intelligence Consortium, Univ Louisiana Lafayette, Ctr Adv Comp Studies, Amer Discount ADS Inc, Univ Houston, Dept Comp Sci, Elder Res Inc				There has been increasing number of independently proposed randomization methods in different stages of decision tree construction to build multiple trees. Randomized decision tree methods have been reported to be significantly more accurate than widely-accepted single decision trees, although the training procedure of some methods incorporates a surprisingly random factor and therefore opposes the generally accepted idea of employing gain functions to choose optimum features at each node and compute a single tree that fits the data. One important question that is not well understood yet is the reason behind the high accuracy. We provide an insight based on posterior probability estimations. We first establish the relationship between effective posterior probability estimation and effective loss reduction. We argue that randomized decision tree methods effectively approximate the true probability distribution using the decision tree hypothesis space. We conduct experiments using both synthetic and real-world datasets under both 0-1 and cost-sensitive loss functions.	IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Fan, W (reprint author), IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA.						Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buntine W. L., 1992, THESIS U TECHNOLOGY; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; Dietterich T., 1998, MACH LEARN, V40, P139; Fan W, 2003, P 3 IEEE INT C DAT M; Fan W, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P336; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hoeting JA, 1999, STAT SCI, V14, P382; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; LIU FT, 2005, P 9 PAC AS KNOWL DIS; Mitchell T. M., 1997, MACHINE LEARNING; PROVOST F, 2003, MACHINE LEARNING SEP, P199; ZADRONZY B, 2002, P 8 INT C KNOWL DISC	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2278-5				2005							154	161				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDS21	WOS:000235162400020		
B	Zhang, Y; Street, WN; Burer, S		Han, J; Wah, BW; Raghavan, V; Wu, X; Rastogi, R		Zhang, Y; Street, WN; Burer, S			Sharing classifiers among ensembles from related problem domains	Fifth IEEE International Conference on Data Mining, Proceedings			English	Proceedings Paper	5th IEEE International Conference on Data Mining	NOV 27-30, 2005	Houston, TX	IEEE Comp Soc, TCII, IEEE Comp Soc, TCPAMI, IBM Res, Knowledge & Informat Syst, Web Intelligence Consortium, Univ Louisiana Lafayette, Ctr Adv Comp Studies, Amer Discount ADS Inc, Univ Houston, Dept Comp Sci, Elder Res Inc				A classification ensemble is a group of classifiers that all solve the same prediction problem in different ways. It is well-known that combining the predictions of classifiers within the same problem domain using techniques like bagging or boosting often improves the performance. This research shows that sharing classifiers among different but closely related problem domains can also be helpful. In addition, a semi-definite programming based ensemble pruning method is implemented in order to optimize the selection of a subset of classfiers for each problem domain. Computational results on a catalog dataset indicate that the ensembles resulting from sharing classifiers among different product categories generally have larger AUCs than those ensembles trained only on their own categories. The pruning algorithm not only prevents the occasional decrease of effectiveness caused by conflicting concepts among the problem domains, hut also provides a better understanding of the problem domains and their relationships.	Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA	Zhang, Y (reprint author), Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA.						Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burer S, 2003, MATH PROGRAM, V95, P329, DOI 10.1007/s10107-002-0352-8; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Caruana R, 2004, P 21 INT C MACH LEAR; Chan PK, 1999, IEEE INTELL SYST APP, V14, P67, DOI 10.1109/5254.809570; Fan W., 1999, P 5 ACM SIGKDD INT C, P362, DOI 10.1145/312129.312283; FAN W, 2004, P 9 INT C EXT DAT TE, P801; Freund Y., 1996, INT C MACH LEARN, P148; Geomans MX, 1995, J ACM, V42, P1115; HAN Q, 2002, MATH PROGRAM, P509; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Lazarevic A., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; MARGINEANTU D.D., 1997, 14 INT C MACH LEARN, P211; MCCALLUM A, AAAI WORKSH TEXT LEA; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Sharkey A. J. C., 1996, Connection Science, V8, DOI 10.1080/095400996116785; Street W., 2001, 7 ACM SIGKDD INT C K, P377; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; ZHANG Y, 2005, UNPUB ENSEMBLE PRUNI	24	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2278-5				2005							522	529				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDS21	WOS:000235162400066		
B	Zhang, Y; Street, WN		Han, J; Wah, BW; Raghavan, V; Wu, X; Rastogi, R		Zhang, Y; Street, WN			Bagging with adaptive costs	Fifth IEEE International Conference on Data Mining, Proceedings			English	Proceedings Paper	5th IEEE International Conference on Data Mining	NOV 27-30, 2005	Houston, TX	IEEE Comp Soc, TCII, IEEE Comp Soc, TCPAMI, IBM Res, Knowledge & Informat Syst, Web Intelligence Consortium, Univ Louisiana Lafayette, Ctr Adv Comp Studies, Amer Discount ADS Inc, Univ Houston, Dept Comp Sci, Elder Res Inc				Ensemble methods have proved to be highly effective in improving the performance of base learners under most circumstances. In this paper, we propose a new algorithm that combines the merits of some existing techniques, namely bagging, arcing and stacking. The basic structure of the algorithm resembles bagging, using a linear, support vector machine (SVM). However, the misclassification cost of each training point is repeatedly adjusted according to its observed out-of-bag vote margin. In this way, the method gains the advantage, of arcing - building the classifier the ensemble needs - without fixaling on potentially noisy points. Computational experiments show that this algorithm performs consistently better than bagging and arcing.	Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA	Zhang, Y (reprint author), Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA.						Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Freund Y., 1996, INT C MACH LEARN, P148; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Vapnik VN, 1995, NATURE STAT LEARNING; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2278-5				2005							825	828				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDS21	WOS:000235162400138		
B	Ma, Y; Schuckers, M; Cukic, B		Martin, DC		Ma, Y; Schuckers, M; Cukic, B			Guidelines for appropriate use of simulated data for bio-authentication research	Fourth IEEE Workshop on Automatic Identification Advanced Technologies, Proceedings			English	Proceedings Paper	4th IEEE Workshop on Automatic Identification Advanced Technologies	OCT 17-18, 2005	Buffalo, NY	IEEE, Univ Buffalo, Ctr Unified Biometr & Sensors, Ultra-Scan, CUBRC				In this paper, we outline a framework for appropriate and proper usage of simulated data for biometric authentication research. Currently, there are no formal guidelines concerning the use of simulated data in the biometric authentication literature. Some have suggested the usage of simulated or synthetic data while others have advised against it. Our position is that there is a place for simulation data in biometrics research but that such implementations need to meet certain requirements. To that end we describe conditions under which it is reasonable to use such data, as well as criteria for evaluating the appropriateness of a data generation methodology. This criteria is that models for generation of artificial data should be flexible, consistent and parsimonious. Along with justifying these criteria, we illustrate how simulated data might be used to evaluate a classifier.	W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA	Ma, Y (reprint author), W Virginia Univ, Dept Stat, Morgantown, WV 26506 USA.						Adler A., 2004, Canadian Conference on Electrical and Computer Engineering 2004 (IEEE Cat. No.04CH37513), DOI 10.1109/CCECE.2004.1345057; BOLLE RM, 2000, P INT C PATT REC ICP, V2; BREIMAN L, WALD LECT, pR2; Breiman L., RANDOM FORESTS CLASS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cappelli R., 2003, P 2003 ACM SIGMM WOR, P95, DOI 10.1145/982507.982525; CUI J, 2004, INT C PATT REC; Daugman J, 2003, PATTERN RECOGN, V36, P279; GENTLER JE, 2003, RANDOM NUMBER GENERA; JACK PC, P 1999 WINT SIM C; Liu J.S., 2001, MONTE CARLO STRATEGI; Orlans N.M., 2004, P INT C ART INT, P499; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; ROSS A, 2005, P SPIE C BIOM TECHN, P68; Ross S., 2002, SIMULATION; SCHUCKERS ME, 2004, COMP STAT METHODS EV, P144; SCHUCKERS ME, 2003, P AM STAT ASS BIOM S; Wackerly D. D., 2002, MATH STAT APPL; WEIN LM, 2005, P NAT AC SCI, V102; YANUSHKEVICH SN, SIMULATION BIOMETRIC	20	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2475-3				2005							251	256				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BDM79	WOS:000234337500042		
S	Dutta, H; Kargupta, H; Joshi, A		Bader, DA; Parashar, M; Sridhar, V; Prasanna, VK		Dutta, H; Kargupta, H; Joshi, A			Orthogonal decision trees for resource-constrained physiological data stream monitoring using mobile devices	HIGH PERFORMANCE COMPUTING - HIPC 2005, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	12th International Conference on High Performance Computing (HiPC 2005)	DEC 18-21, 2005	Goa, INDIA					This paper considers the problem of monitoring physiological data streams obtained from resource-constrained wearable sensing devices for pervasive health-care management. It considers Orthogonal decision trees (ODTs) that offer an effective way to construct a redundancy-free, accurate, and meaningful representation of large decision-tree-ensembles often created by popular techniques such as Bagging, Boosting, Random Forests and many distributed and data stream mining algorithms. ODTs are functionally orthogonal to each other and they correspond to the principal components of the underlying function space. This paper offers experimental results to document the performance of ODTs on grounds of accuracy, model complexity, and resource consumption.	Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA	Dutta, H (reprint author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, 1000 Hilltop Circle, Baltimore, MD 21250 USA.	jhdutta1@cs.umbc.edu; hillol@cs.umbc.edu; joshi@cs.umbc.edu					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Drucker H, 1996, ADV NEUR IN, V8, P479; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Kargupta H., 2002, IEEE T KNOWL DATA EN, V16, P216; Kargupta H, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P427, DOI 10.1109/ICDM.2004.10072; Kostov Y, 2000, REV SCI INSTRUM, V71, P4361, DOI 10.1063/1.1319859; LINIAL N, 1993, J ACM, V40, P607, DOI 10.1145/174130.174138; Merz CJ, 1999, MACH LEARN, V36, P9, DOI 10.1023/A:1007507221352; Park B.H., 2002, P 7 WORKSH RES ISS D, P18; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; STREET WN, 2001, P ACM SIGKDD INT C K; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30936-5	LECT NOTES COMPUT SC			2005	3769						118	127				10	Computer Science, Theory & Methods	Computer Science	BDW21	WOS:000235801700016		
B	Joelsson, SR; Benediktsson, JA; Sveinsson, JR			IEEE	Joelsson, SR; Benediktsson, JA; Sveinsson, JR			Random forest classifiers for hyperspectral data	IGARSS 2005: IEEE International Geoscience and Remote Sensing Symposium, Vols 1-8, Proceedings	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	25th IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2005)	JUL 25-29, 2005	Seoul, SOUTH KOREA	IEEE, IEEE Geosci & Remote Sensing Soc, NASA, NOAA, USN Off Res, Japan Aerosp Explorat Agcy, Natl Polar orbiting Operat Environm Satellite Syst, Ball Aerosp & Technologies Corp, Int Union Radio Sci, Elect & Telecommun Res Inst, Korea Sci & Engn Fdn, Korea Natl Tourism Org, Korea Telecommun				Two random forest (RF) approaches are explored; the RF-BHC (Binary Hierarchical Classifier) and the RF-CART (Classification and Regression Tree). Both methods are based on a collection (forest) of tree-like classifier systems where the difference is in the way the trees are grown. The BHC approach depends on class separability measures and the Fisher projection, which maximizes the Fisher discriminant where each tree is a class hierarchy, and the number of leaves is the same as the number of classes. The CART approach is based on CART-like trees where trees are grown to minimize an impurity measure. Here, these different RF approaches are compared in experiments. The RF approaches were investigated in experiments by classification of an urban area from Pavia, Italy using hyperspectral ROSIS (Reflective Optics System Imaging Spectrometer) data provided by MR.	Univ Iceland, Dept Elect & Comp Engn, IS-107 Reykjavik, Iceland	Joelsson, SR (reprint author), Univ Iceland, Dept Elect & Comp Engn, Hjardarhaga 2-6, IS-107 Reykjavik, Iceland.		Benediktsson, Jon/F-2861-2010				Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; FREUND Y, 1996, MACHINE LEARNING P 1; Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; Landgrebe D. A., 2003, SIGNAL THEORY METHOD	7	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9050-4	INT GEOSCI REMOTE SE			2005							160	163				4	Geosciences, Multidisciplinary; Remote Sensing	Geology; Remote Sensing	BEG75	WOS:000237237600042		
S	Uwents, W; Blockeel, H		Kramer, S; Pfahringer, B		Uwents, W; Blockeel, H			Classifying relational data with neural networks	INDUCTIVE LOGIC PROGRAMMING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	15th International Conference on Inductive Logic Programming (ILP 2005)	AUG 10-13, 2005	Bonn, GERMANY	Gesell Informat, Bioinformat Initiat Munich, TU Munich, PASCAL European Network Excellence, Machine Learning Journal				We introduce a novel method for relational learning with neural networks. The contributions of this paper are threefold. First, we introduce the concept of relational neural networks: feedforward networks with some recurrent components, the structure of which is determined by the relational database schema. For classifying a single tuple, they take as inputs the attribute values of not only the tuple itself, but also of sets of related tuples. We discuss several possible architectures for such networks. Second, we relate the expressiveness of these networks to the 'aggregation vs. selection' dichotomy in current relational learners, and argue that relational neural networks can learn non-trivial combinations of aggregation and selection, a task beyond the capabilities of most current relational learners. Third, we present and motivate different possible training strategies for such networks. We present experimental results on synthetic and benchmark data sets that support our claims and yield insight in the behaviour of the proposed training strategies.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium	Uwents, W (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Louvain, Belgium.	werner.uwents@cs.kuleuven.be; hendrik.blockeel@cs.kuleuven.be					BASILIO R, 2001, LECT NOTES ARTIFICIA; BLOCKEEL H, 2003, IJCAI 2003 WORKSH LE; BOTTA M, 1997, P 14 INT C MACH LEAR, P46; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; De Raedt L., 1998, LECT NOTES ARTIF INT, V1446, P1; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Dzeroski S, 1998, APPL ARTIF INTELL, V12, P363, DOI 10.1080/088395198117686; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; GOLLER C, 1996, P IEEE INT C NEUR NE, P347; Jordan M. I., 1986, P 8 ANN C COGN SCI S, P531; Knobbe A. J., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); KROGEL MA, 2003, P WORK PROGR TRACK 1, P30; Krogel M.-A., 2001, P 11 INT C IND LOG P, P142; MERZ CJ, 1996, UCI RESPOSITORY MACH; MICHIE D, 1994, INT COMPUTER COMMUNI; Perlich Claudia, 2003, P 9 ACM SIGKDD INT C, P167; RAMON J, 2000, P ICML WORKSH ATTR V; Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108; SRINIVASAN A, 1990, P 9 INT WORKSH IND L, P291; VENS C, 2004, P 14 INT C IND LOG P, P323; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337	21	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28177-0	LECT NOTES ARTIF INT			2005	3625						384	396				13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDF31	WOS:000233222900023		
S	Gatnar, E		Baier, D; Wernecke, KD		Gatnar, E			Randomization in aggregated classification trees	INNOVATIONS IN CLASSIFICATION, DATA SCIENCE, AND INFORMATION SYSTEMS	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	27th Annual Conference of the German-Classification-Society	MAR 12-14, 2003	Cottbus, GERMANY	German Classificat Soc, Brandenburg Univ Technol, Chair Marketing & Innovat Management, Holiday Inn Hotel, MTU, Maintenance Berlin-Brandenburg GmbH, Scicon Sci Consulting GmbH, Sparkasse Spree-Neibe, Synergy Microwave Europe GmbH & Co KG, Volkswagen AG, Wolfsburg, Producers Scottish Single Malt Whisky	Brandenburg Univ Technol			Tree-based models are popular and widely used because they are simple, flexible and powerful tools for classification. Unfortunately they are not stable classifiers. Significant improvement of model stability and prediction accuracy can be obtained by aggregation of multiple classification trees.-The reduction of classification error is a result of decreasing bias or/and variance of the committee of trees (called also an ensemble or a forest). In this paper we discuss and compare different methods for model aggregation. We also address the problem of finding minimal number of trees sufficient for the forest.	Katowice Univ Econ, Inst Stat, PL-40226 Katowice, Poland							AMIT Y, 2001, MULTIPLE RANDOMIZED; Blake C. L., 1998, UCI REPOSITORY MACHI; BREIMAN L, 2002, WALD LECT MACHINE LE; BREIMAN L, 1999, 547 U CAL DEP STAT B; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L., 1996, BIAS VARIANCE ARCING, V460; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARTER C, 1987, IEEE EXPERT      FAL, P71; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 1995, MACHINE LEARNING BIA; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 1999, STOCHASTIC GRADIENT; FRIEDMAN JH, 1996, BIAS VARIANCE O1LOSS; GATNAR E, 2002, CLASSIFICATION CLUST, P399; HASTIE T, 1991, SKRINKING TREES; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; JIANG W, 2000, 0005 IEEE T PATT AN; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; KOHAVI R, 1996, P 13 INT C MACH LEAR, P313; LATINNE P, 2001, LNCS, V2096, P178; LUGOSI G, 2002, STAT STUDY REGLULARI; Quinlan J. R., 1993, C4 5 PROGR MACHINE L; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tukey J., 1977, EXPLORATORY DATA ANA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	27	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-23221-4	ST CLASS DAT ANAL			2005							207	216		10.1007/3-540-26981-9_25		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Economics; Medical Informatics; Statistics & Probability	Computer Science; Business & Economics; Medical Informatics; Mathematics	BBN27	WOS:000226261800025		
J	Hall, P; Samworth, RJ				Hall, P; Samworth, RJ			Properties of bagged nearest neighbour classifiers	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Bayes risk; bootstrap; classification error; cross-validation; density; discrimination; error rate; marked point process; Poisson process; prediction; regret; statistical learning; without-replacement sampling; with-replacement sampling	CROSS-VALIDATION; DENSITY-ESTIMATION; SAMPLE-SIZE; CLASSIFICATION; ERROR; DISCRIMINATION; REGRESSION; RULE	It is shown that bagging, a computationally intensive method, asymptotically improves the performance of nearest neighbour classifiers provided that the resample size is less than 69% of the actual sample size, in the case of with-replacement bagging, or less than 50% of the sample size, for without-replacement bagging. However, for larger sampling fractions there is no asymptotic difference between the risk of the regular nearest neighbour classifier and its bagged version. In particular, neither achieves the large sample performance of the Bayes classifier. In contrast, when the sampling fractions converge to 0, but the resample sizes diverge to infinity, the bagged classifier converges to the optimal Bayes rule and its risk converges to the risk of the latter. These results are most readily seen when the two populations have well-defined densities, but they may also be derived in other cases, where densities exist in only a relative sense. Cross-validation can be used effectively to choose the sampling fraction. Numerical calculation is used to illustrate these theoretical properties.	Univ Cambridge, Ctr Math Sci, Stat Lab, Cambridge CB3 0WB, England; Australian Natl Univ, Canberra, ACT, Australia	Samworth, RJ (reprint author), Univ Cambridge, Ctr Math Sci, Stat Lab, Wilberforce Rd, Cambridge CB3 0WB, England.	r.j.samworth@statslab.cam.ac.uk					Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Bickel PJ, 1997, STAT SINICA, V7, P1; BREIMAN L, 1999, 547 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buhlmann P, 2002, ANN STAT, V30, P927; BUJA A, 2000, UNPUB EFFECT BAGGING; BUJA A, 2000, UNPUB SMOOTHING EFFE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cover T. M., 1968, P HAW INT C SYST SCI, P413; Daley DJ, 1988, INTRO THEORY POINT P; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; Devroye L., 1996, PROBABILISTIC THEORY, V31; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Fix E., 1951, 4 US AIR FORC SCH AV; FRANCOIS J, 2001, INFORMATION PROCESSI, V1, P111; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 2000, UNPUB BAGGING NONLIN; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; GUERRASALCEDO C, 1999, P GEN EV COMP C, V1, P236; HALL P, 1989, STAT PROBABIL LETT, V8, P109, DOI 10.1016/0167-7152(89)90002-3; Hand DJ, 1981, DISCRIMINATION CLASS; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HO TK, 1998, P 14 INT C PATT REC, P545; Jiang WX, 2002, ANN STAT, V30, P51, DOI 10.1214/aos/1015362184; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; KUNCHEVA LI, 2002, INFORM FUSION, P245; Larkey Leah S., 1996, P SIGIR 96 19 ACM IN, P289, DOI 10.1145/243199.243276; Lugosi G, 1996, ANN STAT, V24, P687; Mammen E., 1992, LECT NOTES STAT, V77; MARRON JS, 1983, ANN STAT, V11, P1142; MIELNICZUK J, 1989, J STAT PLAN INFER, V23, P53, DOI 10.1016/0378-3758(89)90039-6; MOLLINEDA RA, 2000, P 4 WRLD MULT SYST C, V7, P640; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Schapire RE, 1998, ANN STAT, V26, P1651; Skurichina M, 2002, LECT NOTES COMPUT SC, V2364, P62; Skurichina M, 1998, PATTERN RECOGN, V31, P909, DOI 10.1016/S0031-3203(97)00110-6; Steele BM, 2000, STAT COMPUT, V10, P349, DOI 10.1023/A:1008933626919; STOLLER DS, 1954, J AM STAT ASSOC, V49, P770, DOI 10.2307/2281538; Yang JH, 1999, ORG LETT, V1, P11, DOI 10.1021/ol9900010; ZEMKE S, 1997, P ART NEUR NETW ENG, P1067	46	17	17	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2005	67		3				363	379		10.1111/j.1467-9868.2005.00506.x		17	Statistics & Probability	Mathematics	937CQ	WOS:000229902600003		
S	Wang, HX; Pei, J		Jorge, A; Torgo, L; Brazdil, P; Camacho, R; Gama, J		Wang, HX; Pei, J			A random method for quantifying changing distributions in data streams	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2005	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD				In applications such as fraud and intrusion detection, it is of great interest to measure the evolving trends in the data. We consider the problem of quantifying changes between two datasets with class labels. Traditionally, changes are often measured by first estimating the probability distributions of the given data, and then computing the distance, for instance, the K-L divergence, between the estimated distributions. However, this approach is computationally infeasible for large, high dimensional datasets. The problem becomes more challenging in the streaming data environment, as the high speed makes it difficult for the learning process to keep up with the concept drifts in the data. To tackle this problem, we propose a method to quantify concept drifts using a universal model that incurs minimal learning cost. In addition, our model also provides the ability of performing classification.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada	Wang, HX (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	haixun@us.ibm.com; jpei@cs.sfu.ca					AGGARWAL CC, 2003, SIGMOD; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRIN S, 1995, VLDB; Cover T. M., 1991, ELEMENTS INFORMATION; Freund Y., 1996, INT C MACH LEARN, P148; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hulten G., 2001, SIGKDD, P97; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Ma J., 2003, SIGKDD; OLIVER MA, 1990, INT J GEOGRAPHIC SYS, P4; Turner K., 1996, CONNECT SCI, V8, P385; WANG H, 2003, SIGKDD	13	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29244-6	LECT NOTES ARTIF INT			2005	3721						684	691				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDF43	WOS:000233235600073		
S	Scholz, M		Morik, K; Boulicaut, JF; Siebes, A		Scholz, M			Knowledge-based sampling for subgroup discovery	LOCAL PATTERN DETECTION	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	International Seminar on Local Pattern Detection	APR 12-16, 2004	Dagstuhl, GERMANY					Subgroup discovery aims at finding interesting subsets of a classified example set that deviates from the overall distribution. The search is guided by a so-called utility function, trading the size of subsets (coverage) against their statistical unusualness. By choosing the utility function accordingly, subgroup discovery is well suited to find interesting rules with much smaller coverage and bias than possible with standard classifier induction algorithms. Smaller subsets can be considered local patterns, but this work uses yet another definition: According to this definition global patterns consist of all patterns reflecting the prior knowledge available to a learner, including all previously found patterns. All further unexpected regularities in the data are referred to as local patterns. To address local pattern mining in this scenario, an extension of subgroup discovery by the knowledge-based sampling approach to iterative model refinement is presented. It is a general, cheap way of incorporating prior probabilistic knowledge in arbitrary form into Data Mining algorithms addressing supervised learning tasks.	Univ Dortmund, Dept Comp Sci, Artificial Intelligence Grp, D-4600 Dortmund, Germany	Scholz, M (reprint author), Univ Dortmund, Dept Comp Sci, Artificial Intelligence Grp, D-4600 Dortmund, Germany.	scholz@ls8.cs.uni-dortmund.de					Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brin S., 1997, P ACM SIGMOD INT C M, P255, DOI 10.1145/253260.253325; FAWCETT T, 2004, UNPUB MACHINE LEARNI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRIEDMAN JH, 2000, ANN STAT, P337; Furnkranz J., 2003, P 20 INT C MACH LEAR; HAND D, 2002, PATTERN DETECTION DI; John G.H., 1995, P 11 C UNC ART INT, P338; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, V1st, P249; LAVRAC N, 2002, 2 INT WORKSH INT COL; LAVRAC N, 1999, 9 INT WORKSH IND LOG; LAVRAC N, 2002, 12 INT C IND LOG PRO; Mackay DJC, 1998, NATO ADV SCI I D-BEH, V89, P175; MIERSWA I, 2003, LLWA 03 TAG GI WORKS; Mitchell T. M., 1997, MACHINE LEARNING; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHEFFER T, 2000, P INT C KNOWL DISC D; Scheffer Tobias, 2002, J MACHINE LEARNING R, V3, P833; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; SUZUKI E, 2004, ECML PKDD 2004 WORKS; Witten I., 2000, DATA MINING PRACTICA; Wrobel S, 1997, LECT NOTES ARTIF INT, V1263, P78; ZADROZNY B, 2003, P 2003 IEEE INT C DA	25	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26543-0	LECT NOTES ARTIF INT			2005	3539						171	189		10.1007/11504245_11		19	Computer Science, Artificial Intelligence	Computer Science	BCT64	WOS:000231145200011		
S	Szepannek, G; Luebke, K; Weihs, C		Perner, P; Imilya, A		Szepannek, G; Luebke, K; Weihs, C			Understanding patterns with different subspace classification	MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINDS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Data Minining in Pattern Recognition	JUL 09-11, 2005	Leipzig, GERMANY					By identifying characteristic regions in which classes are dense and also relevant for discrimination a new, intuitive classification method is set up. This method enables a visualized result so the user is provided with an insight into the data with respect to discrimination for an easy interpretation. Additionally, it outperforms Decision trees in a lot of situations and is robust against outliers and missing values.	Univ Dortmund, Dept Stat, Dortmund, Germany	Szepannek, G (reprint author), Univ Dortmund, Dept Stat, Dortmund, Germany.	szepannek@statistik.uni-dortmund.de					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; FREEDMAN D, 1981, Z WAHRSCHEINLICHKEIT, V57, P453, DOI 10.1007/BF01025868; Hastie T., 2001, ELEMENTS STAT LEARNI	5	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26923-1	LECT NOTES ARTIF INT			2005	3587						110	119				10	Computer Science, Artificial Intelligence	Computer Science	BCR27	WOS:000230895100012		
S	Kotsiantis, SB; Tsekouras, GE; Pintelas, PE		Perner, P; Imilya, A		Kotsiantis, SB; Tsekouras, GE; Pintelas, PE			Bagging random trees for estimation of tissue softness	MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINDS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Data Minining in Pattern Recognition	JUL 09-11, 2005	Leipzig, GERMANY				CLASSIFICATION	We present an ensemble of classifiers that can be used to predict quality characteristics of an important process in pulp and paper industry: the tissue softness estimation. This classification problem is a difficult one since, with respect to our data set, the accuracy of all the well-known classifiers is below 68%. Contrary to that, the bagging random trees ensemble model is able to increase the accuracy up to 75%.	Univ Patras, Dept Math, Educ Software Dev Lab, GR-26110 Patras, Greece; Univ Aegean, Dept Cultural Technol & Commun, Mitilini, Greece	Kotsiantis, SB (reprint author), Univ Patras, Dept Math, Educ Software Dev Lab, GR-26110 Patras, Greece.	sotos@math.upatras.gr; gtsek@ct.aegean.gr; pintelas@math.upatras.gr	kotsiantis, sotiris/C-5640-2009; Tsekouras, George/	kotsiantis, sotiris/0000-0002-2247-3082; Tsekouras, George/0000-0001-7006-1536			Aha D. W., 1997, LAZY LEARNING; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burges C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; CORBOY WG, 1991, PULP PAPER MANUFACTU, V7; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Freund Y, P ICML 96, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; LANDWEHR N, 2003, 14 EUR C MACH LEARN, P241; Melville P., 2003, P 18 INT JOINT C ART, P505; Mitchell T. M., 1997, MACHINE LEARNING; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; PLATT J, 1999, ADV NEURAL INFORMATI, V11; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Tsekouras G, 2002, COMPUT CHEM ENG, V26, P429, DOI 10.1016/S0098-1354(01)00762-1; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Witten I., 2000, DATA MINING PRACTICA	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26923-1	LECT NOTES ARTIF INT			2005	3587						674	681				8	Computer Science, Artificial Intelligence	Computer Science	BCR27	WOS:000230895100067		
S	Torkkola, K; Tuv, E		Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Torkkola, K; Tuv, E			Ensemble learning with supervised kernels	MACHINE LEARNING: ECML 2005, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD			NONORTHOGONAL PROBLEMS; RIDGE REGRESSION	Kernel-based methods have outstanding performance on many machine learning and pattern recognition tasks. However, they are sensitive to kernel selection, they may have low tolerance to noise, and they can not deal with mixed-type or missing data. We propose to derive a novel kernel from an ensemble of decision trees. This leads to kernel methods that naturally handle noisy and heterogeneous data with potentially non-randomly missing values. We demonstrate excellent performance of regularized least square learners based on such kernels.	Motorola Inc, Intelligent Syst Lab, Tempe, AZ USA; Intel Corp, Anal & Control Technol, Chandler, AZ 85226 USA	Torkkola, K (reprint author), Motorola Inc, Intelligent Syst Lab, Tempe, AZ USA.	Kari.Torkkola@motorola.com; eugene.tuv@intel.com					Bauer E., 1999, MACH LEARN, V36, P525; BOUSQUET O, 2000, NIPS, P196; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cristianini N., 2001, P NEUR INF PROC SYST, P367; CUCKER F, 2001, B AM MATH SOC, V89, P1; CUCKER F, 2003, FDN COMPUTATIONAL MA, V2, P413; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; FREUND Y, 1996, P 13 ICML; Friedman J, 1999, STOCHASTIC GRADIENT; Friedman J. H., 1999, GREEDY FUNCTION APPR; GUYON I, 2005, ADV NEURAL INF PROCE, V17; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HOERL AE, 1970, TECHNOMETRICS, V12, P55; HOERL AE, 1970, TECHNOMETRICS, V12, P69, DOI 10.2307/1267352; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; MUKHERJEE S, 2002, 2002024 MIT AI; POGGIO T, 2002, 2002003 MIT AI; Poggio T., 2003, NOTICES AMS, V50, P537; Poggio T, 2004, NATURE, V428, P419, DOI 10.1038/nature02341; Rifkin R., 2002, THESIS MIT; Scholkopf B, 2002, LEARNING KERNELS; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Valentini G, 2003, P 20 INT C MACH LEAR, P752	25	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29243-8	LECT NOTES ARTIF INT			2005	3720						400	411				12	Computer Science, Artificial Intelligence	Computer Science	BDF41	WOS:000233235200039		
J	Markowetz, F; Spang, R				Markowetz, F; Spang, R			Molecular diagnosis - Classification, model selection and performance evaluation	METHODS OF INFORMATION IN MEDICINE			English	Article						microarrays; statistical classification; generalization error; model assessment; gene selection	GENE-EXPRESSION DATA; SHRUNKEN CENTROIDS; BREAST-CANCER; PREDICTION; VALIDATION; REGRESSION; DISCOVERY; LEUKEMIA	Objectives. We discuss supervised classification techniques applied to medical diagnosis based on gene expression profiles. Our focus lies on strategies of adaptive model selection to avoid overfitting in high-dimensional spaces. Methods: We introduce likelihood-based methods, classification trees, support vector machines and regularized binary regression. For regularization by dimension reduction, we describe feature selection methods: feature filtering, feature shrinkage and wrapper approaches. In small sample-size situations efficient methods of data re-use are needed to assess the predictive power of a model. We discuss two issues in using cross-validation: the difference between in-loop and out-of-loop feature selection, and estimating model parameters in nested-loop cross-validation. Results: Gene selection does not reduce the dimensionality of the model. Tuning parameters enable adaptive model selection. The feature selection bias is a common pitfall in performance evaluation. Model selection and performance evaluation can be combined by nested-loop cross-validation. Conclusions. Classification of microarrays is prone to overfitting. A rigorous and unbiased assessment of the predictive power of the model is a must.	Max Planck Inst Mol Genet, Computat Diagnost Grp, D-14195 Berlin, Germany	Markowetz, F (reprint author), Max Planck Inst Mol Genet, Computat Diagnost Grp, Ihnestr 63-73, D-14195 Berlin, Germany.	florian.markowetz@molgen.mpg.de					Altman DG, 2000, STAT MED, V19, P453, DOI 10.1002/(SICI)1097-0258(20000229)19:4<453::AID-SIM350>3.3.CO;2-X; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cheok MH, 2003, NAT GENET, V34, P85, DOI 10.1038/ng1151; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eilers PHC, 2001, P SOC PHOTO-OPT INS, V2, P187; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gelman A., 2003, BAYESIAN DATA ANAL; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Hastie T., 2001, ELEMENTS STAT LEARNI; Hochreiter S., 2004, KERNEL METHODS COMPU; Huang E, 2003, RECENT PROG HORM RES, V58, P55, DOI 10.1210/rp.58.1.55; Jager J., 2003, P PAC S BIOC, P53; Johnson V. E., 1999, ORDINAL DATA MODELIN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krishnapuram B., 2004, KERNEL METHODS COMPU; R Development Core Team, 2004, R LANG ENV STAT COMP; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ransohoff DF, 2004, NAT REV CANCER, V4, P309, DOI 10.1038/nrc1322; Ripley B. D., 1996, PATTERN RECOGNITION; ROTH V, 2004, IEEE T NEURAL NETWOR, V15; Scholkopf B., 2001, LEARNING KERNELS; SIMON R, 2003, J NATL CANC I, V95; Spang Rainer, 2002, In Silico Biology, V2, P369; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	39	31	31	SCHATTAUER GMBH-VERLAG MEDIZIN NATURWISSENSCHAFTEN	STUTTGART	HOLDERLINSTRASSE 3, D-70174 STUTTGART, GERMANY	0026-1270			METHOD INFORM MED	Methods Inf. Med.		2005	44	3					438	443				6	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	948RY	WOS:000230734600015	16113770	
S	Banfield, RE; Hall, LO; Bowyer, KW; Kegelmeyer, WP		Oza, NC; Polikar, R; Kittler, J; Roli, F		Banfield, RE; Hall, LO; Bowyer, KW; Kegelmeyer, WP			Ensembles of classifiers from spatially disjoint data	MULTIPLE CLASSIFIER SYSTEMS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Intenational Workshop on Multiple Classifier Systems	JUN 13-15, 2005	Seaside, CA	NASA Ames Res Ctr, Intelligent Syst Div, Rowan Univ, Dept Elect & Comp Engn, Puresence Environm, Int Assoc Pattern Recognit, IAPR Tech Comm TC1				We describe an ensemble learning approach that accurately learns from data that has been partitioned according to the arbitrary spatial requirements of a large-scale simulation wherein classifiers may be trained only on the data local to a given partition. As a result, the class statistics can vary from partition to partition; some classes may even be missing from some partitions. In order to learn from such data, we combine a fast ensemble learning algorithm with Bayesian decision theory to generate an accurate predictive model of the simulation data. Results from a simulation of an impactor bar crushing a storage canister and from region recognition in face images show that regions of interest are successfully identified.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA; Sandia Natl Labs, Biosyst Res Dept, Livermore, CA 94551 USA	Banfield, RE (reprint author), Univ S Florida, Dept Comp Sci & Engn, ENB118,4202 E Fowler Ave, Tampa, FL 33620 USA.	rbanfiel@csee.usf.edu; hall@csee.usf.edu; kwb@cse.nd.edu; wpk@ca.sandia.gov	Bowyer, Kevin/	Bowyer, Kevin/0000-0002-7562-4390			BANFIELD RE, 2004, 5 INT C MULT CLASS S; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chawla N., 2003, WORKSH LEARN IMB DAT; Chawla NV, 2003, PATTERN RECOGN LETT, V24, P455, DOI 10.1016/S0167-8655(02)00269-6; CUSSENS J, 1993, P EUR C MACH LEARN; HALL LO, 2004, 2004 IEEE INT C SYST; LEE BS, 2001, P INT C DAT SYST ADV; *LOS AL NAT LAB, NAT NUCL SEC ADM COL; MUHLBAIER M, 2004, 5 INT C MULT CLASS S; ZADROZNY B, 2001, P 7 C KNOWL DISC DAT; FACIAL RECOGNITION T, P403	11	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26306-3	LECT NOTES COMPUT SC			2005	3541						196	205				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN51	WOS:000230171500020		
S	Chen, L; Kamel, MS		Oza, NC; Polikar, R; Kittler, J; Roli, F		Chen, L; Kamel, MS			Design of multiple classifier systems for time series data	MULTIPLE CLASSIFIER SYSTEMS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Intenational Workshop on Multiple Classifier Systems	JUN 13-15, 2005	Seaside, CA	NASA Ames Res Ctr, Intelligent Syst Div, Rowan Univ, Dept Elect & Comp Engn, Puresence Environm, Int Assoc Pattern Recognit, IAPR Tech Comm TC1				In previous work, we showed that the use of Multiple Input Representation(MIR) for the classification of time series data provides complementary information that leads to better accuracy. [4]. In this paper, we introduce the Static Minimization-Maximization approach to build Multiple Classifier Systems(MCSs) using MIR. SMM consists of two steps. In the minimization step, a greedy algorithm is employed to iteratively select the classifiers from the knowledge space to minimize the training error of MCSs. In the maximization step, a modified version of Behavior Knowledge Space(BKS), Balanced Behavior Knowledge Space(BBKS), is used to maximize the expected accuracy of the whole system given that the training error is minimized. Several popular techniques including AdaBoost, Bagging and Random Subspace are used as the benchmark to evaluate the proposed approach on four time series data sets. The results obtained from our experiments show that the performance of the proposed approach is effective as well as robust for the classification of time series data. In addition, this approach could be further extended to other applications in our future research.	Univ Waterloo, Pattern Anal & Machine Intelligence Lab, Waterloo, ON N2L 3G1, Canada	Chen, L (reprint author), Univ Waterloo, Pattern Anal & Machine Intelligence Lab, Waterloo, ON N2L 3G1, Canada.		Kamel, Mohamed/D-9323-2011; Kamel, Mohamed/	Kamel, Mohamed/0000-0001-6173-8082			Breiman L., 1993, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen L, 2004, LECT NOTES COMPUT SC, V3077, P134; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Diez JJR, 2000, LECT NOTES COMPUT SC, V1857, P210; Duda R., 2000, PATTERN CLASSIFICATI; GHOSH J, 1992, IEEE J OCEANIC ENG, V17, P351, DOI 10.1109/48.180304; GHOSH J, 1992, SPIE P, V1706, P266; GIANCINTO G, 2001, PATTERN RECOGN, V34, P1879; GONZALEZ CJA, 2000, REV IBEROAMERICANA I, V11, P2; Hastie T., 2001, ELEMENTS STAT LEARNI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HSU WH, 1999, P INT JOINT C NEUR N, V3, P1574; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; Saito N, 1994, THESIS YALE U; SANCHO Q, 2001, ARTIFICIAL NEURAL NE, P43	17	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26306-3	LECT NOTES COMPUT SC			2005	3541						216	225				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN51	WOS:000230171500022		
S	Bonissone, P; Eklund, N; Goebel, K		Oza, NC; Polikar, R; Kittler, J; Roli, F		Bonissone, P; Eklund, N; Goebel, K			Using an ensemble of classifiers to audit a production classifier	MULTIPLE CLASSIFIER SYSTEMS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Intenational Workshop on Multiple Classifier Systems	JUN 13-15, 2005	Seaside, CA	NASA Ames Res Ctr, Intelligent Syst Div, Rowan Univ, Dept Elect & Comp Engn, Puresence Environm, Int Assoc Pattern Recognit, IAPR Tech Comm TC1			SYSTEMS	After deploying a classifier in production it is essential to support its lifecycle. This paper describes the application of an ensemble of classifiers to support two stages of the lifecycle of an on-line classifier used to underwrite life insurance applications: the monitoring of its decisions quality and the updating of the production classifier over time. All combinations of five classification methods and seven fusion methods were assessed from the perspective of accuracy and pairwise diversity of the classifiers, and accuracy, precision, and coverage of the fused classifiers. The proposed architecture consists of three off-line classifiers and a fusion module.	GE Global Res, Niskayuna, NY 12309 USA	Bonissone, P (reprint author), GE Global Res, 1 Res Circle, Niskayuna, NY 12309 USA.	bonissone@research.ge.com; eklund@research.ge.com; goebelk@research.ge.com					AGGOUR K, 2003, 5 INT C CAS BAS REAS, P5; BONISSONE P, 2002, IEEE INT C FUZZ SYST; BONISSONE P, 2001, IEEE INT C FUZZ SYST, P995; Bonissone PP, 2003, NAFIPS'2003: 22ND INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS PROCEEDINGS, P488; Bonissone P., 2004, P 2004 MULT SYST MCS, P154; BONISSONE P, 2004, P IPMU 2004 PER IT, P3096; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Freiberg K, 2001, BRIT J DEV PSYCHOL, V19, P1, DOI 10.1348/026151001165903; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; HUANG Y, 1995, T IEEE PATTERN ANAL, V17, P90; Kuncheva L. I., 2001, P IEE WORKSH INT SEN; Kuncheva LI, 2002, IEEE T SYST MAN CY B, V32, P146, DOI 10.1109/3477.990871; Langley P., 1992, P 10 NAT C ART INT, P223; NIYOGI P, 2001, DECORRELATING CLASSI; Partridge D, 1996, NEURAL COMPUT, V8, P869, DOI 10.1162/neco.1996.8.4.869; PATTERSON A, 2005, IN PRESS J QUALITY R; PETRAKOS M, 2000, P IEEE 2000 INT GEOS; Roli F., 2001, LNCS, V2096, P78; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839; Vapnik VN, 1995, NATURE STAT LEARNING	22	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26306-3	LECT NOTES COMPUT SC			2005	3541						376	386				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN51	WOS:000230171500038		
B	Qi, YJ; Klein-Seetharaman, J; Bar-Joseph, Z		Altman, RB; Dunker, AK; Hunter, L; Jung, TA; Klein, TE		Qi, YJ; Klein-Seetharaman, J; Bar-Joseph, Z			Random forest similarity for protein-protein interaction prediction from multiple sources	PACIFIC SYMPOSIUM ON BIOCOMPUTING 2005			English	Proceedings Paper	10th Annual Pacific Symposium on Biocomputing (PSB)	JAN 04-08, 2005	HI				SACCHAROMYCES-CEREVISIAE; GLOBAL ANALYSIS; YEAST; NETWORKS	One of the most important, but often ignored, parts of any clustering and classification algorithm is the computation of the similarity matrix. This is especially important when integrating high throughput biological data sources because of the high noise rates and the many missing values. In this paper we present a new method to compute such simularities for the task of classifying pairs of proteins as interacting or not. Our method uses direct and indirect information about interaction pairs to constructs a random forest (a collection of decision tress) from a training set. ne resulting forest is used to determine the similarity between protein pairs and this similarity is used by a classification algorithm (a modified kNN) to classify protein pairs. Testing the algorithm on yeast data indicates that it is able to improve coverage to 20% of interacting pairs with a false positive rate of 50%. These results compare favorably with all previously suggested methods for this task indicating the importance of robust similarity estimates.	Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Qi, YJ (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.						BADER GD, 2003, NAT BIOTECHNOL, V20, P991; BARJOSEPH Z, 2003, NAT BIOTECHNOL, P1337; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Deng MH, 2002, GENOME RES, V12, P1540, DOI 10.1101/gr.153002; ELION EA, 1995, TRENDS CELL BIOL, V5, P322, DOI 10.1016/S0962-8924(00)89055-8; Enright AJ, 1999, NATURE, V402, P86; Gavin AC, 2002, NATURE, V415, P141, DOI 10.1038/415141a; Gene Ontology Consortium, 2000, NATURE, V23, P25; Ghaemmaghami S, 2003, NATURE, V425, P737, DOI 10.1038/nature02046; Gilchrist MA, 2004, BIOINFORMATICS, V20, P689, DOI 10.1093/bioinformatics/btg469; HO Y, 2002, NATURE, V415; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Tong AHY, 2004, SCIENCE, V303, P808, DOI 10.1126/science.1091317; Uetz P, 2000, NATURE, V403, P623; von Mering C, 2002, NATURE, V417, P399; Xenarios I, 2001, NUCLEIC ACIDS RES, V29, P239, DOI 10.1093/nar/29.1.239; Xing E., 2002, NIPS; Zhang LV, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-38	21	40	45	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			981-256-046-7				2005							531	542				12	Biochemical Research Methods; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BCN48	WOS:000230169100044	15759657	
B	Dai, JY; Lee, J; Wang, MC		Arabnia, HR		Dai, JY; Lee, J; Wang, MC			Efficient parallel data mining for massive datasets: Parallel random forests classifier	PDPTA '05: Proceedings of the 2005 International Conference on Parallel and Distributed Processing Techniques and Applications, Vols 1-3			English	Proceedings Paper	International Conference on Parallel and Distributed Processing Techniques and Applications	JUN 27-30, 2005	Las Vegas, NV			data mining; parallel processing; random forests; cluster computing		Data mining refers to the process of finding hidden patterns inside a large dataset. While improving the accuracy of those algorithms has been the main focus of past research, massive dataset size imposes another challenge. Parallel and distributed processing techniques have been applied to data mining algorithms to make them scalable. In this paper, we discuss a new emerging data mining algorithm, random forests, and its parallelization based on VCluster, a portable parallel runtime system we have developed for a cluster of multiprocessors. Random forests is an ensemble of many decision trees and the classification is performed by majority voting by those decision trees. We also present the experimental results on the performance of parallel random forests approach.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA	Dai, JY (reprint author), Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.						ARAUJO DLA, 2000, P 2000 GEN EV COMP W, P89; Barbara D., 1997, B TECHNICAL COMMITTE, V20, P3; BAUER E, 1999, MACHINE LEARNING; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHEUNG DW, 1999, HIGH PERFORMANCE DAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dhillon Inderjit S., 1999, LARGE SCALE PARALLEL, P245; EUILHON H, 1999, DATA MIN KNOWL DISC, V3, P237; Freitas A. A., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; HAN JW, 2000, DATA MINING CONCEPTS, P5; Kass G., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; LEE JH, 2004, INT C PAR DISTR COMP; LEE JH, 2005, INT C PAR DISTR PROC; LEE JH, 2005, 19 EUR SIM MULT PERF; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; ZAKI MJ, 1999, 15 INT C DAT ENG SYD; 1994, IEEE WORLD C COMP IN, V4, P2052	22	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-61-0				2005							1142	1148				7	Computer Science, Theory & Methods	Computer Science	BDY80	WOS:000236257900168		
B	Geurts, P; Cuesta, AB; Wehenkel, L			IEEE	Geurts, P; Cuesta, AB; Wehenkel, L			Segment and combine approach for biological sequence classification	Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology			English	Proceedings Paper	2nd IEEE Symposium on Computational Intelligence in Bioformatics and Computational Biology	NOV 14-15, 2005	La Jolla, CA	IEEE Computat Intelligence Soc				This paper presents a new algorithm based on the segment and combine paradigm, for automatic classification of biological sequences. It classifies sequences by aggregating the information about their subsequences predicted by a classifier derived by machine learning from a random sample of training subsequences. This generic approach is combined with decision tree based ensemble methods, scalable both with respect to sample size and vocabulary size. The method is applied to three families of problems: DNA sequence recognition, splice junction detection, and gene regulon prediction. With respect to standard approaches based on n-grams, it appears competitive in terms of accuracy, flexibility, and scalability. The paper also highlights the possibility to exploit the resulting models to identify interpretable patterns specific of a given class of biological sequences.	Univ Liege, Dept Elect Engn & Comp Sci, CBIG, B-4000 Liege, Belgium	Geurts, P (reprint author), Univ Liege, Dept Elect Engn & Comp Sci, CBIG, B-4000 Liege, Belgium.						Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2003, SETTING USING UNDERS; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; GEURTS P, 2005, P 9 EUR C PRINC PRAC; GEURTS P, 2005, UNPUB EXTREMELY RAND; Hirsh H., 1994, Proceedings of the Tenth Conference on Artificial Intelligence for Applications (Cat. No. 94CH3421-5), DOI 10.1109/CAIA.1994.323654; Hu YJ, 2000, BIOINFORMATICS, V16, P222, DOI 10.1093/bioinformatics/16.3.222; Leslie C, 2003, ADV NEURAL INFORMATI, V15, P1417; MAREE R, 2005, P IEEE INT C COMP VI; Noordewier M. O., 1991, ADV NEURAL INFORM PR, V3; Saeys Y, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-64; Simonis N, 2004, BIOINFORMATICS, V20, P2370, DOI 10.1093/bioinformatics/bth252; VANHELDEN J, 1998, J MOL BIOL; VANHELDEN J, 2003, NUCLEIC ACIDS RES, P3593; Vert J.P., 2004, KERNEL METHODS COMPU; Wang JTL, 1999, J COMPUT BIOL, V6, P209, DOI 10.1089/cmb.1999.6.209; Wehenkel L., 1998, AUTOMATIC LEARNING T; Zhang M Q, 2000, Brief Bioinform, V1, P331, DOI 10.1093/bib/1.4.331	20	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9387-2				2005							194	201				8	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BDU91	WOS:000235518600027		
B	Wagner, RM; Lopez, M; Mase, K; Domingo-Santamaria, E; Goebel, F; Flix, J; Majumdar, P; Mazin, D; Moralejo, A; Paneque, D; Rico, J; Schweizer, T			Tata Institute Fundamental Res	Wagner, R. M.; Lopez, M.; Mase, K.; Domingo-Santamaria, E.; Goebel, F.; Flix, J.; Majumdar, P.; Mazin, D.; Moralejo, A.; Paneque, D.; Rico, J.; Schweizer, T.		MAGIC Collaboration	Observations of the Crab nebula with the MAGIC telescope	Proceedings of the 29th International Cosmic Ray Conference, Vol 4: OG 2.1, 2.2 & 2.3			English	Proceedings Paper	29th International Cosmic Ray Conference	AUG 03-10, 2005	Pune, INDIA	Forsch Zentrum Karsruhe Inst Kernphys, Univ Karlsruhe, Inst Expt Kemphys, Tata Inst Fundamental Res, Int Union Pure & Appl Phys			SPECTRUM; TEV	During and shortly after the telescope commissioning the MAGIC collaboration observed the Crab nebula. Its steady flux of gamma rays provides good means for studying the telescope performance. Here we present results obtained from these observations. Emphasis is put on the stability of the flux determination during periods with different telescope performances and on describing new analysis methods used to extract signals in the low energy region. The analysis is restricted to energies above 100 GeV, since details in the gamma/hadron separation in the low energy region and the telescope performance require more studies.	Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany	Wagner, RM (reprint author), Max Planck Inst Phys & Astrophys, Fohringer Ring 6, D-80805 Munich, Germany.		Flix, Josep/G-5414-2012; lopez, marcos/L-2304-2014; Moralejo Olaizola, Abelardo/M-2916-2014	lopez, marcos/0000-0002-8791-7908; Moralejo Olaizola, Abelardo/0000-0002-1344-9080			Aharonian F, 2004, ASTROPHYS J, V614, P897, DOI 10.1086/423931; Bock RK, 2004, NUCL INSTRUM METH A, V516, P511, DOI 10.1016/j.nima.2003.08.157; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DEJAGER OC, 1992, ASTROPHYS J, V396, P161, DOI 10.1086/171706; Hillas AM, 1998, ASTROPHYS J, V503, P744, DOI 10.1086/306005; Lorenz E, 2004, NEW ASTRON REV, V48, P339, DOI 10.1016/j.newar.2003.12.059; Schweizer T, 2002, IEEE T NUCL SCI, V49, P2497, DOI 10.1109/TNS.2002.803867; WEEKES T, 1998, ASTROPHYS J, V342, P379	8	0	0	TATA INST FUNDAMENTAL RESEARCH	MUMBAI	HOMI BHABHA MARG, NAVY NAGAR, COLABA, MUMBAI, MH-400005, INDIA							2005							163	166				4	Astronomy & Astrophysics; Instruments & Instrumentation; Physics, Particles & Fields	Astronomy & Astrophysics; Instruments & Instrumentation; Physics	BFO98	WOS:000243524200043		
B	Ona-Wilhelmi, E; de los Reyes, R; Contreras, JL; Baixeras, C; Barrio, JA; Camara, M; Cortina, J; de Jager, OC; Fonseca, MV; Lopez, M; Oya, I; Rico, J			Tata Institute Fundamental Res	Ona-Wilhelmi, E.; de los Reyes, R.; Contreras, J. L.; Baixeras, C.; Barrio, J. A.; Camara, M.; Cortina, J.; de Jager, O. C.; Fonseca, M. V.; Lopez, M.; Oya, I.; Rico, J.		MAGIC Collaboration	First pulsar observations with the MAGIC telescope	Proceedings of the 29th International Cosmic Ray Conference, Vol 4: OG 2.1, 2.2 & 2.3			English	Proceedings Paper	29th International Cosmic Ray Conference	AUG 03-10, 2005	Pune, INDIA	Forsch Zentrum Karsruhe Inst Kernphys, Univ Karlsruhe, Inst Expt Kemphys, Tata Inst Fundamental Res, Int Union Pure & Appl Phys				A few regions of the sky containing pulsars have been observed by the MAGIC Telescope [2] during its commissioning phase, namely PSR B1957+20, and PSR J0218+4232. In this work we report on the analysis of these data, looking for gamma-ray emissions both in continuous and pulsed mode. Constrains to different theoretical models about gamma-ray emission from pulsars and plerions will be discussed.	Univ Autonoma Barcelona, IFAE, Bellaterra 08193, Spain	Ona-Wilhelmi, E (reprint author), Univ Autonoma Barcelona, IFAE, Bellaterra 08193, Spain.		Contreras Gonzalez, Jose Luis/K-7255-2014; Rico, Javier/K-8004-2014; Fernandez, Ester/K-9734-2014; lopez, marcos/L-2304-2014; Fonseca Gonzalez, Maria Victoria/I-2004-2015; Barrio, Juan/L-3227-2014	Contreras Gonzalez, Jose Luis/0000-0001-7282-2394; Rico, Javier/0000-0003-4137-1134; lopez, marcos/0000-0002-8791-7908; Fonseca Gonzalez, Maria Victoria/0000-0003-2235-0725; Barrio, Juan/0000-0002-0965-0259			AHARONIAN FA, 2005, UNPUB ASTRONOMY ASTR; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bulik T, 2000, MON NOT R ASTRON SOC, V317, P97, DOI 10.1046/j.1365-8711.2000.03662.x; DEJAGER OC, 1994, ASTROPHYS J, V436, P239, DOI 10.1086/174896; HARDING A, 1998, NETWORK ATMOSPHERIC; HARDING A, 2005, P NETW ATM CHER DET; HILLAS AM, 1995, P 19 ICRC, V3, P445; Kuiper L, 2000, ASTRON ASTROPHYS, V359, P615; Navarro J., 1995, APJ, V455, P55; Neshpor YI, 1998, ASTRON LETT+, V24, P134; ONAWILHELMI E, 2003, P 28 ICRC, P2457; STAPPERS BW, 2003, SCIENCE, P299	12	0	0	TATA INST FUNDAMENTAL RESEARCH	MUMBAI	HOMI BHABHA MARG, NAVY NAGAR, COLABA, MUMBAI, MH-400005, INDIA							2005							247	250				4	Astronomy & Astrophysics; Instruments & Instrumentation; Physics, Particles & Fields	Astronomy & Astrophysics; Instruments & Instrumentation; Physics	BFO98	WOS:000243524200065		
B	Rico, J; Sidro, N; Cortina, J; Ona-Wilhelmi, E			Tata Institute Fundamental Res	Rico, J.; Sidro, N.; Cortina, J.; Ona-Wilhelmi, E.		MAGIC Collaboration	Study of the MAGIC sensitivity for off-axis observations	Proceedings of the 29th International Cosmic Ray Conference, Vol 5: OG 2.5, 2.6 & 2.7			English	Proceedings Paper	29th International Cosmic Ray Conference	AUG 03-10, 2005	Pune, INDIA	Forsch Zentrum Karsruhe Inst Kernphys, Univ Karlsruhe, Inst Expt Kemphys, Tata Inst Fundamental Res, Int Union Pure & Appl Phys				We present a study of the sensitivity of the MAGIC telescope for off-axis observations. The results presented have been obtained by the comparison of on- and off-axis Crab Nebula observations, for several positions of the source in the field of view (FOV). The source position is. reconstructed for every image using the DISP method. The results are compared with Monte Carlo (MC) simulations. This study allows us to assess the capabilities of MAGIC to perform sky-scans.	Univ Autonoma Barcelona, IFAE, E-08193 Barcelona, Spain	Rico, J (reprint author), Univ Autonoma Barcelona, IFAE, E-08193 Barcelona, Spain.		Rico, Javier/K-8004-2014	Rico, Javier/0000-0003-4137-1134			Aharonian F, 2005, SCIENCE, V307, P1938, DOI 10.1126/science.1108643; Aharonian FA, 2002, ASTRON ASTROPHYS, V395, P803, DOI 10.1051/0004-6361:20021347; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DOMINGOSANTAMAR.E, DISP ANAL METHOD POI; Fegan DJ, 1997, J PHYS G NUCL PARTIC, V23, P1013, DOI 10.1088/0954-3899/23/9/004; MORALEJO A, MAGICTDAS0407; MROALEJO A, MAGICTDAS0404; SOBCZYNSKA D, MAGICTDAS0210	8	0	0	TATA INST FUNDAMENTAL RESEARCH	MUMBAI	HOMI BHABHA MARG, NAVY NAGAR, COLABA, MUMBAI, MH-400005, INDIA							2005							371	374				4	Astronomy & Astrophysics; Instruments & Instrumentation; Physics, Particles & Fields	Astronomy & Astrophysics; Instruments & Instrumentation; Physics	BFO99	WOS:000243524500094		
B	Fan, W; Mathuria, J; Lu, CT		Kargupta, H; Srivastava, J; Kamath, C; Goodman, A		Fan, Wei; Mathuria, Janak; Lu, Chang-tien			Making Data Mining Models Useful to Model Non-Paying Customers of Exchange Carriers	PROCEEDINGS OF THE FIFTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING	SIAM Proceedings Series		English	Proceedings Paper	5th SIAM International Conference on Data Mining	APR 21-23, 2005	Newport Beach, CA	SIAM, Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Amer Stat Assoc				Due to both limitations of technologies and the nature of the problems, data mining may not be able to solve a problem completely in a way as one wishes. When this happens, we need to first understand the actual need of business, characteristic of available partial solution, and then make compromises between the technology solution and business needs. A majority of the papers published in data mining conferences and journals seem to concentrate only on the success side of the story. In this paper, we discuss our experiences and the complete process from near failure to success when applying inductive learning techniques to predict non-paying customers of competitive local exchange carriers (CLEC's), currently at 20%. Experiments with a number of state-of-the-art methods and algorithms found that most customers were labeled as paying on time. Cost-sensitive learning is not possible since the target company cannot define a cost-model. Finally, after discussing with the billing department, a compromised but still useful solution is to predict the probability that someone will default. The billing team can use the predicted score to prioritize collection efforts as well as to predict cash flow. We have found that two randomized decision tree ensemble methods (Fan's random decision tree and a probabilistic extension of Breiman's random forest) are consistently more accurate in posterior probability estimation than single decision tree based probability calibration methods. The software, both Fan's RDT and probabilistic extension of random forest, as well as a longer version of this paper will be made available by the contacting author.	[Fan, Wei] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Fan, W (reprint author), IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA.	weifan@us.ibm.com; janakm@vt.edu; ctlu@vt.edu					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Fan W, 2003, P 3 IEEE INT C DAT M; Zadrozny B., 2001, P 18 INT C MACH LEAR	3	0	0	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			978-0-89871-593-4	SIAM PROC S			2005							486	490				5	Computer Science, Artificial Intelligence	Computer Science	BUJ08	WOS:000289491000046		
S	Hu, QH; Yu, DR; Wang, MY		Slezak, D; Yao, JT; Peters, JF; Ziarko, W; Hu, X		Hu, QH; Yu, DR; Wang, MY			Constructing rough decision forests	ROUGH SETS, FUZZY SETS, DATA MINING, AND GRANULAR COMPUTING, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th International Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing (RSFDGrC 2005)	AUG 31-SEP 03, 2005	Regina, CANADA		Univ Regina		HANDWRITTEN WORD RECOGNITION; FEATURE-SELECTION; SUBSPACE	Decision forests are a type of classification paradigm which combines a collection of decision trees for a classification task, instead of depending on a single tree. Improvement of accuracy and stability is observed in experiments and applications. Some novel techniques to construct decision forests are proposed based on rough set reduction in this paper. As there are a lot of reducts for some data sets, a series of decision trees can be trained with different reducts. Three methods to select decision trees or reducts are presented, and decisions from selected trees are fused with the plurality voting rule. The experiments show that random selection is the worst solution in the proposed methods. It is also found that input diversity maximization doesn't guarantee output diversity maximization. Hence it cannot guarantee a good classification performance in practice. Genetic algorithm based selective rough decision forests consistently get good classification accuracies compared with a single tree trained by raw data as well as the other two forest constructing methods.	Harbin Inst Technol, Harbin 150006, Peoples R China	Hu, QH (reprint author), Harbin Inst Technol, Harbin 150006, Peoples R China.	huqinghua@hcms.hit.edu.cn	Hu, Qinghua/B-8857-2008				Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cheng J, 2004, LECT NOTES COMPUT SC, V3214, P352; Dietterich T.G., 1998, MACH LEARN, P1; Freund Y, 1995, 2 EUR C COMP LEARN T, P23; Gunter S, 2004, INT J PATTERN RECOGN, V18, P957, DOI 10.1142/S0218001404003496; Gunter S, 2004, PATTERN RECOGN LETT, V25, P1323, DOI 10.1016/j.patrec.2004.05.002; HO TK, 3 INT C DOC AN REC, P27; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HU Q, 2003, P 2003 INT C NEUR NE, V1, P543; Hu QH, 2004, INT J UNCERTAIN FUZZ, V12, P575, DOI 10.1142/S0218488504003089; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Schettini R, 2004, INT J PATTERN RECOGN, V18, P819, DOI 10.1142/S0218001404003435; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; Wang Jue, 1998, Journal of Computer Science and Technology (English Language Edition), V13, DOI 10.1007/BF02946606; Wu QX, 2005, KNOWL INF SYST, V7, P246, DOI 10.1007/s10115-004-0150-0; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	18	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28660-8	LECT NOTES ARTIF INT			2005	3642						147	156				10	Computer Science, Artificial Intelligence	Computer Science	BCZ95	WOS:000232190100016		
J	Rossi, A; Amaddeo, F; Sandri, M; Tansella, M				Rossi, A; Amaddeo, F; Sandri, M; Tansella, M			Determinants of once-only contact in a community-based psychiatric service	SOCIAL PSYCHIATRY AND PSYCHIATRIC EPIDEMIOLOGY			English	Article						mental health care; accessibility; patterns of care; once-only contact; low service use	MENTAL-HEALTH-SERVICES; CASE-REGISTER; SOUTH-VERONA; CARE; GRONINGEN	Background This study examined variables associated with patients who had a once-only contact with the out-patient department of a Community Mental Health Service (CMHS). Methods Using the South-Verona Psychiatric Case Register (PCR), an 8-year cohort of patients who had a new episode of care with the out-patient department of the South Verona CMHS was followed up for 3 months after the first contact, to identify those patients who had no further contact with the service. Potential determinants of once-only contact were analysed. Results A total of 2,446 new episodes of care met the inclusion criteria of the study. Of those, 734 (30%) were once-only contacts with the service. Compared to patients with more than one contact, patients who had a once-only contact were older, more likely to be male, had a lower socio-economic status and less severe psychiatric diagnosis. They were more likely to be referred by consultation/liaison or emergency room. Conclusions Multivariate analysis revealed that having a less severe psychiatric diagnosis was the most significant determinant of once-only contact with a CMHS. The results suggest that the behaviour of referring agents in selecting patients and preparing them for treatment merits further investigation.	Osped Policlin, Dept Med & Publ Hlth, Sect Psychiat, I-37134 Verona, Italy; Univ Verona, Dept Med & Publ Hlth, Sect Psychiat, I-37100 Verona, Italy; Univ Verona, Interdepartmental Ctr Econ Documentat, I-37100 Verona, Italy	Rossi, A (reprint author), Osped Policlin, Dept Med & Publ Hlth, Sect Psychiat, Piazzale LA Scuro 10, I-37134 Verona, Italy.	alberto.rossi@medicina.unvr.it	Rossi, Alberto/B-4219-2010; Amaddeo, Francesco/B-4144-2010; Tansella, Michele/B-4106-2010; Sandri, Marco/L-2875-2013	Sandri, Marco/0000-0002-1422-5695			Amaddeo F, 1997, ACTA PSYCHIAT SCAND, V95, P189, DOI 10.1111/j.1600-0447.1997.tb09619.x; BAEKELAND F, 1975, PSYCHOL BULL, V82, P738, DOI 10.1037/h0077132; BALESTRIERI M, 1988, ACTA PSYCHIAT SCAND, V80, P437; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHEN A, 1991, HOSP COMMUNITY PSYCH, V42, P282; DERKSEN S, 1992, BRIT J MATH STAT PSY, V45, P265; Garrett JM, 2000, SWBOOT STATA MODULE; Gould W, 2000, STATA TECHNICAL B, V53, P19; Heaven Cathy, 2003, Epidemiol Psichiatr Soc, V12, P86; HENISZ JE, 1977, ARCH GEN PSYCHIAT, V34, P1345; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Killaspy H, 2000, BRIT J PSYCHIAT, V176, P160, DOI 10.1192/bjp.176.2.160; KONTNY EL, 1982, UNPUB PATIENT WHO IS; LAVIK NJ, 1983, ACTA PSYCHIAT SCAND, V67, P404, DOI 10.1111/j.1600-0447.1983.tb09721.x; LIAW A, 2002, RANDOM FOREST R CLAS; MORLINO M, 1995, ACTA PSYCHIAT SCAND, V92, P1, DOI 10.1111/j.1600-0447.1995.tb09534.x; PHILLIPS MS, 1983, CAN J PSYCHIAT, V28, P202; Rossi A, 2002, BRIT J PSYCHIAT, V181, P331, DOI 10.1192/bjp.181.4.331; Statacorp, 2001, STAT STAT SOFTW REL; SYTEMA S, 1989, ACTA PSYCHIAT SCAND, V79, P153, DOI 10.1111/j.1600-0447.1989.tb08583.x; Sytema S, 1997, PSYCHOL MED, V27, P1355, DOI 10.1017/S0033291797005539; Tansella M, 1991, PSYCHOL MED        S, V19, P5; TANSELLA M, 1998, MENTAL HLTH OUR FUTU; TANSELLA M, 1995, BRIT J PSYCHIAT, V167, P220, DOI 10.1192/bjp.167.2.220; Tansella M, 1999, S VERONA PSYCHIAT CA; TAUBE CA, 1988, AM J PSYCHIAT, V145, P19; Tehrani E, 1996, ACTA PSYCHIAT SCAND, V94, P266, DOI 10.1111/j.1600-0447.1996.tb09859.x; TREPKA C, 1986, BRIT J MED PSYCHOL, V59, P181; Young AS, 2000, PSYCHIATR SERV, V51, P85	30	9	9	DR DIETRICH STEINKOPFF VERLAG	DARMSTADT	PO BOX 10 04 62, D-64204 DARMSTADT, GERMANY	0933-7954			SOC PSYCH PSYCH EPID	Soc. Psychiatry Psychiatr. Epidemiol.	JAN	2005	40	1					50	56		10.1007/s00127-005-0845-x		7	Psychiatry	Psychiatry	882ZV	WOS:000225979800008	15624075	
J	Xiao, YY; Segal, MR				Xiao, YY; Segal, MR			Prediction of genomewide conserved epitope profiles of HIV-1: Classifier choice and peptide representation	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						MHC; peptide binding prediction; learning; ensemble methods	T-CELL EPITOPES; ARTIFICIAL NEURAL-NETWORK; MHC-BINDING PEPTIDES; HLA-DR ALLELES; PROLIFERATIVE RESPONSES; LYMPHOCYTE EPITOPES; INDEPENDENT BINDING; SYNTHETIC PEPTIDES; NATURAL INFECTION; HLA-DR4 MOLECULES	Identification of peptides binding to Major Histocompatibility Complex (MHC) molecules is important for accelerating vaccine development and improving immunotherapy. Accordingly, a wide variety of prediction methods have been applied in this context. In this paper, we introduce (tree-based) ensemble classifiers for such problems and contrast their predictive performance with forefront existing methods for both MHC class I and class II molecules. In addition, we investigate the impact of differing peptide representation schemes on performance. Finally, classifier predictions are used to conduct genomewide scans of a diverse collection of HIV-1 strains, enabling assessment of epitope conservation. We investigated all combinations of six classification methods (classification trees, artificial neural networks, support vector machines, as well as the more recently devised ensemble methods (bagging, random forests, boosting) with four peptide representation schemes (amino acid sequence, select biophysical properties, select quantitative structure-activity relationship (QSAR) descriptors, and the combination of the latter two) in predicting peptide binding to an MHC class I molecule (HLA-A2) and MHC class II molecule (HLA-DR4). Our results show that the ensemble methods are consistently more accurate than the other three alternatives. Furthermore, they are robust with respect to parameter tuning. Among the four representation schemes, the amino acid sequence representation gave consistently (across classifiers) best results. This finding obviates the need for feature selection strategies incurred by use of biophysical and/or QSAR properties. We obtained, and aligned, a diverse set of 32 HIV-1 genomes and pursued genomewide HLA-DR4 epitope profiling by querying with respect to classifier predictions, as obtained under each of the four peptide representation schemes. We validated those epitopes conserved across strains against known T-cell epitopes. Once again, amino acid sequence representation was at least as effective as using properties. Assessment of novel epitope predictions awaits experimental verification.	Univ Calif San Francisco, San Francisco, CA 94143 USA	Xiao, YY (reprint author), Univ Calif San Francisco, San Francisco, CA 94143 USA.	yxiao@itsa.ucsf.edu; mark@biostat.ucsf.edu					Adams SL, 1997, J ACQ IMMUN DEF SYND, V15, P257; Bedford PA, 1997, J ACQ IMMUN DEF SYND, V14, P301; Bhasin M, 2004, BIOINFORMATICS, V20, P421, DOI 10.1093/bioinformatics/btg424; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blythe MJ, 2002, BIOINFORMATICS, V18, P434, DOI 10.1093/bioinformatics/18.3.434; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brusic V, 1996, NUCLEIC ACIDS RES, V24, P242, DOI 10.1093/nar/24.1.242; Brusic V, 1998, BIOINFORMATICS, V14, P121, DOI 10.1093/bioinformatics/14.2.121; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; BUUS S, 1987, SCIENCE, V235, P1353, DOI 10.1126/science.2435001; CalvoCalle JM, 1997, J IMMUNOL, V159, P1362; Carmichael A, 1996, J VIROL, V70, P8468; CHICZ RM, 1993, J EXP MED, V178, P27, DOI 10.1084/jem.178.1.27; Christianini N., 2000, SUPPORT VECTOR MACHI; Congia M, 1998, P NATL ACAD SCI USA, V95, P3833, DOI 10.1073/pnas.95.7.3833; de Lalla C, 1999, J IMMUNOL, V163, P1725; Diepolder HM, 1997, J VIROL, V71, P6011; Dong X, 2000, J IMMUNOL, V164, P129; Donnes P, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-25; Doytchinova IA, 2003, BIOINFORMATICS, V19, P2263, DOI 10.1093/bioinformatics/btg312; Efron B, 1993, INTRO BOOTSTRAP; EMMERT DB, 1994, NUCLEIC ACIDS RES, V22, P3445, DOI 10.1093/nar/22.17.3445; Endl J, 1997, J CLIN INVEST, V99, P2405, DOI 10.1172/JCI119423; FALK K, 1991, NATURE, V351, P290, DOI 10.1038/351290a0; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Fugger L, 1996, EUR J IMMUNOL, V26, P928, DOI 10.1002/eji.1830260431; Gahery-Segard H, 2000, J VIROL, V74, P1694, DOI 10.1128/JVI.74.4.1694-1703.2000; Gaston JSH, 1996, J RHEUMATOL, V23, P130; GERETTI AM, 1994, SCAND J IMMUNOL, V39, P355, DOI 10.1111/j.1365-3083.1994.tb03386.x; GOUDEBOUT P, 1997, J ACQ IMMUN DEF SYND, V14, P91; Gross DM, 1998, SCIENCE, V281, P703, DOI 10.1126/science.281.5377.703; HAMMER J, 1995, J EXP MED, V181, P1847, DOI 10.1084/jem.181.5.1847; Hastie T., 2001, ELEMENTS STAT LEARNI; Honeyman MC, 1998, MOL MED, V4, P231; Hsu C.W., PRACTICAL GUIDE SUPP; KIDERA A, 1985, J PROTEIN CHEM, V4, P23, DOI 10.1007/BF01025492; Kovats S, 1997, EUR J IMMUNOL, V27, P1014, DOI 10.1002/eji.1830270431; KUBO RT, 1994, J IMMUNOL, V152, P3913; Li K, 1998, CANCER IMMUNOL IMMUN, V47, P32, DOI 10.1007/s002620050501; Lin ZH, 2004, J COMPUT BIOL, V11, P683; Livingston B, 2002, J IMMUNOL, V168, P5499; Mallios RR, 2001, BIOINFORMATICS, V17, P942, DOI 10.1093/bioinformatics/17.10.942; Mamitsuka H, 1998, PROTEINS, V33, P460, DOI 10.1002/(SICI)1097-0134(19981201)33:4<460::AID-PROT2>3.0.CO;2-M; MANCA F, 1995, J ACQ IMMUN DEF SYND, V9, P227; MCNICHOLL JM, 1995, J IMMUNOL, V155, P1951; Milik M, 1998, NAT BIOTECHNOL, V16, P753, DOI 10.1038/nbt0898-753; Muntasesll A, 2002, J IMMUNOL, V169, P5052; Muraro PA, 1997, J CLIN INVEST, V100, P339, DOI 10.1172/JCI119539; Nehete PN, 1998, VIRAL IMMUNOL, V11, P147, DOI 10.1089/vim.1998.11.147; PARKER KC, 1992, J IMMUNOL, V149, P3580; PARKER KC, 1994, J IMMUNOL, V152, P163; Peters B, 2003, BIOINFORMATICS, V19, P1765, DOI 10.1093/bioinformatics/btg24; REECE JC, 1993, J IMMUNOL, V151, P6175; Ripley B. D., 1996, PATTERN RECOGNITION; Rosenberg ES, 1997, SCIENCE, V278, P1447, DOI 10.1126/science.278.5342.1447; RUDENSKY AY, 1991, NATURE, V353, P622, DOI 10.1038/353622a0; RUPPERT J, 1993, CELL, V74, P929, DOI 10.1016/0092-8674(93)90472-3; SCHRIER RD, 1989, J IMMUNOL, V142, P1166; Segal MR, 2001, BIOMETRICS, V57, P632, DOI 10.1111/j.0006-341X.2001.00632.x; SEGAL MR, 2004, STAT APPL GENETICS M, V3; Sitz KV, 1999, J INFECT DIS, V179, P817, DOI 10.1086/314685; Sung MH, 2004, J COMPUT BIOL, V11, P125, DOI 10.1089/106652704773416920; Therneau TM, 1997, INTRO RECURSIVE PART; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Topalian SL, 1996, J EXP MED, V183, P1965, DOI 10.1084/jem.183.5.1965; van der Burg SH, 1999, J IMMUNOL, V162, P152; WAHREN B, 1989, J ACQ IMMUN DEF SYND, V2, P448; Wilson CC, 2001, J VIROL, V75, P4195, DOI 10.1128/JVI.75.9.4195-4207.2001; Yu K, 2002, MOL MED, V8, P137; Zhao YD, 2003, BIOINFORMATICS, V19, P1978, DOI 10.1093/bioinformatics/btg255	75	5	6	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MO B	Stat. Appl. Genet. Mol. Biol.		2005	4								25			36	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	055VG	WOS:000238478100013		
B	Liu, RB; Zhang, CS; Xia, YL		He, X		Liu, RB; Zhang, CS; Xia, YL			Importance feature sampling in random subspace	Vision '05: Proceedings of the 2005 International Conference on Computer Vision			English	Proceedings Paper	International Conference on Computer Vision	JUN 20-23, 2005	Las Vegas, NV			classification; ensemble; random subspace		Random subspace method is a combination of classifiers such that each classifier depends on the values of a random feature subset sampled independently and identically. As it is known that the generalization error of an ensemble classifier depends on the strength of the individual classifiers and the correlation among them, purely relying on random sampling could not guarantee the performance of the ensemble classifier. This motivates us to introduce a general method called Weighted Random Subspace Method to improve the performance of the ensemble classifier. Guided by the method, we propose an algorithm called MDWRSM, which uses marginal diversity to weigh sample features. The superiority of the method is demonstrated by experiments on real datasets from UCI repository and USPS database.	Tsing Hua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China	Liu, RB (reprint author), Tsing Hua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; SAON G, 2000, P NEUR INF P SYST DE; VASCONCELOS N, 2002, NEURAL INFORM PROCES; ZHU SC, 1997, NUERAL COMPUTATION, V9	9	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-65-3				2005							192	197				6	Computer Science, Artificial Intelligence	Computer Science	BDZ98	WOS:000236385000028		
J	Dettling, M				Dettling, M			BagBoosting for tumor classification with gene expression data	BIOINFORMATICS			English	Article							ADDITIVE LOGISTIC-REGRESSION; STATISTICAL VIEW; PREDICTION; CANCER	Motivation: Microarray experiments are expected to contribute significantly to the progress in cancer treatment by enabling a precise and early diagnosis. They create a need for class prediction tools, which can deal with a large number of highly correlated input variables, perform feature selection and provide class probability estimates that serve as a quantification of the predictive uncertainty. A very promising solution is to combine the two ensemble schemes bagging and boosting to a novel algorithm called BagBoosting. Results: When bagging is used as a module in boosting, the resulting classifier consistently improves the predictive performance and the probability estimates of both bagging and boosting on real and simulated gene expression data. This quasi-guaranteed improvement can be obtained by simply making a bigger computing effort. The advantageous predictive potential is also confirmed by comparing BagBoosting to several established class prediction tools for microarray data.	ETH, Seminar Stat, CH-8092 Zurich, Switzerland	Dettling, M (reprint author), ETH, Seminar Stat, CH-8092 Zurich, Switzerland.	dettling@stat.math.ethz.ch					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Buhlmann P, 2000, ANN STAT, V28, P377; Burges CJC, 1998, KNOWLEDGE DISCOVERY, V2, P121; Chang CC, 2001, LIBSVM LIB SUPPORT V; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J. H., 2003, IMPORTANCE SAMPLED L; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HOTHORN T, 2003, 82 I STAT; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Meyer D., 2001, R NEWS, V1, P23; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; R Development Core Team, 2004, R LANG ENV STAT COMP; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299	27	133	143	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	DEC 12	2004	20	18					3583	3593		10.1093/bioinformatics/bth447		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	880JR	WOS:000225786600033	15466910	
J	Lunetta, KL; Hayward, LB; Segal, J; Van Eerdewegh, P				Lunetta, KL; Hayward, LB; Segal, J; Van Eerdewegh, P			Screening large-scale association study data: exploiting interactions using random forests	BMC GENETICS			English	Article							MULTIFACTOR-DIMENSIONALITY REDUCTION; DETECTING GENE-GENE; VARIABLE SELECTION; COMPLEX TRAITS; LINKAGE; HETEROGENEITY; POWER; SUBGROUPS; CANCER	Background: Genome-wide association studies for complex diseases will produce genotypes on hundreds of thousands of single nucleotide polymorphisms ( SNPs). A logical first approach to dealing with massive numbers of SNPs is to use some test to screen the SNPs, retaining only those that meet some criterion for futher study. For example, SNPs can be ranked by p-value, and those with the lowest p-values retained. When SNPs have large interaction effects but small marginal effects in a population, they are unlikely to be retained when univariate tests are used for screening. However, model-based screens that pre-specify interactions are impractical for data sets with thousands of SNPs. Random forest analysis is an alternative method that produces a single measure of importance for each predictor variable that takes into account interactions among variables without requiring model specification. Interactions increase the importance for the individual interacting variables, making them more likely to be given high importance relative to other variables. We test the performance of random forests as a screening procedure to identify small numbers of risk-associated SNPs from among large numbers of unassociated SNPs using complex disease models with up to 32 loci, incorporating both genetic heterogeneity and multi-locus interaction. Results: Keeping other factors constant, if risk SNPs interact, the random forest importance measure significantly outperforms the Fisher Exact test as a screening tool. As the number of interacting SNPs increases, the improvement in performance of random forest analysis relative to Fisher Exact test for screening also increases. Random forests perform similarly to the univariate Fisher Exact test as a screening tool when SNPs in the analysis do not interact. Conclusions: In the context of large-scale genetic association studies where unknown interactions exist among true risk-associated SNPs or SNPs and environmental covariates, screening SNPs using random forest analyses can significantly reduce the number of SNPs that need to be retained for further study compared to standard univariate screening methods.	Genome Therapeut Corp, Waltham, MA USA; Boston Univ, Sch Publ Hlth, Dept Biostat, Boston, MA USA; Genizon BioSci Inc, Montreal, PQ, Canada; Harvard Univ, Sch Med, Dept Psychiat, Boston, MA 02115 USA	Lunetta, KL (reprint author), Oscient Pharmaceut Inc, Waltham, MA 02154 USA.	klunetta@bu.edu; brooke.hayward@yahoo.com; jonathan.segal@genizon.com; paul.vaneerdewegh@genizon.com					Agresti A., 1990, CATEGORICAL DATA ANA, P558; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., RANDOM FORESTS VERSI; Breiman L., 1984, WADSWORTH STAT PROBA; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bureau A, 2003, BMC GENET, V4, DOI 10.1186/1471-2156-4-S1-S64; Chang CJ, 2001, GENET EPIDEMIOL, V21, pS180; Cook Nancy R., 2004, Statistics in Medicine, V23, P1439, DOI 10.1002/sim.1749; Costello TJ, 2003, BMC GENET, V4, DOI 10.1186/1471-2156-4-S1-S66; Farrer Lindsay A., 1998, P93; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; Hastie T., 2001, SPRINGER SERIES STAT, Vxvi, P533; HORVATH S, 2003, JOINT STAT M VOLUME; Kooperberg C, 2001, GENET EPIDEMIOL, V21, pS626; LevyLahad E, 1997, AM J HUM GENET, V60, P1059; Nelson MR, 2001, GENOME RES, V11, P458, DOI 10.1101/gr.172901; Oh C, 2003, BMC GENET, V4, DOI 10.1186/1471-2156-4-S1-S69; Province MA, 2001, ADV GENET, V42, P273, DOI 10.1016/S0065-2660(01)42028-1; RISCH N, 1990, AM J HUM GENET, V46, P229; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Schapire RE, 1998, ANN STAT, V26, P1651; Schwender H, 2004, TOXICOL LETT, V151, P291, DOI 10.1016/j.toxlet.2004.02.021; Shannon WD, 2001, GENET EPIDEMIOL, V20, P293, DOI 10.1002/gepi.1; Suh YJ, 2003, HUM HERED, V55, P147, DOI 10.1159/0000072320; Wilcox MA, 1999, GENET EPIDEMIOL, V17, pS391; Yi NJ, 2003, GENETICS, V164, P1129; York TP, 2001, GENET EPIDEMIOL, V21, pS649; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5; Zhang HP, 2001, GENET EPIDEMIOL, V21, pS317	32	173	181	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2156			BMC GENET	BMC Genet.	DEC 10	2004	5								32	10.1186/1471-2156-5-32		13	Genetics & Heredity	Genetics & Heredity	890QQ	WOS:000226526300001	15588316	
J	Nason, M; Emerson, S; LeBlanc, M				Nason, M; Emerson, S; LeBlanc, M			CARTscans: A tool for visualizing complex models	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						bagging; boosting; classification and regression trees; color coding; graphics; linear regression; random forests; visualization		We present CARTscans, a graphical tool that displays predicted values across. a four-dimensional subspace. We show how these plots are useful for understanding the structure and relationships between variables in a wide variety of models. including (but not limited to) regression trees, ensembles of trees, and linear regressions with varving degrees of interactions. In addition, the common visualization framework allows diverse complex models to be visually compared in a way that illuminates the similarities and differences in the underlying methods, facilitates the choice of a particular model structure, and provided a useful check for implausible predictions of future observations in regions With little or no data.	NIAID, Biostat Res Branch, Bethesda, MD 20892 USA; Univ Washington, Dept Biostat, Seattle, WA 98195 USA	Nason, M (reprint author), NIAID, Biostat Res Branch, 6700B Rockledge Dr,MSC 7609, Bethesda, MD 20892 USA.	mnason@niaid.nih.gov					Becker RA, 1996, J COMPUTATIONAL GRAP, V5, P123, DOI DOI 10.2307/1390777; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brewer C. A., 1999, P SECT STAT GRAPH AM, P55; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; Efron B, 1993, INTRO BOOTSTRAP; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hastie T., 2001, ELEMENTS STAT LEARNI; Rosner B., 1990, FUNDAMENTALS BIOSTAT; Swayne DF, 1998, J COMPUT GRAPH STAT, V7, P113, DOI 10.2307/1390772; Tukey PA, 1981, INTERPRETING MULTIVA, P189; URBANEK S, 2002, P 14 C COMP STAT, P303	13	5	5	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	DEC	2004	13	4					807	825		10.1198/106186004X11417		19	Statistics & Probability	Mathematics	879SO	WOS:000225739400005		
J	O'Riordan, E; Orlova, TN; Mei, JF; Butt, K; Chander, PM; Rahman, S; Mya, M; Hu, R; Momin, J; Eng, EW; Hampel, DJ; Hartman, B; Kretzler, M; Delaney, V; Goligorsky, MS				O'Riordan, E; Orlova, TN; Mei, JF; Butt, K; Chander, PM; Rahman, S; Mya, M; Hu, R; Momin, J; Eng, EW; Hampel, DJ; Hartman, B; Kretzler, M; Delaney, V; Goligorsky, MS			Bioinformatic analysis of the urine proteome of acute allograft rejection	JOURNAL OF THE AMERICAN SOCIETY OF NEPHROLOGY			English	Article							RENAL-TRANSPLANTATION; SERUM; RECIPIENTS; TIME; CLASSIFICATION; DIAGNOSIS; SURVIVAL; CANCER	The urinary proteome in health and disease attracts increasing attention because of the potential diagnostic and pathophysiologic biomarker information carried by specific excreted proteins or their constellations. This cross-sectional study aimed to analyze the urinary proteome in patients with biopsy-proven acute rejection (n = 23) compared with transplant recipients with stable graft function (n = 22) and healthy volunteers (n = 20) and to correlate this with clinical, morphologic, and laboratory data. Urine samples were preadsorbed on four different protein chip surfaces, and the protein composition was analyzed using a surface-enhanced laser desorption/ionization time-of-flight mass spectrometer platform. The data were analyzed using two independent approaches to sample classification. Patients who experienced acute rejection could be distinguished from stable patients with a sensitivity of 90.5 to 91.3% and a specificity of 77.2 to 83.3%, depending on the classifier used. Protein masses that were important in constructing the classification algorithms included those of mass 2003.0, 2802.6, 4756.3, 5872.4, 6990.6, 19,018.8, and 25,665.7 Da. Normal urine was distinguished from transplant urine using a protein marker of mass 78,531.2 Da with both a sensitivity and a specificity of 100%. In conclusion, (1) urine proteome in transplant recipients with stable graft function was significantly different from healthy control subjects, and (2) acute rejections were characterized by a constellation of excreted proteins. Analysis of the urinary proteome may expedite the noninvasive prediction of acute graft rejection, thus importantly assisting in establishing the diagnosis.	New York Med Coll, Renal Res Inst, Dept Med, Valhalla, NY 10595 USA; New York Med Coll, Div Nephrol, Dept Med, Valhalla, NY 10595 USA; New York Med Coll, Dept Pathol, Valhalla, NY 10595 USA; New York Med Coll, Dept Surg, Div Transplantat, Valhalla, NY 10595 USA; Ciphergen Biosyst Inc, Fremont, CA USA; Virchow Clin Univ Med, Charite, Div Nephrol & Med Intens Care, Berlin, Germany; Univ Munich, Sch Med, Div Nephrol, D-80539 Munich, Germany	O'Riordan, E (reprint author), New York Med Coll, Renal Res Inst, Dept Med, Room C06,Basic Sci Bldg,95 Grasslands Rd, Valhalla, NY 10595 USA.	edmond_oriordan@nymc.edu					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Clarke W, 2003, ANN SURG, V237, P660, DOI 10.1097/00000658-200305000-00008; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Dupont PJ, 2003, TRANSPLANT INT, V16, P648, DOI 10.1007/s00147-003-0601-7; FUNG E, 2003, RENAL DIS TECHNIQUES, P295; Fung E. T., 2002, COMPUTATIONAL PROT S, V32, pS34; Gaber LW, 1996, TRANSPLANTATION, V61, P1711, DOI 10.1097/00007890-199606270-00008; HAMPEL DJ, 2001, J AM SOC NEPHROL, V12, P1206; Hariharan S, 2000, NEW ENGL J MED, V342, P605, DOI 10.1056/NEJM200003023420901; Hartmann A, 1997, NEPHROL DIAL TRANSPL, V12, P161, DOI 10.1093/ndt/12.1.161; Ishikawa A, 1999, TRANSPLANTATION, V68, P1318, DOI 10.1097/00007890-199911150-00017; Kaplan B, 2002, AM J TRANSPLANT, V2, P970, DOI 10.1034/j.1600-6143.2002.21015.x; KREIS H, 1998, OXFORD TXB CLIN NEPH, P2153; Li BG, 2001, NEW ENGL J MED, V344, P947, DOI 10.1056/NEJM200103293441301; Li JN, 2002, CLIN CHEM, V48, P1296; McLaren AJ, 2000, ANN SURG, V232, P98, DOI 10.1097/00000658-200007000-00014; Ojo AO, 2000, KIDNEY INT, V57, P307, DOI 10.1046/j.1523-1755.2000.00816.x; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Racusen LC, 1999, KIDNEY INT, V55, P713, DOI 10.1046/j.1523-1755.1999.00299.x; Rush D, 1998, J AM SOC NEPHROL, V9, P2129; RUSH DN, 1994, TRANSPLANTATION, V57, P208, DOI 10.1097/00007890-199401001-00009; Sarwal M, 2003, NEW ENGL J MED, V349, P125, DOI 10.1056/NEJMoa035588; Schaub S, 2004, KIDNEY INT, V65, P323, DOI 10.1111/j.1523-1755.2004.00352.x; Schaub S, 2004, J AM SOC NEPHROL, V15, P219, DOI 10.1097/01.ASN.0000101031.52826.BE; Vlahou A, 2001, AM J PATHOL, V158, P1491, DOI 10.1016/S0002-9440(10)64100-4; Wolfe RA, 1999, NEW ENGL J MED, V341, P1725, DOI 10.1056/NEJM199912023412303; YILMAZ S, 1995, KIDNEY INT, V48, P251, DOI 10.1038/ki.1995.291	27	93	95	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	1046-6673			J AM SOC NEPHROL	J. Am. Soc. Nephrol.	DEC	2004	15	12					3240	3248		10.1097/01.ASN.0000145241.83482.68		9	Urology & Nephrology	Urology & Nephrology	876NW	WOS:000225504800033	15579528	
J	Satten, GA; Datta, S; Moura, H; Woolfitt, AR; Carvalho, MD; Carlone, GM; De, BK; Pavlopoulos, A; Barr, JR				Satten, GA; Datta, S; Moura, H; Woolfitt, AR; Carvalho, MD; Carlone, GM; De, BK; Pavlopoulos, A; Barr, JR			Standardization and denoising algorithms for mass spectra to classify whole-organism bacterial specimens	BIOINFORMATICS			English	Article							OVARIAN-CANCER; SPECTROMETRY; SERUM; CLASSIFICATION; PATTERNS	Motivation: Application of mass spectrometry in proteomics is a breakthrough in high-throughput analyses. Early applications have focused on protein expression profiles to differentiate among various types of tissue samples (e.g. normal versus tumor). Here our goal is to use mass spectra to differentiate bacterial species using whole-organism samples. The raw spectra are similar to spectra of tissue samples, raising some of the same statistical issues (e.g. non-uniform baselines and higher noise associated with higher baseline), but are substantially noisier. As a result, new preprocessing procedures are required before these spectra can be used for statistical classification. Results: In this study, we introduce novel preprocessing steps that can be used with any mass spectra. These comprise a standardization step and a denoising step. The noise level for each spectrum is determined using only data from that spectrum. Only spectral features that exceed a threshold defined by the noise level are subsequently used for classification. Using this approach, we trained the Random Forest program to classify 240 mass spectra into four bacterial types. The method resulted in zero prediction errors in the training samples and in two test datasets having 240 and 300 spectra, respectively.	Ctr Dis Control & Prevent, Div Sci Lab, Natl Ctr Environm Hlth, Atlanta, GA 30341 USA; Univ Georgia, Dept Stat, Athens, GA 30602 USA; Ctr Dis Control & Prevent, Div Bacterial & Mycot Dis, Natl Ctr Infect Dis, Atlanta, GA 30333 USA	Satten, GA (reprint author), Ctr Dis Control & Prevent, Div Sci Lab, Natl Ctr Environm Hlth, Atlanta, GA 30341 USA.						Bafna V, 2001, Bioinformatics, V17 Suppl 1, pS13; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Banks N., 1916, Journal of Entomology and Zoology Claremont, V8; Bocker S, 2003, BIOINFORMATICS, V19, pi44; BREIMAN L, 2001, 567 U AL DEP STAT; Breiman L, 1999, 567 U CAL DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; DUCHARME GR, 1995, BIOMETRICS, V51, P1105, DOI 10.2307/2533009; FENSELAU C, 2001, MASS SPECTROM REV, V20, P57; Havilio M, 2003, ANAL CHEM, V75, P435, DOI 10.1021/ac0258913; HAWKINS DM, 2003, CHANCE, V16, P19; Lay JO, 2001, MASS SPECTROM REV, V20, P172, DOI 10.1002/mas.10003; Lu B., 2003, BIOINFORMATICS S2, V19, pii113; Nesvizhskii AI, 2003, ANAL CHEM, V75, P4646, DOI 10.1021/ac0341261; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Purohit PV, 2003, PROTEOMICS, V3, P1699, DOI 10.1002/pmic.200300518; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Thiele H., 2003, CHANCE, V16, P29; THIELE H, 2003, CHANCE, V16, P51; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210	21	33	36	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	NOV 22	2004	20	17					3128	3136		10.1093/bioinformatics/bth372		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	874PD	WOS:000225361400024	15217815	
J	Tong, WD; Xie, W; Hong, HX; Fang, H; Shi, LM; Perkins, R; Petricoin, EF				Tong, WD; Xie, W; Hong, HX; Fang, H; Shi, LM; Perkins, R; Petricoin, EF			Using decision forest to classify prostate cancer samples on the basis of SELDI-TOF MS data: Assessing chance correlation and prediction confidence	ENVIRONMENTAL HEALTH PERSPECTIVES			English	Article						bioinformatics; chance correlation; class prediction; classification; decision forest; prediction confidence; prostate cancer; proteomics; SELDI-TOF	GENE-EXPRESSION DATA; ARTIFICIAL NEURAL NETWORKS; PROTEOMIC PATTERNS; TUMOR CLASSIFICATION; MICROARRAY DATA; SERUM; PROFILES	Class prediction using "omics" data is playing an increasing role in toxicogenomics, diagnosis/prognosis, and risk assessment. These data are usually noisy and represented by relatively few samples and a very large number of predictor variables (e.g., genes of DNA microarray data or m/z peaks of mass spectrometry data). These characteristics manifest the importance of assessing potential random correlation and overfitting of noise for a classification model based on omics data. We present a novel classification method, decision forest (DF), for class prediction using omics data. DF combines the results of multiple heterogeneous but comparable decision tree (DT) models to produce a consensus prediction. The method is less prone to overfitting of noise and chance correlation. A DF model was developed to predict presence of prostate cancer using a proteomic data set generated from surface-enhanced laser deposition/ ionization time-of-flight mass spectrometry (SELDI-TOF MS). The degree of chance correlation and prediction confidence of the model was rigorously assessed by extensive cross-validation and randomization testing. Comparison of model prediction with imposed random correlation demonstrated biologic relevance of the model and the reduction of overfitting in DF. Furthermore, two confidence levels (high and low confidences) were assigned to each prediction, where most misclassifications were associated with the low-confidence region. For the high-confidence prediction, the model achieved 99.2% sensitivity and 98.2% specificity. The model also identified a list of significant peaks that could be useful for biomarker identification. DF should be equally applicable to other omics data such as gene expression data or metabolomic data. The DF algorithm is available upon request.	Natl Ctr Toxicol Res, Ctr Toxicoinformat, Div Biometry & Risk Assessment, Jefferson, AR 72079 USA; Natl Ctr Toxicol Res, Bioinformat Grp, Jefferson, AR 72079 USA; US FDA, Ctr Biol Evaluat & Res, Bethesda, MD 20014 USA	Tong, WD (reprint author), Natl Ctr Toxicol Res, Ctr Toxicoinformat, Div Biometry & Risk Assessment, Jefferson, AR 72079 USA.	wtong@nctr.fda.gov	Shi, Leming/B-3150-2010				Adam BL, 2002, CANCER RES, V62, P3609; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1995, CART CLASSIFICATION; Breiman L, 1999, 567 U CAL DEP STAT; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BUNN DW, 1988, EUR J OPER RES, V33, P223, DOI 10.1016/0377-2217(88)90165-8; Bunn D. W., 1987, JUDGEMENTAL FORECAST, P229; CLARK LA, 1997, MODERN APPL STAT S P; CLEMEN RT, 1989, INT J FORECASTING, V5, P559, DOI 10.1016/0169-2070(89)90012-5; Diamandis EP, 2003, CLIN CHEM, V49, P1272, DOI 10.1373/49.8.1272; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Good P. I., 1994, PERMUTATION TESTS PR; Gunther EC, 2003, P NATL ACAD SCI USA, V100, P9608, DOI 10.1073/pnas.1632587100; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Olshen AB, 2002, BIOINFORMATICS, V18, P961, DOI 10.1093/bioinformatics/18.7.961; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; Simon R, 2003, J NATL CANCER I, V95, P14; Slonim DK, 2002, NAT GENET, V32, P502, DOI 10.1038/ng1033; Tong W, 2003, ENVIRON TOXICOL CHEM, V22, P1680, DOI 10.1897/01-198; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; Zhang HP, 2003, P NATL ACAD SCI USA, V100, P4168, DOI 10.1073/pnas.0230559100; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	30	26	31	US DEPT HEALTH HUMAN SCIENCES PUBLIC HEALTH SCIENCE	RES TRIANGLE PK	NATL INST HEALTH, NATL INST ENVIRONMENTAL HEALTH SCIENCES, PO BOX 12233, RES TRIANGLE PK, NC 27709-2233 USA	0091-6765			ENVIRON HEALTH PERSP	Environ. Health Perspect.	NOV	2004	112	16					1622	1627		10.1289/txg.7109		6	Environmental Sciences; Public, Environmental & Occupational Health; Toxicology	Environmental Sciences & Ecology; Public, Environmental & Occupational Health; Toxicology	878WT	WOS:000225678800014	15598613	
J	Guha, R; Jurs, PC				Guha, R; Jurs, PC			Development of linear, ensemble, and nonlinear models for the prediction and interpretation of the biological activity of a set of PDGFR inhibitors	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							GROWTH-FACTOR RECEPTOR; TYROSINE KINASE INHIBITORS; SELECTIVE INHIBITORS; CRYSTAL-STRUCTURE; QSAR MODELS; IDENTIFICATION; POTENT; REGRESSION; 4-PIPERAZINYLQUINAZOLINES; ANGIOGENESIS	A QSAR modeling Study has been done with a set of 79 piperazyinylquinazoline analogues which exhibit PDGFR inhibition. Linear regression and nonlinear computational neural network models were developed. The regression model was developed with a focus on interpretative ability using a PLS technique. However, it also exhibits a good predictive ability after outlier removal. The nonlinear CNN model had superior predictive ability compared to the linear model with a training,, set error of 0.22 log(IC50) units (R-2 = 0.93) and a prediction set error of 0.32 log(IC50) units (R-2 = 0.61). A random forest model was also developed to provide an alternate measure of descriptor importance. This approach ranks descriptors, and its results confirm the importance of specific descriptors as characterized by the PLS technique. In addition the neural network model contains the two most important descriptors indicated by the random forest model.	Penn State Univ, Dept Chem, University Pk, PA 16802 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, University Pk, PA 16802 USA.						BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Boschelli DH, 1998, J MED CHEM, V41, P4365, DOI 10.1021/jm980398y; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; CRAMER RD, 1988, QUANT STRUCT-ACT REL, V7, P18, DOI 10.1002/qsar.19880070105; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; DELANO WL, PYMOL MOL GRAPHICS G; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Goldberg D. E., 2000, GENETIC ALGORITHMS S; Goldstein H., 1950, CLASSICAL MECH; Guha R, 2004, J CHEM INF COMP SCI, V44, P1440, DOI 10.1021/ci0499469; Hawkins DM, 1997, QUANT STRUCT-ACT REL, V16, P296, DOI 10.1002/qsar.19970160404; *HYP INC, HYP V 6 01; IIDA H, 1991, P NATL ACAD SCI USA, V88, P6560, DOI 10.1073/pnas.88.15.6560; Jurs P, 1979, COMPUTER ASSISTED DR; Khadikar PV, 2003, BIOORG MED CHEM LETT, V13, P3009, DOI 10.1016/S0960-894X(03)00636-X; Kier L., 1986, MOL CONNECTIVITY STR; Kier L. B., 1975, J PHARM SCI, V64; KIER LB, 1976, J PHARM SCI, V65, P1806, DOI 10.1002/jps.2600651228; KIER LB, 1976, MOL CONNECTIONS CHEM; Klutchko SR, 1998, J MED CHEM, V41, P3276, DOI 10.1021/jm9802259; Kraker AJ, 2000, BIOCHEM PHARMACOL, V60, P885, DOI 10.1016/S0006-2952(00)00405-6; Kubo K, 1997, BIOORG MED CHEM LETT, V7, P2935, DOI 10.1016/S0960-894X(97)10117-2; Kurup A, 2001, CHEM REV, V101, P2573, DOI 10.1021/cr010154c; Lang WP, 2001, MIDDLE EAST POLICY, V8, P1, DOI 10.1111/1475-4967.00014; Liu SS, 1998, J CHEM INF COMP SCI, V38, P387, DOI 10.1021/ci970109z; Lokker NA, 1997, J BIOL CHEM, V272, P33037, DOI 10.1074/jbc.272.52.33037; LU X, 1994, ENVIRON TOXICOL CHEM, V13, P841; Matsuno K, 2002, J MED CHEM, V45, P3057, DOI 10.1021/jm010428o; MATTIONI BE, 2003, DEV QUANTITATIVE STR; McTigue MA, 1999, STRUCT FOLD DES, V7, P319, DOI 10.1016/S0969-2126(99)80042-2; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; *MIN MIN INC, MIN V 14; Mohammadi M, 1998, EMBO J, V17, P5896, DOI 10.1093/emboj/17.20.5896; Palmer BD, 1999, J MED CHEM, V42, P2373, DOI 10.1021/jm980658b; Pandey A, 2002, J MED CHEM, V45, P3772, DOI 10.1021/jm020143r; PEARLMAN RS, 1980, PHYS CHEM PROPERTIES; RANDIC M, 1984, J CHEM INF COMP SCI, V24, P164, DOI 10.1021/ci00043a009; Schapire RE, 1999, P 16 INT JOINT C ART; SCHLESSINGER J, 1992, NEURON, V9, P383, DOI 10.1016/0896-6273(92)90177-F; Shen Q, 2003, EUR J PHARM SCI, V20, P63, DOI 10.1016/S0928-0987(03)00170-2; STANTON DT, 2004, J CHEM INF COMPUTER; STANTON DT, 1990, ANAL CHEM, V62, P2323, DOI 10.1021/ac00220a013; Stanton DT, 2003, J CHEM INF COMP SCI, V43, P1423, DOI 10.1021/ci0340658; Stuper A. J., 1979, COMPUTER ASSISTED ST; SUTTER JM, 1997, THSIS PENNSYLVANIA S; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; WESSEL MD, 1994, ANAL CHEM, V66, P2480, DOI 10.1021/ac00087a012; WESSEL MD, 1997, CHEM PENNSYLVANIA ST; Wildman SA, 1999, J CHEM INF COMP SCI, V39, P868, DOI 10.1021/ci990307l	53	53	55	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338			J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	NOV-DEC	2004	44	6					2179	2189		10.1021/ci049849f		11	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	875HQ	WOS:000225411300032	15554688	
J	Mevik, BH; Segtnan, VH; Naes, T				Mevik, BH; Segtnan, VH; Naes, T			Ensemble methods and partial least squares regression	JOURNAL OF CHEMOMETRICS			English	Article						ensemble methods; bootstrap aggregating (bagging); data augmentation; noise addition; partial least squares regression (PLSR)	SIGNAL CORRECTION; MODEL SELECTION; SPECTROSCOPY; CLASSIFIERS	Recently, there has been increased attention in the literature on the use of ensemble methods in multivariate regression and classification. These methods have been shown to have interesting properties for both regression and classification. In particular, they can improve the accuracy of unstable predictors. Ensemble methods have so far been little studied in situations that are common for calibration and prediction in chemistry, i.e. situations with a large number of collinear x-variables and few samples. These situations are often approached by data compression methods such as principal component regression (PCR) or partial least squares regression (PLSR). The present paper is an investigation of the properties of different types of ensemble methods used with PLSR in situations with highly collinear x-data. Bagging and data augmentation by simulated noise are studied. The focus is on the robustness of the calibrations. Real and simulated data are used. The results show that ensembles trained on data with added noise can make PLSR robust against the type of noise added. In particular, the effects of sample temperature variations can be eliminated. Bagging does not seem to give any improvement over PLSR for small and intermediate numbers of components. It is, however, less sensitive to overfitting. Copyright (C) 2005 John Wiley & Sons, Ltd.	Matforsk, N-1430 As, Norway	Mevik, BH (reprint author), Matforsk, Osloveien 1, N-1430 As, Norway.	bjorn-helge.mevik@matforsk.no					Andersson CA, 1999, CHEMOMETR INTELL LAB, V47, P51, DOI 10.1016/S0169-7439(98)00158-0; Barutcuoglu Z, 2003, LECT NOTES COMPUT SC, V2714, P76; Borra S, 2002, COMPUT STAT DATA AN, V38, P407, DOI 10.1016/S0167-9473(01)00068-8; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; Conlin AK, 1998, CHEMOMETR INTELL LAB, V44, P161, DOI 10.1016/S0169-7439(98)00071-9; Despagne F, 1997, ANAL CHEM, V69, P3391, DOI 10.1021/ac970228d; Elder JF, 2003, J COMPUT GRAPH STAT, V12, P853, DOI 10.1198/1061860032733; Friedman J., 2000, BAGGING NONLINEAR ES; GIBBONS JD, 1992, STAT TXB MONOGRAPHS, V131; Ho TK, 2000, LECT NOTES COMPUT SC, V1857, P97; Kim HC, 2003, PATTERN RECOGN, V36, P2757, DOI 10.1016/S0031-3203(03)00175-4; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Lee S, 2001, NEURAL PROCESS LETT, V14, P157, DOI 10.1023/A:1012403711980; MARTENS H, 1991, J PHARMACEUT BIOMED, V9, P625, DOI 10.1016/0731-7085(91)80188-F; Nas T., 1989, MULTIVARIATE CALIBRA; R Development Core Team, 2003, R LANG ENV STAT COMP; Raviv Y., 1996, Connection Science, V8, DOI 10.1080/095400996116811; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Segtnan VH, 2001, ANAL CHEM, V73, P3153, DOI 10.1021/ac010102n; Song MH, 2002, J CHEM INF COMP SCI, V42, P1347, DOI 10.1021/ci025580t; Valentini G, 2004, NEUROCOMPUTING, V56, P461, DOI 10.1016/j.neucom.2003.09.001; Williams P.C., 2001, NEAR INFRARED TECHNO, Vsecond, P171; Wold S, 1998, CHEMOMETR INTELL LAB, V44, P175, DOI 10.1016/S0169-7439(98)00109-9; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609	29	37	38	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0886-9383			J CHEMOMETR	J. Chemometr.	NOV	2004	18	11					498	507		10.1002/cem.895		10	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	929JA	WOS:000229341200003		
J	Fleuret, F				Fleuret, F			Fast binary feature selection with conditional mutual information	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						classification; mutual information; feature selection; naive Bayes; information theory; fast learning		We propose in this paper a very fast feature selection technique based on conditional mutual information. By picking features which maximize their mutual information with the class to predict conditional to any feature already picked, it ensures the selection of features which are both individually informative and two-by-two weakly dependant. We show that this feature selection method outperforms other classical algorithms, and that a naive Bayesian classifier built with features selected that way achieves error rates similar to those of state-of-the-art methods such as boosting or SVMs. The implementation we propose selects 50 features among 40,000, based on a training set of 500 examples in a tenth of a second on a standard 1Ghz PC.	EPFL, CVLAB, Stn 14, CH-1015 Lausanne, Switzerland	Fleuret, F (reprint author), EPFL, CVLAB, Stn 14, CH-1015 Lausanne, Switzerland.	FRANCOIS.FLEURET@EPFL.CH					Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; BATTIT R, 1994, IEEE T NEURAL NETWOR, V5; BONNLANDER BV, 1996, P ISANN; Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, 567 U CAL DEP STAT; Christiani N., 2000, INTRO SUPPORT VECTOR; Cover T. M., 1991, ELEMENTS INFORM THEO; Das S., 2001, P 18 INT C MACH LEAR, P74; Duda R. O., 1973, PATTERN CLASSIFICATI; FLEURET F, 2002, P ICPR2002, V1, P235; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; FLEURET F, 2003, RR4941 INRIA; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRUEND Y, 1996, P 9 ANN C COMP LEARN, P325; FRUEND Y, 1996, P 13 INT C MACH LEAR, P148; Furey T.S., 2000, BIOINFORMATICS, V16; GUYON I, 2004, P NIPS2004 C; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 1998, ADV NEURAL INFORM PR, V10; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, P 13 INT C MACH LEAR, P284; Langley P., 1992, P 10 NAT C ART INT, P223; Mason L., 2000, NIPS, P512; Miyahara K., 2000, PRICAI 2000. Topics in Artificial Intelligence. 6th Pacific Rim International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol.1886); NOVIKOFF A, 1962, S MATH THEORY AUTOMA, P615; Ratanamahatana C, 2003, APPL ARTIF INTELL, V17, P475, DOI 10.1080/08839510390219327; RATSCH G, 1998, P NIPS, P564; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Torkkola K., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753742; Vapnik V. N., 1998, NATURE STAT LEARNING; Vidal-Naquet M., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Yu L., 2003, P 20 INT C MACH LEAR, P856	33	193	199	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	NOV	2004	5						1531	1555				25	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GW	WOS:000236328400005		
J	Kim, Y; Kim, J				Kim, Yongdai; Kim, Jinseog			Convex Hull Ensemble Machine for Regression and Classification	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						Bagging; Boosting; Classification; Ensemble; Regression		We propose a new ensemble algorithm called Convex Hull Ensemble Machine (CHEM). CHEM in Hilbert space is first developed and modified for regression and classification problems. We prove that the ensemble model converges to the optimal model in Hilbert space under regularity conditions. Empirical studies reveal that, for classification problems, CHEM has a prediction accuracy similar to that of boosting, but CHEM is much more robust with respect to output noise and never overfits datasets even when boosting does. For regression problems, CHEM is competitive with other ensemble methods such as gradient boosting and bagging.	[Kim, Yongdai] Ewha Womans Univ, Dept Stat, Seoul 120750, South Korea; [Kim, Jinseog] Seoul Natl Univ, Dept Stat, Seoul, South Korea	Kim, Y (reprint author), Ewha Womans Univ, Dept Stat, Seoul 120750, South Korea.	ydkim@mm.ewha.ac.kr			U.S. Air Force Research [F62562-02P-0547]; KOSEF	We thank the anonymous reviewers for their very useful comments and suggestions. This research is supported in part by U.S. Air Force Research Grant F62562-02P-0547 and in part by KOSEF through the Statistical Research Center for Complex Systems at Seoul National University.	Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Buhlmann P, 2000, ANN STAT, V28, P377; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Jiang WX, 2002, ANN STAT, V30, P51, DOI 10.1214/aos/1015362184; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Mason L., 2000, ADV LARGE MARGIN CLA; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Quinlan J.R., 1996, LECT NOTES COMPUTER, V1160, P143; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Ridgeway G, 2000, ANN STAT, V28, P393; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 1998, ANN STAT, V26, P1651	18	2	2	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	NOV	2004	6	6					645	663		10.1007/s10115-003-0116-7		19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	V97IC	WOS:000206578200001		
J	Pittman, J; Huang, E; Nevins, J; Wang, QL; West, M				Pittman, J; Huang, E; Nevins, J; Wang, QL; West, M			Bayesian analysis of binary prediction tree models for retrospectively sampled outcomes	BIOSTATISTICS			English	Article						Bayesian analysis; binary classification tree; bioinformatics; case-control design; metagenes; molecular classification; predictive classification; retrospective sampling; tree models	BREAST-CANCER	Classification tree models are flexible analysis tools which have the ability to evaluate interactions among predictors as well as generate predictions for responses of interest. We describe Bayesian analysis of a specific class of tree models in which binary response data arise from a retrospective case-control design. We are also particularly interested in problems with potentially very many candidate predictors. This scenario is common in studies concerning gene expression data, which is a key motivating example context. Innovations here include the introduction of tree models that explicitly address and incorporate the retrospective design, and the use of nonparametric Bayesian models involving Dirichlet process priors on the distributions of predictor variables. The model specification influences the generation of trees through Bayes' factor based tests of association that determine significant binary partitions of nodes during a process of forward generation of trees. We describe this constructive process and discuss questions of generating and combining multiple trees via Bayesian model averaging for prediction. Additional discussion of parameter selection and sensitivity is given in the context of an example which concerns prediction of breast tumour status utilizing high-dimensional gene expression data; the example demonstrates the exploratory/explanatory uses of such models as well as their primary utility in prediction. Shortcomings of the approach and comparison with alternative tree modelling algorithms are also discussed, as are issues of modelling and computational extensions.	Duke Univ, Inst Stat & Decis Sci, Durham, NC 27708 USA; Duke Univ, Dept Surg, Durham, NC 27708 USA; Duke Univ, Dept Mol Genet & Microbiol, Durham, NC 27708 USA; Duke Univ, Computat & Appl Genom Program, Durham, NC 27708 USA; Duke Univ, Inst Stat & Decis Sci, Durham, NC 27708 USA	Pittman, J (reprint author), Duke Univ, Inst Stat & Decis Sci, Durham, NC 27708 USA.	jennifer@stat.duke.edu	Huang, Erich/B-1894-2008	Huang, Erich/0000-0001-5547-9408			Boulesteix AL, 2003, BIOINFORMATICS, V19, P2465, DOI 10.1093/bioinformatics/btg361; Box GEP, 1992, BAYESIAN INFERENCE S; BREIMAN L, 2004, RANDOM FOREST PACKAG; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; CLARK L. A., 1992, STAT MODELS S, P377; Denison DGT, 1998, BIOMETRIKA, V85, P363; Hastie R., 2001, ELEMENTS STAT LEARNI; Hastie T, 2001, GENOME BIOL, V2; Huang E, 2003, LANCET, V361, P1590, DOI 10.1016/S0140-6736(03)13308-9; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; R Development Core Team, 2003, R LANG ENV STAT COMP; Raftery AE, 1997, J AM STAT ASSOC, V92, P179, DOI 10.2307/2291462; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Selke T, 2001, AM STAT, V55, P62; SEO D, 2003, GENE EXPRESSION PHEN; West M., 2003, BAYESIAN STAT, P733; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998	21	24	26	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1465-4644			BIOSTATISTICS	Biostatistics	OCT	2004	5	4					587	601		10.1093/biostatistics/kxh011		15	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	865GD	WOS:000224689700007	15475421	
J	Wei, G; Cosman, P; Berry, CC; Feng, ZY; Schafer, WR				Wei, G; Cosman, P; Berry, CC; Feng, ZY; Schafer, WR			Automatic tracking, feature extraction and classification of C-elegans phenotypes	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article; Proceedings Paper	37th Asilomar Conference on Signals, Systems and Computers	NOV 09-12, 2003	Pacific Grove, CA			C. elegans; classification; computer vision; data mining; feature extraction; image processing; Random Forests; tracking	NEMATODE CAENORHABDITIS-ELEGANS; BEHAVIOR; DROSOPHILA; RESPONSES; SEROTONIN; COCAINE; GENES	This paper presents a method for automatic tracking of the head, tail, and entire body movement of the nematode Caenorhabditis elegans (C. elegans) using computer vision and digital image analysis techniques. The characteristics of the worm's movement, posture and texture information were extracted from a 5-min image sequence. A Random Forests classifier was then used to identify the worm type, and the features that best describe the data. A total of 1597 individual worm video sequences, representing wild type and 15 different mutant types, were analyzed. The average correct classification ratio, measured by out-of-bag (OOB) error rate, was 90.9%. The features that have most discrimination ability were also studied. The algorithm developed will be an essential part of a completely automated C elegans tracking and identification system.	Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; Univ Calif San Diego, Div Biostat, Dept Family & Prevent Med, La Jolla, CA 92093 USA; Univ Calif San Diego, Div Biol, La Jolla, CA 92093 USA	Wei, G (reprint author), ID Analyt Inc, San Diego, CA 92193 USA.	wei_geng@yahoo.com					ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023; BAEK J, 2002, J NEUROSCI METH, V118, P921; Bainton RJ, 2000, CURR BIOL, V10, P187, DOI 10.1016/S0960-9822(00)00336-5; Breiman L, 2002, MANUAL SETTING UP US; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRENNER S, 1974, GENETICS, V77, P77; Bylander T, 2002, MACH LEARN, V48, P287, DOI 10.1023/A:1013964023376; de Bono M, 1998, CELL, V94, P679, DOI 10.1016/S0092-8674(00)81609-8; Dhawan R, 1999, J TOXICOL ENV HEAL A, V58, P451, DOI 10.1080/009841099157179; Duda R. O., 2002, PATTERN CLASSIFICATI; FRASER A, 2001, NATURE, V408, P325; Geng W, 2003, GENETICS, V165, P1117; GENG W, EUROSIP J APPL SIGNA; Gonzalez R. C., 2002, DIGITAL IMAGE PROCES; Hardaker LA, 2001, J NEUROBIOL, V49, P303, DOI 10.1002/neu.10014; Hastie T., 2002, ELEMENTS STAT LEARNI; HODGKIN J, 1983, GENETICS, V103, P43; Jain R., 1995, MACHINE VISION; Kim J, 2001, GENETICS, V157, P1599; Liaw A., 2002, CLASSIFICATION REGRE, P18; McClung C, 1998, CURR BIOL, V8, P109, DOI 10.1016/S0960-9822(98)70041-7; Pierce-Shimomura JT, 1999, J NEUROSCI, V19, P9557; SULSTON JE, 1983, DEV BIOL, V100, P64, DOI 10.1016/0012-1606(83)90201-4; SULSTON JE, 1977, DEV BIOL, V56, P110, DOI 10.1016/0012-1606(77)90158-0; Waggoner LE, 1998, NEURON, V21, P203, DOI 10.1016/S0896-6273(00)80527-9; WHITEHEAD PJP, 1986, FISHES NE ATLANTIC M, V3, P1; Zhou GT, 1998, IEEE T SIGNAL PROCES, V46, P2698, DOI 10.1109/78.720372; Zipperlen P, 2001, EMBO J, V20, P3984, DOI 10.1093/emboj/20.15.3984	29	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294			IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	OCT	2004	51	10					1811	1820		10.1109/TBME.2004.831532		10	Engineering, Biomedical	Engineering	855VB	WOS:000224001900012		
J	Cummings, MP; Segal, MR				Cummings, MP; Segal, MR			Few amino acid positions in rpoB are associated with most of the rifampin resistance in Mycobacterium tuberculosis	BMC BIOINFORMATICS			English	Article							SUSCEPTIBILITY; MUTATIONS	Background: Mutations in rpoB, the gene encoding the beta subunit of DNA-dependent RNA polymerase, are associated with rifampin resistance in Mycobacterium tuberculosis. Several studies have been conducted where minimum inhibitory concentration ( MIC, which is defined as the minimum concentration of the antibiotic in a given culture medium below which bacterial growth is not inhibited) of rifampin has been measured and partial DNA sequences have been determined for rpoB in different isolates of M. tuberculosis. However, no model has been constructed to predict rifampin resistance based on sequence information alone. Such a model might provide the basis for quantifying rifampin resistance status based exclusively on DNA sequence data and thus eliminate the requirements for time consuming culturing and antibiotic testing of clinical isolates. Results: Sequence data for amino acid positions 511-533 of rpoB and associated MIC of rifampin for different isolates of M. tuberculosis were taken from studies examining rifampin resistance in clinical samples from New York City and throughout Japan. We used tree-based statistical methods and random forests to generate models of the relationships between rpoB amino acid sequence and rifampin resistance. The proportion of variance explained by a relatively simple tree-based cross-validated regression model involving two amino acid positions (526 and 531) is 0.679. The first partition in the data, based on position 531, results in groups that differ one hundredfold in mean MIC (1.596 mug/ml and 159.676 mug/ml). The subsequent partition based on position 526, the most variable in this region, results in a > 354-fold difference in MIC. When considered as a classification problem ( susceptible or resistant), a cross-validated tree-based model correctly classified most (0.884) of the observations and was very similar to the regression model. Random forest analysis of the MIC data as a continuous variable, a regression problem, produced a model that explained 0.861 of the variance. The random forest analysis of the MIC data as discrete classes produced a model that correctly classified 0.942 of the observations with sensitivity of 0.958 and specificity of 0.885. Conclusions: Highly accurate regression and classification models of rifampin resistance can be made based on this short sequence region. Models may be better with improved ( and consistent) measurements of MIC and more sequence data.	Univ Maryland, Ctr Bioinformat & Computat Biol, College Pk, MD 20742 USA; Univ Calif San Francisco, Dept Epidemiol & Biostat, San Francisco, CA 94143 USA	Cummings, MP (reprint author), Univ Maryland, Ctr Bioinformat & Computat Biol, College Pk, MD 20742 USA.	mike@umiacs.umd.edu; mark@biostat.ucsf.edu					BASS JB, 1994, AM J RESP CRIT CARE, V149, P1359; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 2004, RPART PACKAGE RECURS; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Clark LA, 1993, STAT MODELS S, P377; CUMMINGS MP, 2004, CSTR4581; Cummings MP, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-132; Efron B, 1993, INTRO BOOTSTRAP; Espinal MA, 2001, NEW ENGL J MED, V344, P1294, DOI 10.1056/NEJM200104263441706; Hastie T., 2001, ELEMENTS STAT LEARNI; HEIFETS L, 1988, AM REV RESPIR DIS, V137, P1217; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Moghazeh SL, 1996, ANTIMICROB AGENTS CH, V40, P2655; MYERS DS, 2004, CSTR4584; Ohno H, 1997, AM J RESP CRIT CARE, V155, P2057; Segal MR, 2001, BIOMETRICS, V57, P632, DOI 10.1111/j.0006-341X.2001.00632.x; SEGAL MR, 2004, STAT APPL GENETICS M, V3; Siddiqi N, 2002, ANTIMICROB AGENTS CH, V46, P443, DOI 10.1128/AAC.46.2.443-450.2002; Taniguchi H, 1996, FEMS MICROBIOL LETT, V144, P103, DOI 10.1016/0378-1097(96)00346-1; Therneau TM, 1997, INTRO RECURSIVE PART; THERNEAU TM, 2003, RPART PACKAGE RECURS; Williams DL, 1998, ANTIMICROB AGENTS CH, V42, P1853	25	15	17	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 28	2004	5								137	10.1186/1471-2105-5-137		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	868VC	WOS:000224940100001	15453919	
J	Cummings, MP; Myers, DS				Cummings, MP; Myers, DS			Simple statistical models predict C-to-U edited sites in plant mitochondrial RNA	BMC BIOINFORMATICS			English	Article							WHEAT MITOCHONDRIA; LAND PLANTS; CHLOROPLASTS; RECOGNITION; SEQUENCE; EVOLUTION; ELEMENTS; GENOME; L.	Background: RNA editing is the process whereby an RNA sequence is modified from the sequence of the corresponding DNA template. In the mitochondria of land plants, some cytidines are converted to uridines before translation. Despite substantial study, the molecular biological mechanism by which C-to-U RNA editing proceeds remains relatively obscure, although several experimental studies have implicated a role for cis-recognition. A highly non-random distribution of nucleotides is observed in the immediate vicinity of edited sites (within 20 nucleotides 5' and 3'), but no precise consensus motif has been identified. Results: Data for analysis were derived from the the complete mitochondrial genomes of Arabidopsis thaliana, Brassica napus, and Oryza sativa; additionally, a combined data set of observations across all three genomes was generated. We selected datasets based on the 20 nucleotides 5' and the 20 nucleotides 3' of edited sites and an equivalently sized and appropriately constructed null-set of non-edited sites. We used tree-based statistical methods and random forests to generate models of C-to-U RNA editing based on the nucleotides surrounding the edited/non-edited sites and on the estimated folding energies of those regions. Tree-based statistical methods based on primary sequence data surrounding edited/non-edited sites and estimates of free energy of folding yield models with optimistic re-substitution-based estimates of similar to0.71 accuracy, similar to0.64 sensitivity, and similar to0.88 specificity. Random forest analysis yielded better models and more exact performance estimates with similar to0.74 accuracy, similar to0.72 sensitivity, and similar to0.81 specificity for the combined observations. Conclusions: Simple models do moderately well in predicting which cytidines will be edited to uridines, and provide the first quantitative predictive models for RNA edited sites in plant mitochondria. Our analysis shows that the identity of the nucleotide -1 to the edited C and the estimated free energy of folding for a 41 nt region surrounding the edited C are the most important variables that distinguish most edited from non-edited sites. However, the results suggest that primary sequence data and simple free energy of folding calculations alone are insufficient to make highly accurate predictions.	Univ Maryland, Ctr Bioinformat & Computat Biol, College Pk, MD 20742 USA	Cummings, MP (reprint author), Univ Maryland, Ctr Bioinformat & Computat Biol, College Pk, MD 20742 USA.	mike@umiacs.umd.edu; dmyers@umiacs.umd.edu					ARYA A, 1995, BIOCHIMIE, V77, P87; Benson DA, 2004, NUCLEIC ACIDS RES, V32, pD23, DOI 10.1093/nar/gkh045; BLANC V, 1995, FEBS LETT, V373, P56, DOI 10.1016/0014-5793(95)00991-H; BREIMAN L, 2001, 567 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Carrillo C, 1997, NUCLEIC ACIDS RES, V25, P403, DOI 10.1093/nar/25.2.403; Chateigner-Boutin AL, 2002, MOL CELL BIOL, V22, P8448, DOI 10.1128/MCB.22.24.8448-8456.2002; Clark L.A., 1993, STAT MODELS S; CUMMINGS MP, 2004, CSTR4581 U MAR I ADV; Farre JC, 2001, MOL CELL BIOL, V21, P6731, DOI 10.1128/MCB.21.20.6731-6737.2001; Freyer R, 1997, P NATL ACAD SCI USA, V94, P6285, DOI 10.1073/pnas.94.12.6285; Giege P, 1999, P NATL ACAD SCI USA, V96, P15324, DOI 10.1073/pnas.96.26.15324; GRAY MW, 1993, FASEB J, V7, P64; Gray MW, 2003, IUBMB LIFE, V55, P227, DOI 10.1080/1521654031000119425; Gray MW, 1996, P NATL ACAD SCI USA, V93, P8157, DOI 10.1073/pnas.93.16.8157; GUALBERTO JM, 1989, NATURE, V341, P660, DOI 10.1038/341660a0; Handa H, 2003, NUCLEIC ACIDS RES, V31, P5907, DOI 10.1093/nar/gkg795; Hastie T., 2001, ELEMENTS STAT LEARNI; HIESEL R, 1994, P NATL ACAD SCI USA, V91, P629, DOI 10.1073/pnas.91.2.629; HIESEL R, 1989, SCIENCE, V246, P1632, DOI 10.1126/science.2480644; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Maier RM, 1996, PLANT MOL BIOL, V32, P343, DOI 10.1007/BF00039390; Malek O, 1996, EMBO J, V15, P1403; MATHEWS DH, 1999, J MOL BIOL, V288, P910; Mulligan RM, 1999, J HERED, V90, P338, DOI 10.1093/jhered/90.3.338; Notsu Y, 2002, MOL GENET GENOMICS, V268, P434, DOI 10.1007/s00438-002-0767-1; RAJASEKHAR VK, 1993, PLANT CELL, V5, P1843; Segal MR, 2001, BIOMETRICS, V57, P632, DOI 10.1111/j.0006-341X.2001.00632.x; Smith HC, 1997, RNA, V3, P1105; Therneau TM, 1997, INTRO RECURSIVE PART; Wakasugi T, 1996, P NATL ACAD SCI USA, V93, P8766, DOI 10.1073/pnas.93.16.8766; Williams MA, 1998, PLANT MOL BIOL, V36, P229, DOI 10.1023/A:1005961718612; YU W, 1995, J BIOL CHEM, V270, P18227; YU W, 1995, BIOCHIMIE, V77, P79, DOI 10.1016/0300-9084(96)88108-9; Zuker M, 1999, NATO SCI PARTNERSHIP, V70, P11	37	26	27	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 16	2004	5								132	10.1186/1471-2105-5-132		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	863PZ	WOS:000224575400001	15373947	
J	Ishwaran, H; Blackstone, EH; Pothier, CE; Lauer, MS				Ishwaran, H; Blackstone, EH; Pothier, CE; Lauer, MS			Relative risk forests for exercise heart rate recovery as a predictor of mortality	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						cox regression; MARS; proportional hazards; random forests; relative risk trees; stochastic variable selection.	PRACTICE GUIDELINES COMMITTEE; ADAPTIVE REGRESSION SPLINES; ASSOCIATION TASK-FORCE; ALL-CAUSE MORTALITY; BAROREFLEX SENSITIVITY; TREADMILL EXERCISE; AMERICAN-COLLEGE; RATE-VARIABILITY; MODEL SELECTION; INFARCTION	Recent studies have confirmed heart rate fall after treadmill exercise testing, or heart rate recovery, as a powerful predictor of mortality from heart disease. Heart rate recovery depends on central reactivation of vagal tone and decreased vagal activity is a risk factor for death. If heart rate recovery is defined as the fall in heart rate after I minute following peak exercise, then a heart rate recovery value of 12 beats per minute (bpm) or lower has been shown to be a good prognostic threshold for identifying patients at high risk. Although this finding establishes a simple, useful relationship between heart recovery and mortality, a working understanding of how heart rate recovery interacts with other characteristics of a patient in determining risk of death is still largely unexplored. Such knowledge, addressed in this article, could improve the prognostic value of the exercise test. Our analysis is based on over 23,000 patients who underwent exercise testing. A rich assortment of data was collected on these patients, including clinical and physiological information, heart rate recovery, and other exercise test performance measures. Our approach was to grow relative risk forests, a novel method that combines random forest methodology with survival trees grown using Poisson likelihoods. Our analysis reveals a complex relationship between peak heart rate, age, level of fitness, heart rate recovery, and risk of death.	Cleveland Clin Fdn, Dept Biostat & Epidemiol, Cleveland, OH 44195 USA; Cleveland Clin Fdn, Dept Thorac & Cardiac Surg, Cleveland, OH 44195 USA; Cleveland Clin Fdn, Dept Cardiovasc Med, Cleveland, OH 44195 USA	Ishwaran, H (reprint author), Cleveland Clin Fdn, Dept Biostat & Epidemiol, 9500 Euclid Ave, Cleveland, OH 44195 USA.	ishwaran@bio.ri.ccf.org	Lauer, Michael/L-9656-2013	Lauer, Michael/0000-0002-9217-8177			AALEN O, 1978, ANN STAT, V6, P701, DOI 10.1214/aos/1176344247; Aitkin M., 1980, Applied Statistics, V29, DOI 10.2307/2986301; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Arai Y, 1989, AM J PHYSIOL, V256, P132; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breslow NE, 1972, J R STAT SOC B, V34, P216; CLAYTON D, 1985, APPL STAT-J ROY ST C, V34, P148, DOI 10.2307/2347367; Cole CR, 2000, ANN INTERN MED, V132, P552; Cole CR, 1999, NEW ENGL J MED, V341, P1351, DOI 10.1056/NEJM199910283411804; COX DR, 1972, J R STAT SOC B, V34, P187; Diaz LA, 2001, J AM COLL CARDIOL, V37, P1558, DOI 10.1016/S0735-1097(01)01205-0; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gibbons RJ, 2002, J AM COLL CARDIOL, V40, P1531, DOI 10.1016/S0735-1097(02)02164-2; Gibbons RJ, 2002, CIRCULATION, V106, P1883, DOI 10.1161/01.CIR.0000034670.06526.15; Gibbons RJ, 1997, J AM COLL CARDIOL, V30, P260; HAMMOND HK, 1985, PROG CARDIOVASC DIS, V27, P271, DOI 10.1016/0033-0620(85)90010-6; Hastie T., 2001, ELEMENTS STAT LEARNI; IMAI K, 1994, J AM COLL CARDIOL, V24, P1529; ISHWARAN H, 2000, UNPUB BAYESIAN NONPA; Ishwaran H, 2003, J AM STAT ASSOC, V98, P438, DOI 10.1198/016214503000224; KOOPERBERG C, 1995, J AM STAT ASSOC, V90, P78, DOI 10.2307/2291132; La Rovere MT, 2001, CIRCULATION, V103, P2072; La Rovere MT, 1998, LANCET, V351, P478; Lauer MS, 1996, CIRCULATION, V93, P1520; Lauer MS, 1999, JAMA-J AM MED ASSOC, V281, P524, DOI 10.1001/jama.281.6.524; Lauer Michael S., 2001, Cardiology Clinics, V19, P401, DOI 10.1016/S0733-8651(05)70225-3; Lauer MS, 2002, CIRCULATION, V106, P685, DOI 10.1161/01.CIR.0000024410.15081.FD; LeBlanc M, 1999, BIOMETRICS, V55, P204, DOI 10.1111/j.0006-341X.1999.00204.x; LEBLANC M, 1992, BIOMETRICS, V48, P411, DOI 10.2307/2532300; Nishime EO, 2000, JAMA-J AM MED ASSOC, V284, P1392, DOI 10.1001/jama.284.11.1392; SCHWARTZ PJ, 1992, CIRCULATION, V85, P77; Shetler K, 2001, J AM COLL CARDIOL, V38, P1980, DOI 10.1016/S0735-1097(01)01652-7; Snader CE, 1997, J AM COLL CARDIOL, V30, P641, DOI 10.1016/S0735-1097(97)00217-9; Therneau TM, 1997, TECHNICAL REPORT SER, V61; Watanabe J, 2001, CIRCULATION, V104, P1911; Williams SV, 2001, ANN INTERN MED, V135, P530	38	12	13	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	SEP	2004	99	467					591	600		10.1198/016214504000000638		10	Statistics & Probability	Mathematics	853VR	WOS:000223857500006		
J	Kim, HL; Seligson, D; Liu, XL; Janzen, N; Bui, MHT; Yu, H; Shi, T; Figlin, RA; Horvath, S; Belldegrun, AS				Kim, HL; Seligson, D; Liu, XL; Janzen, N; Bui, MHT; Yu, H; Shi, T; Figlin, RA; Horvath, S; Belldegrun, AS			Using protein expressions to predict survival in clear cell renal carcinoma	CLINICAL CANCER RESEARCH			English	Article							TUMOR-SUPPRESSOR GENE; RECOMBINANT INTERLEUKIN-2; CLINICAL-SIGNIFICANCE; RANDOMIZED-TRIAL; BREAST-CANCER; PTEN/MMAC1; PROGNOSIS; P53; IDENTIFICATION; ANTIBODY	Purpose: An accurate system for predicting survival for patients with solid tumors will allow for better patient selection for both established and novel therapies. We propose a staging system for clear cell variants of renal cell carcinoma (RCC) that includes molecular predictors and standard clinical predictors such as tumor-node-metastasis (TNM) stage, histological grade, and performance status (PS). Experimental Design: A custom tissue array was constructed using clear cell RCC from 318 patients, representing all stages of localized and metastatic RCC, and immunohistochemically stained for molecular markers Ki67, p53, gelsolin, CA9, CA12, PTEN, EpCAM, and vimentin. We present a strategy for evaluating individual candidate markers for prognostic information and integrating informative markers into a multivariate prognostic system. Results: The overall median follow-up and the median follow-up for surviving patients were 28 and 55 months, respectively. A prognostic model based primarily on molecular markers included metastasis status, p53, CA9, gelsolin, and vimentin as predictors and had high discriminatory power: its statistically validated concordance index (C-index) was found to be 0.75. A prognostic model based on a combination of clinical and molecular predictors included metastasis status, T stage, Eastern Cooperative Oncology Group PS, p53, CA9, and vimentin as predictors and had a C-index of 0.79, which was significantly higher (P < 0.05) than that of prognostic models based on grade alone (C = 0.65), TNM stage alone (C = 0.73), or the University of California Los Angeles integrated staging system (C = 0.76). Conclusions: Protein expressions obtained using widely available technology can complement standard clinical predictors such as TNM stage, histological grade, and PS.	Univ Calif Los Angeles, Sch Med, Dept Urol, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Sch Med, Dept Pathol & Lab Med, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Sch Med, Dept Biostat, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Sch Med, Dept Human Genet & Biostat, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Sch Med, Dept Med & Urol, Los Angeles, CA 90095 USA	Belldegrun, AS (reprint author), Univ Calif Los Angeles, Sch Med, Dept Urol, 10833 Le Conte Ave,Room 66-118 CHS, Los Angeles, CA 90095 USA.	Abelldegrun@mednet.ucla.edu					Alimov A, 1999, ANTICANCER RES, V19, P3841; Belldegrun A, 1998, CAMPBELLS UROLOGY, P2283; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bui MHT, 2003, CLIN CANCER RES, V9, P802; DELAHUNT B, 1995, CANCER, V75, P2714, DOI 10.1002/1097-0142(19950601)75:11<2714::AID-CNCR2820751113>3.0.CO;2-X; Fisher RI, 2000, CANCER J SCI AM, V6, pS55; FUHRMAN SA, 1982, AM J SURG PATHOL, V6, P655, DOI 10.1097/00000478-198210000-00007; GNARRA JR, 1994, NAT GENET, V7, P85, DOI 10.1038/ng0594-85; Guinan P, 1997, CANCER, V80, P992, DOI 10.1002/(SICI)1097-0142(19970901)80:5<992::AID-CNCR26>3.0.CO;2-Q; HANLEY JA, 1982, RADIOLOGY, V143, P29; Harrell FE, 2001, REGRESSION MODELING; Kattan MW, 2001, J UROLOGY, V166, P63, DOI 10.1016/S0022-5347(05)66077-6; Kononen J, 1998, NAT MED, V4, P844, DOI 10.1038/nm0798-844; LIAO SY, 1994, AM J PATHOL, V145, P598; LIU X, 2003, JOINT STAT M AM STAT; Maehama T, 1998, J BIOL CHEM, V273, P13375, DOI 10.1074/jbc.273.22.13375; Maxwell PH, 1999, NATURE, V399, P271; Maxwell SA, 2003, J BIOL CHEM, V278, P9784, DOI 10.1074/jbc.M210012200; Moch H, 1999, AM J PATHOL, V154, P981, DOI 10.1016/S0002-9440(10)65349-7; OKEN MM, 1982, AM J CLIN ONCOL-CANC, V5, P649, DOI 10.1097/00000421-198212000-00014; Pyrhonen S, 1999, J CLIN ONCOL, V17, P2859; RIETHMULLER G, 1994, LANCET, V343, P1177, DOI 10.1016/S0140-6736(94)92398-1; Rioux-Leclercq N, 2000, UROLOGY, V55, P501, DOI 10.1016/S0090-4295(99)00550-6; ROSENBERG SA, 1985, NEW ENGL J MED, V313, P1485, DOI 10.1056/NEJM198512053132327; Sabo E, 1997, BRIT J UROL, V80, P864, DOI 10.1046/j.1464-410X.1997.00489.x; Selden LA, 1998, BIOPHYS J, V75, P3092; SHETYE J, 1989, ANTICANCER RES, V9, P395; Shieh DB, 1999, CANCER, V85, P47, DOI 10.1002/(SICI)1097-0142(19990101)85:1<47::AID-CNCR7>3.0.CO;2-L; Shiina H, 1997, EUR UROL, V31, P73; Steck PA, 1997, NAT GENET, V15, P356, DOI 10.1038/ng0497-356; Takahashi M, 2003, ADV CANCER RES, V89, P157, DOI 10.1016/S0065-230X(03)01005-4; Uchida T, 2002, UROLOGY, V59, P615, DOI 10.1016/S0090-4295(01)01601-6; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Velickovic M, 2002, MODERN PATHOL, V15, P479, DOI 10.1038/modpathol.3880551; Vogelzang NJ, 1998, LANCET, V352, P1691, DOI 10.1016/S0140-6736(98)01041-1; Zisman A, 2001, J CLIN ONCOL, V19, P1649; ZISMAN A, 2003, RENAL ADRENAL TUMORS, P3	38	143	151	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	AUG 15	2004	10	16					5464	5471		10.1158/1078-0432.CCR-04-0488		8	Oncology	Oncology	848GC	WOS:000223454600022	15328185	
J	Iorgulescu, I; Beven, KJ				Iorgulescu, I; Beven, KJ			Nonparametric direct mapping of rainfall-runoff relationships: An alternative approach to data analysis and modeling?	WATER RESOURCES RESEARCH			English	Article						rainfall-runoff modeling; nonparametric methods; regression trees; input-to-output mapping; Andrews Experimental Forest Watershed	PARAMETER-ESTIMATION; HYDROLOGIC-MODELS; DECISION TREES; CALIBRATION; CLASSIFICATION; UNCERTAINTY; REGRESSION	We present a new approach for the analysis and modeling of catchment rainfall-runoff relationships that uses as predictor variables input history summary variables only. The latter are defined as linear combinations of inputs at a given number of previous time steps. This transforms the dynamic identification problem into a static one. As the identification algorithm we use regression trees, which act as a nonlinear nonparametric model. The original algorithm is adapted to account for serial correlation in variables. The new method is applied to two subcatchments of the U. S. Department of Agriculture Forest Service Andrews Experimental Forest Watershed (Oregon, United States). Simple and interpretable tree models explain more than 80% of the initial deviance of the observations in both calibration and validation. This suggests that the selected variables have a good predictive power and that further modeling attempts using them are warranted. The models show a distinct pattern of the selected explanatory variables. Applications of the method include data quality control, comparative analysis, assessment of hydrological change, and multicriterion evaluation of parametric hydrological models.	Swiss Fed Inst Technol, Inst Environm Sci & Technol, CH-1015 Lausanne, Switzerland; Univ Lancaster, Inst Environm & Nat Sci, Lancaster LA1 4YQ, England	Iorgulescu, I (reprint author), Swiss Fed Inst Technol, Inst Environm Sci & Technol, CH-1015 Lausanne, Switzerland.	ion.iorgulescu@epfl.ch	Beven, Keith/F-8707-2011				Beven K, 2003, WATER RESOUR RES, V39, DOI 10.1029/2001WR001183; Beven K, 2002, P ROY SOC A-MATH PHY, V458, P2465, DOI 10.1098/rspa.2002.0986; Beven KJ, 2000, HYDROL EARTH SYST SC, V4, P203; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Freer J., 2003, WATER SCI APPL, V6, P69, DOI [10.1029/WS006p0069, DOI 10.1029/WS006P0069]; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; FRIEDMAN J.H., 1994, 113 STANF U DEP STAT; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; Gupta HV, 1998, WATER RESOUR RES, V34, P751, DOI 10.1029/97WR03495; HARR RD, 1977, J HYDROL, V33, P37, DOI 10.1016/0022-1694(77)90097-X; HARR RD, 1982, WATER RESOUR RES, V18, P637, DOI 10.1029/WR018i003p00637; HORNBERGER GM, 1985, WATER RESOUR RES, V21, P1841, DOI 10.1029/WR021i012p01841; Hsu KL, 2002, WATER RESOUR RES, V38, DOI 10.1029/2001WR000795; JAKEMAN AJ, 1993, WATER RESOUR RES, V29, P2637, DOI 10.1029/93WR00877; Jones JA, 1996, WATER RESOUR RES, V32, P959, DOI 10.1029/95WR03493; Kavetski D, 2003, WATER RESOUR RES, V39, DOI 10.1029/2003WR002122; Kirkby M.J., 1975, PROCESS PHYS HUMAN G, P69; Quinlan J, 1993, P 10 INT C MACH LEAR, P236; SCHAAL S, 1994, P C AD BEH LEARN CTR, P123; Sjoberg J, 1995, AUTOMATICA, V31, P1691, DOI 10.1016/0005-1098(95)00120-8; SOROOSHIAN S, 1980, WATER RESOUR RES, V16, P430, DOI 10.1029/WR016i002p00430; SPEAR RC, 1994, WATER RESOUR RES, V30, P3159, DOI 10.1029/94WR01732; Suarez A, 1999, IEEE T PATTERN ANAL, V21, P1297, DOI 10.1109/34.817409; Wagener T, 2003, HYDROL PROCESS, V17, P455, DOI 10.1002/hyp.1135; WAICHLER SR, 2002, PNWD3180 PAC NW NAT; WIGMOSTA MS, 1994, WATER RESOUR RES, V30, P1665, DOI 10.1029/94WR00436; Yapo PO, 1996, J HYDROL, V181, P23, DOI 10.1016/0022-1694(95)02918-4; Youngs PC, 2001, MODEL VALIDATION PER, P117	32	15	15	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0043-1397			WATER RESOUR RES	Water Resour. Res.	AUG 10	2004	40	8							W08403	10.1029/2004WR003094		11	Environmental Sciences; Limnology; Water Resources	Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	846VO	WOS:000223346400001		
J	Luo, T; Kramer, K; Goldgof, DB; Hall, LO; Samson, S; Remsen, A; Hopkins, T				Luo, T; Kramer, K; Goldgof, DB; Hall, LO; Samson, S; Remsen, A; Hopkins, T			Recognizing plankton images from the shadow image particle profiling evaluation recorder	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						feature selection; learning; plankton recognition; probabilistic output; support vector machine (SVM)	RECOGNITION; MACHINES	We present a system to recognize underwater plankton images from the shadow image particle profiling evaluation recorder (SIPPER). The challenge of the SIPPER image set is that many images do not have clear contours. To address that, shape features that do not heavily depend on contour information were developed. A soft margin support vector machine (SVM) was used as the classifier. We developed a way to assign probability after multiclass SVM classification. Our approach achieved approximately 90% accuracy on a collection of plankton images. On another larger image set containing manually unidentifiable particles, it also provided 75.6% overall accuracy. The proposed approach was statistically significantly more accurate on the two data sets than a C4.5 decision tree and a cascade correlation neural network. The single SVM significantly outperformed ensembles of decision trees created by bagging and random forests on the smaller data set and was slightly better on the other data set. The 15-feature subset produced by our feature selection approach provided slightly better accuracy than using all 29 features. Our probability model gave us a reasonable rejection curve on the larger data set.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Univ S Florida, Coll Marine Sci, St Petersburg, FL 33701 USA	Luo, T (reprint author), Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.	tluo2@csee.usf.edu; kkramer@csee.usf.edu; goldgof@csee.usf.edu; hall@csee.usf.edu; sainson@seas.marine.usf.edu; areiiisen@seas.marine.usf.edu; thopkins@seas.marine.usf.edu	Rohlf, F/A-8710-2008				Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang C. C., 2002, LIBSVM LIB SUPPORT V; Ciobanu A., 2002, AUTOMATIC DIATOM IDE, P167; Costa L. D. F., 2001, SHAPE ANAL CLASSIFIC; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dietterich TG, 1997, AI MAG, V18, P97; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Fahlman S. E., 1990, ADV NEURAL INFORMATI, V2, P524; Fischer S., 2002, AUTOMATIC DIATOM IDE, P109; Hand D. J., 2001, PRINCIPLES DATA MINI; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; HU M, 1962, IRE T INFORM THEOR, V8, P179; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kreveld M. V., 2001, COMPUTATIONAL GEOMET; Loke R.E., 2002, AUTOMATIC DIATOM IDE, P141; LUO T, 2003, P IEEE INT C SYST MA, P888; Matheron G, 1975, RANDOM SETS INTEGRAL; Pitas I., 2000, DIGITAL IMAGE PROCES; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Platt JC, 2000, ADV NEUR IN, P61; Quinlan J.R., 1993, C4 5 PROGRAMS EMPIRI; Samson S, 2001, IEEE J OCEANIC ENG, V26, P671, DOI 10.1109/48.972110; Santos L.M., 2002, AUTOMATIC DIATOM IDE, P187; TANG X, UNPUB BINARY PLANKTO; Tang XO, 1998, ARTIF INTELL REV, V12, P177, DOI 10.1023/A:1006517211724; Vapnik V, 2000, NATURE STAT LEARNING; WESTON J, 2001, NEURAL INFORM P SYST, V13; Wilkinson M.H.F., 2002, AUTOMATIC DIATOM IDE, P221; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269	30	39	40	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2004	34	4					1753	1762		10.1109/TSMCB.2004.830340		10	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	838NV	WOS:000222721000012	15462442	
J	Morgan, JT; Ham, J; Crawford, MM				Morgan, JT; Ham, J; Crawford, MM			Adaptive feature spaces for land cover classification with limited ground truth data	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						multiclass problems; multiple classifier systems; hierarchical classifiers; error correcting output codes; small sample size problem; remote sensing	STATISTICAL PATTERN-RECOGNITION; HYPERSPECTRAL DATA-ANALYSIS; FEATURE-EXTRACTION; NEURAL NETWORKS; SAMPLES	Classification of land cover based on hyperspectral data is very challenging because typically tens of classes with uneven priors are involved, the inputs are high dimensional, and there is often scarcity of labeled data. Several researchers have observed that it is often preferable to decompose a multiclass problem into multiple two-class problems, solve each such subproblem using a suitable binary classifier, and then combine the outputs of this collection of classifiers in a suitable manner to obtain the answer to the original multiclass problem. This approach is taken by the popular error correcting output codes (ECOC) technique, as well by the binary hierarchical classifier (BHC). Classical techniques for dealing with small sample sizes include regularization of covariance matrices and feature reduction. In this paper we address the twin problems of small sample sizes and multiclass settings by proposing a feature reduction scheme that adaptively adjusts to the amount of labeled data available. This scheme can be used in conjunction with ECOC and the BHC, as well as other approaches such as round-robin classification that decompose a multiclass problem into a number of two (meta)class problems. In particular, we develop the best-basis binary hierarchical classifier (BB-BHC) and best basis ECOC (BB-ECOC) families of models that are adapted to "small sample size" situations. Currently, there are few studies that compare the efficacy of different approaches to multiclass problems in general settings as well as in the specific context of small sample sizes. Our experiments on two sets of remote sensing data show that both BB-BHC and BB-ECOC methods are superior to their nonadaptive versions when faced with limited data, with the BB-BHC showing a slight edge in terms of classification accuracy as well as interpretability.	Univ Texas, Ctr Space Res, Austin, TX 78712 USA; Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA	Morgan, JT (reprint author), Univ Texas, Ctr Space Res, Austin, TX 78712 USA.	Joseph.Morgan1@scott.af.mil; jham@csr.utexas.edu; Crawford@csr.utexas.edu					ANAND R, 1995, IEEE T NEURAL NETWOR, V6, P117, DOI 10.1109/72.363444; Anderson T. W., 1984, INTRO MULTIVARIATE S, V2nd; BARNARD E, 1993, IEEE T NEURAL NETWOR, V4, P794, DOI 10.1109/72.248457; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; BREIMAN L, 1999, COMBINING ARTIFICIAL, P331; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cocks T, 1998, P 1 EARSEL WORKSH IM, P37; Crammer K., 2000, COMPUTATIONAL LEARNI, P35; DESA VR, 1994, NEURAL INFORMATION P; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Friedman J., 1996, ANOTHER APPROACH POL; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; GHOSH J, 1994, J INTEL MAT SYST STR, V5, P211, DOI 10.1177/1045389X9400500207; HASTIE T, 1999, P INT JOINT C NEUR N; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jackson Q, 2001, IEEE T GEOSCI REMOTE, V39, P2664, DOI 10.1109/36.975001; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain A., 1986, Plant Cell Incompatibility Newsletter, P1; Jeon B, 1999, IEEE T GEOSCI REMOTE, V37, P1073; Jia X., 1996, THESIS U NEW S WALES; Jia XP, 1999, IEEE T GEOSCI REMOTE, V37, P538; Kittler J, 1986, HDB PATTERN RECOGNIT, P59; KUMAR S, 1999, P IJCNN; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Kumar S, 2000, LECT NOTES COMPUT SC, V1857, P270; KUMAR S, 2000, THESIS U TEXAS AUSTI; Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718; Landgrebe D., 1999, INFORMATION PROCESSI, P3; Lee C, 1997, IEEE T NEURAL NETWOR, V8, P75; LEE CH, 1993, IEEE T PATTERN ANAL, V15, P388, DOI 10.1109/34.206958; McCallum A., 1998, P 15 INT C MACH LEAR, P359; Mitchell T. M., 1999, P 6 INT C COGN SCI; Morgan JT, 2002, LECT NOTES COMPUT SC, V2364, P189; Nilsson N. J., 1965, LEARNING MACHINES FD; Platt JC, 2000, ADV NEUR IN, V12, P547; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; SIMARD P, 1996, NEURAL NETWORKS TRIC, P239; SKURICHINA M, 2001, THESIS VILNIUS STATE; Skurichina M, 1996, P 13 INT C PATT REC, V2, P891, DOI 10.1109/ICPR.1996.547204; Surges Christopher J. C, 1998, ADV KERNEL METHODS S; Tadjudin S, 1999, IEEE T GEOSCI REMOTE, V37, P2113, DOI 10.1109/36.774728; TAUDJUDIN S, 2000, IEEE T GEOSCI REMOT, V38, P439; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839; Turner K., 1999, P INT JOINT C NEUR N; USTUN R, 2000, THESIS U TEXAS AUSTI; Vapnik VN, 1995, NATURE STAT LEARNING; Webb A., 1999, STAT PATTERN RECOGNI; White WA, 1985, SUBMERGED LANDS TEXA; Windeatt T., 2001, Information Fusion, V2, DOI 10.1016/S1566-2535(01)00029-X	56	15	15	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	AUG	2004	18	5					777	799		10.1142/S0218001404003411		23	Computer Science, Artificial Intelligence	Computer Science	857ZM	WOS:000224159700003		
J	Wu, TF; Lin, CJ; Weng, RC				Wu, TF; Lin, CJ; Weng, RC			Probability estimates for multi-class classification by pairwise coupling	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						pairwise coupling; probability estimates; random forest; support vector machines	RECOGNITION	Pairwise coupling is a popular multi-class classification method that combines all comparisons for each pair of classes. This paper presents two approaches for obtaining class probabilities. Both methods can be reduced to linear systems and are easy to implement. We show conceptually and experimentally that the proposed approaches are more stable than the two existing popular methods: voting and the method by Hastie and Tibshirani (1998).	Natl Taiwan Univ, Dept Comp Sci, Taipei 106, Taiwan; Natl Chengchi Univ, Dept Stat, Taipei 116, Taiwan	Wu, TF (reprint author), Natl Taiwan Univ, Dept Comp Sci, Taipei 106, Taiwan.	B9098@CSIE.NTU.EDU.TW; CJLIN@CSIE.NTU.EDU.TW; CHWENG@NCCU.EDU.TW					Allwein EL, 2001, J MACH LEARN RES, V1, P113, DOI 10.1162/15324430152733133; Blake C. L., 1998, UCI REPOSITORY MACHI; Boser Bernhard E., 1992, P 5 ANN WORKSH COMP; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI [10.1175/1520-0493(1950)078lessthan0001:VOFEITgreaterthan2.0.CO;2, DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2]; Chang CC, 2001, LIBSVM LIB SUPPORT V; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DUAN KB, 2003, CD0312 NAT U SING DE; FRIEDMAN J, 1996, APPROACH POLYCHOTOMO; Hastie T, 1998, ANN STAT, V26, P451; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Hunter D, 2004, ANN STAT, V32; Knerr S., 1990, NEUROCOMPUTING ALGOR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lin H-T, 2003, NOTE PLATTS PROBABIL; Michie D., 1994, MACHINE LEARNING NEU; Platt J., 2000, ADV LARGE MARGIN CLA; Price D., 1994, NEURAL INFORM PROCES, V7, P1109; Refregier P., 1991, P INT C ART NETW, P1003; Ross SM, 1996, STOCHASTIC PROCESSES, VSecond; SVENTNIK V, 2003, J CHEM INF COMP SCI, V43, P1947; WU TF, 2004, ADV NEURAL INFORM PR, V16; Zermelo E, 1929, MATH Z, V29, P436, DOI 10.1007/BF01180541; Zhang T, 2004, ANN STAT, V32, P56	25	569	601	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	AUG	2004	5						975	1005				31	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GS	WOS:000236328000005		
J	Huang, J; Lin, A; Narasimhan, B; Quertermous, T; Hsiung, CA; Ho, LT; Grove, JS; Olivier, M; Ranade, K; Risch, NJ; Shen, RA				Huang, J; Lin, A; Narasimhan, B; Quertermous, T; Hsiung, CA; Ho, LT; Grove, JS; Olivier, M; Ranade, K; Risch, NJ; Shen, RA			Tree-structured supervised learning and the genetics of hypertension	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article							CLASSIFICATION TREES; DISCRIMINANT-ANALYSIS; ASSOCIATION	This paper is about an algorithm, FlexTree, for general supervised learning. It extends the binary tree-structured approach (Classification and Regression Trees, CART) although it differs greatly in its selection and combination of predictors. It is particularly applicable to assessing interactions: gene by gene and gene by environment as they bear on complex disease. One model for predisposition to complex disease involves many genes. Of them, most are pure noise; each of the values that is not the prevalent genotype for the minority of genes that contribute to the signal carries a "score." Scores add. Individuals with scores above an unknown threshold are predisposed to the disease. For the additive score problem and simulated data, FlexTree has cross-validated risk better than many cutting-edge technologies to which it was compared when small fractions of candidate genes carry the signal. For the model where only a precise list of aberrant genotypes is predisposing, there is not a systematic pattern of absolute superiority; however, overall, FlexTree seems better than the other technologies. We tried the algorithm on data from 563 Chinese women, 206 hypotensive, 357 hypertensive, with information on ethnicity, menopausal status, insulin-resistant status, and 21 loci. FlexTree and Logic Regression appear better than the others in terms of Bayes risk. However, the differences are not significant in the usual statistical sense.	Affymetrix Inc, Santa Clara, CA 95051 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Univ, Sch Med, Div Cardiovasc Med, Stanford, CA 94305 USA; Stanford Univ, Sch Med, Dept Genet, Stanford, CA 94305 USA; Stanford Univ, Sch Med, Dept Hlth Res & Policy, Stanford, CA 94305 USA; Natl Hlth Res Inst, Div Biostat & Bioinformat, Taipei 11529, Taiwan; Taipei Vet Gen Hosp, Dept Med Res & Educ, Taipei 112, Taiwan; Univ Hawaii, John A Burns Sch Med, Dept Publ Hlth Sci & Epidemiol, Honolulu, HI 96822 USA; Med Coll Wisconsin, Dept Human Physiol, Milwaukee, WI USA; Med Coll Wisconsin, Ctr Mol Genet, Milwaukee, WI 52336 USA; Bristol Myers Squibb Co, Pharmaceut Res Inst, Princeton, NJ 08543 USA	Huang, J (reprint author), Affymetrix Inc, 3380 Cent Expressway, Santa Clara, CA 95051 USA.	jing-huang@affymetrix.com	Hsiung, Chao Agnes/E-3994-2010				Bechtel S, 2002, EUR J BIOCHEM, V269, P1118, DOI 10.1046/j.1432-1033.2002.02729.x; BONNARDEAUX A, 1994, HYPERTENSION, V24, P63; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chuang LM, 2001, J MOL MED-JMM, V79, P656, DOI 10.1007/s001090100255; Elchebly M, 1999, SCIENCE, V283, P1544, DOI 10.1126/science.283.5407.1544; Friel DD, 2000, CELL CALCIUM, V28, P307, DOI 10.1054/ceca.2000.0172; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T., 2000, GENOME BIOL, V1; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; LIFTON RP, 1992, NATURE, V355, P262, DOI 10.1038/355262a0; Lifton RP, 1996, SCIENCE, V272, P676, DOI 10.1126/science.272.5262.676; Lin A, 1999, HEALTH SERV RES, V34, P1033; Loh WY, 1997, STAT SINICA, V7, P815; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Morello JP, 2001, ANNU REV PHYSIOL, V63, P607, DOI 10.1146/annurev.physiol.63.1.607; Ostensen CG, 2002, BIOCHEM BIOPH RES CO, V291, P945, DOI 10.1006/bbrc.2002.6536; Ranade K, 2001, HUM MOL GENET, V10, P2157, DOI 10.1093/hmg/10.19.2157; Reaven Gerald M, 2003, Curr Atheroscler Rep, V5, P364, DOI 10.1007/s11883-003-0007-0; Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238; Walsh B, 1998, GENETICS ANAL QUANTI; Wu XD, 2003, METABOLISM, V52, P705, DOI 10.1016/S0026-0495(03)00065-9; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5; Zhang HP, 1998, J AM STAT ASSOC, V93, P180, DOI 10.2307/2669615	25	32	32	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	JUL 20	2004	101	29					10529	10534		10.1073/pnas.0403794101		6	Multidisciplinary Sciences	Science & Technology - Other Topics	840FN	WOS:000222842700009	15249660	
J	Valentini, G; Dietterich, TG				Valentini, G; Dietterich, TG			Bias-variance analysis of support vector machines for the development of SVM-based ensemble methods	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						bias-variance analysis; support vector machines; ensemble methods; multi-classifier systems	CLASSIFIER FUSION; RECOGNITION	Bias-variance analysis provides a tool to study learning algorithms and can be used to properly design ensemble methods well tuned to the properties of a specific base learner. Indeed the effectiveness of ensemble methods critically depends on accuracy, diversity and learning characteristics of base learners. We present an extended experimental analysis of bias-variance decomposition of the error in Support Vector Machines (SVMs), considering Gaussian, polynomial and dot product kernels. A characterization of the error decomposition is provided, by means of the analysis of the relationships between bias, variance, kernel type and its parameters, offering insights into the way SVMs learn. The results show that the expected trade-off between bias and variance is sometimes observed, but more complex relationships can be detected, especially in Gaussian and polynomial kernels. We show that the bias-variance decomposition offers a rationale to develop ensemble methods using SVMs as base learners, and we outline two directions for developing SVM ensembles, exploiting the SVM bias characteristics and the bias-variance dependence on the kernel parameters.	Univ Milan, DSI, Milan, Italy; Oregon State Univ, Dept Comp Sci, Corvallis, OR 97331 USA	Valentini, G (reprint author), Univ Milan, DSI, Via Comelico 39, Milan, Italy.	VALENTINI@DSI.UNIMI.IT; TGD@CS.ORST.EDU	Valentini, Giorgio/H-2134-2012				Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Bauer E., 1999, MACH LEARN, V36, P525; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 1996, 460 TR U CAL STAT DE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUCIU I, 2001, P 2001 IEEE INT C IM, V1, P1054; Canu S, 2003, ADV NEURAL INFORM PR, V15; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Cohen S., 2001, LECT NOTES COMPUTER, V2096, P349; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P., 2000, P 17 INT C MACH LEAR, P231; DOMINGOS P, 2000, UNIFIED BIAS VARIANC; Domingos P., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Evgeniou T., 2000, P 17 INT C MACH LEAR, P271; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Heskes T, 1998, NEURAL COMPUT, V10, P1425, DOI 10.1162/089976698300017232; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; JAMES G, 2003, MACH LEARN, P115; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kim H.C., 2002, P 16 INT C PATT REC, V2, P20160; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kleinberg EM, 2000, LECT NOTES COMPUT SC, V1857, P67; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Kong E., 1995, 12 INT C MACH LEARN, P313; Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X; Kuncheva L. I., 2001, LECT NOTES COMPUTER, V2096, P349; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Li M., 1993, INTRO KOLMOGOROV COM; MASON L, 2000, MACHINE LEARNING; Merz C, 1998, UCI REPOSITORY MACHI; PRODROMIDIS A, 1999, ADV DISTRIBUTED DATA, P81; Schapire R. E., 1999, 16 INT JOINT C ART I, P1401; Schapire RE, 1998, ANN STAT, V26, P1651; Scholkopf B, 2002, LEARNING KERNELS; Tibshirani Robert, 1996, BIAS VARIANCE PREDIC; Valentini G., 2003, MACH LEARN, P752; Valentini G, 2002, NEUROCOMPUTING, V48, P623, DOI 10.1016/S0925-2312(01)00632-4; Valentini G, 2003, IEEE IJCNN, P1844; Vapnik V., 1998, STAT LEARNING THEORY; Wang DY, 1998, IEEE T SYST MAN CY B, V28, P583, DOI 10.1109/3477.704297	47	82	96	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2004	5						725	775				51	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GQ	WOS:000236327800001		
J	Ruczinski, I; Kooperberg, C; LeBlanc, ML				Ruczinski, I; Kooperberg, C; LeBlanc, ML			Exploring interactions in high-dimensional genomic data: an overview of Logic Regression, with applications	JOURNAL OF MULTIVARIATE ANALYSIS			English	Article						adaptive model selection; Boolean logic; binary variables; interactions; single nucleotide polymorphisms	NON-HODGKINS-LYMPHOMA; SEQUENCE; MODEL	Logic Regression is an adaptive regression methodology mainly developed to explore high-order interactions in genomic data. Logic Regression is intended for situations where most of the covariates in the data to be analyzed are binary. The goal of Logic Regression is to find predictors that are Boolean (logical) combinations of the original predictors. In this article, we give an overview of the methodology and discuss some applications. We also describe the software for Logic Regression, which is available as an R and S-Plus package. (C) 2004 Elsevier Inc. All rights reserved.	Johns Hopkins Univ, Dept Biostat, Baltimore, MD 21205 USA; Fred Hutchinson Canc Res Ctr, Div Publ Hlth Sci, Seattle, WA 98109 USA	Ruczinski, I (reprint author), Johns Hopkins Univ, Dept Biostat, 615 N Wolfe St, Baltimore, MD 21205 USA.	ingo@jhu.edu					AARTS EHL, 1989, SIMULTED ANNEALING B; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chakravarti A, 1999, NAT GENET, V21, P56, DOI 10.1038/4482; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; Collins Francis S., 1998, SCIENCE, V282, P683; COX DR, 1972, J R STAT SOC B, V34, P187; Etzioni R, 2003, BIOSTATISTICS, V4, P523, DOI 10.1093/biostatistics/4.4.523; FISHER RI, 1993, NEW ENGL J MED, V328, P1002, DOI 10.1056/NEJM199304083281404; FLEISCHER H, 1983, IBM J RES DEV, V25, P412; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Hastie T., 2001, ELEMENTS STAT LEARNI; Kooperberg C, 2001, GENET EPIDEMIOL, V21, pS626; LEBLANC M, 1993, J AM STAT ASSOC, V88, P457, DOI 10.2307/2290325; LUCEK PR, 1997, GEN EPI, V514, pS1101; SHIPP MA, 1993, NEW ENGL J MED, V329, P987; Ruczinski I., 2000, THESIS U WASHINGTON; Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238; WIJSMAN EM, 2001, ANAL COMPLEX GENETIC, V21; Witte JS, 2001, GENET EPIDEMIOL, V21, pS600; Zee R. Y. L., 2002, Pharmacogenomics Journal, V2, P197, DOI 10.1038/sj.tpj.6500101	22	46	50	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0047-259X			J MULTIVARIATE ANAL	J. Multivar. Anal.	JUL	2004	90	1					178	195		10.1016/j.jmva.2004.02.010		18	Statistics & Probability	Mathematics	828IV	WOS:000221967900009		
J	Jiang, HY; Deng, YP; Chen, HS; Tao, L; Sha, QY; Chen, J; Tsai, CJ; Zhang, SL				Jiang, HY; Deng, YP; Chen, HS; Tao, L; Sha, QY; Chen, J; Tsai, CJ; Zhang, SL			Joint analysis of two microarray gene-expression data sets to select lung adenocarcinoma marker genes	BMC BIOINFORMATICS			English	Article							CLASSIFICATION; SURVIVAL	Background: Due to the high cost and low reproducibility of many microarray experiments, it is not surprising to find a limited number of patient samples in each study, and very few common identified marker genes among different studies involving patients with the same disease. Therefore, it is of great interest and challenge to merge data sets from multiple studies to increase the sample size, which may in turn increase the power of statistical inferences. In this study, we combined two lung cancer studies using micorarray GeneChip(R), employed two gene shaving methods and a two-step survival test to identify genes with expression patterns that can distinguish diseased from normal samples, and to indicate patient survival, respectively. Results: In addition to common data transformation and normalization procedures, we applied a distribution transformation method to integrate the two data sets. Gene shaving (GS) methods based on Random Forests (RF) and Fisher's Linear Discrimination (FLD) were then applied separately to the joint data set for cancer gene selection. The two methods discovered 13 and 10 marker genes (5 in common), respectively, with expression patterns differentiating diseased from normal samples. Among these marker genes, 8 and 7 were found to be cancer-related in other published reports. Furthermore, based on these marker genes, the classifiers we built from one data set predicted the other data set with more than 98% accuracy. Using the univariate Cox proportional hazard regression model, the expression patterns of 36 genes were found to be significantly correlated with patient survival (p < 0.05). Twenty-six of these 36 genes were reported as survival-related genes from the literature, including 7 known tumor-suppressor genes and 9 oncogenes. Additional principal component regression analysis further reduced the gene list from 36 to 16. Conclusion: This study provided a valuable method of integrating microarray data sets with different origins, and new methods of selecting a minimum number of marker genes to aid in cancer diagnosis. After careful data integration, the classification method developed from one data set can be applied to the other with high prediction accuracy.	Michigan Technol Univ, Dept Math Sci, Houghton, MI 49931 USA; Michigan Technol Univ, Sch Forest Resources & Environm Sci, Plant Biotechnol Res Ctr, Houghton, MI 49931 USA; Kansas State Univ, Div Biol, Manhattan, KS 66506 USA	Zhang, SL (reprint author), Michigan Technol Univ, Dept Math Sci, 1400 Townsend Dr, Houghton, MI 49931 USA.	hojiang@mtu.edu; ydeng@ksu.edu; hschen@mtu.edu; ltao@mtu.edu; qsha@mtu.edu; jch5353@ksu.edu; chtsai@mtu.edu; shuzhang@mtu.edu	Tsai, CJ/C-2450-2009; Chen, Huann-Sheng/D-6328-2013	Tsai, CJ/0000-0002-9282-7704; Chen, Huann-Sheng/0000-0002-5905-8050			Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Breiman L., RANDOM FORESTS VERSI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; *CAMDA, 2003, 2003 C SUBM ABSTR CA; Chen GA, 2003, P NATL ACAD SCI USA, V100, P13537, DOI 10.1073/pnas.2233850100; CONWAY AR, 2003, GENESPRING VERSION 6; COX DR, 1972, J R STAT SOC B, V34, P187; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Hastie T, 2000, GENOME BIOL, V1, P1, DOI DOI 10.1186/GB-2000-1-2-RESEARCH0003; *INS CORP, 2003, S PLUS VERS 6 1; Johnson R A, 1998, APPL MULTIVARIATE ST; Li C, 2001, GENOME BIOL, V2, DOI [10.1186/gb-2001-2-8-research0032, DOI 10.1186/GB-2001-2-8-RESEARCH0032]; Nimgaonkar A, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-27; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Xiong MM, 2001, MOL GENET METAB, V73, P239, DOI 10.1006/mgme.2001.3193	16	105	115	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JUN 24	2004	5								81	10.1186/1471-2105-5-81		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	837UN	WOS:000222666600001	15217521	
J	Schwender, H; Zucknick, M; Ickstadt, K; Bolt, HM				Schwender, H; Zucknick, M; Ickstadt, K; Bolt, HM		GENICA Network	A pilot study on the application of statistical classification procedures to molecular epidemiological data	TOXICOLOGY LETTERS			English	Article						breast cancer; classification and regression trees (CART); classification; ensemble methods; single nucleotide polymorphism; support vector machines	CANCER; SUSCEPTIBILITY; GENES	The development of new statistical methods for use in molecular epidemiology comprises the building and application of appropriate classification rules. The aim of this study was to assess various classification methods that can potentially handle genetic interactions. A data set comprising genotypes at 25 single nucleotide polymorphic (SNP) loci from 518 breast cancer cases and 586 age-matched population-based controls from the GENICA study was used to built a classification rule with the discrimination methods SVM (support vector machine), CART (classification and regression tree), Bagging, Random Forest, LogitBoost and k nearest neighbours (kNN). A blind pilot analysis of the genotypic data set was a first approach to obtain an impression of the statistical structure of the data. Furthermore, this analysis was performed to explore classification methods that may be applied to molecular-epidemiological evaluation. The results showed that all blindly applied classification methods had a slightly smaller misclassification rate than a random classification. The findings, nevertheless, suggest that SNP data might be useful for the classification of individuals into categories of high or low risk of diseases. (C) 2004 Elsevier Ireland Ltd. All rights reserved.	Univ Dortmund, Dept Stat, Collaborat Res Ctr 475, D-44221 Dortmund, Germany; Univ London Imperial Coll Sci Technol & Med, Dept Biol Sci, London SW7 2AZ, England; Univ Dortmund, Inst Occupat Physiol, IfADo, D-44221 Dortmund, Germany	Schwender, H (reprint author), Univ Dortmund, Dept Stat, Collaborat Res Ctr 475, D-44221 Dortmund, Germany.	holgers@statistik.uni-dortmund.de					BRAUCH H, 2002, BREAST CANC RISK PRE, P148; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; FIX E, 1951, MACHINE RECOGNITION; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Garte S, 2001, CANCER EPIDEM BIOMAR, V10, P1233; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Hastie T, 2001, ELEMENTS STAT LEARN; Perera FP, 2000, CARCINOGENESIS, V21, P517, DOI 10.1093/carcin/21.3.517; PERERA FP, 1982, J CHRON DIS, V35, P581, DOI 10.1016/0021-9681(82)90078-9; Pesch B, 2004, TOXICOL LETT, V151, P255, DOI 10.1016/j.toxlet.2004.02.020; THIER R, 2001, TRENDS PHARMACOL SCI, V11, P449; Thier R, 2002, TOXICOL LETT, V127, P321, DOI 10.1016/S0378-4274(01)00515-X; Vapnik VN, 1995, NATURE STAT LEARNING	16	22	23	ELSEVIER SCI IRELAND LTD	CLARE	CUSTOMER RELATIONS MANAGER, BAY 15, SHANNON INDUSTRIAL ESTATE CO, CLARE, IRELAND	0378-4274			TOXICOL LETT	Toxicol. Lett.	JUN 15	2004	151	1					291	299		10.1016/j.toxlet.2004.02.021		9	Toxicology	Toxicology	831WB	WOS:000222226100033	15177665	
J	Grosjean, P; Picheral, M; Warembourg, C; Gorsky, G				Grosjean, P; Picheral, M; Warembourg, C; Gorsky, G			Enumeration, measurement, and identification of net zooplankton samples using the ZOOSCAN digital imaging system	ICES JOURNAL OF MARINE SCIENCE			English	Article; Proceedings Paper	3rd International Zooplankton Production Symposium	MAY 20-23, 2003	Gijon, SPAIN			image analysis; long-term series; machine-learning; net samples; pattern recognition; size spectrum; zooplankton	PATTERN-RECOGNITION; OCEAN	Identifying and counting zooplankton are labour-intensive and time-consuming processes that are still performed manually. However, a new system, known as ZOOSCAN, has been designed for counting zooplankton net samples. We describe image-processing and the results of (semi)-automatic identification of taxa with various machine-learning methods. Each scan contains between 1500 and 2000 individuals <0.5 min. We used two training sets of about 1000 objects each divided into 8 (simplified) and 29 groups (detailed), respectively. The new discriminant vector forest algorithm, which is one of the most efficient methods, discriminates between the organisms in the detailed training set with all accuracy of 75% at a speed of 2000 items per second. A supplementary algorithm tags objects that the method classified with low accuracy (suspect items), such that they could be checked by taxonomists. This complementary and interactive semi -automatic process combines both computer speed and the ability to detect variations in proportions and grey levels with the human skills to discriminate animals on the basis of small details, such as presence/absence or number of appendages. After this checking process, total accuracy increases to between 80% and 85%. We discuss the potential of the system as a standard for identification, enumeration. and size frequency distribution of net-collected zooplankton. (C) 2004 Published by Elsevier Ltd on behalf of International Council for the Exploration of the Sea.	Univ Mons, Lab Ecol Numer, B-7000 Mons, Belgium; Observ Oceanol, Stn Zool, UMR 7093, Lab Oceanog Villefranche, F-06234 Villefranche Sur Mer, France	Grosjean, P (reprint author), Univ Mons, Lab Ecol Numer, Ave Maistriau 19, B-7000 Mons, Belgium.	philippe.grosjean@umh.ac.be					BANSE K, 1995, ICES J MAR SCI, V52, P265, DOI 10.1016/1054-3139(95)80043-3; Beaugrand G, 2002, SCIENCE, V296, P1692, DOI 10.1126/science.1071329; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Culverhouse PF, 2003, MAR ECOL PROG SER, V247, P17, DOI 10.3354/meps247017; GORSKY G, 2003, GLOBEC INT NEWSLETTE, V9, P5; GORSKY G, 1989, MAR ECOL PROG SER, V58, P133, DOI 10.3354/meps058133; Grassle J. Frederick, 2000, Oceanography, V13, P5; Harris R. P., 2000, ICES ZOOPLANKTON MET; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; JEFFRIES HP, 1984, MAR BIOL, V78, P329, DOI 10.1007/BF00393019; LONGHURS.AR, 1967, LIMNOL OCEANOGR, V12, P334; Meyer D., 2001, R NEWS, V1, P23; Myers Ransom A., 2000, Oceanography, V13, P56; PAULY D, 1995, TRENDS ECOL EVOL, P10; Peters A., 2002, R NEWS, V2, P33; Planque B, 1997, OCEANOL ACTA, V20, P159; ROLKE M, 1984, J PLANKTON RES, V6, P637, DOI 10.1093/plankt/6.4.637; SIEGENTHALER U, 1993, NATURE, V365, P119, DOI 10.1038/365119a0; SIMPSON R, 1992, MAR ECOL PROG SER, V79, P303; STEIDINGER KA, 1990, TOXIC MARINE PHYTOPL; Tang XO, 1998, ARTIF INTELL REV, V12, P177, DOI 10.1023/A:1006517211724; UNESCO, 1968, ZOOPL SAMPL; Wiebe PH, 2003, PROG OCEANOGR, V56, P7, DOI 10.1016/S0079-6611(02)00140-4; YOUNGBLUTH MJ, 1980, ESTUAR COAST MAR SCI, V10, P265, DOI 10.1016/S0302-3524(80)80101-0	24	70	74	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	1054-3139			ICES J MAR SCI	ICES J. Mar. Sci.	JUN	2004	61	4					518	525		10.1016/j.icesjms.2004.03.012		8	Fisheries; Marine & Freshwater Biology; Oceanography	Fisheries; Marine & Freshwater Biology; Oceanography	833FS	WOS:000222322500010		
J	Wu, YM; Zhang, AD				Wu, YM; Zhang, AD			Interactive pattern analysis for relevance feedback in multimedia information retrieval	MULTIMEDIA SYSTEMS			English	Article; Proceedings Paper	8th International Workshop on Multimedia Information Systems	OCT 30-NOV 01, 2002	Tempe, AZ			multimedia information retrieval; relevance feedback; interactive pattern analysis; random forests		Relevance feedback is a mechanism to interactively learn a user's query concept online. It has been extensively used to improve the performance of multimedia information retrieval. In this paper, we present a novel interactive pattern analysis method that reduces relevance feedback to a two-class classification problem and classifies multimedia objects as relevant or irrelevant. To perform interactive pattern analysis, we propose two online pattern classification methods, called interactive random forests (IRF) and adaptive random forests (ARF), that adapt a composite classifier known as random forests for relevance feedback. IRF improves the efficiency of regular random forests (RRF) with a novel two-level resampling technique called biased random sample reduction, while ARF boosts the performance of RRF with two adaptive learning techniques called dynamic feature extraction and adaptive sample selection. During interactive multimedia retrieval, both ARF and IRF run two to three times faster than RRF while achieving comparable precision and recall against the latter. Extensive experiments on a COREL image set (with 31,438 images) demonstrate that our methods (i.e., IRF and RRF) achieve at least a 20% improvement on average precision and recall over the state-of-the-art approaches.	SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Wu, YM (reprint author), SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.	yiminkwu@cse.buffalo.edu; azhang@cse.buffalo.edu					Baeza-Yates R., 1999, MODERN INFORMATION R, V1st; BARTOLINI I, 2001, P 27 INT C VER LARG; BRANDT S, 2000, P INT C PATT REC SEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, 567 U CAL DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; CHARIKAR M, 1997, P ACM S THEOR COMP; COX IJ, 2000, P IEEE C COMP VIS PA, V20; ELOMAA T, 1999, MACH LEARN, V36, P1; ENFRON B, 1993, INTRO BOOTSTRAP; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; GUO GD, 2001, P IEEE COMP SOC C CO, V1, P731; ISHIKAWA Y, 1998, P 24 INT C VER LARG; Joachims T., 1998, ADV KERNEL METHODS S, P41; Kononenko I, 1995, P 14 INT JOINT C ART; MA WY, 1998, HDB MULTIMEDIA COMPU, P19; MACARTHUR SD, 2000, P IEEE WORKSH CAIVL; Mitchell T. M., 1997, MACHINE LEARNING; NIBLACK W, 1993, P SPIE STOR RETR IM; Pass G., 1996, Proceedings ACM Multimedia 96, DOI 10.1145/244130.244148; PORKAEW K, 1999, P ACM MULT; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rui Y., 1997, P IEEE INT C IM PROC; Rui Y., 2000, P IEEE C COMP VIS PA; SMITH JR, 1994, P IEEE INT C IM PROC; SU Z, 2001, P ACM MULT; Tieu K., 2000, P IEEE C COMP VIS PA; Tong S., 2001, P ACM MULT; VASCONCELOS N, 2000, P IEEE WORKSH CAIVL; WU Y, 2002, P 8 INT WORKSH MULT; WU Y, 2002, P IEEE INT C MULT EX; WU YM, 2002, P IEEE INT C IM PROC; Yang Y., 1997, P ICML 97; ZHOU XS, 2003, ACM MULTIMEDIA SYSTE, V8, P536; ZHOU XS, 2001, P ACM MULT SEP 2001	36	6	6	SPRINGER-VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	0942-4962			MULTIMEDIA SYST	Multimedia Syst.	JUN	2004	10	1					41	55		10.1007/s00530-004-0136-5		15	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	824MO	WOS:000221690900005		
J	Baccini, A; Friedl, MA; Woodcock, CE; Warbington, R				Baccini, A; Friedl, MA; Woodcock, CE; Warbington, R			Forest biomass estimation over regional scales using multisource data	GEOPHYSICAL RESEARCH LETTERS			English	Article							GENERALIZED ADDITIVE-MODELS; SOUTHERN-CALIFORNIA; STRUCTURAL ATTRIBUTES; SPATIAL-DISTRIBUTION; LANDSAT; TERRAIN; VARIABLES; IMAGERY; CARBON; USA	A combination of statistical models and multisource data were used to map above-ground forest biomass for National Forest lands in California. To do this, data from the Moderate Resolution Imaging Spectoradiometer were used in combination with precipitation, temperature, and elevation data. The results show that coarse resolution remotely sensed data in combination with relevant topographic and climate data can be used to map aboveground biomass with good accuracy over large areas. For the data sets considered, empirical models based on a 2 percent sample explained 73 percent of the variance in biomass in the remaining 98 percent of the data with a root mean square error of 44.4 tons/ha. These results suggest that it should be feasible to improve estimates of above-ground carbon stocks at regional to continental scales in the near future.	Boston Univ, Dept Geog, Boston, MA 02215 USA; US Forest Serv, Remote Sensing Lab, USDA, Sacramento, CA 95814 USA	Baccini, A (reprint author), Boston Univ, Dept Geog, 675 Commonwealth Ave, Boston, MA 02215 USA.	abaccini@bu.edu					Box E. O, 1981, MACROCLIMATE PLANT F; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown S, 2002, ENVIRON POLLUT, V116, P363, DOI 10.1016/S0269-7491(01)00212-3; Brown SL, 1999, FOREST ECOL MANAG, V123, P81, DOI 10.1016/S0378-1127(99)00017-1; COHEN WB, 1992, REMOTE SENS ENVIRON, V41, P1, DOI 10.1016/0034-4257(92)90056-P; Cohen WB, 2003, REMOTE SENS ENVIRON, V84, P561, DOI 10.1016/S0034-4257(02)00173-6; DAVIS FW, 1990, LANDSCAPE ECOL, V4, P69, DOI 10.1007/BF02573952; Franklin J, 1998, J VEG SCI, V9, P733, DOI 10.2307/3237291; Franklin J, 2000, PHOTOGRAMM ENG REM S, V66, P1209; Franklin J, 1995, PROG PHYS GEOG, V19, P474, DOI 10.1177/030913339501900403; Frescino TS, 2001, J VEG SCI, V12, P15, DOI 10.2307/3236670; GEMMELL FM, 1995, REMOTE SENS ENVIRON, V51, P291, DOI 10.1016/0034-4257(94)00056-S; GRAY JT, 1982, ECOL MONOGR, V52, P415, DOI 10.2307/2937353; Guisan A, 2002, ECOL MODEL, V157, P89, DOI 10.1016/S0304-3800(02)00204-1; Hastie T. J., 1990, GEN ADDITIVE MODELS; HOLDRIDGE LR, 1947, SCIENCE, V105, P367, DOI 10.1126/science.105.2727.367; HOUGHTON R, 1992, ECOLOGY CONSERVATION, P263; Houghton RA, 2001, GLOBAL CHANGE BIOL, V7, P731, DOI 10.1046/j.1365-2486.2001.00426.x; Lefsky MA, 1999, REMOTE SENS ENVIRON, V67, P83, DOI 10.1016/S0034-4257(98)00071-6; Myneni RB, 2001, P NATL ACAD SCI USA, V98, P14784, DOI 10.1073/pnas.261555198; Puhr CB, 2000, INT J REMOTE SENS, V21, P633, DOI 10.1080/014311600210470; Ranson KJ, 1997, J GEOPHYS RES-ATMOS, V102, P29599, DOI 10.1029/96JD03708; RIGGAN PJ, 1988, ECOL MONOGR, V58, P155, DOI 10.2307/2937023; Schaaf CB, 2002, REMOTE SENS ENVIRON, V83, P135, DOI 10.1016/S0034-4257(02)00091-3; Schroeder P, 1997, FOREST SCI, V43, P424; Thornton PE, 1997, J HYDROL, V190, P214, DOI 10.1016/S0022-1694(96)03128-9; WOODCOCK CE, 1994, REMOTE SENS ENVIRON, V50, P240, DOI 10.1016/0034-4257(94)90074-4	28	40	43	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0094-8276			GEOPHYS RES LETT	Geophys. Res. Lett.	MAY 19	2004	31	10							L10501	10.1029/2004GL019782		4	Geosciences, Multidisciplinary	Geology	823KB	WOS:000221609500001		
J	Li, X; Rao, SQ; Wang, YD; Gong, BS				Li, X; Rao, SQ; Wang, YD; Gong, BS			Gene mining: a novel and powerful ensemble decision approach to hunting for disease genes using microarray expression profiling	NUCLEIC ACIDS RESEARCH			English	Article							FEATURE SUBSET-SELECTION; SAMPLE CLASSIFICATION; ACUTE-LEUKEMIA; TRANSLOCATION; PREDICTION; RELEVANCE; DISCOVERY; PATTERNS; TUMOR; CELLS	Current applications of microarrays focus on precise classification or discovery of biological types, for example tumor versus normal phenotypes in cancer research. Several challenging scientific tasks in the post-genomic epoch, like hunting for the genes underlying complex diseases from genome-wide gene expression profiles and thereby building the corresponding gene networks, are largely overlooked because of the lack of an efficient analysis approach. We have thus developed an innovative ensemble decision approach, which can efficiently perform multiple gene mining tasks. An application of this approach to analyze two publicly available data sets (colon data and leukemia data) identified 20 highly significant colon cancer genes and 23 highly significant molecular signatures for refining the acute leukemia phenotype, most of which have been verified either by biological experiments or by alternative analysis approaches. Furthermore, the globally optimal gene subsets identified by the novel approach have so far achieved the highest accuracy for classification of colon cancer tissue types. Establishment of this analysis strategy has offered the promise of advancing microarray technology as a means of deciphering the involved genetic complexities of complex diseases.	Cleveland Clin Fdn, Dept Mol Cardiol, Cleveland, OH 44195 USA; Harbin Med Univ, Dept Biomed Engn Biomath & Bioinformat, Harbin 150086, Peoples R China; Harbin Inst Technol, Dept Comp Sci, Harbin 150001, Peoples R China; Cleveland Clin Fdn, Dept Cardiovasc Med, Cleveland, OH 44195 USA	Rao, SQ (reprint author), Cleveland Clin Fdn, Dept Mol Cardiol, 9500 Euclid Ave, Cleveland, OH 44195 USA.	lixia@ems.hrbmu.edu.cn; raos@ccf.org					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Bell DA, 2000, MACH LEARN, V41, P175, DOI 10.1023/A:1007612503587; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Bo T, 2002, GENOME BIOL, V3; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burke HB, 2000, MOL DIAGN, V5, P349, DOI 10.1054/modi.2000.19562; Busson-Le Coniat M, 1999, LEUKEMIA, V13, P302; Chilingaryan A, 2002, MATH BIOSCI, V176, P59, DOI 10.1016/S0025-5564(01)00105-5; Cho SJ, 2002, J CHEM INF COMP SCI, V42, P927, DOI 10.1021/ci010247v; Chow ML, 2001, PHYSIOL GENOMICS, V5, P99; DeRisi JL, 1997, SCIENCE, V278, P680, DOI 10.1126/science.278.5338.680; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GUO Z, 2001, ANAL MED DATA INTRO; Hall M. A., 1998, THESIS U WAIKATO HAM; HASEMAN JK, 1972, BEHAV GENET, V2, P3, DOI 10.1007/BF01066731; Hastie T, 2000, GENOME BIOL, V1, P1, DOI DOI 10.1186/GB-2000-1-2-RESEARCH0003; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KOWALSKI J, 1989, MOL CELL BIOL, V9, P1946; Lestou VS, 2003, GENE CHROMOSOME CANC, V36, P375, DOI 10.1002/gcc.10181; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li Zhi-gang, 2003, Zhonghua Xue Ye Xue Za Zhi, V24, P256; Mills JC, 2001, NUCLEIC ACIDS RES, V29, part. no., DOI 10.1093/nar/29.15.e72; Province MA, 2001, ADV GENET, V42, P273, DOI 10.1016/S0065-2660(01)42028-1; Shannon WD, 2001, GENET EPIDEMIOL, V20, P293, DOI 10.1002/gepi.1; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Sun MH, 2003, BIOINFORMATICS, V19, P1243, DOI 10.1093/bioinformatics/btg145; Szabo A, 2003, BIOSTATISTICS, V4, P555, DOI 10.1093/biostatistics/4.4.555; Tsamardinos I., 2003, 9 INT WORKSH ART INT; TSE W, 1995, BLOOD, V85, P650; Watanabe N, 2003, LEUKEMIA, V17, P876, DOI 10.1038/sj.leu.2402900; XING EP, 2001, MACHINE LEARNING; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	37	63	80	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048	1362-4962		NUCLEIC ACIDS RES	Nucleic Acids Res.	MAY	2004	32	9					2685	2694		10.1093/nar/gkh563		10	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	825HM	WOS:000221746900012	15148356	
J	Zhen, XA; Luke, BT; Izmirlian, G; Umar, A; Lynch, PM; Phillips, RKS; Patterson, S; Conrads, TP; Veenstra, TD; Greenwald, P; Hawk, ET; Ali, LU				Zhen, XA; Luke, BT; Izmirlian, G; Umar, A; Lynch, PM; Phillips, RKS; Patterson, S; Conrads, TP; Veenstra, TD; Greenwald, P; Hawk, ET; Ali, LU			Serum proteomic profiles suggest celecoxib-modulated targets and response predictors	CANCER RESEARCH			English	Article							FAMILIAL ADENOMATOUS POLYPOSIS; PREVENT COLORECTAL ADENOMAS; CYCLOOXYGENASE-2 INHIBITOR; MASS-SPECTROMETRY; RANDOMIZED-TRIAL; PROSTATE-CANCER; ASPIRIN; CHEMOPREVENTION; ANGIOGENESIS; EXPRESSION	Cyclooxygenase-2 is a valid target for cancer prevention and treatment. This has been shown in preclinical and clinical cancer prevention studies by using a cyclooxygenase-2 inhibitor, celecoxib. When used in a randomized cancer prevention clinical trial on patients with the inherited autosomal dominant condition, familial adenomatous polyposis, celecoxib proved efficacious. However, a remarkable heterogeneity in patients' responses to the chemopreventive effects of celecoxib was observed. Proteomic profiling of sera from these patients identified several markers, the expression of which was specifically modulated after treatment with celecoxib. A decision tree algorithm identified classifiers for response to celecoxib with relatively high sensitivity but moderate to low specificity. In particular, a spectral feature at m/z 16,961.4 was identified as a strong discriminator between response and nonresponse to celecoxib at the highest dose.	NCI, Div Canc Prevent, Bethesda, MD 20893 USA; NCI, Lab Proteom & Analyt Technol, SAIC Frederick Inc, Frederick, MD 21701 USA; NCI, Adv Biomed Comp Ctr, SAIC Frederick Inc, Frederick, MD 21701 USA; Univ Texas, MD Anderson Canc Ctr, Houston, TX 77030 USA; St Marks Hosp, Imperial Canc Res Fund, London EC1V 2PS, England	Ali, LU (reprint author), NCI, Div Canc Prevent, Bethesda, MD 20893 USA.	alii@mail.nih.gov					Adam BL, 2002, CANCER RES, V62, P3609; Baron JA, 2003, NEW ENGL J MED, V348, P891, DOI 10.1056/NEJMoa021735; Breiman L, 2002, MANUAL SETTING UP US; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; EBERHART CE, 1994, GASTROENTEROLOGY, V107, P1183; ENAMOUZIG R, 2003, GASTROENTEROLOGY, V125, P328; Gately S, 2000, CANCER METAST REV, V19, P19, DOI 10.1023/A:1026575610124; Giardiello FM, 2002, NEW ENGL J MED, V346, P1054, DOI 10.1056/NEJMoa012015; Goss KH, 2000, J CLIN ONCOL, V18, P1967; Hao XP, 1999, J PATHOL, V187, P295; Jacoby RF, 2000, CANCER RES, V60, P5040; Jacoby RF, 2000, CANCER RES, V60, P1864; Li JN, 2002, CLIN CHEM, V48, P1296; LIAW A, 2003, RANDOM FOREST PACKAG; LINDSTROM MJ, 1988, J AM STAT ASSOC, V83, P1014; Lupulescu A, 1996, PROSTAG LEUKOTR ESS, V54, P83, DOI 10.1016/S0952-3278(96)90064-2; Mahmoud NN, 1998, SURGERY, V124, P225, DOI 10.1067/msy.1998.90369; Moore BC, 2000, CURR MED CHEM, V7, P1131; Oshima M, 1996, CELL, V87, P803, DOI 10.1016/S0092-8674(00)81988-1; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; Prescott S. M., 2000, BIOCHIM BIOPHYS ACTA, V1470, P69; Sandler RS, 2003, NEW ENGL J MED, V348, P883, DOI 10.1056/NEJMoa021633; Steinbach G, 2000, NEW ENGL J MED, V342, P1946, DOI 10.1056/NEJM200006293422603; Subbaramaiah K, 2003, TRENDS PHARMACOL SCI, V24, P96, DOI 10.1016/S0165-6147(02)00043-3; Tsujii M, 1998, CELL, V93, P705, DOI 10.1016/S0092-8674(00)81433-6; von Eggeling F, 2001, ELECTROPHORESIS, V22, P2898, DOI 10.1002/1522-2683(200108)22:14<2898::AID-ELPS2898>3.0.CO;2-A; Yip TT, 2002, TECHNOL CANCER RES T, V1, P273; Zhukov TA, 2003, LUNG CANCER, V40, P267, DOI 10.1016/S0169-5002(03)00082-5	30	0	0	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	0008-5472			CANCER RES	Cancer Res.	APR 15	2004	64	8					2904	2909				6	Oncology	Oncology	811ZS	WOS:000220810400040		
J	Huang, XH; Pan, W; Park, S; Han, XQ; Miller, LW; Hall, J				Huang, XH; Pan, W; Park, S; Han, XQ; Miller, LW; Hall, J			Modeling the relationship between LVAD support time and gene expression changes in the human heart by penalized partial least squares	BIOINFORMATICS			English	Article							VENTRICULAR ASSIST DEVICE; MECHANICAL CIRCULATORY SUPPORT; MICROARRAY DATA; CLASSIFICATION; REGRESSION; SELECTION; CARDIOMYOPATHY; SHRINKAGE; FAILURE; LONG	Motivation: Heart failure affects more than 20 million people in the world. Heart transplantation is the most effective therapy, but the number of eligible patients far outweighs the number of available donor hearts. The left mechanical ventricular assist device (LVAD) has been developed as a successful substitution therapy that aids the failing ventricle while a patient is waiting for the donor heart. We obtained genomics data from paired human heart samples harvested at the time of LVAD implant and explant. The heart failure patients in our study were supported by the LVAD for various periods of time. The goal of this study is to model the relationship between the time of LVAD support and gene expression changes. Results: To serve the purpose, we propose a novel penalized partial least squares (PPLS) method to build a regression model. Compared with partial least squares and Breiman's random forest method, PPLS gives the best prediction results for the LVAD data.	Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA; Univ Minnesota, Fairview Med Ctr, Minneapolis, MN 55455 USA; Univ Minnesota, Sch Med, Dept Med, Div Cardiovasc, Minneapolis, MN 55455 USA	Pan, W (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, A460 Mayo Bldg,MMC 303, Minneapolis, MN 55455 USA.	weip@biostat.umn.edu					Altemose GT, 1997, J HEART LUNG TRANSPL, V16, P765; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dipla K, 1998, CIRCULATION, V97, P2316; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Efron B., 1982, JACKKNIFE BOOTSTRAP; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; GARTHWAITE PH, 1994, J AM STAT ASSOC, V89, P122, DOI 10.2307/2291207; Goldstein DJ, 1998, NEW ENGL J MED, V339, P1522, DOI 10.1056/NEJM199811193392107; HAWKINS DM, 2003, EXPLORING BLOOD SPEC; HELLAND IS, 1988, COMMUN STAT SIMULAT, V17, P581, DOI 10.1080/03610918808812681; Hoskuldsson A, 1988, J CHEMOMETR, V2, P211, DOI DOI 10.1002/CEM.1180020306; Huang XH, 2003, BIOINFORMATICS, V19, P2072, DOI 10.1093/bioinformatics/btg283; HUNT SA, 2002, J HEART LUNG TRANSPL, DOI UNSP 211189-211203; Johansson D, 2003, BIOINFORMATICS, V19, P467, DOI 10.1093/bioinformatics/btg017; Levin HR, 1996, J HEART LUNG TRANSPL, V15, P840; MCCARTHY PM, 1995, J THORAC CARDIOV SUR, V109, P409, DOI 10.1016/S0022-5223(95)70271-7; MCCARTHY PM, 1995, ANN THORAC SURG, V59, P609, DOI 10.1016/0003-4975(94)00953-8; McCarthy PM, 2002, SCIENCE, V295, P998, DOI 10.1126/science.1068555; MCCARTHY PM, 1994, CIRCULATION, V90, P83; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Nguyen DV, 2002, BIOINFORMATICS, V18, P1216, DOI 10.1093/bioinformatics/18.9.1216; Nguyen DV, 2002, BIOINFORMATICS, V18, P1625, DOI 10.1093/bioinformatics/18.12.1625; Park Peter J, 2002, Bioinformatics, V18 Suppl 1, pS120; Rose EA, 2001, NEW ENGL J MED, V345, P1435, DOI 10.1056/NEJMoa012175; Simon R, 2003, J NATL CANCER I, V95, P14; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; WEST M, 2002, 0212 DUK U I STAT DE	30	20	20	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	APR 12	2004	20	6					888	894		10.1093/bioinformatics/btg499		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	813GH	WOS:000220895100010	14751963	
J	Chawla, NV; Hall, LO; Bowyer, KW; Kegelmeyer, WP				Chawla, NV; Hall, LO; Bowyer, KW; Kegelmeyer, WP			Learning ensembles from bites: A scalable and accurate approach	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						ensembles; bagging; boosting; diversity; distributed learning	ALGORITHMS	Bagging and boosting are two popular ensemble methods that typically achieve better accuracy than a single classifier. These techniques have limitations on massive data sets, because the size of the data set can be a bottleneck. Voting many classifiers built on small subsets of data ("pasting small votes") is a promising approach for learning from massive data sets, one that can utilize the power of boosting and bagging. We propose a framework for building hundreds or thousands of such classifiers on small subsets of data in a distributed environment. Experiments show this approach is fast, accurate, and scalable.	CIBC, Customer Behav Analyt, Toronto, ON M5L 1A2, Canada; Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA; Sandia Natl Labs, Biosyst Res Dept, Livermore, CA 94551 USA	Chawla, NV (reprint author), CIBC, Customer Behav Analyt, Commerce Court E,11th Floor, Toronto, ON M5L 1A2, Canada.	NITESH.CHAWLA@CIBC.CA; HALL@CSEE.USF.EDU; KWB@CSE.ND.EDU; WPK@CA.SANDIA.GOV					*ACM, 2001, 7 ACM SIGKDD INT C K; Banfield RE, 2003, LECT NOTES COMPUT SC, V2709, P306; Bauer E., 1999, MACHINE LEARNING, V36; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chan P., 1993, AAAI WORKSH KNOWL DI, P227; CHAWLA NV, 2001, ACM SIGKDD WORKSH DA; CHAWLA NV, 2000, 1 IEEE INT C DAT MIN, P581; Chawla NV, 2003, PATTERN RECOGN LETT, V24, P455, DOI 10.1016/S0167-8655(02)00269-6; CHAWLA NV, 2002, 3 INT WORKSH MULT CL, P52; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; DOMINGOS P, 1996, AAAI WORKSH INT MULT, P29; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; ESCHRICH S, 2002, J SYSTEM SIMULATION, V2, P1464; Fahlman S.E., 1990, ADV NEURAL INFORM PR, V2; Fayyad U., 1996, ADV KNOWLEDGE DISCOV; Freund Y, 1996, 13 INT C MACH LEARN; Giacinto G, 2001, PATTERN RECOGN LETT, V22, P25, DOI 10.1016/S0167-8655(00)00096-9; Good I. J., 1965, ESTIMATION PROBABILI; HALL LO, 1999, WORKSH 5 ACM SIGKDD; HALL LO, 2000, SAND20008203 SAND NA; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KUNCHEVA LI, 2000, P 15 INT C PATT REC, V2, P168, DOI 10.1109/ICPR.2000.906041; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Latinne P., 2001, Multiple Classifier Systems. Second International Workshop, MCS 2001. Proceedings (Lecture Notes in Computer Science Vol.2096); *LAWR LIV NAT LAB, ASCI BLUE PAC; *LAWR LIV NAT LAB, 1999, PROT STRUCT PRED CTR; Lazarevic A, 2002, DISTRIB PARALLEL DAT, V11, P203, DOI 10.1023/A:1013992203485; LEAVITT N, 2002, IEEE COMPUTER; MUSICK R, 1993, P 10 INT C MACH LEAR, P212; Perlich C., 2003, J MACHINE LEARNING R, V4, P211; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Provost FJ, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P74; QUINLAN JR, 1992, C4 5 PROGR MACH LEAR; SKALAK DB, 1996, AAAI INT MULT LEARN; Spiegelhalter D.J., 1994, MACHINE LEARNING NEU; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568	42	56	57	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	APR	2004	5						421	451				31	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GM	WOS:000236327400005		
J	Blanchard, G				Blanchard, G			Different paradigms for choosing sequential reweighting algorithms	NEURAL COMPUTATION			English	Article							CLASSIFIERS; TREES	Analyses of the success of ensemble methods in classification have pointed out the important role played by the margin distribution function on the training and test sets. While it is acknowledged that one should generally try to achieve high margins on the training set, the more precise shape of the empirical margin distribution function one should favor in practice is subject to different approaches. We first present two concurrent philosophies for choosing the empirical margin profile: the minimax margin paradigm and the mean and variance paradigm. The best-known representative of the first paradigm is the AdaBoost algorithm, and this philosophy has been shown by several other authors to be closely related to the principle of the support vector machine. We show that the second paradigm is very close in spirit to Fisher's linear discriminant (in a feature space). We construct two boosting-type algorithms, very similar in their form, dedicated to one or the other philosophy. We consequently derive by interpolation a very simple family of iterative reweighting algorithms that can be understood as different trade-offs between the two paradigms and argue from experiments that this can allow for a suitable adaptivity to different classification problems, particularly in the presence of noise or excessive complexity of the base classifiers.	Univ Paris 11, Dept Math, F-91405 Orsay, France; Fraunhofer FIRST, D-12489 Berlin, Germany	Blanchard, G (reprint author), Univ Paris 11, Dept Math, F-91405 Orsay, France.	blanchar@first.fhg.de					AMIT Y, 2001, MULTIPLE RANDOMIZED; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Blackwell D, 1956, PAC J MATH, V6, P1; BLANCHARD G, 2003, NONLINEAR ESTIMATION; BLANCHARD G, 2001, THESIS U PARIS NORD; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1998, PREDICTION GAMES ARC; Devroye L., 1996, PROBABILISTIC THEORY, V31; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Frean Marcus, 1998, SIMPLE COST FUNCTION; Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238163; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Grove A. J., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Hart S, 2001, J ECON THEORY, V98, P26, DOI 10.1006/jeth.2000.2746; Koltchinskii V, 2002, ANN STAT, V30, P1; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Mika S, 2002, THESIS U TECHNOLOGY; Onoda T., 1998, P INT C ART NEUR NET, P195; Ratsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211; RATSCH G, 2001, MARGINAL BOOSTING; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Smola A.J., 2000, ADV LARGE MARGIN CLA; VIOLA P, 2001, CRL200101 COMPAQ	26	2	2	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	APR	2004	16	4					811	836		10.1162/089976604322860712		26	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	779DW	WOS:000189281000007		
J	Alexe, G; Alexe, S; Liotta, LA; Petricoin, E; Reiss, M; Hammer, PL				Alexe, G; Alexe, S; Liotta, LA; Petricoin, E; Reiss, M; Hammer, PL			Ovarian cancer detection by logical analysis of proteomic data	PROTEOMICS			English	Article						logical analysis of data; ovarian cancer	PROSTATE-CANCER; BREAST-CANCER; SERUM; PATTERNS; IDENTIFICATION; PREDICTION; CARCINOMA; MARKERS; RISK	A new type of efficient and accurate proteomic ovarian cancer diagnosis systems is proposed. The system is developed using the combinatorics and optimization-based methodology of logical analysis of data (LAD) to the Ovarian Dataset 8-7-02 (http://clinicalproteomics.steem.com), which updates the one used by Petricoin et al, in The Lancet 2002, 359, 572-577. This mass spectroscopy-generated dataset contains expression profiles of 15154 peptides defined by their mass/charge ratios (m/z) in serum of 162 ovarian cancer and 91 control cases. Several fully reproducible models using only 7-9 of the 15 154 peptides were constructed, and shown in multiple cross-validation tests (k-folding and leave-one-out) to provide sensitivities and specificities of up to 100%. A special diagnostic system for stage I ovarian cancer patients is shown to have similarly high accuracy. Other results: (i) expressions of peptides with relatively low m/z values in the dataset are shown to be better at distinguishing ovarian cancer cases from controls than those with higher m/z values; (ii) two large groups of patients with a high degree of similarities among their formal (mathematical) profiles are detected; (iii) several peptides with a blocking or promoting effect on ovarian cancer are identified.	Rutgers State Univ, Rutgers Ctr Operat Res, RUTCOR, Piscataway, NJ 08854 USA; NCI, Pathol Lab, NIH, Bethesda, MD 20892 USA; US FDA, Ctr Biol Evaluat & Res, NIH, Clin Proteom Program,Dept Therapeut, Bethesda, MD 20014 USA; Univ Med & Dent New Jersey, Robert Wood Johnson Med Sch, Inst Canc, Dept Med, New Brunswick, NJ USA	Hammer, PL (reprint author), Rutgers State Univ, Rutgers Ctr Operat Res, RUTCOR, 640 Bartholomew Rd, Piscataway, NJ 08854 USA.	hammer@rutcor.rutgers.edu	Reiss, Michael/A-8314-2009				ABRAMSON S, 2002, RUTCOR RES REPORT; Adam BL, 2002, CANCER RES, V62, P3609; ALEXE G, 2003, IN PRESS DISER APPL; ALEXE G, 2002, RUTCOR RUTGERS CTR O; Alexe S, 2003, ANN OPER RES, V119, P15, DOI 10.1023/A:1022970120229; ALEXE S, 2003, RUTCOR RES REPORT; Ardekani Ali M, 2002, Expert Rev Mol Diagn, V2, P312, DOI 10.1586/14737159.2.4.312; Bandera CA, 2003, CURR OPIN OBSTET GYN, V15, P51, DOI 10.1097/01.gco.0000051556.77832.52; Bishop C., 1996, NEURAL NETWORKS PATT, V1st; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; Boros E, 1997, MATH PROGRAM, V79, P163, DOI 10.1007/BF02614316; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown RE, 2002, ANN CLIN LAB SCI, V32, P12; Cohen LS, 2001, GYNECOL ONCOL, V82, P40, DOI 10.1006/gyno.2001.6253; Crama Y., 1988, Annals of Operations Research, V16, DOI 10.1007/BF02283750; Cristianini N., 2000, INTRO SUPPORT VECTOR; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd; ECKSTEIN J, 2003, IN PRESS ANN OPERATI; Goldberg D, 1989, GENETIC ALGORITHMS S; Hammer AB, 1999, ANN OPER RES, V87, P165, DOI 10.1023/A:1018920600320; HAMMER PL, 2002, INFORMS ANN M SAN JO; HAMMER PL, 2003, RR7 RUTCOR RUTG U; Hastie T., 2001, ELEMENTS STAT LEARNI; Jobson JD., 1991, APPL MULTIVARIATE DA; Lauer MS, 2002, CIRCULATION, V106, P685, DOI 10.1161/01.CIR.0000024410.15081.FD; Lüftner Diana, 2002, Expert Rev Mol Diagn, V2, P23, DOI 10.1586/14737159.2.1.23; Olshen R. A., 1984, CLASSIFICATION REGRE; Ozolos RF, 2000, PRINCIPLES PRACTICE, P981; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pucci-Minafra I, 2002, PROTEOMICS, V2, P919, DOI 10.1002/1615-9861(200207)2:7<919::AID-PROT919>3.0.CO;2-P; Qu YS, 2002, CLIN CHEM, V48, P1835; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; Sauter ER, 2002, BRIT J CANCER, V86, P1440, DOI 10.1038/sj/bjc/6600285; Srinivas PR, 2001, LANCET ONCOL, V2, P698, DOI 10.1016/S1470-2045(01)00560-5; TIMM N, 2002, APPL MULTIVARIATE AN; Wright George L Jr, 2002, Expert Rev Mol Diagn, V2, P549, DOI 10.1586/14737159.2.6.549; Wulfkuhle JD, 2002, CANCER RES, V62, P6740	38	50	52	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853			PROTEOMICS	Proteomics	MAR	2004	4	3					766	783		10.1002/pmic.200300574		18	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	802QX	WOS:000220179100020	14997498	
J	Goh, CS; Lan, N; Douglas, SM; Wu, BL; Echols, N; Smith, A; Milburn, D; Montelione, GT; Zhao, HY; Gerstein, M				Goh, CS; Lan, N; Douglas, SM; Wu, BL; Echols, N; Smith, A; Milburn, D; Montelione, GT; Zhao, HY; Gerstein, M			Mining the structural genomics pipeline: Identification of protein properties that affect high-throughput experimental analysis	JOURNAL OF MOLECULAR BIOLOGY			English	Article						structural genomics; COGs; charged residues; hydrophobicity; decision trees	INTERACTION NETWORK DATABASE; INTERACTING PROTEINS; UNSTRUCTURED PROTEINS; SEQUENCES; MIPS; PROTEOMICS; BIND; DIP; COMPLEXES; MEMBRANE	Structural genomics projects represent major undertakings that will change our understanding of proteins. They generate unique datasets that, for the first time, present a standardized view of proteins in terms of their physical and chemical properties. By analyzing these datasets here, we are able to discover correlations between a protein's characteristics and its progress through each stage of the structural genomics pipeline, from cloning, expression, purification, and ultimately to structural determination. First, we use tree-based analyses (decision trees and random forest algorithms) to discover the most significant, protein features that influence a protein's amenability to high-throughput experimentation. Based on this, we identify potential bottlenecks in various stages of the structural genomics process through specialized "pipeline schematics". We find that the properties of a protein that are most significant are: (i) whether it is conserved across many organisms; (ii) the percentage composition of charged residues; (iii) the occurrence of hydrophobic patches; (iv) the number of binding partners it has; and (v) its length. Conversely, a number of other properties that might have been thought to be important, such as nuclear localization signals, are not significant. Thus, using our tree-based analyses, we are able to identify combinations of features that best differentiate the small group of proteins for which a structure has been determined from all the currently selected targets. This information may prove useful in optimizing high-throughput experimentation. Further information is available from http://mining.nesg.org/. (C) 2003 Elsevier Ltd. All rights reserved.	Yale Univ, Dept Epidemiol & Publ Hlth, New Haven, CT 06520 USA; Univ Med & Dent New Jersey, NE Struct Genom Consortium, Robert Wood Johnson Med Sch, Piscataway, NJ 08854 USA; Univ Med & Dent New Jersey, Robert Wood Johnson Med Sch, Ctr Adv Biotechnol & Med, Piscataway, NJ 08854 USA; Rutgers State Univ, Robert Wood Johnson Med Sch, Dept Mol Biol & Biochem, UMDNJ, Piscataway, NJ 08854 USA; Univ Med & Dent New Jersey, Robert Wood Johnson Med Sch, Dept Biochem, Piscataway, NJ 08854 USA; Yale Univ, Dept Genet, New Haven, CT 06520 USA	Gerstein, M (reprint author), Yale Univ, Dept Epidemiol & Publ Hlth, 266 Whitney Ave, New Haven, CT 06520 USA.	mark.gerstein@yale.edu					Bader GD, 2001, NUCLEIC ACIDS RES, V29, P242, DOI 10.1093/nar/29.1.242; Bader GD, 2003, NUCLEIC ACIDS RES, V31, P248, DOI 10.1093/nar/gkg056; Bader GD, 2000, BIOINFORMATICS, V16, P465, DOI 10.1093/bioinformatics/16.5.465; Bertone P, 2001, NUCLEIC ACIDS RES, V29, P2884, DOI 10.1093/nar/29.13.2884; BREIMAN L, 2002, IMS WALD LECT 2 P IM; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brenner SE, 2000, PROTEIN SCI, V9, P197; Brenner SE, 2001, NAT REV GENET, V2, P801, DOI 10.1038/35093574; Brenner SE, 2000, NAT STRUCT BIOL, V7, P967, DOI 10.1038/80747; Chance MR, 2002, PROTEIN SCI, V11, P723, DOI 10.1110/ps.470102; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Dunker AK, 2001, NAT BIOTECHNOL, V19, P805, DOI 10.1038/nbt0901-805; Dyson HJ, 2002, CURR OPIN STRUC BIOL, V12, P54, DOI 10.1016/S0959-440X(02)00289-0; ENGELMAN DM, 1986, ANNU REV BIOPHYS BIO, V15, P321, DOI 10.1146/annurev.bb.15.060186.001541; Gattiker A, 2002, PROTEOMICS, V2, P1435, DOI 10.1002/1615-9861(200210)2:10<1435::AID-PROT1435>3.0.CO;2-9; Gavin AC, 2002, NATURE, V415, P141, DOI 10.1038/415141a; GIERASCH LM, 1989, BIOCHEMISTRY-US, V28, P923, DOI 10.1021/bi00429a001; Goh CS, 2003, NUCLEIC ACIDS RES, V31, P2833, DOI 10.1093/nar/gkg397; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Mewes HW, 2002, NUCLEIC ACIDS RES, V30, P31, DOI 10.1093/nar/30.1.31; Mewes HW, 1998, NUCLEIC ACIDS RES, V26, P33, DOI 10.1093/nar/26.1.33; Mewes HW, 1997, NUCLEIC ACIDS RES, V25, P28, DOI 10.1093/nar/25.1.28; Mewes HW, 1999, NUCLEIC ACIDS RES, V27, P44, DOI 10.1093/nar/27.1.44; Mewes HW, 2000, NUCLEIC ACIDS RES, V28, P37, DOI 10.1093/nar/28.1.37; Pedelacq JD, 2002, NAT BIOTECHNOL, V20, P927, DOI 10.1038/nbt732; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; RAPOPORT TA, 1992, SCIENCE, V258, P931, DOI 10.1126/science.1332192; Sali A, 2001, NAT STRUCT BIOL, V8, P482, DOI 10.1038/88529; Sanchez R, 2000, NAT STRUCT BIOL, V7, P986, DOI 10.1038/80776; Savchenko A, 2003, PROTEINS, V50, P392, DOI 10.1002/prot.10282; Service RF, 2002, SCIENCE, V298, P948, DOI 10.1126/science.298.5595.948; Service RF, 2000, SCIENCE, V287, P1954, DOI 10.1126/science.287.5460.1954; Sigrist Christian J A, 2002, Brief Bioinform, V3, P265, DOI 10.1093/bib/3.3.265; Tatusov RL, 1997, SCIENCE, V278, P631, DOI 10.1126/science.278.5338.631; Terwilliger TC, 2000, NAT STRUCT BIOL, V7, P935, DOI 10.1038/80700; Tong AHY, 2002, SCIENCE, V295, P321, DOI 10.1126/science.1064987; Uetz P, 2000, NATURE, V403, P623; von Heijne G, 1990, CURR OPIN CELL BIOL, V2, P604, DOI 10.1016/0955-0674(90)90100-S; WALHOUT AJ, 2000, SCIENCE, V287, P166; Walhout AJM, 2001, NAT REV MOL CELL BIO, V2, P55, DOI 10.1038/35048107; Wootton JC, 1996, METHOD ENZYMOL, V266, P554; Wright PE, 1999, J MOL BIOL, V293, P321, DOI 10.1006/jmbi.1999.3110; Xenarios I, 2001, NUCLEIC ACIDS RES, V29, P239, DOI 10.1093/nar/29.1.239; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Xenarios I, 2000, NUCLEIC ACIDS RES, V28, P289, DOI 10.1093/nar/28.1.289; Yokoyama S, 2003, CURR OPIN CHEM BIOL, V7, P39, DOI 10.1016/S1367-5931(02)00019-4; YU H, 2004, IN PRESS GENOME RES	49	86	94	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-2836			J MOL BIOL	J. Mol. Biol.	FEB 6	2004	336	1					115	130		10.1016/j.jmb.2003.11.053		16	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	768QX	WOS:000188587500010	14741208	
J	Hothorn, T; Lausen, B; Benner, A; Radespiel-Troger, M				Hothorn, T; Lausen, B; Benner, A; Radespiel-Troger, M			Bagging survival tree	STATISTICS IN MEDICINE			English	Article						bootstrap aggregation; censored data; prognostic factors; Brier score	REGRESSION TREES; CENSORED-DATA; CLASSIFICATION; PREDICTORS	Predicted survival probability functions of censored event free survival are improved by bagging survival trees. We suggest a new method to aggregate survival trees in order to obtain better predictions for breast cancer and lymphoma patients. A set of survival trees based on B bootstrap samples is computed. We define the aggregated Kaplan-Meier curve of a new observation by the Kaplan-Meier curve of all observations identified by the B leaves containing the new observation. The integrated Brier score is used for the evaluation of predictive models. We analyse data of a large trial on node positive breast cancer patients conducted by the German Breast Cancer Study Group and a smaller 'pilot' study on diffuse large B-cell lymphoma, where prognostic factors are derived from microarray expression values. In addition, simulation experiments underline the predictive power of our proposal. Copyright (C) 2004 John Wiley Sons, Ltd.	Univ Erlangen Nurnberg, Dept Med Informat Biometry & Epidemiol, D-91054 Erlangen, Germany; German Canc Res Ctr, Cent Unit Biostat, D-69120 Heidelberg, Germany; Populat Based Canc Registry Bavaria, D-91052 Erlangen, Germany	Lausen, B (reprint author), Univ Erlangen Nurnberg, Dept Med Informat Biometry & Epidemiol, Waldstr 6, D-91054 Erlangen, Germany.	berthold.lausen@rzmail.uni-erlangen.de	Hothorn, Torsten/A-3639-2010; Lausen, Berthold/D-4063-2012	Hothorn, Torsten/0000-0001-8301-0471; Lausen, Berthold/0000-0002-0594-7258			AKRITAS MG, 1986, J AM STAT ASSOC, V81, P1032, DOI 10.2307/2289079; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Altman DG, 2000, STAT MED, V19, P453, DOI 10.1002/(SICI)1097-0258(20000229)19:4<453::AID-SIM350>3.3.CO;2-X; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI [10.1175/1520-0493(1950)078lessthan0001:VOFEITgreaterthan2.0.CO;2, DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2]; Buhlmann P, 2002, ANN STAT, V30, P927; CIAMPI A, 1987, P JOSH FESTSCHR, P23; Dannegger F, 2000, STAT MED, V19, P475, DOI 10.1002/(SICI)1097-0258(20000229)19:4<475::AID-SIM351>3.0.CO;2-V; DAVIS RB, 1989, STAT MED, V8, P947, DOI 10.1002/sim.4780080806; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1981, J AM STAT ASSOC, V76, P312, DOI 10.2307/2287832; EISEN MB, 1998, SCANALYSE USER MANUA; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; GORDON L, 1985, CANCER TREAT REP, V69, P1065; Graf E, 1999, STAT MED, V18, P2529; HENDERSON R, 1995, STAT MED, V14, P161, DOI 10.1002/sim.4780140208; Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; KELES S, 2002, STAT MED, V21, P213; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; KORN EL, 1990, STAT MED, V9, P487, DOI 10.1002/sim.4780090503; Lausen B, 1994, CONTR STAT, P483; LAUSEN B, 1992, BIOMETRICS, V48, P73, DOI 10.2307/2532740; LEBLANC M, 2001, STAT ONCOLOGY, P457; LEBLANC M, 1993, J AM STAT ASSOC, V88, P457, DOI 10.2307/2290325; LEBLANC M, 1992, BIOMETRICS, V48, P411, DOI 10.2307/2532300; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; Peters A., 2002, R NEWS, V2, P33; SAUERBREI W, 1998, ENCY BIOSTATISTICS, P433; Sauerbrei W, 1999, J ROY STAT SOC A STA, V162, P71, DOI 10.1111/1467-985X.00122; Schumacher M., 2001, STAT ONCOLOGY, P321; SCHUMACHER M, 1994, J CLIN ONCOL, V12, P2086; SEGAL MR, 1988, BIOMETRICS, V44, P35, DOI 10.2307/2531894; Therneau TM, 1997, INTRO RECURSIVE PART	37	44	47	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0277-6715	1097-0258		STAT MED	Stat. Med.	JAN 15	2004	23	1					77	91		10.1002/sim.1593		15	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Medicine, Research & Experimental; Statistics & Probability	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Research & Experimental Medicine; Mathematics	760YB	WOS:000187861900006	14695641	
J	Bock, RK; Chilingarian, A; Gaug, M; Hakl, F; Hengstebeck, T; Jirina, M; Klaschka, J; Kotrc, E; Savicky, P; Towers, S; Vaiclulis, A; Wittek, W				Bock, RK; Chilingarian, A; Gaug, M; Hakl, F; Hengstebeck, T; Jirina, M; Klaschka, J; Kotrc, E; Savicky, P; Towers, S; Vaiclulis, A; Wittek, W			Methods for multidimensional event classification: a case study using images from a Cherenkov gamma-ray telescope	NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT			English	Article						classification; discrimination; multivariate; neural networks; kernel methods; nearest-neighbour; regression trees		We present results from a case study comparing different multivariate classification methods. The input is a set of Monte Carlo data, generated and approximately triggered and pre-processed for an imaging gamma-ray Cherenkov telescope. Such data belong to two classes, originating either from incident gamma rays or caused by hadronic showers. There is only a weak discrimination between signal (gamma) and background (hadrons), making the data an excellent proving ground for classification techniques. The data and methods are described, and a comparison of the results is made. Several methods give results comparable in quality within small fluctuations, suggesting that they perform at or close to the Bayesian limit of achievable separation. Other methods give clearly inferior or inconclusive results. Some problems that this study can not address are also discussed. (C) 2003 Elsevier B.V. All rights reserved.	Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany; Inst Phys, Cosmic Ray Div, Yerevan, Armenia; Inst Fis Altes Energies, Barcelona, Spain; Acad Sci Czech Republ, Inst Comp Sci, Prague, Czech Republic; Univ GH Siegen, Fachbereich Phys, Siegen, Germany; SUNY Stony Brook, Stony Brook, NY 11794 USA; Univ Rochester, Rochester, NY 14627 USA	Bock, RK (reprint author), Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany.	rkb@mail.cern.ch	Hakl, Frantisek/A-5717-2014; Klaschka, Jan/A-6076-2014; Jirina, Marcel/B-2846-2014; chilingarian, ashot/E-1606-2014; Savicky, Petr/E-7685-2014; GAug, Markus/L-2340-2014	chilingarian, ashot/0000-0002-2018-9715; GAug, Markus/0000-0001-8442-7877			Ametller L, 1996, PHYS REV D, V54, P1233, DOI 10.1103/PhysRevD.54.1233; BOCK RK, 1999, 9904 MAGIC; Breiman L., 1983, CLASSIFICATION REGRE; Breiman L., 1999, COMBINING ARTIFICIAL; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, MANUAL SETTING USING; BREIMAN L, FORTRAN PROGRAM RAND; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chilingaryan A, 2002, MATH BIOSCI, V176, P59, DOI 10.1016/S0025-5564(01)00105-5; CHRISTIANINI N., 2000, INTRO SUPPORT VECTOR; DUNLEA S, 2001, P 2M INT COSM RAY C, P2939; EGAN JP, 1975, SIGNAL DETECTION THE; ERNENWEIN JP, NEUNET PACKAGE ROOT; Farlow S. J., 1984, SELF ORG METHODS MOD; Fegan DJ, 1997, J PHYS G NUCL PARTIC, V23, P1013, DOI 10.1088/0954-3899/23/9/004; GAUG M, 2001, 2 WORKSH METH ASP UN, P123; Hastie T., 2001, ELEMENTS STAT LEARNI; Heck D., 1998, 6019 FZKA; JIRINA M, 1994, P 10 IFAC S SYST ID, V2, P309; JIRINA M, 1995, NEURAL NETWORK WORLD, V5, P329; JOLLIFE IT, 1986, MANY TXB EXPLAIN PCA; KESTEL M, 2001, P 27 INT COSM RAY C; KNUTESON B, 2001, ABSTR PHYSICS; KRANICH D, 2001, THESIS TU MUNCHEN; MORIARTY P, 1999, AIP C P, V515, P338; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1996, P AAAI 96 PORTL OR; TOWERS S, TERRAFERMA SUITE MUL; VAICIULIS A, 2002, P C ADV STAT TECHN P; 2002, P C ADV STAT TECHN P	30	59	59	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0168-9002			NUCL INSTRUM METH A	Nucl. Instrum. Methods Phys. Res. Sect. A-Accel. Spectrom. Dect. Assoc. Equip.	JAN 11	2004	516	2-3					511	528		10.1016/j.nima.2003.08.157		18	Instruments & Instrumentation; Nuclear Science & Technology; Physics, Particles & Fields; Spectroscopy	Instruments & Instrumentation; Nuclear Science & Technology; Physics; Spectroscopy	763KC	WOS:000188083200026		
B	Guo, L; Ma, Y; Cukic, B; Singh, H			ieee computer society	Guo, L; Ma, Y; Cukic, B; Singh, H			Robust prediction of fault-proneness by random forests	15TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, PROCEEDINGS			English	Proceedings Paper	15th International Symposium on Software Reliability Engineering	NOV 02-05, 2004	St Malo, FRANCE	IEEE Comp Soc, Reliabil Soc, IRISA, cigital, Microsoft, france telecom R&D, Thales, IBM, CNRS, DGA, INRIA, Metropole Rennes, Bretagne Reg, Univ Rennes			HIGH-RISK; METRICS	Accurate prediction of fault prone modules (a module is equivalent to a C function or a C++ method) in software development process enables effective detection and identification of defects. Such prediction models are especially beneficial for large-scale systems, where verification experts need to focus their attention and resources to problem areas in the system under development. This paper presents a novel methodology for predicting fault prone modules, based on random forests. Random forests are an extension of decision tree learning. Instead of generating one decision tree, this methodology generates hundreds or even thousands of trees using subsets of the training data. Classification decision is obtained by voting. We applied random forests in five case studies based on NASA data sets. The prediction accuracy of the proposed methodology is generally higher than that achieved by logistic regression, discriminant analysis and the algorithms in two machine learning software packages, WEKA [32] and See5 [5]. The difference in the performance of the proposed methodology over other methods is statistically significant. Further the classification accuracy of random forests is more significant over other methods in larger data sets.	W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA	Guo, L (reprint author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.						Azar D., 2002, Proceedings ASE 2002. 17th IEEE International Conference on Automated Software Engineering, DOI 10.1109/ASE.2002.1115031; Basili VR, 1996, IEEE T SOFTWARE ENG, V22, P751, DOI 10.1109/32.544352; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRIAND LC, 1993, IEEE T SOFTWARE ENG, V19, P1028, DOI 10.1109/32.256851; Ebert C, 1996, SOFTWARE QUAL J, V5, P255, DOI 10.1007/BF00209184; Ebert C., 1998, Proceedings Ninth International Symposium on Software Reliability Engineering (Cat. No.98TB100257), DOI 10.1109/ISSRE.1998.730845; FENTON N, 1999, P 2 EUR SOFTW MEAS C; Gokhale S. S., 1997, P 3 ISSAT INT C REL, P31; GUO L, 2003, P 18 IEEE INT C AUT; Halstead M. H., 1977, ELEMENTS SOFTWARE SC; HUDEPOHL JP, 1996, IEEE SOFTWARE    SEP, P56; Khoshgoftaar T. M., 1997, Proceedings. The Eighth International Symposium on Software Reliability Engineering (Cat. No.97TB100170), DOI 10.1109/ISSRE.1997.630845; Khoshgoftaar TM, 1996, IEEE SOFTWARE, V13, P65, DOI 10.1109/52.476287; KHOSHGOFTAAR TM, 1995, J SYST SOFTWARE, V29, P85, DOI 10.1016/0164-1212(94)00130-F; Khoshgoftaar T. M., 2002, Proceedings Eighth IEEE Symposium on Software Metrics, DOI 10.1109/METRIC.2002.1011339; Kohavi R., 1995, INT JOINT C ART INT; *MCCAB ASS, SOFTW METR MCC METR; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; MCCABE TJ, 1989, COMMUN ACM, V32, P1415, DOI 10.1145/76380.76382; MENZIES T, 2004, UNPUB INT WORKSH MIN; MENZIES T, 2003, IEEE METR 03; MENZIES T, 2004, 2004 IEEE C HIGH ASS; MUNSON JC, 1992, IEEE T SOFTWARE ENG, V18, P423, DOI 10.1109/32.135775; SCHNEIDEWIND NF, 1992, IEEE T SOFTWARE ENG, V18, P410, DOI 10.1109/32.135774; SELBY RW, 1988, IEEE T SOFTWARE ENG, V14, P1743, DOI 10.1109/32.9061; Troster J., 1995, Annals of Software Engineering, V1, DOI 10.1007/BF02249047; Witten I. H., 1999, DATA MINING PRACTICA; Witten I. H., 1999, WEKA PRACTICAL MACHI	28	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2215-7				2004							417	428				12	Computer Science, Software Engineering	Computer Science	BBJ03	WOS:000225734400036		
B	Crawford, MM; Ham, JS; Chen, YC; Ghosh, JD			ieee	Crawford, MM; Ham, JS; Chen, YC; Ghosh, JD			Random forests of binary hierarchical classifiers for analysis of hyperspectral data	2003 IEEE WORKSHOP ON ADVANCES IN TECHNIQUES FOR ANALYSIS OF REMOTELY SENSED DATA			English	Proceedings Paper	IEEE Workshop on Advances in Techniques for Analysis of Remotely Sensed Data held in Honor of David A Landgrebe	OCT 27-28, 2003	Greenbelt, MD	IEEE	NASA Goddard Space Flight Visitor Ctr	binary hierarchical classifier; classification; EO-1; Hyperion; hyperspectral; Okavango Delta; random forests; random subspace feature selection	RANDOM SUBSPACE METHOD; FEATURE-EXTRACTION; FEATURE-SELECTION; CLASSIFICATION; SAMPLES; FUSION	Statistical classification of hyperspectral data is challenging because the input space is high in dimension and correlated, but labeled information to characterize the class distributions is typically sparse. The resulting classifiers are often unstable and have poor generalization. A new approach that is based on the concept of random forests of classifiers and implemented within a multiclassifier system arranged as a binary hierarchy is proposed. The primary goal is to achieve improved generalization of the classifier in analysis of hyperspectral data, particularly when the quantity of training data is limited. The new classifier incorporates bagging of training samples and adaptive random subspace feature selection with the Binary Hierarchical Classifier (BHC), such that the number of features that is selected at each node of the tree is dependent on the quantity of associated training data. Classification results from experiments on data acquired by the Hyperion sensor on the NASA EO-1 satellite over the Okavango Delta of Botswana are superior to those from our original best basis BHC algorithm, a random subspace extension of the BHC, and a random forest implementation using the CART classifier.	Ctr Space Res, Austin, TX 78759 USA	Crawford, MM (reprint author), Ctr Space Res, 3925 W Braker Lane, Austin, TX 78759 USA.						Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CRAWFORD M, 2003 TYRRH INT WORKS, P15; Crawford MM, 1999, IEEE T GEOSCI REMOTE, V37, P1306, DOI 10.1109/36.763293; Dattatreya G.R., 1985, PROGR PATTERN RECOGN, V2; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; HASTIE T, 1999, P INT JOINT C NEUR N; HENNEGUELLE A, 2002, THESIS U TEXAS AUSTI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Jackson Q, 2001, IEEE T GEOSCI REMOTE, V39, P2664, DOI 10.1109/36.975001; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jeon B, 1999, IEEE T GEOSCI REMOTE, V37, P1073; Jia XP, 1999, IEEE T GEOSCI REMOTE, V37, P538; KORYCINSKI D, 2003, THESIS U TEXAS AUSTI; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718; Lee C, 1997, IEEE T NEURAL NETWOR, V8, P75; Morgan JT, 2002, LECT NOTES COMPUT SC, V2364, P189; NEUENSCHWANDER AL, IN PRESS INT J REMOT; OZA NC, 1999, P INT JOINT C NEUR N; PEARLMAN JS, IN PRESS IEEE T GEOS; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; Skurichina M, 1996, P 13 INT C PATT REC, V2, P891, DOI 10.1109/ICPR.1996.547204; Skurichina M, 2002, PATTERN ANAL APPL, V5, P121, DOI 10.1007/s100440200011; Tadjudin S, 1999, IEEE T GEOSCI REMOTE, V37, P2113, DOI 10.1109/36.774728; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839	32	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8350-8				2004							337	345				9	Remote Sensing	Remote Sensing	BAG84	WOS:000222142800049		
S	Dara, RA; Kamel, M			ieee	Dara, RA; Kamel, M			Sharing training patterns in neural network ensembles	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council			PERFORMANCE	The need for the design of complex and incremental training algorithms in multiple neural networks systems has motivated us to study combining methods from cooperation perspective. One way of achieving effective cooperation is through sharing resources such as information and components. The degree and method by which multiple classifier systems share training resources can be a measure of cooperation. Despite the growing number of interests in data modification techniques, such as bagging and k-fold corssvalidation, there is no guidance whether sharing or not sharing training patterns results in higher accuracy and under what conditions. We implemented several partitioning techniques and examined the effect of sharing training patterns by varying the size of overlap between 0-100% of the size of training subsets. Under most conditions studied, multinet systems showed improvement over presence of larger overlap subsets.	Univ Waterloo, Pattern Anal & Machine Intelligence Lab, Waterloo, ON N2L 3G1, Canada	Dara, RA (reprint author), Univ Waterloo, Pattern Anal & Machine Intelligence Lab, Waterloo, ON N2L 3G1, Canada.		Kamel, Mohamed/D-9323-2011; Kamel, Mohamed/	Kamel, Mohamed/0000-0001-6173-8082			Auda G, 1998, NEUROCOMPUTING, V20, P189, DOI 10.1016/S0925-2312(98)00013-7; Auda G, 1999, Int J Neural Syst, V9, P129, DOI 10.1142/S0129065799000125; BLAKE D, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chawla NV, 2003, PATTERN RECOGN LETT, V24, P455, DOI 10.1016/S0167-8655(02)00269-6; DARA R, 2003, THESIS U WATERLOO ON; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; DUIN RPW, 2002, P 16 INT C PATT REC, V2, P765; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GRANITTO P, 2002, BRAZ S NEUR NETW, P178; KAMEL M, 2003, 4 INT WORKSH MCS CAM, P1; Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X; Kuncheva L. I., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00093-3; LAM L, 2000, 1 INT WORKSH MCS CAG, P77; Munro PW, 1997, ADV NEUR IN, V9, P592; SHARKEY A, 2002, 3 INT WORKSH MCS CAG, P108; Sharkey AJC, 1996, NEURAL COMPUT APPL, V4, P218, DOI 10.1007/BF01413820; Verikas A, 1999, PATTERN RECOGN LETT, V20, P429, DOI 10.1016/S0167-8655(99)00012-4	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-8359-1	IEEE IJCNN			2004							1157	1161				5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900200		
S	Lemaire, V; Clerot, F			ieee	Lemaire, V; Clerot, F			An input variable importance definition based on empirical data probability and its use in variable selection	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council				Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. We propose a new method to score subsets of variables according to their usefulness for the performance of a given model. This method is applicable on every kind of model and on classification or regression task. We assess the efficiency of the method with our results on the NIPS 2003 feature selection challenge and with an example of a real application.	France Telecom Res & Dev, FTR&D, DTL, TIC, F-22307 Lannion, France	Lemaire, V (reprint author), France Telecom Res & Dev, FTR&D, DTL, TIC, 2 Ave Pierre Marzin, F-22307 Lannion, France.						BAXT WG, 1995, NEURAL COMPUT, V7, P624, DOI 10.1162/neco.1995.7.3.624; BLUM A, 1997, ARTIF INTELL, V1, P245; Breiman L., 2001, MACHINE LEARNING, V45; BURKITT AN, 1992, COMPLEX SYSTEM; Feraud R, 2002, NEURAL NETWORKS, V15, P237, DOI 10.1016/S0893-6080(01)00127-7; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; *JMLR, 2003, JMLR SPEC ISS VAR FE; KOHAVI R, 1997, ARFIFICIAL INTELLIGE, V97; MOODY J, 1994, PREDICTION RISK ARCH; REFENES AN, 1994, NEURAL NETWORKS, V7, P375; Welch G., 2001, SIGGRAPH	11	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-8359-1	IEEE IJCNN			2004							1375	1380				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900239		
S	Li, JY; Ramamohanarao, K		Dai, H; Srikant, R; Zhang, C		Li, JY; Ramamohanarao, K			A tree-based approach to the discovery of diagnostic biomarkers for ovarian cancer	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th Pacific/Asia Conference on Advances in Knowledge Discovery and Data Mining	MAY 26-28, 2004	Sydney, AUSTRALIA	NICIA, SAS, Univ Technol Sydney, Deakin Univ		decision trees; committee method; ovarian cancer; biomarkers; classification	CLASSIFICATION; PREDICTION	Computational diagnosis of cancer is a classification problem, and it has two special requirements on a learning algorithm: perfect accuracy and small number of features used in the classifier. This paper presents our results on an ovarian cancer data set. This data set is described by 15154 features, and consists of 253 samples. Each sample is referred to a woman who suffers from ovarian cancer or who does not have. In fact, the raw data is generated by the so-called mass spectrosmetry technology measuring the intensities of 15154 protein or peptide-features in a blood sample for every woman. The purpose is to identify a small subset of the features that can be used as biomarkers to separate the two classes of samples with high accuracy. Therefore, the identified features can be potentially used in routine clinical diagnosis for replacing labour-intensive and expensive conventional diagnosis methods. Our new tree-based method can achieve the perfect 100% accuracy in 10-fold cross validation on this data set. Meanwhile, this method also directly outputs a small set of biomarkers. Then we explain why support vector machines, naive bayes, and k-nearest neighbour cannot fulfill the purpose. This study is also aimed to elucidate the communication between contemporary cancer research and data mining techniques.	Inst Infocomm Res, Singapore 119613, Singapore; Univ Melbourne, Dept CSSE, Melbourne, Vic 3010, Australia	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@i2r.a-star.edu.sg; rao@cs.mu.oz.au					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Duda R. O., 1973, PATTERN CLASSIFICATI; Fayyad U., 1993, P 13 INT JOINT C ART, P1022; Freund Y., 1996, INT C MACH LEARN, P148; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Huiqing Liu, 2002, GENOME INFORMATICS, P51; JINYAN L, 2003, P ICDM, P585; JULIA D, 2001, NATURE REV CANC, V3, P267; Langley P., 1994, P 10 C UNC ART INT, P399; LI JY, 2003, BIOINFORMATICS, V19, P1193; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Quinlan JR, 1993, C45 PROGRAMS MACHINE; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22064-X	LECT NOTES ARTIF INT			2004	3056						682	691				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAF29	WOS:000221955100078		
S	Kapetanovic, IM; Rosenfeld, S; Izmirlian, G		Umar, A; Kapetanovic, I; Khan, J		Kapetanovic, IM; Rosenfeld, S; Izmirlian, G			Overview of commonly used bioinformatics methods and their applications	APPLICATIONS OF BIOINFORMATICS IN CANCER DETECTION	Annals of the New York Academy of Sciences		English	Article; Proceedings Paper	Applications of Bioinformatics in Cancer Detection Workshop	AUG 06-07, 2002	Bethesda, MD	NCI, Div Canc Prevent		bioinformatics; data mining; cancer; early detection; risk assessment; hierarchical clustering; neural networks; support vector machines; fuzzy logic; genomics; proteomics; drug discovery	ARTIFICIAL NEURAL NETWORKS; BREAST-CANCER DIAGNOSIS; GENE-EXPRESSION DATA; FUZZY-LOGIC; PROSTATE-CANCER; MEDICAL APPLICATIONS; PATTERNS; CLASSIFICATION; PROFILES; SERUM	Bioinformatics, in its broad sense, involves application of computer processes to solve biological problems. A wide range of computational tools are needed to effectively and efficiently process large amounts of data being generated as a result of recent technological innovations in biology and medicine. A number of computational tools have been developed or adapted to deal with the experimental riches of complex and multivariate data and transition from data collection to information or knowledge. These include a wide variety of clustering and classification algorithms, including self-organized maps (SOM), artificial neural networks (ANN), support vector machines (SVM), fuzzy logic, and even hyphenated techniques as neuro-jazzy networks. These bioinformatics tools are being evaluated and applied in various medical areas including early detection, risk assessment, classification, and prognosis of cancer. The goal of these efforts is to develop and identify bioinformatics methods with optimal sensitivity, specificity, and predictive capabilities.	NCI, Div Canc Prevent, Chemoprevent Agent Dev Res Grp, Bethesda, MD 20892 USA; NCI, Biometry Res Grp, Div Canc Prevent, Bethesda, MD 20892 USA	Kapetanovic, IM (reprint author), NCI, Div Canc Prevent, Chemoprevent Agent Dev Res Grp, Bethesda, MD 20892 USA.	kapetani@mail.nih.gov	Khan, Javed/P-9157-2014	Khan, Javed/0000-0002-5858-0488			Abbod MF, 2001, FUZZY SET SYST, V120, P331, DOI 10.1016/S0165-0114(99)00148-7; Adam BL, 2002, CANCER RES, V62, P3609; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213; Breiman L, 2002, MANUAL SETTING UP US; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Dayhoff JE, 2001, CANCER, V91, P1615, DOI 10.1002/1097-0142(20010415)91:8+<1615::AID-CNCR1175>3.0.CO;2-L; DEAN PM, 2002, BIOTECHNIQUES S, V32, pS28; DeLeo JM, 2001, IEEE IJCNN, P3009, DOI 10.1109/IJCNN.2001.938857; Errejon A, 2001, MOL UROL, V5, P153, DOI 10.1089/10915360152745821; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gruvberger S, 2001, CANCER RES, V61, P5979; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T., 2000, GENOME BIOL, V1; Jagota A., 2001, MICROARRAY DATA ANAL; Keller T, 1998, J CANCER RES CLIN, V124, P565, DOI 10.1007/s004320050216; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kovalerchuk B, 1997, ARTIF INTELL MED, V11, P75, DOI 10.1016/S0933-3657(97)00021-3; Kuncheva LI, 1999, ARTIF INTELL MED, V16, P121, DOI 10.1016/S0933-3657(98)00068-2; Lenz GR, 2000, DRUG DISCOV TODAY, V5, P145, DOI 10.1016/S1359-6446(00)01468-9; LIAW A, 2003, RANDOM FOREST PACKAG; Mahfouf M, 2001, ARTIF INTELL MED, V21, P27, DOI 10.1016/S0933-3657(00)00072-5; McLeod HL, 2001, ANNU REV PHARMACOL, V41, P101, DOI 10.1146/annurev.pharmtox.41.1.101; Pegg SCH, 2001, J COMPUT AID MOL DES, V15, P911, DOI 10.1023/A:1014389729000; Pena-Reyes CA, 1999, ARTIF INTELL MED, V17, P131, DOI 10.1016/S0933-3657(99)00019-6; Pena-Reyes CA, 2000, ARTIF INTELL MED, V19, P1, DOI 10.1016/S0933-3657(99)00047-0; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pratt JM, 2002, MOL CELL PROTEOMICS, V1, P579, DOI 10.1074/mcp.M200046-MCP200; Qu YS, 2002, CLIN CHEM, V48, P1835; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ringner M, 2002, PHARMACOGENOMICS, V3, P403, DOI 10.1517/14622416.3.3.403; Selaru FM, 2002, GASTROENTEROLOGY, V122, P606, DOI 10.1053/gast.2002.31904; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Steimann F, 1997, ARTIF INTELL MED, V11, P1; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Terfloth L, 2001, DRUG DISCOV TODAY, V6, pS102; TIBSHIRANI R, 1999, CLUSTERING METHODS A; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik V., 1998, STAT LEARNING THEORY; Verma B, 2001, IEEE T INF TECHNOL B, V5, P46, DOI 10.1109/4233.908389; Vitez TS, 1996, J CARDIOTHOR VASC AN, V10, P800, DOI 10.1016/S1053-0770(96)80210-2; Woolf PJ, 2000, PHYSIOL GENOMICS, V3, P9; XIAO Z, 2003, UNPUB; Xu Y, 2002, CANCER RES, V62, P3493; Yeang C H, 2001, Bioinformatics, V17 Suppl 1, pS316; Zheng X. F. Steven, 2002, Current Issues in Molecular Biology, V4, P33	52	35	38	NEW YORK ACAD SCIENCES	NEW YORK	2 EAST 63RD ST, NEW YORK, NY 10021 USA	0077-8923		1-57331-511-7	ANN NY ACAD SCI	Ann.NY Acad.Sci.		2004	1020						10	21		10.1196/annals.1310.003		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Oncology; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Oncology; Computer Science; Science & Technology - Other Topics	BAH03	WOS:000222177400002	15208179	
S	Izmirlian, G		Umar, A; Kapetanovic, I; Khan, J		Izmirlian, G			Application of the random forest classification algorithm to a SELDI-TOF proteomics study in the setting of a cancer prevention trial	APPLICATIONS OF BIOINFORMATICS IN CANCER DETECTION	ANNALS OF THE NEW YORK ACADEMY OF SCIENCES		English	Article; Proceedings Paper	Applications of Bioinformatics in Cancer Detection Workshop	AUG 06-07, 2002	Bethesda, MD	NCI, Div Canc Prevent		random forest (RF) algorithm; SELDI-TOF; cancer; classifier; classification tree (CT); detection; prevention; MDM; statistic	OVARIAN-CANCER; PATTERNS; SERUM	A thorough discussion of the random forest (RF) algorithm as it relates to a SELDI-TOF proteomics study is presented, with special emphasis on its application for cancer prevention: specifically, what makes it an efficient, yet reliable classifier, and what makes it optimal among the many available approaches. The main body of the paper treats the particulars of how to successfully apply the RF algorithm in a proteomics profiling study to construct a classifier and discover peak intensities most likely responsible for the separation between the classes.	NCI, DHHS, Div Canc Prevent, Biometry Res Grp, Rockville, MD 20852 USA	Izmirlian, G (reprint author), NCI, DHHS, Div Canc Prevent, Biometry Res Grp, Execut Plaza N,Suite 3131,6130 Execut Blvd,MSC 73, Rockville, MD 20852 USA.	izmirlian@nih.gov					BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 2003, RANDOM FOREST PACKAG; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Diamandis EP, 2002, LANCET, V360, P170, DOI 10.1016/S0140-6736(02)09390-X; Durrett R., 1991, PROBABILITY THEORY E; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Efron B., 1995, CROSS VALIDATION BOO; Elwood M, 2002, LANCET, V360, P170, DOI 10.1016/S0140-6736(02)09389-3; Hastie T., 2001, ELEMENTS STAT LEARNI; LIAW A, 2003, RANDOM FOREST PACKAG; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pollack A., 2004, NY TIMES, P1; Rockhill B, 2002, LANCET, V360, P169, DOI 10.1016/S0140-6736(02)09387-X; SVETNIK V, 2003, COMMUNICATION; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Yip TT, 2002, TECHNOL CANCER RES T, V1, P273; YOUDEN WJ, 1950, CANCER, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3	21	47	49	NEW YORK ACAD SCIENCES	NEW YORK	2 EAST 63RD ST, NEW YORK, NY 10021 USA	0077-8923		1-57331-510-9	ANN NY ACAD SCI	Ann.NY Acad.Sci.		2004	1020						154	174		10.1196/annals.1310.015		21	Biochemical Research Methods; Biotechnology & Applied Microbiology; Oncology; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Oncology; Computer Science; Science & Technology - Other Topics	BAH03	WOS:000222177400014	15208191	
B	Rodriguez, PN; Rodriguez, A			Wessex Inst of Technology	Rodriguez, PN; Rodriguez, A			Predicting stock market indices movements	COMPUTATIONAL FINANCE AND ITS APPLICATIONS			English	Proceedings Paper	1st International Conference on Computational Finance and its Applications	2004	Bologna, ITALY	Wessex Inst Technol		stock indices movements; data mining; ROC analysis	EFFICIENT CAPITAL-MARKETS; NEURAL-NETWORKS; ROC CURVE; CLASSIFICATION; SPLINES; AREA	This paper examines the extent to which the daily movements of three large emerging markets stock indices are predictable. Lagged technical indicators are used as explanatory variables. In the analysis, we employed seven classification techniques and assessed the discriminatory power of the classifiers through the area under the receiver operating characteristic (ROC) curve. The results show that the daily movements of the three indices are better predictable than random. After taking into account the bias induced by non-synchronous price quotations, a trading system with break-even costs is simulated. The non-random classifiers yield returns above those of both random walk and contrarian investment strategies. No inefficiency is found due to the fact that relatively low break-even transaction costs are enough to eliminate the sources of trading profits.	Univ Complutense Madrid, Dept Stat & Operat Res 2, E-28040 Madrid, Spain							Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CAMPBELL JY, 1994, ECONOMETRICS FINANCI; Chande T. S., 1994, NEW TECHNICAL TRADER; Chen CP, 2001, RARE METAL MAT ENG, V30, P31; FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486; FAMA EF, 1991, J FINANC, V46, P1575, DOI 10.2307/2328565; Fernandez-Rodriguez F, 2000, ECON LETT, V69, P89, DOI 10.1016/S0165-1765(00)00270-6; Friedman J. H., 2001, ANN STAT, V29; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Hand D. J., 1997, CONSTRUCTION ASSESSM; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T., 2002, ELEMENTS STAT LEARNI; JOKIVUOLLE E, 1995, J FINANC QUANT ANAL, V30, P455, DOI 10.2307/2331351; Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2; Leung MT, 2000, INT J FORECASTING, V16, P173, DOI 10.1016/S0169-2070(99)00048-5; Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Stone CJ, 1997, ANN STAT, V25, P1371; Tsaih R, 1998, DECIS SUPPORT SYST, V23, P161, DOI 10.1016/S0167-9236(98)00028-1; Zemke S, 1999, PHYSICA A, V269, P177, DOI 10.1016/S0378-4371(99)00091-6; Zhou X.-H., 2002, STAT METHODS DIAGNOS	26	0	0	WIT PRESS	SOUTHAMPTON	ASHURST LODGE, SOUTHAMPTON SO40 7AA, ASHURST, ENGLAND			1-85312-709-4				2004							13	23				11	Business, Finance; Computer Science, Artificial Intelligence	Business & Economics; Computer Science	BAR59	WOS:000223267800002		
S	Tuv, E; Runger, G		Ebecken, NFF; Brebbia, CA; Zanasi, A		Tuv, E; Runger, G			Learning patterns through artificial contrasts with application to process control	DATA MINING IV	MANAGEMENT INFORMATION SYSTEMS		English	Proceedings Paper	4th International Conference on Data Mining	DEC 01-03, 2003	Rio de Janeiro, BRAZIL	Wessex Inst Technol, Coppe, Fed Univ Rio de Janeiro				In manufacturing as well as other application areas there is a need to learn standard operating conditions in order to detect future changes or deviations. This is related to the even more general problem of detecting instances (cases, records) that are unusual compared to the bulk of the data (outliers). Examples of the problem are fault detection in chemical engineering and statistical process control. The outlier problem is ubiquitous. If specific deviations are not a priori specified, this is a type of unsupervised learning problem. The focus here is on the important, practical case for modem data environments. That is, training data with multiple (usual many) variables of mixed types (without the expedient assumptions common in statistics of multivariate normality that rarely holds in practice). An elegant technique is used to transform an unsupervised leaming problem to a supervised one. This methodology uses an artificial reference distribution. For the focus here such a specific reference distribution requires appropriate properties. Then an effective, universal, and nonparametric supervised learner (a gradient boosting machine) is applied to the transformed problem. The results are then in a sense inverted to the original problem. Extensions are mentioned as well as additional insight that becomes available. An illustrative example is presented to justify the validity of this generic and general methodology.	Intel Corp, Anal & Control Technol, Santa Clara, CA 95051 USA	Tuv, E (reprint author), Intel Corp, Anal & Control Technol, Santa Clara, CA 95051 USA.						Breiman L, 1984, CLASSIFICATION REGRE; Breiman L., 2001, MACHINE LEARNING, V45; CUCKER F, 2001, B AMS, V39, P149; FREUND Y, 1995, LNCS; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J, 1999, STOCHASTIC GRADIENT; Friedman J. H., 1999, GREEDY FUNCTION APPR; Hotelling H., 1947, MULTIVARIATE QUALITY, P111; JACKSON JE, 1980, J QUAL TECHNOL, V12, P201; POGGIO T, 2003, MATH LEARNING DEALIN; Runger GC, 1996, COMMUN STAT THEORY, V25, P2203, DOI 10.1080/03610929608831832; Vapnik V., 1998, STAT LEARNING THEORY	12	0	0	WIT PRESS	SOUTHAMPTON	ASHURST LODGE, SOUTHAMPTON SO40 7AA, ASHURST, ENGLAND	1470-6326		1-85312-806-6	MANAG INFORMAT SYST			2004	7						63	72				10	Computer Science, Artificial Intelligence	Computer Science	BY82D	WOS:000189471200006		
S	Gamberger, D; Lavrac, N		LopezdeMantaras, R; Saitta, L		Gamberger, D; Lavrac, N			Avoiding data overfitting in scientific discovery: Experiments in functional genomics	ECAI 2004: 16TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	16th European Conference on Artificial Intelligence	AUG 22-27, 2004	Valencia, SPAIN	European Coordinating Comm Artificial Intelligence, Asoc Espanola Inteligencia Artificial, Assoc Catalana Intelligencia Artificial, Univ Politecn Valencia, Grp Tecnol Informat			CANCER	Functional genomics is a typical scientific discovery domain characterized by a very large number of attributes (genes) relative to the number of examples (observations). The danger of data overfitting is crucial in such domains. This work presents an approach which can help in avoiding data overfitting in supervised inductive learning of short rules that are appropriate for human interpretation. The approach is based on the subgroup discovery rule learning framework, enhanced by methods of restricting the hypothesis search space by exploiting the relevancy of features that enter the rule construction process as well as their combinations that form the rules. A multi-class functional genomics problem of classifying fourteen cancer types based on more than 16000 gene expression values is used to illustrate the methodology.	Rudjer Boskovic Inst, Zagreb, Croatia	Gamberger, D (reprint author), Rudjer Boskovic Inst, Pob 1016, Zagreb, Croatia.	dragan.gamberger@irb.hr; nada.lavrac@ijs.si					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; DUDOIT S, 2000, 576 U CAL; FUMKRANZ J, 1999, ARTIF INTELL, V13, P3; GAMBERGER D, 2004, IN PRESS J BIOINFORM; Gamberger D., 2002, J ARTIF INTELL RES, V17, P501; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; LANGLEY P, 1997, COMPUTATIONAL LEARNI, V4; LAVRAC N, 1997, IEEE INTELL SYST APP, V13, P50; Li J, 2002, SER INF MANAGE SCI, V1, P325; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504	12	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		1-58603-452-9	FRONT ARTIF INTEL AP			2004	110						470	474				5	Computer Science, Artificial Intelligence	Computer Science	BBH24	WOS:000225505100091		
S	Autio, I; Lindgren, JT		LopezdeMantaras, R; Saitta, L		Autio, I; Lindgren, JT			Attention-driven parts-based object detection	ECAI 2004: 16TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS	FRONTIERS IN ARTIFICIAL INTELLIGENCE AND APPLICATIONS		English	Proceedings Paper	16th European Conference on Artificial Intelligence	AUG 22-27, 2004	Valencia, SPAIN	European Coordinating Comm Artificial Intelligence, Asoc Espanola Inteligencia Artificial, Assoc Catalana Intelligencia Artificial, Univ Politecn Valencia, Grp Tecnol Informat			FEATURES	Recent studies have argued that natural vision systems perform classification by utilizing different mechanisms depending on the visual input. In this paper we present a hybrid, data-driven object detection system that combines parts-based matching and view-based attention for faster detection. We propose a simple competitive policy that allows incremental addition of new object classes to the system without requiring class-vs-class training. Using our framework, we show empirical support for the hypothesis that low-frequency visual information can be effectively used to direct attention and possibly subsume further, more costly analysis. We evaluate our approach on face and car detection problems, while concentrating on the capability to learn from small samples. Our implementation is freely available as Matlab source code.	Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland	Autio, I (reprint author), Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland.						Agarwal S., 2002, P 7 EUR C COMP VIS; Bar M, 2003, J COGNITIVE NEUROSCI, V15, P600, DOI 10.1162/089892903321662976; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cristianini N., 2000, INTRO SUPPORT VECTOR; Elad M, 2002, PATTERN RECOGN LETT, V23, P1459, DOI 10.1016/S0167-8655(02)00106-X; Jesorski O., 2001, P 3 INT C AUD VID BA, P90; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Martinez A., 1998, 24 CVC; Palmer SE, 1999, VISION SCI; Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; VIDALNAQUET M, 2003, P 9 IEEE INT C COMP; Viola P, 2001, PROC CVPR IEEE, P511	13	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		1-58603-452-9	FR ART INT			2004	110						917	921				5	Computer Science, Artificial Intelligence	Computer Science	BBH24	WOS:000225505100177		
B	Geurts, P; El Khayat, L; Leduc, G		Rastogi, R; Morik, K; Bramer, M; Wu, X		Geurts, P; El Khayat, L; Leduc, G			A machine learning approach to improve congestion control over wireless computer networks	FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	4th IEEE International Conference on Data Mining	NOV 01-04, 2004	Brighton, ENGLAND	IEEE Comp Soc, TCCI, IEEE Comp Soc, TCPAMI, IBM Res, StatSoft Ltd, Web Intelligence Consortium				In this paper we present the application of machine learning techniques to the improvement of the congestion control of TCP in wired/wireless networks. TCP is suboptimal in hybrid wired/wireless networks because it reacts in the same way to losses due to congestion and losses due to link errors. We thus propose to use machine learning techniques to build automatically a loss classifier from a database obtained by simulations of random network topologies. Several machine learning algorithms are compared for this task and the best method for this application turns out to be decision tree boosting. It outperforms ad hoc classifiers proposed in the networking literature.	Univ Liege, B-4000 Liege, Belgium	Geurts, P (reprint author), Univ Liege, Sart Tilman,B28, B-4000 Liege, Belgium.	geurts@montefiore.ulg.ac.be; elkhayat@montefiore.ulg.ac.be; leduc@montefiore.ulg.ac.be					Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; ELKHAYAT I, 2004, CLASSIFICATION PACKE; Fawcett T., 2004, ROC GRAPHS NOTES PRA; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Fu CP, 2003, IEEE J SEL AREA COMM, V21, P216, DOI 10.1109/JSAC.2002.807336; GEURTS P, 2004, MACHINE LEARNING APP; GEURTS P, 2004, UNPUB EXTREMELY RAND; Mathiss M, 1997, ACM COMPUTER COMMUNI, V27, P67, DOI DOI 10.1145/263932.264023; McCanne S., 1997, LBNL NETWORK SIMULAT; WANG R, 2002, P 7 IEEE S COMP COMM; Xylomenos G, 2001, IEEE COMMUN MAG, V39, P52, DOI 10.1109/35.917504	14	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2142-8				2004							383	386		10.1109/ICDM.2004.10063		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBI95	WOS:000225713000057		
B	Kargupta, H; Dutta, H		Rastogi, R; Morik, K; Bramer, M; Wu, X		Kargupta, H; Dutta, H			Orthogonal decision trees	FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	4th IEEE International Conference on Data Mining	NOV 01-04, 2004	Brighton, ENGLAND	IEEE Comp Soc, TCCI, IEEE Comp Soc, TCPAMI, IBM Res, StatSoft Ltd, Web Intelligence Consortium				This paper introduces orthogonal decision trees that offer an effective way to construct a redundancy-free, accurate, and meaningful representation of large decision-tree-ensembles often created by popular techniques such as Bagging, Boosting, Random Forests and many distributed and data stream mining algorithms. Orthogonal decision trees are functionally orthogonal to each other and they correspond to the principal components of the underlying function space. This paper offers a technique to construct such trees based on eigen-analysis of the ensemble and offers experimental results to document the performance of orthogonal trees on grounds of accuracy and model complexity.	Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA	Kargupta, H (reprint author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, 1000 Hilltop Circle, Baltimore, MD 21250 USA.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Drucker H, 1996, ADV NEUR IN, V8, P479; Kargupta H., 2002, IEEE T KNOWL DATA EN, V16, P216; LINIAL N, 1993, J ACM, V40, P607, DOI 10.1145/174130.174138; Park B.H., 2002, P 7 WORKSH RES ISS D, P18; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; STREET WN, 2001, 7 ACM SIGKDD INT C K; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	9	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2142-8				2004							427	430		10.1109/ICDM.2004.10072		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBI95	WOS:000225713000068		
S	Ledezma, A; Aler, R; Sanchis, A; Borrajo, D		Khoshgoftaar, TM		Ledezma, A; Aler, R; Sanchis, A; Borrajo, D			Empirical evaluation of optimized stacking configurations	ICTAI 2004: 16TH IEEE INTERNATIONALCONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	16th IEEE International Conference on Tools with Artificial Intelligence	NOV 15-17, 2004	Boca Raton, FL	IEEE Comp Soc, Informat Technol Res Inst, Wright State Univ, Florida Atlantic Univ			CLASSIFIERS	Stacking is one of the most used techniques for combining classifiers and improve prediction accuracy. Early research in stacking showed that selecting the right classifiers, their parameters and the metaclassifiers was the main bottleneck for its use. Most of the research on this topic selects by hand the right combination of classifiers and their parameters. Instead of starting from these initial strong assumptions, our approach uses genetic algorithms to search for good stacking configurations. Since this can lead to overfitting, one of the goals of this paper is to evaluate empirically the overall efficiency of the approach. A second goal is to compare our approach with current best stacking building techniques. The results show that our approach finds stacking configurations that, in the worst case, perform as well as the best techniques, with the advantage of not having to set up manually the structure of the stacking system.	Univ Carlos III Madrid, Leganes 28911, Madrid, Spain	Ledezma, A (reprint author), Univ Carlos III Madrid, Avda Univ 30, Leganes 28911, Madrid, Spain.		Borrajo, Daniel/K-4379-2014; Ledezma , Agapito/K-3929-2014	Borrajo, Daniel/0000-0001-5282-0463; Ledezma , Agapito/0000-0002-0041-6829			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cherkauer K.J., 1996, AAAI WORKSH INT MULT, P15; Cleary JG, 1995, P 12 INT C MACH LEAR, P108; Cohen W. W., 1995, MACHINE LEARNING; Demirz G., 1997, P 9 EUR C MACH LEARN, P85; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich TG, 1997, AI MAG, V18, P97; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; DZEROSKI S, 2002, LECT NOTES COMPUTER; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Seewald A. K., 2001, Advances in Intelligent Data Analysis. 4th International Conference, IDA 2001. Proceedings (Lecture Notes in Computer Science Vol.2189); HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HOLLAND JH, 1975, ADAPTATION NATURAL A; Iba W., 1992, P 9 INT C MACH LEARN, P233; John G.H., 1995, P 11 C UNC ART INT, P338; KOHAVI R, 1995, P 8 EUR C MACH LEARN; Kolen JF, 1991, ADV NEURAL INFORMATI, V3, P860; LEDEZMA A, 2001, DATA MINING HEURISTI; Martin B., 1995, THESIS U WAIKATO; Merz CJ, 1999, MACH LEARN, V36, P33, DOI 10.1023/A:1007559205422; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; SEEWALD A, 2002, P 19 INT C MACH LEAR; Ting KM, 1999, J ARTIF INTELL RES, V10, P271; Todorovski L., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Witten I., 1998, P 15 INT C MACH LEAR, P144; WITTEN I, 2000, DATA MINING PRACICAL; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; WU J, 2002, ARTIFICIAL INTELLIGE, V137	32	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		0-7695-2236-X	PROC INT C TOOLS ART			2004							49	55				7	Computer Science, Artificial Intelligence	Computer Science	BBI06	WOS:000225597000006		
B	Chen, YC; Crawford, MM; Ghosh, J			ieee	Chen, YC; Crawford, MM; Ghosh, J			Integrating support vector machines in a hierarchical output space decomposition framework	IGARSS 2004: IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM PROCEEDINGS, VOLS 1-7: SCIENCE FOR SOCIETY: EXPLORING AND MANAGING A CHANGING PLANET	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium	SEP 20-24, 2004	Anchorage, AK	IEEE, IEEE Geosci & Remote Sensing Soc, Univ Alaska Fairbanks, Geophys Inst, Univ Missouri Columbia, NASA, NOAA, USN, Off Naval Res, Ball Aerosp &Technol Corp, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Raytheon, US Geol Survey, ITT Ind, IEEE Ocean Engn Soc, Int Union Radio Sci			CLASSIFIERS	This paper presents a new approach called Hierarchical Support Vector Machines (HSVM), to address multi-class problems. The method solves a series of max-cut problems to hierarchically and recursively partition the set of classes into two-subsets, till pure leaf nodes that have only one class label, are obtained. The SVM is applied at each internal node to construct the discriminant function for a binary meta-class classifier. Because max-cut unsupervised decomposition uses distance measures to investigate the natural class groupings, HSVM has a fast and intuitive SVM training process that requires little tuning and yields both high accuracy levels and good generalization. The HSVM method was applied to Hyperion hyperspectral data collected over the Okavango Delta of Botswana. Classification accuracies and generalization capability are compared to those achieved by the Best Basis Binary Hierarchical Classifier, a Random Forest CART binary decision tree classifier and Binary Hierarchical Support Vector Machines.	Univ Texas, Ctr Space Res, Austin, TX 78759 USA	Chen, YC (reprint author), Univ Texas, Ctr Space Res, 3925 W Braker Lane, Austin, TX 78759 USA.						Boser B. E., 1992, COMPUTATIONAL LEARNI, P144; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CRAWFORD MM, 2003, ADV TECHNIQUES ANAL, P337; DARE JA, 2004, THESIS U TEXAS AUSTI; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323; KULLBACK S, 1959, INFORMATION THEORY S; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; KUMAR S, 1999, GAMLS GEN FRAMEWORK; Nesterov Y. E., 1994, INTERIOR POINT POLYN; Rajan S, 2004, LECT NOTES COMPUT SC, V3077, P283; Schapire R E, 1997, P 14 INT C MACH LEAR, P322; Skurichina M, 2002, PATTERN ANAL APPL, V5, P121, DOI 10.1007/s100440200011; Todd M.J., 2001, SEMIDEFINITE OPTIMIZ	16	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8742-2	INT GEOSCI REMOTE SE			2004							949	952				4	Geosciences, Multidisciplinary; Instruments & Instrumentation; Remote Sensing; Imaging Science & Photographic Technology	Geology; Instruments & Instrumentation; Remote Sensing; Imaging Science & Photographic Technology	BBP98	WOS:000227006900251		
S	Vens, C; Van Assche, A; Blockeel, H; Dzeroski, S		Camacho, R; King, R; Srinivasan, AS		Vens, C; Van Assche, A; Blockeel, H; Dzeroski, S			First order random forests with complex aggregates	INDUCTIVE LOGIC PROGRAMMING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	14th International Conference on Inductive Logic Programming (ILP 2004)	SEP 06-08, 2004	Porto, PORTUGAL	Univ Porto, Fac Engn, Dept Elect Engn, Lab Intelligenc Artificial Ciencias Comp		random forests; aggregation; decision tree learning	MODELS	Random forest induction is a bagging method that randomly samples the feature set at each node in a decision tree. In propositional learning, the method has been shown to work well when lots of features are available. This certainly is the case in first order learning, especially when aggregate functions, combined with selection conditions on the set to be aggregated, are included in the feature space. In this paper, we introduce a random forest based approach to learning first order theories with aggregates. We experimentally validate and compare several variants: first order random forests without aggregates, with simple aggregates, and with complex aggregates in the feature set.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium; Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana 1000, Slovenia	Vens, C (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Heverlee, Belgium.	celine@cs.kuleuven.ac.be; anneleen@cs.kuleuven.ac.be; hendrik@cs.kuleuven.ac.be; Saso.Dzeroski@ijs.si					BERKA P, 2000, ECML PKDD 2002 DISCO; Blockeel H, 2002, J ARTIF INTELL RES, V16, P135; BLOCKEEL H, 2003, IJCAI 2003 WORKSH LE; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; Blockeel H., 1997, LECT NOTES ARTIF INT, V1297, P77; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, OUT OF BAG ESTIMATIO; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; De Raedt L., 1995, LECT NOTES ARTIF INT, V997, P80; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dzeroski S, 1998, APPL ARTIF INTELL, V12, P363, DOI 10.1080/088395198117686; EMDE W, 1995, P 1995 WORKSH GI SPE; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; JENSEN D, 2003, P 20 INT C MACH LEAR; Knobbe A. J., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Koller D, 1999, LECT NOTES ARTIF INT, V1634, P3; Krogel M.-A., 2001, P 11 INT C IND LOG P, P142; Lavrac N., 1994, INDUCTIVE LOGIC PROG; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muggleton S.H, 1992, INDUCTIVE LOGIC PROG; NEVILLE J, 2003, P 9 ACM SIGKDD INT C; Perlich Claudia, 2003, P 9 ACM SIGKDD INT C, P167; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Srinivasan A, 1999, LECT NOTES ARTIF INT, V1634, P291	26	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22941-8	LECT NOTES ARTIF INT			2004	3194						323	340				18	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAX01	WOS:000223999400024		
J	Jung, F				Jung, F			Detecting building changes from multitemporal aerial stereopairs	ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING			English	Article						change detection; classification; object recognition; digital elevation model; decision trees	RECONSTRUCTION; IMAGERY	Our goal is to detect changes in an aerial scene by comparing grey scale stereopairs taken several years apart in order to update a geographic database. A set of image locations that have a high likelihood to contain changes will be submitted to a human operator who will either reject the proposed change or validate it and update the database accordingly. We are mainly interested in changes in buildings. To isolate new construction and buildings, which disappear, we provide an algorithm that works in two steps. First, during a focusing phase, we eliminate a large part of the scene without losing any actual changes by comparing a Digital Elevation Model (DEM) for the two dates. Second, we classify the resulting regions of interest (ROI) based on four images-stereopairs of the area at the two dates. To decide whether or not the ROI contains a change, we classify each of the four images as "building" or "no-building". This classifier is a combination of several decision trees induced from training data. Each node of each decision tree is identified with a graph of features which is more likely to occur on buildings than background. Finally, the classification results at the two different dates are compared. The final set of locations submitted to an operator omits less than 10% of the true changes. The false positive rate represents less than 5% of the scene surface. (C) 2003 Elsevier B.V All rights reserved.	Inst Geog Natl, Lab MATIS, F-94165 St Mande, France	Jung, F (reprint author), Inst Geog Natl, Lab MATIS, 2-4 Ave Pasteur, F-94165 St Mande, France.	franck.jung@ign.fr					Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; BAILLARD C, 1997, THESIS ENST; Baillard C, 1999, COMPUT VIS IMAGE UND, V76, P244, DOI 10.1006/cviu.1999.0793; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHELLAPPA R, 1994, P ARPA IM UND WORKSH, P75; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HO T, 1998, PRAIRIE AGR MACHINER, V20, P565; HOOGS A, 1994, P APRA IM UND WORKSH, P1555; Huet C, 1996, P SOC PHOTO-OPT INS, V2955, P284; JAHN H, 2002, INT ARCH PHOTOGRA 3A, V34, P175; JAMET O, 1998, THESIS NIST; Jensen J. R., 1997, INTEGRATION GEOGRAPH; JUNG F, 1997, AUTOMATIC EXTRACTION, V2, P173; Mayer H, 2002, INT ARCH PHOTOGRA 3A, V34, P211; Mohammad R. M., 1989, Arid Soil Research and Rehabilitation, V3, P11; Paparoditis N, 1998, COMPUT VIS IMAGE UND, V72, P122, DOI 10.1006/cviu.1998.0722; SARKAR S, 1998, COMPUTER VISION IMAG, V71, P94	18	19	20	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0924-2716			ISPRS J PHOTOGRAMM	ISPRS-J. Photogramm. Remote Sens.	JAN	2004	58	3-4					187	201		10.1016/j.isprsjprs.2003.09.005		15	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	773LC	WOS:000188924400005		
B	Luzar-Stiffler, V; Stiffler, C			IEEE	Luzar-Stiffler, V; Stiffler, C			"BOF" trees diagram as a visual way to improve interpretability of tree ensembles	ITI 2004: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY INTERFACES			English	Proceedings Paper	26th International Conference on Information Technology Interfaces	JUN 07-10, 2004	Cavtat, CROATIA	IEEE Reg 8, Univ Comp Ctr, Univ Zagreb, Minist Sci Educ & Sports Republic Croatia, Int Assoc Math & Comp Simulat, Univ ViennaTech, ARGESIM, Athens Univ Econ & Business, Croatian Biometr Soc, Croatian Soc Simulat Modelling, N Carolina State Univ, Dept Comp Sci, Slovak Tech Univ, Dept Comp Sci & Engn, Brunel Univ, Dept Informat Syst & Comp, Polytech Univ Catalonia, Dept Statist & Operat Res, Univ Zagreb, Fac Elect Engn & Comp, IEEE Croatia Sect Comp Chapter, John VonNeumann Comp Soc, Jozef Stefan Inst		classification trees; BOF; bagging; visualization tools; web-survey; tree ensembles; data mining		The motivation for this research stemmed from a desire to create visual aids to help researchers/managers interpret ensembles of decision tree outputs generated by various algorithms. The method employed a simulation experiment (using only bagging) followed by application of the new visualization tools on actual survey data. Simulated data, with a pre-specified structure, were "bagged" with the results presented using five graphical tools that recreated (and/or portrayed) the known data structures captured by the bagging algorithm. Then the same methodology was generalized to a structurally unknown, virgin (survey) data set. Results of the research are that five visual aids tools were examined (two of which are new approaches) and found to be useful for making action oriented interpretations from e.g, web-survey data.	Univ Zagreb, Ctr Comp, Zagreb 41000, Croatia; CAIR Res Ctr, Zagreb, Croatia	Luzar-Stiffler, V (reprint author), Univ Zagreb, Ctr Comp, Zagreb 41000, Croatia.						Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; BREIMAN L, WALD LECT, V2; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARROLL JD, 1972, BEHAV SCI, V1; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Hasti T., 2001, ELEMENTS STAT LEARNI; Kass G., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; LUZARSTIFFLER V, 2004, SURVEY PRIMARY SECON; MORGAN J, 1963, J AM STAT ASSOC, P415; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	14	0	0	UNIV ZAGREB, FACULTY MECHANICAL ENGINEERING & NAVAL ARCHITECTURE	ZAGREB	IVANA LUCICA 5,, 10000 ZAGREB, CROATIA			953-96769-9-1				2004							243	248				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BBA40	WOS:000224384500036		
S	de la Calleja, J; Fuentes, O		Negoita, MG; Howlett, RJ; Jain, LC		de la Calleja, J; Fuentes, O			Automated classification of galaxy images	KNOWLEDGE-BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 3, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th International Conference on Knowledge-Based Intelligent Information and Engineering Systems	SEP, 2004	Wellington, NEW ZEALAND	Royal Soc New Zealand, IPENZ, New Zealand Trade & Enterprise, Telecom, Allied Telesyn, Positively Wellington Business	Wellington Inst Technol			In this paper we present an experimental study of the performance of three machine learning algorithms applied to the difficult problem of galaxy classification. We use the Naive Bayes classifier, the rule-induction algorithm C4.5 and a recently introduced classifier named random forest (RF). We first employ image processing to standardize the images, eliminating the effects of orientation and scale, then perform principal component analysis to reduce the dimensionality of the data, and finally, classify the galaxy images. Our experiments show that RF obtains the best results considering three, five and seven galaxy types.	Inst Nacl Astrofis Opt & Elect, Puebla 72840, Mexico	de la Calleja, J (reprint author), Inst Nacl Astrofis Opt & Elect, Luis Enrique Erro 1, Puebla 72840, Mexico.	jorge@ccc.inaoep.mx; fuentes@inaoep.mx					BALL N, 2002, THESIS U SUSSEX; Bazell D, 2001, ASTROPHYS J, V548, P219, DOI 10.1086/318696; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; de la Calleja J, 2004, MON NOT R ASTRON SOC, V349, P87, DOI 10.1111/j.1365-2966.2004.07442.x; Dietterich TG, 1997, AI MAG, V18, P97; GODERYA SN, 2002, ASTROPHYSICS SPACE S, V279; Lahav O, 1996, DATA ANAL ASTRONOMY; Madgwick DS, 2003, MON NOT R ASTRON SOC, V338, P197, DOI 10.1046/j.1365-8711.2003.06033.x; MAIN A, 1995, MONTHLY NOTICES ROYA, V275; Mitchell T. M., 1997, MACHINE LEARNING; OWENS EA, 1996, MONTHLY NOTICES ROYA, V281; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; STORRIELOMBARDI MC, 1992, MONTHLY NOTICES ROYA, V259; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758	14	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23205-2	LECT NOTES ARTIF INT			2004	3215						411	418				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBB77	WOS:000224585500055		
S	Hilario, M; Mitchell, A; Kim, JH; Bradley, P; Attwood, T		Boulicaut, JF; Esposito, F; Giannotti, F; Pedreschi, D		Hilario, M; Mitchell, A; Kim, JH; Bradley, P; Attwood, T			Classifying protein fingerprints	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2004, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	15th European Conference on Machine Learning/8th European Conference on Principles and Practice of Knowledge Discovery in Databases	SEP 20-24, 2004	Pisa, ITALY	KDNet, Pascal Network, Kluwer & Mach Learning Journal, Springer, Municipal Pisa, Microsoft Res, COOP, Exeura, INSA-Lyon, ISTI-Cnr, Univ Pisa, Univ Bari, Reg Toscana				Protein fingerprints are groups of conserved motifs which can be used as diagnostic signatures to identify and characterize collections of protein sequences. These fingerprints are stored in the PRINTs database after time-consuming annotation by domain experts who must first of all determine the fingerprint type, i.e., whether a fingerprint depicts a protein family, superfamily or domain. To alleviate the annotation bottleneck, a system called PRECIS has been developed which automatically generates PRINTs records, provisionally stored in a supplement called prePRINTS. One limitation of PRECIS is that its classification heuristics, handcoded by proteomics experts, often misclassify fingerprint type; their error rate has been estimated at 40%. This paper reports on an attempt to build more accurate classifiers based on information drawn from the fingerprints themselves and from the SWISS-PROT database. Extensive experimentation using 10-fold cross-validation led to the selection of a model combining the ReliefF feature selector with an SVM-RBF learner. The final model's error rate was estimated at 14.1% on a blind test set, representing a 26% accuracy gain over PRECIS' handcrafted rules.	Univ Geneva, Artificial Intelligence Lab, Geneva, Switzerland; European Bioinformat Inst, Cambridge CB10 1SD, England; Univ Manchester, Sch Biol Sci, Manchester, Lancs, England	Hilario, M (reprint author), Univ Geneva, Artificial Intelligence Lab, Geneva, Switzerland.	Melanie.Hilario@cui.unige.ch; mitchell@ebi.ac.uk; Jee.Kim@cui.unige.ch; pbradley@ebi.ac.uk; attwood@bioinf.man.ac.uk	Kim, Jee-Hyub/	Kim, Jee-Hyub/0000-0002-0359-2887			Attwood TK, 2003, NUCLEIC ACIDS RES, V31, P400, DOI 10.1093/nar/gkg030; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COHEN G, 2003, P INT S MED DAT AN B; Duda R., 2000, PATTERN CLASSIFICATI; Gama J., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00002-5; Hall M. A., 2000, P 17 INT C MACH LEAR; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Little R. J. A., 1987, STAT ANAL MISSING DA; Mitchell AL, 2003, BIOINFORMATICS, V19, P1664, DOI 10.1093/bioinformatics/btg204; Sikonja M., 2003, MACH LEARN, V53, P23; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Witten I., 2000, DATA MINING PRACTICA	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23108-0	LECT NOTES ARTIF INT			2004	3202						197	208				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAX57	WOS:000224109600020		
B	Iverson, LR; Prasad, AM; Liaw, A		Smithers, R		Iverson, LR; Prasad, AM; Liaw, A			New machine learning tools for predictive vegetation mapping after climate change: Bagging and Random Forest perform better than Regression Tree Analysis	LANDSCAPE ECOLOGY OF TREES AND FORESTS			English	Proceedings Paper	12th Annual Conference of the International-Association-for-Landscape-Ecology	JUN 21-24, 2004	Cirencester, ENGLAND	Int Assoc Landscape Ecol, UK Chapter	Royal Agr Coll			More and better machine learning tools are becoming available for landscape ecologists to aid in understanding species-environment relationships and to map probable species occurrence now and potentially into the future. To that end, we evaluated three statistical models: Regression Tree Analysis (RTA), Bagging Trees (BT) and Random Forest (RF) for their utility in predicting the distributions of four tree species under current and future climate. RTA's single tree was the easiest to interpret but is less accurate compared to BT and RF which use multiple regression trees with resampling and resampling-randomisation respectively. Future estimates of suitable habitat following climate change were also improved with BT and RF, with a slight edge to RF because it better smoothes the outputs in a logical gradient fashion. We recommend widespread use of these tools for GIS-based vegetation mapping.	USDA Forest Serv, Delaware, OH 43015 USA	Iverson, LR (reprint author), USDA Forest Serv, 359 Main Rd, Delaware, OH 43015 USA.						Boer GJ, 2000, CLIM DYNAM, V16, P427, DOI 10.1007/s003820050338; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Furlanello C., 2003, P 3 INT WORKSH DISTR, P1; Hagen A, 2003, INT J GEOGR INF SCI, V17, P235, DOI 10.1080/13658810210157822; HAWKINS DM, 1999, COMPUT SCI STAT, V30, P534; Iverson LR, 2001, ECOSYSTEMS, V4, P186, DOI 10.1007/s10021-001-0003-6; IVERSON LR, 1999, NE265 USDA FOR SERV; Iverson LR, 1998, ECOL MONOGR, V68, P465, DOI 10.2307/2657150; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Melillo JM, 1999, SCIENCE, V283, P183, DOI 10.1126/science.283.5399.183; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; MOORE DM, 1991, ENVIRON MANAGE, V15, P59, DOI 10.1007/BF02393838; Peters A., 2002, R NEWS, V2, P33; PRASAD A, UNPUB ECOSYSTEMS; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Therneau TM, 1997, 61 MAYO CLIN	18	4	4	IALE (UK), INT ASSOC LANDSCAPEECOL	LYMM	25 BIRCHBROOK RD, LYMM WA13 9SA, ENGLAND			0-9547130-1-X				2004							317	320				4	Ecology; Forestry	Environmental Sciences & Ecology; Forestry	BBL75	WOS:000226029800042		
S	Robnik-Sikonja, M		Boulicaut, JF; Esposito, F; Giannoti, F; Pedreschi, D		Robnik-Sikonja, M			Improving random forests	MACHINE LEARNING: ECML 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	15th European Conference on Machine Learning/8th European Conference on Principles and Practice of Knowledge Discovery in Databases	SEP 20-24, 2004	Pisa, ITALY	KDNet, Pascal Network, Kluwer & Mach Learning Journal, Springer, Municipal Pisa, Microsoft Res, COOP, Exeura, INSA-Lyon, ISTI-Cnr, Univ Pisa, Univ Bari, Reg Toscana				Random forests are one of the most successful ensemble methods which exhibits performance on the level of boosting and support vector machines. The method is fast, robust to noise, does not overfit and offers possibilities for explanation and visualization of its output. We investigate some possibilities to increase strength or decrease correlation of individual trees in the forest. Using several attribute evaluation measures instead of just one gives promising results. On the other hand replacement of ordinary voting with voting weighted with margin achieved on most similar instances gives improvements which are statistically highly significant over several data sets.	Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1001, Slovenia	Robnik-Sikonja, M (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, Ljubljana 1001, Slovenia.	Marko.Robnik@fri.uni-lj.si	Robnik-Sikonja, Marko/	Robnik-Sikonja, Marko/0000-0002-1232-3320			Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DEMSAR J, 2004, UNPUB STAT CORRECT C; Dietterich T., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); FREUND Y, 1996, ICML 96; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Kononenko I., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Murphy PM, 1995, UCI REPOSITORY MACHI; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Schapire R., 1997, ICML 97, P322; Zar J. H., 1998, BIOSTATISTICAL ANAL, V4th	15	37	39	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23105-6	LECT NOTES COMPUT SC			2004	3201						359	370				12	Computer Science, Artificial Intelligence	Computer Science	BAX02	WOS:000223999500034		
S	Banfield, RE; Hall, LO; Bowyer, KW; Bhadoria, D; Kegelmeyer, WP; Eschrich, S		Roli, F; Kittler, J; Windeatt, T		Banfield, RE; Hall, LO; Bowyer, KW; Bhadoria, D; Kegelmeyer, WP; Eschrich, S			A comparison of ensemble creation techniques	MULTIPLE CLASSIFIER SYSTEMS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	5th International Workshop on Multiple Classifier Systems	JUN 09-SEP 11, 2004	Cagliari, ITALY	Univ Cagliari, Dept Elect & Elect Engn, Univ Surrey, Ctr Vis, Speech & Signal Proc, Int Assoc Pattern Recognit, IAPR Tech Comm TC1				We experimentally evaluated bagging and six other randomization-based ensemble tree methods. Bagging uses randomization to create multiple training sets. Other approaches, such as Randomized C4.5, apply randomization in selecting a test at a given node of a tree. Then there are approaches, such as random forests and random subspaces, that apply randomization in the selection of attributes to be used in building the tree. On the other hand boosting incrementally builds classifiers by focusing on examples misclassified by existing classifiers. Experiments were performed on 34 publicly available data sets. While each of the other six approaches has some strengths, we find that none of them is consistently more accurate than standard bagging when tested for statistical significance.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Sandia Natl Labs, Biosyst Res Dept, Livermore, CA 94551 USA	Banfield, RE (reprint author), Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.	rbanfiel@csee.usf.edu; hall@csee.usf.edu; kwd@cse.nd.edu; dbhadori@csee.usf.edu; wpk@ca.sandia.gov; eschrich@csee.usf.edu	Eschrich, Steven/K-6848-2013; Bowyer, Kevin/	Bowyer, Kevin/0000-0002-7562-4390			BANFIELD R, 2003, OPENDT PROJECT; Banfield RE, 2003, LECT NOTES COMPUT SC, V2709, P306; Bowyer KW, 2000, IEEE SYS MAN CYBERN, P1888, DOI 10.1109/ICSMC.2000.886388; BRAZDIL P, STATL PROJ EV CHAR C; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chawla NV, 2003, PATTERN RECOGN LETT, V24, P455, DOI 10.1016/S0167-8655(02)00269-6; Collins M., 2000, P 13 ANN C COMP LEAR, P158; de Borda J. - C., 1781, MEMOIRE ELECTIONS SC; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; EIBL G, 2002, P 13 EUR C MACH LEAR, P72; Hall LO, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P533; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; HULTEN G, 2002, ADV NEURAL INFORMATI, V14, P673; Merz C.J., UCI REPOSITORY MACHI; Quinlan J.R., 1992, C4 5 PROGRAMS MACHIN; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Witten I. H., 1999, DATA MINING PRACTICA	20	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22144-1	LECT NOTES COMPUT SC			2004	3077						223	232				10	Computer Science, Theory & Methods	Computer Science	BAH27	WOS:000222210200022		
S	Svetnik, V; Liaw, A; Tong, C; Wang, T		Roli, F; Kittler, J; Windeatt, T		Svetnik, V; Liaw, A; Tong, C; Wang, T			Application of Breiman's random forest to modeling structure-activity relationships of pharmaceutical molecules	MULTIPLE CLASSIFIER SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Workshop on Multiple Classifier Systems	JUN 09-SEP 11, 2004	Cagliari, ITALY	Univ Cagliari, Dept Elect & Elect Engn, Univ Surrey, Ctr Vis, Speech & Signal Proc, Int Assoc Pattern Recognit, IAPR Tech Comm TC1			CLASSIFICATION; QSAR; SELECTION	Leo Breiman's Random Forest ensemble learning procedure is applied to the problem of Quantitative Structure-Activity Relationship (QSAR) modeling for pharmaceutical molecules. This entails using a quantitative description of a compound's molecular structure to predict that compound's biological activity as measured in an in vitro assay. Without any parameter tuning, the performance of Random Forest with default settings on six publicly available data sets is already as good or better than that of three other prominent QSAR methods: Decision Tree, Partial Least Squares, and Support Vector Machine. In addition to reliable prediction accuracy, Random Forest provides variable importance measures which can be used in a variable reduction wrapper algorithm. Comparisons of various such wrappers and between Random Forest and Bagging are presented.	Merck & Co Inc, Biometr Res, Rahway, NJ 07065 USA	Svetnik, V (reprint author), Merck & Co Inc, Biometr Res, POB 2000,RY33-300, Rahway, NJ 07065 USA.	vladimir_svetnik@merck.com; andy_liaw@merck.com; christopher_tong@merck.com; ting_wang@merck.com	Tong, Christopher/A-5761-2009	Tong, Christopher/0000-0003-0770-3270			Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Bakken GA, 2000, J MED CHEM, V43, P4534, DOI 10.1021/jm000244u; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Doniger S, 2002, J COMPUT BIOL, V9, P849, DOI 10.1089/10665270260518317; Ekins S, 2000, J PHARMACOL TOXICOL, V44, P251, DOI 10.1016/S1056-8719(00)00109-X; FRIEDMAN JH, IMPORTANCE SAMPLED L; GILLIGAN PJ, 1992, J MED CHEM, V35, P4344, DOI 10.1021/jm00101a012; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T., 2001, ELEMENTS STAT LEARNI; Hawkins DM, 2001, J CHEM INF COMP SCI, V41, P663, DOI 10.1021/ci0001177; Kauffman GW, 2001, J CHEM INF COMP SCI, V41, P1553, DOI 10.1021/ci010073h; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Penzotti JE, 2002, J MED CHEM, V45, P1737, DOI 10.1021/jm0255062; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s	17	48	48	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22144-1	LECT NOTES COMPUT SC			2004	3077						334	343				10	Computer Science, Theory & Methods	Computer Science	BAH27	WOS:000222210200033		
J	Wiemer, JC; Prokudin, A				Wiemer, JC; Prokudin, A			Bioinformatics in proteomics: application, terminology, and pitfalls	PATHOLOGY RESEARCH AND PRACTICE			English	Review						decision trees; bagging; mass spectrometry	PROSTATE-CANCER; IDENTIFICATION; BIOMARKERS	Bioinformatics applies data mining, i.e., modern computer-based statistics, to biomedical data. It leverages on machine learning approaches, such as artificial neural networks, decision trees and clustering algorithms, and is ideally suited for handling huge data amounts. In this article, we review the analysis of mass spectrometry data in proteomics, starting with common pre-processing steps and using single decision trees and decision tree ensembles for classification. Special emphasis is put on the pitfall of overfitting, i.e., of generating too complex single decision trees. Finally, we discuss the pros and cons of the two different decision tree usages. (C) 2004 Elsevier GmbH. All rights reserved.	Europroteome AG, D-16761 Hennigsdorf, Germany	Wiemer, JC (reprint author), Europroteome AG, Neuendorfstr 24B, D-16761 Hennigsdorf, Germany.	jwiemer@europroteome.com					Adam BL, 2002, CANCER RES, V62, P3609; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Campa MJ, 2003, PROTEOMICS, V3, P1659; EBERT MPA, 2004, UNPUB IDENTIFICATION; Hastie T., 2001, ELEMENTS STAT LEARNI; Lee KR, 2003, PROTEOMICS, V3, P1680, DOI 10.1002/pmic.200300515; Li JN, 2002, CLIN CHEM, V48, P1296; MEYER D, 2002, REPORT SERIES SFB; Qu YS, 2002, CLIN CHEM, V48, P1835; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; Scholkopf B, 2002, LEARNING KERNELS; SEIBERT V, UNPUB SURFACE ENHANC; Vlahou A, 2001, AM J PATHOL, V158, P1491, DOI 10.1016/S0002-9440(10)64100-4; Wiemer J, 2003, METHOD INFORM MED, V42, P126	17	12	12	URBAN & FISCHER VERLAG	JENA	BRANCH OFFICE JENA, P O BOX 100537, D-07705 JENA, GERMANY	0344-0338			PATHOL RES PRACT	Pathol. Res. Pract.		2004	200	2					173	178		10.1016/j.prp.2004.01.012		6	Pathology	Pathology	825ZO	WOS:000221798300012	15237926	
B	Fan, W			AAAI	Fan, W			On the optimality of probability estimation by random decision trees	PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Proceedings Paper	19th National Conference on Artificial Intelligence/16th Conference on Innovative Applications of Artificial Intelligence	JUL 25-29, 2004	San Jose, CA	Amer Assoc Artificial Intelligence				Random decision tree is an ensemble of decision trees. The feature at any node of a tree in the ensemble is chosen randomly from remaining features. A chosen discrete feature on a decision path cannot be chosen again. Continuous feature can be chosen multiple times, however, with a different splitting value each time. During classification, each tree outputs raw posterior probability. The probabilities from each tree in the ensemble are averaged as the final posterior probability estimate. Although remarkably simple and somehow counter-intuitive, random decision tree has been shown to be highly accurate under 0-1 loss and cost-sensitive loss functions. Preliminary explanation of its high accuracy is due to the "error-tolerance" property of probabilistic decision making. Our study has shown that the actual reason for random tree's superior performance is due to its optimal approximation to each example's true probability to be a member of a given class.	IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA	Fan, W (reprint author), IBM Corp, TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.						Bradford J. P., 1998, EUR C MACH LEARN, P131; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Fan W, 2003, P 3 IEEE INT C DAT M; Kearns M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237994; Mehta M, 1995, P 1 INT C KNOWL DISC, P216; Mehta Manish, 1996, EXTENDING DATABASE T, P18; Quinlan R., 1993, C4 5 PROGRAMS MACHIN	7	3	6	AMER ASSOC ARTIFICIAL INTELLIGENCE	MENLO PK	445 BURGESS DR, MENLO PK, CA 94025 USA			0-262-51183-5				2004							336	341				6	Computer Science, Artificial Intelligence	Computer Science	BBP85	WOS:000226971400054		
S	Wu, YM; Zhang, AD			IEEE Computer Society	Wu, YM; Zhang, AD			Feature selection for classifying high-dimensional numerical data	PROCEEDINGS OF THE 2004 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOL 2	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 27-JUL 02, 2004	Washington, DC	IEEE Comp Soc				Classifying high-dimensional numerical data is a very challenging problem. In high dimensional feature spaces, the performance of supervised learning methods suffer from the curse of dimensionality, which degrades both classification accuracy and efficiency. To address this issue, we present an efficient feature selection method to facilitate classifying high-dimensional numerical data. Our method employs balanced information gain to measure the contribution of each feature (for data classification); and it calculates feature correlation with a novel extension of balanced information gain. By integrating feature contribution and correlation, our feature selection approach uses a forward sequential selection algorithm to select uncorrelated features with large balanced information gain. Extensive experiments have been carried out on image and gene microarray datasets to demonstrate the effectiveness and robustness of the presented method.	SUNY Coll Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14222 USA	Wu, YM (reprint author), SUNY Coll Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14222 USA.						Aha D.W., 1996, LEARNING DATA, P199; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Ash R. B., 1965, INFORMATION THEORY; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, 567 U CAL DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; ELOMAA T, 1999, MACH LEARN, V36, P1; Fayyad U, 1993, P 13 INT JOINT C ART; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hall MA, 2000, P INT C MACH LEARN; Hall M.A., 1998, P 21 AUSTR COMP SCI; Mitchell T. M., 1997, MACHINE LEARNING; Press W. H., 1988, NUMERICAL RECIPES C; TIEU K, 2000, IEEE INT C COMP VIS; VASCONCELOS N, 2000, IEEE C CVPR; WU Y, 2003, IEEE INT C COMP VIS; WU Y, 2000, IEEE INT C CVPR; WU YM, 2004, IN PRESS ACM MULTIME	20	6	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2158-4	PROC CVPR IEEE			2004							251	258				8	Computer Science, Artificial Intelligence	Computer Science	BAU37	WOS:000223605500034		
B	Ma, SC; Shi, HB			ieee	Ma, SC; Shi, HB			Tree-augmented Naive Bayes ensembles	PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	AUG 26-29, 2004	Shanghai, PEOPLES R CHINA			ensemble; bagging; classifier; TAN		Ensemble learning is an effective method of improving classification accuracy of the classifier. TAN, Tree-Augmented Naive Bayes, is a tree-like Bayesian network. The standard TAN learning algorithm is the stable, which is difficult to improve its accuracy by bagging technique. In this paper, a new TAN learning algorithm called RTAN is presented, and the diversity of the TAN classifiers generated by RTAN is investigated by K statistic. And then Bagging-MultiTAN algorithm generates a TAN ensemble classifier. Through the comparisons of this TAN ensemble classifier with the standard TAN classifier in the experiments, the TAN ensemble classifier shows higher classification accuracy than the standard TAN classifier on the most data.	Shanxi Univ Finance & Econ, Sch Informat & Management, Taiyuan 030006, Peoples R China	Ma, SC (reprint author), Shanxi Univ Finance & Econ, Sch Informat & Management, Taiyuan 030006, Peoples R China.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bryll R, 2003, PATTERN RECOGN, V36, P1291, DOI 10.1016/S0031-3203(02)00121-8; Cheng Jie, 1999, P 15 C UNC ART INT U, P101; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 1997, AI MAG, V18, P97; DIETTERICH TG, HDB BRAIN THEORY NEU, P405; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Shi H., 2003, P 2003 IEEE INT C MA, P345; Witten I., 2000, DATA MINING PRACTICA	14	6	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8403-2				2004							1497	1502				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BBF92	WOS:000225293600295		
B	Martinez-Munoz, G; Suarez, A		Hamza, MH		Martinez-Munoz, G; Suarez, A			Aggregation ordering in bagging	Proceedings of the IASTED International Conference on Artificial Intelligence and Applications, Vols 1and 2			English	Proceedings Paper	IASTED International Conference on Artificial Intelligence and Applications	FEB 16-18, 2004	Innsbruck, AUSTRIA	Int Assoc Sci & Technol Dev		machine learning; bagging; ensemble pruning; decision trees	DECISION TREES	ne order in which classifiers are aggregated in ensemble methods can be an important tool in the identification of subsets of classifiers that, when combined, perform better than the whole ensemble. Ensembles with randomly ordered classifiers usually exhibit a generalization error that decreases as the number of classifiers that are aggregated increases. If an appropriate order for aggregation is chosen, the generalization error reaches, at intermediate numbers of classifiers, a minimum, which lies below the asymptotic error of the ensemble. This work presents some heuristics that exploit the relations between the classifiers in a bagging ensemble to identify the appropriate ordering and then select a subset for aggregation according to a desired amount pruning. The resulting subensembles are smaller and improve the classification performance of the original ensemble.	Univ Autonoma Madrid, Dept Ingn Informat, E-28049 Madrid, Spain	Martinez-Munoz, G (reprint author), Univ Autonoma Madrid, Dept Ingn Informat, Ciudad Univ Cantoblanco, E-28049 Madrid, Spain.		Martinez-Munoz, Gonzalo/K-7269-2012; Suarez, Alberto/D-6293-2011	Martinez-Munoz, Gonzalo/0000-0002-6125-6056; Suarez, Alberto/0000-0003-4534-0909			Bias Breiman L., 1996, 460 U CAL STAT DEP; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Margineantu D. D., 1997, P 14 INT C MACH LEAR, P211; MARTINEZMUNOZ G, 2003, IN PRESS IEEE T SY C; Prodromidis A. L., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011678; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; SCHAPIRE R, 1998, ANN STAT, V12, P1651; Sharkey A.J., 1999, COMBINING ARTIFICIAL; Tamon C., 2000, P 11 EUR C MACH LEAR, P404; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zhou ZH, 2003, LECT NOTES ARTIF INT, V2639, P476	19	25	28	ACTA PRESS	CALGARY	B6, STE 101, 2509 DIEPPE AVE SW, CALGARY, ALBERTA T3E 7J9, CANADA			0-88986-404-7				2004							258	263				6	Computer Science, Artificial Intelligence	Computer Science	BCC65	WOS:000228622100045		
B	Maree, R; Geurts, P; Visimberga, G; Piater, J; Wehenkel, L		Coenen, F; Preece, A; Macintosh, A		Maree, R; Geurts, P; Visimberga, G; Piater, J; Wehenkel, L			A comparison of generic machine learning algorithms for image classification	RESEARCH AND DEVELOPMENT IN INTELLIGENT SYSTEMS XX	BCS CONFERENCE SERIES		English	Proceedings Paper	23rd International Conference on Innovative Techniques and Applications of Artificial Intelligence	DEC, 2003	Cambridge, ENGLAND	SGAI			SUPPORT VECTOR MACHINES; RECOGNITION	In this paper, we evaluate 7 machine learning algorithms for image classification including our recent approach that combines building of ensembles of extremely randomized trees and extraction of sub-windows from the original images. For the approach to be generic, all these methods are applied directly on pixel values without any feature extraction. We compared them on four publicly available datasets corresponding to representative applications of image classification problems: handwritten digits (MNIST), faces (ORL), 3D objects (COIL-100), and textures (OUTEX). A comparison with studies from the computer vision literature shows that generic methods can come remarkably close to specialized methods. In particular, our sub-window algorithm is competitive with the state of the art, a remarkable result considering its generality and conceptual simplicity.	Univ Liege, Inst Montefiore, B-4000 Liege, Belgium	Maree, R (reprint author), Univ Liege, Inst Montefiore, B-4000 Liege, Belgium.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burges CJC, 1997, ADV NEUR IN, V9, P375; Chang C.C., 2003, LIBSVM LIB SUPPORT V; DAHMEN J, 2001, P 2 INT WORKSH MCS 2, P99; Drucker H., 1996, Proceedings. Fifth Annual Symposium on Document Analysis and Information Retrieval; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GEURTS P, 2002, THESIS U LIEGE; GEURTS P, 2003, EXTREMELY RANDOMIZED; Guo G.-D., 2001, P IEEE ICCV WORKSH R, P96; Guo Guodong, 2000, P INT C AUT FAC GEST, p[196, 201]; HOQUE MS, 2000, P 7 INT WORKSH FRONT, P595; KVALSETH TO, 1987, IEEE T SYST MAN CYB, V17, P517, DOI 10.1109/TSMC.1987.4309069; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; MAREE R, UNPUB GENERIC APPROA; MENP T, 2002, P 16 INT C PATT REC; Nefian A., 1999, P IEEE C AUD VID BAS, P19; OBRZALEK S, 2002, EL P 13 BRIT MACH VI; Ojala T, 2002, P 16 INT C PATT REC, V1, P701; Paredes R, 2001, P WORKSH PATT REC IN, P71; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; Vapnik VN, 1995, NATURE STAT LEARNING; Wehenkel L., 1998, AUTOMATIC LEARNING T	25	0	0	SPRINGER-VERLAG LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL RD FARNCOMBE, GODALMING GU7 1NH, SURREY, ENGLAND			1-85233-780-X	BCS CONFERENCE S			2004							169	182				14	Computer Science, Artificial Intelligence	Computer Science	BY78E	WOS:000189461700013		
B	Ren, SQ; Luo, L; Shang, WJ		Chen, J		Ren, SQ; Luo, L; Shang, WJ			A statistical analysis frame on complex data mining in service industries	SERVICE SYSTEMS AND SERVICE MANAGEMENT - PROCEEDINGS OF ICSSSM '04, VOLS 1 AND 2			English	Proceedings Paper	International Conference on Service Systems and Service Management	JUL 19-21, 2004	Beijing, PEOPLES R CHINA	IEEE Syst, Man & Cybernet Soc, Tsinghua Univ, Sch Econ & Management		statistical methods; complex data; service industries; data mining; data analysis	INDEPENDENT COMPONENT ANALYSIS; BOOTSTRAP METHODS	Along with fast economic growth in China, it is important to develop service industries, such as banking, insurance, stock trading, telecommunications, tourism, transport, retailing, real estate, health, sports, education, etc. Theories and applications in service industries will be increasingly investigated, and more and more methods, technologies and tools will be used in data mining. Because of the complex characteristics of data in service industries, analysis ideas of statistical methods are discussed in this paper in order to help health development in service industries in China and promote management improvement. We provide general ideas about process steps in statistical analysis methods for complex data mining. Firstly, prepare complex data from service industries, and explore hierarchical variables by using cluster analysis, discriminant analysis, random forests, multiple additive regression trees, etc. Secondly, Sample from original complex data according to the hierarchical structures. Thirdly, reduce dimensions of the complex data by using project pursuit, principal component analysis or independent component analysis, etc. Fourthly, according to statistical distributions of response variables choose a proper statistical model or methods. If the response variables are subjected to the Normal, or Binomial, Poisson, Inverse Gaussian, Gamma distribution, then it should be mixed models. If the response variables have the other distributions, such as, Multinomial, Pareto, Weibull, Wishart or mixture distribution, then it should be Markov Chain Monte Carlo (MCMC) methods. If the response variables are unknown or complex distribution, Bootstrap methods may be used to fit and estimate.	Sichuan Univ, Inst Serv Management, Sch Business, Chengdu 610064, Sichuan, Peoples R China			Ren, Shiquan/B-4640-2009				Berson A., 2000, BUILDING DATA MINING; Berson A., 1997, DATA WAREHOUSE DATA; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.2307/2290687; CARLIN BP, 1995, J ROY STAT SOC B MET, V57, P473; Chambers R.L., 2003, ANAL SURVEY DATA; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Gilks WR, 1996, MARKOV CHAIN MONTE C; GOLDSTEIN H, 2004, MULTILEVEL STAT MODE; GROTH R, 1997, DATA MINING BUILDING; Han J., 2000, DATA MINING CONCEPTS; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Longford N. T., 1993, RANDOM COEFFICIENT M; REN S, 1999, THESIS W CHINA U MED; Roberts S, 2003, PATTERN RECOGN, V36, P1813, DOI 10.1016/S0031-3203(03)00002-5; SITTER RR, 1992, CAN J STAT, V20, P135, DOI 10.2307/3315464	20	0	0	INTERNATIONAL ACADEMIC PUBLISHERS LTD	HONG KONG	UNIT 1205, 12 FLOOR, SINO PLAZA, 255 GLOUCESTER ROAD, HONG KONG 00000, CAUSEWAY BAY, PEOPLES R CHINA			7-5062-6821-3				2004							500	505				6	Computer Science, Artificial Intelligence; Management; Operations Research & Management Science	Computer Science; Business & Economics; Operations Research & Management Science	BAV84	WOS:000223847800100		
S	Bonissone, PP		LopezDiaz, M; Gil, MA; Grzegorzewski, P; Hryniewicz, O; Lawry, J		Bonissone, PP			Development and maintenance of fuzzy models in financial applications	SOFT METHODOLOGY AND RANDOM INFORMATION SYSTEMS	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	2nd International Conference on Soft Methods in Probability and Statistics (SMPS 2004)	SEP   02, 2004-SEP 04, 2007	Oviedo, SPAIN	Univ Oviedo, Dept Stat, OR & DM			SYSTEMS	Our goal is to illustrate the typical life cycle of a fuzzy knowledge-based model, starting from its development, testing, optimization, and deployment, and ending with the maintenance of its knowledge base. We illustrate this process within the context of an underwriting insurance application. First we define some key concepts of soft computing models and discuss some design tradeoffs that must be addressed. Then we focus on the design and implementation of a fuzzy rule-based classifier (FRC). We establish a standard reference dataset (SRD), consisting of 3,000 insurance applications with their corresponding decisions. The SRD exemplifies the results achieved by an ideal, optimal classifier, and represents the target for our design. We apply evolutionary algorithms to perform an off-line optimization of the design parameters of the classifier, modifying its behavior to approximate this target. The SRD is also used as a reference for testing and performing a five-fold cross-validation of the classifiers. Finally, we focus on the monitoring and maintenance of the FRC. We describe a fusion architecture that supports an off-line quality assurance process of the on-line FRC. The fusion module takes the outputs of multiple classifiers, determines their degree of consensus, and compares their overall agreement with the decision made by the FRC. From this analysis, we can identify the most suitable cases to update the SRD, to audit, or to be reviewed by senior underwriters.	Gen Elect Global Res Ctr Schenectady, Schenectady, NY 12309 USA	Bonissone, PP (reprint author), Gen Elect Global Res Ctr Schenectady, Schenectady, NY 12309 USA.						BABUSKA R, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P859, DOI 10.1109/FUZZY.1994.343848; BERSINI H, 1995, P INT C ART NEUR NET, V1, P169; Bonissone P, 2003, P 2003 N AM FUZZ INF, P488; BONISSONE P, 2002, P 2002 IEEE INT C FU, V2, P1003; BONISSONE P, 2004, P INF PROC MAN UNC 2; BONISSONE P, 2004, UNPUB EVOLUTIONARY A; Bonissone PP, 1999, P IEEE, V87, P1641, DOI 10.1109/5.784245; Bonissone P. P., 1997, Soft Computing, V1, DOI 10.1007/s005000050002; Breiman L., 1999, RANDOM FORESTS; Casillas J., 2003, STUDIES FUZZINESS SO, V128; CRISTANINI N, 2000, INTRO SUPPORT VECTOR; Freitas A.A., 2002, DATA MINING KNOWLEDG; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Guillaume S, 2001, IEEE T FUZZY SYST, V9, P426, DOI 10.1109/91.928739; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; LARRANAGA P, 2002, INT J APPROX REASONI, V31; MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2; PATTERSON A, 2004, IN PRESS INT J QUALI; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Vapnik VN, 1995, NATURE STAT LEARNING; Vonk E., 1997, AUTOMATIC GENERATION; Yao X, 1999, P IEEE, V87, P1423; Zadeh LA, 1994, P IIZUKA 94 3 INT C, P1	23	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-22264-2	ADV SOFT COMP			2004							50	66				17	Computer Science, Artificial Intelligence; Statistics & Probability	Computer Science; Mathematics	BAY44	WOS:000224212800006		
B	Yu, CY; Zhang, HP		Bozdogan, H		Yu, CY; Zhang, HP			Use of a secondary splitting criterion in classifiying forest construction	STATISTICAL DATA MINING AND KNOWLEDGE DISCOVERY			English	Proceedings Paper	C Warren Neel International Conference on Statistical Data Mining and Knowledge Discovery	JUN 22-25, 2002	Knoxville, TN	Dept Statist, Coll Business Adm, SAS Inst, Univ Tennessee Sci Alliance, Off Res Adm, Oak Ridge Natl Lab, Ctr Informat Technol & Res, Statist Innovat Inc, Classificat Soc N Amer			TUMOR CLASSIFICATION; EXPRESSION; GENE; PROTEIN		Yale Univ, New Haven, CT 06520 USA	Yu, CY (reprint author), Yale Univ, New Haven, CT 06520 USA.						Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Bai M, 2001, MODERN PATHOL, V14, P1105, DOI 10.1038/modpathol.3880444; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; DELMER A, 1995, BLOOD, V85, P2870; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hashimoto M, 2002, J PATHOL, V197, P341, DOI 10.1002/path.1126; Herblot S, 2002, MOL CELL BIOL, V22, P886; Moler EJ, 2000, PHYSIOL GENOMICS, V4, P109; Nilson I, 1997, BRIT J HAEMATOL, V98, P157, DOI 10.1046/j.1365-2141.1997.1522966.x; Xiong MM, 2000, BIOTECHNIQUES, V29, P1264; YU LM, 1992, J IMMUNOL, V148, P633; Zhang H, 1999, RECURSIVE PARTITIONI; Zhang HP, 1996, STAT MED, V15, P37, DOI 10.1002/(SICI)1097-0258(19960115)15:1<37::AID-SIM144>3.3.CO;2-S; ZHANG HP, 2002, CELL TUMOR CLASSIFIC; ZHANG HP, 2002, FRONT BIOSCI, V7, P63; ZHANG HP, 1995, AM J EPIDEMIOL, V141, P70; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	19	0	0	CHAPMAN & HALL/CRC PRESS	BOCA RATON	6000 BROKEN SOUND PKWY, NW, STE 300, BOCA RATON, FL 33487 USA			1-58488-344-8				2004							487	495				9	Computer Science, Artificial Intelligence; Statistics & Probability	Computer Science; Mathematics	BY55X	WOS:000189408200029		
J	Bureau, A; Dupuis, J; Hayward, B; Falls, K; Van Eerdewegh, P				Bureau, A; Dupuis, J; Hayward, B; Falls, K; Van Eerdewegh, P			Mapping complex traits using Random Forests	BMC GENETICS			English	Article; Proceedings Paper	13th Genetic Analysis Workshop	NOV 11-14, 2002	NEW ORLEANS, LOUISIANA				ASSOCIATION ANALYSES; LINKAGE	Random Forest is a prediction technique based on growing trees on bootstrap samples of data, in conjunction with a random selection of explanatory variables to define the best split at each node. In the case of a quantitative outcome, the tree predictor takes on a numerical value. We applied Random Forest to the first replicate of the Genetic Analysis Workshop 13 simulated data set, with the sibling pairs as our units of analysis and identity by descent (IBD) at selected loci as our explanatory variables. With the knowledge of the true model, we performed two sets of analyses on three phenotypes: HDL, triglycerides, and glucose. The goal was to approach the mapping of complex traits from a multivariate perspective. The first set of analyses mimics a candidate gene approach with a high proportion of true genes among the predictors while the second set represents a genome scan analysis using microsatellite markers. Random Forest was able to identify a few of the major genes influencing the phenotypes, such as baseline HDL and triglycerides, but failed to identify the major genes regulating baseline glucose levels.	Genome Therapeut Corp, Waltham, MA 02453 USA; Harvard Univ, Sch Med, Dept Psychiat, Boston, MA 02115 USA	Bureau, A (reprint author), Univ Lethbridge, Sch Hlth Sci, Lethbridge, AB T1K 3M4, Canada.	alexandre.bureau@uleth.ca; dupuis@bu.edu; bhayward@genomecorp.com; falls@genomecorp.com; pve@genomecorp.com					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Daw EW, 2003, BMC GENET, V4, DOI 10.1186/1471-2156-4-S1-S3; HASEMAN JK, 1972, BEHAV GENET, V2, P3, DOI 10.1007/BF01066731; Kruglyak L, 1996, AM J HUM GENET, V58, P1347; Mukhopadhyay N, 1999, AM J HUM GENET, V65, pA436; SAS Institute Inc, 1990, SAS LANG REF VERS 6, V1st; Zhang HP, 2001, GENET EPIDEMIOL, V21, pS317	7	18	19	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2156			BMC GENET	BMC Genet.	DEC 31	2003	4			1					S64	10.1186/1471-2156-4-S1-S64		5	Genetics & Heredity	Genetics & Heredity	765ZL	WOS:000188320900064	14975132	
J	Ghosh, D				Ghosh, D			Penalized discriminant methods for the classification of tumors from gene expression data	BIOMETRICS			English	Article						cross-validation; microarrays; partial least squares; principal components; regularization; ridge regression	PARTIAL LEAST-SQUARES; PRINCIPAL COMPONENTS REGRESSION; GENERALIZED LINEAR-REGRESSION; PREDICTION; CANCER	Due to the advent of high-throughput microarray technology, it has become possible to develop molecular classification systems for various types of cancer. In this article, we propose a methodology using regularized regression models for the classification of tumors in microarray experiments. The performances of principal components, partial least squares, and ridge regression models are studied; these regression procedures are adapted to the classification setting using the optimal scoring algorithm. We also develop a procedure for ranking genes based on the fitted regression models. The proposed methodologies are applied to two microarray studies in cancer.	Univ Michigan, Dept Biostat, Ann Arbor, MI 48105 USA	Ghosh, D (reprint author), Univ Michigan, Dept Biostat, 1420 Washington Hts, Ann Arbor, MI 48105 USA.						Alizadeh AA, 2001, J PATHOL, V195, P41, DOI 10.1002/path.889; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BULL SB, 1987, J AM STAT ASSOC, V82, P1118, DOI 10.2307/2289389; DENHAM MC, 1995, STAT COMPUT, V5, P191, DOI 10.1007/BF00142661; Dhanasekaran SM, 2001, NATURE, V412, P822, DOI 10.1038/35090585; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1975, J AM STAT ASSOC, V70, P113; Eilers P. H. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4266, DOI 10.1117/12.427987; Friedman J., 2001, ELEMENTS STAT LEARNI; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; HELLAND IS, 1988, COMMUN STAT SIMULAT, V17, P581, DOI 10.1080/03610918808812681; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Li HZ, 2001, GENOME BIOL, V2; LINDLEY DV, 1972, J ROY STAT SOC B, V34, P1; Marx BD, 1996, TECHNOMETRICS, V38, P374, DOI 10.2307/1271308; MARX BD, 1990, BIOMETRIKA, V77, P23, DOI 10.1093/biomet/77.1.23; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; NAES T, 1985, COMMUN STAT-SIMUL C, V14, P545, DOI 10.1080/03610918508812458; Nas T., 1989, MULTIVARIATE CALIBRA; STONE M, 1990, J ROY STAT SOC B MET, V52, P237; STONE M, 1974, J R STAT SOC B, V36, P111; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; WEST M, 2003, IN PRESS BAYESIAN ST, V7; WOLD H., 1975, PERSPECTIVES PROBABI; Yeang C H, 2001, Bioinformatics, V17 Suppl 1, pS316	31	26	26	BLACKWELL PUBLISHING LTD	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DG, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	DEC	2003	59	4					992	1000		10.1111/j.0006-341X.2003.00114.x		9	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	756UE	WOS:000187501100028	14969478	
J	Svetnik, V; Liaw, A; Tong, C; Culberson, JC; Sheridan, RP; Feuston, BP				Svetnik, V; Liaw, A; Tong, C; Culberson, JC; Sheridan, RP; Feuston, BP			Random forest: A classification and regression tool for compound classification and QSAR modeling	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							PARTIAL LEAST-SQUARES; RESISTANCE REVERSAL AGENTS; DESCRIPTORS; MACHINE; VECTOR	A new classification and regression tool, Random Forest, is introduced and investigated for predicting a compound's quantitative or categorical biological activity based on a quantitative description of the compound's molecular structure. Random Forest is an ensemble of unpruned classification or regression trees created by using bootstrap samples of the training data and random feature selection in tree induction. Prediction is made by aggregating (majority vote or averaging) the predictions of the ensemble. We built predictive models for six cheminformatics data sets. Our analysis demonstrates that Random Forest is a powerful tool capable of delivering performance that is among the most accurate methods to date. We also present three additional features of Random Forest: built-in performance assessment, a measure of relative importance of descriptors, and a measure of compound similarity that is weighted by the relative importance of descriptors. It is the combination of relatively high prediction accuracy and its collection of desired features that makes Random Forest uniquely suited for modeling in cheminformatics.	Merck Res Labs, Rahway, NJ 07065 USA; Merck Res Labs, W Point, PA 19486 USA	Svetnik, V (reprint author), Merck Res Labs, POB 2000, Rahway, NJ 07065 USA.		Tong, Christopher/A-5761-2009	Tong, Christopher/0000-0003-0770-3270			Bakken GA, 2000, J MED CHEM, V43, P4534, DOI 10.1021/jm000244u; Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; BREIMAN L, 2002, IMS WALD LECT 2; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 2003, MANUAL SETTING USING; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Brown RD, 1996, J CHEM INF COMP SCI, V36, P572, DOI 10.1021/ci9501047; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Dietterich T, 2002, HDB BRAIN THEORY NEU; DOMINGOS P, 2000, P 17 NAT C ART INT; Doniger S, 2002, J COMPUT BIOL, V9, P849, DOI 10.1089/10665270260518317; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; GILLIGAN PJ, 1992, J MED CHEM, V35, P4344, DOI 10.1021/jm00101a012; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2001, ELEMENTS STAT LEARNI; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; HAWKINS DM, 1999, COMPUT SCI STAT, V30, P534; Kauffman GW, 2001, J CHEM INF COMP SCI, V41, P1553, DOI 10.1021/ci010073h; Klopman G, 1997, MOL PHARMACOL, V52, P323; LIAW A, 2003, 2L ANN MIDW BIOPH ST; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; MEYER D, 2003, UNPUB NEUROCOMPUTING; *MIL CHEM, DRAGON; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Penzotti JE, 2002, J MED CHEM, V45, P1737, DOI 10.1021/jm0255062; Ripley B. D., 1996, PATTERN RECOGNITION; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Schapire RE, 1998, ANN STAT, V26, P1651; SHERIDAN RP, 1994, J COMPUT AID MOL DES, V8, P323, DOI 10.1007/BF00126749; SVETNIK V, 2001, P 7 COURS ENS METH L; Therneau TM, 1997, INTRO RECURSIVE PART; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; VALENTINI G, 2002, 3 INT WORKSH MULT CL; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Wolpert D. H., 1995, MATH GEN	40	433	443	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338			J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	NOV-DEC	2003	43	6					1947	1958		10.1021/ci034160g		12	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	748DK	WOS:000186848700029	14632445	
J	Meyer, D; Leisch, F; Hornik, K				Meyer, D; Leisch, F; Hornik, K			The support vector machine under test	NEUROCOMPUTING			English	Article						benchmark; comparative study; support vector machines; regression; classification	CLASSIFIERS; REGRESSION; BOOTSTRAP	Support vector machines (SVMs) are rarely benchmarked against other classification or regression methods. We compare a popular SVM implementation (libsvm) to 16 classification methods and 9 regression methods-all accessible through the software R-by the means of standard performance measures (classification error and mean squared error) which are also analyzed by the means of bias-variance decompositions. SVMs showed mostly good performances both on classification and regression tasks, but other methods proved to be very competitive. (C) 2003 Elsevier B.V. All rights reserved.	Vienna Tech Univ, Inst Stat & Wahrscheinlichkeitstheorie, A-1040 Vienna, Austria; Wirtschaftsuniv Wien, Inst Stat, A-1090 Vienna, Austria	Meyer, D (reprint author), Vienna Tech Univ, Inst Stat & Wahrscheinlichkeitstheorie, Wiedner Hauptstr 8-10-1071, A-1040 Vienna, Austria.		Leisch, Friedrich/A-6977-2013	Leisch, Friedrich/0000-0001-7278-1983			Anguita D, 2000, NEURAL PROCESS LETT, V11, P51, DOI 10.1023/A:1009636300083; AUER P, 2002, ARTIFICIAL NEURAL NE; Ben-Hur A., 2001, J MACHINE LEARNING R, V2, P125; BLAKE C, UCI REPOSITORY MACH; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CHAMBERS J M., 1998, PROGRAMMING DATA GUI; Chang CC, 2001, LIBSVM LIB SUPPORT V; Demirez A., 2000, APPL ALGORITHMS COMP; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; GESTEL TV, 2004, IN PRESS MACH LEARN; Guermeur Y., 2000, Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium, DOI 10.1109/IJCNN.2000.860770; Hastie T., 2001, ELEMENTS STAT LEARNI; HERBRICH R, 1999, P IJCAI WORKSH SUPP, P23; Hothorn T, 2003, PATTERN RECOGN, V36, P1303, DOI 10.1016/S0031-3203(02)00169-3; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; IHAKA R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; King R., 1995, APPL ARTIF INTELL, V9, P259; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Kong E., 1995, MACH LEARN, P313; LEISCH F, 1998, THESIS TU WIEN; LEISCH F, 2001, MLBENCH COLLECTION A; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Mangasarian OL, 2000, IEEE T PATTERN ANAL, V22, P950, DOI 10.1109/34.877518; MAYORAZ EN, 2001, ARTIFICIAL NEURAL NE; Meyer D., 2001, R NEWS, V1, P23; Michie D., 1994, MACHINE LEARNING NEU; NEAL R, 1998, NEUAL NETWORKS MACHI; Prechelt L, 1995, NEUROCOMPUTING, V9, P343, DOI 10.1016/0925-2312(95)00084-1; Prechelt L., 1994, PROBEN1 SET NEURAL N; RALAIVOLA L, 2001, ARTIFICIAL NEURAL NE; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Ripley B. D., 1996, PATTERN RECOGNITION; TIPPING ME, 2000, ADV NEURAL INFORMATI; Vapnik V., 1998, STAT LEARNING THEORY; Venables WN, 1996, MODERN APPL STAT S P; VINCENT P, 2001, P NEUR INF PROC SYST; Weston J., 1998, CSDTR9804 U LOND DEP	41	219	223	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	SEP	2003	55	1-2					169	186		10.1016/S0925-2312(03)00431-4		18	Computer Science, Artificial Intelligence	Computer Science	739PF	WOS:000186355100010		
J	Allen, E; Horvath, S; Tong, F; Kraft, P; Spiteri, E; Riggs, AD; Marahrens, Y				Allen, E; Horvath, S; Tong, F; Kraft, P; Spiteri, E; Riggs, AD; Marahrens, Y			High concentrations of long interspersed nuclear element sequence distinguish monoallelically expressed genes	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article							PRADER-WILLI-SYNDROME; X-CHROMOSOME INACTIVATION; ALLELE-SPECIFIC REPLICATION; DEPENDENT KINASE INHIBITOR; ZINC-FINGER GENE; GROWTH-FACTOR-II; IMPRINTED GENE; ASYNCHRONOUS REPLICATION; HUMAN GENOME; ANGELMAN SYNDROME	Genes subject to monoallelic expression are expressed from only one of the two alleles either selected at random (random monoallelic genes) or in a parent-of-origin specific manner (imprinted genes). Because high densities of long interspersed nuclear element (LINE)-1 transposon sequence have been implicated in X-inactivation, we asked whether monclallelically expressed autosomal genes are also flanked by high densities of LINE-1 sequence. A statistical analysis of repeat content in the regions surrounding monoallelically and biallelically expressed genes revealed that random monoallelic genes were flanked by significantly higher densities of LINE-1 sequence, evolutionarily more recent and less truncated LINE-1 elements, fewer CpG islands, and fewer base-pairs of short interspersed nuclear elements (SINEs) sequence than biallelically expressed genes. Random monoallelic and imprinted genes were pooled and subjected to a clustering analysis algorithm, which found two clusters on the basis of aforementioned sequence characteristics. Interestingly, these clusters did not follow the random monoallelic vs. imprinted classifications. We infer that chromosomal sequence context plays a role in monoallelic gene expression and may involve the recognition of long repeats or other features. The sequence characteristics that distinguished the high-LINE-1 category were used to identify more than 1,000 additional genes from the human and mouse genomes as candidate genes for monoallelic expression.	Univ Calif Los Angeles, Dept Human Genet, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Dept Biostat, Los Angeles, CA 90095 USA; Becman Res Inst City Hope, Div Biol, Duarte, CA 91010 USA	Marahrens, Y (reprint author), Univ Calif Los Angeles, Dept Human Genet, Los Angeles, CA 90095 USA.	ymarahrens@mednet.ucla.edu					Alders M, 2000, AM J HUM GENET, V66, P1473, DOI 10.1086/302892; Amiel A, 1999, EUR J HUM GENET, V7, P223, DOI 10.1038/sj.ejhg.5200267; Amiel A, 1997, HUM GENET, V101, P219, DOI 10.1007/s004390050619; Arima T, 2000, GENOMICS, V67, P248, DOI 10.1006/geno.2000.6266; BARLOW DP, 1991, NATURE, V349, P84, DOI 10.1038/349084a0; Bestor TH, 1998, CIBA F SYMP, V214, P187; Bix M, 1998, SCIENCE, V281, P1352, DOI 10.1126/science.281.5381.1352; Blagitko N, 2000, HUM MOL GENET, V9, P1587, DOI 10.1093/hmg/9.11.1587; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRIEMAN L, 1999, MANUAL SETTING UNDER; BROCKDORFF N, 1991, NATURE, V351, P329, DOI 10.1038/351329a0; BROWN CJ, 1991, NATURE, V349, P38, DOI 10.1038/349038a0; CHESS A, 1994, CELL, V78, P823, DOI 10.1016/S0092-8674(94)90562-2; Chess A, 1998, SCIENCE, V279, P2067, DOI 10.1126/science.279.5359.2067; DECHIARA TM, 1991, CELL, V64, P849, DOI 10.1016/0092-8674(91)90513-X; Dotan ZA, 2000, GENE CHROMOSOME CANC, V27, P270, DOI 10.1002/(SICI)1098-2264(200003)27:3<270::AID-GCC7>3.0.CO;2-7; Dreyer WJ, 1999, GENETICA, V107, P249, DOI 10.1023/A:1003909311678; Duvillie B, 1998, GENOMICS, V47, P52, DOI 10.1006/geno.1997.5070; Eggermann K, 1999, ANN GENET-PARIS, V42, P117; Evans HK, 2001, GENOMICS, V77, P99, DOI 10.1006/geno.2001.6612; Garrick D, 1998, NAT GENET, V18, P56, DOI 10.1038/ng0198-56; GARTLER SM, 1983, ANNU REV GENET, V17, P155, DOI 10.1146/annurev.ge.17.120183.001103; Gartler SM, 1999, HUM MOL GENET, V8, P1085, DOI 10.1093/hmg/8.6.1085; GIANNOUKAKIS N, 1993, NAT GENET, V4, P98, DOI 10.1038/ng0593-98; GIDDINGS SJ, 1994, NAT GENET, V6, P310, DOI 10.1038/ng0394-310; Greally JM, 2002, P NATL ACAD SCI USA, V99, P327, DOI 10.1073/pnas.012539199; GUILLEMOT F, 1995, NAT GENET, V9, P235, DOI 10.1038/ng0395-235; HATADA I, 1995, NAT GENET, V11, P204, DOI 10.1038/ng1095-204; Hayward BE, 1998, P NATL ACAD SCI USA, V95, P10038, DOI 10.1073/pnas.95.17.10038; HEILIG JS, 1987, P NATL ACAD SCI USA, V84, P8070, DOI 10.1073/pnas.84.22.8070; Held W, 1998, EUR J IMMUNOL, V28, P2407, DOI 10.1002/(SICI)1521-4141(199808)28:08<2407::AID-IMMU2407>3.0.CO;2-D; DORER DR, 1994, CELL, V77, P993, DOI 10.1016/0092-8674(94)90439-1; Hollander GA, 1998, SCIENCE, V279, P2118, DOI 10.1126/science.279.5359.2118; HOLMQUIST GP, 1989, J MOL EVOL, V28, P469, DOI 10.1007/BF02602928; Hu JF, 1997, J BIOL CHEM, V272, P20715, DOI 10.1074/jbc.272.33.20715; Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; ISSA M, 1969, CYTOGENETICS, V8, P219, DOI 10.1159/000130064; Jay P, 1997, NAT GENET, V17, P357, DOI 10.1038/ng1197-357; JINNO Y, 1994, NAT GENET, V6, P305, DOI 10.1038/ng0394-305; Jong MTC, 1999, HUM MOL GENET, V8, P795, DOI 10.1093/hmg/8.5.795; Kaghad M, 1997, CELL, V90, P809, DOI 10.1016/S0092-8674(00)80540-1; Kagotani K, 2002, BIOSCI BIOTECH BIOCH, V66, P1046; Kamiya M, 2000, HUM MOL GENET, V9, P453, DOI 10.1093/hmg/9.3.453; Kim J, 2001, GENOMICS, V77, P91, DOI 10.1006/geno.2001.6621; Kim J, 2000, GENOMICS, V64, P114, DOI 10.1006/geno.1999.6112; KITSBERG D, 1993, NATURE, V364, P459, DOI 10.1038/364459a0; Kobayashi S, 2000, GENES CELLS, V5, P1029, DOI 10.1046/j.1365-2443.2000.00390.x; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Kuroiwa Y, 1996, NAT GENET, V12, P186, DOI 10.1038/ng0296-186; LaSalle JM, 1996, SCIENCE, V272, P725, DOI 10.1126/science.272.5262.725; LASALLE JM, 1995, NAT GENET, V9, P386, DOI 10.1038/ng0495-386; Lee S, 2000, HUM MOL GENET, V9, P1813, DOI 10.1093/hmg/9.12.1813; LEFF SE, 1992, NAT GENET, V2, P259, DOI 10.1038/ng1292-259; Lyon MF, 1998, CYTOGENET CELL GENET, V80, P133, DOI 10.1159/000014969; LYON MF, 1961, NATURE, V190, P372, DOI 10.1038/190372a0; Marahrens Y, 1998, CELL, V92, P657, DOI 10.1016/S0092-8674(00)81133-2; Marahrens Y, 1999, GENE DEV, V13, P2624, DOI 10.1101/gad.13.20.2624; Matesanz F, 2000, EUR J IMMUNOL, V30, P3516, DOI 10.1002/1521-4141(2000012)30:12<3516::AID-IMMU3516>3.0.CO;2-S; Matsuoka S, 1996, P NATL ACAD SCI USA, V93, P3026, DOI 10.1073/pnas.93.7.3026; Matzke M., 1994, Homologous recombination and gene silencing in plants., P271; Meguro M, 2001, NAT GENET, V28, P19, DOI 10.1038/88209; Mostoslavsky R, 2001, NATURE, V414, P221, DOI 10.1038/35102606; Nicholls RD, 2001, ANNU REV GENOM HUM G, V2, P153, DOI 10.1146/annurev.genom.2.1.153; Nishita Y, 1996, GENOMICS, V36, P539, DOI 10.1006/geno.1996.0502; Ono R, 2001, GENOMICS, V73, P232, DOI 10.1006/geno.2001.6494; Onyango P, 2002, P NATL ACAD SCI USA, V99, P10599, DOI 10.1073/pnas.152327599; PalBhadra M, 1997, CELL, V90, P479, DOI 10.1016/S0092-8674(00)80508-5; Pavlicek A, 2001, GENE, V276, P39, DOI 10.1016/S0378-1119(01)00645-X; Plass C, 1996, NAT GENET, V14, P106, DOI 10.1038/ng0996-106; Qian N, 1997, HUM MOL GENET, V6, P2021, DOI 10.1093/hmg/6.12.2021; REED ML, 1994, NAT GENET, V6, P163, DOI 10.1038/ng0294-163; RIGGS AD, 1990, AUST J ZOOL, V37, P419; Rougeulle C, 1997, NAT GENET, V17, P14, DOI 10.1038/ng0997-14; Rousseeuw P. J., 1990, FINDING GROUPS DATA; Sano Y, 2001, GENOME RES, V11, P1833; Shemer R, 1996, P NATL ACAD SCI USA, V93, P6371, DOI 10.1073/pnas.93.13.6371; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P219, DOI 10.1007/BF02289621; SHI T, 2003, P 7 JOINT C INF SCI; Smit AFA, 1996, CURR OPIN GENET DEV, V6, P743, DOI 10.1016/S0959-437X(96)80030-X; SMIT AFA, 1995, J MOL BIOL, V246, P401, DOI 10.1006/jmbi.1994.0095; TSAI JY, 1991, GENETICS, V129, P1159; Verweij CL, 2001, ADV EXP MED BIOL, V495, P129; VILLAR AJ, 1994, NAT GENET, V8, P373, DOI 10.1038/ng1294-373; Watrin F, 1997, EUR J HUM GENET, V5, P324; Williamson CM, 1996, GENOMICS, V36, P280, DOI 10.1006/geno.1996.0463; WILLIAMSON CM, 1995, GENET RES, V65, P83; Yamada T, 2002, GENE, V288, P57, DOI 10.1016/S0378-1119(02)00428-6; Yoder JA, 1997, TRENDS GENET, V13, P335, DOI 10.1016/S0168-9525(97)01181-5; Yu YH, 1999, P NATL ACAD SCI USA, V96, P214, DOI 10.1073/pnas.96.1.214; ZHANG GH, 1994, NATURE, V372, P809; ZHANG YH, 1992, NAT GENET, V1, P40, DOI 10.1038/ng0492-40	92	87	90	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	AUG 19	2003	100	17					9940	9945		10.1073/pnas.1737401100		6	Multidisciplinary Sciences	Science & Technology - Other Topics	714QY	WOS:000184926000058	12909712	
J	Gunther, EC; Stone, DJ; Gerwien, RW; Bento, P; Heyes, MP				Gunther, EC; Stone, DJ; Gerwien, RW; Bento, P; Heyes, MP			Prediction of clinical drug efficacy by classification of drug-induced genomic expression profiles in vitro	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						pharmacogenomics; predictive efficacy; drug screening	GENE-EXPRESSION; PATTERNS; CANCER; DISTINGUISH; REVEALS; CELLS	Assays of drug action typically evaluate biochemical activity. However, accurately matching therapeutic efficacy with biochemical activity is a challenge. High-content cellular assays seek to bridge this gap by capturing broad information about the cellular physiology of drug action. Here, we present a method of predicting the general therapeutic classes into which various psychoactive drugs fall, based on high-content statistical categorization of gene expression profiles induced by these drugs. When we used the classification tree and random forest supervised classification algorithms to analyze microarray data, we derived general "efficacy profiles" of biomarker gene expression that correlate with antidepressant, antipsychotic and opioid drug action on primary human neurons in vitro. These profiles were used as predictive models to classify naive in vitro drug treatments with 83.3% (random forest) and 88.9% (classification tree) accuracy. Thus, the detailed information contained in genomic expression data is sufficient to match the physiological effect of a novel drug at the cellular level with its clinical relevance. This capacity to identify therapeutic efficacy on the basis of gene expression signatures in vitro has potential utility in drug discovery and drug target validation.	CuraGen Corp, Branford, CT 06405 USA	Gunther, EC (reprint author), CuraGen Corp, 322 E Main St, Branford, CT 06405 USA.						Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CALIFANO A, 2000, ISMB, V8, P75; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Hamadeh HK, 2002, TOXICOL SCI, V67, P232, DOI 10.1093/toxsci/67.2.232; Hamadeh HK, 2002, TOXICOL SCI, V67, P219, DOI 10.1093/toxsci/67.2.219; Hastie T., 2001, ELEMENTS STAT LEARNI; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Lakkis Maha M, 2002, Expert Rev Mol Diagn, V2, P337, DOI 10.1586/14737159.2.4.337; Mendez MA, 2002, FEBS LETT, V522, P24, DOI 10.1016/S0014-5793(02)02873-9; Perou CM, 1999, P NATL ACAD SCI USA, V96, P9212, DOI 10.1073/pnas.96.16.9212; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Stephanopoulos G, 2002, BIOINFORMATICS, V18, P1054, DOI 10.1093/bioinformatics/18.8.1054; Tejedor-Real P, 1998, EUR J PHARMACOL, V354, P1, DOI 10.1016/S0014-2999(98)00423-3; Venables WN, 1999, MODERN APPL STAT S P; Waring JF, 2002, CURR OPIN MOL THER, V4, P229; Waring JF, 2001, TOXICOL LETT, V120, P359, DOI 10.1016/S0378-4274(01)00267-3; Xu Y, 2002, CANCER RES, V62, P3493; Zhang Heping, 2002, Frontiers in Bioscience, V7, pc63, DOI 10.2741/zhang	24	123	129	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	AUG 5	2003	100	16					9608	9613		10.1073/pnas.1632587100		6	Multidisciplinary Sciences	Science & Technology - Other Topics	709HP	WOS:000184620000090	12869696	
J	Royston, P				Royston, P			The use of random forests regression for estimating prognosis with survival data	CONTROLLED CLINICAL TRIALS			English	Meeting Abstract	Joint International Conference of the International-Society-for-Clinical-Biostatistics/Society-for-Clinical-Trials	JUL 20-24, 2003	LONDON, ENGLAND	Int Soc Clin Biostat, Soc Clin Trials					MRC, Clin Trials Unit, London, England							Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; ROYSTON P, 2003, UNPUB REGRESSION RAN	2	0	0	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0197-2456			CONTROL CLIN TRIALS	Controlled Clin. Trials	JUN	2003	24			3		P206	198S	198S				1	Medicine, Research & Experimental; Pharmacology & Pharmacy	Research & Experimental Medicine; Pharmacology & Pharmacy	686TP	WOS:000183337300310		
J	van Rhee, AM				van Rhee, AM			Use of recursion forests in the sequential screening process: Consensus selection by multiple recursion trees	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							DATA SET	The application of Cherninformatics to High-Throughput Screening (HTS) data requires the use of robust modeling methods. Robust models must be able to accommodate false positive and false negative data yet retain good explanatory and predictive power. Recursive Partitioning has been shown to accommodate false positive and false negative data in the model building phase but suffers from a high false positive rate in the prediction phase, especially with sparse data sets such as HTS data. Here, we introduce Consensus Selection as a procedure to decrease the false positive rate of Recursive Partitioning-based models. Consensus Selection by Multiple Recursion Trees can increase the hit rate of a High-Throughput Screen in excess of 30-fold while significantly reducing the false positive rate relative to single Recursion Tree models.	ICAGEN Inc, Res Triangle Pk, NC 27709 USA	van Rhee, AM (reprint author), ICAGEN Inc, POB 14487, Res Triangle Pk, NC 27709 USA.						ABT M, 2002, NATL I STAT SCI TECH, V105, P1; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; Chen HSV, 1997, J PHYSIOL-LONDON, V499, P27; COOK EF, 1984, J CHRON DIS, V37, P721, DOI 10.1016/0021-9681(84)90041-9; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Holzgrabe U, 1998, DRUG DISCOV TODAY, V3, P214, DOI 10.1016/S1359-6446(97)01161-6; Kastenholz MA, 2000, J MED CHEM, V43, P3033, DOI 10.1021/jm000934y; Ravi M, 2001, J CHEM INF COMP SCI, V41, P1587, DOI 10.1021/ci010076u; Rusinko A, 2002, COMB CHEM HIGH T SCR, V5, P125; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; van Rhee AM, 2001, J COMB CHEM, V3, P267, DOI 10.1021/cc0000747; YOUNG SS, 1995, J MED CHEM, V38, P2784, DOI 10.1021/jm00014a030; Zwart R, 1997, MOL PHARMACOL, V52, P886	17	34	34	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338			J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	MAY-JUN	2003	43	3					941	948		10.1021/ci034023j		8	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	684LR	WOS:000183209300025	12767153	
J	Freimer, N; Sabatti, C				Freimer, N; Sabatti, C			The Human Phenome Project	NATURE GENETICS			English	Article							HUMAN GENOME; PHENOTYPES; DISCOVERY; GENETICS; CANCER	A principal goal of genetic research is to identify specific genotypes that are associated with human phenotypes. it will soon be possible to conduct genome-wide genotyping on a massive scale. Our current approaches for defining and assaying phenotypes may be inadequate for making optimal use of such genotypic data. We propose an international effort to create phenomic databases, that is, comprehensive assemblages of systematically collected phenotypic information, and to develop new approaches for analyzing such phenotypic data. We term this effort the Human Phenome Project and suggest a scientific and organizational scope for the project.	Ctr Neurobehav Genet, Inst Neuropsychiat, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Inst Brain Res, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Dept Human Genet, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Freimer, N (reprint author), Ctr Neurobehav Genet, Inst Neuropsychiat, Gonda Bldg Room 3506,695 Charles E Young Dr S, Los Angeles, CA 90095 USA.						Almasy L, 1997, GENET EPIDEMIOL, V14, P953, DOI 10.1002/(SICI)1098-2272(1997)14:6<953::AID-GEPI65>3.0.CO;2-K; Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; Breiman L, 1999, 567 U CAL DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; Cardno AG, 2002, AM J PSYCHIAT, V159, P539, DOI 10.1176/appi.ajp.159.4.539; Couzin J, 2002, SCIENCE, V298, P941; Daly MJ, 2001, NAT GENET, V29, P229, DOI 10.1038/ng1001-229; Feijen M, 2000, BRIT MED BULL, V56, P894, DOI 10.1258/0007142001903580; Goldschmidt R, 2001, FOCUS BIOTECHNOL, V1, P15; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Jacob HJ, 2002, NAT REV GENET, V3, P33, DOI 10.1038/nrg702; Jarvelin MR, 1997, PAEDIATR PERINAT EP, V11, P298, DOI 10.1111/j.1365-3016.1997.tb00007.x; KELSEY JF, 2000, COMPREHENSIVE TXB PS, P2432; Mahner M, 1997, J THEOR BIOL, V186, P55, DOI 10.1006/jtbi.1996.0335; Mardia KV, 1979, MULTIVARIATE ANAL; Mazziotta J, 2001, PHILOS T R SOC B, V356, P1293; Mitchell P, 2002, NAT BIOTECHNOL, V20, P529, DOI 10.1038/nbt0602-529; Paigen K, 2000, MAMM GENOME, V11, P715, DOI 10.1007/s003350010152; Patil N, 2001, SCIENCE, V294, P1719, DOI 10.1126/science.1065573; Peltonen L, 2000, NAT REV GENET, V1, P182, DOI 10.1038/35042049; Peters LL, 2002, PHYSIOL GENOMICS, V11, P185, DOI 10.1152/physiolgenomics.00077.2002; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; RANTAKALLIO P, 1969, ACTA PAEDIAT SCAND S, V0193; Rousseeuw P. J., 1990, FINDING GROUPS DATA; Silverman B. W., 1986, DENT ESTIMATION STAT; Syvanen AC, 2001, NAT REV GENET, V2, P930, DOI 10.1038/35103535; Vapnik VN, 1995, NATURE STAT LEARNING; Yazdanbakhsh M, 2002, SCIENCE, V296, P490, DOI 10.1126/science.296.5567.490	30	205	214	NATURE PUBLISHING GROUP	NEW YORK	345 PARK AVE SOUTH, NEW YORK, NY 10010-1707 USA	1061-4036			NAT GENET	Nature Genet.	MAY	2003	34	1					15	21		10.1038/ng0503-15		7	Genetics & Heredity	Genetics & Heredity	674ZK	WOS:000182667900006	12721547	
J	Zhang, HP; Yu, CY; Singer, B				Zhang, HP; Yu, CY; Singer, B			Cell and tumor classification using gene expression data: Construction of forests	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article							LEUKEMIA; MALIGNANCIES; CANCER	The advent of gene chips has led to a promising technology for cell, tumor, and cancer classification. We exploit and expand the methodology of recursive partitioning trees for tumor and cell classification from microarray gene expression data. To improve classification and prediction accuracy, we introduce a deterministic procedure to form forests of classification trees and compare their performance with extant alternatives. When two published and commonly used data sets are used, we find that the deterministic forests perform similarly to the random forests in terms of the error rate obtained from the leave-one-out procedure, and all of the forests are far better than the single trees. In addition, we provide graphical presentations to facilitate interpretation of complex forests and compare our findings with the current biological literature. In addition to numerical improvement, the main advantage of deterministic forests is reproducibility and scientific interpretability of all steps in tree construction.	Yale Univ, Dept Epidemiol & Publ Hlth, Sch Med, New Haven, CT 06520 USA; Princeton Univ, Off Populat Res, Princeton, NJ 08544 USA	Zhang, HP (reprint author), Yale Univ, Dept Epidemiol & Publ Hlth, Sch Med, New Haven, CT 06520 USA.						Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; DELMER A, 1995, BLOOD, V85, P2870; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hamann PR, 2002, BIOCONJUGATE CHEM, V13, P47, DOI 10.1021/bc010021y; Hol FA, 1998, CLIN GENET, V53, P119; KRISSANSEN GW, 1986, EMBO J, V5, P1799; Moler EJ, 2000, PHYSIOL GENOMICS, V4, P109; Nilson I, 1997, BRIT J HAEMATOL, V98, P157, DOI 10.1046/j.1365-2141.1997.1522966.x; Parisi E, 2002, ORAL SURG ORAL MED O, V93, P257, DOI 10.1067/moe.2002.121988; Sonoki T, 2001, BLOOD, V98, P2837, DOI 10.1182/blood.V98.9.2837; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Xiong MM, 2000, BIOTECHNIQUES, V29, P1264; YU LM, 1992, J IMMUNOL, V148, P633; Zhang H, 1999, RECURSIVE PARTITIONI; Zhang Heping, 2002, Frontiers in Bioscience, V7, pc63, DOI 10.2741/zhang; Zhang HP, 1996, STAT MED, V15, P37, DOI 10.1002/(SICI)1097-0258(19960115)15:1<37::AID-SIM144>3.3.CO;2-S; ZHANG HP, 1995, AM J EPIDEMIOL, V141, P70; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	22	69	78	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	APR 1	2003	100	7					4168	4172		10.1073/pnas.0230559100		5	Multidisciplinary Sciences	Science & Technology - Other Topics	664JR	WOS:000182058400114	12642676	
S	Wu, YM; Zhang, AD			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Wu, YM; Zhang, AD			Adaptive pattern discovery for interactive multimedia retrieval	2003 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOL II, PROCEEDINGS	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 18-20, 2003	MADISON, WI	IEEE Comp Soc, Tech Comm Pattern Anal & Machine Intelligence				Relevance feedback has been an indispensable component for multimedia retrieval systems. In this paper, we present an adaptive pattern discovery method, which addresses relevance feedback by interactively discovering meaningful patterns of relevant objects. To facilitate pattern discovery, we first present a dynamic feature extraction method, which aims to alleviate the curse of dimensionality by extracting a feature subspace using balanced information gain. In the feature subspace, we train an online pattern classification method called adaptive random forests to classify multimedia objects as relevant or irrelevant. Our adaptive random forests adapts the traditional classification method known as random forests for relevance feedback. It improves the efficiency of pattern discovery by choosing the most-informative samples for online learning. Extensive experiments are carried out on a Corel image set (with 31,438 images) to evaluate the performance of our method as compared against the state-of-the-art approaches.	SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Wu, YM (reprint author), SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.						BRANDT S, 2000, P ICPR           SEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, 567 U CAL DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; CHARIKAR M, 1997, P ACM S THEOR COMP; ELOMAA T, 1999, MACH LEARN, V36, P1; ENFRON B, 1993, INTRO BOOTSTRAP; Freund Y., 1997, J COMP SYS SCI, V55; Fukunaga K., 1990, INTRO STAT PATTERN R, Vsecond; Joachims T., 1998, ADV KERNEL METHODS S; Mitchell T. M., 1997, MACHINE LEARNING; RUI Y, 2000, IEEE C CVPR JUN; SU Z, 2001, P ACM MULTIMEDIA; TIEU K, 2000, IEEE C CVPR JUN; TONG S, 2001, P ACM MULTIMEDIA; VASCONCELOS N, 2000, P IEEE WORKSH CAIVI; WU Y, 2002, P IEEE INT C IM P; Yang Y., 1997, P ICML 97; ZHOU XS, 2001, P ACM MULTIMEDIA	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919			PROC CVPR IEEE			2003							649	655				7	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BX05C	WOS:000184081500084		
S	Kim, Y		Whang, KY; Jeon, J; Shim, K; Srivastava, J		Kim, Y			Averaged boosting: A noise-robust ensemble method	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR 30-MAY 02, 2003	SEOUL, SOUTH KOREA	Adv Informat Technol Res Ctr, KAIST, Stat Res Ctr Complex Syst, SNU, Korea Informat Sci Soc, Korean Datamining Soc, USAF, Off Sci Res, Asian Off Aerosp Res & Dev, ACM SIGKDD			ALGORITHMS	A new noise robust ensemble method called "Averaged Boosting (A-Boosting)" is proposed. Using the hypothetical ensemble algorithm in Hilbert space, we explain that A-Boosting can be understood as a method of constructing a sequence of hypotheses and coefficients such that the average of the product of the base hypotheses and coefficients converges to the desirable function. Empirical studies showed that A-Boosting outperforms Bagging for low noise cases and is more robust than AdaBoost to label noise.	Ewha Womans Univ, Dept Stat, Seoul 120750, South Korea	Kim, Y (reprint author), Ewha Womans Univ, Dept Stat, Seoul 120750, South Korea.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 2001, ANN STAT, V39, P1189; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Mason L., 2000, ADV LARGE MARGIN CLA; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Quinlan J.R., 1996, LECT NOTES COMPUTER, V1160, P143; Rasch G., 2001, MACH LEARN, V42, P287; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 1998, ANN STAT, V26, P1651	13	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-04760-3	LECT NOTES ARTIF INT			2003	2637						388	393				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	BX23S	WOS:000184716000038		
J	Hothorn, T; Lausen, B				Hothorn, T; Lausen, B			Bagging tree classifiers for laser scanning images: a data- and simulation-based strategy	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						discriminant analysis; laser scanning; images; bagging; error rate; estimation; simulation	DISCRIMINANT-ANALYSIS; CLASSIFICATION; PREDICTORS; GLAUCOMA; REGRESSION; DIAGNOSIS	Diagnosis based on medical image data is common in medical decision making and clinical routine. We discuss a strategy to derive a classifier with good performance on clinical image data and to justify the properties of the classifier by an adapted simulation model of image data. We focus on the problem of classifying eyes as normal or glaucomatous based on 62 routine explanatory variables derived from laser scanning images of the optic nerve head. As learning sample we use a case-control study of 98 normal and 98 glaucomatous subjects matched by age and sex. Aggregating multiple unstable classifiers allows substantial reduction of misclassification error in many applications and bench mark problems. We investigate the performance of various classifiers for the clinical learning sample as well as for a simulation model of eye morphologies. Bagged classification trees (bagged-CTREE) are compared to single classification trees and linear discriminant analysis (LDA). We additionally compare three estimators of misclassification error: 10-fold cross-validation, the 0.632+ bootstrap and the out-of-bag estimate. In summary, the application of our strategy of a knowledge-based decision support shows that bagged classification trees perform best for glaucoma classification. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Erlangen Nurnberg, Inst Med Informat Biometrie & Epidemiol, D-91054 Erlangen, Germany	Lausen, B (reprint author), Univ Erlangen Nurnberg, Inst Med Informat Biometrie & Epidemiol, Waldstr 6, D-91054 Erlangen, Germany.	torsten.hothorn@rzmail.uni-erlangen.de; berthold.lausen@rzmail.uni-erlangen.de	Hothorn, Torsten/A-3639-2010; Lausen, Berthold/D-4063-2012	Hothorn, Torsten/0000-0001-8301-0471; Lausen, Berthold/0000-0002-0594-7258			BIAS TR, 1996, VARIANCE PREDICTION; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 1996, CA94708 U CAL STAT D; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burk ROW, 2000, GRAEF ARCH CLIN EXP, V238, P375, DOI 10.1007/s004170050368; Choulakian V, 2001, COMPUT STAT DATA AN, V35, P253, DOI 10.1016/S0167-9473(00)00019-0; Christmann A, 2001, COMPUT STAT DATA AN, V37, P65, DOI 10.1016/S0167-9473(00)00063-3; Ciampi A, 2000, ST CLASS DAT ANAL, P223; Coleman AL, 1999, LANCET, V354, P1803, DOI 10.1016/S0140-6736(99)04240-3; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hand DJ, 2001, COMPUT STAT DATA AN, V36, P209; *HEID ENG, 1997, HEID RET TOM BED SOF; Hilton S, 1996, STAT MED, V15, P1349, DOI 10.1002/(SICI)1097-0258(19960715)15:13<1349::AID-SIM270>3.0.CO;2-B; HOTHORN T, 2003, IN PRESS PATTERN REC; Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; Lausen B, 1996, COMPUT STAT DATA AN, V21, P307, DOI 10.1016/0167-9473(95)00016-X; Lee SS, 2000, COMPUT STAT DATA AN, V34, P165, DOI 10.1016/S0167-9473(99)00095-X; MARDIN C, UNPUB NEW GLAUCOMA C; Mardin CY, 1999, BRIT J OPHTHALMOL, V83, P299, DOI 10.1136/bjo.83.3.299; Mikelberg F S, 1995, J Glaucoma, V4, P242; Mojirsheibani M, 2001, COMPUT STAT DATA AN, V38, P125, DOI 10.1016/S0167-9473(01)00024-X; Park J, 2001, ARTIF INTELL MED, V23, P277, DOI 10.1016/S0933-3657(01)00086-0; Schiavo RA, 2000, INT STAT REV, V68, P295, DOI 10.2307/1403415; Steel SJ, 2001, COMPUT STAT DATA AN, V37, P249, DOI 10.1016/S0167-9473(01)00012-3; Swift S, 2002, ARTIF INTELL MED, V24, P5, DOI 10.1016/S0933-3657(01)00095-1; Swindale NV, 2000, INVEST OPHTH VIS SCI, V41, P1730; Therneau T, 1997, 61 MAYO CLIN SECT BI; Weih LM, 2001, OPHTHALMOLOGY, V108, P1966, DOI 10.1016/S0161-6420(01)00799-0; Wetter T, 2002, ARTIF INTELL MED, V24, P195, DOI 10.1016/S0933-3657(01)00103-8	34	31	31	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657	1873-2860		ARTIF INTELL MED	Artif. Intell. Med.	JAN	2003	27	1					65	79	PII S0933-3657(02)00085-4	10.1016/S0933-3657(02)00085-4		15	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	635DT	WOS:000180383400004	12473392	
S	Geng, W; Cosman, P; Huang, C; Schafer, WR		Matthews, MB		Geng, W; Cosman, P; Huang, C; Schafer, WR			Automated worm tracking and classification	CONFERENCE RECORD OF THE THIRTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2	CONFERENCE RECORD OF THE ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS		English	Proceedings Paper	37th Asilomar Conference on Signals, Systems and Computers	NOV 09-12, 2003	Pacific Grove, CA				CAENORHABDITIS-ELEGANS; BEHAVIOR	The locomotion of C elegans (a microscopic worm) provides valuable information about mutant genes and their effect on behavior. In order to investigate detailed movement and body posture characteristics of these living animals, advanced automated tracking algorithms are required. Here we describe a novel procedure of tracking an individual worms body part movement accurately by combining head and tail recognition with tracking. In addition, we describe a classification system to distinguish mutant types from each other. We demonstrate that its performance can be improved by incorporating new image features introduced by this tracking method.	Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	Geng, W (reprint author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.						ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023; Baek JH, 2002, J NEUROSCI METH, V118, P9, DOI 10.1016/S0165-0270(02)00117-6; Breiman L, 2002, MANUAL SETTING UP US; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRENNER S, 1974, GENETICS, V77, P77; Bylander T, 2002, MACH LEARN, V48, P287, DOI 10.1023/A:1013964023376; de Bono M, 1998, CELL, V94, P679, DOI 10.1016/S0092-8674(00)81609-8; Dhawan R, 1999, J TOXICOL ENV HEAL A, V58, P451, DOI 10.1080/009841099157179; GENG W, 2003, P IASTED INT C SIGN, P342; GENG W, 2003, IN PRESS GENETICS; HASTIE T, 1983, J GENET, V103, P43; LIAW A, 1983, R NEWSLETTER, V2, P64; Waggoner LE, 1998, NEURON, V21, P203, DOI 10.1016/S0896-6273(00)80527-9; Zhou GT, 1998, IEEE T SIGNAL PROCES, V46, P2698, DOI 10.1109/78.720372	15	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1058-6393		0-7803-8104-1	CONF REC ASILOMAR C			2003							2063	2068				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BY93K	WOS:000189498700388		
S	Rodriguez, JJ; Alonso, CJ		Conejo, R; Urretavizcaya, M; PerezDeLaCruz, JL		Rodriguez, JJ; Alonso, CJ			Rotation-based ensembles	CURRENT TOPICS IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th Conference of the Spanish-Association-for-Artificial-Intelligence (CAEPIA 2003)/5th Conference on Technology Transfer (TTIA 2003)	NOV 12-14, 2003	San Sebastian, SPAIN	Spanish Assoc Artificial Intelligence				A new method for ensemble generation is presented. It is based on grouping the attributes in different subgroups, and to apply, for each group, an axis rotation, using Principal Component Analysis. If the used method for the induction of the classifiers is not invariant to rotations in the data set, the generated classifier can be very different. Hence, once of the objectives aimed when generating ensembles is achieved, that the different classifiers were rather diverse. The majority of ensemble methods eliminate some information (e.g., instances or attributes) of the data set for obtaining this diversity. The proposed ensemble method transforms the data set in a way such as all the information is preserved. The experimental validation, using decision trees as base classifiers, is favorable to rotation based ensembles when comparing to Bagging, Random Forests and the most well-known version of Boosting.	Univ Burgos, Lenguages & Sistemas Informat, Burgos, Spain; Univ Valladolid, Grp Sistemas Inteligentes, Dept Informat, Valladolid, Spain	Rodriguez, JJ (reprint author), Univ Burgos, Lenguages & Sistemas Informat, Burgos, Spain.	jjrodriguez@ubu.es; calonso@infor.uva.es	Rodriguez, Juan/B-1014-2008	Rodriguez, Juan/0000-0002-3291-2739			Blake C. L., 1998, UCI RESPOSITORY MACH; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Han J., 2001, DATA MINING CONCEPTS; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Schapire R., 2002, MSRI WORKSH NONL EST; THOMAS G, 2000, MULTIPLE CLASSIFIER, P1; Tumer K, 2003, PATTERN ANAL APPL, V6, P65, DOI 10.1007/s10044-002-0181-7; Witten I. H., 1999, DATA MINING PRACTICA	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22218-9	LECT NOTES COMPUT SC			2003	3040						498	506				9	Computer Science, Artificial Intelligence	Computer Science	BAK71	WOS:000222638300049		
J	Costello, TJ; Falk, CT; Ye, KQ				Costello, TJ; Falk, CT; Ye, KQ			Data mining and computationally intensive methods: Summary of group 7 contributions to Genetic Analysis Workshop 13	GENETIC EPIDEMIOLOGY			English	Article; Proceedings Paper	13th Genetic Analysis Workshop	NOV 11-14, 2002	NEW ORLEANS, LOUISIANA			tree-based methods; neural networks; discriminant analysis; stochastic search variable selection; random forests; association test; genetic linkage; framingham heart study; hypertension; systolic blood pressure; glucose levels; cardiovascular disease	GENOME-WIDE SEARCH; LINKAGE; DISEASE; ASTHMA; SCAN	The Framingham Heart Study data, as well as a related simulated data set, were generously provided to the participants of the Genetic Analysis Workshop 13 in order that newly developed and emerging statistical methodologies could be tested on that well-characterized data set. The impetus driving the development of novel methods is to elucidate the contributions of genes, environment, and interactions between and among them, as well as to allow comparison between and validation of methods. The seven papers that comprise this group used data-mining methodologies (tree-based methods, neural networks, discriminant analysis, and Bayesian variable selection) in an attempt to identify the underlying genetics of cardiovascular disease and related traits in the presence of environmental and genetic covariates. Data-mining strategies are gaining popularity because they are extremely flexible and may have greater efficiency and potential in identifying the factors involved in complex disorders. While the methods grouped together here constitute a diverse collection, some papers asked similar questions with very different methods, while others used the same underlying methodology to ask very different questions. This paper briefly describes the data-mining methodologies applied to the Genetic Analysis Workshop 13 data sets and the results of those investigations. (C) 2003 Wiley-Liss, Inc.	New York Blood Ctr, Lindsley F Kimball Res Inst, New York, NY 10021 USA; Univ Texas, MD Anderson Canc Ctr, Dept Epidemiol, Houston, TX 77030 USA; Univ Texas, Hlth Sci Ctr, Grad Sch Biomed Sci, Houston, TX USA; SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA	Falk, CT (reprint author), New York Blood Ctr, Lindsley F Kimball Res Inst, 310 E 67th St, New York, NY 10021 USA.		Costello, Tracy/	Costello, Tracy/0000-0001-6138-2450			ATKINSON EJ, 2003, BMC GENET S, V4, P63; Baima J, 1999, HYPERTENSION, V34, P4; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUREAU A, 2003, BMC GENET S, V4, P64; CHEN CH, 2003, BMC GENET S, V4, P65; COTELLO TJ, 2003, BMC GENET S, V4, P66; Marsh DG, 1997, NAT GENET, V15, P389; DAWBER TR, 1951, AM J PUBLIC HEALTH, V41, P279; Elston RC, 2000, GENET EPIDEMIOL, V19, P1, DOI 10.1002/1098-2272(200007)19:1<1::AID-GEPI1>3.0.CO;2-E; FALK CT, 2003, BMC GENET S, V4, P67; Falk CT, 1998, AM J HUM GENET, V62, P941, DOI 10.1086/301780; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; GUO Z, 2003, BMC GENET S, V4, P68; KANNEL WB, 1979, AM J EPIDEMIOL, V110, P281; Levy D, 2000, HYPERTENSION, V36, P477; LI X, 2001, GENET EPIDEMIOL S, V21, P516; OH C, 2003, BMC GENET S, V4, P69; SAS Institute, 1989, SAS STAT US GUID VER; Shannon WD, 2001, GENET EPIDEMIOL, V20, P293, DOI 10.1002/gepi.1; Shearman AM, 2000, HUM MOL GENET, V9, P1315, DOI 10.1093/hmg/9.9.1315; *SNNS, 1995, STUTTG NEUR NETW SIM; SUH YJ, 2001, GENET EPIDEMIOL S, V21, P706; Wjst M, 1999, GENOMICS, V58, P1, DOI 10.1006/geno.1999.5806; Zhang H, 1999, RECURSIVE PARTITIONI; ZHANG H, 2001, GENET EPIDEMIOL S, V21, P317; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5	27	5	6	WILEY-LISS	NEW YORK	DIV JOHN WILEY & SONS INC, 605 THIRD AVE, NEW YORK, NY 10158-0012 USA	0741-0395			GENET EPIDEMIOL	Genet. Epidemiol.		2003	25			1			S57	S63		10.1002/gepi.10285		7	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	751GP	WOS:000187044700008	14635170	
B	Pal, M			IEEE; IEEE; IEEE	Pal, M			Random forests for land cover classification	IGARSS 2003: IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS I - VII, PROCEEDINGS: LEARNING FROM EARTH'S SHAPES AND SIZES	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	23rd International Geoscience and Remote Sensing Symposium (IGARSS 2003)	JUL 21-25, 2003	TOULOUSE, FRANCE	IEE, IEEE Geosci & Remote Sensing Soc, Ctr Natl Etudes Spatiales, NASA, Natl Ocean & Atmospher Adm, US Dept Commerce, Off Naval Res, eesa, NPOESS, NASDA, Ball Aerosp & Technol Corp, uRSi			ALGORITHMS; TREES	In recent years, a number of works reported the use of combination of multiple classifiers to produce a single classification and demonstrated significant performance improvement (Breiman, 1996; Baur and Kohavi 1999; Opitz and Maclin 1999). The resulting classifier, referred to as an ensemble classifier, is a set of classifiers whose individual decisions are combined by weighted or unweighted voting to classify new examples. An ensembles are often more accurate than the individual classifiers that makes them up (Dietterich, 2002). In remote sensing Giacinto and Roli, 1997, Roli et al., 1997 report the use of ensemble of neural networks and the integration of classification results of different type of classifiers. Studies by growing an ensemble of decision trees and allowing them to vote for the most popular class reported a significant improvement in classification accuracy for land cover classification (Friedl et al., 1999, Pal and Mather, 2001). This paper presents results obtained by random forests classifier, another technique of generating ensemble of classifiers (Breiman, 1999), and their performance is compared with the ensemble of decision tree classifiers. A classification accuracy of 88.32% is achieved by random forest classifier in comparison with 87.38% and 87.28% by decision tree ensemble created using boosting and bagging techniques. Further, study also suggests that bagging perform well in comparison with boosting in case of noise in training data.	Natl Inst Technol, Dept Civil Engn, Kurukshetra, Haryana, India	Pal, M (reprint author), Natl Inst Technol, Dept Civil Engn, Kurukshetra, Haryana, India.		Pal, Mahesh/P-1136-2014	Pal, Mahesh/0000-0003-1805-2952			Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Breiman L., 1999, RANDOM FORESTS; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1998, 518 U CAL STAT DEP; Breiman L, 2000, 577 U CAL STAT DEP; Breiman L, 1984, CLASSIFICATION REGRE; Dietterich T, 2002, HDB BRAIN THEORY NEU; DIETTERICH TG, 1998, BAGGING BOOSTING RAN, P1; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedl MA, 1999, IEEE T GEOSCI REMOTE, V37, P969, DOI 10.1109/36.752215; Friedman J., 1998, ADDITIVE LOGISTIC RE; Giacinto G., 1997, P EUR S INT TECHN BA, P166; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Mason L, 2000, ADV NEUR IN, V12, P512; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; PAL M, 2001, P 27 ANN C REM SENS	17	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7929-2	INT GEOSCI REMOTE SE			2003							3510	3512				3	Geosciences, Multidisciplinary; Instruments & Instrumentation; Remote Sensing; Imaging Science & Photographic Technology	Geology; Instruments & Instrumentation; Remote Sensing; Imaging Science & Photographic Technology	BY01Z	WOS:000187293501159		
J	Segal, MR; Dahlquist, KD; Conklin, BR				Segal, MR; Dahlquist, KD; Conklin, BR			Regression approaches for microarray data analysis	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						cardiomyopathy; gene harvesting; least angle regression; microarray; support vector machine	GENE-EXPRESSION DATA; CONDITIONAL EXPRESSION; G(I)-COUPLED RECEPTOR; MODEL SELECTION; CLASSIFICATION; CANCER; SAMPLES; LASSO	A variety of new procedures have been devised to handle the two-sample comparison (e.g., tumor versus normal tissue) of gene expression values as measured with microarrays. Such new methods are required in part because of some defining characteristics of microarray-based studies: (i) the very large number of genes contributing expression measures which far exceeds the number of samples (observations) available and (ii) the fact that by virtue of pathway/network relationships, the gene expression measures tend to be highly correlated. These concerns are exacerbated in the regression setting, where the objective is to relate gene expression, simultaneously for multiple genes, to some external outcome or phenotype. Correspondingly, several methods have been recently proposed for addressing these issues. We briefly critique some of these methods prior to a detailed evaluation of gene harvesting. This reveals that gene harvesting, without additional constraints, can yield artifactual solutions. Results obtained employing such constraints motivate the use of regularized regression procedures such as the lasso, least angle regression, and support vector machines. Model selection and solution multiplicity issues are also discussed. The methods are evaluated using a microarray-based study of cardiomyopathy in transgenic mice.	Univ Calif San Francisco, Dept Epidemiol & Biostat, San Francisco, CA 94143 USA; Univ Calif San Francisco, Gladstone Inst Cardiovasc Dis, San Francisco, CA 94143 USA; Univ Calif San Francisco, Cardiovasc Res Inst, San Francisco, CA 94143 USA	Segal, MR (reprint author), Univ Calif San Francisco, Dept Epidemiol & Biostat, 500 Parnassus Ave,MU 420-W, San Francisco, CA 94143 USA.	mark@biostat.ucsf.edu					Akaike H., 1973, 2 INT S INF THEOR, P267; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 2002, UNPUB LEAST ANGLE RE; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Goryachev AB, 2001, J COMPUT BIOL, V8, P443, DOI 10.1089/106652701752236232; GUARDAVACCARO D, 1995, CELL GROWTH DIFFER, V6, P159; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 2001, GENOME BIOL, V2; HOERL AE, 1970, TECHNOMETRICS, V12, P55; KELES S, 2002, UNPUB IDENTIFICATION; KENT C, 1999, TRENDS BIOCHEM SCI, V24, P127; Kim S, 2002, J COMPUT BIOL, V9, P127, DOI 10.1089/10665270252833226; Kooperberg C, 2002, J COMPUT BIOL, V9, P55, DOI 10.1089/10665270252833190; LEE Y, 2002, UNPUB CLASSIFICATION; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Li HZ, 2001, GENOME BIOL, V2; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Nelson DP, 2002, ANN THORAC SURG, V73, P156, DOI 10.1016/S0003-4975(01)03303-3; Newton MA, 2001, J COMPUT BIOL, V8, P37, DOI 10.1089/106652701300099074; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Redfern CH, 1999, NAT BIOTECHNOL, V17, P165; Redfern CH, 2000, P NATL ACAD SCI USA, V97, P4826, DOI 10.1073/pnas.97.9.4826; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 1999, J ROY STAT SOC B, V61, P529, DOI 10.1111/1467-9868.00191; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik V., 1998, STAT LEARNING THEORY; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Westphal CH, 1999, CELL, V96, P689, DOI 10.1016/S0092-8674(00)80579-6; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	40	62	67	MARY ANN LIEBERT INC PUBL	LARCHMONT	2 MADISON AVENUE, LARCHMONT, NY 10538 USA	1066-5277			J COMPUT BIOL	J. Comput. Biol.		2003	10	6					961	980		10.1089/106652703322756177		20	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	767MM	WOS:000188455100009	14980020	
S	Breiman, L		Lavrac, N; Gamberger, D; Todorovski, L; Blockeel, H		Breiman, L			Two-eyed algorithms and problems	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2003, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th European Conferenc on Priciples and Practice of Knowledge Discovery in Databases	SEP 22-26, 2003	CAVTAT, CROATIA	Croatian Minist Sci & Technol, Slovenian Minist Educ, Sci & Sports, Knowledge Discovery Network Excellence					Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Breiman, L (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20085-1	LECT NOTES ARTIF INT			2003	2838						9	9				1	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BX96Y	WOS:000187062000002		
S	Breiman, L		Lavrac, N; Gamberger, D; Blockeel, H; Todorovski, L		Breiman, L			Two-eyed algorithms and problems	MACHINE LEARNING: ECML 2003	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	14th European Conference on Machine Learning	SEP 22-26, 2003	CAVTAT, CROATIA	Croatian Minist Sci & Technol, Slovenian Minist Educ, Sci & Sports, Knowledge Discovery Network Excellence					Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Breiman, L (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20121-1	LECT NOTES ARTIF INT			2003	2837						9	9				1	Computer Science, Artificial Intelligence	Computer Science	BX96X	WOS:000187061900002		
S	Ernst, D; Geurts, P; Wehenkel, L		Lavrac, N; Gamberger, D; Blockeel, H; Todorovski, L		Ernst, D; Geurts, P; Wehenkel, L			Iteratively extending time horizon reinforcement learning	MACHINE LEARNING: ECML 2003	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	14th European Conference on Machine Learning	SEP 22-26, 2003	CAVTAT, CROATIA	Croatian Minist Sci & Technol, Slovenian Minist Educ, Sci & Sports, Knowledge Discovery Network Excellence				Reinforcement learning aims to determine an (infinite time horizon) optimal control policy from interaction with a system. It can be solved by approximating the so-called Q-function from a sample of four-tuples (x(t), u(t), r(t), x(t+1)) where x(t) denotes the system state at time t, ut the control action taken, rt the instantaneous reward obtained and x(t+1) the successor state of the system, and by determining the optimal control from the Q-function. Classical reinforcement learning algorithms use an ad hoc version of stochastic approximation which iterates over the Q-function approximations on a four-tuple by four-tuple basis. In this paper, we reformulate this problem as a sequence of batch mode supervised learning problems which in the limit converges to (an approximation of) the Q-function. Each step of this algorithm uses the full sample of four-tuples gathered from interaction with the system and extends by one step the horizon of the optimality criterion. An advantage of this approach is to allow the use of standard batch mode supervised learning algorithms, instead of the incremental versions used up to now. In addition to a theoretical justification the paper provides empirical tests in the context of the "Car on the Hill" control problem based on the use of ensembles of regression trees. The resulting algorithm is in principle able to handle efficiently large scale reinforcement learning problems.	Univ Liege, Inst Montefiore, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium	Ernst, D (reprint author), Univ Liege, Inst Montefiore, Dept Elect Engn & Comp Sci, Sart Tilman B28, B-4000 Liege, Belgium.						Bertsekas D. P., 2000, DYNAMIC PROGRAMMING, V1; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; ERNST D, 2003, THESIS U LIEGE BELGI; GEURTS P, 2003, EXTREMELY RANDOMIZED; GUERTS P, 2002, THESIS U LIEGE BELGI; MOORE AW, 1993, MACH LEARN, V13, P103, DOI 10.1023/A:1022635613229; ROSENSTEIN MT, 2002, SUPERVISED LEARNING; SMART WD, 2000, P 16 INT C MACH LEAR; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	11	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20121-1	LECT NOTES ARTIF INT			2003	2837						96	107				12	Computer Science, Artificial Intelligence	Computer Science	BX96X	WOS:000187061900011		
S	Banfield, RE; Hall, LO; Bowyer, KW; Kegelmeyer, WP		Windeatt, T; Roli, F		Banfield, RE; Hall, LO; Bowyer, KW; Kegelmeyer, WP			A new ensemble diversity measure applied to thinning ensembles	MULTIPLE CLASSIFIER SYSTEMS, PROCEEDING	Lecture Notes in Computer Science		English	Article; Proceedings Paper	4th International Workshop on Multiple Classifier Systems (MCS 2003)	JUN 11-13, 2003	GUILDFORD, ENGLAND	Univ Cagliri, Int Assoc Pattern Recognit	UNIV SURREY			We introduce a new way of describing the diversity of an ensemble of classifiers, the Percentage Correct Diversity Measure, and compare it against existing methods. We then introduce two new methods for removing classifiers from an ensemble based on diversity calculations. Empirical results for twelve datasets from the UC Irvine repository show that diversity is generally modeled by our measure and ensembles can be made smaller without loss in accuracy.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Univ Notre Dame, Dept Comp Engn & Sci, Notre Dame, IN 46556 USA; Sandia Natl Labs, Biosyst Res Dept, Livermore, CA 94551 USA	Banfield, RE (reprint author), Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave, Tampa, FL 33620 USA.	rbanfiel@csee.usf.edu; hall@csee.usf.edu; kwb@cse.nd.edu; wpk@ca.sandia.gov	Bowyer, Kevin/	Bowyer, Kevin/0000-0002-7562-4390			Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T.G., 2000, P 1 INT WORKSH MULT, P1; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Giacinto G, 2001, PATTERN RECOGN LETT, V22, P25, DOI 10.1016/S0167-8655(00)00096-9; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Kuncheva LI, 2000, INT C PATT RECOG, P168; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Latinne P., 2001, 2 INT WORKSH MULT CL, P178; Merz C.J., UCI REPOSITORY MACHI	12	16	16	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40369-8	LECT NOTES COMPUT SC			2003	2709						306	316				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BX32F	WOS:000184942400031		
S	Valentini, G		Apolloni, B; Marinaro, M; Tagliaferri, R		Valentini, G			An application of low bias bagged SVMs to the classification of heterogeneous malignant tissues	NEURAL NETS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	14th Italian Workshop on Neural Nets	JUN 04-07, 2003	VIETRI SUL MARE, ITALY	Int Inst Adv Sci Studies, Univ Salerno, Dipartmento Fis, Univ Salerno, Dipartmento Matemat Informat, Univ Milano, Dipartmento Sci Informaz, Soc Italiana Reti Neuronich, IEEE Neural Network Soc, Italian Chapter, INNS SIG Italy, Ist Italiano Studi Filosofici, Provincia Salerno			GENE-EXPRESSION DATA; CANCER; PREDICTION	DNA microarray data are characterized by high-dimensional and low-sized samples, as only few tens of DNA microarray experiments, involving each one thousands of genes, are usually available for data processing. Considering also the large biological variability of gene expression and the noise introduced by the bio-technological machinery, we need robust and variance-reducing data analysis methods. To this purpose, we propose an application of a new ensemble method based on the bias-variance decomposition of the error, using Support Vector Machines (SVMs) as base learners. This approach, that we named Low bias bagging (Lobag), tries to reduce both the bias and the variance components of the error, selecting the base learners with the lowest bias, and combining them through bootstrap aggregating techniques. We applied Lobag to the classification of normal and heterogeneous malignant tissues, using DNA microarray gene expression data. Preliminary results on this challenging two-class classification problem show that Lobag, in association with simple feature selection methods, outperforms both single and bagged ensembles of SVMs.	Univ Milan, Dipartimento Sci Informaz, I-20135 Milan, Italy; Ist Nazl Fis Mat, INFM, I-16146 Genoa, Italy	Valentini, G (reprint author), Univ Milan, Dipartimento Sci Informaz, I-20135 Milan, Italy.	valenti@disi.unige.it	Valentini, Giorgio/H-2134-2012; Valentini, Giorgio/	Valentini, Giorgio/0000-0002-5694-3919			Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DOMINGOS P, 2000, UNIFIED BIAS VARIANC; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1999, METHOD ENZYMOL, V303, P179; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; VALENTINI G, 2003, P ICML 2003 20 INT C; VALENTINI G, 2003, IJCNN 2003 IEEE INNS; Valentini G, 2002, NEUROCOMPUTING, V48, P623, DOI 10.1016/S0925-2312(01)00632-4; Valentini G, 2002, LECT NOTES COMPUT SC, V2364, P222; Valentini G., 2002, ARTIF INTELL, V26, P283	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20227-7	LECT NOTES COMPUT SC			2003	2859						316	321				6	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BY16J	WOS:000188006800036		
B	Margineantu, DD; Dietterich, TG		Dension, DD; Hansen, MH; Holmes, CC; Mallick, B; Yu, B		Margineantu, DD; Dietterich, TG			Improved class probability estimates from decision tree models	NONLINEAR ESTIMATION AND CLASSIFICATION	LECTURE NOTES IN STATISTICS		English	Proceedings Paper	Workshop on Nonlinear Estimation and Classification	MAR 00-21, 2001	Berkeley, CA					Decision tree models typically give good classification decisions but poor probability estimates. In many applications, it is important to have good probability estimates as well. This chapter introduces a new algorithm, Bagged Lazy Option Trees (B-LOTs), for constructing decision trees and compares it to an alternative, Bagged Probability Estimation Trees (B-PETs). The quality of the class probability estimates produced by the two methods is evaluated in two ways. First, we compare the ability of the two methods to make good classification decisions when the misclassification costs are asymmetric. Second, we compare the absolute accuracy of the estimates themselves. The experiments show that B-LOTs, produce better decisions and more accurate probability estimates than B-PETs.	Boeing Co, Adapt Syst Math & Comp Technol, Seattle, WA 98124 USA	Margineantu, DD (reprint author), Boeing Co, Adapt Syst Math & Comp Technol, Seattle, WA 98124 USA.						BHATTACHARYA BK, 1987, P 16 S COMP SCI STAT, P97; Blake C. L., 1998, UCI REPOSITORY MACHI; Bradford J., 1998, LECT NOTES ARTIF INT, V1398, P131; Breiman L., 1999, RANDOM FORESTS; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Buntine W., 1990, THESIS U TECHNOLOGY; CESTNIK B, 1999, P 9 EUR C ART INT, P147; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; DASARATHY B.V, 1991, NEAREST NEIGHBOR NN; Denison DGT, 1998, BIOMETRIKA, V85, P363; Dietterich T.G., 2000, MACH LEARN, V40, P1; Efron B, 1993, INTRO BOOTSTRAP; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Good I. J., 1965, ESTIMATION PROBABILI; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kohavi R, 1997, P 14 INT C MACH LEAR, P161; MARGINEANTU DD, 2000, P 17 INT C MACH LEAR; PROVOST F, 2000, IS0004 NEW YORK U ST; Quinlan J.R., 1993, C4 5 PROGRAMS EMPIRI; Wettschereck D, 1994, THESIS OREGON STATE	25	1	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES			0-387-95471-6	LECT NOTES STAT			2003	171						173	188				16	Computer Science, Artificial Intelligence; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	BY75J	WOS:000189454900009		
S	Kuncheva, LI		Perales, FJ		Kuncheva, LI			That elusive diversity in classifier ensembles	PATTERN RECOGNITION AND IMAGE ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st Iberian Conference on Pattern Recognition and Image Analysis	JUN 04-06, 2003	MALLORCA, SPAIN	MCyT, Int Assoc Pattern Recognit, European Union, Conselleria Innovacio Energia	UNIV ILLES BALEARS, DEPT CIENCIES MATH & INFORMAT			Is "useful, diversity" a myth? Many experiments and the little available theory on diversity in classifier ensembles are either inconclusive, too heavily assumption-bound or openly non-supportive of the intuition that diverse classifiers fare better than non-divers ones. Although a rough general tendency was confirmed in our previous studies, no prominent link appeared between diversity of the ensemble and its accuracy. Diversity alone is a poor predictor of the ensemble accuracy. But there is no agreed definition of diversity to start with! Can we borrow a concept of diversity from biology? How can diversity, as far as we can define and measure it, be used to improve the ensemble? Here we argue that even without a clear-cut definition and theory behind it, studying diversity may prompt viable heuristic solutions. We look into some ways in which diversity can be used in analyzing, selecting or training the ensemble.	Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales	Kuncheva, LI (reprint author), Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cunningham P., 2000, TCDCS200002 DEP COMP; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Fleiss J.L., 1981, STAT METHODS RATES P; Ghosh J, 2002, LECT NOTES COMPUT SC, V2364, P1; Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho T.K., 2002, HYBRID METHODS PATTE, P171; Kleinberg E. M., 1990, ANN MATH ARTIFICIAL, V1, P207, DOI 10.1007/BF01531079; Kohavi R., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; KUNCHEVA LI, 2000, FUZZY CLASSIFIER DES; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Lam L., 2000, LECT NOTES COMPUTER, V1857, P78; LITTLEWOOD B, 1989, IEEE T SOFTWARE ENG, V15, P1596, DOI 10.1109/32.58771; Margineantu D., 1997, P 14 INT C MACH LEAR, P378; Pekalska E, 2002, LECT NOTES COMPUT SC, V2364, P137; Rao C, 1982, SANKHYA A, V44, P1; Roli F., 2001, LNCS, V2096, P78; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; Shipp C. A., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00051-9; Skalak D., 1996, P AM ASS ART INT AAA; Sokal RR, 1973, NUMERICAL TAXONOMY; Tumer K., 1999, COMBINING ARTIFICIAL, P127	24	37	38	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40217-9	LECT NOTES COMPUT SC			2003	2652						1126	1138				13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BX28N	WOS:000184832300130		
S	Laubach, M			IEEE	Laubach, M			Verifying neuronal codes: The statistical pattern recognition approach	PROCEEDINGS OF THE 25TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-4: A NEW BEGINNING FOR HUMAN HEALTH	PROCEEDINGS OF ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY		English	Proceedings Paper	25th Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society	SEP 17-21, 2003	Cancun, MEXICO	IEEE Engn Med & Biol Soc, Coral, Univ Autonome Metropolitana, Sandia Natl Lab		brain-machine interface; neuronal coding; neuroengineering; neuronal ensemble recording		In recent years, a variety of statistical methods have been proposed for studying neuronal codes. Many methods are developed by researchers specifically for their own data and are rarely validated by outside groups. An alternative approach is to use methods that have been developed by experts in signal processing and statistics, that have passed through peer review, and that are widely available. My research group uses such methods to study neural coding in the cerebral cortex. We study simultaneously record neuronal spike trains and wideband field potentials in the cerebral cortex of animals that perform psychophysical and sensorimotor behavioral tasks. This approach allows us to assess neuronal codes that are behaviorally relevant, free from the effects of anesthesia, and may be represented across multiple scales. We define relevant features in neuronal activity using wavelet-based methods and then use pattern recognition methods to quantify the information content of the features on a trial-by-trial basis. Using these methods, we are able to interpret the network properties of neuronal codes and, using a cluster of workstations, we can now analyze neuronal ensemble data sets during the actual performance of behavioral tasks. This approach leads to a new kind of experimental neurophysiology that allows for the verification of neuronal codes.	Yale Univ, Sch Med, John B Pierce Lab, New Haven, CT 06519 USA	Laubach, M (reprint author), Yale Univ, Sch Med, John B Pierce Lab, 333 Cedar St, New Haven, CT 06519 USA.						BREIMAN L, 1994, 421 U CAL BERK STAT; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BUCKHEIT JB, 1995, P SOC PHOTO-OPT INS, V2569, P540, DOI 10.1117/12.217608; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohonen T., 2001, SELF ORG MAPS, V3rd; Laubach M, 2000, NATURE, V405, P567, DOI 10.1038/35014604; Nicolelis MAL, 1997, NEURON, V18, P529, DOI 10.1016/S0896-6273(00)80295-0; Nicolelis MAL, 2002, SCI AM, V287, P46; RICHMOND BJ, 1987, J NEUROPHYSIOL, V57, P147; SAITO N, 1995, P 20 IEEE INT C AC S, P1529	10	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1094-687X		0-7803-7789-3	P ANN INT IEEE EMBS			2003	25		1-4				2147	2150				4	Cardiac & Cardiovascular Systems; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Medicine, Research & Experimental; Neurosciences; Radiology, Nuclear Medicine & Medical Imaging	Cardiovascular System & Cardiology; Computer Science; Engineering; Research & Experimental Medicine; Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	BY50W	WOS:000189395300561		
B	Shi, T; Horvath, S		Chen, SH; Cheng, HD; Chiu, DKY; Das, S; Duro, R; Kerre, EE; Leong, HV; Li, Q; Lu, M; Romay, MG; Ventura, D; Wu, J		Shi, T; Horvath, S			Using random forest similarities in unsupervised learning: Applications to microarray data	PROCEEDINGS OF THE 7TH JOINT CONFERENCE ON INFORMATION SCIENCES			English	Proceedings Paper	7th Joint Conference on Information Sciences (JCIS)	SEP 26-30, 2003	RES TRIANGLE PK, NC	Assoc Intelligent Machinery, Duke Univ, Elsevier Publ Inc, Informat Sci Journal, Harbin Inst Technol, NIEHS		random forest; clustering; similarity; multi-dimensional scaling; microarray data		A random forest (RF, Breiman, 2001) predictor is an ensemble of individual classification tree predictors. Interestingly, the RF prediction method can also be used to arrive at an "internal" similarity measure between observations even when no outcome has been specified. This similarity measure can be used for clustering or for creating multidimensional scaling plots. To define the similarity measure one needs to generate a set of synthetic data from a null distribution corresponding to no clusters in the data set. Apart from choosing a way of generating synthetic observations, one needs to specify the number of random features mtry. We discuss the nature of clusters produced when using a RF similarity measure. Depending on the method used for generating synthetic variables, we present guidelines for choosing multidimensional scaling methods and the mtry parameter. We apply RF clustering to simulated and real data sets and show that it can outperform standard methods based on the Euclidean distance.	Univ Calif Los Angeles, David Geffen Sch Mec, Dept Human Genet, Los Angeles, CA 90024 USA	Shi, T (reprint author), Univ Calif Los Angeles, David Geffen Sch Mec, Dept Human Genet, Los Angeles, CA 90024 USA.						BREIMAN L, 1999, RANDOM FORESTS MANUA; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cox T. F., 2001, MULTIDIMENSIONAL SCA, V2nd; Hartigan J. A., 1975, CLUSTERING ALGORITHM; LIU B, 2000, RC21695 IBM; PAVEL B, 2002, SURVEY CLUSTERING DA; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Rousseeuw P. J., 1990, FINDING GROUPS DATA; Shepard R. N., 1972, MULTIDIMENSIONAL SCA	11	0	0	ASSOC INTELLIGENT MACHINERY	DURHAM	PO BOX 90291, DURHAM, NC 27708-0291 USA			0-9707890-2-5				2003							883	886				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BX96T	WOS:000187061500217		
B	Laubach, M; Arieh, Y; Luczak, A; Oh, J; Xu, Y		Reisman, S; Foulds, R; Mantilla, B		Laubach, M; Arieh, Y; Luczak, A; Oh, J; Xu, Y			A cluster of workstations for on-line analyses of neurophysiological data	PROCEEDINGS OF THE IEEE 29TH ANNUAL NORTHEAST BIOENGINEERING CONFERENCE			English	Proceedings Paper	IEEE 29th Annual Northeast Bioengineering Conference	MAR 22-23, 2003	NEWARK, NJ	Schering Plough, Becton Dickinson, Boston Sci, Reva Med, Vyteris, Whitaker Fdn, NJIT Pre Coll Programs, NJIT Student Senate, NJIT Grad Student Assoc	NJ INST TECHNOL	Brain-Machine Interface; cluster computing; neurophysiology; data mining	NEURONS	Recent advances in the fields of neuroscience, computer science, and biomedical engineering now allow for the analysis of large-scale neurophysiological data sets to be carried out on-line and in real time. Here, we described an on-going effort in our research laboratory to build a computer system that will allow for on-line, real-time analyses of the response properties of ensembles of neurons (as many as 256) recorded in the brains of awake animals that perform behavioral tasks. A cluster of workstations allows us to carry out sequential and simultaneous analyses of neuronal signals. This new methodology can be used to change a behavioral task on-line to test real-time decoding of brain signals.	Yale Univ, John B Pierce Lab, New Haven, CT 06519 USA	Laubach, M (reprint author), Yale Univ, John B Pierce Lab, 333 Cedar St, New Haven, CT 06519 USA.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chapin JK, 1999, NAT NEUROSCI, V2, P664, DOI 10.1038/10223; Laubach M, 2000, NATURE, V405, P567, DOI 10.1038/35014604; Nicolelis MAL, 2002, SCI AM, V287, P46; SAITO N, 1994, P SPIE, V2303; Wessberg J, 2000, NATURE, V408, P361	6	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7767-2				2003							17	18				2	Computer Science, Artificial Intelligence; Engineering, Biomedical; Instruments & Instrumentation; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Instruments & Instrumentation; Radiology, Nuclear Medicine & Medical Imaging	BX14C	WOS:000184414900007		
B	Hall, LO; Bowyer, KW; Banfield, RE; Bhadoria, D		Wu, XD; Tuzhilin, A; Shavlik, J		Hall, LO; Bowyer, KW; Banfield, RE; Bhadoria, D			Comparing pure parallel ensemble creation techniques against bagging	THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	MELBOURNE, FL	IEEE Comp Soc TCCI, IEEE Comp Soc TCPAMI				We experimentally evaluate randomization-based approaches to creating an ensemble of decision-tree classifiers. Unlike methods related to boosting, all of the eight approaches considered here create each classifier in an ensemble independently of the other classifiers. Experiments were performed on 28 publicly available datasets, using C4.5 release 8 as the base classifier While each of the other seven approaches has some strengths, we find that none of them is consistently more accurate than standard bagging when tested for statistical significance.	Univ S Florida, Tampa, FL 33620 USA	Hall, LO (reprint author), Univ S Florida, Tampa, FL 33620 USA.		Bowyer, Kevin/	Bowyer, Kevin/0000-0002-7562-4390			Bowyer KW, 2000, IEEE SYS MAN CYBERN, P1888, DOI 10.1109/ICSMC.2000.886388; BRAZDIL P, 1998, STATLOG PROJECT EVAL; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chawla NV, 2003, PATTERN RECOGN LETT, V24, P455, DOI 10.1016/S0167-8655(02)00269-6; Collins M., 2000, P 13 ANN C COMP LEAR, P158; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HULTEN G, 2002, ADV NEURAL INFORMATI, V14, P673; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Merz C.J., UCI REPOSITORY MACHI; Quinlan J.R., 1992, C4 5 PROGRAMS MACHIN; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Witten I. H., 1999, DATA MINING PRACTICA	15	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1978-4				2003							533	536				4	Computer Science, Artificial Intelligence	Computer Science	BY34Z	WOS:000188999400075		
B	Li, JY; Liu, HQ		Wu, XD; Tuzhilin, A; Shavlik, J		Li, JY; Liu, HQ			Ensembles of cascading trees	THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	MELBOURNE, FL	IEEE Comp Soc TCCI, IEEE Comp Soc TCPAMI			ACUTE LYMPHOBLASTIC-LEUKEMIA; GENE-EXPRESSION PROFILES; CLASSIFICATION	We introduce a new method, called CS4, to construct committees of decision trees for classification. The method considers different top-ranked features as the root nodes of member trees. This idea is particularly suitable for dealing with high-dimensional bio-medical data as top-ranked features in this type of data usually possess similar merits for classification. To make a decision, the committee combines the power of individual trees in a weighted manner Unlike Bagging or Boosting which uses bootstrapped training data, our method builds all the member trees of a committee using exactly the same set of training data. We have tested these ideas on UC1 data sets as well as recent bio-medical data sets of gene expression or proteomic profiles that are usually described by more than 10,000 features. All the experimental results show that our method is efficient and that the classification performance are superior to C4.5 family algorithms.	Inst Infocomm Res, Singapore 119613, Singapore	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; LI J, 2003, IN PRESS BIOINFORMAT, V19; Li Jun, 2003, Control & Automation; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	11	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1978-4				2003							585	588				4	Computer Science, Artificial Intelligence	Computer Science	BY34Z	WOS:000188999400088		
S	Estruch, V; Ferri, C; Hernandez-Orallo, J; Ramirez-Quintana, MJ		Garijo, FJ; Riquelme, JC; Toro, M		Estruch, V; Ferri, C; Hernandez-Orallo, J; Ramirez-Quintana, MJ			Shared ensemble learning using multi-trees	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2002, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	8th Ibero-American Conference on Artifical Intelligence (IBERAMIA 02)	NOV 12-15, 2002	SEVILLE, SPAIN	Univ Sevilla, CICYT, FIDETIA		decision-tree learning; decision support systems; boosting; machine learning; hypothesis combination; randomisation		Decision tree learning is a machine learning technique that allows accurate and comprehensible models to be generated. Accuracy can be improved by ensemble methods which combine the predictions of a set of different trees. However, a large amount of resources is necessary to generate the ensemble. In this paper, we introduce a new ensemble method that minimises the usage of resources by sharing the common parts of the components of the ensemble. For this purpose, we learn a decision multi-tree instead of a decision tree. We call this new approach shared ensembles. The use of a multi-tree produces an exponential number of hypotheses to be combined, which provides better results than boosting/bagging. We performed several experiments, showing that the technique allows us to obtain accurate models and improves the use of resources with respect to classical ensemble methods.	Univ Politecn Valencia, DSIC, Valencia 46020, Spain	Estruch, V (reprint author), Univ Politecn Valencia, DSIC, Camino Vera S-N, Valencia 46020, Spain.	vestruch@dsic.upv.es; cferri@dsic.upv.es; jorallo@dsic.upv.es; mramirez@dsic.upv.es	Ramirez Quintana, Maria Jose/H-9174-2015; Ferri Ramirez, Cesar/H-9181-2015; Hernandez-Orallo, Jose/H-9166-2015	Ramirez Quintana, Maria Jose/0000-0002-0559-3568; Ferri Ramirez, Cesar/0000-0002-8975-1120; Hernandez-Orallo, Jose/0000-0001-9746-7632			Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; FERRI C, 2002, LEARNING MULTIPLE DI; FERRI C, 2002, LNCS; FERRI C, 2002, SMILES SYSTEM MULTIP; Freund Y., 1996, 13 INT C MACH LEARN, P148; Ho T. K., 1995, P 3 INT C DOC AN REC, P278; HO TK, 1998, P 14 INT C PATT REC, P545; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; MARGINEANTU D.D., 1997, 14 INT C MACH LEARN, P211; Nilsson N., 1998, ARTIFICIAL INTELLIGE; Pearl J., 1985, HEURISTICS INTELLIGE; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; QUINLAN JR, 1990, READ MACHINE LEARNIN; *U CA, UCI MACH REP CONT SU; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zheng ZJ, 1998, PROC INT C TOOLS ART, P216; Zheng ZJ, 1998, LECT NOTES ARTIF INT, V1502, P321	21	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-00131-X	LECT NOTES ARTIF INT			2002	2527						204	213				10	Computer Science, Artificial Intelligence	Computer Science	BY35P	WOS:000189008100021		
S	Kim, Y; Street, WN; Menczer, F			IEEE; IEEE	Kim, Y; Street, WN; Menczer, F			Meta-evolutionary ensembles	PROCEEDING OF THE 2002 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-3	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN 02)	MAY 12-17, 2002	HONOLULU, HI	IEEE, IEEE Neural Networks Soc, Int Neural Network Soc			DECISION FORESTS	Ensemble methods have shown the potential to improve on the performance of individual classifiers as long as the members of the ensemble are sufficiently diverse. In this paper we propose a meta-evolutionary approach in which both individual classifiers and ensembles adapt. Ensembles compete for member classifiers, and are rewarded based on their predictive performance. Individual classifiers also evolve, competing to correctly classify test points, and are given extra rewards for getting difficult points right. In this way we aim to build small-sized optimal ensembles rather than form large-sized ensembles of individually-optimized classifiers. We use neural networks as individual classifiers, and feature selection to promote the diversity among classifiers in the same ensemble. Experimental results on 17 data sets suggest that our algorithms can generate ensembles that are more effective than single classifiers and traditional ensemble methods. We also use the evolutionary framework to explore the role of ensemble characteristics such as size and diversity in creating accurate ensembles.	Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA	Kim, Y (reprint author), Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA.						Breiman L, 1996, MACH LEARN, V24, P49; Breiman L., 1996, 460 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1999, 567 U CAL DEP STAT; Cunningham P., 2000, TCDCS200002 DEP COMP; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Guerra-Salcedo C, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P236; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HO TK, 1998, P 14 INT C PATT REC, P545; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Opitz DW, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P379; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Streets T. H., 1877, B US NATL MUSEUM, V7, P1	13	9	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-7278-6	IEEE IJCNN			2002							2791	2796				4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BU92F	WOS:000177402800494		
B	Kamath, C; Cantu-Paz, E; Littau, D		Grossman, R; Han, J; Motwani, R; Kumar, V; Mannila, H		Kamath, C; Cantu-Paz, E; Littau, D			Approximate splitting for ensembles of trees using histograms	PROCEEDINGS OF THE SECOND SIAM INTERNATIONAL CONFERENCE ON DATA MINING	SIAM PROCEEDINGS SERIES		English	Proceedings Paper	2nd SIAM International Conference on Data Mining (SDM 02)	APR 11-13, 2002	ARLINGTON, VA	SIAM			DECISION TREES		Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94551 USA	Kamath, C (reprint author), Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, POB 808,L-561, Livermore, CA 94551 USA.						ALSABTI K, 1998, 4 INT C KNOWL DISC D, P2; Breiman L., 1999, 567 U CAL STAT DEP; BREIMAN L, 1996, PASTING BITES TOGETH; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1984, CLASSIFICATION REGRE; Catlett J., 1991, THESIS U SYDNEY; Cherkauer K. J., 1996, AAAI WORKSH INT MULT; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich T.G., 2000, P 1 INT WORKSH MULT, P1; Dougherty J., 1995, MACHINE LEARNING; Elomma T., 1999, MACH LEARN, P1; FAYYAD U, 1992, MACH LEARN, V9, P87; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Hall L.O., 2000, WORKSH DISTR PAR KNO; HO K, 1997, P KDD 97 3 INT C KNO; Ho T. K., 1995, P 3 INT C DOC AN REC, P278; KAMATH C, 2001, P 33 S INT COMP SCI; Kerber R., 1992, P 10 NAT C ART INT, P123; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Liu H, 1995, PROC INT C TOOLS ART, P388; MURTHY KVS, 1997, THESIS JOHNS HOPKINS; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Susmaga R., 1997, INTELL DATA ANAL, V1, P157, DOI 10.1016/S1088-467X(97)00007-3; 2001, UCI KNOWLEDGE DISCOV	28	3	3	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			0-89871-517-2	SIAM PROC S			2002							370	383				14	Computer Science, Artificial Intelligence	Computer Science	BU81X	WOS:000177123500022		
J	Breiman, L				Breiman, L			Random forests	MACHINE LEARNING			English	Article						classification; regression; ensemble		Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148-156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.	Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Breiman, L (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.		Moorthy, Kohbalan/B-2470-2015	Moorthy, Kohbalan/0000-0002-6184-0359			Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Amit Y., 1999, MULTIPLE RANDOMIZED; Breiman L, 2000, 579 UCB STAT DEP; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 1998, IN PRESS MACHINE LEA; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Breiman Leo, 1999, 547 UCB STAT DEP; Dietterich T.G., 1998, MACH LEARN, P1; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Grove A., 1998, P 15 NAT C ART INT; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kleinberg EM, 2000, IEEE T PATTERN ANAL, V22, P473, DOI 10.1109/34.857004; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Tibshirani Robert, 1996, BIAS VARIANCE PREDIC; WOLPERT DH, 1997, IN PRESS MACHINE LEA	17	7813	8103	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	OCT	2001	45	1					5	32		10.1023/A:1010933404324		28	Computer Science, Artificial Intelligence	Computer Science	463QZ	WOS:000170489900001		
J	Breiman, L				Breiman, L			Statistical modeling: The two cultures	STATISTICAL SCIENCE			English	Article							LOGISTIC-REGRESSION	There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.	Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Breiman, L (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.						Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; ARENA C, 2000, 2 IND US WORKSH MATH; BICKEL P, 2001, UNPUB TAILOR MADE TE; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L., 2000, SOME INFINITY THEORY; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cristianini N., 2000, INTRO SUPPORT VECTOR; Daniel C., 1971, FITTING EQUATIONS DA; Dempster AP, 1998, STAT SCI, V13, P248; DIACONIS P, 1983, SCI AM, V248, P116; Domingos P., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; Dudoit S., 2000, COMP DISCRIMINATION; FREEDMAN D, 1991, FDN SCI, V1, P19; Freedman D, 1997, ADV APPL MATH, V18, P59, DOI 10.1006/aama.1996.0501; FREEDMAN D, 1991, SOCIOL METHODOL, P291; FREEDMAN DA, 1987, J EDUC STAT, V12, P101; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN J, 1999, GREEDY PREDICTIVE AP; Gifi A, 1990, NONLINEAR MULTIVARIA; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; LANDWEHR JM, 1984, J AM STAT ASSOC, V79, P61, DOI 10.2307/2288334; McCullagh P., 1989, GEN LINEAR MODELS, Vsecond; Meisel W.S., 1972, COMPUTER ORIENTED AP; Michie D., 1994, MACHINE LEARNING NEU; Mosteller F., 1977, DATA ANAL REGRESSION; MOUNTAIN D, 1989, J AM STAT ASSOC, V84, P76; STONE M, 1974, J R STAT SOC B, V36, P111; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; Wahba G., 1990, SPLINE MODELS OBSERV; Zhang H, 1999, RECURSIVE PARTITIONI	37	495	509	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0883-4237			STAT SCI	Stat. Sci.	AUG	2001	16	3					199	215		10.1214/ss/1009213726		17	Statistics & Probability	Mathematics	504FP	WOS:000172846900001		
B	Wheway, V		Cercone, N; Lin, TY; Wi, XD		Wheway, V			Using boosting to simplify classification models	2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	IEEE International Conference on Data Mining	NOV 29-DEC 02, 2001	SAN JOSE, CA	IEEE Comp Soc, TCPAMI, IEEE Comp Soc, TFVI, Insightful Corp, Microsoft Res, NARAX Inc, Springer Verlag, New York, StatSoft Inc				Ensemble classification techniques such as bagging, boosting and arcing algorithms have been shown to lead to reduced classification error on unseen cases and seem immune to the problem of overfitting. Several explanations for the reduction in generalisation error have been presented, with authors more recently defining and applying diagnostics such as edge and margin [4,9,10]. These measures provide insight into the behaviour of ensemble classifiers but can they be exploited further? In this paper a four stage classification procedure in introduced, which is based on an extension of edge and margin analysis. This new procedure allows inverse sub-contexts and difficult border regions to be detected using properties of the edge distribution. It is widely known that ensemble classifiers 'balance' the margin as the number of iterations increases. However by exploiting this balancing property and flagging observations whose edges (and margins) are not 'balanced', datasets can often be partitioned into subcontexts and classification made more robust as confounding within a dataset is removed. In the majority of cases, the subcontexts detected are inverse to each other or quite possibly, the smaller sub-context contains mislabelled observations. The majority of classification techniques have not been adapted to detect contexts within a dataset and the generalisation error reported in studies to date is based on the entire dataset and can be improved by partitioning the dataset in question. The aim of this study is to move towards interpretability, and it is shown that by training on a subset of the original training data we gain simplicity of models and reduced generalisation error.	Univ Wollongong, Sch Math & Appl Stat, Sch Informat Technol & Comp Sci, Wollongong, NSW 2522, Australia	Wheway, V (reprint author), Univ Wollongong, Sch Math & Appl Stat, Sch Informat Technol & Comp Sci, Wollongong, NSW 2522, Australia.						Bias Breiman L., 1996, 460 U CAL STAT DEP; Blake C., 1988, UCI REPOSITORY MACHI; Breiman L., 1999, 567 U CAL STAT DEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 1997, 486 U CAL STAT DEP; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Schapire RE, 1998, ANN STAT, V26, P1651; WHEWAY VL, 2000, IN PRESS LECT NOTES, V2112	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1119-8				2001							558	565				8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BT50G	WOS:000173158200071		
J	Breiman, L				Breiman, L			Additive logistic regression: A statistical view of boosting - Discussion	ANNALS OF STATISTICS			English	Editorial Material									Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Breiman, L (reprint author), Univ Calif Berkeley, Dept Stat, 367 Evans Hall,3860, Berkeley, CA 94720 USA.						Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Breiman L., 1999, RANDOM FORESTS; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; WHEWAY V, 1999, VARIANCE REDUCTION T	5	3	3	INST MATHEMATICAL STATISTICS	HAYWARD	IMS BUSINESS OFFICE-SUITE 7, 3401 INVESTMENT BLVD, HAYWARD, CA 94545 USA	0090-5364			ANN STAT	Ann. Stat.	APR	2000	28	2					374	377				4	Statistics & Probability	Mathematics	360LT	WOS:000089669700002		
